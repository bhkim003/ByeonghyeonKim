{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25706/652520392.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "                    dvs_relative_timestep = True, \n",
    "                    \n",
    "                    I_wanna_sweep_at_this_epoch = -1,\n",
    "                    dvs_duration_domain = [],\n",
    "\n",
    "                    extra_train_dataset = 0,\n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = False,\n",
    "                    pin_memory = True, # True # False\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    test_loader_domain_set = []\n",
    "    test_loader_domain_set.append(test_loader)\n",
    "    ###########################################################################################################################################\n",
    "    \n",
    "    ## 다른 dvs duration domain을 validation set으로 불러오기 ##############################################################\n",
    "    dvs_duration_domain_temp = []\n",
    "    if len(dvs_duration_domain) > 0:\n",
    "        for domain in dvs_duration_domain:\n",
    "            target_domain_timestep = (dvs_duration*TIME)//domain[0] if dvs_relative_timestep == True else TIME\n",
    "            dvs_duration_domain_temp.append(domain + (target_domain_timestep,))\n",
    "            train_loader_domain, test_loader_domain, synapse_conv_in_channels_domain, CLASS_NUM_domain = data_loader(\n",
    "                    which_data,\n",
    "                    data_path, \n",
    "                    rate_coding, \n",
    "                    BATCH, \n",
    "                    IMAGE_SIZE,\n",
    "                    ddp_on,\n",
    "                    target_domain_timestep,\n",
    "                    domain[1], # dvs_clipping\n",
    "                    domain[0], # dvs_duration\n",
    "                    exclude_class,\n",
    "                    merge_polarities,\n",
    "                    domain[2], # denoise_on \n",
    "                    my_seed,\n",
    "                    extra_train_dataset,\n",
    "                    num_workers,\n",
    "                    chaching_on,\n",
    "                    pin_memory)\n",
    "            test_loader_domain_set.append(test_loader_domain)\n",
    "        dvs_duration_domain = dvs_duration_domain_temp\n",
    "    ######################################################################################################################\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (I_wanna_sweep_at_this_epoch == epoch):\n",
    "            net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "            no_val_best_growth_count = 0\n",
    "            DFA_current = not DFA_current\n",
    "            DFA_toggle = True\n",
    "            DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "        else:\n",
    "            if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "                assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "                if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap :\n",
    "                    if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                        net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                        no_val_best_growth_count = 0\n",
    "                        DFA_current = not DFA_current\n",
    "                        DFA_toggle = True\n",
    "                        DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "                if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                    if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                        net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                        no_tr_best_growth_count = 0\n",
    "                        DFA_current = not DFA_current\n",
    "                        DFA_toggle = True\n",
    "                        DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################         \n",
    "                               \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "                \n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                domain_index = 0\n",
    "                val_loss_set = []\n",
    "                val_acc_now_set = []\n",
    "                while True:\n",
    "                    val_loss = 0\n",
    "                    correct_val = 0\n",
    "                    total_val = 0\n",
    "                    test_loader = test_loader_domain_set[domain_index]\n",
    "                    domain_index = domain_index + 1\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        net.eval() # eval 모드로 바꿔줘야함 \n",
    "                        for data_val in test_loader:\n",
    "                            ## data_val loading & semi-pre-processing ##########################################################\n",
    "                            if len(data_val) == 2:\n",
    "                                inputs_val, labels_val = data_val\n",
    "                                # 처리 로직 작성\n",
    "                            elif len(data_val) == 3:\n",
    "                                inputs_val, labels_val, x_len = data_val\n",
    "                                # print('x_len',x_len)\n",
    "                                # mask = padded_sequence_mask(x_len)\n",
    "                                # max_time_step = x_len.max()\n",
    "                                # min_time_step = x_len.min()\n",
    "                                # B, T, *spatial_dims = inputs_val.shape\n",
    "                            else:\n",
    "                                assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                                inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            elif rate_coding == True :\n",
    "                                inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                            else :\n",
    "                                inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                            # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                            ###################################################################################################\n",
    "\n",
    "                            inputs_val = inputs_val.to(device)\n",
    "                            labels_val = labels_val.to(device)\n",
    "                            real_batch = labels_val.size(0)\n",
    "                            \n",
    "                            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                            if (which_data == 'DVS_GESTURE'):\n",
    "                                labels_val[labels_val>2] -= 1\n",
    "                            #######################################################\n",
    "                            \n",
    "                            if merge_polarities == True:\n",
    "                                inputs_val = inputs_val[:,:,0,:,:]\n",
    "\n",
    "                            ## network 연산 시작 ############################################################################################################\n",
    "                            if single_step == False:\n",
    "                                outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                                val_loss_val += criterion(outputs, labels_val)/len(test_loader)\n",
    "                            else:\n",
    "                                outputs_all = []\n",
    "                                for t in range(TIME):\n",
    "                                    outputs = net(inputs_val[t])\n",
    "                                    val_loss_temp = criterion(outputs, labels_val)\n",
    "                                    outputs_all.append(outputs.detach())\n",
    "                                    val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                                outputs = outputs_all.mean(1)\n",
    "                            val_loss_set.append(val_loss)\n",
    "                            #################################################################################################################################\n",
    "\n",
    "                            _, predicted = torch.max(outputs.data, 1)\n",
    "                            total_val += real_batch\n",
    "                            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                            correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                        val_acc_now = correct_val / total_val\n",
    "                        # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "                        val_acc_now_set.append(val_acc_now)\n",
    "\n",
    "                    if domain_index == len(dvs_duration_domain) + 1:\n",
    "                        break\n",
    "\n",
    "                val_loss = val_loss_set[0]\n",
    "                val_acc_now = val_acc_now_set[0]\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    if len(dvs_duration_domain) > 0:\n",
    "                        dvs_duration_full = [(dvs_duration, dvs_clipping, denoise_on, TIME)] + dvs_duration_domain\n",
    "                        print(\" | \".join(f\"{dvs_duration_full[i][0]:,}c{dvs_duration_full[i][1]}d{dvs_duration_full[i][2]}t{dvs_duration_full[i][3]}:{val_acc_now_set[i]*100:.2f}%\" for i in range(len(val_acc_now_set))))\n",
    "                    iter_of_val = False\n",
    "            \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "\n",
    "\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"0\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 60, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.720291189014991, # 1.3102821334243646,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 3.555718888923306, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.0001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "#                 # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "#                 drop_rate = 0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = True, # True # False\n",
    "\n",
    "#                 I_wanna_sweep_at_this_epoch = -1, # 지정 에포크에서 BP와 DFA를 바꿔줌. -1이면 실행 안함.\n",
    "#                 # dvs_duration_domain=[(100_000,5,False),(125_000,5,False),(150_000,5,False),],\n",
    "#                 # dvs_duration_domain=[(40_000,4,False),(50_000,4,False),(60_000,4,False),],\n",
    "#                 # [duration, clipping, denoise_on]\n",
    "#                 dvs_duration_domain=[(25_000,1,False)],\n",
    "#                 dvs_relative_timestep = False, # True # False \n",
    "                \n",
    "#                 extra_train_dataset = 0,\n",
    "\n",
    "#                 num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "#                 chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드0\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hei1zyia with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241010_225400-hei1zyia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hei1zyia' target=\"_blank\">colorful-sweep-46</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hei1zyia' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hei1zyia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 6bfe112fbeab20d0d3bfdbe39d8150a3\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304236/  2.298794, tr:   8.89%, val:  14.17%, val_best:  14.17%: 100%|██████████| 62/62 [00:33<00:00,  1.84it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.203609/  2.016125, tr:  26.66%, val:  34.58%, val_best:  34.58%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.728984/  1.649610, tr:  48.01%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:06<00:00,  8.93it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.391955/  1.501894, tr:  62.21%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.226112/  1.402464, tr:  66.70%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.119565/  1.362296, tr:  68.34%, val:  61.67%, val_best:  62.92%: 100%|██████████| 62/62 [00:07<00:00,  8.64it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.035965/  1.313606, tr:  73.44%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.966858/  1.374587, tr:  76.20%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:07<00:00,  8.60it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.892671/  1.296228, tr:  81.51%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.60it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.848597/  1.311893, tr:  82.94%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.815480/  1.286381, tr:  81.92%, val:  67.50%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.31it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.733663/  1.337462, tr:  87.64%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.704963/  1.298387, tr:  88.15%, val:  65.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.705550/  1.231946, tr:  82.33%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  8.68it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.605784/  1.286165, tr:  93.16%, val:  73.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  7.88it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.573929/  1.310657, tr:  94.38%, val:  72.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  8.41it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.529981/  1.328887, tr:  94.69%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.08it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.491213/  1.298439, tr:  94.99%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:07<00:00,  7.87it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.440299/  1.375841, tr:  98.06%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:07<00:00,  8.46it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.404865/  1.341142, tr:  97.34%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:07<00:00,  8.34it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.375271/  1.413831, tr:  98.77%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.85it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.354075/  1.429661, tr:  99.18%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  7.92it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.329391/  1.434701, tr:  98.37%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.30it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286002/  1.503995, tr:  99.49%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.35it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.280720/  1.520843, tr:  99.49%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.51it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.260556/  1.519406, tr:  99.08%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.23it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.239602/  1.489707, tr:  99.59%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.26it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.214336/  1.590168, tr:  99.80%, val:  76.25%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.05it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.194782/  1.590421, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.184622/  1.617384, tr:  99.69%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.10it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.155004/  1.638006, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.10it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.150049/  1.657414, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:08<00:00,  7.31it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.136008/  1.707090, tr:  99.90%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  7.85it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.120515/  1.719182, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.00it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.115295/  1.766462, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  7.76it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.108454/  1.724638, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.100750/  1.787329, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.094926/  1.790928, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.084988/  1.833029, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.23it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.076725/  1.857871, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.070269/  1.866846, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.066107/  1.889085, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.065185/  1.917872, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.060466/  1.930752, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.052165/  1.949669, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.051564/  1.948518, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.048577/  1.972968, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.043894/  2.009741, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.040187/  2.004321, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.040160/  2.041957, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.041800/  2.079787, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.036610/  2.073794, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.036187/  2.091018, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.036375/  2.090957, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.033241/  2.080374, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.031923/  2.107308, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.030266/  2.128878, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.029362/  2.125573, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.029604/  2.113382, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.026971/  2.109569, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.024844/  2.132056, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.026775/  2.137433, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.032530/  2.172341, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.054217/  2.167245, tr:  99.90%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.026245/  2.136009, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.023479/  2.180834, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.021528/  2.175549, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.019567/  2.205206, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.019132/  2.194048, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.018398/  2.209348, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.019208/  2.220838, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.019316/  2.232343, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.017157/  2.258237, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.015641/  2.248618, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.015142/  2.244815, tr: 100.00%, val:  82.50%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.019021/  2.274572, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.017694/  2.284900, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.015639/  2.298601, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.016916/  2.305635, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.013835/  2.305021, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.013421/  2.304647, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.012761/  2.310547, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.013760/  2.289483, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.013523/  2.346805, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.012925/  2.324124, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.013325/  2.333296, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.017561/  2.336429, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.013502/  2.350425, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.012679/  2.366928, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.013656/  2.347122, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.011719/  2.345309, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.011827/  2.372918, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.010636/  2.344129, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.010654/  2.360234, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.010291/  2.384094, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.010435/  2.381706, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.009610/  2.394557, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.009720/  2.395812, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.009519/  2.374839, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.009946/  2.405029, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.009055/  2.415302, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.008838/  2.411055, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.008206/  2.412015, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.008204/  2.432309, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.008499/  2.433718, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.008134/  2.414011, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.008635/  2.414528, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.008034/  2.425467, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.007689/  2.434799, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.007922/  2.435584, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.011789/  2.448330, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.011322/  2.442972, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.008203/  2.447995, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.007994/  2.463811, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.007717/  2.475939, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.007766/  2.480775, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.007572/  2.484080, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.007445/  2.490935, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.007049/  2.498440, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.008071/  2.487993, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.007356/  2.481939, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.008912/  2.508793, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.007761/  2.516114, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.008023/  2.519284, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.007422/  2.507771, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.006827/  2.508328, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.007280/  2.495243, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.006561/  2.493504, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.007117/  2.509325, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.006179/  2.518638, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.006615/  2.518399, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:08<00:00,  7.23it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.006610/  2.513843, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.006324/  2.519391, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.006896/  2.526285, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.006452/  2.508285, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.005759/  2.512332, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.005511/  2.508381, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.005927/  2.524084, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.006049/  2.529489, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.006099/  2.519903, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.005806/  2.522478, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.007588/  2.528255, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.006224/  2.540487, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.005982/  2.532003, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.005540/  2.531454, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.005412/  2.521798, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.006124/  2.510025, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.005669/  2.518521, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.005914/  2.519836, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.005478/  2.538046, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.004980/  2.528104, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.005338/  2.536566, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.004809/  2.546389, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.005568/  2.542963, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.005910/  2.550191, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.005287/  2.562010, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.005139/  2.549510, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.005029/  2.546520, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.005013/  2.544308, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.005080/  2.549368, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.005139/  2.571193, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.004725/  2.585514, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.004714/  2.581609, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.005086/  2.586900, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.004985/  2.584191, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.004623/  2.585135, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.004688/  2.602354, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.004659/  2.582090, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.004617/  2.577765, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.004696/  2.586109, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.004816/  2.597320, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.004361/  2.581500, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.005020/  2.605011, tr: 100.00%, val:  80.83%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.004370/  2.598333, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.005312/  2.618077, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.004556/  2.615742, tr: 100.00%, val:  79.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.004116/  2.610780, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.004351/  2.615878, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.004396/  2.614948, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.004068/  2.626645, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.004291/  2.627993, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.003939/  2.621647, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.004319/  2.630840, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.004095/  2.626323, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.003999/  2.619763, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.004377/  2.632501, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.003942/  2.632138, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.004053/  2.632462, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.004072/  2.641497, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.003815/  2.653848, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.003804/  2.630570, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.004080/  2.633395, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.004208/  2.629344, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.005053/  2.635332, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.004551/  2.642791, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.003839/  2.630698, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.003746/  2.624960, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.003700/  2.629864, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.003842/  2.642191, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.003475/  2.639536, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f88e0f4ef04e30a4d8de4e6d7b73d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.418 MB of 4.418 MB uploaded (3.196 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 69.2%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>val_loss</td><td>▅▁▁▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00348</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.8375</td></tr><tr><td>val_loss</td><td>2.63954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-46</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hei1zyia' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hei1zyia</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241010_225400-hei1zyia/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6hsl1bpo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 50000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241010_231522-6hsl1bpo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6hsl1bpo' target=\"_blank\">brisk-sweep-49</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6hsl1bpo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6hsl1bpo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 0d8b728364de4ecf8568b4c6954ef3a4\n",
      "cache path doesn't exist\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304453/  2.302613, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [02:35<00:00,  2.51s/it]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304370/  2.302693, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305113/  2.302622, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304620/  2.302310, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.300770/  2.291932, tr:  11.95%, val:  12.08%, val_best:  12.08%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.225334/  2.170034, tr:  17.16%, val:  18.33%, val_best:  18.33%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.008942/  1.989219, tr:  29.01%, val:  35.42%, val_best:  35.42%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.729117/  1.796698, tr:  48.62%, val:  38.75%, val_best:  38.75%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.510947/  1.694535, tr:  55.98%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.381977/  1.639410, tr:  60.67%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.290323/  1.643694, tr:  66.29%, val:  45.00%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.222795/  1.630342, tr:  69.25%, val:  47.92%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.169098/  1.581748, tr:  72.01%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.142895/  1.558527, tr:  73.24%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.048723/  1.565450, tr:  78.65%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.010010/  1.561648, tr:  80.39%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.985045/  1.607529, tr:  82.64%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.929037/  1.572528, tr:  83.04%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.882120/  1.620134, tr:  85.60%, val:  53.75%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.846214/  1.567206, tr:  87.54%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.801794/  1.623613, tr:  89.68%, val:  59.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.770950/  1.623446, tr:  91.73%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.736301/  1.638053, tr:  91.01%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698552/  1.736465, tr:  92.44%, val:  60.83%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.698593/  1.735917, tr:  91.73%, val:  57.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.654873/  1.751812, tr:  94.08%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.616599/  1.718845, tr:  94.89%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.594170/  1.779879, tr:  94.59%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.567737/  1.752383, tr:  96.32%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.558051/  1.829662, tr:  95.20%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.519754/  1.783612, tr:  96.53%, val:  64.17%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.498050/  1.814247, tr:  97.14%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.467611/  1.873927, tr:  97.24%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.453829/  1.945429, tr:  97.75%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.434357/  1.983273, tr:  97.45%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.401538/  2.001785, tr:  97.85%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.393430/  2.021288, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.383840/  2.019406, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.352348/  2.077858, tr:  98.57%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.337143/  2.123051, tr:  98.88%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.327187/  2.094044, tr:  98.77%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.303727/  2.182719, tr:  98.88%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.295676/  2.205085, tr:  98.98%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.285624/  2.282178, tr:  99.18%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.267487/  2.239787, tr:  98.98%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.254357/  2.309304, tr:  99.08%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.251039/  2.325897, tr:  99.28%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.231962/  2.399669, tr:  99.59%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.227673/  2.378632, tr:  99.39%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.214757/  2.406626, tr:  99.49%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.210652/  2.467655, tr:  99.59%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.200284/  2.422487, tr:  99.49%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.210335/  2.496546, tr:  99.69%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.194084/  2.523542, tr:  99.80%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.183544/  2.526844, tr:  99.59%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.168971/  2.588564, tr:  99.80%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.164101/  2.548164, tr:  99.69%, val:  64.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.168199/  2.603082, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.156458/  2.612416, tr:  99.80%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.156114/  2.653112, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.150686/  2.703130, tr:  99.80%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.148362/  2.674302, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.140094/  2.734603, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.129976/  2.742191, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.131548/  2.774594, tr:  99.90%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.134058/  2.789547, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.124165/  2.804651, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.120506/  2.806127, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.113658/  2.851587, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.107899/  2.851581, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.109808/  2.865618, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.109130/  2.870938, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.101528/  2.895401, tr:  99.90%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.099936/  2.879575, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.099223/  2.900136, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.104835/  2.939298, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.103599/  2.955451, tr: 100.00%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.091016/  2.937270, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.090395/  2.970046, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.094301/  3.028446, tr:  99.80%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.084386/  2.989377, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.076960/  3.059082, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.081167/  3.023106, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.079329/  3.074957, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.079408/  3.078703, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.078313/  3.108752, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.073337/  3.073727, tr:  99.90%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.069771/  3.120673, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.071667/  3.141786, tr: 100.00%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.067946/  3.119981, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.065193/  3.139883, tr:  99.90%, val:  66.67%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.066376/  3.163111, tr:  99.90%, val:  66.25%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.061751/  3.167231, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.064184/  3.185883, tr: 100.00%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.062342/  3.198515, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.061584/  3.242489, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.059837/  3.232558, tr: 100.00%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.057179/  3.200498, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.057694/  3.256129, tr: 100.00%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.058504/  3.289832, tr: 100.00%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.057030/  3.253619, tr:  99.90%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.055641/  3.290505, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.055002/  3.250223, tr:  99.90%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.054756/  3.339558, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.054725/  3.281593, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.058926/  3.318944, tr:  99.90%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.056122/  3.336075, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.052472/  3.315499, tr:  99.90%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.054250/  3.403196, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.048881/  3.441761, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.055467/  3.394903, tr:  99.90%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.065678/  3.366781, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.054403/  3.390027, tr: 100.00%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.053404/  3.402450, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.048982/  3.382859, tr: 100.00%, val:  64.58%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.044795/  3.406709, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.048061/  3.444878, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.044510/  3.429260, tr: 100.00%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.045463/  3.503633, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.047742/  3.462282, tr:  99.90%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.043883/  3.519145, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.045606/  3.469776, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.041058/  3.489861, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.040050/  3.487185, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.040463/  3.521026, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.039054/  3.520821, tr: 100.00%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.039658/  3.453574, tr:  99.90%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.039410/  3.516922, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.039714/  3.506242, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.040796/  3.496258, tr:  99.90%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.038810/  3.531704, tr: 100.00%, val:  67.08%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.038022/  3.525686, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.039758/  3.555133, tr:  99.90%, val:  69.58%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.039172/  3.558971, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.038630/  3.583277, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.034586/  3.573347, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.034504/  3.591938, tr: 100.00%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.033378/  3.588923, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.033105/  3.591370, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.035078/  3.574950, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.034686/  3.623275, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.034329/  3.599630, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.033085/  3.630665, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.032454/  3.639629, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.030451/  3.619901, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.033445/  3.637792, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.036321/  3.642178, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.035442/  3.628707, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.034931/  3.641021, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.036688/  3.654200, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.030012/  3.641887, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.031947/  3.655067, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.030386/  3.658773, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.029973/  3.679085, tr: 100.00%, val:  70.00%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.029210/  3.695593, tr: 100.00%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.029176/  3.733212, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.030359/  3.723458, tr: 100.00%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.027821/  3.707346, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.027894/  3.724938, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.028003/  3.739951, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.026543/  3.745548, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.026734/  3.694466, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.027620/  3.706000, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.028980/  3.735811, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.029335/  3.708570, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.028421/  3.718160, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.026898/  3.738636, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.025792/  3.732581, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.026253/  3.735591, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.026157/  3.760191, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.025923/  3.782076, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.024423/  3.772164, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.027203/  3.803185, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.027678/  3.795582, tr:  99.90%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.026169/  3.820550, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.024298/  3.812088, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.024153/  3.822913, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.024369/  3.819350, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.026582/  3.811915, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.024102/  3.795786, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.024833/  3.827460, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.024030/  3.817664, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.87it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.022541/  3.836058, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.023178/  3.828174, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.021329/  3.807445, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.022026/  3.817512, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.022002/  3.834085, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.023919/  3.827212, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.023465/  3.834579, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.98it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.023745/  3.801741, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.021754/  3.833331, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 13.13it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.022316/  3.862770, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.022303/  3.857607, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.020717/  3.839989, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.021750/  3.891340, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.021810/  3.885577, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.021115/  3.903272, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.021308/  3.888603, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.97it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.020989/  3.889684, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.019138/  3.886042, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b43546c6484c7b8e921094327a5ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>val_loss</td><td>▃▃▁▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01914</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>3.88604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-49</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6hsl1bpo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6hsl1bpo</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241010_231522-6hsl1bpo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9t4q7m61 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241010_233653-9t4q7m61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9t4q7m61' target=\"_blank\">dandy-sweep-52</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9t4q7m61' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9t4q7m61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 6bfe112fbeab20d0d3bfdbe39d8150a3\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304236/  2.298794, tr:   8.89%, val:  14.17%, val_best:  14.17%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.203609/  2.016125, tr:  26.66%, val:  34.58%, val_best:  34.58%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.728984/  1.649610, tr:  48.01%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.391955/  1.501894, tr:  62.21%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.226112/  1.402464, tr:  66.70%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.119565/  1.362296, tr:  68.34%, val:  61.67%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.035965/  1.313606, tr:  73.44%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.966858/  1.374587, tr:  76.20%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.892671/  1.296228, tr:  81.51%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.848597/  1.311893, tr:  82.94%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.815480/  1.286381, tr:  81.92%, val:  67.50%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.733663/  1.337462, tr:  87.64%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.704963/  1.298387, tr:  88.15%, val:  65.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.705550/  1.231946, tr:  82.33%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.605784/  1.286165, tr:  93.16%, val:  73.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.573929/  1.310657, tr:  94.38%, val:  72.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.529981/  1.328887, tr:  94.69%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.491213/  1.298439, tr:  94.99%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.440299/  1.375841, tr:  98.06%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.404865/  1.341142, tr:  97.34%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.375271/  1.413831, tr:  98.77%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.354075/  1.429661, tr:  99.18%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.329391/  1.434701, tr:  98.37%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286002/  1.503995, tr:  99.49%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.280720/  1.520843, tr:  99.49%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.260556/  1.519406, tr:  99.08%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.239602/  1.489707, tr:  99.59%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.214336/  1.590168, tr:  99.80%, val:  76.25%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.194782/  1.590421, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.184622/  1.617384, tr:  99.69%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.155004/  1.638006, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.150049/  1.657414, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.136008/  1.707090, tr:  99.90%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.120515/  1.719182, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.115295/  1.766462, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.108454/  1.724638, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.100750/  1.787329, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.094926/  1.790928, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.084988/  1.833029, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.076725/  1.857871, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.070269/  1.866846, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.066107/  1.889085, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.065185/  1.917872, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.060466/  1.930752, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.052165/  1.949669, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.051564/  1.948518, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.048577/  1.972968, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.043894/  2.009741, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.040187/  2.004321, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.040160/  2.041957, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.041800/  2.079787, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.036610/  2.073794, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.036187/  2.091018, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.036375/  2.090957, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.033241/  2.080374, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.031923/  2.107308, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.030266/  2.128878, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.029362/  2.125573, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.029604/  2.113382, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.026971/  2.109569, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.024844/  2.132056, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.026775/  2.137433, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.032530/  2.172341, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.054217/  2.167245, tr:  99.90%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.026245/  2.136009, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.023479/  2.180834, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.021528/  2.175549, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.019567/  2.205206, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.019132/  2.194048, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.018398/  2.209348, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.019208/  2.220838, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.019316/  2.232343, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.017157/  2.258237, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.015641/  2.248618, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.015142/  2.244815, tr: 100.00%, val:  82.50%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.019021/  2.274572, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.017694/  2.284900, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.015639/  2.298601, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.016916/  2.305635, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.013835/  2.305021, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.013421/  2.304647, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.012761/  2.310547, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.013760/  2.289483, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.013523/  2.346805, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.012925/  2.324124, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.013325/  2.333296, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.017561/  2.336429, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.013502/  2.350425, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.012679/  2.366928, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.013656/  2.347122, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.011719/  2.345309, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.011827/  2.372918, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.010636/  2.344129, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.010654/  2.360234, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.010291/  2.384094, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.010435/  2.381706, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.009610/  2.394557, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.009720/  2.395812, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.009519/  2.374839, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.009946/  2.405029, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.009055/  2.415302, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.008838/  2.411055, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.008206/  2.412015, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.008204/  2.432309, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.008499/  2.433718, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.008134/  2.414011, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.008635/  2.414528, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.008034/  2.425467, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.007689/  2.434799, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.007922/  2.435584, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.011789/  2.448330, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.011322/  2.442972, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.008203/  2.447995, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.007994/  2.463811, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.007717/  2.475939, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.007766/  2.480775, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.007572/  2.484080, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.007445/  2.490935, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.007049/  2.498440, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.008071/  2.487993, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.007356/  2.481939, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.008912/  2.508793, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.007761/  2.516114, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.008023/  2.519284, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.007422/  2.507771, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.006827/  2.508328, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.007280/  2.495243, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.006561/  2.493504, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.007117/  2.509325, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.006179/  2.518638, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.006615/  2.518399, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.006610/  2.513843, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.006324/  2.519391, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.006896/  2.526285, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.006452/  2.508285, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.005759/  2.512332, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.005511/  2.508381, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.005927/  2.524084, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.006049/  2.529489, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.006099/  2.519903, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.005806/  2.522478, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.007588/  2.528255, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.006224/  2.540487, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.005982/  2.532003, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.005540/  2.531454, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.005412/  2.521798, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.006124/  2.510025, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:19<00:00,  3.11it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.005669/  2.518521, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:11<00:00,  5.59it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.005914/  2.519836, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.005478/  2.538046, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.004980/  2.528104, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.005338/  2.536566, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.004809/  2.546389, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.005568/  2.542963, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.005910/  2.550191, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.005287/  2.562010, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.005139/  2.549510, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [03:28<00:00,  3.36s/it]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.005029/  2.546520, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.005013/  2.544308, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.005080/  2.549368, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.005139/  2.571193, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.76it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.004725/  2.585514, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.76it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.004714/  2.581609, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.83it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.005086/  2.586900, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.51it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.004985/  2.584191, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:08<00:00,  7.26it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.004623/  2.585135, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:08<00:00,  7.62it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.004688/  2.602354, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.22it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.004659/  2.582090, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.73it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.004617/  2.577765, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.87it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.004696/  2.586109, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  8.93it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.004816/  2.597320, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.004361/  2.581500, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.14it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.005020/  2.605011, tr: 100.00%, val:  80.83%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.004370/  2.598333, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.005312/  2.618077, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.004556/  2.615742, tr: 100.00%, val:  79.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.004116/  2.610780, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.88it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.004351/  2.615878, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.11it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.004396/  2.614948, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  8.96it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.004068/  2.626645, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  8.96it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.004291/  2.627993, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.23it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.003939/  2.621647, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.87it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.004319/  2.630840, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.11it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.004095/  2.626323, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.003999/  2.619763, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:08<00:00,  7.19it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.004377/  2.632501, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.003942/  2.632138, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.90it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.004053/  2.632462, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  7.94it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.004072/  2.641497, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.003815/  2.653848, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.003804/  2.630570, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.004080/  2.633395, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.004208/  2.629344, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.005053/  2.635332, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.004551/  2.642791, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.003839/  2.630698, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.003746/  2.624960, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.003700/  2.629864, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.003842/  2.642191, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.003475/  2.639536, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208c7896b240419d813caaa2783a8b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>val_loss</td><td>▅▁▁▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00348</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.8375</td></tr><tr><td>val_loss</td><td>2.63954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sweep-52</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9t4q7m61' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9t4q7m61</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241010_233653-9t4q7m61/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5gh3409y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_000047-5gh3409y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5gh3409y' target=\"_blank\">glad-sweep-54</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5gh3409y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5gh3409y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 871deb4c6efc1e89b23170a12d036de8\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.822676/  1.486042, tr:  37.59%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:20<00:00,  2.95it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.205255/  1.412726, tr:  61.08%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.023828/  1.241579, tr:  68.44%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.904307/  1.321116, tr:  71.50%, val:  59.17%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.798142/  1.150117, tr:  78.24%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.704334/  1.284318, tr:  77.73%, val:  63.75%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.607979/  1.193012, tr:  84.88%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.542224/  1.196620, tr:  86.21%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.416390/  1.304494, tr:  93.26%, val:  72.50%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.351059/  1.314683, tr:  95.10%, val:  71.25%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.293291/  1.303429, tr:  97.55%, val:  67.92%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.260731/  1.334744, tr:  97.85%, val:  72.92%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.214208/  1.349609, tr:  98.16%, val:  71.67%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.223671/  1.359918, tr:  96.42%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.118016/  1.423987, tr:  99.59%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.097344/  1.440685, tr: 100.00%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.066554/  1.474169, tr: 100.00%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.055293/  1.493791, tr:  99.90%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.034668/  1.499570, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.029351/  1.574427, tr: 100.00%, val:  74.58%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.023305/  1.559284, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.019043/  1.556926, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.015785/  1.621334, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.013960/  1.636381, tr: 100.00%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.011821/  1.659351, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.010452/  1.664829, tr: 100.00%, val:  76.67%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.009797/  1.674429, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.008952/  1.686745, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.008267/  1.701648, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.007572/  1.724800, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.006735/  1.719773, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.006434/  1.733874, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.005914/  1.727611, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.005574/  1.755300, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.005240/  1.763338, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.005132/  1.761733, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.004762/  1.776102, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.004644/  1.789084, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.004326/  1.795872, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.004063/  1.795900, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.003958/  1.804143, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.003727/  1.798992, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.003677/  1.815336, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.003543/  1.824275, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.003343/  1.822570, tr: 100.00%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.003259/  1.815216, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.003108/  1.834628, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.003045/  1.838719, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002929/  1.850514, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002855/  1.863393, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002809/  1.849990, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002672/  1.863465, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.002584/  1.859882, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.002533/  1.879040, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.002475/  1.883197, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.002359/  1.878492, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002273/  1.875869, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.002211/  1.892301, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.002239/  1.889035, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.002250/  1.896427, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.002146/  1.905016, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.002044/  1.901892, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.002014/  1.906680, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001960/  1.917319, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001944/  1.908523, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001929/  1.911687, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001874/  1.928893, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001867/  1.925261, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001788/  1.920569, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001788/  1.927955, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001699/  1.936890, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001673/  1.928598, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001628/  1.924380, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001641/  1.937684, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001583/  1.935937, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001511/  1.936202, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001503/  1.952648, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001460/  1.943919, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001437/  1.948428, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001445/  1.952135, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.99it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001388/  1.950972, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.001376/  1.962209, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001372/  1.960567, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.001345/  1.972424, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001305/  1.966334, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001274/  1.968922, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.94it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.001304/  1.978312, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001275/  1.977572, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001264/  1.999043, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001236/  1.981421, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001213/  1.983116, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001197/  1.983352, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.001192/  1.990384, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001164/  1.984927, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001135/  1.990953, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.001112/  1.993502, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.001115/  1.996624, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001093/  1.995803, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.001092/  1.998059, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.001087/  2.012978, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.001095/  2.021014, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.001059/  2.009963, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.001029/  2.011861, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.001031/  2.011297, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.001008/  2.010526, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.000989/  2.025687, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.000972/  2.019599, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.000970/  2.023334, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.000948/  2.027758, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.000955/  2.035674, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.000932/  2.033067, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.000927/  2.031463, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.000916/  2.032019, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.000909/  2.028316, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.000896/  2.035815, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.000873/  2.036015, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.000882/  2.029781, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.000866/  2.045635, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.000850/  2.048080, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.000853/  2.047887, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.000846/  2.043007, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.000851/  2.051351, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.000837/  2.053292, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.000818/  2.054736, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.000810/  2.061743, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.000808/  2.060600, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.000810/  2.051867, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.000798/  2.055882, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.000786/  2.061712, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.000787/  2.060858, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.000766/  2.066965, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.000741/  2.062185, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.000745/  2.063353, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.000734/  2.064849, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.000734/  2.074137, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.000711/  2.068386, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.000717/  2.072417, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.000723/  2.073521, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.000705/  2.066206, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.000700/  2.072147, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.000684/  2.080893, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.000685/  2.079418, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.000672/  2.087139, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.000676/  2.088693, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.000668/  2.088280, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.000661/  2.083572, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.000656/  2.085515, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.000654/  2.093900, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.000653/  2.088656, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.000636/  2.092307, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.000632/  2.096173, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.000627/  2.095181, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.000615/  2.097321, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.000612/  2.104072, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.000616/  2.104707, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.000607/  2.095854, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.000601/  2.099603, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.000594/  2.106046, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.000590/  2.106638, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.000582/  2.097489, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.000587/  2.101926, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.000585/  2.099643, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.000576/  2.107061, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.000571/  2.110091, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.000569/  2.112912, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.000569/  2.107687, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.000554/  2.108529, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.000554/  2.110514, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.000547/  2.109610, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.000547/  2.110633, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.000546/  2.119108, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.000534/  2.121353, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.000538/  2.120005, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.000529/  2.118510, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.000532/  2.121208, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.000525/  2.120702, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.000518/  2.120287, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.000515/  2.119449, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.000515/  2.125425, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.000508/  2.126574, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000507/  2.129447, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000502/  2.132924, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000502/  2.129499, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000490/  2.134046, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000491/  2.138649, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000493/  2.139174, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000489/  2.127442, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000486/  2.134291, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000478/  2.136393, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000480/  2.135481, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000466/  2.139057, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.000468/  2.137359, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.000461/  2.138924, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.000464/  2.140432, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000459/  2.141240, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000457/  2.148244, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000459/  2.142691, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000457/  2.142637, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000455/  2.151165, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000453/  2.153462, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca7170294d34da4991e5db4e9c51f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▁██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▇▆▇▇█▇▇███████████████▇█▇▇▇▇█▇▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▇▇████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▇▆▇▇█▇▇███████████████▇█▇▇▇▇█▇▇█▇████</td></tr><tr><td>val_loss</td><td>▂▁▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00045</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>2.15346</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-54</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5gh3409y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5gh3409y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_000047-5gh3409y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xbi1ejly with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 50000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_001945-xbi1ejly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xbi1ejly' target=\"_blank\">treasured-sweep-55</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xbi1ejly' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xbi1ejly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 24a068bd1c4b5fa25d606185f5cfbf3f\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.843950/  1.596418, tr:  33.20%, val:  46.25%, val_best:  46.25%: 100%|██████████| 62/62 [00:25<00:00,  2.41it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.294249/  1.507533, tr:  54.34%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.109998/  1.277175, tr:  62.21%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.971246/  1.486042, tr:  67.21%, val:  52.50%, val_best:  58.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.886390/  1.285517, tr:  71.91%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.813347/  1.416681, tr:  73.34%, val:  50.42%, val_best:  61.67%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.700639/  1.265893, tr:  79.88%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.601929/  1.451532, tr:  85.80%, val:  62.50%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00,  9.00it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.536646/  1.303545, tr:  91.52%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.418582/  1.343916, tr:  93.67%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.343042/  1.486214, tr:  94.99%, val:  61.25%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.274254/  1.400983, tr:  97.65%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:07<00:00,  8.68it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.201713/  1.470808, tr:  98.06%, val:  66.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.251992/  1.488395, tr:  96.94%, val:  71.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.137575/  1.514969, tr:  99.28%, val:  67.50%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.114053/  1.639778, tr:  99.39%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:07<00:00,  8.81it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.084332/  1.597430, tr:  99.59%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.059448/  1.569468, tr:  99.90%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.035077/  1.615239, tr: 100.00%, val:  71.67%, val_best:  73.33%: 100%|██████████| 62/62 [00:07<00:00,  8.41it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.026714/  1.625911, tr: 100.00%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.018785/  1.621017, tr: 100.00%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.015175/  1.620025, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  8.97it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.012391/  1.654526, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.010948/  1.683936, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.009869/  1.701620, tr: 100.00%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.008649/  1.692109, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.008051/  1.724712, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.007212/  1.742590, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.006744/  1.742040, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.006291/  1.759241, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.005720/  1.771726, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.005453/  1.776432, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.004973/  1.783216, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.004773/  1.783726, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.004474/  1.807876, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.004242/  1.804316, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.004078/  1.805446, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.003845/  1.832555, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.003697/  1.834742, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.003495/  1.830311, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.003355/  1.840714, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.003211/  1.840895, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.003095/  1.848506, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.002932/  1.846989, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.002814/  1.861661, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.002756/  1.852920, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.002677/  1.884177, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002630/  1.873736, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002546/  1.890424, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002435/  1.884507, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.08it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002405/  1.887307, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002331/  1.888049, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.002237/  1.893075, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.002178/  1.903350, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.002103/  1.898286, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.002060/  1.902530, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.001973/  1.911306, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.001923/  1.917498, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.001897/  1.917622, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.001834/  1.930173, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001814/  1.930104, tr: 100.00%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001803/  1.930043, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001711/  1.939669, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001666/  1.947450, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001637/  1.944561, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001619/  1.943222, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001582/  1.953673, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.23it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001562/  1.954423, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001530/  1.968078, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001526/  1.960742, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001482/  1.957151, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  8.87it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001447/  1.968635, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001417/  1.968028, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001413/  1.967781, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001380/  1.975722, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001345/  1.977236, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001328/  1.986656, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001287/  1.983146, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001271/  1.984165, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001259/  1.991890, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001224/  1.987197, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.001211/  2.000454, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001191/  1.998647, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.001183/  2.004642, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001163/  2.004177, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001152/  1.999826, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.001105/  2.008065, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001087/  2.017066, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001097/  2.005463, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001073/  2.010923, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001065/  2.007434, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001050/  2.023474, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.001040/  2.016354, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001027/  2.029278, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001015/  2.029358, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.000980/  2.029532, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.000976/  2.040694, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.000957/  2.029742, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.000952/  2.033944, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000941/  2.042074, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.000957/  2.040668, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.000922/  2.038322, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.000907/  2.047864, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.000887/  2.047374, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.000890/  2.039103, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.000881/  2.049852, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.000864/  2.060197, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.000872/  2.054822, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.000861/  2.058167, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.000856/  2.055150, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.000834/  2.053614, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.000828/  2.058049, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.000814/  2.059264, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.000817/  2.066398, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.000796/  2.065043, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.000783/  2.068656, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.000773/  2.076039, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.000768/  2.068992, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.000761/  2.076218, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.000751/  2.071426, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.000738/  2.078510, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.000738/  2.081129, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.000721/  2.081905, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.000714/  2.081716, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.16it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.000711/  2.080645, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.67it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.000705/  2.079818, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.000696/  2.084269, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.000691/  2.089337, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.000688/  2.087847, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.000678/  2.089116, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.000671/  2.084817, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.000669/  2.086248, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.000656/  2.093942, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.000655/  2.093836, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.000660/  2.098452, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.000644/  2.096308, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.000648/  2.100271, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.000645/  2.099731, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.000642/  2.104730, tr: 100.00%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  8.92it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.000626/  2.105647, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.000623/  2.105022, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.000618/  2.103057, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.000607/  2.096682, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.000607/  2.108159, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.000603/  2.111031, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.000592/  2.110263, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.000593/  2.110473, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.000592/  2.111848, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.000588/  2.112765, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.000573/  2.120748, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.000570/  2.115717, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.000566/  2.122746, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.30it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.000561/  2.120937, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.000559/  2.114339, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.000554/  2.123053, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.000556/  2.126194, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.000547/  2.127054, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.000540/  2.123473, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.000534/  2.133693, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.000545/  2.130989, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.000537/  2.130013, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.000526/  2.128048, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.000522/  2.135155, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.000523/  2.140729, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.000512/  2.139723, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.000512/  2.135541, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.000503/  2.144315, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.000499/  2.144056, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.64it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.000497/  2.148916, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.000496/  2.149253, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.000494/  2.147584, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.31it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.000488/  2.148260, tr: 100.00%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.000486/  2.145951, tr: 100.00%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.77it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.000482/  2.138395, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.000476/  2.146862, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.000472/  2.145380, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.000472/  2.146053, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.000465/  2.147452, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.000470/  2.149668, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.000469/  2.153195, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000465/  2.150113, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000457/  2.156178, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000457/  2.161127, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000451/  2.154437, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000453/  2.151128, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000451/  2.153588, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000444/  2.156189, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000446/  2.150569, tr: 100.00%, val:  74.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000437/  2.162185, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000437/  2.160552, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000439/  2.160622, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.000434/  2.161110, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.000426/  2.165851, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.000428/  2.163297, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.23it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000424/  2.162742, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000418/  2.164529, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.81it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000419/  2.160664, tr: 100.00%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000413/  2.164564, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000421/  2.165624, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000423/  2.173856, tr: 100.00%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508c5c74449b47fca6d5115dc354409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▁██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▆▆▇███████▇████████▇▇█████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▇█████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▇████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▆▆▇███████▇████████▇▇█████████████████</td></tr><tr><td>val_loss</td><td>▂▂▁▄▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00042</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>2.17386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-sweep-55</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xbi1ejly' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xbi1ejly</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_001945-xbi1ejly/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 27ntxznp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 50000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_004211-27ntxznp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/27ntxznp' target=\"_blank\">upbeat-sweep-58</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/27ntxznp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/27ntxznp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = ad721072af258d2249b4ee156d11b4c0\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.985427/  1.649110, tr:  30.95%, val:  47.50%, val_best:  47.50%: 100%|██████████| 62/62 [00:06<00:00,  8.92it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.332627/  1.434368, tr:  58.84%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.093663/  1.370466, tr:  67.52%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.961908/  1.395151, tr:  73.34%, val:  55.83%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.840120/  1.362723, tr:  77.73%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.722470/  1.406743, tr:  82.02%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.616560/  1.361534, tr:  88.05%, val:  61.25%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.538137/  1.415775, tr:  89.68%, val:  60.42%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.439579/  1.428876, tr:  95.30%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.372390/  1.506516, tr:  96.63%, val:  65.42%, val_best:  67.50%: 100%|██████████| 62/62 [00:07<00:00,  8.75it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.294551/  1.557174, tr:  98.47%, val:  63.33%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.268403/  1.622950, tr:  97.34%, val:  66.67%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.206063/  1.580461, tr:  99.39%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.171137/  1.620055, tr:  99.49%, val:  71.67%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.121738/  1.669190, tr: 100.00%, val:  71.25%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  8.88it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.090055/  1.751505, tr: 100.00%, val:  69.58%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.066858/  1.810400, tr: 100.00%, val:  69.58%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.049923/  1.783331, tr: 100.00%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.039179/  1.819822, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.032822/  1.888999, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.026616/  1.917669, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.022757/  1.916707, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.019642/  1.949851, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.017642/  1.972442, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.016067/  1.998797, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.014612/  2.030459, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.012994/  2.041562, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.011300/  2.058948, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.010426/  2.071591, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.009549/  2.083263, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.008704/  2.096933, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.008038/  2.111021, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.007584/  2.121841, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.007116/  2.138147, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.006778/  2.169021, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.006260/  2.144746, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.006019/  2.169835, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.005723/  2.171501, tr: 100.00%, val:  69.17%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.005380/  2.187298, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.004990/  2.198437, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.004895/  2.210186, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.004636/  2.212117, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.004494/  2.226696, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.004189/  2.229541, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.004056/  2.233033, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.003886/  2.244402, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.003794/  2.236183, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.003590/  2.249636, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.003568/  2.249264, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.003445/  2.274456, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.003398/  2.270418, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.003294/  2.270635, tr: 100.00%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.003163/  2.290075, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.003070/  2.289557, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.002968/  2.294469, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.002892/  2.298549, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002806/  2.297504, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.002766/  2.314226, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.002656/  2.322230, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.002529/  2.332581, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.002536/  2.342678, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.002483/  2.341276, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.002438/  2.354954, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:07<00:00,  8.79it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.002343/  2.361822, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.002346/  2.370687, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.002237/  2.348934, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.002196/  2.364683, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.002114/  2.376179, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.002068/  2.382046, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.002027/  2.382468, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.002027/  2.400943, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.002029/  2.392639, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001930/  2.415879, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001905/  2.413357, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001851/  2.403645, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001829/  2.416923, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001810/  2.419417, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001742/  2.422232, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001685/  2.427868, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001704/  2.427186, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001641/  2.433643, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.001642/  2.431233, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001646/  2.443252, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.001599/  2.447941, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001560/  2.437492, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001539/  2.447684, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.001482/  2.456788, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001481/  2.454224, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001441/  2.459296, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001426/  2.459270, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001409/  2.466532, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001408/  2.468748, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.001363/  2.469147, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001354/  2.480037, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001334/  2.486703, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.001363/  2.480356, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.001327/  2.488873, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001293/  2.486571, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.001289/  2.492054, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.001267/  2.491050, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.001251/  2.496650, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.001225/  2.498456, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.001189/  2.499274, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.001192/  2.510515, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.001185/  2.503202, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.001176/  2.510416, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.001173/  2.503125, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.001143/  2.508067, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.001121/  2.512835, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.001116/  2.508468, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.001086/  2.517492, tr: 100.00%, val:  69.58%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.001088/  2.511535, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.001066/  2.526124, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.001059/  2.525011, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.001053/  2.532316, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.001032/  2.524589, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.001022/  2.528397, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.001014/  2.536971, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.001011/  2.541270, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.000978/  2.541036, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.000991/  2.540540, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.000987/  2.543127, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.000978/  2.547201, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.000984/  2.548432, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.000957/  2.546174, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.000951/  2.552968, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.000938/  2.549907, tr: 100.00%, val:  69.58%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.000934/  2.553003, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.000924/  2.557041, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.000930/  2.562025, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.000920/  2.567248, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.000882/  2.566916, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.000884/  2.572872, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.000883/  2.568944, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.000873/  2.576485, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.000853/  2.582061, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.000862/  2.579482, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.000876/  2.579369, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.000840/  2.592664, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.000822/  2.590348, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.000826/  2.577704, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.000820/  2.587850, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.000796/  2.594426, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.000806/  2.593193, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.07it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.000801/  2.600668, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.000784/  2.595386, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.000778/  2.591608, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.000772/  2.601051, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.000752/  2.597301, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.000757/  2.597313, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.000744/  2.593807, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [19:36<00:00, 18.98s/it]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.000748/  2.598892, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.000733/  2.598059, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.000738/  2.595809, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.000727/  2.596631, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.000723/  2.605843, tr: 100.00%, val:  69.58%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.000715/  2.608106, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.000697/  2.608505, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.000700/  2.617303, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.000695/  2.618800, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.000685/  2.611648, tr: 100.00%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.000691/  2.615972, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.000683/  2.618811, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:07<00:00,  8.73it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.000672/  2.617979, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.000661/  2.619607, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.000664/  2.621525, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.000651/  2.618651, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.000657/  2.626375, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.000634/  2.625485, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.000643/  2.624082, tr: 100.00%, val:  70.00%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.000645/  2.625699, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.000638/  2.625812, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.000641/  2.626302, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.000643/  2.628085, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.000633/  2.630946, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.000620/  2.628927, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.000623/  2.624694, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.000609/  2.631544, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.000613/  2.625524, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.00it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.000610/  2.627824, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000611/  2.636103, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000598/  2.634301, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000588/  2.630618, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000584/  2.637978, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000580/  2.639304, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000596/  2.643819, tr: 100.00%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000573/  2.641860, tr: 100.00%, val:  70.83%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000572/  2.645138, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000567/  2.644849, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000569/  2.646615, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000558/  2.644438, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.000565/  2.644155, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.000547/  2.650191, tr: 100.00%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.000551/  2.649098, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000539/  2.648141, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000543/  2.655836, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000537/  2.650735, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000542/  2.646077, tr: 100.00%, val:  71.25%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000540/  2.647837, tr: 100.00%, val:  72.08%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000538/  2.653947, tr: 100.00%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8652efba4f9b46e29005041a48a0079f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇█▇▇▇▇██▇▇██▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆█████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇█▇▇▇▇██▇▇██▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▁▁▂▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00054</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.71667</td></tr><tr><td>val_loss</td><td>2.65395</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-58</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/27ntxznp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/27ntxznp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_004211-27ntxznp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wyi3xyg2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_012333-wyi3xyg2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wyi3xyg2' target=\"_blank\">quiet-sweep-63</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wyi3xyg2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wyi3xyg2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 99a8e3deb4ba015e94ead90dc5a474ba\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.863081/  1.577407, tr:  31.56%, val:  48.75%, val_best:  48.75%: 100%|██████████| 62/62 [00:18<00:00,  3.34it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.272386/  1.483496, tr:  54.24%, val:  45.83%, val_best:  48.75%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.047389/  1.270090, tr:  66.91%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.900956/  1.272307, tr:  71.09%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.747664/  1.184071, tr:  79.37%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.654045/  1.414185, tr:  82.02%, val:  55.83%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.533686/  1.236175, tr:  87.74%, val:  65.00%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.417898/  1.353003, tr:  94.28%, val:  63.33%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.325839/  1.348694, tr:  96.22%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.231362/  1.367457, tr:  98.57%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.202103/  1.470348, tr:  98.67%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.136419/  1.449600, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.33it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.091962/  1.511659, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.067387/  1.499883, tr: 100.00%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.047882/  1.538514, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.036495/  1.583747, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.026703/  1.614390, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.021013/  1.629088, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.017405/  1.624665, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  8.97it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.015503/  1.660449, tr: 100.00%, val:  71.25%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.013061/  1.654841, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.011645/  1.672352, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.010124/  1.698326, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.009212/  1.717503, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.008615/  1.721893, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.007746/  1.724807, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.007311/  1.752994, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.006744/  1.757695, tr: 100.00%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.006330/  1.762824, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.005996/  1.776407, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.005447/  1.778132, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.005097/  1.775438, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.004764/  1.803897, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.004595/  1.799432, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.004324/  1.803654, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.004205/  1.825164, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.003981/  1.824145, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.003778/  1.829090, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.003635/  1.841899, tr: 100.00%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.003394/  1.838141, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.003288/  1.843322, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.003164/  1.857880, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.003155/  1.863286, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.002956/  1.861785, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.002883/  1.877185, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.002794/  1.880900, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.002712/  1.889101, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002644/  1.890519, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002531/  1.886943, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002490/  1.903127, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002429/  1.901329, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002374/  1.897826, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.002291/  1.896296, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.002255/  1.924528, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.002184/  1.916963, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.002053/  1.927775, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002040/  1.921800, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.002013/  1.931258, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.001940/  1.923873, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.001921/  1.933126, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001891/  1.939309, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001826/  1.938473, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001806/  1.947944, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001752/  1.952027, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001711/  1.953585, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001668/  1.967797, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001644/  1.967160, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001623/  1.975527, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001604/  1.978880, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001569/  1.972010, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001526/  1.978776, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001532/  1.984632, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001479/  1.985618, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001489/  1.987722, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001434/  1.985573, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:07<00:00,  8.80it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001405/  1.998059, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001388/  2.008446, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001350/  1.997965, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001321/  2.001870, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001309/  2.008135, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001286/  2.004299, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.001241/  2.001799, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001233/  2.009210, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.001220/  2.016038, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001210/  2.011677, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001196/  2.022802, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.001165/  2.020535, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001155/  2.021992, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001137/  2.021034, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001114/  2.028686, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001105/  2.025699, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001086/  2.031840, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.001078/  2.023229, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001059/  2.033374, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001061/  2.037362, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.001018/  2.035981, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.001013/  2.045041, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001003/  2.054784, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.001002/  2.052713, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000981/  2.059378, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.000983/  2.057204, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.000967/  2.057846, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.000955/  2.059378, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.000941/  2.053865, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.000929/  2.062490, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.000913/  2.065110, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.000911/  2.067488, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.000898/  2.065554, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.000882/  2.064540, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.000890/  2.066213, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.000865/  2.070872, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.000870/  2.073966, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.000850/  2.077385, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.000862/  2.084156, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.000835/  2.086197, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.000817/  2.091311, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.000814/  2.084894, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.000812/  2.089309, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.000790/  2.092678, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.000787/  2.092242, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.000773/  2.094678, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.000767/  2.100985, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.000767/  2.099511, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.000761/  2.104508, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.000752/  2.104120, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.000747/  2.103605, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.000741/  2.111436, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.000732/  2.110668, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.000730/  2.107364, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.000720/  2.111281, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.00it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.000713/  2.115746, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.000703/  2.111063, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.05it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.000688/  2.112096, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.000692/  2.113384, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.000693/  2.118127, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.000674/  2.119926, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.000679/  2.118253, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.000690/  2.118081, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.000669/  2.118343, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.000663/  2.118845, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.000665/  2.125550, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.000660/  2.118918, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.000635/  2.128427, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.000643/  2.117572, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.000638/  2.129994, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.000625/  2.124409, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.000629/  2.126244, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.000620/  2.128877, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.000624/  2.129025, tr: 100.00%, val:  68.75%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.000608/  2.130635, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.000604/  2.130824, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.000593/  2.129997, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.000595/  2.133152, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.000589/  2.131048, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.000585/  2.138001, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.000583/  2.139626, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.000579/  2.141602, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.000577/  2.145394, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.000572/  2.142970, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.000573/  2.143535, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.000570/  2.141863, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.000562/  2.143226, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.000552/  2.145154, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.000544/  2.144010, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.000536/  2.144278, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.000543/  2.148650, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.19it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.000538/  2.152455, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.000533/  2.153285, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:07<00:00,  8.72it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.000531/  2.154342, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.000519/  2.154969, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.000517/  2.160014, tr: 100.00%, val:  70.83%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.000512/  2.158298, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.000512/  2.161401, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.000506/  2.158976, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.000503/  2.160111, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.000500/  2.164540, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.000491/  2.158005, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.000488/  2.164960, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.000489/  2.161927, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.000488/  2.163648, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000484/  2.163648, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000480/  2.177384, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000476/  2.169569, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.20it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000475/  2.174034, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000475/  2.168602, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000465/  2.172418, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000467/  2.170990, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000465/  2.174258, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000463/  2.171379, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000459/  2.175527, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000454/  2.181321, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.000460/  2.189753, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.000452/  2.188264, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.000448/  2.190056, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000445/  2.189921, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000443/  2.193553, tr: 100.00%, val:  69.58%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000437/  2.195710, tr: 100.00%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000436/  2.195749, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000436/  2.191832, tr: 100.00%, val:  70.42%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000435/  2.197828, tr: 100.00%, val:  69.17%, val_best:  71.67%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b509e7245a34304a8750194419808c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▇▇█▇██▇█▇██████████████▇█▇███▇████████</td></tr><tr><td>tr_acc</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▇▇█▇██▇█▇██████████████▇█▇███▇████████</td></tr><tr><td>val_loss</td><td>▂▁▁▃▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00044</td></tr><tr><td>val_acc_best</td><td>0.71667</td></tr><tr><td>val_acc_now</td><td>0.69167</td></tr><tr><td>val_loss</td><td>2.19783</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-63</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wyi3xyg2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wyi3xyg2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_012333-wyi3xyg2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hq0i55xe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_014519-hq0i55xe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hq0i55xe' target=\"_blank\">proud-sweep-66</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hq0i55xe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hq0i55xe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 0f46a843f722240a7de67648f0143d49\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304440/  2.302613, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:12<00:00,  4.86it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304356/  2.302693, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305100/  2.302649, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304714/  2.302675, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304882/  2.302659, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.305051/  2.302687, tr:   6.13%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.304376/  2.302777, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304082/  2.301598, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.272383/  2.223702, tr:  12.97%, val:  13.75%, val_best:  13.75%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.121402/  2.122538, tr:  20.33%, val:  14.17%, val_best:  14.17%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.012335/  2.049098, tr:  25.03%, val:  24.17%, val_best:  24.17%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.902699/  1.959981, tr:  31.66%, val:  28.33%, val_best:  28.33%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.709457/  1.805039, tr:  44.02%, val:  38.75%, val_best:  38.75%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.544207/  1.715287, tr:  50.15%, val:  42.08%, val_best:  42.08%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.402027/  1.659185, tr:  57.81%, val:  45.83%, val_best:  45.83%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.320502/  1.662341, tr:  62.61%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.266408/  1.675734, tr:  64.04%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.193736/  1.677728, tr:  69.77%, val:  50.83%, val_best:  51.25%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.139036/  1.679199, tr:  73.24%, val:  51.25%, val_best:  51.25%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.073308/  1.638143, tr:  76.40%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.038950/  1.657447, tr:  79.26%, val:  55.42%, val_best:  56.25%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.984673/  1.673451, tr:  82.84%, val:  55.00%, val_best:  56.25%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.939206/  1.671005, tr:  84.27%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.914074/  1.702387, tr:  83.96%, val:  53.33%, val_best:  57.92%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.881616/  1.756933, tr:  86.62%, val:  50.83%, val_best:  57.92%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.847565/  1.769443, tr:  87.64%, val:  53.75%, val_best:  57.92%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.811518/  1.793977, tr:  88.46%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.780835/  1.779312, tr:  89.68%, val:  57.50%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.754480/  1.780082, tr:  90.81%, val:  58.75%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.742780/  1.845764, tr:  90.81%, val:  57.08%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.688262/  1.805762, tr:  91.83%, val:  58.33%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.683270/  1.845682, tr:  92.85%, val:  56.25%, val_best:  59.17%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.644839/  1.875934, tr:  93.46%, val:  58.75%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.620531/  1.941071, tr:  94.38%, val:  57.50%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.603821/  1.965158, tr:  94.18%, val:  56.25%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.576208/  1.975581, tr:  95.20%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.552707/  1.945821, tr:  96.02%, val:  59.17%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.545462/  1.979440, tr:  95.61%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.508479/  2.037117, tr:  96.22%, val:  60.42%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.495712/  2.030398, tr:  96.94%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.489259/  2.068645, tr:  96.42%, val:  61.25%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.462607/  2.145122, tr:  97.45%, val:  60.42%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.441169/  2.165032, tr:  97.55%, val:  61.25%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.439704/  2.209531, tr:  97.14%, val:  60.00%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.401062/  2.176691, tr:  97.65%, val:  62.08%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.384447/  2.215294, tr:  98.67%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.383413/  2.257439, tr:  98.37%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.360899/  2.283647, tr:  98.67%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.354909/  2.300637, tr:  98.67%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [1:06:58<00:00, 64.82s/it] \n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.341278/  2.342129, tr:  98.88%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.330219/  2.357510, tr:  98.77%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.322168/  2.386518, tr:  99.08%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.314043/  2.428183, tr:  98.88%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.298177/  2.465788, tr:  99.28%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.292253/  2.435591, tr:  98.88%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.272915/  2.514186, tr:  99.18%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.261824/  2.535294, tr:  99.39%, val:  63.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.261720/  2.573703, tr:  99.28%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.250563/  2.592865, tr:  99.69%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.241332/  2.620013, tr:  99.59%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.243763/  2.662659, tr:  99.49%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.234112/  2.650681, tr:  99.80%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.221138/  2.693073, tr:  99.59%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.211437/  2.708821, tr:  99.80%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.208350/  2.707423, tr:  99.80%, val:  63.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.213261/  2.724055, tr:  99.69%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.203040/  2.764164, tr:  99.69%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.189471/  2.817327, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.182110/  2.847413, tr:  99.80%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.184746/  2.844851, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.175632/  2.829782, tr:  99.80%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.172460/  2.892006, tr:  99.80%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.173108/  2.960670, tr:  99.80%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.161346/  2.913944, tr:  99.80%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.153928/  2.976668, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.160655/  2.987242, tr:  99.80%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.158276/  2.973833, tr:  99.69%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.151148/  2.995888, tr:  99.80%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.147906/  3.004720, tr:  99.80%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.141765/  3.062039, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.139117/  3.039719, tr:  99.80%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.135296/  3.075849, tr:  99.80%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.131320/  3.055743, tr:  99.80%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.127752/  3.099735, tr:  99.80%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.128237/  3.120429, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.127581/  3.184820, tr:  99.80%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.122522/  3.154974, tr:  99.80%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.120912/  3.179519, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.112597/  3.216681, tr:  99.80%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.111407/  3.245467, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.107834/  3.240719, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.105023/  3.275802, tr:  99.80%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.104213/  3.311161, tr:  99.90%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.102923/  3.314061, tr:  99.80%, val:  63.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.098366/  3.307245, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.101122/  3.313930, tr:  99.80%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.095570/  3.328118, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.094221/  3.367905, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.095867/  3.332897, tr:  99.90%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.092035/  3.376318, tr:  99.80%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.093043/  3.392413, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.089477/  3.428156, tr:  99.80%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.086941/  3.457014, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.087728/  3.473521, tr:  99.80%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.085319/  3.468292, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.082948/  3.468282, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.083170/  3.472839, tr:  99.90%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.082041/  3.470940, tr:  99.90%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.084188/  3.502675, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.079044/  3.527842, tr:  99.80%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.085258/  3.540870, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.097331/  3.551826, tr: 100.00%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.078335/  3.557843, tr:  99.80%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.079164/  3.552000, tr:  99.90%, val:  64.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.078157/  3.590455, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.075706/  3.622507, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.071138/  3.609012, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.073083/  3.599351, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.05it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.072782/  3.651677, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.073154/  3.683651, tr:  99.80%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.068522/  3.698957, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.075244/  3.701358, tr:  99.80%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.070247/  3.709414, tr:  99.80%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.066792/  3.721600, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.065400/  3.734568, tr:  99.90%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.067194/  3.754896, tr:  99.90%, val:  59.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.067097/  3.732013, tr:  99.90%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.062485/  3.769067, tr:  99.90%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.062411/  3.782486, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.061818/  3.732031, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.064172/  3.806694, tr:  99.90%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.058870/  3.787236, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.057976/  3.815196, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.056585/  3.836219, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.059899/  3.826213, tr: 100.00%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.058122/  3.855971, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.057328/  3.866993, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.059756/  3.894208, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.055551/  3.862614, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.058464/  3.874925, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.057320/  3.853938, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.054220/  3.909955, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.052887/  3.925621, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.054579/  3.908912, tr:  99.90%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.051391/  3.898671, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.059647/  3.917120, tr:  99.90%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.31it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.057719/  3.914451, tr:  99.90%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.055638/  3.925553, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.054446/  3.943996, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.053325/  3.959564, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.051628/  3.969351, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.052726/  3.980409, tr:  99.90%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.050992/  3.992722, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.049095/  3.989006, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.050722/  3.989473, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.049465/  4.007982, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.052558/  4.020497, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.051540/  4.017144, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.049666/  4.027700, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.044746/  4.057252, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.048173/  4.075184, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.048558/  4.054677, tr:  99.90%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.050524/  4.061852, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.047335/  4.076685, tr:  99.90%, val:  58.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.046815/  4.088013, tr:  99.90%, val:  58.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.047161/  4.089314, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.044583/  4.072229, tr: 100.00%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.048808/  4.069383, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.047521/  4.100083, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.045790/  4.119781, tr:  99.90%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.047519/  4.120749, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.045049/  4.108391, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.045588/  4.104851, tr: 100.00%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.044495/  4.157606, tr: 100.00%, val:  59.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.043494/  4.133418, tr: 100.00%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.043000/  4.111519, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.043643/  4.138093, tr:  99.90%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.042629/  4.106900, tr: 100.00%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.042670/  4.142025, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.039816/  4.159828, tr:  99.90%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.044672/  4.137248, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.042332/  4.172367, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.043806/  4.172158, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.042243/  4.166191, tr: 100.00%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.044347/  4.193608, tr:  99.90%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.043270/  4.172628, tr: 100.00%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.040744/  4.212325, tr:  99.90%, val:  58.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.041984/  4.207440, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.043864/  4.228174, tr: 100.00%, val:  58.75%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.040367/  4.213351, tr:  99.90%, val:  61.25%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.037377/  4.225943, tr:  99.90%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.041542/  4.212728, tr:  99.90%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.036154/  4.208467, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.039032/  4.237761, tr: 100.00%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.038556/  4.248072, tr: 100.00%, val:  59.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.040332/  4.270001, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.038345/  4.248322, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.039501/  4.246260, tr:  99.90%, val:  59.17%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.040202/  4.249810, tr: 100.00%, val:  60.00%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.038697/  4.263828, tr:  99.90%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d11ef3ea5c408c8b1c205274d7ab66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▆▇█▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▆▇▇▇▇██▇█▇███████████▇███▇████▇▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▁▂▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▆▇▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▆▇▇▇▇██▇█▇███████████▇███▇████▇▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▃▃▂▁▁▁▂▂▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99898</td></tr><tr><td>tr_epoch_loss</td><td>0.0387</td></tr><tr><td>val_acc_best</td><td>0.64583</td></tr><tr><td>val_acc_now</td><td>0.60833</td></tr><tr><td>val_loss</td><td>4.26383</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-66</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hq0i55xe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hq0i55xe</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_014519-hq0i55xe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: amrwmbh0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_031334-amrwmbh0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/amrwmbh0' target=\"_blank\">helpful-sweep-75</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/amrwmbh0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/amrwmbh0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 35e1860ac21424850a12783e823030af\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.030148/  1.651071, tr:  29.83%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:26<00:00,  2.37it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.315910/  1.284831, tr:  59.45%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.085036/  1.184425, tr:  67.62%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.947653/  1.166815, tr:  71.20%, val:  64.17%, val_best:  67.08%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.837306/  1.134001, tr:  76.20%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.784163/  1.128374, tr:  76.40%, val:  68.33%, val_best:  69.58%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.706694/  1.119486, tr:  81.31%, val:  67.08%, val_best:  69.58%: 100%|██████████| 62/62 [00:06<00:00,  8.91it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.637080/  1.122911, tr:  83.55%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.580543/  1.100562, tr:  88.56%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.558445/  1.180383, tr:  85.80%, val:  70.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.504778/  1.067518, tr:  91.42%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.460007/  1.166190, tr:  90.30%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.404388/  1.206709, tr:  93.16%, val:  74.58%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.405026/  1.128759, tr:  89.68%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.350978/  1.171025, tr:  96.53%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.315380/  1.316342, tr:  96.53%, val:  71.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.277748/  1.253908, tr:  97.75%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.251547/  1.233547, tr:  97.14%, val:  77.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.186017/  1.310553, tr:  99.90%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.187591/  1.333996, tr:  98.57%, val:  73.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.146948/  1.312612, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.142481/  1.313015, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.110077/  1.365656, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.089490/  1.406662, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.076427/  1.402261, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.078455/  1.428915, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.062235/  1.454551, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.050301/  1.499819, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.043017/  1.487903, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.040404/  1.521427, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.037759/  1.519358, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.029941/  1.542369, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.027067/  1.616428, tr: 100.00%, val:  78.75%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.025233/  1.581699, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.020275/  1.591819, tr: 100.00%, val:  79.17%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.018673/  1.603826, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.017526/  1.627298, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.016672/  1.632760, tr: 100.00%, val:  80.00%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.014490/  1.639709, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.012951/  1.643078, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.012915/  1.638125, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.011902/  1.631179, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.011608/  1.696176, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.010771/  1.695409, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.010207/  1.714716, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.009328/  1.714845, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.008666/  1.717027, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.008479/  1.730839, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.007785/  1.734238, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.007553/  1.738013, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.007078/  1.729650, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.006671/  1.749137, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.006307/  1.742992, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.006470/  1.748192, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.006138/  1.763002, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.005668/  1.755445, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.005718/  1.758900, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.005391/  1.765236, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.005349/  1.801611, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.005140/  1.783908, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.004935/  1.787118, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.004816/  1.796744, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.004677/  1.792186, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.004370/  1.789893, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.004264/  1.804688, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.004203/  1.806067, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.004033/  1.809605, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.003851/  1.831245, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.003711/  1.832580, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.003646/  1.831175, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.003663/  1.840919, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.003473/  1.836898, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.003317/  1.857335, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.003318/  1.846411, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.003279/  1.854509, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.003177/  1.857696, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.002964/  1.862628, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.003048/  1.856575, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.002904/  1.873698, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.002794/  1.870868, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.002753/  1.869355, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.002662/  1.861346, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.002863/  1.872923, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.002664/  1.873999, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.002719/  1.864473, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.002627/  1.887272, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.002542/  1.875841, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.002487/  1.876989, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.002428/  1.885652, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.002390/  1.887571, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.002331/  1.889217, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.002331/  1.886945, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.002215/  1.885635, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.002276/  1.879807, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.002132/  1.881994, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.002127/  1.891655, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.002051/  1.896678, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.002041/  1.900141, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.002036/  1.897004, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.002017/  1.894549, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.002053/  1.904313, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.002085/  1.885906, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.001979/  1.897411, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.001954/  1.902432, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.001931/  1.910812, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.001837/  1.911090, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.001884/  1.908954, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.001847/  1.910286, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.001800/  1.921019, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.001809/  1.921693, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.001790/  1.931080, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.001690/  1.928228, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.001668/  1.935551, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.001677/  1.937190, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.001708/  1.939963, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.001665/  1.938724, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.001679/  1.933982, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.001622/  1.938277, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.001574/  1.946230, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.001601/  1.948694, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.001619/  1.951883, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.001573/  1.955863, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.001543/  1.969676, tr: 100.00%, val:  80.00%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.001534/  1.961686, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.001532/  1.970318, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.001514/  1.966860, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.001522/  1.964892, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.001452/  1.971745, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.001457/  1.974678, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.001480/  1.981852, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.001449/  1.969144, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.001420/  1.964660, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.001398/  1.975584, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.001419/  1.993971, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.001459/  1.990284, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.001437/  1.998369, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.001353/  2.008933, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.001353/  2.004709, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.001296/  2.018991, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.001321/  2.014821, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.001318/  2.010582, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.001306/  2.007310, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.001284/  2.010722, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.001278/  2.019398, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.001293/  2.008842, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.001285/  2.022416, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.001294/  2.019182, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.001239/  2.020711, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.001277/  2.023184, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.001305/  2.025495, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.001220/  2.029987, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.001217/  2.042634, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.001187/  2.025026, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.001174/  2.027486, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.001183/  2.036510, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.001187/  2.046880, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.001196/  2.053278, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.001194/  2.054047, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.001170/  2.048688, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.001163/  2.043175, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.001169/  2.052156, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.001176/  2.053263, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.001134/  2.056704, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.001117/  2.066629, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.001155/  2.065794, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.001152/  2.071418, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.001112/  2.064555, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.001114/  2.069595, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.001094/  2.063160, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.001077/  2.068629, tr: 100.00%, val:  80.00%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.001067/  2.072222, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.001071/  2.083922, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.001068/  2.077991, tr: 100.00%, val:  80.00%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.001074/  2.087609, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.001051/  2.097191, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.001051/  2.080845, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.001055/  2.087129, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.001043/  2.086940, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.001044/  2.087809, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.001088/  2.094652, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000988/  2.090624, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000977/  2.102139, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000953/  2.094846, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000939/  2.091834, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000940/  2.093837, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000901/  2.099621, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000917/  2.094604, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000902/  2.093868, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000803/  2.103165, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000816/  2.097762, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000806/  2.105173, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.000798/  2.099362, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.000768/  2.103886, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.000770/  2.095842, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000750/  2.097691, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000775/  2.097433, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000749/  2.083818, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000729/  2.094168, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000727/  2.092015, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000733/  2.101371, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27425306c5740ccb903b5a8b7632dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▅▇▇▇█▇█▇▇████▇███▇▇█▇▇██▇█▇▇▇▇▇▇▇███</td></tr><tr><td>tr_acc</td><td>▁▄▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▅▇▇▇█▇█▇▇████▇███▇▇█▇▇██▇█▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▂▁▁▂▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00073</td></tr><tr><td>val_acc_best</td><td>0.83333</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>2.10137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-75</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/amrwmbh0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/amrwmbh0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_031334-amrwmbh0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5o0zrcn4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_033502-5o0zrcn4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5o0zrcn4' target=\"_blank\">expert-sweep-78</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5o0zrcn4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5o0zrcn4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 1752c8ca53f7366e2cf7c74a839d0e77\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.295748/  2.215512, tr:  11.54%, val:  26.67%, val_best:  26.67%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.878036/  1.646891, tr:  41.98%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.393352/  1.418562, tr:  62.21%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.190787/  1.360082, tr:  66.60%, val:  61.25%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.072630/  1.286895, tr:  70.38%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.987427/  1.282893, tr:  73.03%, val:  64.17%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.907362/  1.258969, tr:  76.92%, val:  66.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.837147/  1.280708, tr:  79.78%, val:  66.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.761492/  1.200105, tr:  83.86%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.722243/  1.278028, tr:  85.19%, val:  67.08%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.685310/  1.208771, tr:  86.52%, val:  67.08%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.610708/  1.264407, tr:  88.46%, val:  70.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.567798/  1.248870, tr:  91.93%, val:  71.25%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.591602/  1.194462, tr:  85.39%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.482995/  1.213337, tr:  96.12%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.444584/  1.280356, tr:  95.81%, val:  70.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.400792/  1.287641, tr:  96.73%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.369539/  1.256516, tr:  96.63%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.318906/  1.346572, tr:  99.28%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.296026/  1.319832, tr:  98.57%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.264172/  1.363966, tr:  99.18%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.232230/  1.382975, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.212712/  1.402881, tr:  99.28%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.183309/  1.460736, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.172229/  1.498441, tr:  99.90%, val:  79.17%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.165533/  1.506222, tr:  99.80%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.140844/  1.533420, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.124704/  1.557256, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.104336/  1.541023, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.101299/  1.604718, tr:  99.90%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.079607/  1.609671, tr: 100.00%, val:  81.67%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.076572/  1.607641, tr: 100.00%, val:  82.08%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.068881/  1.672663, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.062890/  1.705539, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.058199/  1.697671, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.051124/  1.710967, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.047388/  1.764457, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.044321/  1.774926, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.035233/  1.773376, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.035482/  1.808858, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.035516/  1.809452, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.030047/  1.825301, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.027256/  1.851160, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.026566/  1.895312, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.025758/  1.881197, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.023151/  1.886158, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.021328/  1.912365, tr: 100.00%, val:  81.67%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.020223/  1.934894, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.019461/  1.925262, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.018265/  1.947658, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.017891/  1.970488, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.016944/  1.965427, tr: 100.00%, val:  81.67%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.016535/  1.988193, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.015560/  2.003706, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.015581/  2.016760, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.014212/  2.014356, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.013966/  2.032067, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.014278/  2.033386, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.014190/  2.055937, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.013594/  2.064761, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.011667/  2.067003, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.012020/  2.092618, tr: 100.00%, val:  81.67%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.011102/  2.081083, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.010179/  2.089161, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.009853/  2.087451, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.010227/  2.114931, tr: 100.00%, val:  81.25%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.009656/  2.100408, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.009910/  2.093300, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.009177/  2.107582, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.009601/  2.117991, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.008234/  2.137438, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.008670/  2.137624, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.008277/  2.153940, tr: 100.00%, val:  82.08%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.007707/  2.141948, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.007630/  2.169154, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.010012/  2.166868, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.008796/  2.168971, tr: 100.00%, val:  81.25%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.007693/  2.177227, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.007853/  2.190974, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.008345/  2.186864, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.006630/  2.188358, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  8.89it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.006098/  2.215727, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.005901/  2.206570, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.005705/  2.204283, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.005275/  2.211928, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.005336/  2.219045, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.005615/  2.228694, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.004964/  2.237864, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.004895/  2.226243, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.005182/  2.226094, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.005033/  2.221965, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.005741/  2.252589, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.005327/  2.242555, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.004914/  2.260356, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.005022/  2.234712, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.004671/  2.255294, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.004511/  2.254346, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:07<00:00,  8.41it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.004706/  2.269173, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.004393/  2.278925, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.004674/  2.258795, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.004669/  2.275227, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.004771/  2.280015, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.005143/  2.273822, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.004613/  2.296034, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.004239/  2.294031, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.003940/  2.294475, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.004041/  2.298129, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.004005/  2.287684, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.004028/  2.297154, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.003858/  2.300540, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.006285/  2.299266, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.005415/  2.320654, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.004660/  2.322299, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.004069/  2.311662, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.003731/  2.322411, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.004125/  2.328451, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.003598/  2.327744, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.003669/  2.330537, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.003528/  2.334082, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.004058/  2.341605, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.003557/  2.346439, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.003668/  2.337341, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.003872/  2.344532, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.003537/  2.340684, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.003509/  2.336085, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.003625/  2.355503, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.003341/  2.346891, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.003377/  2.349370, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.003293/  2.332375, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.003361/  2.348804, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.003303/  2.340175, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.003369/  2.356095, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.003050/  2.363248, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.003231/  2.350524, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.003252/  2.359689, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.003268/  2.365318, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.003105/  2.364704, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.003207/  2.362451, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.003399/  2.376377, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.003288/  2.359027, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.003014/  2.366099, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.002881/  2.364739, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.003042/  2.381546, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.003136/  2.381296, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.003573/  2.383600, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.003164/  2.378577, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.003355/  2.386381, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.003079/  2.383914, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.003382/  2.385139, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.002845/  2.398278, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.002816/  2.386940, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.002676/  2.393576, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.002651/  2.397786, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.002917/  2.391531, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.002969/  2.395819, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.002794/  2.389658, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.002974/  2.400608, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.003040/  2.402545, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.002860/  2.397641, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.002803/  2.398307, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.002911/  2.408012, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.002876/  2.415730, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.002877/  2.414075, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.002865/  2.416598, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.002747/  2.419130, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.002723/  2.428382, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.002720/  2.435916, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.002666/  2.434839, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.002592/  2.442895, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.002474/  2.445710, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.002525/  2.446786, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.002635/  2.447474, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.002528/  2.449918, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.002704/  2.468638, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.002511/  2.463970, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.002493/  2.470263, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.002603/  2.467656, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.002616/  2.469541, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.002450/  2.463157, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.002637/  2.476755, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.002197/  2.467397, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.002229/  2.480436, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.002383/  2.467748, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.002241/  2.467818, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.002164/  2.480964, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.002407/  2.482109, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.002377/  2.477942, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.002210/  2.483356, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.002583/  2.482895, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.002425/  2.477665, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.002419/  2.486075, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.002327/  2.489728, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.002310/  2.492939, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.002572/  2.493254, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.002026/  2.495989, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.002567/  2.491797, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.002293/  2.483841, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.002338/  2.483840, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.002270/  2.492014, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.002291/  2.501176, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd432509a1d4aab9d0f74b2f412d889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▆█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▇▇▇▇█▇▇▇█▇████▇█████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▇▇▇▇█▇▇▇█▇████▇█████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▂▃▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00229</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.83333</td></tr><tr><td>val_loss</td><td>2.50118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-78</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5o0zrcn4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5o0zrcn4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_033502-5o0zrcn4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jvm1t4j8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 50000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_035600-jvm1t4j8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jvm1t4j8' target=\"_blank\">curious-sweep-81</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jvm1t4j8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jvm1t4j8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 0d8b728364de4ecf8568b4c6954ef3a4\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304453/  2.302613, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304370/  2.302693, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305113/  2.302622, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304620/  2.302310, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.300770/  2.291932, tr:  11.95%, val:  12.08%, val_best:  12.08%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.225334/  2.170034, tr:  17.16%, val:  18.33%, val_best:  18.33%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.008942/  1.989219, tr:  29.01%, val:  35.42%, val_best:  35.42%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.729117/  1.796698, tr:  48.62%, val:  38.75%, val_best:  38.75%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.510947/  1.694535, tr:  55.98%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.381977/  1.639410, tr:  60.67%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.290323/  1.643694, tr:  66.29%, val:  45.00%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.222795/  1.630342, tr:  69.25%, val:  47.92%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.169098/  1.581748, tr:  72.01%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.142895/  1.558527, tr:  73.24%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:06<00:00,  9.31it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.048723/  1.565450, tr:  78.65%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.010010/  1.561648, tr:  80.39%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.985045/  1.607529, tr:  82.64%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.929037/  1.572528, tr:  83.04%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.882120/  1.620134, tr:  85.60%, val:  53.75%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.846214/  1.567206, tr:  87.54%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.801794/  1.623613, tr:  89.68%, val:  59.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.770950/  1.623446, tr:  91.73%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.736301/  1.638053, tr:  91.01%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698552/  1.736465, tr:  92.44%, val:  60.83%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.698593/  1.735917, tr:  91.73%, val:  57.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.654873/  1.751812, tr:  94.08%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.616599/  1.718845, tr:  94.89%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.594170/  1.779879, tr:  94.59%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.567737/  1.752383, tr:  96.32%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.558051/  1.829662, tr:  95.20%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.519754/  1.783612, tr:  96.53%, val:  64.17%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.498050/  1.814247, tr:  97.14%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.467611/  1.873927, tr:  97.24%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.453829/  1.945429, tr:  97.75%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.434357/  1.983273, tr:  97.45%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.401538/  2.001785, tr:  97.85%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.393430/  2.021288, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.383840/  2.019406, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.352348/  2.077858, tr:  98.57%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.337143/  2.123051, tr:  98.88%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.327187/  2.094044, tr:  98.77%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.303727/  2.182719, tr:  98.88%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.295676/  2.205085, tr:  98.98%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.285624/  2.282178, tr:  99.18%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.267487/  2.239787, tr:  98.98%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.254357/  2.309304, tr:  99.08%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.251039/  2.325897, tr:  99.28%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.231962/  2.399669, tr:  99.59%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.227673/  2.378632, tr:  99.39%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.214757/  2.406626, tr:  99.49%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.210652/  2.467655, tr:  99.59%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.200284/  2.422487, tr:  99.49%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:07<00:00,  8.15it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.210335/  2.496546, tr:  99.69%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.194084/  2.523542, tr:  99.80%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.183544/  2.526844, tr:  99.59%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.168971/  2.588564, tr:  99.80%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.164101/  2.548164, tr:  99.69%, val:  64.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.168199/  2.603082, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.156458/  2.612416, tr:  99.80%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.156114/  2.653112, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.150686/  2.703130, tr:  99.80%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.148362/  2.674302, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.140094/  2.734603, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.129976/  2.742191, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.131548/  2.774594, tr:  99.90%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.134058/  2.789547, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.30it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.124165/  2.804651, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.120506/  2.806127, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.113658/  2.851587, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.107899/  2.851581, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.109808/  2.865618, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.109130/  2.870938, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.101528/  2.895401, tr:  99.90%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.099936/  2.879575, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.099223/  2.900136, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.104835/  2.939298, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.103599/  2.955451, tr: 100.00%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.091016/  2.937270, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.090395/  2.970046, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.094301/  3.028446, tr:  99.80%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.084386/  2.989377, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.04it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.076960/  3.059082, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.081167/  3.023106, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.079329/  3.074957, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.079408/  3.078703, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.078313/  3.108752, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.073337/  3.073727, tr:  99.90%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.069771/  3.120673, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.071667/  3.141786, tr: 100.00%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.067946/  3.119981, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.065193/  3.139883, tr:  99.90%, val:  66.67%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.066376/  3.163111, tr:  99.90%, val:  66.25%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.061751/  3.167231, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.064184/  3.185883, tr: 100.00%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.062342/  3.198515, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.061584/  3.242489, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.059837/  3.232558, tr: 100.00%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.057179/  3.200498, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.057694/  3.256129, tr: 100.00%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.058504/  3.289832, tr: 100.00%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.057030/  3.253619, tr:  99.90%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.055641/  3.290505, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.055002/  3.250223, tr:  99.90%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.054756/  3.339558, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.054725/  3.281593, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.058926/  3.318944, tr:  99.90%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.056122/  3.336075, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.052472/  3.315499, tr:  99.90%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.054250/  3.403196, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.048881/  3.441761, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.055467/  3.394903, tr:  99.90%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.065678/  3.366781, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.054403/  3.390027, tr: 100.00%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.053404/  3.402450, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.048982/  3.382859, tr: 100.00%, val:  64.58%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.07it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.044795/  3.406709, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.048061/  3.444878, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.044510/  3.429260, tr: 100.00%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.045463/  3.503633, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.047742/  3.462282, tr:  99.90%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.043883/  3.519145, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.045606/  3.469776, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.041058/  3.489861, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.040050/  3.487185, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.040463/  3.521026, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.039054/  3.520821, tr: 100.00%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.039658/  3.453574, tr:  99.90%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.039410/  3.516922, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.039714/  3.506242, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.040796/  3.496258, tr:  99.90%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.038810/  3.531704, tr: 100.00%, val:  67.08%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.038022/  3.525686, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.039758/  3.555133, tr:  99.90%, val:  69.58%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.039172/  3.558971, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.038630/  3.583277, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.034586/  3.573347, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.034504/  3.591938, tr: 100.00%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.033378/  3.588923, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.033105/  3.591370, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.035078/  3.574950, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.034686/  3.623275, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.034329/  3.599630, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.033085/  3.630665, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.032454/  3.639629, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.030451/  3.619901, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.033445/  3.637792, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.036321/  3.642178, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.035442/  3.628707, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.034931/  3.641021, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.036688/  3.654200, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.030012/  3.641887, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.031947/  3.655067, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.030386/  3.658773, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.029973/  3.679085, tr: 100.00%, val:  70.00%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.029210/  3.695593, tr: 100.00%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.029176/  3.733212, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.030359/  3.723458, tr: 100.00%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.027821/  3.707346, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.027894/  3.724938, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.028003/  3.739951, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.026543/  3.745548, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.026734/  3.694466, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.027620/  3.706000, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.028980/  3.735811, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.029335/  3.708570, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.028421/  3.718160, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.026898/  3.738636, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.025792/  3.732581, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.026253/  3.735591, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.026157/  3.760191, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.025923/  3.782076, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.024423/  3.772164, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.027203/  3.803185, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.027678/  3.795582, tr:  99.90%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.026169/  3.820550, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.024298/  3.812088, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.024153/  3.822913, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.024369/  3.819350, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.026582/  3.811915, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.024102/  3.795786, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.024833/  3.827460, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.024030/  3.817664, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.022541/  3.836058, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.023178/  3.828174, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.021329/  3.807445, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.022026/  3.817512, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.022002/  3.834085, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.023919/  3.827212, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.023465/  3.834579, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.023745/  3.801741, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.021754/  3.833331, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.022316/  3.862770, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.022303/  3.857607, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.020717/  3.839989, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.021750/  3.891340, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.021810/  3.885577, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.021115/  3.903272, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.021308/  3.888603, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.020989/  3.889684, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.019138/  3.886042, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d297ad29759416483db059564e3d651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>val_loss</td><td>▃▃▁▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01914</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>3.88604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-81</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jvm1t4j8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jvm1t4j8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_035600-jvm1t4j8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hlrd1si with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_041709-4hlrd1si</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hlrd1si' target=\"_blank\">fancy-sweep-84</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hlrd1si' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hlrd1si</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 6bfe112fbeab20d0d3bfdbe39d8150a3\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304236/  2.298794, tr:   8.89%, val:  14.17%, val_best:  14.17%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.203609/  2.016125, tr:  26.66%, val:  34.58%, val_best:  34.58%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.728984/  1.649610, tr:  48.01%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.391955/  1.501894, tr:  62.21%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.226112/  1.402464, tr:  66.70%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.119565/  1.362296, tr:  68.34%, val:  61.67%, val_best:  62.92%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.035965/  1.313606, tr:  73.44%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.966858/  1.374587, tr:  76.20%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.892671/  1.296228, tr:  81.51%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.848597/  1.311893, tr:  82.94%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.815480/  1.286381, tr:  81.92%, val:  67.50%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.733663/  1.337462, tr:  87.64%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.704963/  1.298387, tr:  88.15%, val:  65.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.705550/  1.231946, tr:  82.33%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.605784/  1.286165, tr:  93.16%, val:  73.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.573929/  1.310657, tr:  94.38%, val:  72.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.529981/  1.328887, tr:  94.69%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.491213/  1.298439, tr:  94.99%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.440299/  1.375841, tr:  98.06%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.404865/  1.341142, tr:  97.34%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.375271/  1.413831, tr:  98.77%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.354075/  1.429661, tr:  99.18%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.329391/  1.434701, tr:  98.37%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286002/  1.503995, tr:  99.49%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.280720/  1.520843, tr:  99.49%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.260556/  1.519406, tr:  99.08%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.239602/  1.489707, tr:  99.59%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.214336/  1.590168, tr:  99.80%, val:  76.25%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.194782/  1.590421, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.184622/  1.617384, tr:  99.69%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.155004/  1.638006, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.150049/  1.657414, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.136008/  1.707090, tr:  99.90%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.120515/  1.719182, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.115295/  1.766462, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.108454/  1.724638, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.100750/  1.787329, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.094926/  1.790928, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.084988/  1.833029, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.076725/  1.857871, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.070269/  1.866846, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.066107/  1.889085, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.065185/  1.917872, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.060466/  1.930752, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.052165/  1.949669, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.051564/  1.948518, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.048577/  1.972968, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.043894/  2.009741, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.040187/  2.004321, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.040160/  2.041957, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.041800/  2.079787, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.036610/  2.073794, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.036187/  2.091018, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.036375/  2.090957, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.033241/  2.080374, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.031923/  2.107308, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.030266/  2.128878, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.029362/  2.125573, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.029604/  2.113382, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.026971/  2.109569, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.024844/  2.132056, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.026775/  2.137433, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.032530/  2.172341, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.054217/  2.167245, tr:  99.90%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.026245/  2.136009, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.023479/  2.180834, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.021528/  2.175549, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.019567/  2.205206, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.019132/  2.194048, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.018398/  2.209348, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.019208/  2.220838, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.019316/  2.232343, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.017157/  2.258237, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.015641/  2.248618, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.015142/  2.244815, tr: 100.00%, val:  82.50%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.019021/  2.274572, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.017694/  2.284900, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.015639/  2.298601, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.016916/  2.305635, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.013835/  2.305021, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.013421/  2.304647, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.012761/  2.310547, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.013760/  2.289483, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.013523/  2.346805, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.012925/  2.324124, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.013325/  2.333296, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.017561/  2.336429, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.013502/  2.350425, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.012679/  2.366928, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.013656/  2.347122, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.011719/  2.345309, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.011827/  2.372918, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.010636/  2.344129, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.010654/  2.360234, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.010291/  2.384094, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.010435/  2.381706, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.009610/  2.394557, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.009720/  2.395812, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.009519/  2.374839, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.009946/  2.405029, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.009055/  2.415302, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.008838/  2.411055, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.008206/  2.412015, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.008204/  2.432309, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.008499/  2.433718, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.008134/  2.414011, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.008635/  2.414528, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.008034/  2.425467, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.007689/  2.434799, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.007922/  2.435584, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.011789/  2.448330, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.011322/  2.442972, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.008203/  2.447995, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.007994/  2.463811, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.007717/  2.475939, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.007766/  2.480775, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.007572/  2.484080, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.007445/  2.490935, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.007049/  2.498440, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.008071/  2.487993, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.007356/  2.481939, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.008912/  2.508793, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.007761/  2.516114, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.008023/  2.519284, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.007422/  2.507771, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.006827/  2.508328, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.007280/  2.495243, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.006561/  2.493504, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.007117/  2.509325, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.006179/  2.518638, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.006615/  2.518399, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.006610/  2.513843, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.006324/  2.519391, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.006896/  2.526285, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.006452/  2.508285, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.005759/  2.512332, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.005511/  2.508381, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.005927/  2.524084, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.006049/  2.529489, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.006099/  2.519903, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.005806/  2.522478, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.007588/  2.528255, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.006224/  2.540487, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.005982/  2.532003, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.005540/  2.531454, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.005412/  2.521798, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.006124/  2.510025, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.005669/  2.518521, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.005914/  2.519836, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.005478/  2.538046, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.004980/  2.528104, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.005338/  2.536566, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.004809/  2.546389, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.005568/  2.542963, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.005910/  2.550191, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.005287/  2.562010, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.005139/  2.549510, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.005029/  2.546520, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.005013/  2.544308, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.005080/  2.549368, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.005139/  2.571193, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.004725/  2.585514, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.004714/  2.581609, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.005086/  2.586900, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.004985/  2.584191, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.004623/  2.585135, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.004688/  2.602354, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.004659/  2.582090, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.004617/  2.577765, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.004696/  2.586109, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.004816/  2.597320, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.004361/  2.581500, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.005020/  2.605011, tr: 100.00%, val:  80.83%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.004370/  2.598333, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.005312/  2.618077, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.004556/  2.615742, tr: 100.00%, val:  79.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.004116/  2.610780, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.004351/  2.615878, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.004396/  2.614948, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.004068/  2.626645, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.004291/  2.627993, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.003939/  2.621647, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.004319/  2.630840, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.004095/  2.626323, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.003999/  2.619763, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.004377/  2.632501, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.003942/  2.632138, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.004053/  2.632462, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.004072/  2.641497, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.003815/  2.653848, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.003804/  2.630570, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.004080/  2.633395, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.004208/  2.629344, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.005053/  2.635332, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.004551/  2.642791, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.003839/  2.630698, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.003746/  2.624960, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.003700/  2.629864, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.003842/  2.642191, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.003475/  2.639536, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edf218c9b4542b89c2ef7a5ddfa4e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>val_loss</td><td>▅▁▁▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00348</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.8375</td></tr><tr><td>val_loss</td><td>2.63954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-84</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hlrd1si' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4hlrd1si</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_041709-4hlrd1si/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xv9i14nz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 50000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_043757-xv9i14nz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xv9i14nz' target=\"_blank\">likely-sweep-87</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xv9i14nz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xv9i14nz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 0d8b728364de4ecf8568b4c6954ef3a4\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304453/  2.302613, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304370/  2.302693, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305113/  2.302622, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304620/  2.302310, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.300770/  2.291932, tr:  11.95%, val:  12.08%, val_best:  12.08%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.225334/  2.170034, tr:  17.16%, val:  18.33%, val_best:  18.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.008942/  1.989219, tr:  29.01%, val:  35.42%, val_best:  35.42%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.729117/  1.796698, tr:  48.62%, val:  38.75%, val_best:  38.75%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.510947/  1.694535, tr:  55.98%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.381977/  1.639410, tr:  60.67%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.290323/  1.643694, tr:  66.29%, val:  45.00%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.222795/  1.630342, tr:  69.25%, val:  47.92%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.169098/  1.581748, tr:  72.01%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.142895/  1.558527, tr:  73.24%, val:  55.42%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.048723/  1.565450, tr:  78.65%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.010010/  1.561648, tr:  80.39%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.985045/  1.607529, tr:  82.64%, val:  56.67%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.929037/  1.572528, tr:  83.04%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.882120/  1.620134, tr:  85.60%, val:  53.75%, val_best:  61.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.846214/  1.567206, tr:  87.54%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.801794/  1.623613, tr:  89.68%, val:  59.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.770950/  1.623446, tr:  91.73%, val:  58.33%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.736301/  1.638053, tr:  91.01%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698552/  1.736465, tr:  92.44%, val:  60.83%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.698593/  1.735917, tr:  91.73%, val:  57.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.654873/  1.751812, tr:  94.08%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.616599/  1.718845, tr:  94.89%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.594170/  1.779879, tr:  94.59%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.567737/  1.752383, tr:  96.32%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.558051/  1.829662, tr:  95.20%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.519754/  1.783612, tr:  96.53%, val:  64.17%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.498050/  1.814247, tr:  97.14%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.467611/  1.873927, tr:  97.24%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.453829/  1.945429, tr:  97.75%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.434357/  1.983273, tr:  97.45%, val:  62.08%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.401538/  2.001785, tr:  97.85%, val:  61.67%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.393430/  2.021288, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.383840/  2.019406, tr:  98.57%, val:  64.17%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.352348/  2.077858, tr:  98.57%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.337143/  2.123051, tr:  98.88%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.327187/  2.094044, tr:  98.77%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.303727/  2.182719, tr:  98.88%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.295676/  2.205085, tr:  98.98%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.285624/  2.282178, tr:  99.18%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.267487/  2.239787, tr:  98.98%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [5:02:50<00:00, 293.07s/it]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.254357/  2.309304, tr:  99.08%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.251039/  2.325897, tr:  99.28%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.231962/  2.399669, tr:  99.59%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.227673/  2.378632, tr:  99.39%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.214757/  2.406626, tr:  99.49%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.210652/  2.467655, tr:  99.59%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.200284/  2.422487, tr:  99.49%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.210335/  2.496546, tr:  99.69%, val:  64.58%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.194084/  2.523542, tr:  99.80%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.183544/  2.526844, tr:  99.59%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.168971/  2.588564, tr:  99.80%, val:  63.75%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.164101/  2.548164, tr:  99.69%, val:  64.17%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.168199/  2.603082, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.156458/  2.612416, tr:  99.80%, val:  65.83%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.156114/  2.653112, tr:  99.90%, val:  65.42%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.150686/  2.703130, tr:  99.80%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.148362/  2.674302, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.140094/  2.734603, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.129976/  2.742191, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.131548/  2.774594, tr:  99.90%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.134058/  2.789547, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.124165/  2.804651, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.120506/  2.806127, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.113658/  2.851587, tr:  99.90%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.107899/  2.851581, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.109808/  2.865618, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.109130/  2.870938, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.101528/  2.895401, tr:  99.90%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.099936/  2.879575, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.099223/  2.900136, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.104835/  2.939298, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.103599/  2.955451, tr: 100.00%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.091016/  2.937270, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.090395/  2.970046, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.094301/  3.028446, tr:  99.80%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.084386/  2.989377, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.076960/  3.059082, tr:  99.90%, val:  67.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.081167/  3.023106, tr:  99.90%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.079329/  3.074957, tr:  99.90%, val:  66.25%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.079408/  3.078703, tr:  99.90%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.078313/  3.108752, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.073337/  3.073727, tr:  99.90%, val:  65.83%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.069771/  3.120673, tr:  99.90%, val:  67.08%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.33it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.071667/  3.141786, tr: 100.00%, val:  67.50%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.067946/  3.119981, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.065193/  3.139883, tr:  99.90%, val:  66.67%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.066376/  3.163111, tr:  99.90%, val:  66.25%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.061751/  3.167231, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.064184/  3.185883, tr: 100.00%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.062342/  3.198515, tr:  99.90%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.061584/  3.242489, tr:  99.90%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.059837/  3.232558, tr: 100.00%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.057179/  3.200498, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.057694/  3.256129, tr: 100.00%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.058504/  3.289832, tr: 100.00%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.057030/  3.253619, tr:  99.90%, val:  67.50%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.055641/  3.290505, tr: 100.00%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.055002/  3.250223, tr:  99.90%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.054756/  3.339558, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.054725/  3.281593, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.058926/  3.318944, tr:  99.90%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.056122/  3.336075, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.052472/  3.315499, tr:  99.90%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.054250/  3.403196, tr:  99.90%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.048881/  3.441761, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.055467/  3.394903, tr:  99.90%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.065678/  3.366781, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.054403/  3.390027, tr: 100.00%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.053404/  3.402450, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.048982/  3.382859, tr: 100.00%, val:  64.58%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.044795/  3.406709, tr: 100.00%, val:  65.42%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.048061/  3.444878, tr: 100.00%, val:  65.83%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.044510/  3.429260, tr: 100.00%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.045463/  3.503633, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.047742/  3.462282, tr:  99.90%, val:  66.25%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.043883/  3.519145, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.045606/  3.469776, tr: 100.00%, val:  67.08%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.041058/  3.489861, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.040050/  3.487185, tr: 100.00%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.040463/  3.521026, tr: 100.00%, val:  68.75%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.039054/  3.520821, tr: 100.00%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.039658/  3.453574, tr:  99.90%, val:  68.33%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.039410/  3.516922, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.039714/  3.506242, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.040796/  3.496258, tr:  99.90%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.038810/  3.531704, tr: 100.00%, val:  67.08%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.038022/  3.525686, tr: 100.00%, val:  67.50%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.039758/  3.555133, tr:  99.90%, val:  69.58%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.039172/  3.558971, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.038630/  3.583277, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.034586/  3.573347, tr: 100.00%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.034504/  3.591938, tr: 100.00%, val:  67.92%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.033378/  3.588923, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.033105/  3.591370, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.035078/  3.574950, tr: 100.00%, val:  69.17%, val_best:  70.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.034686/  3.623275, tr: 100.00%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.034329/  3.599630, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.033085/  3.630665, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.032454/  3.639629, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.030451/  3.619901, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.033445/  3.637792, tr: 100.00%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.036321/  3.642178, tr: 100.00%, val:  68.75%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.035442/  3.628707, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.034931/  3.641021, tr: 100.00%, val:  68.33%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.036688/  3.654200, tr:  99.90%, val:  69.17%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.030012/  3.641887, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.031947/  3.655067, tr: 100.00%, val:  69.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.030386/  3.658773, tr: 100.00%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.029973/  3.679085, tr: 100.00%, val:  70.00%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.029210/  3.695593, tr: 100.00%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.029176/  3.733212, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.030359/  3.723458, tr: 100.00%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.027821/  3.707346, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.027894/  3.724938, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.028003/  3.739951, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.026543/  3.745548, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.026734/  3.694466, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.027620/  3.706000, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.028980/  3.735811, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.029335/  3.708570, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.028421/  3.718160, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.026898/  3.738636, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.025792/  3.732581, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.026253/  3.735591, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.026157/  3.760191, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.025923/  3.782076, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.024423/  3.772164, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.027203/  3.803185, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.027678/  3.795582, tr:  99.90%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.026169/  3.820550, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.024298/  3.812088, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.024153/  3.822913, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.024369/  3.819350, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.026582/  3.811915, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.024102/  3.795786, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.024833/  3.827460, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.024030/  3.817664, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.022541/  3.836058, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.023178/  3.828174, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.021329/  3.807445, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.022026/  3.817512, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.022002/  3.834085, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.023919/  3.827212, tr: 100.00%, val:  68.75%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.023465/  3.834579, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.023745/  3.801741, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.021754/  3.833331, tr: 100.00%, val:  70.00%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.022316/  3.862770, tr: 100.00%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.022303/  3.857607, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.020717/  3.839989, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.021750/  3.891340, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.021810/  3.885577, tr: 100.00%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.021115/  3.903272, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.021308/  3.888603, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.020989/  3.889684, tr: 100.00%, val:  69.58%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.019138/  3.886042, tr: 100.00%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cc973b380f4ae6ac79a23633e6bc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇█████████▇▇████████████████</td></tr><tr><td>val_loss</td><td>▃▃▁▁▁▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01914</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>3.88604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-87</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xv9i14nz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xv9i14nz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_043757-xv9i14nz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tcz73ov0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_100126-tcz73ov0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tcz73ov0' target=\"_blank\">fine-sweep-122</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tcz73ov0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tcz73ov0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 6bfe112fbeab20d0d3bfdbe39d8150a3\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.304236/  2.298794, tr:   8.89%, val:  14.17%, val_best:  14.17%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.203609/  2.016125, tr:  26.66%, val:  34.58%, val_best:  34.58%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.728984/  1.649610, tr:  48.01%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.391955/  1.501894, tr:  62.21%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.226112/  1.402464, tr:  66.70%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.119565/  1.362296, tr:  68.34%, val:  61.67%, val_best:  62.92%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.035965/  1.313606, tr:  73.44%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.966858/  1.374587, tr:  76.20%, val:  64.58%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.892671/  1.296228, tr:  81.51%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.848597/  1.311893, tr:  82.94%, val:  68.33%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.815480/  1.286381, tr:  81.92%, val:  67.50%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.733663/  1.337462, tr:  87.64%, val:  67.92%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.704963/  1.298387, tr:  88.15%, val:  65.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.705550/  1.231946, tr:  82.33%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.605784/  1.286165, tr:  93.16%, val:  73.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.573929/  1.310657, tr:  94.38%, val:  72.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.529981/  1.328887, tr:  94.69%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.491213/  1.298439, tr:  94.99%, val:  76.25%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.440299/  1.375841, tr:  98.06%, val:  75.00%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.404865/  1.341142, tr:  97.34%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.375271/  1.413831, tr:  98.77%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.354075/  1.429661, tr:  99.18%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.329391/  1.434701, tr:  98.37%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286002/  1.503995, tr:  99.49%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.280720/  1.520843, tr:  99.49%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.260556/  1.519406, tr:  99.08%, val:  76.67%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.239602/  1.489707, tr:  99.59%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.214336/  1.590168, tr:  99.80%, val:  76.25%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.194782/  1.590421, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.184622/  1.617384, tr:  99.69%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.155004/  1.638006, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.150049/  1.657414, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.136008/  1.707090, tr:  99.90%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.120515/  1.719182, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.115295/  1.766462, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.108454/  1.724638, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.100750/  1.787329, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.094926/  1.790928, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.084988/  1.833029, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.076725/  1.857871, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.070269/  1.866846, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.066107/  1.889085, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.065185/  1.917872, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.060466/  1.930752, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.052165/  1.949669, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.051564/  1.948518, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.048577/  1.972968, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.043894/  2.009741, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.040187/  2.004321, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.040160/  2.041957, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.041800/  2.079787, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.036610/  2.073794, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.036187/  2.091018, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.036375/  2.090957, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.033241/  2.080374, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.031923/  2.107308, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.030266/  2.128878, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.029362/  2.125573, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.029604/  2.113382, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.026971/  2.109569, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.024844/  2.132056, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.026775/  2.137433, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.032530/  2.172341, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.054217/  2.167245, tr:  99.90%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.026245/  2.136009, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.023479/  2.180834, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.021528/  2.175549, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.019567/  2.205206, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.019132/  2.194048, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.018398/  2.209348, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.019208/  2.220838, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.019316/  2.232343, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.017157/  2.258237, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.015641/  2.248618, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.015142/  2.244815, tr: 100.00%, val:  82.50%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.019021/  2.274572, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.017694/  2.284900, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.015639/  2.298601, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.016916/  2.305635, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.013835/  2.305021, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.013421/  2.304647, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.012761/  2.310547, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.013760/  2.289483, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.013523/  2.346805, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.012925/  2.324124, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.013325/  2.333296, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.017561/  2.336429, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.013502/  2.350425, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.012679/  2.366928, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.013656/  2.347122, tr: 100.00%, val:  83.33%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.011719/  2.345309, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.011827/  2.372918, tr: 100.00%, val:  82.50%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.010636/  2.344129, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.010654/  2.360234, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.010291/  2.384094, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.010435/  2.381706, tr: 100.00%, val:  82.92%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.009610/  2.394557, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.009720/  2.395812, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.009519/  2.374839, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.009946/  2.405029, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.009055/  2.415302, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.008838/  2.411055, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.008206/  2.412015, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.008204/  2.432309, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.008499/  2.433718, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.008134/  2.414011, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.008635/  2.414528, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.008034/  2.425467, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.007689/  2.434799, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.007922/  2.435584, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.011789/  2.448330, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.011322/  2.442972, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.008203/  2.447995, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.007994/  2.463811, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.007717/  2.475939, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.007766/  2.480775, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.007572/  2.484080, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.007445/  2.490935, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.007049/  2.498440, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.008071/  2.487993, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.007356/  2.481939, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.008912/  2.508793, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.007761/  2.516114, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.008023/  2.519284, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.007422/  2.507771, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.006827/  2.508328, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.007280/  2.495243, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.006561/  2.493504, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.007117/  2.509325, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.006179/  2.518638, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.006615/  2.518399, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.006610/  2.513843, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.006324/  2.519391, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.006896/  2.526285, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.006452/  2.508285, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.005759/  2.512332, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.005511/  2.508381, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.005927/  2.524084, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.006049/  2.529489, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.006099/  2.519903, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.005806/  2.522478, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.007588/  2.528255, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.006224/  2.540487, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.005982/  2.532003, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.005540/  2.531454, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.005412/  2.521798, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.006124/  2.510025, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.005669/  2.518521, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.005914/  2.519836, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.005478/  2.538046, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.004980/  2.528104, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.005338/  2.536566, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.004809/  2.546389, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.005568/  2.542963, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.005910/  2.550191, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.005287/  2.562010, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.005139/  2.549510, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.005029/  2.546520, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.005013/  2.544308, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.005080/  2.549368, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.005139/  2.571193, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.004725/  2.585514, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.004714/  2.581609, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.005086/  2.586900, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.004985/  2.584191, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.004623/  2.585135, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.004688/  2.602354, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.004659/  2.582090, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.004617/  2.577765, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.004696/  2.586109, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.004816/  2.597320, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.004361/  2.581500, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.005020/  2.605011, tr: 100.00%, val:  80.83%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.004370/  2.598333, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.005312/  2.618077, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.004556/  2.615742, tr: 100.00%, val:  79.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.004116/  2.610780, tr: 100.00%, val:  81.67%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.004351/  2.615878, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.004396/  2.614948, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.004068/  2.626645, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.004291/  2.627993, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.003939/  2.621647, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.004319/  2.630840, tr: 100.00%, val:  81.25%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.004095/  2.626323, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.003999/  2.619763, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.004377/  2.632501, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.003942/  2.632138, tr: 100.00%, val:  82.08%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.004053/  2.632462, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.004072/  2.641497, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.003815/  2.653848, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.003804/  2.630570, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.004080/  2.633395, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.004208/  2.629344, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.005053/  2.635332, tr: 100.00%, val:  82.50%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.37it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.004551/  2.642791, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.003839/  2.630698, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.003746/  2.624960, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.003700/  2.629864, tr: 100.00%, val:  83.33%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.003842/  2.642191, tr: 100.00%, val:  82.92%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.003475/  2.639536, tr: 100.00%, val:  83.75%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12076f37ba346e2b9c8609d1dd39aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████████████████▇██▇███</td></tr><tr><td>val_loss</td><td>▅▁▁▁▁▂▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00348</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.8375</td></tr><tr><td>val_loss</td><td>2.63954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-122</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tcz73ov0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tcz73ov0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_100126-tcz73ov0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rzg4cmnz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_102030-rzg4cmnz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rzg4cmnz' target=\"_blank\">misunderstood-sweep-124</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rzg4cmnz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rzg4cmnz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = e4f53e6da8bea326220fd94e3b404107\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.256123/  2.050023, tr:  15.53%, val:  30.42%, val_best:  30.42%: 100%|██████████| 62/62 [00:22<00:00,  2.73it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.719911/  1.541454, tr:  48.72%, val:  59.58%, val_best:  59.58%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.349207/  1.405213, tr:  61.80%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.163909/  1.366311, tr:  67.72%, val:  62.92%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.043346/  1.315153, tr:  73.95%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.938789/  1.320649, tr:  75.18%, val:  64.58%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.850971/  1.320968, tr:  81.51%, val:  60.83%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.774847/  1.396896, tr:  84.27%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.685858/  1.320056, tr:  89.58%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.620989/  1.424113, tr:  89.79%, val:  64.17%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.579748/  1.339171, tr:  91.83%, val:  69.58%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.500045/  1.448147, tr:  93.36%, val:  72.50%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.432972/  1.416932, tr:  95.81%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.416761/  1.381506, tr:  94.99%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.343923/  1.462358, tr:  98.88%, val:  72.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.301266/  1.515115, tr:  98.88%, val:  74.58%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.251403/  1.545329, tr:  99.59%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.231791/  1.540481, tr:  99.49%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.176202/  1.596737, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.159026/  1.602554, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.127333/  1.682048, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.112207/  1.659011, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.096211/  1.700856, tr: 100.00%, val:  77.50%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.081515/  1.790667, tr: 100.00%, val:  77.92%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.068189/  1.810079, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.067058/  1.835697, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.056606/  1.880360, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.047212/  1.886371, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.038805/  1.914003, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.036507/  1.918159, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.029353/  1.940957, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.025679/  1.933612, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.023983/  1.960209, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.021359/  2.013381, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.019492/  2.001430, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.017720/  2.005865, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.016308/  2.010674, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.014917/  2.021149, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.014128/  2.047701, tr: 100.00%, val:  81.67%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.013241/  2.047446, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.011930/  2.060302, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.010550/  2.087669, tr: 100.00%, val:  83.33%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.009590/  2.076211, tr: 100.00%, val:  83.33%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.009777/  2.106297, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.008650/  2.105203, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.008531/  2.121774, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.008000/  2.125562, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.008078/  2.137780, tr: 100.00%, val:  81.67%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.007667/  2.146959, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.006883/  2.138457, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.006834/  2.154875, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.006261/  2.178964, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.005792/  2.184761, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.006070/  2.199648, tr: 100.00%, val:  82.08%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.005953/  2.195707, tr: 100.00%, val:  82.92%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.005367/  2.195826, tr: 100.00%, val:  83.33%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.005116/  2.198536, tr: 100.00%, val:  83.75%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.005044/  2.197324, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.004839/  2.216630, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.004875/  2.217673, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.004798/  2.222689, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.005083/  2.219580, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.004863/  2.222027, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.004308/  2.239703, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.004278/  2.238952, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.004130/  2.243513, tr: 100.00%, val:  81.67%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.004082/  2.244139, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.003993/  2.251628, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.003623/  2.244729, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.003557/  2.259236, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.003371/  2.271442, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.003363/  2.267038, tr: 100.00%, val:  82.08%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.003358/  2.271278, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.003298/  2.269460, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.003220/  2.272243, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.003031/  2.273587, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.002910/  2.283107, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.002888/  2.294852, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.16it/s]\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.002883/  2.299371, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.002919/  2.296170, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.002802/  2.300658, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.002761/  2.309266, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.002802/  2.306451, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.002797/  2.320285, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:07<00:00,  8.25it/s]\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.002610/  2.325851, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:07<00:00,  8.72it/s]\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.002614/  2.330645, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:07<00:00,  8.48it/s]\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.002808/  2.325032, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.002525/  2.333757, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.002433/  2.346063, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.002464/  2.329617, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.002486/  2.329802, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.002504/  2.355255, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.002588/  2.348999, tr: 100.00%, val:  82.92%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.002325/  2.354893, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.002254/  2.362607, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.002343/  2.353037, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.002316/  2.358195, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.002363/  2.372680, tr: 100.00%, val:  82.08%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.002314/  2.373274, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.002160/  2.378843, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.002041/  2.373618, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.001918/  2.385870, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.001872/  2.383523, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.001904/  2.385495, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.001887/  2.392888, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.001817/  2.388220, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.001827/  2.385380, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.001734/  2.409224, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.001701/  2.401402, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.001769/  2.382695, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:09<00:00,  6.54it/s]\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.001759/  2.409284, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.001697/  2.409009, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.001641/  2.406028, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.001679/  2.402152, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.001663/  2.406609, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.001615/  2.406263, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.001597/  2.413394, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.001568/  2.424492, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.001514/  2.432204, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.001500/  2.435024, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.001509/  2.434064, tr: 100.00%, val:  83.75%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.001457/  2.436826, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.001445/  2.424771, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.001420/  2.437182, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.001461/  2.435830, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.001390/  2.441386, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.001423/  2.440110, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.001367/  2.438114, tr: 100.00%, val:  83.33%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.001344/  2.447832, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.001337/  2.437852, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.001349/  2.457563, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.001291/  2.448420, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.001290/  2.460959, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.001297/  2.457396, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.001284/  2.447734, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.001264/  2.455632, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.001239/  2.457317, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.001249/  2.454985, tr: 100.00%, val:  85.83%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.001202/  2.456437, tr: 100.00%, val:  85.83%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.001266/  2.464080, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.001229/  2.460686, tr: 100.00%, val:  86.25%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.001214/  2.473397, tr: 100.00%, val:  85.83%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.001185/  2.470842, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.001123/  2.474324, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.001178/  2.481501, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.001142/  2.488311, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.001150/  2.490827, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 13.05it/s]\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.001112/  2.485105, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.001113/  2.489801, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.001088/  2.494294, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.001070/  2.492622, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.001068/  2.492673, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.001059/  2.505003, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.001045/  2.499006, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.001035/  2.507467, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.97it/s]\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.001027/  2.515830, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.001008/  2.513157, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.001004/  2.504898, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.001023/  2.510572, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.000995/  2.506074, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.000981/  2.514320, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.000961/  2.509014, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.000970/  2.507783, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.000967/  2.514725, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.000941/  2.521251, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.000999/  2.513801, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.000971/  2.525969, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.000928/  2.527479, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.000986/  2.533958, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.000959/  2.534494, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.000953/  2.545400, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.000964/  2.531799, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.000933/  2.537259, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.000913/  2.534238, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.000932/  2.536448, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.000901/  2.533663, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.000913/  2.537412, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.000890/  2.539201, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.000909/  2.536423, tr: 100.00%, val:  83.33%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.000906/  2.536675, tr: 100.00%, val:  83.33%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.000876/  2.546906, tr: 100.00%, val:  83.33%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.000879/  2.545324, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.000911/  2.543010, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.000887/  2.543148, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.000895/  2.540344, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.000863/  2.549836, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.000838/  2.551488, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.000867/  2.557192, tr: 100.00%, val:  83.75%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.000831/  2.551903, tr: 100.00%, val:  83.33%, val_best:  86.25%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.000836/  2.548815, tr: 100.00%, val:  83.33%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.000981/  2.539783, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.001594/  2.549421, tr: 100.00%, val:  84.17%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.001507/  2.547183, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.001065/  2.552892, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.000973/  2.563247, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.000959/  2.567639, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  0.000890/  2.561124, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  0.000845/  2.559965, tr: 100.00%, val:  84.58%, val_best:  86.25%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  0.000821/  2.563142, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.83it/s]\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  0.000817/  2.567588, tr: 100.00%, val:  85.00%, val_best:  86.25%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6609255aa839497f834d01dec591169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▅▆▆▇▇▇▇▇▇█▇▇▇█▇█▇▇███▇█████████▇█▇███</td></tr><tr><td>tr_acc</td><td>▁▅▇█████████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▅▆▆▇▇▇▇▇▇█▇▇▇█▇█▇▇███▇█████████▇█▇███</td></tr><tr><td>val_loss</td><td>▂▁▂▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00082</td></tr><tr><td>val_acc_best</td><td>0.8625</td></tr><tr><td>val_acc_now</td><td>0.85</td></tr><tr><td>val_loss</td><td>2.56759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-124</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rzg4cmnz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rzg4cmnz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241011_102030-rzg4cmnz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1sboysar with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tI_wanna_sweep_at_this_epoch: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration_domain: []\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_relative_timestep: [False]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3.555718888923306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.720291189014991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20241011_103931-1sboysar</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1sboysar' target=\"_blank\">generous-sweep-125</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ywcothlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1sboysar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1sboysar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_relative_timestep' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'I_wanna_sweep_at_this_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration_domain' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 29895be2ed3ab1cb928232acf3c90aed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.795577/  1.360274, tr:  39.12%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.10it/s]\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.134894/  1.262497, tr:  63.02%, val:  60.00%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  0.979571/  1.109356, tr:  68.34%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.851895/  1.169346, tr:  72.42%, val:  62.92%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.760621/  1.042081, tr:  77.22%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.696660/  1.127696, tr:  77.12%, val:  64.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.626975/  1.051578, tr:  81.72%, val:  67.50%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.563112/  1.061946, tr:  82.84%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.483544/  1.104503, tr:  89.99%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.460879/  1.185734, tr:  88.15%, val:  70.83%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.399304/  1.158410, tr:  92.34%, val:  68.75%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.374478/  1.136708, tr:  90.40%, val:  70.42%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.327349/  1.160261, tr:  95.10%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.316208/  1.167410, tr:  93.36%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.234275/  1.170870, tr:  97.75%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.215293/  1.372760, tr:  99.08%, val:  67.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.211758/  1.277354, tr:  97.45%, val:  72.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.170549/  1.184381, tr:  98.47%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.110125/  1.229443, tr:  99.90%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.134958/  1.288428, tr:  98.57%, val:  74.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.092988/  1.306357, tr:  99.90%, val:  76.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.103619/  1.261543, tr:  99.28%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.062413/  1.346133, tr: 100.00%, val:  76.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.047329/  1.361074, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.036160/  1.382239, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.038191/  1.393292, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.024546/  1.415632, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [31:35<00:00, 30.56s/it]\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.021141/  1.453801, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.017030/  1.438080, tr: 100.00%, val:  76.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.015260/  1.455807, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:33<00:00,  1.87it/s]\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.013049/  1.474945, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:08<00:00,  7.58it/s]\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.012102/  1.490865, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:07<00:00,  8.64it/s]\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.011037/  1.498105, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.010140/  1.525771, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.009951/  1.511673, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.009065/  1.523300, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.008819/  1.539842, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:07<00:00,  8.74it/s]\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.007696/  1.510919, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.007066/  1.520369, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.006745/  1.541388, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.006435/  1.556636, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.005999/  1.570238, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.006024/  1.558400, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.005656/  1.579492, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.005357/  1.569220, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.005310/  1.579910, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:13<00:00,  4.51it/s]\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.004842/  1.592217, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.004631/  1.595541, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:28<00:00,  2.15it/s]\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.004446/  1.613099, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:37<00:00,  1.65it/s]\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.004236/  1.602903, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.91it/s]\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.004282/  1.609715, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.004027/  1.613692, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:20<00:00,  3.03it/s]\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.003799/  1.626463, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:30<00:00,  2.06it/s]\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.003863/  1.637901, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:26<00:00,  2.32it/s]\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.003648/  1.637778, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:44<00:00,  1.41it/s]\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.003559/  1.642921, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.003305/  1.636874, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:45<00:00,  1.38it/s]\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.003198/  1.652908, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:31<00:00,  1.96it/s]\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.003089/  1.653537, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:37<00:00,  1.65it/s]\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.003007/  1.651921, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:30<00:00,  2.03it/s]\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.002952/  1.653014, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:43<00:00,  1.44it/s]\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.002830/  1.648368, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:40<00:00,  1.55it/s]\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.002721/  1.657605, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:30<00:00,  2.03it/s]\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.002683/  1.665928, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:45<00:00,  1.37it/s]\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.002655/  1.669112, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:53<00:00,  1.16it/s]\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.002512/  1.663549, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:48<00:00,  1.29it/s]\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.002507/  1.661752, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:39<00:00,  1.55it/s]\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.002404/  1.674244, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:41<00:00,  1.49it/s]\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.002382/  1.672153, tr: 100.00%, val:  80.42%, val_best:  82.50%: 100%|██████████| 62/62 [00:50<00:00,  1.24it/s]\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.002301/  1.664392, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:36<00:00,  1.68it/s]\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.002218/  1.670432, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n",
      "epoch-71  iter_acc: 100.00%, lr=['0.0010000'], iter_loss:  0.002059, val_best:  82.50%:  34%|███▍      | 21/62 [00:14<00:29,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'random', # 'random', 'bayes'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"values\": [0.001]}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"epoch_num\": {\"values\": [200]},\n",
    "        \"dvs_duration\": {\"values\": [25_000,50_000,100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [1,2,3,4,5]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [3.555718888923306]},\n",
    "        \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.720291189014991]},\n",
    "        \"scheduler_name\": {\"values\": ['no']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "        \"denoise_on\": {\"values\": [True,False]}, \n",
    "        \"I_wanna_sweep_at_this_epoch\": {\"values\": [-1]}, \n",
    "        \"dvs_duration_domain\": {\"values\": [[]]}, \n",
    "        \"dvs_relative_timestep\": {\"values\": [[False]]}, \n",
    "        \"extra_train_dataset\": {\"values\": [0]}, \n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "    lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "    scheduler_name  =  wandb.config.scheduler_name\n",
    "    denoise_on  =  wandb.config.denoise_on\n",
    "    I_wanna_sweep_at_this_epoch  =  wandb.config.I_wanna_sweep_at_this_epoch\n",
    "    dvs_duration_domain  =  wandb.config.dvs_duration_domain\n",
    "    dvs_relative_timestep  =  wandb.config.dvs_relative_timestep\n",
    "    extra_train_dataset  =  wandb.config.extra_train_dataset\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = denoise_on,\n",
    "\n",
    "                I_wanna_sweep_at_this_epoch = I_wanna_sweep_at_this_epoch,\n",
    "                dvs_duration_domain = dvs_duration_domain,\n",
    "                dvs_relative_timestep = dvs_relative_timestep, # True # False \n",
    "\n",
    "                extra_train_dataset = extra_train_dataset,\n",
    "\n",
    "                num_workers = 2,\n",
    "                chaching_on = True,\n",
    "                pin_memory = False, # True # False\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "sweep_id = 'ywcothlb'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
