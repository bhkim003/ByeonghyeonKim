{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "            converted_net = torch.nn.DataParallel(converted_net)\n",
    "            # print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            converted_net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "            converted_net = torch.nn.DataParallel(converted_net)\n",
    "            # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # pre_net = Autoencoder_conv1_old(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge)\n",
    "        # pre_net = torch.nn.DataParallel(pre_net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = zero_to_one_normalize_features(spike) if normalize_on else spike\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                spike_class = net(spike) # batch, time, feature\n",
    "\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = zero_to_one_normalize_features(spike_template) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template).float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                                \n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/len(k_means_bin_origin_feature):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = '4'\n",
    "# Conv_net = True\n",
    "# SAE_net = False\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# max_epoch = 1\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = True # True or False # 0부터1까지 normalize\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 10 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "# v_decay = 1.0 # -cor\n",
    "# v_threshold = 0.53 # -cor\n",
    "# v_reset = 0.0 # -cor # 10000 이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = True # True False\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'SGD' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# coarse_com_mode = False\n",
    "# coarse_com_config = (2.0, -2.0) # (max, min) (2.0, -2.0) (3.0 -3.0)\n",
    "\n",
    "# sae_l2_norm_bridge = True # True False\n",
    "# sae_lif_bridge = True # False True\n",
    "\n",
    "# accuracy_check_epoch_term = 1\n",
    "\n",
    "# lif_add_at_last = False # True False\n",
    "\n",
    "# two_channel_input = False # True False\n",
    "\n",
    "# lateral_feature_num = 4\n",
    "\n",
    "# lc_adc_on = False # True False\n",
    "\n",
    "# converted_net_forward = True # True False\n",
    "\n",
    "\n",
    "# # pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "#     current_time = current_time,\n",
    "\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#     coarse_com_mode = coarse_com_mode,\n",
    "#     coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "#     sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#     sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#     accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "#     lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "#     two_channel_input = two_channel_input,\n",
    "\n",
    "#     lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#     lc_adc_on = lc_adc_on, \n",
    "\n",
    "#     converted_net_forward = converted_net_forward,\n",
    "\n",
    "#     pretrained_net = pretrained_net,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: fl1aqd31\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/fl1aqd31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 63of4t3s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taccuracy_check_epoch_term: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_config: [2, -2]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconverted_net_forward: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlateral_feature_num: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlc_adc_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_last: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpretrained_net: /home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_l2_norm_bridge: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_lif_bridge: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 2400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttwo_channel_input: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250113_220729-63of4t3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/63of4t3s' target=\"_blank\">usual-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/fl1aqd31' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/fl1aqd31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/fl1aqd31' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/fl1aqd31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/63of4t3s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/63of4t3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_mode' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_l2_norm_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_lif_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'accuracy_check_epoch_term' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_last' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'two_channel_input' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lateral_feature_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lc_adc_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'converted_net_forward' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pretrained_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_config' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0,4', 'Conv_net': True, 'SAE_net': False, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 1, 'learning_rate': 0.0001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 6000, 'v_decay': 1, 'v_threshold': 0.25, 'v_reset': 0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250113_220737_504', 'optimizer': 'Adam', 'coarse_com_mode': False, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': True, 'pretrained_net': '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth', 'coarse_com_config': [2, -2]}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "ae conv lenght [50, 24, 11, 5]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): Autoencoder_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): SSBH_DimChanger_for_fc()\n",
      "      (7): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (8): ReLU()\n",
      "      (9): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250113_220737_504\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "epoch-0 loss : 0.00000\n",
      "ae train 실행 시간: 0.001초\n",
      "\n",
      "epoch-0 accuracy check\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'converted_k_means_acc'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [32]}, \n",
    "        \"max_epoch\": {\"values\": [1]}, \n",
    "        \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "        \"normalize_on\": {\"values\": [True]},\n",
    "        \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2000,3000,4000,5000,6000,7000]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "        \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "        \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "        \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "        \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "        \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "        \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "        \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  '0,4'\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "    coarse_com_mode = wandb.config.coarse_com_mode\n",
    "    coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "    sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "    accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "    lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "    two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "    lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "    lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "    converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "    pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "        coarse_com_mode = coarse_com_mode,\n",
    "        coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "        sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "        sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "        accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "        lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "        two_channel_input = two_channel_input,\n",
    "        \n",
    "        lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "        lc_adc_on = lc_adc_on,\n",
    "\n",
    "        converted_net_forward = converted_net_forward,\n",
    "\n",
    "        pretrained_net = pretrained_net,\n",
    "\n",
    "        )\n",
    "    \n",
    "# sweep_id = 'ygoj9jt4'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
