{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13890/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    test_timesteps=-1,\n",
    "                    random_select_ratio=3,\n",
    "                    leaky_temporal_filter = 1.0,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "    train_timesteps = TIME\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "            # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "            return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                        \n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    max_of_inf_acculmulation = 0.0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "\n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                assert False\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                assert False\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # if i % 1000 == 999:\n",
    "            #     # SYNAPSE_FCÏóê ÏûàÎäî sparsity_print_and_reset() Ïã§Ìñâ\n",
    "            #     for name, module in net.module.named_modules():\n",
    "            #         if isinstance(module, SYNAPSE_FC):\n",
    "            #             module.sparsity_print_and_reset()\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                assert False\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            assert test_timesteps == -2\n",
    "            TIME = train_timesteps\n",
    "            net.module.change_timesteps(train_timesteps) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            \n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(inputs.shape[0]//temporal_filter):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2)\n",
    "                    slice_concat = slice_concat.reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    # print(slice_concat.shape)\n",
    "                    # torch.Size([1, 2, 14, 70])\n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        for ttt in range(temporal_filter):\n",
    "                            if ttt == 0:\n",
    "                                pass\n",
    "                            else:\n",
    "                                slice_concat[..., shape_temp[-1] * (ttt) : shape_temp[-1] * (ttt+1)] = slice_concat[..., shape_temp[-1] * (ttt) : shape_temp[-1] * (ttt+1)] + slice_concat[..., shape_temp[-1] * (ttt-1) : shape_temp[-1] * (ttt)]\n",
    "                        slice_bucket.append(slice_concat)\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                # if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                #     inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "            if extra_train_dataset == -1:\n",
    "                # print(inputs.shape)\n",
    "                assert BATCH == 1\n",
    "                this_sample_total_tw = inputs.shape[0]\n",
    "\n",
    "                # Í∞Å timestepÎ≥Ñ Ìï© Í≥ÑÏÇ∞\n",
    "                time_sums = inputs.sum(dim=(1, 2, 3, 4)) \n",
    "                \n",
    "                # time_sums ÏÉÅÏúÑ NÍ∞ú Ïù∏Îç±Ïä§ Ï∂îÏ∂ú (Ïòà: N = TIME * 2)\n",
    "                N = min(this_sample_total_tw, round(TIME * random_select_ratio))\n",
    "                topk_vals, topk_idx = torch.topk(time_sums, k=N)\n",
    "\n",
    "                # ÏÉÅÏúÑ NÍ∞ú Ï§ëÏóêÏÑú TIMEÍ∞ú ÎûúÎç§ ÏÑ†ÌÉù\n",
    "                chosen_idx = topk_idx[torch.randperm(N)[:TIME]]\n",
    "\n",
    "                # ÏÑ†ÌÉùÌïú Ïù∏Îç±Ïä§ Ï†ïÎ†¨ (ÏãúÍ∞Ñ ÏàúÏÑú Ïú†ÏßÄ)\n",
    "                chosen_idx, _ = torch.sort(chosen_idx)\n",
    "\n",
    "                # ÏÑ†ÌÉùÌïú Ïù∏Îç±Ïä§Î°ú Ïä¨ÎùºÏù¥Ïã±\n",
    "                inputs = inputs[chosen_idx]\n",
    "                # print(f'N {N}, this_sample_total_tw {this_sample_total_tw}, inputs.shape after random select: {inputs.shape}')\n",
    "                # print(f'chosen_idx {chosen_idx}, TIME {TIME}, time_sums.shape {time_sums.shape} time_sums {time_sums}')\n",
    "\n",
    "                if dvs_clipping != 0:\n",
    "                    inputs[inputs<dvs_clipping] = 0.0\n",
    "                    inputs[inputs>=dvs_clipping] = 1.0\n",
    "                    \n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = (outputs_one_time.detach()).argmax(dim=1)\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            assert False\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            assert False\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        assert test_timesteps == -2\n",
    "                        this_data_timesteps = inputs_val.shape[0]\n",
    "                        TIME = this_data_timesteps//temporal_filter\n",
    "                        net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    for ttt in range(temporal_filter):\n",
    "                                        if ttt == 0:\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            slice_concat[..., shape_temp[-1] * (ttt) : shape_temp[-1] * (ttt+1)] = slice_concat[..., shape_temp[-1] * (ttt) : shape_temp[-1] * (ttt+1)] + slice_concat[..., shape_temp[-1] * (ttt-1) : shape_temp[-1] * (ttt)]\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        if extra_train_dataset == -1:\n",
    "                            assert BATCH == 1\n",
    "                            # now_T = inputs_val.shape[1]\n",
    "                            # now_time_steps = temporal_filter*TIME\n",
    "                            # start_idx = 0\n",
    "                            # inputs_val = inputs_val[:, start_idx : start_idx + now_time_steps]\n",
    "\n",
    "                            if dvs_clipping != 0:\n",
    "                                inputs_val[inputs_val<dvs_clipping] = 0.0\n",
    "                                inputs_val[inputs_val>=dvs_clipping] = 1.0\n",
    "\n",
    "\n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                            if max_of_inf_acculmulation < outputs_all.sum(1).max().item() * (2**(-scale_exp[2][0])):\n",
    "                                max_of_inf_acculmulation = outputs_all.sum(1).max().item() * (2**(-scale_exp[2][0]))\n",
    "                                print(\"max_of_inf_acculmulation updated:\", max_of_inf_acculmulation)\n",
    "                            \n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "                \n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.6\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "# my_snn_system(  devices = \"0\",\n",
    "#                 single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "#                 BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 14, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "#                 # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "#                 lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "#                 synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 1000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 25, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 25_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "#                 # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "#                 # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "#                 merge_polarities = True, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = -1, \n",
    "\n",
    "#                 num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "#                 chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 5, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = True, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "# # 1w -11~-9\n",
    "# # 1b -11~ -7\n",
    "# # 2w -10~-8\n",
    "# # 2b -10~-8\n",
    "# # 3w -10\n",
    "# # 3b -10\n",
    "#                 test_timesteps=-2,\n",
    "#                 random_select_ratio=3,\n",
    "#                 leaky_temporal_filter = 0.5,\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# # average pooling  \n",
    "# # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e7mmg2eu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 15000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tleaky_temporal_filter: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0078125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_select_ratio: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_timesteps: -2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251113_105736-e7mmg2eu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e7mmg2eu' target=\"_blank\">peach-sweep-8</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/5y9wllw2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/5y9wllw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/5y9wllw2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/5y9wllw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e7mmg2eu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e7mmg2eu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'test_timesteps' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'random_select_ratio' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'leaky_temporal_filter' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': '20251113_105744_828', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 10, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0078125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 20, 'dvs_duration': 15000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': True, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': True, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'test_timesteps': -2, 'random_select_ratio': 3, 'leaky_temporal_filter': 0.25} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 29bd129597e48179cd5900673c4c5cb4\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=10, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0078125\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 320.0\n",
      "lif layer 1 self.abs_max_v: 320.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 175.0\n",
      "lif layer 2 self.abs_max_v: 175.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "lif layer 1 self.abs_max_v: 437.5\n",
      "fc layer 2 self.abs_max_out: 325.0\n",
      "lif layer 2 self.abs_max_v: 352.0\n",
      "fc layer 3 self.abs_max_out: 65.0\n",
      "lif layer 1 self.abs_max_v: 479.0\n",
      "fc layer 2 self.abs_max_out: 362.0\n",
      "lif layer 2 self.abs_max_v: 392.5\n",
      "fc layer 3 self.abs_max_out: 67.0\n",
      "fc layer 1 self.abs_max_out: 366.0\n",
      "lif layer 1 self.abs_max_v: 488.5\n",
      "fc layer 3 self.abs_max_out: 117.0\n",
      "fc layer 2 self.abs_max_out: 387.0\n",
      "lif layer 2 self.abs_max_v: 459.0\n",
      "fc layer 1 self.abs_max_out: 697.0\n",
      "lif layer 1 self.abs_max_v: 697.0\n",
      "fc layer 2 self.abs_max_out: 482.0\n",
      "lif layer 2 self.abs_max_v: 644.5\n",
      "fc layer 3 self.abs_max_out: 148.0\n",
      "fc layer 1 self.abs_max_out: 822.0\n",
      "lif layer 1 self.abs_max_v: 822.0\n",
      "fc layer 3 self.abs_max_out: 188.0\n",
      "lif layer 2 self.abs_max_v: 729.0\n",
      "fc layer 1 self.abs_max_out: 863.0\n",
      "lif layer 1 self.abs_max_v: 863.0\n",
      "fc layer 2 self.abs_max_out: 600.0\n",
      "lif layer 2 self.abs_max_v: 854.0\n",
      "fc layer 3 self.abs_max_out: 327.0\n",
      "fc layer 2 self.abs_max_out: 760.0\n",
      "lif layer 2 self.abs_max_v: 1062.0\n",
      "fc layer 1 self.abs_max_out: 1436.0\n",
      "lif layer 1 self.abs_max_v: 1436.0\n",
      "fc layer 2 self.abs_max_out: 801.0\n",
      "fc layer 3 self.abs_max_out: 367.0\n",
      "lif layer 2 self.abs_max_v: 1100.5\n",
      "fc layer 2 self.abs_max_out: 807.0\n",
      "lif layer 2 self.abs_max_v: 1120.5\n",
      "fc layer 1 self.abs_max_out: 1638.0\n",
      "lif layer 1 self.abs_max_v: 1690.5\n",
      "fc layer 2 self.abs_max_out: 1093.0\n",
      "lif layer 2 self.abs_max_v: 1191.5\n",
      "lif layer 2 self.abs_max_v: 1373.5\n",
      "lif layer 2 self.abs_max_v: 1443.0\n",
      "lif layer 2 self.abs_max_v: 1538.5\n",
      "lif layer 2 self.abs_max_v: 1600.5\n",
      "lif layer 2 self.abs_max_v: 1701.5\n",
      "lif layer 2 self.abs_max_v: 1708.5\n",
      "lif layer 2 self.abs_max_v: 1739.5\n",
      "fc layer 1 self.abs_max_out: 1823.0\n",
      "lif layer 1 self.abs_max_v: 1823.0\n",
      "fc layer 2 self.abs_max_out: 1138.0\n",
      "fc layer 3 self.abs_max_out: 378.0\n",
      "fc layer 3 self.abs_max_out: 424.0\n",
      "fc layer 3 self.abs_max_out: 480.0\n",
      "fc layer 3 self.abs_max_out: 481.0\n",
      "fc layer 2 self.abs_max_out: 1254.0\n",
      "fc layer 3 self.abs_max_out: 514.0\n",
      "fc layer 3 self.abs_max_out: 517.0\n",
      "fc layer 3 self.abs_max_out: 561.0\n",
      "lif layer 1 self.abs_max_v: 1845.5\n",
      "lif layer 1 self.abs_max_v: 1984.0\n",
      "fc layer 2 self.abs_max_out: 1295.0\n",
      "fc layer 2 self.abs_max_out: 1302.0\n",
      "fc layer 2 self.abs_max_out: 1377.0\n",
      "fc layer 2 self.abs_max_out: 1384.0\n",
      "fc layer 2 self.abs_max_out: 1425.0\n",
      "fc layer 2 self.abs_max_out: 1515.0\n",
      "fc layer 2 self.abs_max_out: 1619.0\n",
      "fc layer 1 self.abs_max_out: 1840.0\n",
      "lif layer 2 self.abs_max_v: 1842.0\n",
      "fc layer 1 self.abs_max_out: 2079.0\n",
      "lif layer 1 self.abs_max_v: 1999.0\n",
      "lif layer 2 self.abs_max_v: 1903.0\n",
      "fc layer 3 self.abs_max_out: 587.0\n",
      "fc layer 3 self.abs_max_out: 648.0\n",
      "fc layer 2 self.abs_max_out: 1671.0\n",
      "fc layer 2 self.abs_max_out: 2032.0\n",
      "lif layer 2 self.abs_max_v: 2032.0\n",
      "lif layer 1 self.abs_max_v: 2092.5\n",
      "lif layer 1 self.abs_max_v: 2129.5\n",
      "lif layer 1 self.abs_max_v: 2139.0\n",
      "lif layer 1 self.abs_max_v: 2174.5\n",
      "lif layer 1 self.abs_max_v: 2285.5\n",
      "fc layer 3 self.abs_max_out: 709.0\n",
      "fc layer 3 self.abs_max_out: 730.0\n",
      "lif layer 2 self.abs_max_v: 2058.5\n",
      "lif layer 2 self.abs_max_v: 2065.5\n",
      "fc layer 1 self.abs_max_out: 2124.0\n",
      "fc layer 1 self.abs_max_out: 2137.0\n",
      "lif layer 2 self.abs_max_v: 2098.5\n",
      "fc layer 3 self.abs_max_out: 786.0\n",
      "fc layer 1 self.abs_max_out: 2279.0\n",
      "lif layer 2 self.abs_max_v: 2208.5\n",
      "lif layer 2 self.abs_max_v: 2320.5\n",
      "lif layer 2 self.abs_max_v: 2406.0\n",
      "lif layer 1 self.abs_max_v: 2419.0\n",
      "lif layer 2 self.abs_max_v: 2409.5\n",
      "lif layer 2 self.abs_max_v: 2458.0\n",
      "fc layer 3 self.abs_max_out: 877.0\n",
      "fc layer 2 self.abs_max_out: 2056.0\n",
      "lif layer 2 self.abs_max_v: 2494.5\n",
      "fc layer 1 self.abs_max_out: 2379.0\n",
      "fc layer 1 self.abs_max_out: 2510.0\n",
      "lif layer 1 self.abs_max_v: 2510.0\n",
      "fc layer 1 self.abs_max_out: 2645.0\n",
      "lif layer 1 self.abs_max_v: 2645.0\n",
      "lif layer 2 self.abs_max_v: 2510.5\n",
      "fc layer 3 self.abs_max_out: 971.0\n",
      "lif layer 2 self.abs_max_v: 2533.5\n",
      "lif layer 2 self.abs_max_v: 2607.0\n",
      "lif layer 2 self.abs_max_v: 2729.5\n",
      "lif layer 1 self.abs_max_v: 2892.0\n",
      "lif layer 1 self.abs_max_v: 2952.0\n",
      "lif layer 1 self.abs_max_v: 3549.0\n",
      "lif layer 1 self.abs_max_v: 3647.5\n",
      "lif layer 1 self.abs_max_v: 3818.0\n",
      "fc layer 1 self.abs_max_out: 2701.0\n",
      "fc layer 1 self.abs_max_out: 3456.0\n",
      "lif layer 2 self.abs_max_v: 2814.0\n",
      "lif layer 2 self.abs_max_v: 2925.0\n",
      "fc layer 2 self.abs_max_out: 2108.0\n",
      "fc layer 2 self.abs_max_out: 2137.0\n",
      "fc layer 2 self.abs_max_out: 2144.0\n",
      "lif layer 1 self.abs_max_v: 4051.0\n",
      "fc layer 3 self.abs_max_out: 990.0\n",
      "fc layer 2 self.abs_max_out: 2172.0\n",
      "fc layer 2 self.abs_max_out: 2430.0\n",
      "fc layer 3 self.abs_max_out: 1007.0\n",
      "fc layer 3 self.abs_max_out: 1027.0\n",
      "lif layer 2 self.abs_max_v: 2935.5\n",
      "lif layer 2 self.abs_max_v: 2940.0\n",
      "lif layer 2 self.abs_max_v: 3321.0\n",
      "fc layer 2 self.abs_max_out: 2472.0\n",
      "lif layer 1 self.abs_max_v: 4168.5\n",
      "lif layer 1 self.abs_max_v: 4312.5\n",
      "lif layer 1 self.abs_max_v: 4399.5\n",
      "lif layer 1 self.abs_max_v: 4464.5\n",
      "lif layer 1 self.abs_max_v: 4494.0\n",
      "max_of_inf_acculmulation updated: 48374.0\n",
      "lif layer 1 self.abs_max_v: 5013.0\n",
      "lif layer 1 self.abs_max_v: 5107.5\n",
      "max_of_inf_acculmulation updated: 68782.0\n",
      "fc layer 1 self.abs_max_out: 3643.0\n",
      "lif layer 1 self.abs_max_v: 5172.0\n",
      "lif layer 2 self.abs_max_v: 3484.5\n",
      "lif layer 1 self.abs_max_v: 5196.0\n",
      "lif layer 1 self.abs_max_v: 5486.5\n",
      "lif layer 1 self.abs_max_v: 5499.5\n",
      "lif layer 1 self.abs_max_v: 5605.5\n",
      "lif layer 1 self.abs_max_v: 5633.0\n",
      "lif layer 1 self.abs_max_v: 6220.5\n",
      "lif layer 1 self.abs_max_v: 6532.5\n",
      "fc layer 1 self.abs_max_out: 3983.0\n",
      "fc layer 1 self.abs_max_out: 4255.0\n",
      "lif layer 1 self.abs_max_v: 6725.0\n",
      "lif layer 2 self.abs_max_v: 3498.5\n",
      "lif layer 2 self.abs_max_v: 3575.5\n",
      "max_of_inf_acculmulation updated: 94229.0\n",
      "epoch-0   lr=['0.0078125'], tr/val_loss:  1.598722/  1.916952, val:  39.17%, val_best:  39.17%, tr:  98.77%, tr_best:  98.77%, epoch time: 134.17 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6428%\n",
      "layer   2  Sparsity: 79.2885%\n",
      "layer   3  Sparsity: 74.9612%\n",
      "total_backward_count 9790 real_backward_count 1670  17.058%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "fc layer 2 self.abs_max_out: 2519.0\n",
      "lif layer 2 self.abs_max_v: 3647.5\n",
      "lif layer 2 self.abs_max_v: 3907.5\n",
      "lif layer 2 self.abs_max_v: 3910.5\n",
      "lif layer 2 self.abs_max_v: 4120.5\n",
      "lif layer 2 self.abs_max_v: 4125.0\n",
      "fc layer 3 self.abs_max_out: 1046.0\n",
      "fc layer 3 self.abs_max_out: 1071.0\n",
      "fc layer 3 self.abs_max_out: 1076.0\n",
      "fc layer 3 self.abs_max_out: 1084.0\n",
      "fc layer 1 self.abs_max_out: 4288.0\n",
      "lif layer 2 self.abs_max_v: 4217.5\n",
      "lif layer 2 self.abs_max_v: 4410.0\n",
      "lif layer 2 self.abs_max_v: 4465.5\n",
      "lif layer 2 self.abs_max_v: 4481.0\n",
      "fc layer 2 self.abs_max_out: 2623.0\n",
      "lif layer 2 self.abs_max_v: 4610.0\n",
      "lif layer 2 self.abs_max_v: 4671.0\n",
      "lif layer 2 self.abs_max_v: 4733.5\n",
      "lif layer 2 self.abs_max_v: 4744.5\n",
      "lif layer 2 self.abs_max_v: 4796.0\n",
      "lif layer 2 self.abs_max_v: 4882.0\n",
      "fc layer 2 self.abs_max_out: 2680.0\n",
      "lif layer 2 self.abs_max_v: 4923.0\n",
      "lif layer 1 self.abs_max_v: 7114.5\n",
      "lif layer 1 self.abs_max_v: 7721.5\n",
      "fc layer 1 self.abs_max_out: 4330.0\n",
      "lif layer 1 self.abs_max_v: 8191.0\n",
      "fc layer 1 self.abs_max_out: 4424.0\n",
      "lif layer 2 self.abs_max_v: 4937.0\n",
      "epoch-1   lr=['0.0078125'], tr/val_loss:  1.512944/  1.867489, val:  39.17%, val_best:  39.17%, tr:  99.80%, tr_best:  99.80%, epoch time: 140.45 seconds, 2.34 minutes\n",
      "layer   1  Sparsity: 93.6400%\n",
      "layer   2  Sparsity: 78.5934%\n",
      "layer   3  Sparsity: 76.7346%\n",
      "total_backward_count 19580 real_backward_count 3053  15.592%\n",
      "fc layer 2 self.abs_max_out: 2708.0\n",
      "fc layer 1 self.abs_max_out: 4519.0\n",
      "fc layer 3 self.abs_max_out: 1127.0\n",
      "fc layer 3 self.abs_max_out: 1130.0\n",
      "fc layer 3 self.abs_max_out: 1137.0\n",
      "fc layer 1 self.abs_max_out: 4540.0\n",
      "fc layer 1 self.abs_max_out: 4657.0\n",
      "fc layer 1 self.abs_max_out: 4711.0\n",
      "lif layer 1 self.abs_max_v: 8518.0\n",
      "fc layer 1 self.abs_max_out: 5000.0\n",
      "lif layer 1 self.abs_max_v: 9259.0\n",
      "fc layer 1 self.abs_max_out: 5109.0\n",
      "lif layer 1 self.abs_max_v: 9738.5\n",
      "lif layer 1 self.abs_max_v: 9791.5\n",
      "lif layer 1 self.abs_max_v: 9906.0\n",
      "fc layer 1 self.abs_max_out: 5256.0\n",
      "fc layer 1 self.abs_max_out: 5273.0\n",
      "max_of_inf_acculmulation updated: 115514.0\n",
      "fc layer 3 self.abs_max_out: 1162.0\n",
      "fc layer 3 self.abs_max_out: 1170.0\n",
      "epoch-2   lr=['0.0078125'], tr/val_loss:  1.508029/  1.859023, val:  44.58%, val_best:  44.58%, tr:  99.18%, tr_best:  99.80%, epoch time: 135.96 seconds, 2.27 minutes\n",
      "layer   1  Sparsity: 93.6404%\n",
      "layer   2  Sparsity: 78.6436%\n",
      "layer   3  Sparsity: 77.1187%\n",
      "total_backward_count 29370 real_backward_count 4408  15.009%\n",
      "fc layer 3 self.abs_max_out: 1204.0\n",
      "fc layer 2 self.abs_max_out: 2830.0\n",
      "fc layer 2 self.abs_max_out: 2842.0\n",
      "fc layer 2 self.abs_max_out: 2885.0\n",
      "fc layer 2 self.abs_max_out: 2925.0\n",
      "epoch-3   lr=['0.0078125'], tr/val_loss:  1.455998/  1.842632, val:  43.75%, val_best:  44.58%, tr:  99.69%, tr_best:  99.80%, epoch time: 137.10 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6414%\n",
      "layer   2  Sparsity: 78.5156%\n",
      "layer   3  Sparsity: 76.8828%\n",
      "total_backward_count 39160 real_backward_count 5689  14.528%\n",
      "fc layer 1 self.abs_max_out: 5351.0\n",
      "fc layer 2 self.abs_max_out: 3042.0\n",
      "fc layer 3 self.abs_max_out: 1245.0\n",
      "fc layer 3 self.abs_max_out: 1275.0\n",
      "fc layer 3 self.abs_max_out: 1364.0\n",
      "fc layer 1 self.abs_max_out: 5394.0\n",
      "fc layer 1 self.abs_max_out: 5587.0\n",
      "lif layer 1 self.abs_max_v: 10519.0\n",
      "fc layer 3 self.abs_max_out: 1404.0\n",
      "max_of_inf_acculmulation updated: 142036.0\n",
      "lif layer 2 self.abs_max_v: 5103.0\n",
      "epoch-4   lr=['0.0078125'], tr/val_loss:  1.439696/  1.815027, val:  48.33%, val_best:  48.33%, tr:  99.59%, tr_best:  99.80%, epoch time: 133.29 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 93.6419%\n",
      "layer   2  Sparsity: 78.1370%\n",
      "layer   3  Sparsity: 77.6336%\n",
      "total_backward_count 48950 real_backward_count 6978  14.255%\n",
      "fc layer 1 self.abs_max_out: 6001.0\n",
      "lif layer 1 self.abs_max_v: 10759.0\n",
      "lif layer 1 self.abs_max_v: 10980.5\n",
      "lif layer 1 self.abs_max_v: 11081.5\n",
      "lif layer 1 self.abs_max_v: 11122.0\n",
      "fc layer 1 self.abs_max_out: 6211.0\n",
      "lif layer 1 self.abs_max_v: 11464.0\n",
      "fc layer 2 self.abs_max_out: 3110.0\n",
      "fc layer 2 self.abs_max_out: 3184.0\n",
      "fc layer 2 self.abs_max_out: 3188.0\n",
      "fc layer 2 self.abs_max_out: 3195.0\n",
      "lif layer 2 self.abs_max_v: 5174.5\n",
      "fc layer 2 self.abs_max_out: 3202.0\n",
      "fc layer 2 self.abs_max_out: 3251.0\n",
      "epoch-5   lr=['0.0078125'], tr/val_loss:  1.419794/  1.802924, val:  50.42%, val_best:  50.42%, tr:  99.80%, tr_best:  99.80%, epoch time: 135.32 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6374%\n",
      "layer   2  Sparsity: 77.8974%\n",
      "layer   3  Sparsity: 77.5365%\n",
      "total_backward_count 58740 real_backward_count 8274  14.086%\n",
      "fc layer 1 self.abs_max_out: 6220.0\n",
      "fc layer 3 self.abs_max_out: 1410.0\n",
      "fc layer 2 self.abs_max_out: 3309.0\n",
      "lif layer 1 self.abs_max_v: 11514.0\n",
      "fc layer 1 self.abs_max_out: 6222.0\n",
      "fc layer 1 self.abs_max_out: 6243.0\n",
      "lif layer 1 self.abs_max_v: 11547.0\n",
      "fc layer 1 self.abs_max_out: 6318.0\n",
      "lif layer 1 self.abs_max_v: 11783.0\n",
      "lif layer 2 self.abs_max_v: 5414.0\n",
      "epoch-6   lr=['0.0078125'], tr/val_loss:  1.364702/  1.777817, val:  46.67%, val_best:  50.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 138.80 seconds, 2.31 minutes\n",
      "layer   1  Sparsity: 93.6443%\n",
      "layer   2  Sparsity: 78.6753%\n",
      "layer   3  Sparsity: 76.2534%\n",
      "total_backward_count 68530 real_backward_count 9551  13.937%\n",
      "fc layer 3 self.abs_max_out: 1425.0\n",
      "fc layer 1 self.abs_max_out: 6614.0\n",
      "fc layer 2 self.abs_max_out: 3338.0\n",
      "epoch-7   lr=['0.0078125'], tr/val_loss:  1.343106/  1.768799, val:  45.00%, val_best:  50.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 135.40 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6350%\n",
      "layer   2  Sparsity: 78.9536%\n",
      "layer   3  Sparsity: 77.6252%\n",
      "total_backward_count 78320 real_backward_count 10741  13.714%\n",
      "lif layer 1 self.abs_max_v: 11887.5\n",
      "lif layer 1 self.abs_max_v: 12096.5\n",
      "lif layer 1 self.abs_max_v: 12441.5\n",
      "fc layer 2 self.abs_max_out: 3405.0\n",
      "fc layer 2 self.abs_max_out: 3475.0\n",
      "epoch-8   lr=['0.0078125'], tr/val_loss:  1.375438/  1.748261, val:  46.25%, val_best:  50.42%, tr:  99.69%, tr_best: 100.00%, epoch time: 134.94 seconds, 2.25 minutes\n",
      "layer   1  Sparsity: 93.6403%\n",
      "layer   2  Sparsity: 79.1249%\n",
      "layer   3  Sparsity: 78.1944%\n",
      "total_backward_count 88110 real_backward_count 12005  13.625%\n",
      "fc layer 1 self.abs_max_out: 6929.0\n",
      "lif layer 1 self.abs_max_v: 12777.0\n",
      "lif layer 1 self.abs_max_v: 13118.5\n",
      "lif layer 1 self.abs_max_v: 13436.5\n",
      "epoch-9   lr=['0.0078125'], tr/val_loss:  1.362668/  1.799861, val:  48.75%, val_best:  50.42%, tr:  99.49%, tr_best: 100.00%, epoch time: 134.52 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6403%\n",
      "layer   2  Sparsity: 79.3762%\n",
      "layer   3  Sparsity: 78.8424%\n",
      "total_backward_count 97900 real_backward_count 13245  13.529%\n",
      "lif layer 2 self.abs_max_v: 5453.0\n",
      "lif layer 2 self.abs_max_v: 5761.0\n",
      "lif layer 2 self.abs_max_v: 5830.0\n",
      "lif layer 2 self.abs_max_v: 5998.0\n",
      "fc layer 3 self.abs_max_out: 1438.0\n",
      "lif layer 2 self.abs_max_v: 6096.5\n",
      "lif layer 2 self.abs_max_v: 6158.5\n",
      "lif layer 2 self.abs_max_v: 6264.0\n",
      "lif layer 2 self.abs_max_v: 6272.0\n",
      "epoch-10  lr=['0.0078125'], tr/val_loss:  1.340516/  1.778434, val:  45.42%, val_best:  50.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 135.36 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6406%\n",
      "layer   2  Sparsity: 79.0301%\n",
      "layer   3  Sparsity: 78.5688%\n",
      "total_backward_count 107690 real_backward_count 14457  13.425%\n",
      "lif layer 2 self.abs_max_v: 6383.5\n",
      "fc layer 1 self.abs_max_out: 6964.0\n",
      "fc layer 1 self.abs_max_out: 6969.0\n",
      "epoch-11  lr=['0.0078125'], tr/val_loss:  1.351423/  1.720171, val:  49.17%, val_best:  50.42%, tr:  99.69%, tr_best: 100.00%, epoch time: 138.83 seconds, 2.31 minutes\n",
      "layer   1  Sparsity: 93.6446%\n",
      "layer   2  Sparsity: 78.6410%\n",
      "layer   3  Sparsity: 78.6364%\n",
      "total_backward_count 117480 real_backward_count 15655  13.326%\n",
      "lif layer 2 self.abs_max_v: 6417.0\n",
      "fc layer 2 self.abs_max_out: 3534.0\n",
      "lif layer 2 self.abs_max_v: 6418.0\n",
      "lif layer 2 self.abs_max_v: 6698.5\n",
      "fc layer 2 self.abs_max_out: 3548.0\n",
      "fc layer 2 self.abs_max_out: 3582.0\n",
      "fc layer 1 self.abs_max_out: 7326.0\n",
      "lif layer 1 self.abs_max_v: 13536.5\n",
      "lif layer 1 self.abs_max_v: 13669.0\n",
      "epoch-12  lr=['0.0078125'], tr/val_loss:  1.325480/  1.745366, val:  43.75%, val_best:  50.42%, tr:  99.69%, tr_best: 100.00%, epoch time: 136.12 seconds, 2.27 minutes\n",
      "layer   1  Sparsity: 93.6409%\n",
      "layer   2  Sparsity: 78.6914%\n",
      "layer   3  Sparsity: 78.6176%\n",
      "total_backward_count 127270 real_backward_count 16854  13.243%\n",
      "fc layer 2 self.abs_max_out: 3588.0\n",
      "lif layer 2 self.abs_max_v: 6824.5\n",
      "fc layer 2 self.abs_max_out: 3668.0\n",
      "fc layer 2 self.abs_max_out: 3746.0\n",
      "lif layer 2 self.abs_max_v: 6848.0\n",
      "epoch-13  lr=['0.0078125'], tr/val_loss:  1.319537/  1.779826, val:  45.42%, val_best:  50.42%, tr:  99.18%, tr_best: 100.00%, epoch time: 137.53 seconds, 2.29 minutes\n",
      "layer   1  Sparsity: 93.6391%\n",
      "layer   2  Sparsity: 78.5436%\n",
      "layer   3  Sparsity: 79.1139%\n",
      "total_backward_count 137060 real_backward_count 18104  13.209%\n",
      "fc layer 2 self.abs_max_out: 3756.0\n",
      "lif layer 2 self.abs_max_v: 6930.5\n",
      "fc layer 1 self.abs_max_out: 7506.0\n",
      "epoch-14  lr=['0.0078125'], tr/val_loss:  1.355926/  1.714455, val:  50.00%, val_best:  50.42%, tr:  99.39%, tr_best: 100.00%, epoch time: 136.99 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6414%\n",
      "layer   2  Sparsity: 79.1657%\n",
      "layer   3  Sparsity: 79.5682%\n",
      "total_backward_count 146850 real_backward_count 19273  13.124%\n",
      "lif layer 2 self.abs_max_v: 7112.5\n",
      "fc layer 2 self.abs_max_out: 3763.0\n",
      "lif layer 2 self.abs_max_v: 7140.5\n",
      "fc layer 2 self.abs_max_out: 4009.0\n",
      "fc layer 1 self.abs_max_out: 7835.0\n",
      "lif layer 1 self.abs_max_v: 14128.0\n",
      "lif layer 1 self.abs_max_v: 14183.0\n",
      "lif layer 1 self.abs_max_v: 14355.5\n",
      "fc layer 1 self.abs_max_out: 7935.0\n",
      "lif layer 1 self.abs_max_v: 14391.5\n",
      "lif layer 1 self.abs_max_v: 14401.0\n",
      "epoch-15  lr=['0.0078125'], tr/val_loss:  1.349836/  1.758637, val:  47.50%, val_best:  50.42%, tr:  99.69%, tr_best: 100.00%, epoch time: 138.30 seconds, 2.31 minutes\n",
      "layer   1  Sparsity: 93.6394%\n",
      "layer   2  Sparsity: 79.6038%\n",
      "layer   3  Sparsity: 79.0951%\n",
      "total_backward_count 156640 real_backward_count 20460  13.062%\n",
      "lif layer 1 self.abs_max_v: 14528.0\n",
      "lif layer 1 self.abs_max_v: 14718.0\n",
      "lif layer 1 self.abs_max_v: 14909.0\n",
      "epoch-16  lr=['0.0078125'], tr/val_loss:  1.362448/  1.733105, val:  54.58%, val_best:  54.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 138.09 seconds, 2.30 minutes\n",
      "layer   1  Sparsity: 93.6396%\n",
      "layer   2  Sparsity: 79.5970%\n",
      "layer   3  Sparsity: 80.3291%\n",
      "total_backward_count 166430 real_backward_count 21667  13.019%\n",
      "fc layer 1 self.abs_max_out: 8010.0\n",
      "lif layer 1 self.abs_max_v: 15231.5\n",
      "epoch-17  lr=['0.0078125'], tr/val_loss:  1.404400/  1.720182, val:  60.00%, val_best:  60.00%, tr:  99.80%, tr_best: 100.00%, epoch time: 131.97 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 93.6425%\n",
      "layer   2  Sparsity: 78.8001%\n",
      "layer   3  Sparsity: 81.8439%\n",
      "total_backward_count 176220 real_backward_count 22920  13.006%\n",
      "fc layer 1 self.abs_max_out: 9092.0\n",
      "lif layer 1 self.abs_max_v: 16296.5\n",
      "lif layer 1 self.abs_max_v: 16704.5\n",
      "epoch-18  lr=['0.0078125'], tr/val_loss:  1.390821/  1.734051, val:  47.50%, val_best:  60.00%, tr:  99.90%, tr_best: 100.00%, epoch time: 140.36 seconds, 2.34 minutes\n",
      "layer   1  Sparsity: 93.6443%\n",
      "layer   2  Sparsity: 78.0813%\n",
      "layer   3  Sparsity: 81.1076%\n",
      "total_backward_count 186010 real_backward_count 24160  12.989%\n",
      "epoch-19  lr=['0.0078125'], tr/val_loss:  1.390894/  1.801773, val:  42.08%, val_best:  60.00%, tr:  99.90%, tr_best: 100.00%, epoch time: 135.53 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6397%\n",
      "layer   2  Sparsity: 78.9480%\n",
      "layer   3  Sparsity: 81.5513%\n",
      "total_backward_count 195800 real_backward_count 25352  12.948%\n",
      "fc layer 1 self.abs_max_out: 9141.0\n",
      "epoch-20  lr=['0.0078125'], tr/val_loss:  1.373738/  1.795268, val:  40.42%, val_best:  60.00%, tr:  99.69%, tr_best: 100.00%, epoch time: 141.62 seconds, 2.36 minutes\n",
      "layer   1  Sparsity: 93.6452%\n",
      "layer   2  Sparsity: 78.5993%\n",
      "layer   3  Sparsity: 81.0940%\n",
      "total_backward_count 205590 real_backward_count 26513  12.896%\n",
      "fc layer 1 self.abs_max_out: 9307.0\n",
      "lif layer 1 self.abs_max_v: 17224.0\n",
      "lif layer 1 self.abs_max_v: 17233.5\n",
      "epoch-21  lr=['0.0078125'], tr/val_loss:  1.390617/  1.738115, val:  47.92%, val_best:  60.00%, tr:  99.90%, tr_best: 100.00%, epoch time: 133.81 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 93.6382%\n",
      "layer   2  Sparsity: 78.8868%\n",
      "layer   3  Sparsity: 80.4338%\n",
      "total_backward_count 215380 real_backward_count 27743  12.881%\n",
      "epoch-22  lr=['0.0078125'], tr/val_loss:  1.399838/  1.714338, val:  57.92%, val_best:  60.00%, tr:  99.69%, tr_best: 100.00%, epoch time: 138.91 seconds, 2.32 minutes\n",
      "layer   1  Sparsity: 93.6384%\n",
      "layer   2  Sparsity: 78.6669%\n",
      "layer   3  Sparsity: 81.9349%\n",
      "total_backward_count 225170 real_backward_count 28992  12.876%\n",
      "fc layer 1 self.abs_max_out: 9377.0\n",
      "epoch-23  lr=['0.0078125'], tr/val_loss:  1.412849/  1.753023, val:  53.33%, val_best:  60.00%, tr:  99.80%, tr_best: 100.00%, epoch time: 138.72 seconds, 2.31 minutes\n",
      "layer   1  Sparsity: 93.6412%\n",
      "layer   2  Sparsity: 78.7601%\n",
      "layer   3  Sparsity: 81.8908%\n",
      "total_backward_count 234960 real_backward_count 30239  12.870%\n",
      "fc layer 1 self.abs_max_out: 10008.0\n",
      "lif layer 1 self.abs_max_v: 17809.5\n",
      "lif layer 1 self.abs_max_v: 18207.0\n",
      "epoch-24  lr=['0.0078125'], tr/val_loss:  1.412991/  1.749583, val:  47.08%, val_best:  60.00%, tr:  99.59%, tr_best: 100.00%, epoch time: 135.35 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6390%\n",
      "layer   2  Sparsity: 78.8955%\n",
      "layer   3  Sparsity: 80.1227%\n",
      "total_backward_count 244750 real_backward_count 31429  12.841%\n",
      "max_of_inf_acculmulation updated: 144787.0\n",
      "epoch-25  lr=['0.0078125'], tr/val_loss:  1.421049/  1.753062, val:  53.33%, val_best:  60.00%, tr:  99.80%, tr_best: 100.00%, epoch time: 140.43 seconds, 2.34 minutes\n",
      "layer   1  Sparsity: 93.6373%\n",
      "layer   2  Sparsity: 79.2957%\n",
      "layer   3  Sparsity: 81.8441%\n",
      "total_backward_count 254540 real_backward_count 32661  12.831%\n",
      "epoch-26  lr=['0.0078125'], tr/val_loss:  1.409014/  1.727454, val:  57.50%, val_best:  60.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 135.66 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6362%\n",
      "layer   2  Sparsity: 78.7805%\n",
      "layer   3  Sparsity: 81.3613%\n",
      "total_backward_count 264330 real_backward_count 33873  12.815%\n",
      "epoch-27  lr=['0.0078125'], tr/val_loss:  1.407833/  1.740445, val:  56.67%, val_best:  60.00%, tr:  99.49%, tr_best: 100.00%, epoch time: 137.11 seconds, 2.29 minutes\n",
      "layer   1  Sparsity: 93.6412%\n",
      "layer   2  Sparsity: 78.9200%\n",
      "layer   3  Sparsity: 82.1675%\n",
      "total_backward_count 274120 real_backward_count 35077  12.796%\n",
      "epoch-28  lr=['0.0078125'], tr/val_loss:  1.384987/  1.780247, val:  49.17%, val_best:  60.00%, tr:  99.90%, tr_best: 100.00%, epoch time: 134.76 seconds, 2.25 minutes\n",
      "layer   1  Sparsity: 93.6417%\n",
      "layer   2  Sparsity: 79.2862%\n",
      "layer   3  Sparsity: 82.9475%\n",
      "total_backward_count 283910 real_backward_count 36229  12.761%\n",
      "lif layer 2 self.abs_max_v: 7180.5\n",
      "lif layer 2 self.abs_max_v: 7186.5\n",
      "lif layer 2 self.abs_max_v: 7331.0\n",
      "lif layer 1 self.abs_max_v: 18318.0\n",
      "epoch-29  lr=['0.0078125'], tr/val_loss:  1.423092/  1.746869, val:  48.75%, val_best:  60.00%, tr:  99.49%, tr_best: 100.00%, epoch time: 136.11 seconds, 2.27 minutes\n",
      "layer   1  Sparsity: 93.6409%\n",
      "layer   2  Sparsity: 79.1702%\n",
      "layer   3  Sparsity: 82.4895%\n",
      "total_backward_count 293700 real_backward_count 37389  12.730%\n",
      "fc layer 3 self.abs_max_out: 1471.0\n",
      "epoch-30  lr=['0.0078125'], tr/val_loss:  1.403867/  1.745702, val:  57.08%, val_best:  60.00%, tr:  99.90%, tr_best: 100.00%, epoch time: 134.35 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6413%\n",
      "layer   2  Sparsity: 79.0453%\n",
      "layer   3  Sparsity: 81.7155%\n",
      "total_backward_count 303490 real_backward_count 38579  12.712%\n",
      "epoch-31  lr=['0.0078125'], tr/val_loss:  1.418256/  1.746915, val:  47.08%, val_best:  60.00%, tr:  99.18%, tr_best: 100.00%, epoch time: 135.51 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6384%\n",
      "layer   2  Sparsity: 79.1092%\n",
      "layer   3  Sparsity: 81.5606%\n",
      "total_backward_count 313280 real_backward_count 39796  12.703%\n",
      "epoch-32  lr=['0.0078125'], tr/val_loss:  1.427052/  1.753963, val:  53.75%, val_best:  60.00%, tr:  99.80%, tr_best: 100.00%, epoch time: 134.20 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6421%\n",
      "layer   2  Sparsity: 79.2884%\n",
      "layer   3  Sparsity: 82.1344%\n",
      "total_backward_count 323070 real_backward_count 40973  12.682%\n",
      "epoch-33  lr=['0.0078125'], tr/val_loss:  1.444059/  1.756787, val:  51.67%, val_best:  60.00%, tr:  99.59%, tr_best: 100.00%, epoch time: 134.58 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6406%\n",
      "layer   2  Sparsity: 79.0016%\n",
      "layer   3  Sparsity: 81.8468%\n",
      "total_backward_count 332860 real_backward_count 42210  12.681%\n",
      "epoch-34  lr=['0.0078125'], tr/val_loss:  1.427385/  1.810875, val:  39.58%, val_best:  60.00%, tr:  99.80%, tr_best: 100.00%, epoch time: 134.75 seconds, 2.25 minutes\n",
      "layer   1  Sparsity: 93.6449%\n",
      "layer   2  Sparsity: 78.8422%\n",
      "layer   3  Sparsity: 82.6394%\n",
      "total_backward_count 342650 real_backward_count 43411  12.669%\n",
      "epoch-35  lr=['0.0078125'], tr/val_loss:  1.398710/  1.697223, val:  55.83%, val_best:  60.00%, tr:  99.49%, tr_best: 100.00%, epoch time: 136.92 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6403%\n",
      "layer   2  Sparsity: 79.0073%\n",
      "layer   3  Sparsity: 82.0182%\n",
      "total_backward_count 352440 real_backward_count 44600  12.655%\n",
      "epoch-36  lr=['0.0078125'], tr/val_loss:  1.390065/  1.688757, val:  62.50%, val_best:  62.50%, tr:  99.80%, tr_best: 100.00%, epoch time: 136.82 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6417%\n",
      "layer   2  Sparsity: 78.4207%\n",
      "layer   3  Sparsity: 81.7304%\n",
      "total_backward_count 362230 real_backward_count 45738  12.627%\n",
      "epoch-37  lr=['0.0078125'], tr/val_loss:  1.367865/  1.676036, val:  59.17%, val_best:  62.50%, tr:  99.90%, tr_best: 100.00%, epoch time: 136.27 seconds, 2.27 minutes\n",
      "layer   1  Sparsity: 93.6437%\n",
      "layer   2  Sparsity: 79.4077%\n",
      "layer   3  Sparsity: 82.2163%\n",
      "total_backward_count 372020 real_backward_count 46833  12.589%\n",
      "fc layer 3 self.abs_max_out: 1476.0\n",
      "epoch-38  lr=['0.0078125'], tr/val_loss:  1.388604/  1.743701, val:  53.33%, val_best:  62.50%, tr:  99.59%, tr_best: 100.00%, epoch time: 134.77 seconds, 2.25 minutes\n",
      "layer   1  Sparsity: 93.6411%\n",
      "layer   2  Sparsity: 79.5362%\n",
      "layer   3  Sparsity: 82.9774%\n",
      "total_backward_count 381810 real_backward_count 48029  12.579%\n",
      "epoch-39  lr=['0.0078125'], tr/val_loss:  1.402473/  1.745526, val:  51.25%, val_best:  62.50%, tr:  99.59%, tr_best: 100.00%, epoch time: 138.11 seconds, 2.30 minutes\n",
      "layer   1  Sparsity: 93.6454%\n",
      "layer   2  Sparsity: 79.3478%\n",
      "layer   3  Sparsity: 82.9139%\n",
      "total_backward_count 391600 real_backward_count 49195  12.563%\n",
      "epoch-40  lr=['0.0078125'], tr/val_loss:  1.438574/  1.745177, val:  57.92%, val_best:  62.50%, tr:  99.69%, tr_best: 100.00%, epoch time: 134.60 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6363%\n",
      "layer   2  Sparsity: 79.1025%\n",
      "layer   3  Sparsity: 83.3970%\n",
      "total_backward_count 401390 real_backward_count 50363  12.547%\n",
      "epoch-41  lr=['0.0078125'], tr/val_loss:  1.437638/  1.754246, val:  57.08%, val_best:  62.50%, tr:  99.90%, tr_best: 100.00%, epoch time: 135.70 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6411%\n",
      "layer   2  Sparsity: 79.3827%\n",
      "layer   3  Sparsity: 83.4177%\n",
      "total_backward_count 411180 real_backward_count 51514  12.528%\n",
      "epoch-42  lr=['0.0078125'], tr/val_loss:  1.417091/  1.730472, val:  61.25%, val_best:  62.50%, tr:  99.69%, tr_best: 100.00%, epoch time: 137.12 seconds, 2.29 minutes\n",
      "layer   1  Sparsity: 93.6452%\n",
      "layer   2  Sparsity: 79.0244%\n",
      "layer   3  Sparsity: 83.1705%\n",
      "total_backward_count 420970 real_backward_count 52639  12.504%\n",
      "epoch-43  lr=['0.0078125'], tr/val_loss:  1.417873/  1.741008, val:  62.92%, val_best:  62.92%, tr:  99.69%, tr_best: 100.00%, epoch time: 135.67 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6416%\n",
      "layer   2  Sparsity: 79.1610%\n",
      "layer   3  Sparsity: 83.4871%\n",
      "total_backward_count 430760 real_backward_count 53801  12.490%\n",
      "epoch-44  lr=['0.0078125'], tr/val_loss:  1.402800/  1.680292, val:  61.67%, val_best:  62.92%, tr:  99.80%, tr_best: 100.00%, epoch time: 138.41 seconds, 2.31 minutes\n",
      "layer   1  Sparsity: 93.6380%\n",
      "layer   2  Sparsity: 79.2134%\n",
      "layer   3  Sparsity: 82.2386%\n",
      "total_backward_count 440550 real_backward_count 54975  12.479%\n",
      "epoch-45  lr=['0.0078125'], tr/val_loss:  1.372566/  1.698050, val:  57.50%, val_best:  62.92%, tr:  99.69%, tr_best: 100.00%, epoch time: 133.29 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 93.6430%\n",
      "layer   2  Sparsity: 79.1224%\n",
      "layer   3  Sparsity: 83.4435%\n",
      "total_backward_count 450340 real_backward_count 56145  12.467%\n",
      "epoch-46  lr=['0.0078125'], tr/val_loss:  1.405421/  1.705099, val:  60.00%, val_best:  62.92%, tr:  99.80%, tr_best: 100.00%, epoch time: 144.80 seconds, 2.41 minutes\n",
      "layer   1  Sparsity: 93.6410%\n",
      "layer   2  Sparsity: 78.7778%\n",
      "layer   3  Sparsity: 84.0571%\n",
      "total_backward_count 460130 real_backward_count 57332  12.460%\n",
      "lif layer 1 self.abs_max_v: 18727.0\n",
      "lif layer 1 self.abs_max_v: 18817.5\n",
      "epoch-47  lr=['0.0078125'], tr/val_loss:  1.406346/  1.770313, val:  45.42%, val_best:  62.92%, tr:  99.80%, tr_best: 100.00%, epoch time: 133.05 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 93.6462%\n",
      "layer   2  Sparsity: 78.5585%\n",
      "layer   3  Sparsity: 84.0061%\n",
      "total_backward_count 469920 real_backward_count 58506  12.450%\n",
      "epoch-48  lr=['0.0078125'], tr/val_loss:  1.410632/  1.780337, val:  50.42%, val_best:  62.92%, tr:  99.90%, tr_best: 100.00%, epoch time: 136.51 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6399%\n",
      "layer   2  Sparsity: 79.5663%\n",
      "layer   3  Sparsity: 83.8616%\n",
      "total_backward_count 479710 real_backward_count 59679  12.441%\n",
      "epoch-49  lr=['0.0078125'], tr/val_loss:  1.390737/  1.674004, val:  65.83%, val_best:  65.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 135.19 seconds, 2.25 minutes\n",
      "layer   1  Sparsity: 93.6398%\n",
      "layer   2  Sparsity: 79.4934%\n",
      "layer   3  Sparsity: 82.8137%\n",
      "total_backward_count 489500 real_backward_count 60806  12.422%\n",
      "epoch-50  lr=['0.0078125'], tr/val_loss:  1.372030/  1.718412, val:  60.00%, val_best:  65.83%, tr:  99.69%, tr_best: 100.00%, epoch time: 137.03 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6386%\n",
      "layer   2  Sparsity: 79.2531%\n",
      "layer   3  Sparsity: 82.7672%\n",
      "total_backward_count 499290 real_backward_count 61966  12.411%\n",
      "epoch-51  lr=['0.0078125'], tr/val_loss:  1.378484/  1.715179, val:  49.58%, val_best:  65.83%, tr:  99.49%, tr_best: 100.00%, epoch time: 135.89 seconds, 2.26 minutes\n",
      "layer   1  Sparsity: 93.6354%\n",
      "layer   2  Sparsity: 79.3259%\n",
      "layer   3  Sparsity: 81.6278%\n",
      "total_backward_count 509080 real_backward_count 63112  12.397%\n",
      "epoch-52  lr=['0.0078125'], tr/val_loss:  1.333431/  1.650882, val:  57.50%, val_best:  65.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 133.30 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 93.6387%\n",
      "layer   2  Sparsity: 78.9064%\n",
      "layer   3  Sparsity: 81.9070%\n",
      "total_backward_count 518870 real_backward_count 64257  12.384%\n",
      "fc layer 1 self.abs_max_out: 10502.0\n",
      "lif layer 1 self.abs_max_v: 19752.0\n",
      "lif layer 1 self.abs_max_v: 19905.0\n",
      "epoch-53  lr=['0.0078125'], tr/val_loss:  1.296852/  1.669613, val:  61.25%, val_best:  65.83%, tr:  99.39%, tr_best: 100.00%, epoch time: 136.88 seconds, 2.28 minutes\n",
      "layer   1  Sparsity: 93.6382%\n",
      "layer   2  Sparsity: 79.3267%\n",
      "layer   3  Sparsity: 82.0034%\n",
      "total_backward_count 528660 real_backward_count 65401  12.371%\n",
      "fc layer 3 self.abs_max_out: 1489.0\n",
      "fc layer 3 self.abs_max_out: 1520.0\n",
      "epoch-54  lr=['0.0078125'], tr/val_loss:  1.342951/  1.657312, val:  57.50%, val_best:  65.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 132.53 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 93.6422%\n",
      "layer   2  Sparsity: 79.5495%\n",
      "layer   3  Sparsity: 81.3598%\n",
      "total_backward_count 538450 real_backward_count 66559  12.361%\n",
      "epoch-55  lr=['0.0078125'], tr/val_loss:  1.317105/  1.657833, val:  60.83%, val_best:  65.83%, tr:  99.80%, tr_best: 100.00%, epoch time: 134.24 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 93.6420%\n",
      "layer   2  Sparsity: 79.3254%\n",
      "layer   3  Sparsity: 81.2264%\n",
      "total_backward_count 548240 real_backward_count 67707  12.350%\n",
      "fc layer 3 self.abs_max_out: 1541.0\n",
      "fc layer 3 self.abs_max_out: 1572.0\n",
      "fc layer 3 self.abs_max_out: 1577.0\n",
      "fc layer 3 self.abs_max_out: 1608.0\n",
      "fc layer 3 self.abs_max_out: 1632.0\n",
      "max_of_inf_acculmulation updated: 154174.0\n",
      "epoch-56  lr=['0.0078125'], tr/val_loss:  1.290902/  1.687998, val:  57.08%, val_best:  65.83%, tr:  99.80%, tr_best: 100.00%, epoch time: 136.12 seconds, 2.27 minutes\n",
      "layer   1  Sparsity: 93.6438%\n",
      "layer   2  Sparsity: 79.2838%\n",
      "layer   3  Sparsity: 80.6922%\n",
      "total_backward_count 558030 real_backward_count 68851  12.338%\n",
      "fc layer 1 self.abs_max_out: 10566.0\n",
      "epoch-57  lr=['0.0078125'], tr/val_loss:  1.273687/  1.640630, val:  55.83%, val_best:  65.83%, tr:  99.69%, tr_best: 100.00%, epoch time: 131.95 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 93.6410%\n",
      "layer   2  Sparsity: 78.8673%\n",
      "layer   3  Sparsity: 80.4611%\n",
      "total_backward_count 567820 real_backward_count 69973  12.323%\n"
     ]
    }
   ],
   "source": [
    "# sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        # \"my_seed\": {\"min\": 1, \"max\": 42000},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [2.0, 1.0, 0.5, 0.25, 0.125, 0.0625]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [2, 4, 6, 8, 10]},\n",
    "        # \"lif_layer_sg_width\": {\"values\": [3.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1/128, 1/256, 1/512, 1/1024]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [5, 10, 15, 20, 25, 30]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [5000, 15000, 25_000]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [True]},\n",
    "        \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [-1]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [True]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [5]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [True]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [-11,-10,-9]},\n",
    "        # \"scale_exp_1w\": {\"values\": [-10]},\n",
    "        # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "        # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "        # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "        # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "        # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "        \"test_timesteps\": {\"values\": [-2]},\n",
    "        \"random_select_ratio\": {\"values\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]},\n",
    "        \"leaky_temporal_filter\": {\"values\": [0.25, 0.5, 1.0]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"0\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w + 1,wandb.config.scale_exp_1w + 1]],\n",
    "        test_timesteps  =  wandb.config.test_timesteps,\n",
    "        random_select_ratio  =  wandb.config.random_select_ratio,\n",
    "        leaky_temporal_filter  =  wandb.config.leaky_temporal_filter,\n",
    "                        ) \n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling\n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = '5y9wllw2'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
