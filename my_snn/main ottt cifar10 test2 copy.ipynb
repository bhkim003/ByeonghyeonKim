{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48513/2361114005.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    \n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4) # NDA\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name = f'result_save/{base_name}_hyperparameters.json_{unique_name}'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name, iter_acc_array)\n",
    "            # np.save(val_acc_file_name, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters.json_{unique_name}', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==================================================\n",
      "My Num of PARAMS: 9,302,410, system's param_num : 9,305,162\n",
      "Memory: 35.49MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 46.25%, lr=['0.0001'], iter_loss: 0.2484496682882309, val_acc: 45.46%: 100%|██████████| 391/391 [09:48<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 588.7657201290131 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 43.75%, lr=['9.999725846827562e-05'], iter_loss: 0.24541953206062317, val_acc: 54.21%: 100%|██████████| 391/391 [09:41<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 581.7353081703186 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 53.75%, lr=['9.998903417374228e-05'], iter_loss: 0.22589871287345886, val_acc: 59.50%: 100%|██████████| 391/391 [09:32<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 572.7447073459625 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 57.50%, lr=['9.997532801828658e-05'], iter_loss: 0.19511249661445618, val_acc: 61.40%: 100%|██████████| 391/391 [09:57<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 597.1876242160797 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 55.00%, lr=['9.995614150494293e-05'], iter_loss: 0.21415650844573975, val_acc: 64.04%: 100%|██████████| 391/391 [10:28<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 628.8364593982697 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-99/391 iter_acc: 64.06%, lr=['9.99314767377287e-05'], iter_loss: 0.19125041365623474, val_acc: 64.04%:  26%|██▌       | 100/391 [02:18<06:40,  1.38s/it]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'mainotttcifar10_3' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "my_snn_system(  devices = \"6\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = False, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.0001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'Adam', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename='hyperparameters.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch.spikevision import spikedata\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# root, train=True, transform=None, target_transform=None, download_and_create=True, num_steps=1000, ds=1, dt=1000)\n",
    "train_ds = spikedata.SHD(\"/data2/Heidelberg\", train=True)\n",
    "test_ds = spikedata.SHD(\"/data2/Heidelberg\", train=False)\n",
    "\n",
    "# create dataloaders\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=64) # 8156x2x1000x700\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=64) # 2264x2x1000x700\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "\n",
    "# choose a random sample\n",
    "n = 6295\n",
    "\n",
    "# initialize figure and axes\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# use spikeplot to generate a raster\n",
    "splt.raster(train_dl.dataset[n][0], ax, s=1.5, c=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
