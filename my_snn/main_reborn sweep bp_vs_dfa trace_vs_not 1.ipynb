{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17549/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True and trace_on == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # True # False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.720291189014991,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 3.555718888923306, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = ['M', 'M', 200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.0001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 10000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 5, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "#                 # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = False, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 0, \n",
    "\n",
    "#                 num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "#                 chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = True, # True # False \n",
    "\n",
    "#                 last_lif = False,\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    "\n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kg0aow58 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_225259-kg0aow58</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kg0aow58' target=\"_blank\">sweepy-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kg0aow58' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kg0aow58</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.300316/  2.290214, val:  16.25%, val_best:  16.25%, tr:  11.95%, tr_best:  11.95%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.281796/  2.274030, val:  22.92%, val_best:  22.92%, tr:  20.43%, tr_best:  20.43%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.258851/  2.251652, val:  26.67%, val_best:  26.67%, tr:  23.39%, tr_best:  23.39%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.223936/  2.219326, val:  27.50%, val_best:  27.50%, tr:  26.05%, tr_best:  26.05%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.176919/  2.176255, val:  31.25%, val_best:  31.25%, tr:  28.60%, tr_best:  28.60%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.118258/  2.122498, val:  32.08%, val_best:  32.08%, tr:  31.66%, tr_best:  31.66%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.051328/  2.060135, val:  36.25%, val_best:  36.25%, tr:  38.00%, tr_best:  38.00%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.968034/  1.998424, val:  40.42%, val_best:  40.42%, tr:  42.90%, tr_best:  42.90%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.893825/  1.931145, val:  45.42%, val_best:  45.42%, tr:  46.17%, tr_best:  46.17%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.814518/  1.869427, val:  50.00%, val_best:  50.00%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.748252/  1.816124, val:  52.92%, val_best:  52.92%, tr:  53.83%, tr_best:  53.83%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.694107/  1.771706, val:  54.58%, val_best:  54.58%, tr:  54.65%, tr_best:  54.65%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.643268/  1.737977, val:  51.67%, val_best:  54.58%, tr:  55.77%, tr_best:  55.77%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.600027/  1.706185, val:  52.92%, val_best:  54.58%, tr:  58.32%, tr_best:  58.32%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.556495/  1.674912, val:  53.75%, val_best:  54.58%, tr:  58.02%, tr_best:  58.32%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.517726/  1.655512, val:  54.58%, val_best:  54.58%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.490080/  1.629471, val:  57.92%, val_best:  57.92%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.462672/  1.615641, val:  61.67%, val_best:  61.67%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.433279/  1.598706, val:  59.58%, val_best:  61.67%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.408577/  1.588662, val:  60.00%, val_best:  61.67%, tr:  63.13%, tr_best:  64.56%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.390278/  1.576302, val:  59.17%, val_best:  61.67%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.370476/  1.565365, val:  60.83%, val_best:  61.67%, tr:  64.66%, tr_best:  65.68%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.355446/  1.553513, val:  61.25%, val_best:  61.67%, tr:  64.35%, tr_best:  65.68%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.335061/  1.554235, val:  59.58%, val_best:  61.67%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.316773/  1.546681, val:  64.58%, val_best:  64.58%, tr:  65.88%, tr_best:  66.70%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.307195/  1.540257, val:  64.58%, val_best:  64.58%, tr:  66.09%, tr_best:  66.70%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.288917/  1.523841, val:  62.50%, val_best:  64.58%, tr:  65.68%, tr_best:  66.70%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.275005/  1.512892, val:  62.92%, val_best:  64.58%, tr:  67.42%, tr_best:  67.42%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.271510/  1.508975, val:  62.50%, val_best:  64.58%, tr:  66.19%, tr_best:  67.42%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.249087/  1.506227, val:  64.17%, val_best:  64.58%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.242648/  1.502613, val:  62.08%, val_best:  64.58%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.226140/  1.489833, val:  64.17%, val_best:  64.58%, tr:  67.01%, tr_best:  68.03%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.217989/  1.489602, val:  60.00%, val_best:  64.58%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.214072/  1.473791, val:  60.83%, val_best:  64.58%, tr:  66.91%, tr_best:  68.23%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.196767/  1.471903, val:  62.08%, val_best:  64.58%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.185915/  1.471501, val:  60.83%, val_best:  64.58%, tr:  68.13%, tr_best:  68.34%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.174529/  1.465751, val:  61.25%, val_best:  64.58%, tr:  67.93%, tr_best:  68.34%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.165221/  1.465475, val:  65.42%, val_best:  65.42%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.160826/  1.456782, val:  61.25%, val_best:  65.42%, tr:  69.87%, tr_best:  70.07%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.153884/  1.460441, val:  61.25%, val_best:  65.42%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.137237/  1.462614, val:  61.25%, val_best:  65.42%, tr:  68.95%, tr_best:  71.09%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.140746/  1.467697, val:  56.67%, val_best:  65.42%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.122611/  1.459664, val:  63.33%, val_best:  65.42%, tr:  71.50%, tr_best:  71.71%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.114613/  1.465959, val:  62.08%, val_best:  65.42%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.113806/  1.467077, val:  59.17%, val_best:  65.42%, tr:  71.60%, tr_best:  71.71%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.097284/  1.461335, val:  64.17%, val_best:  65.42%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.093845/  1.458659, val:  57.08%, val_best:  65.42%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.091234/  1.457085, val:  59.58%, val_best:  65.42%, tr:  70.99%, tr_best:  73.44%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.087456/  1.457716, val:  63.75%, val_best:  65.42%, tr:  73.14%, tr_best:  73.44%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.074235/  1.461462, val:  59.58%, val_best:  65.42%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.065315/  1.467882, val:  62.92%, val_best:  65.42%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.057550/  1.455181, val:  60.00%, val_best:  65.42%, tr:  72.22%, tr_best:  73.95%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.048973/  1.452793, val:  59.17%, val_best:  65.42%, tr:  73.85%, tr_best:  73.95%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.039625/  1.444845, val:  60.00%, val_best:  65.42%, tr:  72.83%, tr_best:  73.95%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.036159/  1.463603, val:  59.58%, val_best:  65.42%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.027444/  1.456772, val:  63.75%, val_best:  65.42%, tr:  75.49%, tr_best:  75.79%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.015055/  1.451078, val:  63.33%, val_best:  65.42%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.018027/  1.447829, val:  63.75%, val_best:  65.42%, tr:  75.28%, tr_best:  77.94%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.006028/  1.458836, val:  62.08%, val_best:  65.42%, tr:  74.26%, tr_best:  77.94%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.005741/  1.442698, val:  63.33%, val_best:  65.42%, tr:  76.51%, tr_best:  77.94%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.998465/  1.437128, val:  64.17%, val_best:  65.42%, tr:  73.95%, tr_best:  77.94%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.994672/  1.447897, val:  61.67%, val_best:  65.42%, tr:  74.67%, tr_best:  77.94%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.992083/  1.444427, val:  64.58%, val_best:  65.42%, tr:  75.69%, tr_best:  77.94%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.978344/  1.430170, val:  60.83%, val_best:  65.42%, tr:  77.02%, tr_best:  77.94%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.973060/  1.448763, val:  59.58%, val_best:  65.42%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.971392/  1.438526, val:  64.17%, val_best:  65.42%, tr:  76.71%, tr_best:  78.04%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.966585/  1.425971, val:  67.50%, val_best:  67.50%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.970893/  1.427585, val:  63.33%, val_best:  67.50%, tr:  78.24%, tr_best:  78.96%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.958202/  1.435048, val:  66.67%, val_best:  67.50%, tr:  75.28%, tr_best:  78.96%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.955730/  1.428365, val:  67.08%, val_best:  67.50%, tr:  77.83%, tr_best:  78.96%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.951390/  1.438070, val:  62.08%, val_best:  67.50%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.945438/  1.437405, val:  66.25%, val_best:  67.50%, tr:  78.86%, tr_best:  80.29%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.939289/  1.432757, val:  64.17%, val_best:  67.50%, tr:  78.04%, tr_best:  80.29%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.938891/  1.423664, val:  62.08%, val_best:  67.50%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.928577/  1.445722, val:  64.58%, val_best:  67.50%, tr:  78.35%, tr_best:  80.29%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.933210/  1.440156, val:  65.00%, val_best:  67.50%, tr:  78.24%, tr_best:  80.29%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.913214/  1.451315, val:  63.75%, val_best:  67.50%, tr:  80.08%, tr_best:  80.29%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.922558/  1.446591, val:  64.17%, val_best:  67.50%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.911596/  1.426000, val:  65.83%, val_best:  67.50%, tr:  81.31%, tr_best:  82.33%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.904158/  1.457690, val:  62.08%, val_best:  67.50%, tr:  80.18%, tr_best:  82.33%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.899916/  1.445821, val:  65.00%, val_best:  67.50%, tr:  79.06%, tr_best:  82.33%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.894019/  1.444277, val:  66.67%, val_best:  67.50%, tr:  80.49%, tr_best:  82.33%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.889073/  1.455360, val:  65.00%, val_best:  67.50%, tr:  81.10%, tr_best:  82.33%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.890506/  1.450682, val:  67.08%, val_best:  67.50%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.883100/  1.455634, val:  61.67%, val_best:  67.50%, tr:  82.33%, tr_best:  83.04%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.880986/  1.475621, val:  62.92%, val_best:  67.50%, tr:  82.12%, tr_best:  83.04%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.877076/  1.478872, val:  65.00%, val_best:  67.50%, tr:  81.51%, tr_best:  83.04%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.877499/  1.460267, val:  67.92%, val_best:  67.92%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.865678/  1.482279, val:  63.75%, val_best:  67.92%, tr:  83.86%, tr_best:  84.27%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.861243/  1.504056, val:  60.83%, val_best:  67.92%, tr:  81.82%, tr_best:  84.27%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.865993/  1.477617, val:  63.75%, val_best:  67.92%, tr:  83.55%, tr_best:  84.27%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.847523/  1.483167, val:  65.83%, val_best:  67.92%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.858712/  1.495735, val:  65.42%, val_best:  67.92%, tr:  82.23%, tr_best:  84.47%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.862222/  1.496469, val:  67.08%, val_best:  67.92%, tr:  84.17%, tr_best:  84.47%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.861914/  1.502750, val:  63.75%, val_best:  67.92%, tr:  84.07%, tr_best:  84.47%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.847514/  1.497748, val:  67.08%, val_best:  67.92%, tr:  84.27%, tr_best:  84.47%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.847039/  1.534322, val:  66.25%, val_best:  67.92%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.850111/  1.499090, val:  68.75%, val_best:  68.75%, tr:  81.72%, tr_best:  85.90%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.852335/  1.526098, val:  67.08%, val_best:  68.75%, tr:  83.04%, tr_best:  85.90%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.849529/  1.516837, val:  68.75%, val_best:  68.75%, tr:  83.25%, tr_best:  85.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4db812111f47178f5449fc52051ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▃▃▅▅▄▃▆▇▇▅▃▅▅▇▅▇▇▆▅▅▆▇▇▇▆▇▅▇▇▅▅▅▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▄▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>tr_acc</td><td>▁▂▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▆▆▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▄▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▄▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>val_loss</td><td>██▇▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.83248</td></tr><tr><td>tr_epoch_loss</td><td>0.84953</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6875</td></tr><tr><td>val_loss</td><td>1.51684</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweepy-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kg0aow58' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kg0aow58</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_225259-kg0aow58/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rino1xbk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f08eb156e3c4d1980d3e3757c176f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112744097287457, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_225924-rino1xbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rino1xbk' target=\"_blank\">legendary-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rino1xbk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rino1xbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 28.210550/ 54.979710, val:  40.00%, val_best:  40.00%, tr:  30.44%, tr_best:  30.44%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 38.748215/ 40.076187, val:  40.42%, val_best:  40.42%, tr:  44.54%, tr_best:  44.54%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 27.615219/ 47.879341, val:  46.25%, val_best:  46.25%, tr:  55.67%, tr_best:  55.67%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 31.921532/ 26.206667, val:  51.25%, val_best:  51.25%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 28.325157/ 49.126709, val:  48.75%, val_best:  51.25%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 26.427284/ 40.754410, val:  53.33%, val_best:  53.33%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 26.830200/ 50.382313, val:  62.50%, val_best:  62.50%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 17.389654/ 39.971676, val:  50.83%, val_best:  62.50%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 14.458720/ 32.326149, val:  60.83%, val_best:  62.50%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 17.074503/ 47.623768, val:  59.17%, val_best:  62.50%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 13.296255/ 36.112782, val:  72.50%, val_best:  72.50%, tr:  85.70%, tr_best:  85.70%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  8.829143/ 39.162685, val:  67.92%, val_best:  72.50%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 10.286394/ 38.740700, val:  72.08%, val_best:  72.50%, tr:  90.81%, tr_best:  92.24%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  7.667179/ 41.112114, val:  68.75%, val_best:  72.50%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  4.545019/ 41.620831, val:  70.42%, val_best:  72.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  3.849314/ 38.034069, val:  75.83%, val_best:  75.83%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  2.855877/ 42.231419, val:  69.17%, val_best:  75.83%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  2.658193/ 40.983337, val:  77.50%, val_best:  77.50%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  2.228786/ 43.006588, val:  72.50%, val_best:  77.50%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  1.398397/ 44.370998, val:  72.92%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  1.156353/ 43.730446, val:  76.25%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  1.028389/ 49.180561, val:  69.17%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.800335/ 48.383698, val:  75.00%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.719795/ 47.196178, val:  73.33%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.589209/ 48.357296, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.536476/ 50.960983, val:  73.75%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.405214/ 51.025768, val:  72.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.272046/ 51.695438, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.348323/ 50.957508, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.289572/ 52.595634, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.210547/ 51.352863, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.319011/ 52.962486, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.138697/ 54.734112, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.194856/ 53.186420, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.175295/ 53.276325, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.163136/ 55.411060, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.131037/ 54.092007, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.126289/ 53.995018, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.165611/ 54.490173, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.134680/ 55.148647, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.137389/ 56.961399, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.113212/ 55.229477, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.111472/ 56.777416, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.097934/ 57.539047, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.190229/ 55.587822, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.103167/ 57.229198, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.100872/ 58.410534, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.119776/ 56.161392, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.075598/ 57.147869, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.077257/ 56.285480, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.104048/ 55.552216, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.084709/ 57.381794, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.071983/ 57.387505, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.052089/ 58.750526, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.076608/ 57.539795, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.116083/ 57.944614, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.089002/ 58.452667, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.066047/ 59.789062, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.034039/ 57.979458, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.034045/ 58.258369, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.056813/ 60.211601, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.022400/ 59.100151, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.047111/ 61.154175, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.031138/ 59.572628, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.034647/ 58.344952, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.060158/ 61.341911, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.037802/ 61.250748, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.029080/ 61.536713, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.033956/ 60.737381, val:  73.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.047237/ 60.664131, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.019935/ 62.090298, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.015072/ 61.550297, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.015124/ 62.827042, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.040552/ 61.925232, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.045703/ 62.696411, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.020957/ 61.104431, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.041301/ 61.137093, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.047843/ 62.925667, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.017615/ 62.288139, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.032501/ 60.784786, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.015252/ 60.824001, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.027517/ 62.152447, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.013678/ 60.542461, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.021648/ 61.252525, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.018122/ 59.693985, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.011090/ 59.600410, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.049580/ 61.473064, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.046173/ 62.042404, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.023025/ 61.772552, val:  74.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.028456/ 60.555481, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.011595/ 61.529549, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.011584/ 60.752342, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.009075/ 59.903938, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000493/ 60.066086, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000418/ 60.415588, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.002487/ 60.587883, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.005354/ 59.359650, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.008261/ 59.741837, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.021043/ 61.795231, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.028152/ 60.753361, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6afb34ba36406483ffc05037aedd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▆▄▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▃▄▇▆█▇▆▇▇▇▇█▇▇▇▇█▇█▇▇▇█▇▇▇▇▇▇▇██▇▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>███▅▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▅▅▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▃▄▇▆█▇▆▇▇▇▇█▇▇▇▇█▇█▇▇▇█▇▇▇▇▇▇▇██▇▇█▇▇</td></tr><tr><td>val_loss</td><td>▆▄▄▁▄▁▂▂▃▄▄▅▅▆▆▅▆▆▆▆▆▆▆▇▇▇████▇█▇▇▇█▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02815</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>60.75336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-sweep-7</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rino1xbk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rino1xbk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_225924-rino1xbk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vkn98q5s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914bdd283082403aaed0557b4b8b612f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113122271166908, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_230625-vkn98q5s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vkn98q5s' target=\"_blank\">decent-sweep-11</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vkn98q5s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vkn98q5s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302747/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302738/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302605, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302685/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302820/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302609, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302779/  2.302603, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302691/  2.302607, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302883/  2.302611, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302826/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302753/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.302773/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302603, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.302739/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.302776/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.302690/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.302775/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.302693/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.302906/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.302793/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.302770/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.302866/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.11%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.302885/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.11%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.302852/  2.302598, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.302803/  2.302592, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.302764/  2.302594, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302596, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.302876/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.302864/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.302786/  2.302591, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.302822/  2.302595, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302598, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.11%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.302728/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.302796/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  10.42%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.302846/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.302759/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.302730/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.42%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.302802/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.302804/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.302787/  2.302590, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302593, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  10.42%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  2.302809/  2.302600, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.42%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  2.302807/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.42%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.42%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  2.302812/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  2.302837/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.42%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.42%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  2.302818/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89c2dcb7b7642d394d62cdd92d37a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▄▅▅▁▇▅█▄▁▄▅▄▅▁▇▂▇▄▁▄▅▂▁▁▄▂▂▁▇▁▄▄▁▂</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▃▇▂▄▁▁▄▁▆▄▇▃▅▇▇▃▄█▇▇▇▂▆▁</td></tr><tr><td>tr_epoch_loss</td><td>█▇█▄▁▂▅▂▂▄▃▃▁▃▂▃▂▂▂▃▂▃▂▃▃▂▂▃▃▃▃▃▃▂▂▃▃▃▂▃</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30282</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.3026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-sweep-11</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vkn98q5s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vkn98q5s</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_230625-vkn98q5s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3yki3csw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baba36566b7b4109b805628019954797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111311055202451, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_231300-3yki3csw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yki3csw' target=\"_blank\">logical-sweep-15</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yki3csw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yki3csw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302941/  2.302764, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.302925/  2.302673, val:  11.25%, val_best:  11.25%, tr:  10.62%, tr_best:  10.62%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302258/  2.302210, val:  11.67%, val_best:  11.67%, tr:  11.85%, tr_best:  11.85%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.301153/  2.301020, val:  11.67%, val_best:  11.67%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.299150/  2.297834, val:  12.92%, val_best:  12.92%, tr:  13.28%, tr_best:  13.69%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.292773/  2.289670, val:  14.17%, val_best:  14.17%, tr:  13.07%, tr_best:  13.69%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.277267/  2.271635, val:  15.42%, val_best:  15.42%, tr:  13.07%, tr_best:  13.69%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.250829/  2.243384, val:  19.17%, val_best:  19.17%, tr:  15.32%, tr_best:  15.32%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.209978/  2.199193, val:  21.67%, val_best:  21.67%, tr:  20.94%, tr_best:  20.94%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.152720/  2.153188, val:  20.83%, val_best:  21.67%, tr:  22.47%, tr_best:  22.47%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.098125/  2.106228, val:  27.92%, val_best:  27.92%, tr:  23.70%, tr_best:  23.70%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.045789/  2.060270, val:  28.75%, val_best:  28.75%, tr:  26.46%, tr_best:  26.46%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.989499/  2.016237, val:  33.75%, val_best:  33.75%, tr:  30.23%, tr_best:  30.23%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.931698/  1.969383, val:  38.33%, val_best:  38.33%, tr:  36.26%, tr_best:  36.26%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.876609/  1.924781, val:  43.33%, val_best:  43.33%, tr:  37.79%, tr_best:  37.79%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.821767/  1.882447, val:  44.17%, val_best:  44.17%, tr:  42.39%, tr_best:  42.39%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.782113/  1.850156, val:  49.58%, val_best:  49.58%, tr:  47.09%, tr_best:  47.09%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.739838/  1.823192, val:  47.50%, val_best:  49.58%, tr:  50.05%, tr_best:  50.05%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.706870/  1.799397, val:  45.83%, val_best:  49.58%, tr:  51.99%, tr_best:  51.99%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.682101/  1.778057, val:  45.42%, val_best:  49.58%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.656460/  1.760152, val:  46.67%, val_best:  49.58%, tr:  54.24%, tr_best:  54.24%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.628477/  1.739264, val:  49.58%, val_best:  49.58%, tr:  56.69%, tr_best:  56.69%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.616627/  1.719541, val:  49.58%, val_best:  49.58%, tr:  56.18%, tr_best:  56.69%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.587089/  1.706245, val:  49.17%, val_best:  49.58%, tr:  57.51%, tr_best:  57.51%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.573820/  1.691684, val:  50.42%, val_best:  50.42%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.555842/  1.680174, val:  52.92%, val_best:  52.92%, tr:  58.22%, tr_best:  58.73%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.543982/  1.672527, val:  52.92%, val_best:  52.92%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.537596/  1.669269, val:  54.17%, val_best:  54.17%, tr:  58.84%, tr_best:  59.45%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.523369/  1.661421, val:  54.58%, val_best:  54.58%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.505275/  1.653393, val:  55.00%, val_best:  55.00%, tr:  59.86%, tr_best:  60.47%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.502018/  1.654260, val:  54.17%, val_best:  55.00%, tr:  60.16%, tr_best:  60.47%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.486831/  1.654080, val:  56.25%, val_best:  56.25%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.481646/  1.646691, val:  58.75%, val_best:  58.75%, tr:  60.67%, tr_best:  60.88%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.476108/  1.643833, val:  56.25%, val_best:  58.75%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.463377/  1.641627, val:  56.67%, val_best:  58.75%, tr:  59.96%, tr_best:  61.18%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.460682/  1.636192, val:  55.42%, val_best:  58.75%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.447939/  1.637370, val:  55.83%, val_best:  58.75%, tr:  62.41%, tr_best:  62.92%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.448752/  1.636892, val:  55.42%, val_best:  58.75%, tr:  62.82%, tr_best:  62.92%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.440098/  1.636961, val:  56.25%, val_best:  58.75%, tr:  61.80%, tr_best:  62.92%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.435198/  1.637310, val:  55.00%, val_best:  58.75%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.421248/  1.636014, val:  59.58%, val_best:  59.58%, tr:  62.21%, tr_best:  63.94%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.424164/  1.636320, val:  56.25%, val_best:  59.58%, tr:  63.13%, tr_best:  63.94%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.417058/  1.636212, val:  56.67%, val_best:  59.58%, tr:  63.84%, tr_best:  63.94%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.415171/  1.633598, val:  55.83%, val_best:  59.58%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.409500/  1.637961, val:  56.25%, val_best:  59.58%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.401501/  1.632929, val:  59.58%, val_best:  59.58%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.394253/  1.633567, val:  57.08%, val_best:  59.58%, tr:  62.92%, tr_best:  64.15%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.392854/  1.626676, val:  59.58%, val_best:  59.58%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.390203/  1.628512, val:  59.17%, val_best:  59.58%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.383443/  1.630510, val:  59.58%, val_best:  59.58%, tr:  64.86%, tr_best:  67.31%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.374225/  1.632302, val:  61.25%, val_best:  61.25%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.378584/  1.633926, val:  59.58%, val_best:  61.25%, tr:  66.50%, tr_best:  68.03%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.364924/  1.632847, val:  61.67%, val_best:  61.67%, tr:  64.76%, tr_best:  68.03%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.370718/  1.629555, val:  60.00%, val_best:  61.67%, tr:  67.52%, tr_best:  68.03%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.365009/  1.635534, val:  59.17%, val_best:  61.67%, tr:  64.86%, tr_best:  68.03%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.368635/  1.629708, val:  60.00%, val_best:  61.67%, tr:  64.76%, tr_best:  68.03%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.364176/  1.625307, val:  61.25%, val_best:  61.67%, tr:  65.99%, tr_best:  68.03%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.350222/  1.626096, val:  61.25%, val_best:  61.67%, tr:  67.93%, tr_best:  68.03%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.342253/  1.625120, val:  60.42%, val_best:  61.67%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.346821/  1.625961, val:  60.83%, val_best:  61.67%, tr:  66.60%, tr_best:  68.44%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.343516/  1.632426, val:  61.25%, val_best:  61.67%, tr:  67.93%, tr_best:  68.44%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.338231/  1.632403, val:  60.42%, val_best:  61.67%, tr:  68.34%, tr_best:  68.44%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.334564/  1.633827, val:  57.92%, val_best:  61.67%, tr:  65.07%, tr_best:  68.44%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.329823/  1.631887, val:  61.67%, val_best:  61.67%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.327030/  1.633164, val:  63.75%, val_best:  63.75%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.327822/  1.631640, val:  61.25%, val_best:  63.75%, tr:  68.44%, tr_best:  69.36%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.317896/  1.638772, val:  63.33%, val_best:  63.75%, tr:  67.01%, tr_best:  69.36%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.322336/  1.622845, val:  63.75%, val_best:  63.75%, tr:  69.25%, tr_best:  69.36%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.310192/  1.634905, val:  58.75%, val_best:  63.75%, tr:  68.44%, tr_best:  69.36%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.314870/  1.633902, val:  61.67%, val_best:  63.75%, tr:  68.85%, tr_best:  69.36%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.304947/  1.625226, val:  62.50%, val_best:  63.75%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.309162/  1.627219, val:  63.75%, val_best:  63.75%, tr:  69.15%, tr_best:  69.66%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.301750/  1.619726, val:  62.08%, val_best:  63.75%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.304800/  1.622495, val:  61.67%, val_best:  63.75%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.296207/  1.620392, val:  62.50%, val_best:  63.75%, tr:  70.17%, tr_best:  70.38%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.294706/  1.617948, val:  60.42%, val_best:  63.75%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.292476/  1.617047, val:  62.08%, val_best:  63.75%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.292527/  1.618832, val:  62.50%, val_best:  63.75%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.294949/  1.626699, val:  63.75%, val_best:  63.75%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.288276/  1.631604, val:  61.25%, val_best:  63.75%, tr:  70.79%, tr_best:  72.83%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.280563/  1.624535, val:  62.08%, val_best:  63.75%, tr:  70.68%, tr_best:  72.83%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.278404/  1.624727, val:  65.83%, val_best:  65.83%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.274449/  1.629933, val:  62.92%, val_best:  65.83%, tr:  70.79%, tr_best:  73.65%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.269532/  1.638217, val:  61.67%, val_best:  65.83%, tr:  71.91%, tr_best:  73.65%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.268764/  1.633082, val:  65.00%, val_best:  65.83%, tr:  72.52%, tr_best:  73.65%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.254542/  1.637121, val:  62.92%, val_best:  65.83%, tr:  72.11%, tr_best:  73.65%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.264855/  1.639010, val:  63.75%, val_best:  65.83%, tr:  70.89%, tr_best:  73.65%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.266680/  1.638564, val:  62.08%, val_best:  65.83%, tr:  72.52%, tr_best:  73.65%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.252593/  1.636666, val:  64.58%, val_best:  65.83%, tr:  72.22%, tr_best:  73.65%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.254189/  1.642771, val:  65.00%, val_best:  65.83%, tr:  72.73%, tr_best:  73.65%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.249487/  1.645919, val:  65.00%, val_best:  65.83%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.247795/  1.638166, val:  61.25%, val_best:  65.83%, tr:  71.40%, tr_best:  74.67%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.246178/  1.643585, val:  64.17%, val_best:  65.83%, tr:  73.03%, tr_best:  74.67%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.246173/  1.642086, val:  63.33%, val_best:  65.83%, tr:  73.14%, tr_best:  74.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1b1f888ba544d89f5bfecd2ee89480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▂▁▂▄▃▄▅▆▅▅▆▅▅▅▇▄▅▅▅▅▅▆▅▇▆▅▇▅▆▅▆▆▄▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▂▃▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇███▇██▇</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▂▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>██████▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▂▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▂▃▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇███▇██▇</td></tr><tr><td>val_loss</td><td>██████▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.73136</td></tr><tr><td>tr_epoch_loss</td><td>1.24617</td></tr><tr><td>val_acc_best</td><td>0.65833</td></tr><tr><td>val_acc_now</td><td>0.63333</td></tr><tr><td>val_loss</td><td>1.64209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-15</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yki3csw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yki3csw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_231300-3yki3csw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ot5imsl8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_232022-ot5imsl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ot5imsl8' target=\"_blank\">woven-sweep-20</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ot5imsl8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ot5imsl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303254/  2.302925, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303192/  2.302879, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303442/  2.302868, val:  10.42%, val_best:  10.42%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.302958/  2.302423, val:  10.42%, val_best:  10.42%, tr:  11.03%, tr_best:  11.03%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302454/  2.301783, val:  11.25%, val_best:  11.25%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.301640/  2.300393, val:  11.25%, val_best:  11.25%, tr:  12.77%, tr_best:  12.77%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.298958/  2.298349, val:  10.00%, val_best:  11.25%, tr:  12.56%, tr_best:  12.77%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.294440/  2.294248, val:  11.25%, val_best:  11.25%, tr:  13.18%, tr_best:  13.18%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.287155/  2.287653, val:  12.50%, val_best:  12.50%, tr:  13.38%, tr_best:  13.38%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.273988/  2.275465, val:  17.08%, val_best:  17.08%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.255270/  2.257987, val:  18.33%, val_best:  18.33%, tr:  18.08%, tr_best:  18.08%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.227634/  2.234732, val:  21.25%, val_best:  21.25%, tr:  22.98%, tr_best:  22.98%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.192133/  2.201636, val:  25.42%, val_best:  25.42%, tr:  27.17%, tr_best:  27.17%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.144969/  2.163362, val:  27.08%, val_best:  27.08%, tr:  30.23%, tr_best:  30.23%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.098033/  2.122729, val:  33.33%, val_best:  33.33%, tr:  36.36%, tr_best:  36.36%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.047360/  2.081414, val:  37.50%, val_best:  37.50%, tr:  41.06%, tr_best:  41.06%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.994191/  2.038875, val:  40.00%, val_best:  40.00%, tr:  42.59%, tr_best:  42.59%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.938382/  2.001261, val:  42.08%, val_best:  42.08%, tr:  44.74%, tr_best:  44.74%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.893650/  1.965381, val:  42.92%, val_best:  42.92%, tr:  45.97%, tr_best:  45.97%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.843298/  1.925440, val:  42.50%, val_best:  42.92%, tr:  47.60%, tr_best:  47.60%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.804658/  1.891519, val:  46.67%, val_best:  46.67%, tr:  49.23%, tr_best:  49.23%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.762388/  1.857122, val:  47.08%, val_best:  47.08%, tr:  50.36%, tr_best:  50.36%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.727295/  1.829271, val:  47.92%, val_best:  47.92%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.699539/  1.808439, val:  45.00%, val_best:  47.92%, tr:  53.52%, tr_best:  53.52%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.671209/  1.787369, val:  46.25%, val_best:  47.92%, tr:  53.22%, tr_best:  53.52%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.642320/  1.767431, val:  44.58%, val_best:  47.92%, tr:  53.22%, tr_best:  53.52%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.624339/  1.747646, val:  45.42%, val_best:  47.92%, tr:  55.06%, tr_best:  55.06%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.601040/  1.733397, val:  48.75%, val_best:  48.75%, tr:  56.38%, tr_best:  56.38%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.586952/  1.720850, val:  48.33%, val_best:  48.75%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.567729/  1.706173, val:  48.75%, val_best:  48.75%, tr:  56.89%, tr_best:  57.30%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.545387/  1.692996, val:  49.58%, val_best:  49.58%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.537659/  1.683315, val:  49.17%, val_best:  49.58%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.525325/  1.670541, val:  50.42%, val_best:  50.42%, tr:  59.04%, tr_best:  59.55%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.508278/  1.660131, val:  52.50%, val_best:  52.50%, tr:  59.35%, tr_best:  59.55%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.498378/  1.651476, val:  53.33%, val_best:  53.33%, tr:  59.35%, tr_best:  59.55%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.485372/  1.647958, val:  52.92%, val_best:  53.33%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.478408/  1.634258, val:  52.50%, val_best:  53.33%, tr:  58.73%, tr_best:  60.16%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.470048/  1.627209, val:  51.25%, val_best:  53.33%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.456196/  1.623256, val:  53.75%, val_best:  53.75%, tr:  61.08%, tr_best:  61.59%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.448870/  1.620522, val:  52.50%, val_best:  53.75%, tr:  61.18%, tr_best:  61.59%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.434530/  1.612296, val:  52.92%, val_best:  53.75%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.433190/  1.607003, val:  52.92%, val_best:  53.75%, tr:  61.39%, tr_best:  62.82%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.426309/  1.603155, val:  52.08%, val_best:  53.75%, tr:  60.88%, tr_best:  62.82%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.419440/  1.598943, val:  52.92%, val_best:  53.75%, tr:  61.59%, tr_best:  62.82%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.409225/  1.595806, val:  53.33%, val_best:  53.75%, tr:  61.08%, tr_best:  62.82%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.404378/  1.594450, val:  55.00%, val_best:  55.00%, tr:  62.00%, tr_best:  62.82%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.398582/  1.585999, val:  53.75%, val_best:  55.00%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.394279/  1.579652, val:  54.58%, val_best:  55.00%, tr:  62.41%, tr_best:  62.92%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.387520/  1.575205, val:  54.17%, val_best:  55.00%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.376431/  1.570783, val:  55.00%, val_best:  55.00%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.369872/  1.570186, val:  53.75%, val_best:  55.00%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.362677/  1.568894, val:  53.75%, val_best:  55.00%, tr:  62.82%, tr_best:  63.43%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.360351/  1.570914, val:  51.25%, val_best:  55.00%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.352996/  1.566971, val:  54.58%, val_best:  55.00%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.341723/  1.565212, val:  51.25%, val_best:  55.00%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.348798/  1.564369, val:  52.92%, val_best:  55.00%, tr:  64.15%, tr_best:  65.17%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.333014/  1.563063, val:  51.25%, val_best:  55.00%, tr:  63.43%, tr_best:  65.17%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.338938/  1.558753, val:  52.92%, val_best:  55.00%, tr:  64.15%, tr_best:  65.17%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.332222/  1.556372, val:  52.50%, val_best:  55.00%, tr:  64.15%, tr_best:  65.17%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.336338/  1.553714, val:  52.08%, val_best:  55.00%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.326365/  1.554897, val:  51.67%, val_best:  55.00%, tr:  64.15%, tr_best:  65.58%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.314900/  1.550394, val:  53.33%, val_best:  55.00%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.307444/  1.545294, val:  54.58%, val_best:  55.00%, tr:  66.29%, tr_best:  66.39%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.311866/  1.546047, val:  53.75%, val_best:  55.00%, tr:  65.58%, tr_best:  66.39%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.306838/  1.547137, val:  52.92%, val_best:  55.00%, tr:  65.37%, tr_best:  66.39%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.309934/  1.544801, val:  53.33%, val_best:  55.00%, tr:  65.27%, tr_best:  66.39%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.295664/  1.543810, val:  54.17%, val_best:  55.00%, tr:  64.56%, tr_best:  66.39%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.298650/  1.540257, val:  52.92%, val_best:  55.00%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.293999/  1.539099, val:  52.50%, val_best:  55.00%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.284513/  1.539314, val:  53.33%, val_best:  55.00%, tr:  65.88%, tr_best:  67.31%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.282596/  1.539470, val:  53.75%, val_best:  55.00%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.276035/  1.535452, val:  53.33%, val_best:  55.00%, tr:  66.60%, tr_best:  67.31%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.270390/  1.535583, val:  54.58%, val_best:  55.00%, tr:  65.47%, tr_best:  67.31%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.271924/  1.533122, val:  52.50%, val_best:  55.00%, tr:  65.58%, tr_best:  67.31%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.269558/  1.535969, val:  55.83%, val_best:  55.83%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.267871/  1.533511, val:  52.92%, val_best:  55.83%, tr:  66.60%, tr_best:  67.93%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.264480/  1.528943, val:  53.33%, val_best:  55.83%, tr:  67.42%, tr_best:  67.93%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.265365/  1.526307, val:  53.33%, val_best:  55.83%, tr:  67.21%, tr_best:  67.93%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.253763/  1.526624, val:  55.00%, val_best:  55.83%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.256779/  1.522701, val:  53.75%, val_best:  55.83%, tr:  67.01%, tr_best:  68.13%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.254678/  1.518553, val:  55.42%, val_best:  55.83%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.250011/  1.522519, val:  54.58%, val_best:  55.83%, tr:  67.93%, tr_best:  68.64%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.252001/  1.516935, val:  53.33%, val_best:  55.83%, tr:  67.93%, tr_best:  68.64%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.248735/  1.520090, val:  57.08%, val_best:  57.08%, tr:  67.62%, tr_best:  68.64%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.238296/  1.516928, val:  57.08%, val_best:  57.08%, tr:  68.13%, tr_best:  68.64%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.240888/  1.515194, val:  55.83%, val_best:  57.08%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.234044/  1.514811, val:  55.42%, val_best:  57.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.228721/  1.514688, val:  55.42%, val_best:  57.08%, tr:  68.03%, tr_best:  69.77%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.229943/  1.513888, val:  52.50%, val_best:  57.08%, tr:  68.74%, tr_best:  69.77%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.215614/  1.511513, val:  56.67%, val_best:  57.08%, tr:  68.03%, tr_best:  69.77%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.227124/  1.510774, val:  57.92%, val_best:  57.92%, tr:  68.74%, tr_best:  69.77%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.226672/  1.516011, val:  53.33%, val_best:  57.92%, tr:  69.15%, tr_best:  69.77%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.216445/  1.511571, val:  52.92%, val_best:  57.92%, tr:  68.13%, tr_best:  69.77%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.221209/  1.508217, val:  57.08%, val_best:  57.92%, tr:  68.13%, tr_best:  69.77%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.211530/  1.509716, val:  54.17%, val_best:  57.92%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.221887/  1.502721, val:  55.00%, val_best:  57.92%, tr:  69.15%, tr_best:  69.97%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.218303/  1.504255, val:  54.17%, val_best:  57.92%, tr:  68.03%, tr_best:  69.97%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.205900/  1.507762, val:  57.08%, val_best:  57.92%, tr:  68.54%, tr_best:  69.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5822cebd2e4640c482f32831488cffa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▂▁▂▂▄▅▄▄▇▆▆▄▆▅▅▆▇▅▆▆▅▆▆▇▇▆▇▆█▇▇▆█▇▆▇▇▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▃▅▆▆▇▆▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▂▃▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>tr_epoch_loss</td><td>██████▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▃▅▆▆▇▆▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>val_loss</td><td>██████▇▆▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.68539</td></tr><tr><td>tr_epoch_loss</td><td>1.2059</td></tr><tr><td>val_acc_best</td><td>0.57917</td></tr><tr><td>val_acc_now</td><td>0.57083</td></tr><tr><td>val_loss</td><td>1.50776</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-20</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ot5imsl8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ot5imsl8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_232022-ot5imsl8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dsv0ofsy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f5b0e38d9044a5899f9fd56edac70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112988346980678, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_232728-dsv0ofsy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dsv0ofsy' target=\"_blank\">tough-sweep-24</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dsv0ofsy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dsv0ofsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303385/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.302991/  2.302757, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302881/  2.302676, val:  10.42%, val_best:  10.42%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.302889/  2.302536, val:  10.83%, val_best:  10.83%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302400/  2.302341, val:  11.25%, val_best:  11.25%, tr:  11.85%, tr_best:  11.85%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.301756/  2.301779, val:  12.50%, val_best:  12.50%, tr:  12.46%, tr_best:  12.46%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.301154/  2.300630, val:  11.25%, val_best:  12.50%, tr:  11.64%, tr_best:  12.46%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.298692/  2.298056, val:  11.67%, val_best:  12.50%, tr:  12.46%, tr_best:  12.46%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.293483/  2.292984, val:  12.92%, val_best:  12.92%, tr:  13.79%, tr_best:  13.79%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.283867/  2.283220, val:  12.92%, val_best:  12.92%, tr:  14.40%, tr_best:  14.40%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.267885/  2.264535, val:  15.83%, val_best:  15.83%, tr:  15.83%, tr_best:  15.83%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.238772/  2.238413, val:  22.08%, val_best:  22.08%, tr:  19.82%, tr_best:  19.82%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.200064/  2.202713, val:  22.92%, val_best:  22.92%, tr:  23.29%, tr_best:  23.29%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.153237/  2.162784, val:  22.50%, val_best:  22.92%, tr:  24.62%, tr_best:  24.62%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.102945/  2.120274, val:  25.83%, val_best:  25.83%, tr:  27.27%, tr_best:  27.27%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.049010/  2.083670, val:  35.42%, val_best:  35.42%, tr:  32.79%, tr_best:  32.79%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.007099/  2.047691, val:  34.17%, val_best:  35.42%, tr:  36.06%, tr_best:  36.06%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.957843/  2.011371, val:  36.67%, val_best:  36.67%, tr:  39.73%, tr_best:  39.73%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.919263/  1.975214, val:  42.08%, val_best:  42.08%, tr:  43.11%, tr_best:  43.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.874883/  1.935668, val:  40.42%, val_best:  42.08%, tr:  45.86%, tr_best:  45.86%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.828722/  1.899397, val:  41.25%, val_best:  42.08%, tr:  47.60%, tr_best:  47.60%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.790751/  1.863598, val:  40.83%, val_best:  42.08%, tr:  48.31%, tr_best:  48.31%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.747239/  1.831401, val:  43.33%, val_best:  43.33%, tr:  49.23%, tr_best:  49.23%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.707679/  1.801220, val:  42.50%, val_best:  43.33%, tr:  51.38%, tr_best:  51.38%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.680372/  1.776700, val:  44.17%, val_best:  44.17%, tr:  49.85%, tr_best:  51.38%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.644589/  1.755825, val:  44.58%, val_best:  44.58%, tr:  51.28%, tr_best:  51.38%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.625504/  1.737761, val:  45.83%, val_best:  45.83%, tr:  51.48%, tr_best:  51.48%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.595316/  1.717141, val:  47.08%, val_best:  47.08%, tr:  53.83%, tr_best:  53.83%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.572214/  1.698152, val:  47.08%, val_best:  47.08%, tr:  54.44%, tr_best:  54.44%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.562179/  1.680987, val:  47.08%, val_best:  47.08%, tr:  56.69%, tr_best:  56.69%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.545195/  1.667261, val:  48.33%, val_best:  48.33%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.523311/  1.651806, val:  46.25%, val_best:  48.33%, tr:  56.89%, tr_best:  57.20%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.511014/  1.640335, val:  47.08%, val_best:  48.33%, tr:  56.49%, tr_best:  57.20%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.497666/  1.630062, val:  50.00%, val_best:  50.00%, tr:  57.00%, tr_best:  57.20%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.487057/  1.615962, val:  50.00%, val_best:  50.00%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.474372/  1.611407, val:  50.00%, val_best:  50.00%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.457144/  1.605375, val:  50.83%, val_best:  50.83%, tr:  58.43%, tr_best:  59.24%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.449361/  1.594409, val:  52.08%, val_best:  52.08%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.436750/  1.586030, val:  52.08%, val_best:  52.08%, tr:  59.96%, tr_best:  60.06%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.432168/  1.579830, val:  52.50%, val_best:  52.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.421276/  1.574991, val:  51.25%, val_best:  52.50%, tr:  59.45%, tr_best:  60.67%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.413765/  1.571840, val:  55.00%, val_best:  55.00%, tr:  59.96%, tr_best:  60.67%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.397588/  1.564524, val:  56.25%, val_best:  56.25%, tr:  59.55%, tr_best:  60.67%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.396108/  1.557501, val:  54.58%, val_best:  56.25%, tr:  60.57%, tr_best:  60.67%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.388915/  1.550207, val:  53.75%, val_best:  56.25%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.385136/  1.545748, val:  52.50%, val_best:  56.25%, tr:  60.06%, tr_best:  61.18%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.375393/  1.544380, val:  50.83%, val_best:  56.25%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.367899/  1.541047, val:  54.17%, val_best:  56.25%, tr:  60.47%, tr_best:  61.80%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.360494/  1.538050, val:  54.17%, val_best:  56.25%, tr:  61.59%, tr_best:  61.80%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.354371/  1.534335, val:  54.58%, val_best:  56.25%, tr:  61.49%, tr_best:  61.80%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.348863/  1.528857, val:  53.75%, val_best:  56.25%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.342235/  1.526647, val:  54.58%, val_best:  56.25%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.330267/  1.526749, val:  55.00%, val_best:  56.25%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.332158/  1.529680, val:  55.00%, val_best:  56.25%, tr:  62.41%, tr_best:  63.23%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.317162/  1.524751, val:  53.75%, val_best:  56.25%, tr:  61.49%, tr_best:  63.23%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.322801/  1.519964, val:  55.42%, val_best:  56.25%, tr:  62.92%, tr_best:  63.23%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.316121/  1.519152, val:  53.33%, val_best:  56.25%, tr:  61.49%, tr_best:  63.23%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.317034/  1.515005, val:  55.42%, val_best:  56.25%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.309430/  1.509769, val:  57.08%, val_best:  57.08%, tr:  62.92%, tr_best:  63.23%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.296652/  1.508065, val:  56.67%, val_best:  57.08%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.286813/  1.505861, val:  55.00%, val_best:  57.08%, tr:  63.84%, tr_best:  64.04%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.294630/  1.505740, val:  57.08%, val_best:  57.08%, tr:  63.64%, tr_best:  64.04%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.289993/  1.504340, val:  57.92%, val_best:  57.92%, tr:  63.84%, tr_best:  64.04%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.285348/  1.499951, val:  58.33%, val_best:  58.33%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.276251/  1.498462, val:  55.83%, val_best:  58.33%, tr:  64.96%, tr_best:  65.88%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.276342/  1.492446, val:  59.58%, val_best:  59.58%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.271652/  1.485463, val:  60.00%, val_best:  60.00%, tr:  65.88%, tr_best:  66.91%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.265605/  1.487342, val:  59.58%, val_best:  60.00%, tr:  65.27%, tr_best:  66.91%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.259613/  1.486137, val:  59.58%, val_best:  60.00%, tr:  64.96%, tr_best:  66.91%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.255127/  1.481782, val:  58.33%, val_best:  60.00%, tr:  66.39%, tr_best:  66.91%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.246737/  1.485729, val:  59.17%, val_best:  60.00%, tr:  65.68%, tr_best:  66.91%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.247669/  1.483497, val:  59.17%, val_best:  60.00%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.245730/  1.480335, val:  58.75%, val_best:  60.00%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.247535/  1.480596, val:  58.75%, val_best:  60.00%, tr:  66.60%, tr_best:  67.21%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.240866/  1.478527, val:  57.50%, val_best:  60.00%, tr:  67.01%, tr_best:  67.21%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.241842/  1.469236, val:  58.33%, val_best:  60.00%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.231733/  1.470191, val:  61.25%, val_best:  61.25%, tr:  66.39%, tr_best:  67.93%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.233633/  1.469254, val:  57.92%, val_best:  61.25%, tr:  67.01%, tr_best:  67.93%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.227438/  1.467289, val:  58.33%, val_best:  61.25%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.227906/  1.464306, val:  60.42%, val_best:  61.25%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.227082/  1.460421, val:  57.08%, val_best:  61.25%, tr:  67.21%, tr_best:  69.46%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.224316/  1.457365, val:  61.25%, val_best:  61.25%, tr:  68.03%, tr_best:  69.46%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.213153/  1.459456, val:  57.92%, val_best:  61.25%, tr:  68.03%, tr_best:  69.46%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.215405/  1.456973, val:  59.58%, val_best:  61.25%, tr:  69.05%, tr_best:  69.46%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.209987/  1.460943, val:  59.58%, val_best:  61.25%, tr:  68.44%, tr_best:  69.46%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.203468/  1.461578, val:  57.92%, val_best:  61.25%, tr:  67.72%, tr_best:  69.46%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.206362/  1.458894, val:  59.58%, val_best:  61.25%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.190010/  1.456252, val:  59.17%, val_best:  61.25%, tr:  68.03%, tr_best:  69.56%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.199930/  1.453416, val:  58.75%, val_best:  61.25%, tr:  68.13%, tr_best:  69.56%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.203921/  1.457176, val:  57.08%, val_best:  61.25%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.186485/  1.457515, val:  60.42%, val_best:  61.25%, tr:  69.25%, tr_best:  70.48%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.187593/  1.455727, val:  60.00%, val_best:  61.25%, tr:  68.95%, tr_best:  70.48%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.181250/  1.455487, val:  60.83%, val_best:  61.25%, tr:  69.77%, tr_best:  70.48%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.181089/  1.449277, val:  60.00%, val_best:  61.25%, tr:  69.15%, tr_best:  70.48%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.183689/  1.451427, val:  60.42%, val_best:  61.25%, tr:  68.95%, tr_best:  70.48%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.171828/  1.450198, val:  60.83%, val_best:  61.25%, tr:  70.48%, tr_best:  70.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cc1da43b6842e299a11a511afc02db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▁▁▁▂▄▂▃▅▅▃▄▆▄▅▅▆▄▄▅▄▅▄▆▅▆▅▅▆▅▅▅▇▆▅▆█▅</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▂▃▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>███████▇▆▆▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▂▃▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>███████▇▆▆▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.7048</td></tr><tr><td>tr_epoch_loss</td><td>1.17183</td></tr><tr><td>val_acc_best</td><td>0.6125</td></tr><tr><td>val_acc_now</td><td>0.60833</td></tr><tr><td>val_loss</td><td>1.4502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tough-sweep-24</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dsv0ofsy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dsv0ofsy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_232728-dsv0ofsy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v75lhj8g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_233434-v75lhj8g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v75lhj8g' target=\"_blank\">silvery-sweep-29</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v75lhj8g' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v75lhj8g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  4.341489/  3.340554, val:  36.67%, val_best:  36.67%, tr:  29.11%, tr_best:  29.11%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  4.477851/  5.522863, val:  30.00%, val_best:  36.67%, tr:  27.58%, tr_best:  29.11%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  6.110122/  5.637372, val:  30.00%, val_best:  36.67%, tr:  27.27%, tr_best:  29.11%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  8.602212/  8.027091, val:  26.25%, val_best:  36.67%, tr:  25.03%, tr_best:  29.11%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  8.558986/  7.116114, val:  23.75%, val_best:  36.67%, tr:  25.84%, tr_best:  29.11%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  7.228690/  9.296453, val:  20.00%, val_best:  36.67%, tr:  28.09%, tr_best:  29.11%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  7.248675/ 10.681976, val:  25.00%, val_best:  36.67%, tr:  26.35%, tr_best:  29.11%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 13.771871/ 15.800137, val:  17.08%, val_best:  36.67%, tr:  17.36%, tr_best:  29.11%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 16.527178/ 13.210021, val:  21.25%, val_best:  36.67%, tr:  17.67%, tr_best:  29.11%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 12.316884/ 25.682314, val:  10.00%, val_best:  36.67%, tr:  19.61%, tr_best:  29.11%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 17.320923/ 10.471684, val:  18.33%, val_best:  36.67%, tr:  13.59%, tr_best:  29.11%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 14.063461/ 13.928366, val:  17.50%, val_best:  36.67%, tr:  18.18%, tr_best:  29.11%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 12.130188/  9.759794, val:  25.00%, val_best:  36.67%, tr:  18.79%, tr_best:  29.11%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 14.670574/ 13.429181, val:  15.00%, val_best:  36.67%, tr:  20.33%, tr_best:  29.11%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 15.548183/ 22.182138, val:  12.08%, val_best:  36.67%, tr:  15.93%, tr_best:  29.11%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss: 11.487381/ 11.371516, val:  19.17%, val_best:  36.67%, tr:  17.36%, tr_best:  29.11%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss: 12.556807/ 11.854700, val:  19.58%, val_best:  36.67%, tr:  17.47%, tr_best:  29.11%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss: 13.942278/ 19.109434, val:  10.00%, val_best:  36.67%, tr:  14.40%, tr_best:  29.11%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss: 31.962278/ 19.324545, val:  10.00%, val_best:  36.67%, tr:   8.38%, tr_best:  29.11%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss: 27.736595/ 28.597601, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss: 25.131220/ 21.295610, val:  10.00%, val_best:  36.67%, tr:  10.01%, tr_best:  29.11%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss: 21.264271/ 19.189520, val:  10.00%, val_best:  36.67%, tr:   9.50%, tr_best:  29.11%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss: 23.169027/ 19.829330, val:  10.00%, val_best:  36.67%, tr:  10.21%, tr_best:  29.11%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss: 35.769020/ 26.707445, val:  10.00%, val_best:  36.67%, tr:   9.09%, tr_best:  29.11%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss: 26.700644/ 24.207529, val:  10.00%, val_best:  36.67%, tr:   8.68%, tr_best:  29.11%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss: 24.526022/ 28.701052, val:  10.00%, val_best:  36.67%, tr:  10.62%, tr_best:  29.11%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss: 28.789467/ 31.323399, val:  10.00%, val_best:  36.67%, tr:   9.81%, tr_best:  29.11%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss: 26.498852/ 26.471527, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss: 25.910816/ 21.427689, val:  10.00%, val_best:  36.67%, tr:  10.32%, tr_best:  29.11%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss: 22.888912/ 23.400436, val:  10.00%, val_best:  36.67%, tr:  10.83%, tr_best:  29.11%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss: 21.841208/ 21.428707, val:  10.00%, val_best:  36.67%, tr:  11.13%, tr_best:  29.11%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss: 24.192486/ 16.664837, val:  10.00%, val_best:  36.67%, tr:   8.99%, tr_best:  29.11%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss: 21.256662/ 23.208908, val:  10.00%, val_best:  36.67%, tr:   9.91%, tr_best:  29.11%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss: 20.217371/ 27.899836, val:  10.00%, val_best:  36.67%, tr:  11.54%, tr_best:  29.11%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss: 21.232487/  9.333352, val:  10.00%, val_best:  36.67%, tr:  10.93%, tr_best:  29.11%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss: 18.866648/ 24.679821, val:  10.00%, val_best:  36.67%, tr:  10.52%, tr_best:  29.11%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss: 24.303308/ 22.960625, val:  10.00%, val_best:  36.67%, tr:  10.42%, tr_best:  29.11%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss: 23.373899/ 45.172955, val:  10.00%, val_best:  36.67%, tr:   9.40%, tr_best:  29.11%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss: 26.025030/ 19.096960, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss: 22.397804/ 22.291906, val:  10.00%, val_best:  36.67%, tr:   7.76%, tr_best:  29.11%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss: 24.512352/ 14.815220, val:  10.00%, val_best:  36.67%, tr:  10.93%, tr_best:  29.11%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss: 17.648260/ 12.015810, val:  10.00%, val_best:  36.67%, tr:   9.91%, tr_best:  29.11%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss: 25.285286/ 16.305422, val:  10.00%, val_best:  36.67%, tr:  10.42%, tr_best:  29.11%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss: 24.805792/ 18.565287, val:  10.00%, val_best:  36.67%, tr:   9.70%, tr_best:  29.11%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss: 25.996723/ 23.947269, val:  10.00%, val_best:  36.67%, tr:  10.01%, tr_best:  29.11%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss: 25.962727/ 20.639376, val:  10.00%, val_best:  36.67%, tr:   8.07%, tr_best:  29.11%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss: 21.885180/ 30.703976, val:  10.00%, val_best:  36.67%, tr:  10.62%, tr_best:  29.11%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss: 25.108316/ 17.846342, val:  10.00%, val_best:  36.67%, tr:   9.91%, tr_best:  29.11%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss: 22.599762/ 14.328671, val:  10.00%, val_best:  36.67%, tr:   9.81%, tr_best:  29.11%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss: 24.353073/ 13.667909, val:  10.00%, val_best:  36.67%, tr:  10.42%, tr_best:  29.11%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss: 24.605427/ 37.460472, val:  10.00%, val_best:  36.67%, tr:  10.42%, tr_best:  29.11%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss: 31.332928/ 17.297544, val:  10.00%, val_best:  36.67%, tr:  10.01%, tr_best:  29.11%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss: 23.233109/ 28.897678, val:  10.00%, val_best:  36.67%, tr:   9.30%, tr_best:  29.11%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss: 24.440363/ 29.290287, val:  10.00%, val_best:  36.67%, tr:   9.40%, tr_best:  29.11%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss: 27.220160/ 27.300951, val:  10.00%, val_best:  36.67%, tr:   8.58%, tr_best:  29.11%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss: 22.891294/ 27.257402, val:  10.00%, val_best:  36.67%, tr:   9.19%, tr_best:  29.11%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss: 24.704699/ 42.023182, val:  10.00%, val_best:  36.67%, tr:  10.62%, tr_best:  29.11%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss: 30.164112/ 21.089079, val:  10.00%, val_best:  36.67%, tr:   7.25%, tr_best:  29.11%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss: 22.584431/ 16.374632, val:  10.00%, val_best:  36.67%, tr:  10.32%, tr_best:  29.11%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss: 24.586941/ 24.458210, val:  10.00%, val_best:  36.67%, tr:   8.17%, tr_best:  29.11%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss: 24.541327/ 29.316051, val:  10.00%, val_best:  36.67%, tr:   8.89%, tr_best:  29.11%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss: 26.465927/ 12.613945, val:  10.00%, val_best:  36.67%, tr:   9.50%, tr_best:  29.11%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss: 20.716568/ 29.499659, val:  10.00%, val_best:  36.67%, tr:   8.89%, tr_best:  29.11%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss: 24.511759/ 12.303993, val:  10.00%, val_best:  36.67%, tr:   8.89%, tr_best:  29.11%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss: 19.453728/ 16.680616, val:  10.00%, val_best:  36.67%, tr:   9.70%, tr_best:  29.11%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss: 21.399639/ 21.889128, val:  10.00%, val_best:  36.67%, tr:  10.83%, tr_best:  29.11%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss: 23.367256/ 29.216480, val:  10.00%, val_best:  36.67%, tr:   9.70%, tr_best:  29.11%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss: 32.424240/ 18.214128, val:  10.00%, val_best:  36.67%, tr:   9.70%, tr_best:  29.11%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss: 22.203924/ 24.761284, val:  10.00%, val_best:  36.67%, tr:  12.05%, tr_best:  29.11%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss: 22.151594/ 27.031876, val:  10.00%, val_best:  36.67%, tr:  10.93%, tr_best:  29.11%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss: 22.969017/ 14.620646, val:  10.00%, val_best:  36.67%, tr:   9.60%, tr_best:  29.11%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss: 20.901190/ 23.296146, val:  10.00%, val_best:  36.67%, tr:   9.91%, tr_best:  29.11%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss: 22.176350/ 30.372169, val:  10.00%, val_best:  36.67%, tr:  11.03%, tr_best:  29.11%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss: 28.275078/ 17.750179, val:  10.00%, val_best:  36.67%, tr:   9.60%, tr_best:  29.11%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss: 19.809366/ 32.220963, val:  10.00%, val_best:  36.67%, tr:  11.24%, tr_best:  29.11%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss: 24.047279/ 25.516882, val:  10.00%, val_best:  36.67%, tr:  11.24%, tr_best:  29.11%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss: 24.641733/ 18.218941, val:  10.00%, val_best:  36.67%, tr:   9.09%, tr_best:  29.11%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss: 27.675720/ 28.859491, val:  10.00%, val_best:  36.67%, tr:  11.75%, tr_best:  29.11%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss: 28.238852/ 11.874263, val:  10.00%, val_best:  36.67%, tr:   8.58%, tr_best:  29.11%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss: 25.274134/ 21.194464, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss: 19.369410/ 31.020954, val:  10.00%, val_best:  36.67%, tr:   8.17%, tr_best:  29.11%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss: 22.737526/ 16.830626, val:  10.00%, val_best:  36.67%, tr:   9.50%, tr_best:  29.11%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss: 25.538525/ 28.565748, val:  10.00%, val_best:  36.67%, tr:  10.21%, tr_best:  29.11%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss: 22.842360/ 18.339651, val:  10.00%, val_best:  36.67%, tr:   9.19%, tr_best:  29.11%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss: 21.707222/ 33.789322, val:  10.00%, val_best:  36.67%, tr:  11.95%, tr_best:  29.11%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss: 27.868402/ 19.681250, val:  10.00%, val_best:  36.67%, tr:   9.30%, tr_best:  29.11%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss: 20.894941/ 16.083912, val:  10.00%, val_best:  36.67%, tr:   9.60%, tr_best:  29.11%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss: 17.593418/ 17.811893, val:  10.00%, val_best:  36.67%, tr:   9.40%, tr_best:  29.11%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss: 25.444792/ 24.420296, val:  10.00%, val_best:  36.67%, tr:   8.99%, tr_best:  29.11%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss: 25.790182/ 24.623171, val:  10.00%, val_best:  36.67%, tr:  10.73%, tr_best:  29.11%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss: 20.193180/ 15.038349, val:  10.00%, val_best:  36.67%, tr:  11.75%, tr_best:  29.11%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss: 18.593262/ 32.287369, val:  10.00%, val_best:  36.67%, tr:   9.19%, tr_best:  29.11%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss: 22.737968/ 25.518307, val:  10.00%, val_best:  36.67%, tr:   9.09%, tr_best:  29.11%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss: 25.117029/ 26.067787, val:  10.00%, val_best:  36.67%, tr:  10.62%, tr_best:  29.11%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss: 26.877853/ 20.582790, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss: 25.869219/ 37.087151, val:  10.00%, val_best:  36.67%, tr:   8.38%, tr_best:  29.11%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss: 25.865177/ 34.709316, val:  10.00%, val_best:  36.67%, tr:  10.73%, tr_best:  29.11%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss: 34.681519/ 23.771708, val:  10.00%, val_best:  36.67%, tr:   9.50%, tr_best:  29.11%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss: 27.575367/ 26.965353, val:  10.00%, val_best:  36.67%, tr:  10.93%, tr_best:  29.11%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss: 24.599054/ 24.223267, val:  10.00%, val_best:  36.67%, tr:  10.11%, tr_best:  29.11%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af08a8ca31764267b2c2aebd65424f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▆▂▅▃▅▅▂▁▃▃▆▂▁▅▇▆▆▂▂▅▁▃▃▃▅▂▂▂▁▂▂▅▂▂▃▃▃▁▂</td></tr><tr><td>summary_val_acc</td><td>█▆▅▃▁▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>█▇▇▄▅▅▄▃▂▂▁▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▃▂▂▂▁▂</td></tr><tr><td>tr_epoch_loss</td><td>▁▁▂▃▃▃▄▃▆▅▆▇▅▅▄▅▅▆▆▆▆▅▆▇▆▆▅▇▅▅▆▆▆▆▅▄▆▅▆█</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>█▆▅▃▁▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▂▃▅▂▄▄▅▄▄▆▄▄▅█▄▃▄▃▃▅▅▄▅▃▄▃▃▆▅▅▄▅▆▃▅▅▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.10112</td></tr><tr><td>tr_epoch_loss</td><td>24.59905</td></tr><tr><td>val_acc_best</td><td>0.36667</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>24.22327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-sweep-29</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v75lhj8g' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/v75lhj8g</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_233434-v75lhj8g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pm39ur4k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_234048-pm39ur4k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pm39ur4k' target=\"_blank\">dashing-sweep-32</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pm39ur4k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pm39ur4k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  3.316756/  4.141489, val:  47.50%, val_best:  47.50%, tr:  34.22%, tr_best:  34.22%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  4.360225/  3.521001, val:  53.33%, val_best:  53.33%, tr:  50.26%, tr_best:  50.26%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  5.973984/  6.294258, val:  45.83%, val_best:  53.33%, tr:  48.21%, tr_best:  50.26%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  3.265098/  4.257076, val:  56.67%, val_best:  56.67%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  3.233162/  4.624830, val:  59.17%, val_best:  59.17%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.028798/  5.287341, val:  47.92%, val_best:  59.17%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.395201/  5.089060, val:  56.25%, val_best:  59.17%, tr:  70.58%, tr_best:  70.58%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.674062/  5.585132, val:  46.25%, val_best:  59.17%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.568815/  3.258400, val:  67.50%, val_best:  67.50%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.422984/  4.327792, val:  63.75%, val_best:  67.50%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.949782/  3.835498, val:  75.00%, val_best:  75.00%, tr:  83.55%, tr_best:  86.41%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.691208/  4.483513, val:  66.25%, val_best:  75.00%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.346316/  4.097012, val:  75.42%, val_best:  75.42%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.024282/  4.564316, val:  73.33%, val_best:  75.42%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.774818/  4.396730, val:  74.58%, val_best:  75.42%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.575021/  5.364604, val:  67.50%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.535292/  5.203763, val:  70.83%, val_best:  75.42%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.568586/  4.910691, val:  77.50%, val_best:  77.50%, tr:  98.26%, tr_best:  98.57%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.393467/  5.213888, val:  72.08%, val_best:  77.50%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.332989/  5.222917, val:  72.92%, val_best:  77.50%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.247146/  5.128870, val:  77.50%, val_best:  77.50%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.185738/  5.342870, val:  71.25%, val_best:  77.50%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.178074/  5.343614, val:  78.33%, val_best:  78.33%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.259622/  5.493084, val:  74.58%, val_best:  78.33%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.145023/  5.599092, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.121035/  5.689521, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.093463/  5.778791, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.072266/  5.822399, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.057303/  5.593260, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.056172/  6.086195, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.059508/  6.002454, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.036436/  6.250572, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.048890/  6.138628, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.036761/  6.316618, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.039230/  6.055773, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.052348/  6.117119, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.030076/  6.126061, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.040997/  6.101649, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.040043/  6.161480, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.035926/  6.397394, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.023548/  6.169291, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.014993/  6.235410, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.012309/  6.426147, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.012133/  6.421232, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.013094/  6.392512, val:  82.08%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.016892/  6.412228, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.020093/  6.259117, val:  80.42%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.012632/  6.313339, val:  80.42%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.015474/  6.522172, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.010824/  6.612861, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.009748/  6.570573, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.014326/  6.699367, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.017250/  6.596923, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.014748/  6.759565, val:  76.25%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.009861/  6.648010, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.012119/  6.652050, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.009251/  6.666767, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.005484/  6.537582, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.007310/  6.638224, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.007895/  6.760668, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.007521/  6.842940, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.005547/  6.747742, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.005311/  6.803447, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.004692/  6.781530, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.002373/  6.738274, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001755/  6.670802, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.003087/  6.655120, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.005766/  6.710715, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.003640/  6.648120, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001908/  6.674788, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001876/  6.603090, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001294/  6.739615, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001828/  6.645217, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001817/  6.754647, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.003798/  6.806859, val:  77.08%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.004367/  6.787225, val:  76.67%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.002540/  6.821521, val:  77.08%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.002313/  6.787111, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.002151/  6.748006, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000924/  6.816898, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.001965/  6.721474, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001229/  6.736622, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.001310/  6.658023, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.001384/  6.752011, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.001559/  6.796659, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000660/  6.779716, val:  77.08%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000762/  6.758119, val:  77.08%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000440/  6.783192, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000854/  6.755649, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.005501/  6.780681, val:  77.50%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.005743/  6.697417, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.005374/  6.680957, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.003765/  6.847821, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.002781/  6.746542, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.005734/  6.846348, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.005604/  6.729948, val:  81.25%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.005575/  6.860151, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.003185/  6.765836, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.004790/  6.895864, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.002357/  6.794359, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2e74cd564548e68b5c2336620d2229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▇▅███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▄▁▄▇▇▇▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇▇▇▇█▇▇▇▇█▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▂▄▆▇▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▅█▅▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▅▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▄▁▄▇▇▇▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇▇▇▇█▇▇▇▇█▇▇▇▇██</td></tr><tr><td>val_loss</td><td>▁▇▂▅▂▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00236</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>6.79436</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dashing-sweep-32</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pm39ur4k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pm39ur4k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_234048-pm39ur4k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4fjx5nr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11efb4ecdb534d99be5c635dfd01b1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112689521784585, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_234754-z4fjx5nr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4fjx5nr' target=\"_blank\">exalted-sweep-37</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4fjx5nr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4fjx5nr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.985349/  1.733638, val:  45.42%, val_best:  45.42%, tr:  29.32%, tr_best:  29.32%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.398307/  1.496097, val:  56.25%, val_best:  56.25%, tr:  53.12%, tr_best:  53.12%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.222399/  1.505791, val:  52.08%, val_best:  56.25%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.006532/  1.592396, val:  56.25%, val_best:  56.25%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.996130/  1.555379, val:  60.83%, val_best:  60.83%, tr:  69.25%, tr_best:  70.17%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.936145/  1.746898, val:  60.00%, val_best:  60.83%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.853186/  1.624468, val:  62.92%, val_best:  62.92%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.796388/  1.868547, val:  65.42%, val_best:  65.42%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.795579/  2.022402, val:  60.42%, val_best:  65.42%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.729596/  2.011949, val:  68.75%, val_best:  68.75%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.701395/  2.198580, val:  60.00%, val_best:  68.75%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.672080/  2.371641, val:  66.67%, val_best:  68.75%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.629694/  1.973162, val:  73.33%, val_best:  73.33%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.727262/  2.304272, val:  67.92%, val_best:  73.33%, tr:  85.70%, tr_best:  88.25%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.655475/  2.579738, val:  67.92%, val_best:  73.33%, tr:  87.44%, tr_best:  88.25%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.522325/  2.620220, val:  67.92%, val_best:  73.33%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.498992/  2.947643, val:  62.50%, val_best:  73.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.560431/  2.688690, val:  70.83%, val_best:  73.33%, tr:  93.56%, tr_best:  93.77%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.515893/  2.745654, val:  67.50%, val_best:  73.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.617749/  2.963565, val:  70.42%, val_best:  73.33%, tr:  90.91%, tr_best:  93.87%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.538706/  3.221174, val:  66.25%, val_best:  73.33%, tr:  93.56%, tr_best:  93.87%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.536883/  3.287714, val:  64.17%, val_best:  73.33%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.555787/  3.296501, val:  69.17%, val_best:  73.33%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.576125/  3.123663, val:  67.50%, val_best:  73.33%, tr:  94.28%, tr_best:  95.20%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.565499/  3.172324, val:  65.42%, val_best:  73.33%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.537680/  3.358525, val:  70.83%, val_best:  73.33%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.649637/  3.326576, val:  71.67%, val_best:  73.33%, tr:  93.26%, tr_best:  95.40%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.675080/  3.482909, val:  69.17%, val_best:  73.33%, tr:  94.69%, tr_best:  95.40%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.646995/  3.225098, val:  74.17%, val_best:  74.17%, tr:  94.28%, tr_best:  95.40%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.520656/  3.097301, val:  70.83%, val_best:  74.17%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.549722/  3.276672, val:  68.75%, val_best:  74.17%, tr:  95.40%, tr_best:  95.91%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.498904/  3.580616, val:  69.58%, val_best:  74.17%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.691687/  3.910671, val:  68.33%, val_best:  74.17%, tr:  94.89%, tr_best:  96.22%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.756674/  3.474791, val:  68.33%, val_best:  74.17%, tr:  93.56%, tr_best:  96.22%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.762618/  3.842449, val:  60.00%, val_best:  74.17%, tr:  92.85%, tr_best:  96.22%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.595637/  3.184812, val:  72.08%, val_best:  74.17%, tr:  95.51%, tr_best:  96.22%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.557377/  3.354152, val:  72.50%, val_best:  74.17%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.706061/  3.627607, val:  59.17%, val_best:  74.17%, tr:  94.59%, tr_best:  96.83%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.631388/  4.051785, val:  67.92%, val_best:  74.17%, tr:  94.89%, tr_best:  96.83%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.643489/  3.260007, val:  74.58%, val_best:  74.58%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.924418/  4.008210, val:  70.00%, val_best:  74.58%, tr:  91.32%, tr_best:  96.83%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.822087/  3.691881, val:  66.67%, val_best:  74.58%, tr:  93.46%, tr_best:  96.83%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.913824/  3.803084, val:  68.75%, val_best:  74.58%, tr:  91.32%, tr_best:  96.83%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.847850/  3.550384, val:  74.58%, val_best:  74.58%, tr:  94.48%, tr_best:  96.83%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.865344/  3.668455, val:  66.67%, val_best:  74.58%, tr:  92.65%, tr_best:  96.83%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.879969/  3.591989, val:  72.50%, val_best:  74.58%, tr:  92.44%, tr_best:  96.83%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.839499/  3.693306, val:  69.58%, val_best:  74.58%, tr:  93.97%, tr_best:  96.83%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.937497/  4.032023, val:  64.58%, val_best:  74.58%, tr:  93.87%, tr_best:  96.83%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  1.060560/  3.544331, val:  72.92%, val_best:  74.58%, tr:  92.24%, tr_best:  96.83%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.939662/  3.848604, val:  67.92%, val_best:  74.58%, tr:  94.59%, tr_best:  96.83%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  1.138578/  4.495511, val:  61.67%, val_best:  74.58%, tr:  90.09%, tr_best:  96.83%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  1.221273/  3.973132, val:  70.42%, val_best:  74.58%, tr:  88.25%, tr_best:  96.83%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  1.088329/  3.653749, val:  70.83%, val_best:  74.58%, tr:  90.60%, tr_best:  96.83%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  1.140303/  3.806358, val:  75.42%, val_best:  75.42%, tr:  90.60%, tr_best:  96.83%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  1.172587/  3.708661, val:  68.33%, val_best:  75.42%, tr:  91.01%, tr_best:  96.83%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  1.036266/  4.059585, val:  62.92%, val_best:  75.42%, tr:  92.54%, tr_best:  96.83%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  1.189778/  3.843315, val:  68.33%, val_best:  75.42%, tr:  88.76%, tr_best:  96.83%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  1.185642/  3.974883, val:  67.92%, val_best:  75.42%, tr:  89.99%, tr_best:  96.83%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  1.101627/  3.785656, val:  70.00%, val_best:  75.42%, tr:  89.99%, tr_best:  96.83%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  1.115891/  3.855525, val:  70.00%, val_best:  75.42%, tr:  92.75%, tr_best:  96.83%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  1.117545/  4.552092, val:  55.83%, val_best:  75.42%, tr:  91.83%, tr_best:  96.83%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  1.306247/  4.001309, val:  66.25%, val_best:  75.42%, tr:  88.25%, tr_best:  96.83%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  1.255026/  3.811982, val:  70.42%, val_best:  75.42%, tr:  88.56%, tr_best:  96.83%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  1.334257/  4.660064, val:  59.58%, val_best:  75.42%, tr:  90.50%, tr_best:  96.83%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  1.456083/  4.421160, val:  64.17%, val_best:  75.42%, tr:  87.23%, tr_best:  96.83%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  1.721361/  4.172081, val:  66.25%, val_best:  75.42%, tr:  83.55%, tr_best:  96.83%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  1.420030/  4.211758, val:  67.08%, val_best:  75.42%, tr:  89.38%, tr_best:  96.83%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  1.618986/  4.264518, val:  67.50%, val_best:  75.42%, tr:  86.21%, tr_best:  96.83%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  1.605655/  4.117102, val:  67.92%, val_best:  75.42%, tr:  86.82%, tr_best:  96.83%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  1.427305/  4.832917, val:  58.75%, val_best:  75.42%, tr:  87.33%, tr_best:  96.83%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  1.528200/  4.204572, val:  61.25%, val_best:  75.42%, tr:  85.60%, tr_best:  96.83%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  1.641245/  4.331004, val:  58.75%, val_best:  75.42%, tr:  85.50%, tr_best:  96.83%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  2.057934/  4.712230, val:  62.08%, val_best:  75.42%, tr:  81.92%, tr_best:  96.83%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  2.298699/  4.383735, val:  67.92%, val_best:  75.42%, tr:  79.78%, tr_best:  96.83%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  2.039080/  4.735174, val:  60.83%, val_best:  75.42%, tr:  81.10%, tr_best:  96.83%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  1.722984/  4.142481, val:  67.08%, val_best:  75.42%, tr:  85.29%, tr_best:  96.83%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  1.713573/  4.008307, val:  66.25%, val_best:  75.42%, tr:  85.29%, tr_best:  96.83%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  1.869796/  5.170259, val:  50.42%, val_best:  75.42%, tr:  83.76%, tr_best:  96.83%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  2.429734/  4.671046, val:  59.17%, val_best:  75.42%, tr:  79.37%, tr_best:  96.83%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  1.698848/  4.451752, val:  65.83%, val_best:  75.42%, tr:  83.86%, tr_best:  96.83%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  1.580457/  3.517822, val:  69.58%, val_best:  75.42%, tr:  88.97%, tr_best:  96.83%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  1.692259/  4.722169, val:  58.75%, val_best:  75.42%, tr:  86.41%, tr_best:  96.83%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  1.964451/  5.532954, val:  60.00%, val_best:  75.42%, tr:  81.61%, tr_best:  96.83%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  2.388198/  4.620376, val:  64.58%, val_best:  75.42%, tr:  78.86%, tr_best:  96.83%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  2.189670/  5.090715, val:  64.17%, val_best:  75.42%, tr:  79.16%, tr_best:  96.83%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  2.331809/  4.456367, val:  57.08%, val_best:  75.42%, tr:  77.94%, tr_best:  96.83%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  2.233953/  4.866683, val:  55.83%, val_best:  75.42%, tr:  76.20%, tr_best:  96.83%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  2.171391/  4.615179, val:  66.67%, val_best:  75.42%, tr:  76.30%, tr_best:  96.83%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  1.861907/  3.959905, val:  64.58%, val_best:  75.42%, tr:  80.18%, tr_best:  96.83%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  2.092822/  5.184809, val:  50.42%, val_best:  75.42%, tr:  79.06%, tr_best:  96.83%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  1.805634/  4.172594, val:  58.75%, val_best:  75.42%, tr:  82.43%, tr_best:  96.83%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  1.962430/  6.059251, val:  46.25%, val_best:  75.42%, tr:  79.98%, tr_best:  96.83%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  2.171699/  4.933104, val:  59.58%, val_best:  75.42%, tr:  81.21%, tr_best:  96.83%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  2.630682/  4.161782, val:  63.33%, val_best:  75.42%, tr:  73.75%, tr_best:  96.83%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  2.728989/  5.772254, val:  53.75%, val_best:  75.42%, tr:  73.14%, tr_best:  96.83%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  2.574399/  4.638311, val:  55.42%, val_best:  75.42%, tr:  71.91%, tr_best:  96.83%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  2.931110/  5.188769, val:  45.42%, val_best:  75.42%, tr:  65.27%, tr_best:  96.83%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  2.038223/  4.859730, val:  55.83%, val_best:  75.42%, tr:  79.57%, tr_best:  96.83%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  2.139771/  4.620495, val:  56.25%, val_best:  75.42%, tr:  77.22%, tr_best:  96.83%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  2.350519/  4.850551, val:  54.58%, val_best:  75.42%, tr:  77.02%, tr_best:  96.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d4b61ef5424005a75baddd4e6e8b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▄▅▆▇▅██████▇▇▆▇▇▆▇▇▇█▆▆▇▇▇▄▇▇▇▆▇▇▅▅▅▄</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▇█▆▇▇▅▆▇▇▆▇▄█▇▆▆▆▇▆▆▇▆▆▆▅▅▆▂▆▅▅▆▂▄▃▃</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█▇████████▇███▇▇▇█▇▇▇▇▇▇▇▇▆▆▆▆▆▅▆</td></tr><tr><td>tr_epoch_loss</td><td>▆▃▃▂▂▁▁▁▁▁▁▁▁▂▁▂▁▂▂▂▂▃▃▃▃▄▅▅▄▆▅▆▅▆▇▇▆▇█▆</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▇█▆▇▇▅▆▇▇▆▇▄█▇▆▆▆▇▆▆▇▆▆▆▅▅▆▂▆▅▅▆▂▄▃▃</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▂▃▃▄▄▄▄▄▅▄▅▄▅▅▅▅▅▅▅▅▅▆▆▆▇▆▇▆█▇▆▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.66667</td></tr><tr><td>tr_acc</td><td>0.77017</td></tr><tr><td>tr_epoch_loss</td><td>2.35052</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.54583</td></tr><tr><td>val_loss</td><td>4.85055</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-37</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4fjx5nr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z4fjx5nr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_234754-z4fjx5nr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c84ui2u7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_235419-c84ui2u7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c84ui2u7' target=\"_blank\">classic-sweep-40</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c84ui2u7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c84ui2u7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.273478/  3.501319, val:  28.33%, val_best:  28.33%, tr:  25.43%, tr_best:  25.43%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  3.878482/  5.025558, val:  24.58%, val_best:  28.33%, tr:  27.27%, tr_best:  27.27%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  4.423460/  5.348520, val:  16.67%, val_best:  28.33%, tr:  32.99%, tr_best:  32.99%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  5.168913/  4.314217, val:  41.67%, val_best:  41.67%, tr:  31.66%, tr_best:  32.99%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  5.161928/  7.024266, val:  37.50%, val_best:  41.67%, tr:  36.06%, tr_best:  36.06%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  6.058775/  9.158151, val:  35.42%, val_best:  41.67%, tr:  37.69%, tr_best:  37.69%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  4.210918/  7.593858, val:  34.58%, val_best:  41.67%, tr:  41.27%, tr_best:  41.27%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  8.501784/  8.564407, val:  29.58%, val_best:  41.67%, tr:  36.26%, tr_best:  41.27%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  7.073157/ 13.398521, val:  22.08%, val_best:  41.67%, tr:  36.87%, tr_best:  41.27%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  8.109832/ 14.601402, val:  25.42%, val_best:  41.67%, tr:  37.39%, tr_best:  41.27%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 10.289981/ 12.428533, val:  27.92%, val_best:  41.67%, tr:  36.98%, tr_best:  41.27%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  7.969508/ 13.351978, val:  30.83%, val_best:  41.67%, tr:  40.35%, tr_best:  41.27%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 12.382495/ 11.907524, val:  36.25%, val_best:  41.67%, tr:  35.34%, tr_best:  41.27%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 12.105273/ 11.644164, val:  36.25%, val_best:  41.67%, tr:  34.83%, tr_best:  41.27%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 12.299967/ 13.911760, val:  31.67%, val_best:  41.67%, tr:  32.28%, tr_best:  41.27%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss: 10.065510/ 14.552611, val:  24.58%, val_best:  41.67%, tr:  36.16%, tr_best:  41.27%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss: 12.479812/ 17.262068, val:  33.33%, val_best:  41.67%, tr:  33.40%, tr_best:  41.27%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss: 12.076916/ 13.902103, val:  34.17%, val_best:  41.67%, tr:  29.83%, tr_best:  41.27%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss: 14.784658/ 11.158044, val:  33.33%, val_best:  41.67%, tr:  31.15%, tr_best:  41.27%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss: 13.639288/ 13.525715, val:  28.75%, val_best:  41.67%, tr:  36.26%, tr_best:  41.27%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss: 11.577469/ 14.586602, val:  39.58%, val_best:  41.67%, tr:  41.57%, tr_best:  41.57%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss: 10.524488/  9.809331, val:  41.25%, val_best:  41.67%, tr:  42.49%, tr_best:  42.49%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  9.673385/ 12.946482, val:  38.75%, val_best:  41.67%, tr:  41.27%, tr_best:  42.49%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  9.267118/  9.501547, val:  39.17%, val_best:  41.67%, tr:  44.33%, tr_best:  44.33%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss: 10.373666/ 14.046008, val:  30.42%, val_best:  41.67%, tr:  42.59%, tr_best:  44.33%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss: 10.394751/ 12.678199, val:  37.92%, val_best:  41.67%, tr:  40.76%, tr_best:  44.33%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  9.671377/  7.431512, val:  38.75%, val_best:  41.67%, tr:  39.43%, tr_best:  44.33%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss: 11.318282/ 16.809896, val:  32.50%, val_best:  41.67%, tr:  37.28%, tr_best:  44.33%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss: 11.080385/ 10.575382, val:  40.42%, val_best:  41.67%, tr:  42.39%, tr_best:  44.33%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  9.638821/ 11.993932, val:  32.50%, val_best:  41.67%, tr:  42.08%, tr_best:  44.33%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  8.848970/ 13.904287, val:  34.58%, val_best:  41.67%, tr:  41.57%, tr_best:  44.33%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  9.551083/ 14.741291, val:  30.83%, val_best:  41.67%, tr:  43.51%, tr_best:  44.33%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss: 11.616903/ 18.585457, val:  35.83%, val_best:  41.67%, tr:  44.84%, tr_best:  44.84%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss: 10.792888/ 13.325932, val:  34.58%, val_best:  41.67%, tr:  43.82%, tr_best:  44.84%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss: 13.515451/ 12.431062, val:  41.25%, val_best:  41.67%, tr:  41.16%, tr_best:  44.84%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss: 11.193770/  9.079037, val:  35.83%, val_best:  41.67%, tr:  44.43%, tr_best:  44.84%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss: 11.614613/ 14.106089, val:  46.67%, val_best:  46.67%, tr:  42.59%, tr_best:  44.84%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss: 12.444290/ 17.440828, val:  42.08%, val_best:  46.67%, tr:  40.14%, tr_best:  44.84%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss: 11.728851/  9.586878, val:  42.08%, val_best:  46.67%, tr:  42.39%, tr_best:  44.84%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  8.733560/  9.915417, val:  45.83%, val_best:  46.67%, tr:  43.72%, tr_best:  44.84%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  7.319438/  9.769965, val:  41.25%, val_best:  46.67%, tr:  45.76%, tr_best:  45.76%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  9.545300/  9.340841, val:  37.50%, val_best:  46.67%, tr:  43.41%, tr_best:  45.76%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss: 12.627048/ 11.763712, val:  42.92%, val_best:  46.67%, tr:  39.63%, tr_best:  45.76%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss: 11.108183/ 11.538143, val:  43.75%, val_best:  46.67%, tr:  41.78%, tr_best:  45.76%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss: 10.308564/ 15.384865, val:  26.25%, val_best:  46.67%, tr:  40.35%, tr_best:  45.76%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  9.546873/  9.624394, val:  37.92%, val_best:  46.67%, tr:  43.21%, tr_best:  45.76%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  9.990623/ 12.420906, val:  45.00%, val_best:  46.67%, tr:  45.86%, tr_best:  45.86%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  8.893847/ 12.290301, val:  42.50%, val_best:  46.67%, tr:  46.58%, tr_best:  46.58%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss: 10.487254/  8.701092, val:  37.08%, val_best:  46.67%, tr:  41.37%, tr_best:  46.58%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  8.828194/ 11.138186, val:  36.67%, val_best:  46.67%, tr:  44.13%, tr_best:  46.58%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  8.054749/ 14.765096, val:  37.50%, val_best:  46.67%, tr:  45.25%, tr_best:  46.58%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss: 10.319741/  9.138455, val:  40.00%, val_best:  46.67%, tr:  46.88%, tr_best:  46.88%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  7.801771/ 10.255517, val:  43.33%, val_best:  46.67%, tr:  47.70%, tr_best:  47.70%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  8.250427/ 12.217503, val:  45.42%, val_best:  46.67%, tr:  45.86%, tr_best:  47.70%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  9.025405/  9.110903, val:  38.33%, val_best:  46.67%, tr:  47.09%, tr_best:  47.70%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  9.461961/  6.801466, val:  51.67%, val_best:  51.67%, tr:  46.58%, tr_best:  47.70%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss: 10.191148/ 19.935184, val:  35.42%, val_best:  51.67%, tr:  44.84%, tr_best:  47.70%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss: 10.086790/ 14.262451, val:  37.50%, val_best:  51.67%, tr:  44.64%, tr_best:  47.70%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  7.991282/  9.650263, val:  45.00%, val_best:  51.67%, tr:  49.64%, tr_best:  49.64%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  9.414505/ 15.747430, val:  29.58%, val_best:  51.67%, tr:  46.17%, tr_best:  49.64%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  9.575210/ 13.797174, val:  37.92%, val_best:  51.67%, tr:  47.50%, tr_best:  49.64%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  9.084397/  8.672870, val:  51.25%, val_best:  51.67%, tr:  49.13%, tr_best:  49.64%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  9.501090/ 10.179188, val:  44.58%, val_best:  51.67%, tr:  42.80%, tr_best:  49.64%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  9.549262/ 10.768023, val:  40.83%, val_best:  51.67%, tr:  46.37%, tr_best:  49.64%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  9.133356/ 12.129815, val:  42.92%, val_best:  51.67%, tr:  47.19%, tr_best:  49.64%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  9.776223/ 14.135462, val:  40.42%, val_best:  51.67%, tr:  47.60%, tr_best:  49.64%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss: 10.167132/ 12.843537, val:  38.75%, val_best:  51.67%, tr:  46.99%, tr_best:  49.64%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  8.932405/ 11.189029, val:  40.42%, val_best:  51.67%, tr:  47.91%, tr_best:  49.64%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  9.135067/ 10.601410, val:  38.75%, val_best:  51.67%, tr:  44.54%, tr_best:  49.64%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  9.405394/ 12.886469, val:  35.83%, val_best:  51.67%, tr:  45.45%, tr_best:  49.64%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  9.274858/ 13.329993, val:  45.00%, val_best:  51.67%, tr:  47.60%, tr_best:  49.64%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  8.398684/ 13.891259, val:  39.58%, val_best:  51.67%, tr:  44.33%, tr_best:  49.64%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss: 10.381019/ 13.745582, val:  46.67%, val_best:  51.67%, tr:  44.02%, tr_best:  49.64%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  9.281774/ 10.614270, val:  38.33%, val_best:  51.67%, tr:  49.74%, tr_best:  49.74%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  9.119179/ 15.185339, val:  44.58%, val_best:  51.67%, tr:  48.52%, tr_best:  49.74%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss: 13.085968/ 13.624697, val:  39.17%, val_best:  51.67%, tr:  44.64%, tr_best:  49.74%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  9.302428/  6.569491, val:  47.92%, val_best:  51.67%, tr:  45.86%, tr_best:  49.74%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  7.325040/ 16.679190, val:  38.33%, val_best:  51.67%, tr:  51.17%, tr_best:  51.17%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss: 14.198846/ 16.788696, val:  30.00%, val_best:  51.67%, tr:  41.06%, tr_best:  51.17%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  8.674291/ 11.394933, val:  42.92%, val_best:  51.67%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss: 11.075210/  9.431187, val:  30.00%, val_best:  51.67%, tr:  40.76%, tr_best:  52.81%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss: 12.948334/ 18.900229, val:  36.25%, val_best:  51.67%, tr:  40.14%, tr_best:  52.81%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss: 11.212237/ 14.209888, val:  44.17%, val_best:  51.67%, tr:  44.02%, tr_best:  52.81%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  7.505864/  7.844725, val:  41.67%, val_best:  51.67%, tr:  46.88%, tr_best:  52.81%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss: 10.017816/ 14.303423, val:  33.75%, val_best:  51.67%, tr:  46.68%, tr_best:  52.81%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss: 10.236113/ 13.126998, val:  32.92%, val_best:  51.67%, tr:  44.94%, tr_best:  52.81%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  8.638928/  8.168540, val:  37.50%, val_best:  51.67%, tr:  46.58%, tr_best:  52.81%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  7.954512/ 18.855787, val:  31.25%, val_best:  51.67%, tr:  49.95%, tr_best:  52.81%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  8.324842/ 15.322034, val:  43.33%, val_best:  51.67%, tr:  50.26%, tr_best:  52.81%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  9.475022/ 10.123277, val:  46.25%, val_best:  51.67%, tr:  48.21%, tr_best:  52.81%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  9.089842/ 10.341191, val:  43.75%, val_best:  51.67%, tr:  49.95%, tr_best:  52.81%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  8.709056/ 11.387613, val:  30.00%, val_best:  51.67%, tr:  50.05%, tr_best:  52.81%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  7.866370/  8.502552, val:  45.00%, val_best:  51.67%, tr:  47.60%, tr_best:  52.81%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  7.503314/ 10.722962, val:  43.33%, val_best:  51.67%, tr:  51.28%, tr_best:  52.81%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  7.752001/ 11.592701, val:  43.33%, val_best:  51.67%, tr:  47.91%, tr_best:  52.81%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  8.433362/ 12.852553, val:  42.08%, val_best:  51.67%, tr:  50.87%, tr_best:  52.81%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  8.085262/ 12.007446, val:  44.58%, val_best:  51.67%, tr:  49.44%, tr_best:  52.81%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  7.712291/ 14.076673, val:  42.08%, val_best:  51.67%, tr:  51.89%, tr_best:  52.81%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss: 11.119958/  7.990883, val:  38.75%, val_best:  51.67%, tr:  48.72%, tr_best:  52.81%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  9.534573/ 10.303762, val:  40.42%, val_best:  51.67%, tr:  50.15%, tr_best:  52.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615cac5030774ae0afbca232e7da44a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▄▁▁▃▆▂▃▂▃▆▅▄▆▂▇▅▃▃▅▅▅█▄▅▇▅▂▃▅▄█▆▆▅▅▅▄▂▃▂</td></tr><tr><td>summary_val_acc</td><td>▃▁▅▄▃▅▄▅▃▆▄▅▄▅▅▆▇▆▃▆▅▆▅▅▄█▆▆▇▇▆▅▆▇▄▄▇▇▆▆</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▄▄▃▂▄▅▅▅▅▆▆▅▆▅▅▆▆▇▇▆▆▇▇▇▇▆▆██▆▆▇▇▇██</td></tr><tr><td>tr_epoch_loss</td><td>▁▂▃▅▅▇▇▇█▆▆▆▆▇▆▇▅▇▆▅▅▄▅▆▅▅▆▅▅▆█▄▅▇▆▄▅▄▅▄</td></tr><tr><td>val_acc_best</td><td>▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▃▁▅▄▃▅▄▅▃▆▄▅▄▅▅▆▇▆▃▆▅▆▅▅▄█▆▆▇▇▆▅▆▇▄▄▇▇▆▆</td></tr><tr><td>val_loss</td><td>▁▂▃▃▆▅▆▆▆▄▆▃▅█▄▇▄▅▆▅▄▄▄▆▇▃▆▅▅▆▆▇▅▆▆█▄▃▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.50153</td></tr><tr><td>tr_epoch_loss</td><td>9.53457</td></tr><tr><td>val_acc_best</td><td>0.51667</td></tr><tr><td>val_acc_now</td><td>0.40417</td></tr><tr><td>val_loss</td><td>10.30376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-40</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c84ui2u7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c84ui2u7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_235419-c84ui2u7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: phekb5p0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_000032-phekb5p0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/phekb5p0' target=\"_blank\">glad-sweep-44</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/phekb5p0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/phekb5p0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.007849/  1.565417, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.323269/  1.429568, val:  51.67%, val_best:  51.67%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.173709/  1.400553, val:  54.58%, val_best:  54.58%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.036636/  1.405511, val:  57.50%, val_best:  57.50%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.970302/  1.303158, val:  59.58%, val_best:  59.58%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.928441/  1.256284, val:  65.00%, val_best:  65.00%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.861428/  1.253414, val:  62.50%, val_best:  65.00%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.836347/  1.306047, val:  65.83%, val_best:  65.83%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.805460/  1.322491, val:  67.08%, val_best:  67.08%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.768022/  1.416504, val:  59.58%, val_best:  67.08%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.744346/  1.486244, val:  60.42%, val_best:  67.08%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.669890/  1.329080, val:  70.00%, val_best:  70.00%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.646208/  1.378895, val:  70.42%, val_best:  70.42%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.606187/  1.414698, val:  69.17%, val_best:  70.42%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.567097/  1.579422, val:  65.00%, val_best:  70.42%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.537657/  1.572292, val:  65.42%, val_best:  70.42%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.539513/  1.532057, val:  67.50%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.498677/  1.614767, val:  68.75%, val_best:  70.42%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.491463/  1.765510, val:  63.33%, val_best:  70.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.483969/  1.753350, val:  67.08%, val_best:  70.42%, tr:  94.28%, tr_best:  95.81%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.461769/  1.828582, val:  62.08%, val_best:  70.42%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.444924/  1.824708, val:  65.83%, val_best:  70.42%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.440916/  1.948393, val:  62.50%, val_best:  70.42%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.416775/  1.950535, val:  65.00%, val_best:  70.42%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.399946/  1.958265, val:  65.42%, val_best:  70.42%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.375480/  1.995910, val:  68.75%, val_best:  70.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.403844/  2.093623, val:  66.67%, val_best:  70.42%, tr:  96.83%, tr_best:  98.67%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.368805/  2.186205, val:  62.92%, val_best:  70.42%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.353746/  2.171611, val:  69.58%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.334615/  2.291924, val:  63.75%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.334122/  2.299945, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.321587/  2.362353, val:  65.83%, val_best:  70.42%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.322405/  2.365868, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.311590/  2.399657, val:  65.42%, val_best:  70.42%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.293704/  2.524293, val:  65.83%, val_best:  70.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.309601/  2.526775, val:  66.67%, val_best:  70.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.288224/  2.536476, val:  66.25%, val_best:  70.42%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.263717/  2.614729, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.270008/  2.624046, val:  65.00%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.261669/  2.688289, val:  65.83%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.264950/  2.775618, val:  68.33%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.258720/  2.788832, val:  64.17%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.242871/  2.798048, val:  67.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.260693/  2.903164, val:  66.25%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.242125/  2.964726, val:  67.08%, val_best:  70.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.232564/  2.963949, val:  67.08%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.235766/  2.995975, val:  65.00%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.225573/  3.150798, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.238496/  3.039989, val:  68.33%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.242544/  3.205051, val:  67.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.209145/  3.268563, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.225158/  3.221506, val:  66.25%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.202298/  3.317571, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.191598/  3.337388, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.184830/  3.405065, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.185530/  3.464525, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.189409/  3.502273, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.187915/  3.549896, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.176732/  3.600696, val:  67.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.174016/  3.684161, val:  65.42%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.163204/  3.649122, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.158698/  3.731511, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.162408/  3.728475, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.157262/  3.812711, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.175734/  3.844702, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.152366/  3.850598, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.156215/  3.892855, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.154331/  3.954949, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.156970/  4.056862, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.183809/  3.969005, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.147863/  4.077610, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.160372/  4.054020, val:  66.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.150239/  4.171999, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.155237/  4.144114, val:  63.33%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.142051/  4.176569, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.148744/  4.203733, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.161937/  4.255033, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.150938/  4.327878, val:  62.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.139610/  4.340270, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.126764/  4.405076, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.127919/  4.461441, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.139615/  4.435988, val:  61.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.143295/  4.514951, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.132169/  4.514896, val:  66.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.143847/  4.481551, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.137505/  4.529276, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.136991/  4.590755, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.143691/  4.633200, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.134788/  4.644016, val:  62.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.137480/  4.649119, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.130925/  4.668377, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.127290/  4.753328, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.120203/  4.760028, val:  61.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.130869/  4.769228, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.135882/  4.856189, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.143449/  4.871269, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.143305/  4.943291, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.127994/  4.900231, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.131795/  4.882963, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.157396/  4.994504, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b83c9caeef7456c939eb155750f4342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▃▃▃▇▆▆▇█████▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.1574</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>4.9945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glad-sweep-44</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/phekb5p0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/phekb5p0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_000032-phekb5p0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wgzqoytc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_000730-wgzqoytc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wgzqoytc' target=\"_blank\">apricot-sweep-48</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wgzqoytc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wgzqoytc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.096365/  1.688264, val:  43.33%, val_best:  43.33%, tr:  23.19%, tr_best:  23.19%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.389252/  1.384813, val:  53.75%, val_best:  53.75%, tr:  51.07%, tr_best:  51.07%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.184351/  1.347393, val:  55.00%, val_best:  55.00%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.051598/  1.302646, val:  57.92%, val_best:  57.92%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.995081/  1.252804, val:  62.50%, val_best:  62.50%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.926829/  1.184545, val:  65.00%, val_best:  65.00%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.862326/  1.193647, val:  62.50%, val_best:  65.00%, tr:  72.22%, tr_best:  72.22%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.842360/  1.159939, val:  68.33%, val_best:  68.33%, tr:  72.22%, tr_best:  72.22%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.796962/  1.203555, val:  66.67%, val_best:  68.33%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.767834/  1.200961, val:  65.42%, val_best:  68.33%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.737384/  1.203692, val:  67.50%, val_best:  68.33%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.681041/  1.155904, val:  67.50%, val_best:  68.33%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.665237/  1.185338, val:  65.83%, val_best:  68.33%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.626655/  1.197531, val:  66.67%, val_best:  68.33%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.580990/  1.308371, val:  68.33%, val_best:  68.33%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.559006/  1.233443, val:  66.67%, val_best:  68.33%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.556659/  1.190308, val:  69.58%, val_best:  69.58%, tr:  90.19%, tr_best:  90.70%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.505302/  1.230679, val:  72.08%, val_best:  72.08%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.485373/  1.299513, val:  67.50%, val_best:  72.08%, tr:  93.05%, tr_best:  93.97%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.466733/  1.303758, val:  69.17%, val_best:  72.08%, tr:  93.67%, tr_best:  93.97%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.436730/  1.342858, val:  66.25%, val_best:  72.08%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.422721/  1.317278, val:  69.17%, val_best:  72.08%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.410929/  1.356433, val:  68.75%, val_best:  72.08%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.372549/  1.335867, val:  69.17%, val_best:  72.08%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.358182/  1.370269, val:  68.75%, val_best:  72.08%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.344699/  1.370218, val:  72.92%, val_best:  72.92%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.347535/  1.388888, val:  70.42%, val_best:  72.92%, tr:  97.14%, tr_best:  97.85%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.322647/  1.439121, val:  69.58%, val_best:  72.92%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.314927/  1.411328, val:  70.00%, val_best:  72.92%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.285887/  1.477629, val:  68.33%, val_best:  72.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.279349/  1.458001, val:  68.75%, val_best:  72.92%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.286952/  1.494862, val:  68.75%, val_best:  72.92%, tr:  98.47%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.270962/  1.524939, val:  67.50%, val_best:  72.92%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.269499/  1.514831, val:  69.17%, val_best:  72.92%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.252215/  1.581342, val:  68.75%, val_best:  72.92%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.242164/  1.568850, val:  69.17%, val_best:  72.92%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.228877/  1.581722, val:  67.50%, val_best:  72.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.223357/  1.591442, val:  67.92%, val_best:  72.92%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.217050/  1.598611, val:  69.17%, val_best:  72.92%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.213783/  1.608906, val:  66.67%, val_best:  72.92%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.208168/  1.671572, val:  69.58%, val_best:  72.92%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.199950/  1.633635, val:  66.67%, val_best:  72.92%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.185023/  1.641978, val:  70.00%, val_best:  72.92%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.186826/  1.692425, val:  69.17%, val_best:  72.92%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.180465/  1.708556, val:  66.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.178749/  1.731124, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.167431/  1.705968, val:  70.00%, val_best:  72.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.165977/  1.751282, val:  67.08%, val_best:  72.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.162515/  1.744860, val:  69.17%, val_best:  72.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.158322/  1.774692, val:  69.58%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.150045/  1.776951, val:  68.33%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.143362/  1.791831, val:  68.75%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.139648/  1.816634, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.141355/  1.826259, val:  66.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.135453/  1.847842, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.132005/  1.860809, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.133055/  1.880043, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.131166/  1.862128, val:  70.00%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.123531/  1.883139, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.118753/  1.908311, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.115862/  1.896554, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.112345/  1.922608, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.112858/  1.930872, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.109101/  1.948940, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.108428/  1.971201, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.104360/  1.981997, val:  67.92%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.104979/  1.976629, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.106244/  1.985484, val:  70.42%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.102793/  2.005620, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.093526/  1.988076, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.093207/  2.035943, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.096443/  2.059654, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.093367/  2.075736, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.091406/  2.048986, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.086811/  2.085277, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.086958/  2.082992, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.081363/  2.129710, val:  67.92%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.083501/  2.127474, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.085787/  2.148686, val:  71.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.079094/  2.122459, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.077656/  2.141081, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.074756/  2.167583, val:  70.42%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.072056/  2.200853, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.072664/  2.196260, val:  70.00%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.068418/  2.200985, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.067842/  2.220386, val:  70.83%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.067362/  2.249296, val:  70.42%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.065227/  2.258197, val:  69.58%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.065110/  2.230285, val:  70.00%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.065240/  2.258317, val:  70.83%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.067795/  2.263763, val:  71.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.061886/  2.284948, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.058316/  2.299478, val:  68.33%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.059366/  2.305413, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.059283/  2.324261, val:  70.83%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.057787/  2.335938, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.057244/  2.369798, val:  70.83%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.058950/  2.335558, val:  70.42%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.057356/  2.346309, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.061150/  2.374038, val:  70.83%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8fbca9c6dc4ec48b66a5b0f4eabe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▄▅▅▆▄▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▇▆▆▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▇▆▆▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇█</td></tr><tr><td>val_loss</td><td>▄▂▂▁▁▁▂▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.06115</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.70833</td></tr><tr><td>val_loss</td><td>2.37404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-48</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wgzqoytc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wgzqoytc</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_000730-wgzqoytc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l598014e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5298a67cd4a42b2af0329ba72edc9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112609754006068, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_001437-l598014e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l598014e' target=\"_blank\">spring-sweep-52</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l598014e' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l598014e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.007849/  1.565417, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.323269/  1.429568, val:  51.67%, val_best:  51.67%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.173709/  1.400553, val:  54.58%, val_best:  54.58%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.036636/  1.405511, val:  57.50%, val_best:  57.50%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.970302/  1.303158, val:  59.58%, val_best:  59.58%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.928441/  1.256284, val:  65.00%, val_best:  65.00%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.861428/  1.253414, val:  62.50%, val_best:  65.00%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.836347/  1.306047, val:  65.83%, val_best:  65.83%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.805460/  1.322491, val:  67.08%, val_best:  67.08%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.768022/  1.416504, val:  59.58%, val_best:  67.08%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.744346/  1.486244, val:  60.42%, val_best:  67.08%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.669890/  1.329080, val:  70.00%, val_best:  70.00%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.646208/  1.378895, val:  70.42%, val_best:  70.42%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.606187/  1.414698, val:  69.17%, val_best:  70.42%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.567097/  1.579422, val:  65.00%, val_best:  70.42%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.537657/  1.572292, val:  65.42%, val_best:  70.42%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.539513/  1.532057, val:  67.50%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.498677/  1.614767, val:  68.75%, val_best:  70.42%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.491463/  1.765510, val:  63.33%, val_best:  70.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.483969/  1.753350, val:  67.08%, val_best:  70.42%, tr:  94.28%, tr_best:  95.81%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.461769/  1.828582, val:  62.08%, val_best:  70.42%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.444924/  1.824708, val:  65.83%, val_best:  70.42%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.440916/  1.948393, val:  62.50%, val_best:  70.42%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.416775/  1.950535, val:  65.00%, val_best:  70.42%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.399946/  1.958265, val:  65.42%, val_best:  70.42%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.375480/  1.995910, val:  68.75%, val_best:  70.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.403844/  2.093623, val:  66.67%, val_best:  70.42%, tr:  96.83%, tr_best:  98.67%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.368805/  2.186205, val:  62.92%, val_best:  70.42%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.353746/  2.171611, val:  69.58%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.334615/  2.291924, val:  63.75%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.334122/  2.299945, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.321587/  2.362353, val:  65.83%, val_best:  70.42%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.322405/  2.365868, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.311590/  2.399657, val:  65.42%, val_best:  70.42%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.293704/  2.524293, val:  65.83%, val_best:  70.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.309601/  2.526775, val:  66.67%, val_best:  70.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.288224/  2.536476, val:  66.25%, val_best:  70.42%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.263717/  2.614729, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.270008/  2.624046, val:  65.00%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.261669/  2.688289, val:  65.83%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.264950/  2.775618, val:  68.33%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.258720/  2.788832, val:  64.17%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.242871/  2.798048, val:  67.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.260693/  2.903164, val:  66.25%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.242125/  2.964726, val:  67.08%, val_best:  70.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.232564/  2.963949, val:  67.08%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.235766/  2.995975, val:  65.00%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.225573/  3.150798, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.238496/  3.039989, val:  68.33%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.242544/  3.205051, val:  67.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.209145/  3.268563, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.225158/  3.221506, val:  66.25%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.202298/  3.317571, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.191598/  3.337388, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.184830/  3.405065, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.185530/  3.464525, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.189409/  3.502273, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.187915/  3.549896, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.176732/  3.600696, val:  67.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.174016/  3.684161, val:  65.42%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.163204/  3.649122, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.158698/  3.731511, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.162408/  3.728475, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.157262/  3.812711, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.175734/  3.844702, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.152366/  3.850598, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.156215/  3.892855, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.154331/  3.954949, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.156970/  4.056862, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.183809/  3.969005, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.147863/  4.077610, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.160372/  4.054020, val:  66.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.150239/  4.171999, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.155237/  4.144114, val:  63.33%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.142051/  4.176569, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.148744/  4.203733, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.161937/  4.255033, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.150938/  4.327878, val:  62.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.139610/  4.340270, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.126764/  4.405076, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.127919/  4.461441, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.139615/  4.435988, val:  61.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.143295/  4.514951, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.132169/  4.514896, val:  66.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.143847/  4.481551, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.137505/  4.529276, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.136991/  4.590755, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.143691/  4.633200, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.134788/  4.644016, val:  62.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.137480/  4.649119, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.130925/  4.668377, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.127290/  4.753328, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.120203/  4.760028, val:  61.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.130869/  4.769228, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.135882/  4.856189, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.143449/  4.871269, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.143305/  4.943291, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.127994/  4.900231, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.131795/  4.882963, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.157396/  4.994504, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca1970c7a94b28941068a0f31eb676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▃▃▃▇▆▆▇█████▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.1574</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>4.9945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-52</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l598014e' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l598014e</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_001437-l598014e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3yltmlv9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_002151-3yltmlv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yltmlv9' target=\"_blank\">radiant-sweep-56</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yltmlv9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yltmlv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.060629/  1.679069, val:  52.08%, val_best:  52.08%, tr:  27.58%, tr_best:  27.58%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.430566/  1.481912, val:  57.08%, val_best:  57.08%, tr:  56.08%, tr_best:  56.08%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.247546/  1.386219, val:  59.17%, val_best:  59.17%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.087887/  1.520179, val:  58.75%, val_best:  59.17%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.993297/  1.475701, val:  58.33%, val_best:  59.17%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.954488/  1.404588, val:  66.25%, val_best:  66.25%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.858299/  1.398571, val:  62.50%, val_best:  66.25%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.803276/  1.489702, val:  62.92%, val_best:  66.25%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.759205/  1.515086, val:  65.00%, val_best:  66.25%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.696871/  1.599966, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.663912/  1.654228, val:  66.67%, val_best:  67.92%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.605999/  1.709758, val:  74.17%, val_best:  74.17%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.583955/  1.686770, val:  68.75%, val_best:  74.17%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.518462/  1.795502, val:  73.75%, val_best:  74.17%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.439055/  2.259461, val:  66.25%, val_best:  74.17%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.429415/  2.086715, val:  68.33%, val_best:  74.17%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.377435/  2.156818, val:  73.33%, val_best:  74.17%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.370347/  2.122242, val:  75.42%, val_best:  75.42%, tr:  96.22%, tr_best:  97.55%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.323428/  2.296088, val:  67.92%, val_best:  75.42%, tr:  96.32%, tr_best:  97.55%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.304189/  2.366753, val:  72.92%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.268390/  2.314691, val:  74.58%, val_best:  75.42%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.241368/  2.516396, val:  67.50%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.192926/  2.468761, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286472/  2.497247, val:  76.25%, val_best:  76.25%, tr:  97.85%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.180535/  2.554672, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.139435/  2.551605, val:  75.83%, val_best:  77.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.158872/  2.636175, val:  77.50%, val_best:  77.50%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.149316/  2.692245, val:  79.17%, val_best:  79.17%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.113046/  2.715733, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.075672/  2.892610, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.072648/  2.874541, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.058813/  3.033061, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.056109/  3.094202, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.050927/  3.039777, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.039025/  3.248237, val:  73.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.047744/  3.122020, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.036543/  3.131391, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.031634/  3.212302, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.026369/  3.293380, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.027552/  3.286091, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.026962/  3.279810, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.018657/  3.325139, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.012598/  3.382587, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.015043/  3.383414, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.014956/  3.349200, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.012062/  3.486905, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.008683/  3.357147, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.009804/  3.379526, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.009466/  3.435631, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.006019/  3.488192, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.005703/  3.452363, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.006238/  3.476765, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.008102/  3.487957, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.005164/  3.538590, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.006160/  3.614767, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.003797/  3.629519, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.003511/  3.591570, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.004160/  3.641281, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.006857/  3.583557, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.004247/  3.594861, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.004083/  3.632077, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.003154/  3.637581, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.003780/  3.611901, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.002289/  3.625989, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.002258/  3.627726, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.002044/  3.640879, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001986/  3.664173, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001870/  3.657732, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001639/  3.655009, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001591/  3.692255, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001537/  3.644223, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001569/  3.659027, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001351/  3.668327, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001339/  3.659644, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001235/  3.678963, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001150/  3.667636, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001102/  3.667462, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001115/  3.682498, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001493/  3.706462, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001748/  3.735568, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001691/  3.740037, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.002256/  3.764322, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001961/  3.711734, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.002507/  3.725888, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001387/  3.694194, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001190/  3.708414, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000975/  3.717273, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001267/  3.717355, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001178/  3.731985, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001096/  3.734346, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001133/  3.712806, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001434/  3.725451, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000943/  3.726154, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001350/  3.773880, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.002364/  3.742359, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.001501/  3.736881, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.001116/  3.778324, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001181/  3.812017, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.000853/  3.795150, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000931/  3.821196, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410e9bd774f34499841b074a4dd827e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▄▅▅▇▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▅▅▅▇▆▅▇▇▇▇▇▇▇▇████▇▇█▇██████▇▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▅▅▅▇▆▅▇▇▇▇▇▇▇▇████▇▇█▇██████▇▇▇█████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▂▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇█▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00093</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>3.8212</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-56</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yltmlv9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3yltmlv9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_002151-3yltmlv9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xcz4dx58 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_002830-xcz4dx58</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xcz4dx58' target=\"_blank\">vital-sweep-60</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xcz4dx58' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xcz4dx58</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.060629/  1.679069, val:  52.08%, val_best:  52.08%, tr:  27.58%, tr_best:  27.58%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.430566/  1.481912, val:  57.08%, val_best:  57.08%, tr:  56.08%, tr_best:  56.08%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.247546/  1.386219, val:  59.17%, val_best:  59.17%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.087887/  1.520179, val:  58.75%, val_best:  59.17%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.993297/  1.475701, val:  58.33%, val_best:  59.17%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.954488/  1.404588, val:  66.25%, val_best:  66.25%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.858299/  1.398571, val:  62.50%, val_best:  66.25%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.803276/  1.489702, val:  62.92%, val_best:  66.25%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.759205/  1.515086, val:  65.00%, val_best:  66.25%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.696871/  1.599966, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.663912/  1.654228, val:  66.67%, val_best:  67.92%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.605999/  1.709758, val:  74.17%, val_best:  74.17%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.583955/  1.686770, val:  68.75%, val_best:  74.17%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.518462/  1.795502, val:  73.75%, val_best:  74.17%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.439055/  2.259461, val:  66.25%, val_best:  74.17%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.429415/  2.086715, val:  68.33%, val_best:  74.17%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.377435/  2.156818, val:  73.33%, val_best:  74.17%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.370347/  2.122242, val:  75.42%, val_best:  75.42%, tr:  96.22%, tr_best:  97.55%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.323428/  2.296088, val:  67.92%, val_best:  75.42%, tr:  96.32%, tr_best:  97.55%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.304189/  2.366753, val:  72.92%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.268390/  2.314691, val:  74.58%, val_best:  75.42%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.241368/  2.516396, val:  67.50%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.192926/  2.468761, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.286472/  2.497247, val:  76.25%, val_best:  76.25%, tr:  97.85%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.180535/  2.554672, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.139435/  2.551605, val:  75.83%, val_best:  77.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.158872/  2.636175, val:  77.50%, val_best:  77.50%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.149316/  2.692245, val:  79.17%, val_best:  79.17%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.113046/  2.715733, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.075672/  2.892610, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.072648/  2.874541, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.058813/  3.033061, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.056109/  3.094202, val:  76.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.050927/  3.039777, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.039025/  3.248237, val:  73.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.047744/  3.122020, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.036543/  3.131391, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.031634/  3.212302, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.026369/  3.293380, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.027552/  3.286091, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.026962/  3.279810, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.018657/  3.325139, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.012598/  3.382587, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.015043/  3.383414, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.014956/  3.349200, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.012062/  3.486905, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.008683/  3.357147, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.009804/  3.379526, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.009466/  3.435631, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.006019/  3.488192, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.005703/  3.452363, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.006238/  3.476765, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.008102/  3.487957, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.005164/  3.538590, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.006160/  3.614767, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.003797/  3.629519, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.003511/  3.591570, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.004160/  3.641281, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.006857/  3.583557, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.004247/  3.594861, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.004083/  3.632077, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.003154/  3.637581, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.003780/  3.611901, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.002289/  3.625989, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.002258/  3.627726, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.002044/  3.640879, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001986/  3.664173, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001870/  3.657732, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001639/  3.655009, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001591/  3.692255, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001537/  3.644223, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001569/  3.659027, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001351/  3.668327, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001339/  3.659644, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001235/  3.678963, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001150/  3.667636, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001102/  3.667462, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001115/  3.682498, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001493/  3.706462, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001748/  3.735568, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.001691/  3.740037, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.002256/  3.764322, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.001961/  3.711734, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.002507/  3.725888, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.001387/  3.694194, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.001190/  3.708414, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000975/  3.717273, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001267/  3.717355, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001178/  3.731985, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001096/  3.734346, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.001133/  3.712806, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001434/  3.725451, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000943/  3.726154, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001350/  3.773880, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.002364/  3.742359, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.001501/  3.736881, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.001116/  3.778324, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001181/  3.812017, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.000853/  3.795150, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000931/  3.821196, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ff48961a444535bbbf23923be0b001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▄▅▅▇▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▅▅▅▇▆▅▇▇▇▇▇▇▇▇████▇▇█▇██████▇▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▅▅▅▇▆▅▇▇▇▇▇▇▇▇████▇▇█▇██████▇▇▇█████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▂▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇█▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00093</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>3.8212</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-sweep-60</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xcz4dx58' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xcz4dx58</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_002830-xcz4dx58/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pmr8jmwy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04186b1124d44964966db0ad8e431e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112812456364434, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_003508-pmr8jmwy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pmr8jmwy' target=\"_blank\">likely-sweep-64</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pmr8jmwy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pmr8jmwy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.193166/  1.939117, val:  36.25%, val_best:  36.25%, tr:  18.39%, tr_best:  18.39%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.596445/  1.538843, val:  56.25%, val_best:  56.25%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.374148/  1.504866, val:  55.00%, val_best:  56.25%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.272936/  1.492908, val:  58.75%, val_best:  58.75%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.231004/  1.469412, val:  58.75%, val_best:  58.75%, tr:  63.13%, tr_best:  63.84%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.181969/  1.432151, val:  64.17%, val_best:  64.17%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.130880/  1.435866, val:  61.25%, val_best:  64.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.124110/  1.450976, val:  62.08%, val_best:  64.17%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.087939/  1.483909, val:  60.00%, val_best:  64.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.081649/  1.512360, val:  59.17%, val_best:  64.17%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.075077/  1.557770, val:  56.67%, val_best:  64.17%, tr:  72.11%, tr_best:  72.73%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.031409/  1.512975, val:  61.25%, val_best:  64.17%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.032472/  1.569944, val:  58.75%, val_best:  64.17%, tr:  75.49%, tr_best:  75.69%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.024697/  1.581399, val:  63.75%, val_best:  64.17%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.989958/  1.774732, val:  57.92%, val_best:  64.17%, tr:  77.83%, tr_best:  78.04%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.988663/  1.699107, val:  62.50%, val_best:  64.17%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.001385/  1.668627, val:  62.92%, val_best:  64.17%, tr:  78.75%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.965800/  1.698771, val:  62.50%, val_best:  64.17%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.968380/  1.842503, val:  60.83%, val_best:  64.17%, tr:  82.84%, tr_best:  84.58%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.976029/  1.809729, val:  65.00%, val_best:  65.00%, tr:  81.51%, tr_best:  84.58%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.953923/  1.939612, val:  62.08%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.938328/  1.932675, val:  62.92%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.946192/  1.963732, val:  63.75%, val_best:  65.00%, tr:  85.09%, tr_best:  85.19%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.921071/  2.004754, val:  62.92%, val_best:  65.00%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.912818/  2.081909, val:  64.17%, val_best:  65.00%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.924512/  2.089756, val:  65.83%, val_best:  65.83%, tr:  89.89%, tr_best:  90.40%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.938146/  2.147205, val:  64.58%, val_best:  65.83%, tr:  89.27%, tr_best:  90.40%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.919848/  2.259307, val:  60.83%, val_best:  65.83%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.928758/  2.266344, val:  67.50%, val_best:  67.50%, tr:  90.40%, tr_best:  90.91%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.904377/  2.418868, val:  58.33%, val_best:  67.50%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.901257/  2.436279, val:  64.58%, val_best:  67.50%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.918823/  2.499423, val:  63.33%, val_best:  67.50%, tr:  91.32%, tr_best:  93.46%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.907202/  2.583228, val:  64.17%, val_best:  67.50%, tr:  92.13%, tr_best:  93.46%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.927218/  2.594553, val:  62.08%, val_best:  67.50%, tr:  92.75%, tr_best:  93.46%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.877721/  2.682896, val:  60.42%, val_best:  67.50%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.927637/  2.886584, val:  60.00%, val_best:  67.50%, tr:  91.52%, tr_best:  95.71%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.897621/  2.790205, val:  62.08%, val_best:  67.50%, tr:  93.97%, tr_best:  95.71%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.897012/  2.864525, val:  64.58%, val_best:  67.50%, tr:  95.30%, tr_best:  95.71%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.901069/  2.892008, val:  64.17%, val_best:  67.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.885706/  2.971587, val:  65.83%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.921253/  3.140809, val:  66.67%, val_best:  67.50%, tr:  93.77%, tr_best:  96.73%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.900491/  3.166608, val:  62.08%, val_best:  67.50%, tr:  96.02%, tr_best:  96.73%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.885927/  3.123917, val:  65.42%, val_best:  67.50%, tr:  96.22%, tr_best:  96.73%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.883350/  3.226336, val:  64.17%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.868177/  3.336858, val:  65.83%, val_best:  67.50%, tr:  96.53%, tr_best:  96.73%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.879438/  3.476895, val:  64.58%, val_best:  67.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.876472/  3.444482, val:  67.50%, val_best:  67.50%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.881349/  3.566679, val:  64.17%, val_best:  67.50%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.902812/  3.620230, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.909536/  3.763088, val:  67.08%, val_best:  67.50%, tr:  96.02%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.897933/  3.823657, val:  65.42%, val_best:  67.50%, tr:  96.83%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.921506/  3.850721, val:  63.75%, val_best:  67.50%, tr:  96.22%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.878395/  3.920132, val:  62.92%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.875459/  3.925065, val:  63.33%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.908434/  4.063511, val:  65.00%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.885495/  4.166838, val:  64.58%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.891168/  4.235428, val:  64.58%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.904209/  4.202693, val:  65.42%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.901683/  4.408100, val:  65.83%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.917671/  4.462821, val:  65.83%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.900324/  4.409728, val:  66.25%, val_best:  67.50%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.916592/  4.574003, val:  64.17%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.918912/  4.598024, val:  64.58%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.912576/  4.673869, val:  64.17%, val_best:  67.50%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.951523/  4.838566, val:  62.50%, val_best:  67.50%, tr:  97.14%, tr_best:  98.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.929579/  4.837544, val:  63.75%, val_best:  67.50%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.943912/  4.801209, val:  63.33%, val_best:  67.50%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.978586/  4.870781, val:  64.17%, val_best:  67.50%, tr:  98.26%, tr_best:  98.77%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.928512/  5.056540, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.974683/  5.035474, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  98.88%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.955963/  5.190147, val:  65.83%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.966961/  5.238400, val:  64.17%, val_best:  67.50%, tr:  98.06%, tr_best:  98.98%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.958911/  5.391454, val:  64.17%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.979799/  5.308387, val:  64.17%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.964715/  5.419832, val:  65.83%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.980169/  5.544930, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.968358/  5.632122, val:  65.83%, val_best:  67.50%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.988867/  5.605183, val:  63.75%, val_best:  67.50%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.985602/  5.728496, val:  64.58%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.989630/  5.790163, val:  63.33%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.946726/  5.743594, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.937975/  5.892830, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.973990/  5.979602, val:  65.42%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.968340/  6.040612, val:  65.42%, val_best:  67.50%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.975842/  6.045587, val:  66.25%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.959686/  6.149115, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.966483/  6.255885, val:  66.67%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.010518/  6.260497, val:  65.83%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.970384/  6.322037, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.940430/  6.472783, val:  64.58%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.016080/  6.364972, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.968965/  6.490075, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.984306/  6.480693, val:  65.42%, val_best:  67.50%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.985216/  6.495708, val:  67.50%, val_best:  67.50%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.993391/  6.601977, val:  62.92%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.002850/  6.695262, val:  66.25%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.982645/  6.811234, val:  64.58%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.027471/  6.617285, val:  66.25%, val_best:  67.50%, tr:  98.26%, tr_best:  99.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.965649/  6.649284, val:  65.42%, val_best:  67.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.042163/  6.814491, val:  62.50%, val_best:  67.50%, tr:  99.08%, tr_best:  99.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290ce2488289460ea9035a67fe626bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▂▃▃▆▆▁▆▆██▆▇▆██▇██▇█▇██████▇▇█▇███▆▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99081</td></tr><tr><td>tr_epoch_loss</td><td>1.04216</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>6.81449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-64</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pmr8jmwy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pmr8jmwy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_003508-pmr8jmwy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ahyf1vy9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_004220-ahyf1vy9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ahyf1vy9' target=\"_blank\">divine-sweep-68</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ahyf1vy9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ahyf1vy9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.271144/  2.213912, val:  23.75%, val_best:  23.75%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.119504/  2.065082, val:  38.33%, val_best:  38.33%, tr:  27.89%, tr_best:  27.89%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.917099/  1.901326, val:  46.25%, val_best:  46.25%, tr:  40.86%, tr_best:  40.86%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.712377/  1.767536, val:  50.00%, val_best:  50.00%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.567230/  1.685006, val:  50.42%, val_best:  50.42%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.459769/  1.610650, val:  54.58%, val_best:  54.58%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.398363/  1.574295, val:  57.50%, val_best:  57.50%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.341755/  1.544551, val:  55.83%, val_best:  57.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.300183/  1.523292, val:  60.00%, val_best:  60.00%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.271581/  1.513263, val:  53.75%, val_best:  60.00%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.239508/  1.501374, val:  59.58%, val_best:  60.00%, tr:  63.74%, tr_best:  64.15%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.207462/  1.475154, val:  59.17%, val_best:  60.00%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.185769/  1.452586, val:  55.83%, val_best:  60.00%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.169933/  1.438281, val:  59.58%, val_best:  60.00%, tr:  66.80%, tr_best:  66.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.118432/  1.456435, val:  58.33%, val_best:  60.00%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.113631/  1.436250, val:  61.67%, val_best:  61.67%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.099342/  1.413429, val:  57.08%, val_best:  61.67%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.063788/  1.389606, val:  63.33%, val_best:  63.33%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.044016/  1.458339, val:  57.50%, val_best:  63.33%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.037125/  1.461781, val:  60.42%, val_best:  63.33%, tr:  70.17%, tr_best:  73.95%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.008587/  1.436370, val:  59.58%, val_best:  63.33%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.995020/  1.407226, val:  62.92%, val_best:  63.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.010781/  1.402310, val:  60.83%, val_best:  63.33%, tr:  72.63%, tr_best:  76.40%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.974947/  1.412822, val:  65.83%, val_best:  65.83%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.953457/  1.447899, val:  62.08%, val_best:  65.83%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.945204/  1.432182, val:  65.00%, val_best:  65.83%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.930286/  1.402901, val:  68.33%, val_best:  68.33%, tr:  77.73%, tr_best:  78.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.918623/  1.467899, val:  61.67%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.905570/  1.433413, val:  68.33%, val_best:  68.33%, tr:  79.98%, tr_best:  80.29%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.891169/  1.499568, val:  60.00%, val_best:  68.33%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.884161/  1.466674, val:  64.17%, val_best:  68.33%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885212/  1.528810, val:  63.75%, val_best:  68.33%, tr:  78.96%, tr_best:  82.02%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.878800/  1.503499, val:  65.42%, val_best:  68.33%, tr:  80.59%, tr_best:  82.02%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.867940/  1.545360, val:  66.67%, val_best:  68.33%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.855133/  1.529981, val:  64.58%, val_best:  68.33%, tr:  82.74%, tr_best:  83.04%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.860671/  1.592199, val:  60.42%, val_best:  68.33%, tr:  82.12%, tr_best:  83.04%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.830630/  1.523988, val:  66.67%, val_best:  68.33%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.835012/  1.568986, val:  67.08%, val_best:  68.33%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.827137/  1.553537, val:  68.33%, val_best:  68.33%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.821829/  1.581612, val:  66.25%, val_best:  68.33%, tr:  85.80%, tr_best:  86.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.808516/  1.545291, val:  67.92%, val_best:  68.33%, tr:  85.50%, tr_best:  86.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816658/  1.600840, val:  65.83%, val_best:  68.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.802062/  1.613271, val:  67.50%, val_best:  68.33%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.792263/  1.652269, val:  67.50%, val_best:  68.33%, tr:  86.93%, tr_best:  87.44%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.785542/  1.618566, val:  68.75%, val_best:  68.75%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.773058/  1.674953, val:  66.67%, val_best:  68.75%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.779096/  1.682626, val:  67.08%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.765017/  1.753861, val:  67.92%, val_best:  68.75%, tr:  87.84%, tr_best:  88.76%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.774353/  1.697718, val:  70.42%, val_best:  70.42%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.757714/  1.744035, val:  69.17%, val_best:  70.42%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.749776/  1.773715, val:  70.83%, val_best:  70.83%, tr:  89.99%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.735386/  1.857619, val:  68.33%, val_best:  70.83%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.727392/  1.871766, val:  63.33%, val_best:  70.83%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.736892/  1.886971, val:  67.08%, val_best:  70.83%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.737400/  1.844973, val:  69.58%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.726919/  1.898565, val:  67.92%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.727255/  2.010104, val:  61.25%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.733125/  1.929105, val:  67.50%, val_best:  70.83%, tr:  90.30%, tr_best:  91.22%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.706081/  2.015479, val:  62.08%, val_best:  70.83%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.704463/  1.999632, val:  65.00%, val_best:  70.83%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.697379/  2.012823, val:  66.67%, val_best:  70.83%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.699366/  2.049498, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.696666/  1.982021, val:  66.25%, val_best:  70.83%, tr:  91.62%, tr_best:  93.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.690303/  1.949631, val:  68.33%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.682222/  2.182542, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.678254/  2.093792, val:  68.33%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.657245/  2.104634, val:  64.17%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.678574/  2.185186, val:  65.42%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.669829/  2.143760, val:  65.83%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.663757/  2.222388, val:  63.33%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.664197/  2.173170, val:  68.75%, val_best:  70.83%, tr:  93.67%, tr_best:  94.28%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.658573/  2.264093, val:  66.25%, val_best:  70.83%, tr:  94.08%, tr_best:  94.28%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.649531/  2.311089, val:  66.67%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.697815/  2.388317, val:  62.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.679183/  2.287027, val:  64.58%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.661421/  2.334292, val:  65.83%, val_best:  70.83%, tr:  93.56%, tr_best:  94.28%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.641969/  2.338767, val:  62.08%, val_best:  70.83%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.654468/  2.357919, val:  64.58%, val_best:  70.83%, tr:  93.87%, tr_best:  94.99%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.643049/  2.393985, val:  67.08%, val_best:  70.83%, tr:  93.46%, tr_best:  94.99%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.629749/  2.407182, val:  67.50%, val_best:  70.83%, tr:  93.77%, tr_best:  94.99%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.630240/  2.430224, val:  63.75%, val_best:  70.83%, tr:  94.69%, tr_best:  94.99%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.629139/  2.470051, val:  67.50%, val_best:  70.83%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.626601/  2.557223, val:  63.75%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.650782/  2.664475, val:  62.08%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.633163/  2.498292, val:  65.42%, val_best:  70.83%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.640605/  2.526422, val:  66.25%, val_best:  70.83%, tr:  95.10%, tr_best:  96.42%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.621260/  2.476778, val:  65.00%, val_best:  70.83%, tr:  94.48%, tr_best:  96.42%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.620244/  2.573562, val:  65.83%, val_best:  70.83%, tr:  95.51%, tr_best:  96.42%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.620359/  2.622973, val:  62.08%, val_best:  70.83%, tr:  95.81%, tr_best:  96.42%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.605548/  2.640956, val:  65.42%, val_best:  70.83%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.629322/  2.612954, val:  62.50%, val_best:  70.83%, tr:  95.30%, tr_best:  96.42%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.619542/  2.711474, val:  61.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.627735/  2.750376, val:  60.00%, val_best:  70.83%, tr:  95.40%, tr_best:  96.42%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.637624/  2.683571, val:  64.17%, val_best:  70.83%, tr:  94.99%, tr_best:  96.42%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.619945/  2.644697, val:  65.83%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.630613/  2.787121, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.599588/  2.837799, val:  59.17%, val_best:  70.83%, tr:  96.22%, tr_best:  96.42%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.616224/  2.720553, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.590106/  2.774406, val:  64.58%, val_best:  70.83%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.609097/  2.823443, val:  62.92%, val_best:  70.83%, tr:  96.12%, tr_best:  96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ce02db42d441c19e286cedde005f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▁▃▁▄▆▂▄▅▅▇▄▆▆▇▇▆█▇▇█▆▇█▇▇██▇█▇▅█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▄▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96118</td></tr><tr><td>tr_epoch_loss</td><td>0.6091</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.62917</td></tr><tr><td>val_loss</td><td>2.82344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-68</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ahyf1vy9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ahyf1vy9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_004220-ahyf1vy9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dd6wg0i1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_004836-dd6wg0i1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dd6wg0i1' target=\"_blank\">zany-sweep-72</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dd6wg0i1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dd6wg0i1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.210216/  1.945272, val:  36.25%, val_best:  36.25%, tr:  17.16%, tr_best:  17.16%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.441017/  1.537189, val:  49.58%, val_best:  49.58%, tr:  52.09%, tr_best:  52.09%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.189114/  1.485398, val:  55.42%, val_best:  55.42%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.982218/  1.577979, val:  54.17%, val_best:  55.42%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.956850/  1.512325, val:  60.42%, val_best:  60.42%, tr:  67.31%, tr_best:  68.64%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.833812/  1.631244, val:  58.75%, val_best:  60.42%, tr:  72.22%, tr_best:  72.22%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.812878/  1.262199, val:  66.67%, val_best:  66.67%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.789406/  1.464521, val:  62.08%, val_best:  66.67%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.695573/  1.472700, val:  65.83%, val_best:  66.67%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.601816/  1.695167, val:  64.58%, val_best:  66.67%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.601959/  1.594698, val:  65.42%, val_best:  66.67%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.584791/  1.694145, val:  70.83%, val_best:  70.83%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.545843/  1.707375, val:  74.58%, val_best:  74.58%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.531435/  1.749769, val:  70.83%, val_best:  74.58%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.459162/  1.964682, val:  70.83%, val_best:  74.58%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.395649/  2.202012, val:  69.58%, val_best:  74.58%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.458090/  2.334516, val:  69.58%, val_best:  74.58%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.445775/  1.965104, val:  72.92%, val_best:  74.58%, tr:  92.13%, tr_best:  93.36%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.371478/  2.171320, val:  71.67%, val_best:  74.58%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.413409/  2.515940, val:  65.42%, val_best:  74.58%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.319140/  2.297279, val:  72.50%, val_best:  74.58%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.205748/  2.713903, val:  67.08%, val_best:  74.58%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.209946/  2.574071, val:  75.42%, val_best:  75.42%, tr:  98.37%, tr_best:  99.08%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.269054/  2.776462, val:  70.83%, val_best:  75.42%, tr:  97.65%, tr_best:  99.08%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.197320/  2.710768, val:  75.00%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.212903/  2.621464, val:  78.75%, val_best:  78.75%, tr:  98.37%, tr_best:  99.08%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.178677/  2.917868, val:  70.00%, val_best:  78.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.119517/  3.076658, val:  76.67%, val_best:  78.75%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.127025/  3.250551, val:  76.25%, val_best:  78.75%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.126456/  3.383505, val:  75.42%, val_best:  78.75%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.146786/  3.298286, val:  72.50%, val_best:  78.75%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.082628/  3.595428, val:  71.25%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.109412/  3.458840, val:  75.00%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.170134/  3.325785, val:  79.17%, val_best:  79.17%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.093311/  3.637505, val:  73.33%, val_best:  79.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.174839/  3.398141, val:  74.58%, val_best:  79.17%, tr:  99.18%, tr_best:  99.90%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.129816/  3.424897, val:  77.92%, val_best:  79.17%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.130209/  3.610535, val:  74.58%, val_best:  79.17%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.077087/  3.694784, val:  74.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.111910/  3.509865, val:  76.67%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.063130/  3.546870, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.058453/  3.815758, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.073131/  3.838005, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.042060/  3.982440, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.033164/  3.665140, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.043124/  3.896621, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.072723/  3.930115, val:  77.92%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.065127/  3.940380, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.090506/  4.087783, val:  74.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.135980/  3.870476, val:  76.25%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.104646/  4.047028, val:  76.25%, val_best:  80.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.085954/  4.030563, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.059237/  4.327750, val:  74.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.069410/  4.063169, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.042052/  4.275276, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.037093/  4.048324, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.042015/  4.287971, val:  75.42%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.041925/  4.002731, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.032852/  4.247165, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.026941/  4.189180, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.025892/  4.327552, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.019221/  4.165228, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.048685/  4.359090, val:  75.83%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.051623/  4.388027, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.062837/  4.167758, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.038694/  4.858767, val:  72.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.051278/  4.471108, val:  77.50%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.039617/  4.535212, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.050250/  4.582498, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.042458/  4.244183, val:  80.83%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.026386/  4.380062, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.026045/  4.379738, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.050106/  4.787440, val:  77.92%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.014269/  4.734328, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.011926/  4.633681, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.013240/  4.534726, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.019878/  4.755481, val:  75.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.007936/  4.805967, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.004494/  4.754364, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.003388/  4.652237, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.002904/  4.629365, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.006294/  4.370375, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.009173/  4.725375, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.021678/  4.981267, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.116067/  4.101861, val:  80.00%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.037549/  4.466341, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.025994/  4.321225, val:  77.50%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.015805/  4.273341, val:  79.17%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.008790/  4.543974, val:  76.67%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.005826/  4.701606, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.006152/  4.481299, val:  79.17%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.005785/  4.515682, val:  77.50%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.003649/  4.523674, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.003489/  4.594383, val:  79.17%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.013744/  4.679358, val:  77.50%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.006197/  4.589981, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.007743/  4.791193, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.006840/  4.716321, val:  79.58%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.012508/  4.850351, val:  79.17%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.009229/  4.802740, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9499bd195c48f284bc525fcbd1c7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▇▇▆█▇▇███████████▇███████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▇▆▇▆▆▇▆▇▇▇▇▇▇█▇▇▇▇█▇█▇▇██▇▇▇███████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▇▆▇▆▆▇▆▇▇▇▇▇▇█▇▇▇▇█▇█▇▇██▇▇▇███████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▂▂▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▆▇▇█▇▇█▇███▆▇█▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00923</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>4.80274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-72</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dd6wg0i1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dd6wg0i1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_004836-dd6wg0i1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6x1mepig with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_005500-6x1mepig</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6x1mepig' target=\"_blank\">amber-sweep-76</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6x1mepig' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6x1mepig</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.223132/  2.002686, val:  33.33%, val_best:  33.33%, tr:  15.73%, tr_best:  15.73%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.646732/  1.575394, val:  55.42%, val_best:  55.42%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.372906/  1.491806, val:  55.83%, val_best:  55.83%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.268665/  1.484575, val:  59.58%, val_best:  59.58%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.219088/  1.457247, val:  60.42%, val_best:  60.42%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.171647/  1.394018, val:  62.92%, val_best:  62.92%, tr:  63.64%, tr_best:  64.04%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.116940/  1.393969, val:  60.00%, val_best:  62.92%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.093962/  1.379677, val:  58.33%, val_best:  62.92%, tr:  66.91%, tr_best:  67.31%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.055203/  1.372605, val:  64.17%, val_best:  64.17%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.043046/  1.387284, val:  59.17%, val_best:  64.17%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.033951/  1.394526, val:  57.50%, val_best:  64.17%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.007317/  1.371447, val:  64.58%, val_best:  64.58%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.000964/  1.352160, val:  60.42%, val_best:  64.58%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.997045/  1.362018, val:  64.17%, val_best:  64.58%, tr:  71.91%, tr_best:  73.54%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.958671/  1.464957, val:  61.25%, val_best:  64.58%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.963711/  1.388220, val:  64.17%, val_best:  64.58%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.981052/  1.361770, val:  62.92%, val_best:  64.58%, tr:  73.34%, tr_best:  75.59%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.937431/  1.376124, val:  65.42%, val_best:  65.42%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.928476/  1.498154, val:  58.75%, val_best:  65.42%, tr:  75.89%, tr_best:  77.94%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.934240/  1.411411, val:  62.92%, val_best:  65.42%, tr:  75.18%, tr_best:  77.94%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.917973/  1.429030, val:  62.92%, val_best:  65.42%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.905660/  1.420187, val:  62.50%, val_best:  65.42%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.928158/  1.459875, val:  61.67%, val_best:  65.42%, tr:  75.89%, tr_best:  78.86%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.907592/  1.476621, val:  61.25%, val_best:  65.42%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.880166/  1.470958, val:  61.25%, val_best:  65.42%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.881017/  1.433986, val:  65.83%, val_best:  65.83%, tr:  79.67%, tr_best:  82.84%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.895718/  1.456358, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.886454/  1.536756, val:  57.92%, val_best:  66.25%, tr:  81.10%, tr_best:  82.84%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.887316/  1.461037, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.864054/  1.579258, val:  60.83%, val_best:  66.25%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.856266/  1.603251, val:  59.58%, val_best:  66.25%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885827/  1.554118, val:  62.92%, val_best:  66.25%, tr:  80.08%, tr_best:  83.55%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.871941/  1.589672, val:  62.08%, val_best:  66.25%, tr:  80.69%, tr_best:  83.55%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.855188/  1.629326, val:  63.33%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.846618/  1.604717, val:  65.42%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.873432/  1.636944, val:  60.42%, val_best:  66.25%, tr:  81.61%, tr_best:  83.55%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.819472/  1.603188, val:  62.92%, val_best:  66.25%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.844137/  1.701811, val:  65.83%, val_best:  66.25%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.837160/  1.657102, val:  61.67%, val_best:  66.25%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.815818/  1.693619, val:  61.67%, val_best:  66.25%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.826555/  1.756078, val:  65.00%, val_best:  66.25%, tr:  83.66%, tr_best:  86.72%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816026/  1.728303, val:  61.25%, val_best:  66.25%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.808087/  1.654136, val:  66.25%, val_best:  66.25%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.814506/  1.772221, val:  62.50%, val_best:  66.25%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.792904/  1.756599, val:  66.67%, val_best:  66.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.779269/  1.761614, val:  64.58%, val_best:  66.67%, tr:  87.84%, tr_best:  88.66%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.775480/  1.741632, val:  66.67%, val_best:  66.67%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.783227/  1.807499, val:  65.00%, val_best:  66.67%, tr:  88.97%, tr_best:  89.07%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.805892/  1.723932, val:  65.00%, val_best:  66.67%, tr:  88.56%, tr_best:  89.07%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.796156/  1.767691, val:  67.08%, val_best:  67.08%, tr:  87.44%, tr_best:  89.07%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.794473/  1.827904, val:  64.17%, val_best:  67.08%, tr:  87.33%, tr_best:  89.07%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.829250/  1.777983, val:  64.58%, val_best:  67.08%, tr:  84.58%, tr_best:  89.07%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.766114/  1.804216, val:  64.17%, val_best:  67.08%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.770968/  1.810026, val:  67.50%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.793794/  1.856610, val:  65.83%, val_best:  67.50%, tr:  89.38%, tr_best:  90.70%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.760632/  1.853680, val:  62.92%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.778129/  1.968967, val:  61.67%, val_best:  67.50%, tr:  88.36%, tr_best:  90.70%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.802386/  1.824670, val:  65.00%, val_best:  67.50%, tr:  87.84%, tr_best:  90.70%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.768591/  1.996533, val:  60.42%, val_best:  67.50%, tr:  89.17%, tr_best:  90.70%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.766381/  1.939684, val:  65.42%, val_best:  67.50%, tr:  88.05%, tr_best:  90.70%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.758057/  1.876465, val:  66.25%, val_best:  67.50%, tr:  89.58%, tr_best:  90.70%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.768309/  1.941056, val:  61.25%, val_best:  67.50%, tr:  90.30%, tr_best:  90.70%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.762010/  2.005100, val:  60.42%, val_best:  67.50%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.749036/  1.964597, val:  64.17%, val_best:  67.50%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.767938/  2.052987, val:  60.83%, val_best:  67.50%, tr:  90.09%, tr_best:  91.73%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.754043/  1.993210, val:  62.50%, val_best:  67.50%, tr:  90.70%, tr_best:  91.73%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.770516/  2.113071, val:  61.25%, val_best:  67.50%, tr:  90.91%, tr_best:  91.73%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.766177/  1.978093, val:  60.42%, val_best:  67.50%, tr:  91.42%, tr_best:  91.73%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.757744/  2.173551, val:  58.33%, val_best:  67.50%, tr:  91.22%, tr_best:  91.73%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.776188/  2.089108, val:  63.33%, val_best:  67.50%, tr:  88.56%, tr_best:  91.73%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.762170/  2.067266, val:  64.17%, val_best:  67.50%, tr:  91.62%, tr_best:  91.73%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.781851/  2.191415, val:  60.42%, val_best:  67.50%, tr:  90.40%, tr_best:  91.73%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.758126/  2.176638, val:  62.50%, val_best:  67.50%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.786769/  2.128878, val:  63.33%, val_best:  67.50%, tr:  89.99%, tr_best:  92.13%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.800965/  2.129314, val:  63.33%, val_best:  67.50%, tr:  90.91%, tr_best:  92.13%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.804875/  2.252852, val:  61.67%, val_best:  67.50%, tr:  90.70%, tr_best:  92.13%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.766759/  2.272423, val:  62.92%, val_best:  67.50%, tr:  89.38%, tr_best:  92.13%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.821836/  2.259508, val:  61.25%, val_best:  67.50%, tr:  89.48%, tr_best:  92.13%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.811524/  2.266636, val:  60.83%, val_best:  67.50%, tr:  88.97%, tr_best:  92.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.776070/  2.216362, val:  63.33%, val_best:  67.50%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.771906/  2.261730, val:  60.83%, val_best:  67.50%, tr:  91.73%, tr_best:  92.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.802366/  2.255741, val:  64.17%, val_best:  67.50%, tr:  90.50%, tr_best:  92.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.802616/  2.359800, val:  55.83%, val_best:  67.50%, tr:  91.11%, tr_best:  92.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.791338/  2.454720, val:  61.25%, val_best:  67.50%, tr:  89.79%, tr_best:  92.13%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.788659/  2.234620, val:  64.17%, val_best:  67.50%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.780635/  2.285981, val:  59.58%, val_best:  67.50%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.771102/  2.369335, val:  62.08%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.810745/  2.302168, val:  65.42%, val_best:  67.50%, tr:  89.99%, tr_best:  93.05%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.783924/  2.403520, val:  60.42%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.752935/  2.452646, val:  60.00%, val_best:  67.50%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.818026/  2.384936, val:  61.67%, val_best:  67.50%, tr:  91.62%, tr_best:  93.05%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.790593/  2.616165, val:  55.42%, val_best:  67.50%, tr:  90.30%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.787843/  2.505027, val:  60.83%, val_best:  67.50%, tr:  91.93%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.791389/  2.424564, val:  63.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.785110/  2.480027, val:  62.08%, val_best:  67.50%, tr:  92.34%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.788248/  2.454785, val:  61.25%, val_best:  67.50%, tr:  91.73%, tr_best:  93.05%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.787971/  2.684330, val:  58.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.799346/  2.498815, val:  63.75%, val_best:  67.50%, tr:  89.89%, tr_best:  93.05%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.784911/  2.623399, val:  63.75%, val_best:  67.50%, tr:  90.91%, tr_best:  93.05%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.832112/  2.533987, val:  61.25%, val_best:  67.50%, tr:  89.68%, tr_best:  93.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e24d58f00074185ba96eeb8268b316d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▄▆▃▃▆▇▇▆▆▆▇█▆▇▆▅█▆▆█▆▆▇▇▆▆█▅▇▆▇▃▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▂▂▁▁▁▂▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▆▇▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.89683</td></tr><tr><td>tr_epoch_loss</td><td>0.83211</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.6125</td></tr><tr><td>val_loss</td><td>2.53399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-sweep-76</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6x1mepig' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6x1mepig</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_005500-6x1mepig/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6g6l2luf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_010208-6g6l2luf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6g6l2luf' target=\"_blank\">neat-sweep-80</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6g6l2luf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6g6l2luf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.069320/  1.703325, val:  49.17%, val_best:  49.17%, tr:  29.01%, tr_best:  29.01%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.425422/  1.465425, val:  58.75%, val_best:  58.75%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.218719/  1.379099, val:  58.75%, val_best:  58.75%, tr:  62.10%, tr_best:  62.10%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.080683/  1.405091, val:  59.58%, val_best:  59.58%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.990555/  1.328532, val:  63.33%, val_best:  63.33%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.933939/  1.275293, val:  65.83%, val_best:  65.83%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.852055/  1.265472, val:  64.17%, val_best:  65.83%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.798317/  1.251875, val:  65.00%, val_best:  65.83%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.755471/  1.278903, val:  67.92%, val_best:  67.92%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.695203/  1.293574, val:  71.67%, val_best:  71.67%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.666707/  1.332700, val:  65.00%, val_best:  71.67%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.588037/  1.241452, val:  71.25%, val_best:  71.67%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.577586/  1.288363, val:  68.75%, val_best:  71.67%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.529531/  1.309248, val:  70.00%, val_best:  71.67%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.480440/  1.497092, val:  69.17%, val_best:  71.67%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.455086/  1.389291, val:  69.58%, val_best:  71.67%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.409623/  1.354792, val:  77.08%, val_best:  77.08%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.365742/  1.365264, val:  78.33%, val_best:  78.33%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.341054/  1.416604, val:  67.92%, val_best:  78.33%, tr:  96.12%, tr_best:  97.96%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.309159/  1.518090, val:  65.42%, val_best:  78.33%, tr:  97.24%, tr_best:  97.96%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.281904/  1.545641, val:  73.75%, val_best:  78.33%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.259397/  1.622575, val:  69.17%, val_best:  78.33%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.223468/  1.637111, val:  71.67%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.219616/  1.561787, val:  79.58%, val_best:  79.58%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.175065/  1.590408, val:  78.33%, val_best:  79.58%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.158339/  1.609632, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.157065/  1.602524, val:  80.83%, val_best:  80.83%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.136197/  1.700850, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.115811/  1.690304, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.103701/  1.758471, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.085545/  1.756503, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.085954/  1.775013, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.078344/  1.823073, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.070369/  1.839505, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.060453/  1.917351, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.058317/  1.895052, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.051140/  1.912192, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.040779/  1.930339, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.037260/  1.926906, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.037809/  1.967368, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.031647/  1.988282, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.028368/  1.989620, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.028347/  1.982446, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.025434/  2.009107, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.022192/  2.043795, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.019444/  2.053592, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.019039/  2.082557, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.016845/  2.100438, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.015546/  2.093639, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.014918/  2.113493, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.014227/  2.117326, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.013475/  2.149936, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.014253/  2.143698, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.013171/  2.141709, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.011284/  2.172559, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.011540/  2.178073, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.011390/  2.182519, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.010937/  2.197639, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.009923/  2.225821, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.009607/  2.210573, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.009297/  2.225993, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.009391/  2.246781, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.008771/  2.263395, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.008217/  2.272469, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.007298/  2.268537, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.007147/  2.284866, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.007289/  2.292893, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.007205/  2.305815, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.006735/  2.304552, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.006505/  2.315229, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.006408/  2.307411, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.006871/  2.330429, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.006410/  2.315210, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.006046/  2.320779, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.005530/  2.314020, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.005610/  2.335378, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.006132/  2.335202, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.005246/  2.339326, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.004800/  2.349553, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.005062/  2.369631, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.004855/  2.375621, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.004846/  2.359398, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.004765/  2.363947, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.004539/  2.378445, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.004307/  2.387015, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.004140/  2.389626, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.004103/  2.407632, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.003922/  2.415345, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.004101/  2.422428, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.003872/  2.421356, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.004023/  2.421541, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.004043/  2.416546, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.003744/  2.429828, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.003534/  2.428027, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.003777/  2.433073, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.003640/  2.439327, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.003337/  2.442110, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.003486/  2.455488, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.003231/  2.464000, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.003136/  2.448555, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fd0876d79a46bca4ac5bf4abf5a833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▂▃▁▇▇▂████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▆▅▅▇▅▅▇█▇▇▇▇▇▇▇▇███████▇████▇█▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▆▅▅▇▅▅▇█▇▇▇▇▇▇▇▇███████▇████▇█▇▇▇▇██</td></tr><tr><td>val_loss</td><td>▄▂▁▁▁▁▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00314</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>2.44856</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-80</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6g6l2luf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6g6l2luf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_010208-6g6l2luf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xihslute with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_010840-xihslute</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xihslute' target=\"_blank\">autumn-sweep-84</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xihslute' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xihslute</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.938504/  1.640882, val:  41.25%, val_best:  41.25%, tr:  27.89%, tr_best:  27.89%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.317404/  1.461997, val:  53.33%, val_best:  53.33%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.190751/  1.402987, val:  60.83%, val_best:  60.83%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.017383/  1.515241, val:  57.08%, val_best:  60.83%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.977931/  1.340519, val:  65.83%, val_best:  65.83%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.915254/  1.374753, val:  62.50%, val_best:  65.83%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.850480/  1.375341, val:  63.33%, val_best:  65.83%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.782186/  1.512994, val:  63.75%, val_best:  65.83%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.740673/  1.479688, val:  67.50%, val_best:  67.50%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.648208/  1.558541, val:  62.92%, val_best:  67.50%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.625063/  1.694741, val:  65.00%, val_best:  67.50%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.531183/  1.560369, val:  75.83%, val_best:  75.83%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.486659/  1.630527, val:  72.92%, val_best:  75.83%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.448822/  1.692085, val:  75.83%, val_best:  75.83%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.388249/  1.799662, val:  72.50%, val_best:  75.83%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.358896/  1.895715, val:  71.67%, val_best:  75.83%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.338432/  1.892128, val:  72.50%, val_best:  75.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.309274/  1.905239, val:  73.75%, val_best:  75.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.293472/  1.999134, val:  73.75%, val_best:  75.83%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.258605/  2.090443, val:  71.25%, val_best:  75.83%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.228238/  2.168044, val:  74.17%, val_best:  75.83%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.210675/  2.180846, val:  73.75%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.193211/  2.216239, val:  72.50%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.181918/  2.276545, val:  74.58%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.154072/  2.290147, val:  76.67%, val_best:  76.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.143716/  2.361749, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.143240/  2.455405, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.127284/  2.515887, val:  74.58%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.113221/  2.533747, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.103030/  2.637879, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.096817/  2.637688, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.088079/  2.632921, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.084368/  2.698198, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.082466/  2.788178, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.070666/  2.828412, val:  73.75%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.070446/  2.838286, val:  74.17%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.064757/  2.835955, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.059837/  2.893404, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.054756/  2.887219, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.051138/  2.925054, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.049886/  2.993777, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.045806/  2.974859, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.042271/  3.033602, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.040441/  3.034586, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.037214/  3.005142, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.034083/  3.092935, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.032247/  3.084149, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.030773/  3.119865, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.031271/  3.129151, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.029029/  3.157838, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.026615/  3.149428, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.024340/  3.174185, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.022277/  3.162220, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.020648/  3.192266, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.022416/  3.200281, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.023623/  3.228860, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.021722/  3.247716, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.023415/  3.289253, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.022212/  3.275930, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.019791/  3.312250, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.017404/  3.309093, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.017141/  3.331068, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.017988/  3.336666, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.014694/  3.319099, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.013113/  3.339378, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.013934/  3.299650, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.012424/  3.336388, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.014538/  3.341114, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.016677/  3.348902, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.016031/  3.390695, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.012863/  3.399561, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.013483/  3.440865, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.012144/  3.435546, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.010964/  3.446314, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.013235/  3.453158, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.012145/  3.454694, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.010849/  3.482747, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.009523/  3.507155, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.009953/  3.511697, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.009573/  3.516718, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.009758/  3.555545, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.009337/  3.526441, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.009121/  3.548402, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.008877/  3.558902, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.008850/  3.560302, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.007228/  3.579894, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.008444/  3.593151, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.008731/  3.583485, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.008191/  3.589946, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.009358/  3.619882, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.009902/  3.597133, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.008657/  3.631924, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.007008/  3.655694, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.006696/  3.622009, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.006522/  3.638667, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.006302/  3.652820, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.005724/  3.620535, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.006226/  3.668439, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.006493/  3.665642, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.006414/  3.654250, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455ccd02f9f44231a56cd07ecd69cfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▄▆▆█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▅▅▇▇▇▇▇█▇▇█▇█████████████████████▇███</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▅▅▇▇▇▇▇█▇▇█▇█████████████████████▇███</td></tr><tr><td>val_loss</td><td>▂▁▁▂▂▂▂▃▃▄▄▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00641</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>3.65425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-84</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xihslute' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xihslute</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_010840-xihslute/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1z5f9tht with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_011542-1z5f9tht</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1z5f9tht' target=\"_blank\">resilient-sweep-88</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1z5f9tht' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1z5f9tht</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.008364/  1.608458, val:  52.50%, val_best:  52.50%, tr:  30.03%, tr_best:  30.03%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.374709/  1.471918, val:  55.42%, val_best:  55.42%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.204977/  1.388918, val:  59.58%, val_best:  59.58%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.032300/  1.526812, val:  57.08%, val_best:  59.58%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.945360/  1.497551, val:  62.08%, val_best:  62.08%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.886835/  1.445980, val:  66.25%, val_best:  66.25%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.808012/  1.410287, val:  60.00%, val_best:  66.25%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.739172/  1.506575, val:  65.00%, val_best:  66.25%, tr:  77.22%, tr_best:  78.35%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.680080/  1.573759, val:  65.42%, val_best:  66.25%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.617143/  1.691453, val:  65.42%, val_best:  66.25%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.581684/  1.698720, val:  69.58%, val_best:  69.58%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.500964/  1.746773, val:  73.33%, val_best:  73.33%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.452154/  1.805467, val:  69.58%, val_best:  73.33%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.409395/  1.889858, val:  72.50%, val_best:  73.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.332563/  2.229170, val:  71.25%, val_best:  73.33%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.305346/  2.169692, val:  70.83%, val_best:  73.33%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.255759/  2.350931, val:  68.75%, val_best:  73.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.251347/  2.197459, val:  76.25%, val_best:  76.25%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.197419/  2.270770, val:  74.58%, val_best:  76.25%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.168556/  2.449761, val:  74.17%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.168059/  2.695299, val:  71.25%, val_best:  76.25%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.160893/  2.666319, val:  68.75%, val_best:  76.25%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.108310/  2.604903, val:  76.25%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.120111/  2.601001, val:  76.67%, val_best:  76.67%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.079443/  2.708733, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.049571/  2.737780, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.039638/  2.697255, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.039905/  2.875513, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.023695/  2.838433, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.019868/  2.873804, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.016261/  2.880155, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.015449/  2.878868, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.014415/  2.928833, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.012970/  2.938431, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.011393/  3.037414, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.010638/  3.101221, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.009004/  3.039071, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.010360/  3.066433, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.006780/  3.037152, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.006596/  3.068453, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.005337/  3.114017, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.005951/  3.111064, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.004758/  3.167670, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.004250/  3.149670, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.003208/  3.132931, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.003688/  3.185057, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.003528/  3.196795, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002923/  3.243393, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002326/  3.195115, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002400/  3.210095, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002603/  3.225904, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002443/  3.197799, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.003612/  3.258526, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.004137/  3.234734, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.003802/  3.217031, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.003825/  3.244654, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002428/  3.229712, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.002093/  3.278054, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.002160/  3.249174, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.002025/  3.291715, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001790/  3.254856, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001516/  3.265167, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001461/  3.292719, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001477/  3.300766, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001682/  3.303293, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001970/  3.298305, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001939/  3.326146, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001428/  3.342084, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001377/  3.326409, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001342/  3.364409, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001373/  3.347101, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001265/  3.370033, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001071/  3.368817, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001040/  3.373309, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001253/  3.361948, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001431/  3.365650, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001217/  3.357425, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001101/  3.361525, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.000970/  3.381468, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001038/  3.391617, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.000997/  3.379458, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.000913/  3.366438, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.000953/  3.396550, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.000921/  3.391519, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.000862/  3.413682, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.000884/  3.404688, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000955/  3.406603, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.000880/  3.401722, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.000807/  3.390507, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.000954/  3.389870, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.002133/  3.431521, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001350/  3.406967, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000966/  3.421370, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001067/  3.415986, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001020/  3.414259, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.000902/  3.420812, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.000876/  3.418736, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001342/  3.404874, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.001989/  3.444068, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.001697/  3.438380, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b11cc0000a4908a616087460983a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▆▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▄▅▆▇▆▅▇▇▇▇███▇██▇▇█▇███▇▇▇▇████▇██▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▄▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▄▅▆▇▆▅▇▇▇▇███▇██▇▇█▇███▇▇▇▇████▇██▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0017</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>3.43838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resilient-sweep-88</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1z5f9tht' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1z5f9tht</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_011542-1z5f9tht/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yraidv2m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_012201-yraidv2m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yraidv2m' target=\"_blank\">breezy-sweep-92</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yraidv2m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yraidv2m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.992836/  1.530355, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.270813/  1.365592, val:  54.58%, val_best:  54.58%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.069424/  1.281831, val:  57.08%, val_best:  57.08%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.933384/  1.251486, val:  61.25%, val_best:  61.25%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.866738/  1.182627, val:  65.83%, val_best:  65.83%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.786886/  1.128070, val:  68.33%, val_best:  68.33%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.703391/  1.155334, val:  62.50%, val_best:  68.33%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.662856/  1.105658, val:  74.17%, val_best:  74.17%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.586745/  1.165156, val:  70.00%, val_best:  74.17%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.531940/  1.184574, val:  71.25%, val_best:  74.17%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.481265/  1.274785, val:  68.33%, val_best:  74.17%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.411131/  1.205037, val:  71.25%, val_best:  74.17%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.380376/  1.218549, val:  72.92%, val_best:  74.17%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.355044/  1.233106, val:  73.33%, val_best:  74.17%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.313360/  1.399375, val:  67.08%, val_best:  74.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.281016/  1.315073, val:  68.75%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.276405/  1.278273, val:  71.67%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.230744/  1.304451, val:  73.33%, val_best:  74.17%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.217097/  1.367440, val:  72.50%, val_best:  74.17%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.189200/  1.388709, val:  72.92%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.168005/  1.429032, val:  71.67%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.156738/  1.423135, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.155678/  1.448348, val:  72.50%, val_best:  74.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.137104/  1.465722, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.117735/  1.489887, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.113048/  1.494661, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.111899/  1.517547, val:  74.58%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.094039/  1.552814, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.085773/  1.558714, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.080534/  1.610260, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.074078/  1.616008, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.076707/  1.639017, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.064758/  1.633267, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.065957/  1.667854, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.062587/  1.702203, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.057386/  1.693906, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.053166/  1.707784, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.051085/  1.738894, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.050181/  1.742640, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.047369/  1.752363, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.044923/  1.768679, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.040334/  1.768954, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.039417/  1.797302, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.038766/  1.812773, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.038489/  1.810026, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.035944/  1.837535, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.032449/  1.834346, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.031562/  1.855415, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.030469/  1.863177, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.028516/  1.870352, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.027792/  1.918565, val:  71.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.026748/  1.908998, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.026891/  1.912619, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.028077/  1.918764, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.025418/  1.924893, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.023315/  1.923090, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.022478/  1.936789, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.021557/  1.945426, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.021156/  1.942656, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.019743/  1.953326, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.020329/  1.953163, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.019369/  1.960923, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.017890/  1.973290, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.017283/  1.984569, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.016926/  1.986783, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.016638/  2.007506, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.016184/  2.003598, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.015977/  2.000960, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.015402/  2.013381, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.014964/  2.022342, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.014858/  2.019135, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.015367/  2.032981, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.014025/  2.042576, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.013691/  2.045029, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.013978/  2.043543, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.013692/  2.051186, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.012567/  2.055531, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.012612/  2.053025, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.011796/  2.063824, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.011929/  2.070036, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.011806/  2.073155, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.011632/  2.079894, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.011438/  2.081168, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.011136/  2.092202, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.011016/  2.103305, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.010949/  2.107349, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.010504/  2.118123, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.010123/  2.105605, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.010164/  2.123651, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.009368/  2.132211, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.009824/  2.126709, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.009035/  2.133195, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.009100/  2.135625, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.009616/  2.147619, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.009408/  2.143027, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.009128/  2.150978, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.008981/  2.144156, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.008209/  2.152747, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.008215/  2.172714, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.008785/  2.173029, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a3a5b2c2b2488c9e225039e77937a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▇▆▇█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▄▂▂▁▂▂▃▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00878</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>2.17303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-92</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yraidv2m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yraidv2m</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_012201-yraidv2m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dxjxm55j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_012901-dxjxm55j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dxjxm55j' target=\"_blank\">desert-sweep-96</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dxjxm55j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dxjxm55j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.101541/  1.705437, val:  44.17%, val_best:  44.17%, tr:  21.65%, tr_best:  21.65%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.427291/  1.495476, val:  55.42%, val_best:  55.42%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.234004/  1.433671, val:  57.50%, val_best:  57.50%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.119208/  1.399969, val:  59.58%, val_best:  59.58%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.072644/  1.327740, val:  62.08%, val_best:  62.08%, tr:  66.19%, tr_best:  66.19%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.024688/  1.294808, val:  64.58%, val_best:  64.58%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.962419/  1.299021, val:  58.33%, val_best:  64.58%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.943641/  1.246138, val:  64.58%, val_best:  64.58%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.912892/  1.274094, val:  65.83%, val_best:  65.83%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.868515/  1.316151, val:  64.58%, val_best:  65.83%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.849140/  1.369713, val:  57.92%, val_best:  65.83%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.791138/  1.193023, val:  72.92%, val_best:  72.92%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.769048/  1.219640, val:  68.75%, val_best:  72.92%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.740487/  1.279686, val:  65.42%, val_best:  72.92%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.701644/  1.395256, val:  65.83%, val_best:  72.92%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.683036/  1.283003, val:  70.83%, val_best:  72.92%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.665659/  1.208397, val:  74.58%, val_best:  74.58%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.617594/  1.240173, val:  70.83%, val_best:  74.58%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.604865/  1.311759, val:  70.83%, val_best:  74.58%, tr:  91.62%, tr_best:  92.65%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.577839/  1.296950, val:  72.08%, val_best:  74.58%, tr:  91.32%, tr_best:  92.65%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.555077/  1.324425, val:  67.08%, val_best:  74.58%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.538471/  1.309493, val:  71.25%, val_best:  74.58%, tr:  93.26%, tr_best:  94.59%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.522815/  1.330669, val:  68.33%, val_best:  74.58%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.526528/  1.307281, val:  71.25%, val_best:  74.58%, tr:  94.38%, tr_best:  95.51%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.469417/  1.319095, val:  74.17%, val_best:  74.58%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.462766/  1.299407, val:  76.67%, val_best:  76.67%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.470814/  1.304700, val:  74.58%, val_best:  76.67%, tr:  94.18%, tr_best:  96.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.430539/  1.360234, val:  72.50%, val_best:  76.67%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.414955/  1.327409, val:  77.92%, val_best:  77.92%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.405118/  1.443299, val:  72.50%, val_best:  77.92%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.386219/  1.399337, val:  74.58%, val_best:  77.92%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.377999/  1.428092, val:  74.17%, val_best:  77.92%, tr:  97.75%, tr_best:  97.96%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.388867/  1.468970, val:  73.75%, val_best:  77.92%, tr:  97.75%, tr_best:  97.96%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.380117/  1.441606, val:  72.92%, val_best:  77.92%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.355473/  1.503972, val:  70.83%, val_best:  77.92%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.355916/  1.498461, val:  72.92%, val_best:  77.92%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.326438/  1.438901, val:  78.33%, val_best:  78.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.321928/  1.476905, val:  75.42%, val_best:  78.33%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.315707/  1.483829, val:  76.25%, val_best:  78.33%, tr:  98.47%, tr_best:  99.08%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.307685/  1.464998, val:  77.50%, val_best:  78.33%, tr:  98.77%, tr_best:  99.08%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.306315/  1.531820, val:  76.67%, val_best:  78.33%, tr:  98.47%, tr_best:  99.08%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.287101/  1.543935, val:  76.25%, val_best:  78.33%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.288729/  1.530743, val:  75.42%, val_best:  78.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.268593/  1.562824, val:  76.67%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.265242/  1.553149, val:  77.50%, val_best:  78.33%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.252620/  1.539915, val:  80.42%, val_best:  80.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.255615/  1.539937, val:  80.00%, val_best:  80.42%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.240803/  1.569030, val:  78.75%, val_best:  80.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.238624/  1.553267, val:  78.75%, val_best:  80.42%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.234122/  1.588045, val:  81.25%, val_best:  81.25%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.221198/  1.649723, val:  77.50%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.220337/  1.638631, val:  80.42%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.215198/  1.618470, val:  80.00%, val_best:  81.25%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.208147/  1.669891, val:  78.75%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.208857/  1.652514, val:  79.58%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.196989/  1.680173, val:  77.92%, val_best:  81.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.192231/  1.735240, val:  77.50%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.205126/  1.679641, val:  80.42%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.181393/  1.746649, val:  79.58%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.177156/  1.739695, val:  81.25%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.174718/  1.762753, val:  80.83%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.176704/  1.766982, val:  80.00%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.165018/  1.785090, val:  79.58%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.163311/  1.785574, val:  79.17%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.156542/  1.797117, val:  79.17%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.151039/  1.819122, val:  80.83%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.147096/  1.826458, val:  82.08%, val_best:  82.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.146047/  1.832819, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.144980/  1.862115, val:  80.83%, val_best:  82.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.137560/  1.866465, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.136603/  1.883384, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.145329/  1.869765, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.137553/  1.918341, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.134755/  1.880919, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.128260/  1.911110, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.124197/  1.928428, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.127749/  1.906390, val:  80.42%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.124034/  1.942630, val:  78.75%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.116879/  1.976337, val:  80.42%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.118204/  1.956524, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.112945/  1.946819, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.110931/  1.931917, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.107641/  1.992500, val:  80.42%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.104187/  2.028512, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.104759/  2.008801, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.109663/  2.005770, val:  81.67%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.106445/  2.020138, val:  79.17%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.103418/  2.010340, val:  81.67%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.101644/  2.025369, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.094127/  2.020715, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.097548/  2.040927, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.092285/  2.045221, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.089651/  2.050596, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.088235/  2.062793, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.088743/  2.065829, val:  81.25%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.089883/  2.100394, val:  80.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.085511/  2.149553, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.087237/  2.075638, val:  81.25%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.083451/  2.120402, val:  78.33%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.086739/  2.101919, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ccb173dd924acaaf19544539fe8528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▄▆▄▇▄▇████▇██▇███████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▅▅▆▅▆▆▆▇▇▆▇▆▇▇▇▇▇█████████▇▇▇████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▅▅▆▅▆▆▆▇▇▆▇▆▇▇▇▇▇█████████▇▇▇████████</td></tr><tr><td>val_loss</td><td>▅▃▂▁▂▁▂▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.08674</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>2.10192</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">desert-sweep-96</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dxjxm55j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dxjxm55j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_012901-dxjxm55j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n3gi2wfb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d882560eb34bb4b07e4313dfdad6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113048375894627, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_013609-n3gi2wfb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n3gi2wfb' target=\"_blank\">deep-sweep-100</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n3gi2wfb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n3gi2wfb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.243242/  2.124186, val:  28.33%, val_best:  28.33%, tr:  17.26%, tr_best:  17.26%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.864803/  1.757179, val:  50.83%, val_best:  50.83%, tr:  40.96%, tr_best:  40.96%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.521397/  1.569973, val:  51.67%, val_best:  51.67%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.351221/  1.527105, val:  56.67%, val_best:  56.67%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.264221/  1.438615, val:  59.17%, val_best:  59.17%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.188069/  1.391747, val:  61.67%, val_best:  61.67%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.108269/  1.374183, val:  60.00%, val_best:  61.67%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.065224/  1.341167, val:  59.17%, val_best:  61.67%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.007178/  1.310837, val:  66.25%, val_best:  66.25%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.975028/  1.330811, val:  61.25%, val_best:  66.25%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.952237/  1.380338, val:  55.83%, val_best:  66.25%, tr:  69.87%, tr_best:  71.09%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.906371/  1.268516, val:  64.17%, val_best:  66.25%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.889389/  1.286184, val:  59.58%, val_best:  66.25%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.858184/  1.310512, val:  65.00%, val_best:  66.25%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.821835/  1.380808, val:  62.08%, val_best:  66.25%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.800791/  1.373180, val:  63.75%, val_best:  66.25%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.827191/  1.296533, val:  66.67%, val_best:  66.67%, tr:  75.59%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.772485/  1.333233, val:  63.75%, val_best:  66.67%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.747060/  1.429825, val:  63.75%, val_best:  66.67%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.751238/  1.417867, val:  66.67%, val_best:  66.67%, tr:  80.59%, tr_best:  82.33%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.720116/  1.420429, val:  67.92%, val_best:  67.92%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.699841/  1.423842, val:  65.83%, val_best:  67.92%, tr:  84.37%, tr_best:  84.88%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.715861/  1.433404, val:  67.92%, val_best:  67.92%, tr:  83.15%, tr_best:  84.88%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.685908/  1.459699, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.659097/  1.466386, val:  66.25%, val_best:  67.92%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.648164/  1.478790, val:  68.75%, val_best:  68.75%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.651217/  1.521018, val:  67.08%, val_best:  68.75%, tr:  87.13%, tr_best:  87.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.611899/  1.564894, val:  69.17%, val_best:  69.17%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.624858/  1.512855, val:  70.00%, val_best:  70.00%, tr:  87.95%, tr_best:  89.38%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.606112/  1.705009, val:  64.17%, val_best:  70.00%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.578967/  1.667041, val:  67.50%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.587257/  1.687154, val:  67.92%, val_best:  70.00%, tr:  89.48%, tr_best:  92.54%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.613017/  1.677269, val:  70.00%, val_best:  70.00%, tr:  90.70%, tr_best:  92.54%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.613487/  1.663072, val:  66.25%, val_best:  70.00%, tr:  91.62%, tr_best:  92.54%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.569194/  1.789078, val:  66.67%, val_best:  70.00%, tr:  91.52%, tr_best:  92.54%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.580293/  1.845011, val:  66.67%, val_best:  70.00%, tr:  89.17%, tr_best:  92.54%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.521068/  1.697164, val:  70.42%, val_best:  70.42%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.507637/  1.833766, val:  68.33%, val_best:  70.42%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.530018/  1.933958, val:  66.25%, val_best:  70.42%, tr:  94.59%, tr_best:  95.10%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.501346/  1.851378, val:  69.58%, val_best:  70.42%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.506107/  1.922060, val:  69.58%, val_best:  70.42%, tr:  93.56%, tr_best:  95.40%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.489477/  1.989336, val:  68.75%, val_best:  70.42%, tr:  95.20%, tr_best:  95.40%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.471262/  1.951523, val:  70.83%, val_best:  70.83%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.461584/  2.020993, val:  66.67%, val_best:  70.83%, tr:  94.99%, tr_best:  96.02%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.461115/  1.962519, val:  65.83%, val_best:  70.83%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.440820/  2.004915, val:  68.75%, val_best:  70.83%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.450386/  2.151669, val:  66.67%, val_best:  70.83%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.406636/  2.164783, val:  67.92%, val_best:  70.83%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.420317/  2.174956, val:  68.33%, val_best:  70.83%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.429699/  2.121202, val:  68.75%, val_best:  70.83%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.388140/  2.245872, val:  68.75%, val_best:  70.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.462284/  2.170427, val:  71.67%, val_best:  71.67%, tr:  94.69%, tr_best:  98.37%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.365864/  2.289234, val:  68.33%, val_best:  71.67%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.359126/  2.404623, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.348281/  2.307922, val:  69.58%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.361034/  2.443887, val:  69.17%, val_best:  71.67%, tr:  98.26%, tr_best:  98.88%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.349044/  2.487273, val:  67.92%, val_best:  71.67%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.359885/  2.505711, val:  69.58%, val_best:  71.67%, tr:  97.75%, tr_best:  98.88%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.339618/  2.492781, val:  68.33%, val_best:  71.67%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.329144/  2.607036, val:  67.50%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.312389/  2.642590, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.325251/  2.597434, val:  65.42%, val_best:  71.67%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.323082/  2.599294, val:  67.50%, val_best:  71.67%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.284650/  2.684657, val:  67.08%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.282754/  2.802027, val:  67.50%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.291464/  2.812501, val:  65.00%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.276671/  2.786575, val:  65.83%, val_best:  71.67%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.258991/  2.857569, val:  67.08%, val_best:  71.67%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.264946/  2.958286, val:  66.25%, val_best:  71.67%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.280527/  3.043354, val:  64.17%, val_best:  71.67%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.234249/  2.915497, val:  65.00%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.233587/  3.172272, val:  63.75%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.237163/  3.103238, val:  63.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.268257/  3.077068, val:  67.08%, val_best:  71.67%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.225738/  3.136847, val:  65.83%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.223096/  3.231972, val:  66.67%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.220988/  3.110435, val:  65.42%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.263986/  3.246860, val:  66.67%, val_best:  71.67%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.280463/  3.234407, val:  66.25%, val_best:  71.67%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.248444/  3.156211, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.209407/  3.240279, val:  65.42%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.207473/  3.201180, val:  67.92%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.235370/  3.239149, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.273124/  3.437421, val:  65.83%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.215331/  3.306569, val:  70.00%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.214575/  3.467093, val:  66.67%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.182948/  3.345486, val:  68.75%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.195729/  3.396218, val:  68.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.181826/  3.446512, val:  67.50%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.165390/  3.546609, val:  66.67%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.194697/  3.544030, val:  66.67%, val_best:  71.67%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.197478/  3.558749, val:  66.25%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.178992/  3.519618, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.175679/  3.575575, val:  67.08%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.161661/  3.649698, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.158628/  3.667777, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.146545/  3.738120, val:  67.08%, val_best:  71.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.159661/  3.732493, val:  66.25%, val_best:  71.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.124277/  3.781419, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.144722/  3.838679, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d9800132e4968b3a2499ee3665e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▂▄▆▁▄███▇▇▇█▇▇███████████▇███▇██▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▃▄▄▄▅▅▅▅▆▆▇▇▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.14472</td></tr><tr><td>val_acc_best</td><td>0.71667</td></tr><tr><td>val_acc_now</td><td>0.675</td></tr><tr><td>val_loss</td><td>3.83868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-100</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n3gi2wfb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n3gi2wfb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_013609-n3gi2wfb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lteu45t5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfdcbe604034fc7a70902119fcebf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113810508201519, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_014222-lteu45t5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lteu45t5' target=\"_blank\">treasured-sweep-104</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lteu45t5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lteu45t5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.223132/  2.002686, val:  33.33%, val_best:  33.33%, tr:  15.73%, tr_best:  15.73%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.646732/  1.575394, val:  55.42%, val_best:  55.42%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.372906/  1.491806, val:  55.83%, val_best:  55.83%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.268665/  1.484575, val:  59.58%, val_best:  59.58%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.219088/  1.457247, val:  60.42%, val_best:  60.42%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.171647/  1.394018, val:  62.92%, val_best:  62.92%, tr:  63.64%, tr_best:  64.04%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.116940/  1.393969, val:  60.00%, val_best:  62.92%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.093962/  1.379677, val:  58.33%, val_best:  62.92%, tr:  66.91%, tr_best:  67.31%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.055203/  1.372605, val:  64.17%, val_best:  64.17%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.043046/  1.387284, val:  59.17%, val_best:  64.17%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.033951/  1.394526, val:  57.50%, val_best:  64.17%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.007317/  1.371447, val:  64.58%, val_best:  64.58%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.000964/  1.352160, val:  60.42%, val_best:  64.58%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.997045/  1.362018, val:  64.17%, val_best:  64.58%, tr:  71.91%, tr_best:  73.54%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.958671/  1.464957, val:  61.25%, val_best:  64.58%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.963711/  1.388220, val:  64.17%, val_best:  64.58%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.981052/  1.361770, val:  62.92%, val_best:  64.58%, tr:  73.34%, tr_best:  75.59%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.937431/  1.376124, val:  65.42%, val_best:  65.42%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.928476/  1.498154, val:  58.75%, val_best:  65.42%, tr:  75.89%, tr_best:  77.94%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.934240/  1.411411, val:  62.92%, val_best:  65.42%, tr:  75.18%, tr_best:  77.94%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.917973/  1.429030, val:  62.92%, val_best:  65.42%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.905660/  1.420187, val:  62.50%, val_best:  65.42%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.928158/  1.459875, val:  61.67%, val_best:  65.42%, tr:  75.89%, tr_best:  78.86%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.907592/  1.476621, val:  61.25%, val_best:  65.42%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.880166/  1.470958, val:  61.25%, val_best:  65.42%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.881017/  1.433986, val:  65.83%, val_best:  65.83%, tr:  79.67%, tr_best:  82.84%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.895718/  1.456358, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.886454/  1.536756, val:  57.92%, val_best:  66.25%, tr:  81.10%, tr_best:  82.84%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.887316/  1.461037, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.864054/  1.579258, val:  60.83%, val_best:  66.25%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.856266/  1.603251, val:  59.58%, val_best:  66.25%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885827/  1.554118, val:  62.92%, val_best:  66.25%, tr:  80.08%, tr_best:  83.55%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.871941/  1.589672, val:  62.08%, val_best:  66.25%, tr:  80.69%, tr_best:  83.55%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.855188/  1.629326, val:  63.33%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.846618/  1.604717, val:  65.42%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.873432/  1.636944, val:  60.42%, val_best:  66.25%, tr:  81.61%, tr_best:  83.55%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.819472/  1.603188, val:  62.92%, val_best:  66.25%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.844137/  1.701811, val:  65.83%, val_best:  66.25%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.837160/  1.657102, val:  61.67%, val_best:  66.25%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.815818/  1.693619, val:  61.67%, val_best:  66.25%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.826555/  1.756078, val:  65.00%, val_best:  66.25%, tr:  83.66%, tr_best:  86.72%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816026/  1.728303, val:  61.25%, val_best:  66.25%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.808087/  1.654136, val:  66.25%, val_best:  66.25%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.814506/  1.772221, val:  62.50%, val_best:  66.25%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.792904/  1.756599, val:  66.67%, val_best:  66.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.779269/  1.761614, val:  64.58%, val_best:  66.67%, tr:  87.84%, tr_best:  88.66%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.775480/  1.741632, val:  66.67%, val_best:  66.67%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.783227/  1.807499, val:  65.00%, val_best:  66.67%, tr:  88.97%, tr_best:  89.07%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.805892/  1.723932, val:  65.00%, val_best:  66.67%, tr:  88.56%, tr_best:  89.07%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.796156/  1.767691, val:  67.08%, val_best:  67.08%, tr:  87.44%, tr_best:  89.07%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.794473/  1.827904, val:  64.17%, val_best:  67.08%, tr:  87.33%, tr_best:  89.07%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.829250/  1.777983, val:  64.58%, val_best:  67.08%, tr:  84.58%, tr_best:  89.07%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.766114/  1.804216, val:  64.17%, val_best:  67.08%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.770968/  1.810026, val:  67.50%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.793794/  1.856610, val:  65.83%, val_best:  67.50%, tr:  89.38%, tr_best:  90.70%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.760632/  1.853680, val:  62.92%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.778129/  1.968967, val:  61.67%, val_best:  67.50%, tr:  88.36%, tr_best:  90.70%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.802386/  1.824670, val:  65.00%, val_best:  67.50%, tr:  87.84%, tr_best:  90.70%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.768591/  1.996533, val:  60.42%, val_best:  67.50%, tr:  89.17%, tr_best:  90.70%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.766381/  1.939684, val:  65.42%, val_best:  67.50%, tr:  88.05%, tr_best:  90.70%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.758057/  1.876465, val:  66.25%, val_best:  67.50%, tr:  89.58%, tr_best:  90.70%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.768309/  1.941056, val:  61.25%, val_best:  67.50%, tr:  90.30%, tr_best:  90.70%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.762010/  2.005100, val:  60.42%, val_best:  67.50%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.749036/  1.964597, val:  64.17%, val_best:  67.50%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.767938/  2.052987, val:  60.83%, val_best:  67.50%, tr:  90.09%, tr_best:  91.73%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.754043/  1.993210, val:  62.50%, val_best:  67.50%, tr:  90.70%, tr_best:  91.73%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.770516/  2.113071, val:  61.25%, val_best:  67.50%, tr:  90.91%, tr_best:  91.73%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.766177/  1.978093, val:  60.42%, val_best:  67.50%, tr:  91.42%, tr_best:  91.73%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.757744/  2.173551, val:  58.33%, val_best:  67.50%, tr:  91.22%, tr_best:  91.73%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.776188/  2.089108, val:  63.33%, val_best:  67.50%, tr:  88.56%, tr_best:  91.73%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.762170/  2.067266, val:  64.17%, val_best:  67.50%, tr:  91.62%, tr_best:  91.73%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.781851/  2.191415, val:  60.42%, val_best:  67.50%, tr:  90.40%, tr_best:  91.73%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.758126/  2.176638, val:  62.50%, val_best:  67.50%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.786769/  2.128878, val:  63.33%, val_best:  67.50%, tr:  89.99%, tr_best:  92.13%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.800965/  2.129314, val:  63.33%, val_best:  67.50%, tr:  90.91%, tr_best:  92.13%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.804875/  2.252852, val:  61.67%, val_best:  67.50%, tr:  90.70%, tr_best:  92.13%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.766759/  2.272423, val:  62.92%, val_best:  67.50%, tr:  89.38%, tr_best:  92.13%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.821836/  2.259508, val:  61.25%, val_best:  67.50%, tr:  89.48%, tr_best:  92.13%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.811524/  2.266636, val:  60.83%, val_best:  67.50%, tr:  88.97%, tr_best:  92.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.776070/  2.216362, val:  63.33%, val_best:  67.50%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.771906/  2.261730, val:  60.83%, val_best:  67.50%, tr:  91.73%, tr_best:  92.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.802366/  2.255741, val:  64.17%, val_best:  67.50%, tr:  90.50%, tr_best:  92.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.802616/  2.359800, val:  55.83%, val_best:  67.50%, tr:  91.11%, tr_best:  92.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.791338/  2.454720, val:  61.25%, val_best:  67.50%, tr:  89.79%, tr_best:  92.13%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.788659/  2.234620, val:  64.17%, val_best:  67.50%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.780635/  2.285981, val:  59.58%, val_best:  67.50%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.771102/  2.369335, val:  62.08%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.810745/  2.302168, val:  65.42%, val_best:  67.50%, tr:  89.99%, tr_best:  93.05%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.783924/  2.403520, val:  60.42%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.752935/  2.452646, val:  60.00%, val_best:  67.50%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.818026/  2.384936, val:  61.67%, val_best:  67.50%, tr:  91.62%, tr_best:  93.05%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.790593/  2.616165, val:  55.42%, val_best:  67.50%, tr:  90.30%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.787843/  2.505027, val:  60.83%, val_best:  67.50%, tr:  91.93%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.791389/  2.424564, val:  63.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.785110/  2.480027, val:  62.08%, val_best:  67.50%, tr:  92.34%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.788248/  2.454785, val:  61.25%, val_best:  67.50%, tr:  91.73%, tr_best:  93.05%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.787971/  2.684330, val:  58.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.799346/  2.498815, val:  63.75%, val_best:  67.50%, tr:  89.89%, tr_best:  93.05%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.784911/  2.623399, val:  63.75%, val_best:  67.50%, tr:  90.91%, tr_best:  93.05%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.832112/  2.533987, val:  61.25%, val_best:  67.50%, tr:  89.68%, tr_best:  93.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a66b83219645ef83ff565648a17de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▄▆▃▃▆▇▇▆▆▆▇█▆▇▆▅█▆▆█▆▆▇▇▆▆█▅▇▆▇▃▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▂▂▁▁▁▂▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▆▇▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.89683</td></tr><tr><td>tr_epoch_loss</td><td>0.83211</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.6125</td></tr><tr><td>val_loss</td><td>2.53399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-sweep-104</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lteu45t5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lteu45t5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_014222-lteu45t5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0coui84l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_014918-0coui84l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0coui84l' target=\"_blank\">fast-sweep-108</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0coui84l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0coui84l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.243242/  2.124186, val:  28.33%, val_best:  28.33%, tr:  17.26%, tr_best:  17.26%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.864803/  1.757179, val:  50.83%, val_best:  50.83%, tr:  40.96%, tr_best:  40.96%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.521397/  1.569973, val:  51.67%, val_best:  51.67%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.351221/  1.527105, val:  56.67%, val_best:  56.67%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.264221/  1.438615, val:  59.17%, val_best:  59.17%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.188069/  1.391747, val:  61.67%, val_best:  61.67%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.108269/  1.374183, val:  60.00%, val_best:  61.67%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.065224/  1.341167, val:  59.17%, val_best:  61.67%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.007178/  1.310837, val:  66.25%, val_best:  66.25%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.975028/  1.330811, val:  61.25%, val_best:  66.25%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.952237/  1.380338, val:  55.83%, val_best:  66.25%, tr:  69.87%, tr_best:  71.09%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.906371/  1.268516, val:  64.17%, val_best:  66.25%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.889389/  1.286184, val:  59.58%, val_best:  66.25%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.858184/  1.310512, val:  65.00%, val_best:  66.25%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.821835/  1.380808, val:  62.08%, val_best:  66.25%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.800791/  1.373180, val:  63.75%, val_best:  66.25%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.827191/  1.296533, val:  66.67%, val_best:  66.67%, tr:  75.59%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.772485/  1.333233, val:  63.75%, val_best:  66.67%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.747060/  1.429825, val:  63.75%, val_best:  66.67%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.751238/  1.417867, val:  66.67%, val_best:  66.67%, tr:  80.59%, tr_best:  82.33%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.720116/  1.420429, val:  67.92%, val_best:  67.92%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.699841/  1.423842, val:  65.83%, val_best:  67.92%, tr:  84.37%, tr_best:  84.88%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.715861/  1.433404, val:  67.92%, val_best:  67.92%, tr:  83.15%, tr_best:  84.88%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.685908/  1.459699, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.659097/  1.466386, val:  66.25%, val_best:  67.92%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.648164/  1.478790, val:  68.75%, val_best:  68.75%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.651217/  1.521018, val:  67.08%, val_best:  68.75%, tr:  87.13%, tr_best:  87.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.611899/  1.564894, val:  69.17%, val_best:  69.17%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.624858/  1.512855, val:  70.00%, val_best:  70.00%, tr:  87.95%, tr_best:  89.38%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.606112/  1.705009, val:  64.17%, val_best:  70.00%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.578967/  1.667041, val:  67.50%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.587257/  1.687154, val:  67.92%, val_best:  70.00%, tr:  89.48%, tr_best:  92.54%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.613017/  1.677269, val:  70.00%, val_best:  70.00%, tr:  90.70%, tr_best:  92.54%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.613487/  1.663072, val:  66.25%, val_best:  70.00%, tr:  91.62%, tr_best:  92.54%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.569194/  1.789078, val:  66.67%, val_best:  70.00%, tr:  91.52%, tr_best:  92.54%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.580293/  1.845011, val:  66.67%, val_best:  70.00%, tr:  89.17%, tr_best:  92.54%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.521068/  1.697164, val:  70.42%, val_best:  70.42%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.507637/  1.833766, val:  68.33%, val_best:  70.42%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.530018/  1.933958, val:  66.25%, val_best:  70.42%, tr:  94.59%, tr_best:  95.10%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.501346/  1.851378, val:  69.58%, val_best:  70.42%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.506107/  1.922060, val:  69.58%, val_best:  70.42%, tr:  93.56%, tr_best:  95.40%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.489477/  1.989336, val:  68.75%, val_best:  70.42%, tr:  95.20%, tr_best:  95.40%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.471262/  1.951523, val:  70.83%, val_best:  70.83%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.461584/  2.020993, val:  66.67%, val_best:  70.83%, tr:  94.99%, tr_best:  96.02%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.461115/  1.962519, val:  65.83%, val_best:  70.83%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.440820/  2.004915, val:  68.75%, val_best:  70.83%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.450386/  2.151669, val:  66.67%, val_best:  70.83%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.406636/  2.164783, val:  67.92%, val_best:  70.83%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.420317/  2.174956, val:  68.33%, val_best:  70.83%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.429699/  2.121202, val:  68.75%, val_best:  70.83%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.388140/  2.245872, val:  68.75%, val_best:  70.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.462284/  2.170427, val:  71.67%, val_best:  71.67%, tr:  94.69%, tr_best:  98.37%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.365864/  2.289234, val:  68.33%, val_best:  71.67%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.359126/  2.404623, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.348281/  2.307922, val:  69.58%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.361034/  2.443887, val:  69.17%, val_best:  71.67%, tr:  98.26%, tr_best:  98.88%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.349044/  2.487273, val:  67.92%, val_best:  71.67%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.359885/  2.505711, val:  69.58%, val_best:  71.67%, tr:  97.75%, tr_best:  98.88%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.339618/  2.492781, val:  68.33%, val_best:  71.67%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.329144/  2.607036, val:  67.50%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.312389/  2.642590, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.325251/  2.597434, val:  65.42%, val_best:  71.67%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.323082/  2.599294, val:  67.50%, val_best:  71.67%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.284650/  2.684657, val:  67.08%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.282754/  2.802027, val:  67.50%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.291464/  2.812501, val:  65.00%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.276671/  2.786575, val:  65.83%, val_best:  71.67%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.258991/  2.857569, val:  67.08%, val_best:  71.67%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.264946/  2.958286, val:  66.25%, val_best:  71.67%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.280527/  3.043354, val:  64.17%, val_best:  71.67%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.234249/  2.915497, val:  65.00%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.233587/  3.172272, val:  63.75%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.237163/  3.103238, val:  63.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.268257/  3.077068, val:  67.08%, val_best:  71.67%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.225738/  3.136847, val:  65.83%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.223096/  3.231972, val:  66.67%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.220988/  3.110435, val:  65.42%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.263986/  3.246860, val:  66.67%, val_best:  71.67%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.280463/  3.234407, val:  66.25%, val_best:  71.67%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.248444/  3.156211, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.209407/  3.240279, val:  65.42%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.207473/  3.201180, val:  67.92%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.235370/  3.239149, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.273124/  3.437421, val:  65.83%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.215331/  3.306569, val:  70.00%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.214575/  3.467093, val:  66.67%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.182948/  3.345486, val:  68.75%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.195729/  3.396218, val:  68.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.181826/  3.446512, val:  67.50%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.165390/  3.546609, val:  66.67%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.194697/  3.544030, val:  66.67%, val_best:  71.67%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.197478/  3.558749, val:  66.25%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.178992/  3.519618, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.175679/  3.575575, val:  67.08%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.161661/  3.649698, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.158628/  3.667777, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.146545/  3.738120, val:  67.08%, val_best:  71.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.159661/  3.732493, val:  66.25%, val_best:  71.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.124277/  3.781419, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.144722/  3.838679, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fe218bc35d42b5b5701ca8e5b769c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▂▄▆▁▄███▇▇▇█▇▇███████████▇███▇██▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▃▄▄▄▅▅▅▅▆▆▇▇▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.14472</td></tr><tr><td>val_acc_best</td><td>0.71667</td></tr><tr><td>val_acc_now</td><td>0.675</td></tr><tr><td>val_loss</td><td>3.83868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-108</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0coui84l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0coui84l</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_014918-0coui84l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9zm92sj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_015539-n9zm92sj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n9zm92sj' target=\"_blank\">swift-sweep-112</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n9zm92sj' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n9zm92sj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.273818/  2.222530, val:  22.08%, val_best:  22.08%, tr:  16.24%, tr_best:  16.24%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.142191/  2.078036, val:  35.42%, val_best:  35.42%, tr:  28.70%, tr_best:  28.70%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.939570/  1.881010, val:  51.25%, val_best:  51.25%, tr:  44.13%, tr_best:  44.13%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.726709/  1.736983, val:  49.58%, val_best:  51.25%, tr:  51.48%, tr_best:  51.48%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.580908/  1.645921, val:  48.33%, val_best:  51.25%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.483293/  1.582306, val:  52.92%, val_best:  52.92%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.427029/  1.545796, val:  53.33%, val_best:  53.33%, tr:  58.22%, tr_best:  58.22%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.373922/  1.512188, val:  53.33%, val_best:  53.33%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.330579/  1.480447, val:  58.75%, val_best:  58.75%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.299843/  1.466618, val:  57.08%, val_best:  58.75%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.265174/  1.452660, val:  57.08%, val_best:  58.75%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.237906/  1.428298, val:  60.42%, val_best:  60.42%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.230057/  1.418218, val:  60.00%, val_best:  60.42%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.213599/  1.397276, val:  62.08%, val_best:  62.08%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.173706/  1.399103, val:  58.33%, val_best:  62.08%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.164229/  1.381113, val:  64.17%, val_best:  64.17%, tr:  66.09%, tr_best:  66.29%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.140009/  1.375154, val:  61.67%, val_best:  64.17%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.123435/  1.357370, val:  66.67%, val_best:  66.67%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.101345/  1.359325, val:  64.17%, val_best:  66.67%, tr:  68.95%, tr_best:  70.17%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.095541/  1.364873, val:  62.08%, val_best:  66.67%, tr:  67.11%, tr_best:  70.17%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.070207/  1.350767, val:  65.83%, val_best:  66.67%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.059847/  1.340439, val:  64.17%, val_best:  66.67%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.053895/  1.362418, val:  63.33%, val_best:  66.67%, tr:  68.95%, tr_best:  71.60%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.030164/  1.327953, val:  67.08%, val_best:  67.08%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.015773/  1.335099, val:  64.17%, val_best:  67.08%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.003062/  1.319029, val:  68.75%, val_best:  68.75%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.992001/  1.308965, val:  69.58%, val_best:  69.58%, tr:  73.75%, tr_best:  74.97%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.978354/  1.333263, val:  65.42%, val_best:  69.58%, tr:  76.51%, tr_best:  76.51%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.974972/  1.307635, val:  65.00%, val_best:  69.58%, tr:  75.18%, tr_best:  76.51%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.954319/  1.320678, val:  64.58%, val_best:  69.58%, tr:  75.59%, tr_best:  76.51%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.943358/  1.308603, val:  65.83%, val_best:  69.58%, tr:  75.49%, tr_best:  76.51%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.935696/  1.325087, val:  69.17%, val_best:  69.58%, tr:  76.00%, tr_best:  76.51%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.927954/  1.338678, val:  64.17%, val_best:  69.58%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.921722/  1.335066, val:  68.75%, val_best:  69.58%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.908837/  1.320341, val:  66.25%, val_best:  69.58%, tr:  77.22%, tr_best:  78.04%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.899046/  1.360935, val:  63.75%, val_best:  69.58%, tr:  77.53%, tr_best:  78.04%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.890746/  1.335332, val:  62.08%, val_best:  69.58%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.877339/  1.329951, val:  69.58%, val_best:  69.58%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.877042/  1.320268, val:  70.00%, val_best:  70.00%, tr:  81.41%, tr_best:  81.92%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.860805/  1.327827, val:  69.58%, val_best:  70.00%, tr:  80.90%, tr_best:  81.92%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.849837/  1.330432, val:  70.83%, val_best:  70.83%, tr:  80.80%, tr_best:  81.92%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.846789/  1.330328, val:  70.42%, val_best:  70.83%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.826809/  1.355422, val:  66.25%, val_best:  70.83%, tr:  85.09%, tr_best:  85.19%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.826684/  1.361061, val:  69.58%, val_best:  70.83%, tr:  82.64%, tr_best:  85.19%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.820560/  1.347655, val:  68.75%, val_best:  70.83%, tr:  80.90%, tr_best:  85.19%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.803435/  1.338632, val:  69.17%, val_best:  70.83%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.797324/  1.364299, val:  69.58%, val_best:  70.83%, tr:  85.29%, tr_best:  85.50%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.792908/  1.375672, val:  67.08%, val_best:  70.83%, tr:  82.84%, tr_best:  85.50%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.793822/  1.366205, val:  70.83%, val_best:  70.83%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.787196/  1.339954, val:  74.17%, val_best:  74.17%, tr:  85.39%, tr_best:  87.95%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.774740/  1.365398, val:  69.17%, val_best:  74.17%, tr:  85.90%, tr_best:  87.95%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.766241/  1.381560, val:  72.08%, val_best:  74.17%, tr:  87.54%, tr_best:  87.95%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.766333/  1.391287, val:  65.00%, val_best:  74.17%, tr:  85.60%, tr_best:  87.95%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.765495/  1.361164, val:  74.17%, val_best:  74.17%, tr:  85.39%, tr_best:  87.95%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.742573/  1.379645, val:  69.58%, val_best:  74.17%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.744352/  1.388652, val:  71.67%, val_best:  74.17%, tr:  88.46%, tr_best:  89.48%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.724573/  1.395636, val:  72.08%, val_best:  74.17%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.728662/  1.401633, val:  70.00%, val_best:  74.17%, tr:  89.17%, tr_best:  90.60%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.709337/  1.402028, val:  69.58%, val_best:  74.17%, tr:  89.07%, tr_best:  90.60%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.713754/  1.403358, val:  70.83%, val_best:  74.17%, tr:  89.27%, tr_best:  90.60%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.704584/  1.399634, val:  70.42%, val_best:  74.17%, tr:  89.48%, tr_best:  90.60%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.696006/  1.429689, val:  70.00%, val_best:  74.17%, tr:  89.27%, tr_best:  90.60%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.694232/  1.459346, val:  67.50%, val_best:  74.17%, tr:  89.17%, tr_best:  90.60%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.685001/  1.418185, val:  70.00%, val_best:  74.17%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.677154/  1.466423, val:  71.67%, val_best:  74.17%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.676050/  1.486573, val:  70.00%, val_best:  74.17%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.669371/  1.451000, val:  75.00%, val_best:  75.00%, tr:  90.40%, tr_best:  91.22%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.670578/  1.486866, val:  72.08%, val_best:  75.00%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.657087/  1.469058, val:  70.83%, val_best:  75.00%, tr:  89.99%, tr_best:  92.34%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.649523/  1.495108, val:  72.08%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.644205/  1.499997, val:  73.33%, val_best:  75.00%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.631729/  1.542442, val:  70.00%, val_best:  75.00%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.639986/  1.539856, val:  70.42%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.631186/  1.519689, val:  70.00%, val_best:  75.00%, tr:  92.65%, tr_best:  93.05%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.617082/  1.556238, val:  71.67%, val_best:  75.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.625138/  1.538250, val:  71.25%, val_best:  75.00%, tr:  92.85%, tr_best:  94.18%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.604425/  1.575666, val:  70.83%, val_best:  75.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.610037/  1.591379, val:  70.00%, val_best:  75.00%, tr:  93.05%, tr_best:  94.18%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.602856/  1.595269, val:  72.50%, val_best:  75.00%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.590539/  1.582070, val:  71.67%, val_best:  75.00%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.581975/  1.601726, val:  67.92%, val_best:  75.00%, tr:  94.18%, tr_best:  94.48%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.584935/  1.620869, val:  69.17%, val_best:  75.00%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.573780/  1.623938, val:  69.17%, val_best:  75.00%, tr:  94.59%, tr_best:  94.89%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.567469/  1.635053, val:  71.67%, val_best:  75.00%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.565320/  1.642029, val:  69.17%, val_best:  75.00%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.556058/  1.660344, val:  69.58%, val_best:  75.00%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.556893/  1.669695, val:  72.50%, val_best:  75.00%, tr:  95.40%, tr_best:  96.12%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.550573/  1.684049, val:  70.83%, val_best:  75.00%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.538491/  1.680002, val:  72.08%, val_best:  75.00%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.529986/  1.725007, val:  67.50%, val_best:  75.00%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.541465/  1.665970, val:  73.75%, val_best:  75.00%, tr:  95.81%, tr_best:  96.94%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.524672/  1.701176, val:  70.83%, val_best:  75.00%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.525259/  1.753062, val:  70.42%, val_best:  75.00%, tr:  96.73%, tr_best:  97.24%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.533777/  1.749123, val:  66.25%, val_best:  75.00%, tr:  96.02%, tr_best:  97.24%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.521413/  1.793484, val:  66.67%, val_best:  75.00%, tr:  96.63%, tr_best:  97.24%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.513267/  1.765542, val:  67.08%, val_best:  75.00%, tr:  96.94%, tr_best:  97.24%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.512040/  1.801333, val:  68.33%, val_best:  75.00%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.517622/  1.768761, val:  69.58%, val_best:  75.00%, tr:  94.99%, tr_best:  97.24%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.500190/  1.771072, val:  67.92%, val_best:  75.00%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.508606/  1.788883, val:  70.42%, val_best:  75.00%, tr:  96.42%, tr_best:  97.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4b9c6cf89e4c9c93b218eb60dd34a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▁▃▂▅▆▂▂▆▆▆▅▆▅▇▇▅█▇▆▆▇▇█▇█▇▇▇▇▇▆█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇█▇█▇▇█▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇█▇█▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96425</td></tr><tr><td>tr_epoch_loss</td><td>0.50861</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.70417</td></tr><tr><td>val_loss</td><td>1.78888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-sweep-112</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n9zm92sj' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n9zm92sj</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_015539-n9zm92sj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cop35cwz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_020157-cop35cwz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cop35cwz' target=\"_blank\">scarlet-sweep-115</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cop35cwz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cop35cwz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305096/  2.302658, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304728/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304693/  2.302339, val:  10.83%, val_best:  10.83%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.303576/  2.301017, val:  10.00%, val_best:  10.83%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.298600/  2.295210, val:  11.25%, val_best:  11.25%, tr:  13.59%, tr_best:  13.59%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.272594/  2.270865, val:  17.50%, val_best:  17.50%, tr:  16.34%, tr_best:  16.34%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.215499/  2.237830, val:  25.00%, val_best:  25.00%, tr:  21.55%, tr_best:  21.55%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.170267/  2.193887, val:  25.00%, val_best:  25.00%, tr:  26.35%, tr_best:  26.35%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.088695/  2.086650, val:  34.58%, val_best:  34.58%, tr:  32.69%, tr_best:  32.69%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.940284/  1.955743, val:  39.17%, val_best:  39.17%, tr:  41.06%, tr_best:  41.06%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.792898/  1.832241, val:  47.08%, val_best:  47.08%, tr:  45.25%, tr_best:  45.25%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.654497/  1.729021, val:  50.42%, val_best:  50.42%, tr:  52.09%, tr_best:  52.09%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.544335/  1.675065, val:  50.00%, val_best:  50.42%, tr:  53.83%, tr_best:  53.83%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.476754/  1.630565, val:  50.83%, val_best:  50.83%, tr:  55.87%, tr_best:  55.87%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.414323/  1.581363, val:  50.83%, val_best:  50.83%, tr:  58.32%, tr_best:  58.32%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.370531/  1.549902, val:  53.33%, val_best:  53.33%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.335585/  1.529557, val:  52.50%, val_best:  53.33%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.315694/  1.512243, val:  54.17%, val_best:  54.17%, tr:  60.16%, tr_best:  61.08%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.277089/  1.487082, val:  55.00%, val_best:  55.00%, tr:  60.98%, tr_best:  61.08%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.256041/  1.488778, val:  55.42%, val_best:  55.42%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.250545/  1.476662, val:  56.25%, val_best:  56.25%, tr:  60.88%, tr_best:  62.82%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.218640/  1.470145, val:  58.75%, val_best:  58.75%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.194566/  1.463137, val:  55.42%, val_best:  58.75%, tr:  65.78%, tr_best:  65.78%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.182896/  1.444472, val:  58.75%, val_best:  58.75%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.171862/  1.422048, val:  58.75%, val_best:  58.75%, tr:  65.37%, tr_best:  65.88%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.151253/  1.446525, val:  57.50%, val_best:  58.75%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.145063/  1.441748, val:  58.33%, val_best:  58.75%, tr:  66.09%, tr_best:  67.72%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.117597/  1.451230, val:  55.83%, val_best:  58.75%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.108670/  1.444108, val:  58.33%, val_best:  58.75%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.096717/  1.428121, val:  60.83%, val_best:  60.83%, tr:  68.03%, tr_best:  68.64%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.085384/  1.460401, val:  58.33%, val_best:  60.83%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.078108/  1.470889, val:  58.75%, val_best:  60.83%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.065331/  1.433775, val:  58.33%, val_best:  60.83%, tr:  69.87%, tr_best:  70.89%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.053450/  1.465870, val:  57.08%, val_best:  60.83%, tr:  70.58%, tr_best:  70.89%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.035833/  1.478960, val:  57.92%, val_best:  60.83%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.030091/  1.431935, val:  62.50%, val_best:  62.50%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.027647/  1.431315, val:  62.50%, val_best:  62.50%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.008991/  1.435165, val:  62.50%, val_best:  62.50%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.993595/  1.456788, val:  63.75%, val_best:  63.75%, tr:  72.83%, tr_best:  74.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.986814/  1.461894, val:  61.25%, val_best:  63.75%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.973631/  1.442253, val:  62.92%, val_best:  63.75%, tr:  75.18%, tr_best:  76.40%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.970135/  1.465158, val:  62.92%, val_best:  63.75%, tr:  74.16%, tr_best:  76.40%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.958218/  1.432110, val:  64.17%, val_best:  64.17%, tr:  75.28%, tr_best:  76.40%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.940759/  1.435442, val:  60.00%, val_best:  64.17%, tr:  75.69%, tr_best:  76.40%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.936741/  1.473385, val:  63.33%, val_best:  64.17%, tr:  76.30%, tr_best:  76.40%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.929839/  1.467393, val:  64.58%, val_best:  64.58%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.925004/  1.447257, val:  64.17%, val_best:  64.58%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.919165/  1.466440, val:  60.83%, val_best:  64.58%, tr:  75.49%, tr_best:  77.73%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.911514/  1.513587, val:  61.67%, val_best:  64.58%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.893552/  1.517593, val:  62.08%, val_best:  64.58%, tr:  78.14%, tr_best:  79.06%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.889545/  1.497727, val:  62.92%, val_best:  64.58%, tr:  77.83%, tr_best:  79.06%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.880685/  1.515013, val:  62.08%, val_best:  64.58%, tr:  78.24%, tr_best:  79.06%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.883369/  1.539923, val:  61.67%, val_best:  64.58%, tr:  78.75%, tr_best:  79.06%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.874360/  1.554753, val:  65.00%, val_best:  65.00%, tr:  78.24%, tr_best:  79.06%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.859677/  1.588967, val:  63.75%, val_best:  65.00%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.858494/  1.565753, val:  61.67%, val_best:  65.00%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.858677/  1.604127, val:  63.75%, val_best:  65.00%, tr:  79.47%, tr_best:  80.18%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.854617/  1.652472, val:  63.75%, val_best:  65.00%, tr:  79.98%, tr_best:  80.18%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.846600/  1.615804, val:  60.42%, val_best:  65.00%, tr:  79.88%, tr_best:  80.18%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.844144/  1.630593, val:  62.08%, val_best:  65.00%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.864328/  1.616019, val:  64.17%, val_best:  65.00%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.840967/  1.625246, val:  62.50%, val_best:  65.00%, tr:  81.31%, tr_best:  83.25%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.826756/  1.706619, val:  64.58%, val_best:  65.00%, tr:  82.33%, tr_best:  83.25%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.833094/  1.653506, val:  63.75%, val_best:  65.00%, tr:  81.92%, tr_best:  83.25%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.832286/  1.626283, val:  67.92%, val_best:  67.92%, tr:  82.12%, tr_best:  83.25%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.836717/  1.677644, val:  65.42%, val_best:  67.92%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.815645/  1.673728, val:  65.00%, val_best:  67.92%, tr:  81.31%, tr_best:  84.07%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.802199/  1.657353, val:  67.92%, val_best:  67.92%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.798124/  1.672124, val:  67.50%, val_best:  67.92%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.798643/  1.698422, val:  65.42%, val_best:  67.92%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.793810/  1.739981, val:  66.25%, val_best:  67.92%, tr:  85.29%, tr_best:  85.90%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.822613/  1.780449, val:  61.25%, val_best:  67.92%, tr:  83.66%, tr_best:  85.90%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.804939/  1.722328, val:  65.83%, val_best:  67.92%, tr:  84.88%, tr_best:  85.90%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.789707/  1.750934, val:  68.33%, val_best:  68.33%, tr:  84.47%, tr_best:  85.90%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.791369/  1.772154, val:  66.25%, val_best:  68.33%, tr:  85.50%, tr_best:  85.90%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.792691/  1.783633, val:  67.92%, val_best:  68.33%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.793081/  1.768430, val:  68.75%, val_best:  68.75%, tr:  86.01%, tr_best:  86.62%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.770574/  1.792240, val:  67.92%, val_best:  68.75%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.772013/  1.834512, val:  63.33%, val_best:  68.75%, tr:  86.41%, tr_best:  87.23%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.783520/  1.869156, val:  67.08%, val_best:  68.75%, tr:  86.41%, tr_best:  87.23%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.769779/  1.838772, val:  68.75%, val_best:  68.75%, tr:  86.62%, tr_best:  87.23%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.769569/  1.901774, val:  69.58%, val_best:  69.58%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.765374/  1.915229, val:  64.17%, val_best:  69.58%, tr:  89.27%, tr_best:  89.68%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.765136/  1.899271, val:  65.83%, val_best:  69.58%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.756158/  1.965871, val:  69.58%, val_best:  69.58%, tr:  88.36%, tr_best:  89.99%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.752011/  1.959716, val:  68.33%, val_best:  69.58%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.737929/  1.979725, val:  69.17%, val_best:  69.58%, tr:  88.97%, tr_best:  90.40%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.717533/  2.036964, val:  72.08%, val_best:  72.08%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.748084/  1.992404, val:  68.33%, val_best:  72.08%, tr:  90.09%, tr_best:  90.40%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.724873/  1.985957, val:  69.58%, val_best:  72.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.732715/  2.146086, val:  65.42%, val_best:  72.08%, tr:  89.68%, tr_best:  91.11%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.737580/  2.128371, val:  64.58%, val_best:  72.08%, tr:  90.70%, tr_best:  91.11%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.738948/  2.090375, val:  68.33%, val_best:  72.08%, tr:  90.50%, tr_best:  91.11%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.737039/  2.128911, val:  70.42%, val_best:  72.08%, tr:  90.40%, tr_best:  91.11%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.732860/  2.184000, val:  67.92%, val_best:  72.08%, tr:  90.30%, tr_best:  91.11%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.738635/  2.193155, val:  70.42%, val_best:  72.08%, tr:  89.99%, tr_best:  91.11%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.710866/  2.243579, val:  66.25%, val_best:  72.08%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.725053/  2.122749, val:  70.00%, val_best:  72.08%, tr:  90.40%, tr_best:  92.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18177e2c36b49c6b23882eb691095af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▂▂▄▆▄▅▆▆▆▆▆▅▅▇▅▇▇▇▇▅▆▇█▇▇▇▇██▅█▇█▇███</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▂▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇██</td></tr><tr><td>tr_acc</td><td>▁▁▁▂▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>████▇▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▂▃▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▂▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇██</td></tr><tr><td>val_loss</td><td>████▇▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.90398</td></tr><tr><td>tr_epoch_loss</td><td>0.72505</td></tr><tr><td>val_acc_best</td><td>0.72083</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>2.12275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-115</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cop35cwz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cop35cwz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_020157-cop35cwz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dteevt7z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_020825-dteevt7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dteevt7z' target=\"_blank\">bumbling-sweep-120</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dteevt7z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dteevt7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.244790/  2.117971, val:  30.00%, val_best:  30.00%, tr:  17.06%, tr_best:  17.06%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.844503/  1.726617, val:  53.33%, val_best:  53.33%, tr:  45.15%, tr_best:  45.15%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.516969/  1.577969, val:  59.17%, val_best:  59.17%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.358892/  1.518518, val:  60.00%, val_best:  60.00%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.275653/  1.454797, val:  59.58%, val_best:  60.00%, tr:  64.35%, tr_best:  65.17%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.194170/  1.388654, val:  61.25%, val_best:  61.25%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.130845/  1.353649, val:  61.25%, val_best:  61.25%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.087978/  1.326963, val:  59.58%, val_best:  61.25%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.043500/  1.304993, val:  68.33%, val_best:  68.33%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.015802/  1.303504, val:  61.67%, val_best:  68.33%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.994253/  1.319968, val:  59.58%, val_best:  68.33%, tr:  70.68%, tr_best:  71.91%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.957368/  1.239127, val:  67.08%, val_best:  68.33%, tr:  71.30%, tr_best:  71.91%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.944597/  1.237786, val:  63.33%, val_best:  68.33%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.922963/  1.254665, val:  65.00%, val_best:  68.33%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.880083/  1.313445, val:  61.25%, val_best:  68.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.865699/  1.260782, val:  65.42%, val_best:  68.33%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.869617/  1.206606, val:  68.33%, val_best:  68.33%, tr:  75.69%, tr_best:  77.32%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.812456/  1.211958, val:  65.83%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.800647/  1.286116, val:  62.92%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.792536/  1.259680, val:  64.58%, val_best:  68.33%, tr:  77.63%, tr_best:  80.29%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.750448/  1.226432, val:  70.83%, val_best:  70.83%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.738894/  1.238234, val:  71.25%, val_best:  71.25%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.744808/  1.242270, val:  69.58%, val_best:  71.25%, tr:  81.10%, tr_best:  82.74%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.706007/  1.257317, val:  69.58%, val_best:  71.25%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.679400/  1.273968, val:  65.42%, val_best:  71.25%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.664042/  1.267639, val:  70.00%, val_best:  71.25%, tr:  85.80%, tr_best:  86.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.657055/  1.270736, val:  71.67%, val_best:  71.67%, tr:  85.19%, tr_best:  86.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.630816/  1.311020, val:  71.25%, val_best:  71.67%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.623369/  1.268060, val:  73.75%, val_best:  73.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.610355/  1.352269, val:  63.33%, val_best:  73.75%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.585453/  1.333915, val:  69.58%, val_best:  73.75%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.595883/  1.357217, val:  70.42%, val_best:  73.75%, tr:  88.15%, tr_best:  91.62%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.582845/  1.342523, val:  72.08%, val_best:  73.75%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.565615/  1.315497, val:  75.00%, val_best:  75.00%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.538868/  1.394151, val:  66.67%, val_best:  75.00%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.547774/  1.391047, val:  68.75%, val_best:  75.00%, tr:  89.68%, tr_best:  93.97%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.506756/  1.320149, val:  75.83%, val_best:  75.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.501048/  1.382256, val:  75.83%, val_best:  75.83%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.491646/  1.421288, val:  71.67%, val_best:  75.83%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.481220/  1.397108, val:  74.17%, val_best:  75.83%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.477703/  1.398490, val:  74.58%, val_best:  75.83%, tr:  94.59%, tr_best:  96.12%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.455845/  1.453521, val:  72.08%, val_best:  75.83%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.436150/  1.413260, val:  75.00%, val_best:  75.83%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.432621/  1.442278, val:  72.08%, val_best:  75.83%, tr:  96.63%, tr_best:  97.04%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.429943/  1.469997, val:  75.42%, val_best:  75.83%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.409982/  1.455422, val:  77.08%, val_best:  77.08%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.408917/  1.473186, val:  75.00%, val_best:  77.08%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.390471/  1.499934, val:  77.08%, val_best:  77.08%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.398830/  1.484194, val:  79.17%, val_best:  79.17%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.385126/  1.509684, val:  77.92%, val_best:  79.17%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.372553/  1.542214, val:  72.08%, val_best:  79.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.389611/  1.484313, val:  77.50%, val_best:  79.17%, tr:  96.53%, tr_best:  99.08%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.346050/  1.533707, val:  75.42%, val_best:  79.17%, tr:  98.47%, tr_best:  99.08%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.344386/  1.612259, val:  75.42%, val_best:  79.17%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.347577/  1.545712, val:  77.92%, val_best:  79.17%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.329431/  1.582648, val:  72.92%, val_best:  79.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.325292/  1.632455, val:  72.92%, val_best:  79.17%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.326688/  1.592955, val:  78.33%, val_best:  79.17%, tr:  98.67%, tr_best:  99.39%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.319869/  1.613359, val:  74.17%, val_best:  79.17%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.311526/  1.617214, val:  79.58%, val_best:  79.58%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.289803/  1.633234, val:  77.50%, val_best:  79.58%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.302365/  1.638213, val:  78.75%, val_best:  79.58%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.285579/  1.648915, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.274519/  1.640497, val:  79.58%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.274801/  1.698146, val:  76.25%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.258618/  1.670486, val:  78.33%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.260837/  1.671966, val:  77.50%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.254638/  1.678733, val:  78.75%, val_best:  79.58%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.254895/  1.722391, val:  76.25%, val_best:  79.58%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.249644/  1.683241, val:  76.67%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.238139/  1.736616, val:  78.75%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.245067/  1.754478, val:  77.50%, val_best:  79.58%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.234814/  1.770116, val:  74.17%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.234421/  1.775457, val:  73.33%, val_best:  79.58%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.220742/  1.747667, val:  77.92%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.215102/  1.789567, val:  75.83%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.216391/  1.755097, val:  77.50%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.207319/  1.798704, val:  79.17%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.212309/  1.822869, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.198274/  1.814663, val:  77.08%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.189054/  1.841744, val:  77.50%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.189737/  1.809117, val:  78.75%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.186041/  1.860261, val:  76.67%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.183467/  1.921055, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.177126/  1.831232, val:  80.42%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.182208/  1.910857, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.168104/  1.876740, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.171495/  1.900102, val:  79.17%, val_best:  80.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.165875/  1.883553, val:  79.58%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.153418/  1.946973, val:  75.83%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.161553/  1.917978, val:  77.92%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.151340/  1.972408, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.143546/  1.948620, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.147177/  1.980421, val:  75.42%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.137661/  2.004752, val:  77.92%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.138156/  2.013861, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.131274/  2.055763, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.136665/  1.984224, val:  78.75%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.126464/  2.055424, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.126992/  2.088540, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a94cda1a24a47e7a4e9f6f98a481703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▆▅▅▅▅▆▁▃▇█▇█▇▇▇█▇███████████▇██████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▅▅▆▅▆▆▇▆▇▆▇▆▇▇▇▇██▇███████▇▇██▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▅▅▆▅▆▆▇▆▇▆▇▆▇▇▇▇██▇███████▇▇██▇██▇███</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.12699</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>2.08854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-120</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dteevt7z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dteevt7z</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_020825-dteevt7z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a035lfhm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_021453-a035lfhm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a035lfhm' target=\"_blank\">giddy-sweep-124</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a035lfhm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a035lfhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305360/  2.302797, val:  10.42%, val_best:  10.42%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304970/  2.302624, val:  10.42%, val_best:  10.42%, tr:   7.87%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.304989/  2.302469, val:  10.00%, val_best:  10.42%, tr:   8.89%, tr_best:   8.89%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.303798/  2.301386, val:  11.67%, val_best:  11.67%, tr:   9.40%, tr_best:   9.40%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.300072/  2.295965, val:  18.33%, val_best:  18.33%, tr:  10.62%, tr_best:  10.62%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.284949/  2.278604, val:  18.75%, val_best:  18.75%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.237391/  2.229289, val:  28.33%, val_best:  28.33%, tr:  22.47%, tr_best:  22.47%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.157542/  2.152783, val:  31.67%, val_best:  31.67%, tr:  29.83%, tr_best:  29.83%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.044703/  2.038674, val:  39.58%, val_best:  39.58%, tr:  34.63%, tr_best:  34.63%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.902698/  1.924257, val:  40.42%, val_best:  40.42%, tr:  41.88%, tr_best:  41.88%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.762313/  1.803662, val:  46.25%, val_best:  46.25%, tr:  44.02%, tr_best:  44.02%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.644220/  1.702269, val:  47.50%, val_best:  47.50%, tr:  48.72%, tr_best:  48.72%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.552742/  1.633219, val:  51.25%, val_best:  51.25%, tr:  52.20%, tr_best:  52.20%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.485839/  1.584638, val:  50.83%, val_best:  51.25%, tr:  55.16%, tr_best:  55.16%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.418152/  1.553835, val:  51.67%, val_best:  51.67%, tr:  56.49%, tr_best:  56.49%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.380402/  1.523051, val:  52.08%, val_best:  52.08%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.336751/  1.479230, val:  52.92%, val_best:  52.92%, tr:  58.43%, tr_best:  58.43%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.307638/  1.452161, val:  54.58%, val_best:  54.58%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.270802/  1.439857, val:  53.33%, val_best:  54.58%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.254542/  1.413745, val:  52.50%, val_best:  54.58%, tr:  57.71%, tr_best:  61.39%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.223421/  1.401001, val:  59.58%, val_best:  59.58%, tr:  59.45%, tr_best:  61.39%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.193643/  1.394864, val:  55.42%, val_best:  59.58%, tr:  60.67%, tr_best:  61.39%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.182748/  1.381293, val:  55.00%, val_best:  59.58%, tr:  59.24%, tr_best:  61.39%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.154500/  1.362579, val:  59.58%, val_best:  59.58%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.136005/  1.359159, val:  56.67%, val_best:  59.58%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.114529/  1.338744, val:  60.00%, val_best:  60.00%, tr:  64.04%, tr_best:  65.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.101959/  1.310122, val:  60.83%, val_best:  60.83%, tr:  63.02%, tr_best:  65.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.078939/  1.313820, val:  58.75%, val_best:  60.83%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.074189/  1.296219, val:  61.25%, val_best:  61.25%, tr:  65.78%, tr_best:  66.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.050573/  1.303089, val:  59.17%, val_best:  61.25%, tr:  65.47%, tr_best:  66.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.040714/  1.299331, val:  58.33%, val_best:  61.25%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.026736/  1.284724, val:  60.00%, val_best:  61.25%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.014732/  1.294072, val:  62.08%, val_best:  62.08%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.007791/  1.278976, val:  60.83%, val_best:  62.08%, tr:  69.56%, tr_best:  70.28%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.994247/  1.254887, val:  61.67%, val_best:  62.08%, tr:  69.46%, tr_best:  70.28%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.977311/  1.279285, val:  60.00%, val_best:  62.08%, tr:  69.36%, tr_best:  70.28%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.969361/  1.266232, val:  60.42%, val_best:  62.08%, tr:  69.97%, tr_best:  70.28%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.956229/  1.255737, val:  64.17%, val_best:  64.17%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.951702/  1.257934, val:  62.08%, val_best:  64.17%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.939573/  1.253659, val:  63.75%, val_best:  64.17%, tr:  72.01%, tr_best:  73.14%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.928158/  1.255442, val:  62.92%, val_best:  64.17%, tr:  71.09%, tr_best:  73.14%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.923121/  1.246840, val:  64.17%, val_best:  64.17%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.902428/  1.249557, val:  62.92%, val_best:  64.17%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.899695/  1.247160, val:  64.58%, val_best:  64.58%, tr:  74.16%, tr_best:  74.97%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.890487/  1.239798, val:  63.75%, val_best:  64.58%, tr:  72.83%, tr_best:  74.97%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.879116/  1.238050, val:  66.67%, val_best:  66.67%, tr:  74.77%, tr_best:  74.97%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.869198/  1.245446, val:  65.42%, val_best:  66.67%, tr:  74.06%, tr_best:  74.97%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.870067/  1.250994, val:  65.42%, val_best:  66.67%, tr:  74.46%, tr_best:  74.97%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.860679/  1.243532, val:  67.50%, val_best:  67.50%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.850734/  1.241505, val:  62.92%, val_best:  67.50%, tr:  75.28%, tr_best:  75.49%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.843207/  1.236095, val:  64.58%, val_best:  67.50%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.832575/  1.232796, val:  65.83%, val_best:  67.50%, tr:  76.61%, tr_best:  76.92%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.833183/  1.232092, val:  67.50%, val_best:  67.50%, tr:  74.87%, tr_best:  76.92%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.822004/  1.226472, val:  70.00%, val_best:  70.00%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.810730/  1.234008, val:  64.58%, val_best:  70.00%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.805778/  1.229294, val:  67.08%, val_best:  70.00%, tr:  77.73%, tr_best:  78.14%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.786604/  1.228593, val:  67.92%, val_best:  70.00%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.785395/  1.235947, val:  67.92%, val_best:  70.00%, tr:  79.57%, tr_best:  81.10%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.776683/  1.250997, val:  63.75%, val_best:  70.00%, tr:  78.35%, tr_best:  81.10%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.773963/  1.243453, val:  68.75%, val_best:  70.00%, tr:  78.35%, tr_best:  81.10%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.765133/  1.237709, val:  65.83%, val_best:  70.00%, tr:  78.65%, tr_best:  81.10%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.760210/  1.247058, val:  67.50%, val_best:  70.00%, tr:  80.49%, tr_best:  81.10%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.755590/  1.249079, val:  68.33%, val_best:  70.00%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.741108/  1.244564, val:  70.42%, val_best:  70.42%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.732745/  1.261962, val:  70.83%, val_best:  70.83%, tr:  82.64%, tr_best:  83.25%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.732267/  1.267821, val:  62.50%, val_best:  70.83%, tr:  82.94%, tr_best:  83.25%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.731683/  1.260668, val:  70.83%, val_best:  70.83%, tr:  81.92%, tr_best:  83.25%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.737692/  1.285823, val:  70.83%, val_best:  70.83%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.714406/  1.273813, val:  69.58%, val_best:  70.83%, tr:  81.31%, tr_best:  85.19%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.710052/  1.278302, val:  70.00%, val_best:  70.83%, tr:  84.17%, tr_best:  85.19%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.698441/  1.265170, val:  70.42%, val_best:  70.83%, tr:  84.37%, tr_best:  85.19%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.692728/  1.292340, val:  66.67%, val_best:  70.83%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.688978/  1.289652, val:  66.67%, val_best:  70.83%, tr:  84.17%, tr_best:  86.72%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.693661/  1.298376, val:  65.83%, val_best:  70.83%, tr:  84.47%, tr_best:  86.72%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.676779/  1.292488, val:  68.33%, val_best:  70.83%, tr:  84.98%, tr_best:  86.72%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.676007/  1.288414, val:  69.58%, val_best:  70.83%, tr:  85.29%, tr_best:  86.72%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.656057/  1.312176, val:  69.58%, val_best:  70.83%, tr:  86.11%, tr_best:  86.72%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.670736/  1.330669, val:  66.25%, val_best:  70.83%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.654407/  1.306683, val:  70.42%, val_best:  70.83%, tr:  86.82%, tr_best:  87.64%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.645001/  1.322924, val:  70.42%, val_best:  70.83%, tr:  86.82%, tr_best:  87.64%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.638277/  1.335612, val:  68.75%, val_best:  70.83%, tr:  87.33%, tr_best:  87.64%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.647639/  1.334029, val:  65.83%, val_best:  70.83%, tr:  86.93%, tr_best:  87.64%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.621237/  1.337615, val:  67.50%, val_best:  70.83%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.625349/  1.325582, val:  68.75%, val_best:  70.83%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.616010/  1.353010, val:  67.92%, val_best:  70.83%, tr:  89.58%, tr_best:  90.30%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.618672/  1.349557, val:  70.42%, val_best:  70.83%, tr:  89.68%, tr_best:  90.30%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.604118/  1.362417, val:  66.67%, val_best:  70.83%, tr:  88.66%, tr_best:  90.30%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.606240/  1.358115, val:  69.17%, val_best:  70.83%, tr:  90.50%, tr_best:  90.50%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.593111/  1.367447, val:  69.58%, val_best:  70.83%, tr:  89.68%, tr_best:  90.50%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.584553/  1.387192, val:  67.50%, val_best:  70.83%, tr:  90.30%, tr_best:  90.50%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.589091/  1.359584, val:  67.92%, val_best:  70.83%, tr:  89.89%, tr_best:  90.50%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.577121/  1.381365, val:  70.00%, val_best:  70.83%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.583362/  1.396366, val:  68.33%, val_best:  70.83%, tr:  90.91%, tr_best:  91.52%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.572079/  1.389077, val:  70.00%, val_best:  70.83%, tr:  91.11%, tr_best:  91.52%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.569142/  1.405664, val:  67.92%, val_best:  70.83%, tr:  90.60%, tr_best:  91.52%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.557927/  1.421485, val:  69.58%, val_best:  70.83%, tr:  91.11%, tr_best:  91.52%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.556888/  1.429026, val:  67.50%, val_best:  70.83%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.554900/  1.400054, val:  74.17%, val_best:  74.17%, tr:  90.60%, tr_best:  92.54%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.542553/  1.446153, val:  68.33%, val_best:  74.17%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.548631/  1.451200, val:  69.17%, val_best:  74.17%, tr:  91.01%, tr_best:  92.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0174eb5db8a4cd88ff8dcccfb1d6c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▄▄▅▆▅▃▆▆▆▆▆▅▆▇▆█▆▆▇▅▅████▇▅▇▇▅█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▃▄▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▁▁▃▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>tr_epoch_loss</td><td>███▇▆▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▃▄▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>███▇▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91011</td></tr><tr><td>tr_epoch_loss</td><td>0.54863</td></tr><tr><td>val_acc_best</td><td>0.74167</td></tr><tr><td>val_acc_now</td><td>0.69167</td></tr><tr><td>val_loss</td><td>1.4512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-124</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a035lfhm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a035lfhm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_021453-a035lfhm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y9kd9jlb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_022116-y9kd9jlb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y9kd9jlb' target=\"_blank\">cosmic-sweep-128</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y9kd9jlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y9kd9jlb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.096589/  1.696667, val:  48.33%, val_best:  48.33%, tr:  21.14%, tr_best:  21.14%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.402306/  1.498014, val:  55.00%, val_best:  55.00%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.228683/  1.449726, val:  55.42%, val_best:  55.42%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.114747/  1.432845, val:  56.25%, val_best:  56.25%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.056240/  1.359940, val:  62.08%, val_best:  62.08%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.016324/  1.307576, val:  61.67%, val_best:  62.08%, tr:  65.47%, tr_best:  66.39%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.955725/  1.341051, val:  60.00%, val_best:  62.08%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.951516/  1.341892, val:  58.75%, val_best:  62.08%, tr:  69.05%, tr_best:  69.97%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.920585/  1.345503, val:  64.17%, val_best:  64.17%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.905326/  1.388613, val:  55.42%, val_best:  64.17%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.890476/  1.429028, val:  52.08%, val_best:  64.17%, tr:  73.34%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.837207/  1.282250, val:  66.67%, val_best:  66.67%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.825512/  1.280854, val:  64.17%, val_best:  66.67%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.806575/  1.336441, val:  64.17%, val_best:  66.67%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.768214/  1.514016, val:  64.58%, val_best:  66.67%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.766790/  1.393650, val:  65.00%, val_best:  66.67%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.775469/  1.339215, val:  66.67%, val_best:  66.67%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.707681/  1.385211, val:  66.25%, val_best:  66.67%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.713861/  1.538893, val:  61.25%, val_best:  66.67%, tr:  86.72%, tr_best:  87.23%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.731255/  1.450260, val:  67.08%, val_best:  67.08%, tr:  85.90%, tr_best:  87.23%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.714004/  1.577367, val:  63.75%, val_best:  67.08%, tr:  84.88%, tr_best:  87.23%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.698870/  1.502367, val:  65.00%, val_best:  67.08%, tr:  86.93%, tr_best:  87.23%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.659909/  1.597225, val:  61.67%, val_best:  67.08%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.679170/  1.594809, val:  67.08%, val_best:  67.08%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.641857/  1.644811, val:  62.08%, val_best:  67.08%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.644439/  1.566210, val:  67.92%, val_best:  67.92%, tr:  91.11%, tr_best:  92.54%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.666123/  1.618842, val:  65.00%, val_best:  67.92%, tr:  89.58%, tr_best:  92.54%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.633958/  1.696515, val:  61.67%, val_best:  67.92%, tr:  92.13%, tr_best:  92.54%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.639267/  1.696404, val:  69.17%, val_best:  69.17%, tr:  90.50%, tr_best:  92.54%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.613480/  1.782937, val:  61.67%, val_best:  69.17%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.596732/  1.782046, val:  62.08%, val_best:  69.17%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.607107/  1.793110, val:  65.42%, val_best:  69.17%, tr:  92.34%, tr_best:  94.08%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.615252/  1.814600, val:  65.42%, val_best:  69.17%, tr:  93.26%, tr_best:  94.08%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.637626/  1.812728, val:  64.58%, val_best:  69.17%, tr:  90.91%, tr_best:  94.08%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.577463/  1.863082, val:  65.00%, val_best:  69.17%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.594687/  1.875233, val:  65.00%, val_best:  69.17%, tr:  93.05%, tr_best:  94.59%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.587534/  1.796554, val:  68.33%, val_best:  69.17%, tr:  94.28%, tr_best:  94.59%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.601771/  1.980787, val:  65.42%, val_best:  69.17%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.583491/  1.943850, val:  65.83%, val_best:  69.17%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.570486/  1.901969, val:  66.25%, val_best:  69.17%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.546648/  1.944585, val:  66.67%, val_best:  69.17%, tr:  95.10%, tr_best:  95.61%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.535378/  1.981388, val:  65.42%, val_best:  69.17%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.554059/  1.910898, val:  68.75%, val_best:  69.17%, tr:  95.91%, tr_best:  96.83%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.549671/  2.011567, val:  68.75%, val_best:  69.17%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.551838/  2.050116, val:  69.17%, val_best:  69.17%, tr:  95.71%, tr_best:  96.83%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.518050/  2.026741, val:  68.75%, val_best:  69.17%, tr:  96.63%, tr_best:  96.83%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.530153/  2.001516, val:  70.00%, val_best:  70.00%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.512708/  2.036574, val:  72.08%, val_best:  72.08%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.529711/  2.016115, val:  72.08%, val_best:  72.08%, tr:  96.73%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.509533/  2.027750, val:  72.92%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.487125/  2.079347, val:  70.42%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.513431/  2.116364, val:  72.50%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.471009/  2.105737, val:  73.33%, val_best:  73.33%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.474431/  2.169151, val:  70.83%, val_best:  73.33%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.500935/  2.238964, val:  73.33%, val_best:  73.33%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.458538/  2.257398, val:  70.42%, val_best:  73.33%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.493196/  2.328326, val:  69.58%, val_best:  73.33%, tr:  97.14%, tr_best:  98.16%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.499855/  2.229045, val:  74.58%, val_best:  74.58%, tr:  97.04%, tr_best:  98.16%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.496695/  2.411724, val:  69.58%, val_best:  74.58%, tr:  96.94%, tr_best:  98.16%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.485623/  2.336427, val:  75.42%, val_best:  75.42%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.454313/  2.337089, val:  72.50%, val_best:  75.42%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.486076/  2.407667, val:  72.08%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.452783/  2.377891, val:  72.08%, val_best:  75.42%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.434806/  2.402891, val:  74.17%, val_best:  75.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.446249/  2.447223, val:  74.17%, val_best:  75.42%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.454807/  2.393776, val:  71.67%, val_best:  75.42%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.425114/  2.469238, val:  71.67%, val_best:  75.42%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.442987/  2.479203, val:  73.75%, val_best:  75.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.449480/  2.562901, val:  70.00%, val_best:  75.42%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.444445/  2.536687, val:  70.42%, val_best:  75.42%, tr:  98.37%, tr_best:  98.77%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.427545/  2.527987, val:  70.83%, val_best:  75.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.448239/  2.728068, val:  67.92%, val_best:  75.42%, tr:  98.47%, tr_best:  98.98%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.445309/  2.644156, val:  72.08%, val_best:  75.42%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.464778/  2.776425, val:  69.17%, val_best:  75.42%, tr:  97.85%, tr_best:  98.98%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.455143/  2.711345, val:  68.33%, val_best:  75.42%, tr:  97.85%, tr_best:  98.98%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.436100/  2.825577, val:  65.42%, val_best:  75.42%, tr:  97.96%, tr_best:  98.98%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.423074/  2.723932, val:  66.25%, val_best:  75.42%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.433361/  2.660647, val:  70.00%, val_best:  75.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.417561/  2.725543, val:  71.25%, val_best:  75.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.415548/  2.723648, val:  70.83%, val_best:  75.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.412004/  2.803539, val:  69.17%, val_best:  75.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.442471/  2.817372, val:  69.58%, val_best:  75.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.432058/  2.970409, val:  65.83%, val_best:  75.42%, tr:  98.37%, tr_best:  99.39%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.436525/  2.962376, val:  68.75%, val_best:  75.42%, tr:  98.57%, tr_best:  99.39%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.403974/  2.853273, val:  72.50%, val_best:  75.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.410058/  2.913912, val:  71.25%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.400376/  2.997666, val:  68.75%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.430539/  2.894315, val:  72.50%, val_best:  75.42%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.404294/  2.940016, val:  72.50%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.393621/  2.983871, val:  72.08%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.418274/  2.987765, val:  71.25%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.417608/  2.993801, val:  72.08%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.406763/  3.062874, val:  70.42%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.406812/  3.114444, val:  70.00%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.397157/  3.064453, val:  71.25%, val_best:  75.42%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.412029/  3.092029, val:  70.00%, val_best:  75.42%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.396741/  3.219587, val:  67.50%, val_best:  75.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.410793/  3.260687, val:  69.17%, val_best:  75.42%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.395357/  3.280419, val:  68.33%, val_best:  75.42%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.406782/  3.300207, val:  67.92%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb9dab335914db38e806152372031a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▅▄▅▆▄▆█▇▇▇▇▇██▇▇▇▇█▇▇████████████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▄▃▅▅▆▆▅▅▅▄▅▅▅▆▆▆▇▇▇▇██▇▇█▇▇▅▇▇▆▇▇▇▇▇▆</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▄▃▅▅▆▆▅▅▅▄▅▅▅▆▆▆▇▇▇▇██▇▇█▇▇▅▇▇▆▇▇▇▇▇▆</td></tr><tr><td>val_loss</td><td>▂▂▁▁▁▁▂▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99285</td></tr><tr><td>tr_epoch_loss</td><td>0.40678</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.67917</td></tr><tr><td>val_loss</td><td>3.30021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-128</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y9kd9jlb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y9kd9jlb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_022116-y9kd9jlb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8h72dlom with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_022805-8h72dlom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8h72dlom' target=\"_blank\">bumbling-sweep-132</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8h72dlom' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8h72dlom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.234804/  3.071601, val:  37.92%, val_best:  37.92%, tr:  19.10%, tr_best:  19.10%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.221493/  2.855472, val:  43.33%, val_best:  43.33%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.558656/  2.637255, val:  51.67%, val_best:  51.67%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.228843/  2.623923, val:  48.33%, val_best:  51.67%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.034297/  2.440976, val:  55.00%, val_best:  55.00%, tr:  58.73%, tr_best:  60.27%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.826170/  2.605286, val:  52.08%, val_best:  55.00%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.741121/  2.785662, val:  55.83%, val_best:  55.83%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.147352/  2.834924, val:  58.33%, val_best:  58.33%, tr:  66.09%, tr_best:  67.21%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.875922/  2.619875, val:  54.58%, val_best:  58.33%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.175238/  3.408055, val:  48.33%, val_best:  58.33%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.882383/  2.520783, val:  63.75%, val_best:  63.75%, tr:  72.32%, tr_best:  72.32%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.809396/  3.035299, val:  57.50%, val_best:  63.75%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.815366/  2.545238, val:  72.50%, val_best:  72.50%, tr:  74.26%, tr_best:  75.08%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.315470/  3.015358, val:  60.42%, val_best:  72.50%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  1.744661/  2.999409, val:  67.50%, val_best:  72.50%, tr:  78.65%, tr_best:  82.74%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  1.278785/  3.557123, val:  60.00%, val_best:  72.50%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  1.379841/  3.251621, val:  66.67%, val_best:  72.50%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  1.348719/  3.255627, val:  66.25%, val_best:  72.50%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  1.297308/  3.514925, val:  65.83%, val_best:  72.50%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  1.244768/  3.961256, val:  64.17%, val_best:  72.50%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  1.382072/  3.909916, val:  67.08%, val_best:  72.50%, tr:  89.07%, tr_best:  90.19%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  1.367557/  4.796414, val:  61.25%, val_best:  72.50%, tr:  89.38%, tr_best:  90.19%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  1.157821/  4.195743, val:  67.08%, val_best:  72.50%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  1.287889/  4.171992, val:  71.25%, val_best:  72.50%, tr:  90.70%, tr_best:  93.46%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  1.119053/  4.714222, val:  68.33%, val_best:  72.50%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  1.155579/  4.856626, val:  68.33%, val_best:  72.50%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  1.230141/  5.271836, val:  64.58%, val_best:  72.50%, tr:  93.77%, tr_best:  95.81%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  1.171286/  5.492729, val:  65.83%, val_best:  72.50%, tr:  94.89%, tr_best:  95.81%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  1.153554/  5.048601, val:  75.00%, val_best:  75.00%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  1.195096/  6.511027, val:  65.83%, val_best:  75.00%, tr:  95.91%, tr_best:  96.53%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  1.090783/  5.835569, val:  70.42%, val_best:  75.00%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  1.003187/  6.373233, val:  70.42%, val_best:  75.00%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  1.169015/  6.921896, val:  69.17%, val_best:  75.00%, tr:  97.75%, tr_best:  98.06%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  1.325776/  6.589508, val:  68.75%, val_best:  75.00%, tr:  95.40%, tr_best:  98.06%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  1.226507/  6.956828, val:  69.58%, val_best:  75.00%, tr:  97.65%, tr_best:  98.06%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  1.057370/  7.329993, val:  68.75%, val_best:  75.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  1.080715/  6.857724, val:  74.17%, val_best:  75.00%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  1.089904/  8.370018, val:  65.42%, val_best:  75.00%, tr:  98.37%, tr_best:  98.67%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  1.330414/  7.565271, val:  71.67%, val_best:  75.00%, tr:  96.94%, tr_best:  98.67%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  1.243586/  7.518916, val:  71.67%, val_best:  75.00%, tr:  96.53%, tr_best:  98.67%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  1.109039/  7.673846, val:  73.75%, val_best:  75.00%, tr:  97.96%, tr_best:  98.67%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  1.074032/  8.087737, val:  71.25%, val_best:  75.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  1.228507/  8.362539, val:  72.08%, val_best:  75.00%, tr:  98.47%, tr_best:  98.98%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  1.232801/  8.791550, val:  67.50%, val_best:  75.00%, tr:  98.47%, tr_best:  98.98%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  1.240541/  8.954618, val:  70.00%, val_best:  75.00%, tr:  98.06%, tr_best:  98.98%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  1.094941/  8.708161, val:  74.17%, val_best:  75.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  1.511661/  9.160048, val:  69.58%, val_best:  75.00%, tr:  96.94%, tr_best:  98.98%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  1.159701/  9.311403, val:  75.42%, val_best:  75.42%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  1.241619/  9.848335, val:  73.33%, val_best:  75.42%, tr:  98.16%, tr_best:  99.18%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  1.167245/  9.536393, val:  71.25%, val_best:  75.42%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  1.072718/  9.943044, val:  70.42%, val_best:  75.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  1.095139/ 10.268429, val:  72.50%, val_best:  75.42%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  1.066478/ 10.619504, val:  72.50%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  1.176482/ 10.890358, val:  70.83%, val_best:  75.42%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  1.222038/ 10.686680, val:  73.75%, val_best:  75.42%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.991435/ 11.492677, val:  72.92%, val_best:  75.42%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.965667/ 11.827879, val:  73.33%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  1.300929/ 11.668137, val:  74.17%, val_best:  75.42%, tr:  97.96%, tr_best:  99.90%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  1.095739/ 12.794436, val:  67.92%, val_best:  75.42%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  1.137181/ 12.115040, val:  74.17%, val_best:  75.42%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  1.018493/ 12.271145, val:  75.83%, val_best:  75.83%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.986691/ 12.778419, val:  74.17%, val_best:  75.83%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.871993/ 12.933059, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.919331/ 13.294705, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.958907/ 13.284894, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.933701/ 14.148812, val:  73.75%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.934068/ 14.712746, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.937432/ 14.029224, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  1.011041/ 14.532275, val:  72.92%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.958515/ 14.632792, val:  73.75%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.841926/ 15.080962, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.953081/ 15.340033, val:  74.58%, val_best:  77.08%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.966409/ 15.589252, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  1.023687/ 15.588778, val:  74.58%, val_best:  77.08%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.961072/ 15.653016, val:  76.25%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.864751/ 16.809052, val:  73.75%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.924942/ 16.344976, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.932712/ 16.457792, val:  78.33%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.962977/ 16.662430, val:  76.25%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.949389/ 16.897499, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.850538/ 17.624077, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  1.007935/ 17.569851, val:  77.92%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.992619/ 17.718109, val:  75.00%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.905751/ 19.529730, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.995999/ 18.557587, val:  77.92%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  1.070072/ 18.301949, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.951835/ 19.267244, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.997981/ 19.365952, val:  77.08%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.901119/ 19.640839, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.911527/ 20.067577, val:  75.83%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.924883/ 20.284277, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.969212/ 20.549477, val:  75.00%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.882267/ 21.079111, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.847622/ 20.634071, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.888207/ 20.963600, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.936602/ 21.297094, val:  75.00%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.853042/ 22.526651, val:  72.92%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  1.275344/ 21.310797, val:  77.08%, val_best:  78.33%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.930793/ 21.979284, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.858376/ 22.123491, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaad66645b5471da5e6ef8336b9074b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▄▄▅▇▅▆▇██▇▆███████████████▇██████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▅▃▇▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇████▇█</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▅▆▆▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▆▆▅▅▃▃▃▂▃▂▂▂▂▃▃▃▂▂▂▃▃▂▂▁▁▁▂▁▁▁▂▂▂▁▁▁▃</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▅▃▇▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇████▇█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.85838</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>22.12349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-132</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8h72dlom' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8h72dlom</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_022805-8h72dlom/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4vc7gxyd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_023503-4vc7gxyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4vc7gxyd' target=\"_blank\">unique-sweep-136</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4vc7gxyd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4vc7gxyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.223132/  2.002686, val:  33.33%, val_best:  33.33%, tr:  15.73%, tr_best:  15.73%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.646732/  1.575394, val:  55.42%, val_best:  55.42%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.372906/  1.491806, val:  55.83%, val_best:  55.83%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.268665/  1.484575, val:  59.58%, val_best:  59.58%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.219088/  1.457247, val:  60.42%, val_best:  60.42%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.171647/  1.394018, val:  62.92%, val_best:  62.92%, tr:  63.64%, tr_best:  64.04%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.116940/  1.393969, val:  60.00%, val_best:  62.92%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.093962/  1.379677, val:  58.33%, val_best:  62.92%, tr:  66.91%, tr_best:  67.31%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.055203/  1.372605, val:  64.17%, val_best:  64.17%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.043046/  1.387284, val:  59.17%, val_best:  64.17%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.033951/  1.394526, val:  57.50%, val_best:  64.17%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.007317/  1.371447, val:  64.58%, val_best:  64.58%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.000964/  1.352160, val:  60.42%, val_best:  64.58%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.997045/  1.362018, val:  64.17%, val_best:  64.58%, tr:  71.91%, tr_best:  73.54%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.958671/  1.464957, val:  61.25%, val_best:  64.58%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.963711/  1.388220, val:  64.17%, val_best:  64.58%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.981052/  1.361770, val:  62.92%, val_best:  64.58%, tr:  73.34%, tr_best:  75.59%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.937431/  1.376124, val:  65.42%, val_best:  65.42%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.928476/  1.498154, val:  58.75%, val_best:  65.42%, tr:  75.89%, tr_best:  77.94%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.934240/  1.411411, val:  62.92%, val_best:  65.42%, tr:  75.18%, tr_best:  77.94%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.917973/  1.429030, val:  62.92%, val_best:  65.42%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.905660/  1.420187, val:  62.50%, val_best:  65.42%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.928158/  1.459875, val:  61.67%, val_best:  65.42%, tr:  75.89%, tr_best:  78.86%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.907592/  1.476621, val:  61.25%, val_best:  65.42%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.880166/  1.470958, val:  61.25%, val_best:  65.42%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.881017/  1.433986, val:  65.83%, val_best:  65.83%, tr:  79.67%, tr_best:  82.84%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.895718/  1.456358, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.886454/  1.536756, val:  57.92%, val_best:  66.25%, tr:  81.10%, tr_best:  82.84%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.887316/  1.461037, val:  66.25%, val_best:  66.25%, tr:  80.39%, tr_best:  82.84%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.864054/  1.579258, val:  60.83%, val_best:  66.25%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.856266/  1.603251, val:  59.58%, val_best:  66.25%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885827/  1.554118, val:  62.92%, val_best:  66.25%, tr:  80.08%, tr_best:  83.55%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.871941/  1.589672, val:  62.08%, val_best:  66.25%, tr:  80.69%, tr_best:  83.55%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.855188/  1.629326, val:  63.33%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.846618/  1.604717, val:  65.42%, val_best:  66.25%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.873432/  1.636944, val:  60.42%, val_best:  66.25%, tr:  81.61%, tr_best:  83.55%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.819472/  1.603188, val:  62.92%, val_best:  66.25%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.844137/  1.701811, val:  65.83%, val_best:  66.25%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.837160/  1.657102, val:  61.67%, val_best:  66.25%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.815818/  1.693619, val:  61.67%, val_best:  66.25%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.826555/  1.756078, val:  65.00%, val_best:  66.25%, tr:  83.66%, tr_best:  86.72%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816026/  1.728303, val:  61.25%, val_best:  66.25%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.808087/  1.654136, val:  66.25%, val_best:  66.25%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.814506/  1.772221, val:  62.50%, val_best:  66.25%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.792904/  1.756599, val:  66.67%, val_best:  66.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.779269/  1.761614, val:  64.58%, val_best:  66.67%, tr:  87.84%, tr_best:  88.66%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.775480/  1.741632, val:  66.67%, val_best:  66.67%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.783227/  1.807499, val:  65.00%, val_best:  66.67%, tr:  88.97%, tr_best:  89.07%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.805892/  1.723932, val:  65.00%, val_best:  66.67%, tr:  88.56%, tr_best:  89.07%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.796156/  1.767691, val:  67.08%, val_best:  67.08%, tr:  87.44%, tr_best:  89.07%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.794473/  1.827904, val:  64.17%, val_best:  67.08%, tr:  87.33%, tr_best:  89.07%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.829250/  1.777983, val:  64.58%, val_best:  67.08%, tr:  84.58%, tr_best:  89.07%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.766114/  1.804216, val:  64.17%, val_best:  67.08%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.770968/  1.810026, val:  67.50%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.793794/  1.856610, val:  65.83%, val_best:  67.50%, tr:  89.38%, tr_best:  90.70%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.760632/  1.853680, val:  62.92%, val_best:  67.50%, tr:  90.60%, tr_best:  90.70%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.778129/  1.968967, val:  61.67%, val_best:  67.50%, tr:  88.36%, tr_best:  90.70%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.802386/  1.824670, val:  65.00%, val_best:  67.50%, tr:  87.84%, tr_best:  90.70%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.768591/  1.996533, val:  60.42%, val_best:  67.50%, tr:  89.17%, tr_best:  90.70%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.766381/  1.939684, val:  65.42%, val_best:  67.50%, tr:  88.05%, tr_best:  90.70%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.758057/  1.876465, val:  66.25%, val_best:  67.50%, tr:  89.58%, tr_best:  90.70%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.768309/  1.941056, val:  61.25%, val_best:  67.50%, tr:  90.30%, tr_best:  90.70%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.762010/  2.005100, val:  60.42%, val_best:  67.50%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.749036/  1.964597, val:  64.17%, val_best:  67.50%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.767938/  2.052987, val:  60.83%, val_best:  67.50%, tr:  90.09%, tr_best:  91.73%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.754043/  1.993210, val:  62.50%, val_best:  67.50%, tr:  90.70%, tr_best:  91.73%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.770516/  2.113071, val:  61.25%, val_best:  67.50%, tr:  90.91%, tr_best:  91.73%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.766177/  1.978093, val:  60.42%, val_best:  67.50%, tr:  91.42%, tr_best:  91.73%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.757744/  2.173551, val:  58.33%, val_best:  67.50%, tr:  91.22%, tr_best:  91.73%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.776188/  2.089108, val:  63.33%, val_best:  67.50%, tr:  88.56%, tr_best:  91.73%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.762170/  2.067266, val:  64.17%, val_best:  67.50%, tr:  91.62%, tr_best:  91.73%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.781851/  2.191415, val:  60.42%, val_best:  67.50%, tr:  90.40%, tr_best:  91.73%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.758126/  2.176638, val:  62.50%, val_best:  67.50%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.786769/  2.128878, val:  63.33%, val_best:  67.50%, tr:  89.99%, tr_best:  92.13%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.800965/  2.129314, val:  63.33%, val_best:  67.50%, tr:  90.91%, tr_best:  92.13%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.804875/  2.252852, val:  61.67%, val_best:  67.50%, tr:  90.70%, tr_best:  92.13%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.766759/  2.272423, val:  62.92%, val_best:  67.50%, tr:  89.38%, tr_best:  92.13%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.821836/  2.259508, val:  61.25%, val_best:  67.50%, tr:  89.48%, tr_best:  92.13%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.811524/  2.266636, val:  60.83%, val_best:  67.50%, tr:  88.97%, tr_best:  92.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.776070/  2.216362, val:  63.33%, val_best:  67.50%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.771906/  2.261730, val:  60.83%, val_best:  67.50%, tr:  91.73%, tr_best:  92.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.802366/  2.255741, val:  64.17%, val_best:  67.50%, tr:  90.50%, tr_best:  92.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.802616/  2.359800, val:  55.83%, val_best:  67.50%, tr:  91.11%, tr_best:  92.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.791338/  2.454720, val:  61.25%, val_best:  67.50%, tr:  89.79%, tr_best:  92.13%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.788659/  2.234620, val:  64.17%, val_best:  67.50%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.780635/  2.285981, val:  59.58%, val_best:  67.50%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.771102/  2.369335, val:  62.08%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.810745/  2.302168, val:  65.42%, val_best:  67.50%, tr:  89.99%, tr_best:  93.05%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.783924/  2.403520, val:  60.42%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.752935/  2.452646, val:  60.00%, val_best:  67.50%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.818026/  2.384936, val:  61.67%, val_best:  67.50%, tr:  91.62%, tr_best:  93.05%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.790593/  2.616165, val:  55.42%, val_best:  67.50%, tr:  90.30%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.787843/  2.505027, val:  60.83%, val_best:  67.50%, tr:  91.93%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.791389/  2.424564, val:  63.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.785110/  2.480027, val:  62.08%, val_best:  67.50%, tr:  92.34%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.788248/  2.454785, val:  61.25%, val_best:  67.50%, tr:  91.73%, tr_best:  93.05%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.787971/  2.684330, val:  58.75%, val_best:  67.50%, tr:  91.83%, tr_best:  93.05%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.799346/  2.498815, val:  63.75%, val_best:  67.50%, tr:  89.89%, tr_best:  93.05%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.784911/  2.623399, val:  63.75%, val_best:  67.50%, tr:  90.91%, tr_best:  93.05%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.832112/  2.533987, val:  61.25%, val_best:  67.50%, tr:  89.68%, tr_best:  93.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae625c1a1c29418c85bd4df7a6f09c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▄▆▃▃▆▇▇▆▆▆▇█▆▇▆▅█▆▆█▆▆▇▇▆▆█▅▇▆▇▃▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▇▇█▇▇▇█▇▇▇█▇████▇███▇▇▇▇▇▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▂▂▁▁▁▂▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▇▆▇▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.89683</td></tr><tr><td>tr_epoch_loss</td><td>0.83211</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.6125</td></tr><tr><td>val_loss</td><td>2.53399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-136</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4vc7gxyd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4vc7gxyd</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_023503-4vc7gxyd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 57wy53d4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_024207-57wy53d4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/57wy53d4' target=\"_blank\">zesty-sweep-140</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/57wy53d4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/57wy53d4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.011752/  1.784737, val:  41.25%, val_best:  41.25%, tr:  32.38%, tr_best:  32.38%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.442204/  1.530775, val:  51.67%, val_best:  51.67%, tr:  54.55%, tr_best:  54.55%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.250597/  1.508354, val:  52.50%, val_best:  52.50%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.092085/  1.608101, val:  54.58%, val_best:  54.58%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.055312/  1.436268, val:  60.83%, val_best:  60.83%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.931353/  1.475673, val:  60.00%, val_best:  60.83%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.914040/  1.453921, val:  56.67%, val_best:  60.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.923405/  1.563659, val:  61.25%, val_best:  61.25%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.856032/  1.435183, val:  66.25%, val_best:  66.25%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.838176/  1.484804, val:  58.75%, val_best:  66.25%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.786472/  1.597113, val:  55.00%, val_best:  66.25%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.745374/  1.640250, val:  61.25%, val_best:  66.25%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.758620/  1.427673, val:  72.08%, val_best:  72.08%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.717476/  1.658719, val:  58.75%, val_best:  72.08%, tr:  82.74%, tr_best:  83.25%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.646900/  1.923794, val:  60.42%, val_best:  72.08%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.681948/  1.846733, val:  59.17%, val_best:  72.08%, tr:  85.90%, tr_best:  86.41%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.613611/  1.858570, val:  62.08%, val_best:  72.08%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.576947/  1.767414, val:  60.83%, val_best:  72.08%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.598356/  1.948114, val:  60.42%, val_best:  72.08%, tr:  89.17%, tr_best:  89.99%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.611392/  1.898796, val:  60.00%, val_best:  72.08%, tr:  86.21%, tr_best:  89.99%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.548013/  2.048352, val:  62.08%, val_best:  72.08%, tr:  87.84%, tr_best:  89.99%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.529988/  2.298768, val:  57.50%, val_best:  72.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.470849/  2.168254, val:  59.17%, val_best:  72.08%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.497947/  2.016341, val:  62.50%, val_best:  72.08%, tr:  92.03%, tr_best:  92.95%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.426176/  2.353517, val:  60.83%, val_best:  72.08%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.430774/  2.389116, val:  60.83%, val_best:  72.08%, tr:  95.20%, tr_best:  96.02%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.464879/  2.301048, val:  64.17%, val_best:  72.08%, tr:  91.62%, tr_best:  96.02%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.364976/  2.740139, val:  64.17%, val_best:  72.08%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.394404/  2.751377, val:  68.33%, val_best:  72.08%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.408139/  2.568407, val:  62.50%, val_best:  72.08%, tr:  96.32%, tr_best:  97.45%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.310279/  3.189380, val:  63.75%, val_best:  72.08%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.308847/  2.958678, val:  62.50%, val_best:  72.08%, tr:  97.55%, tr_best:  98.47%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.396000/  3.297037, val:  61.25%, val_best:  72.08%, tr:  96.32%, tr_best:  98.47%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.570202/  2.901181, val:  62.50%, val_best:  72.08%, tr:  92.44%, tr_best:  98.47%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.346007/  3.080567, val:  64.17%, val_best:  72.08%, tr:  97.04%, tr_best:  98.47%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.249754/  3.322849, val:  65.42%, val_best:  72.08%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.242444/  3.106311, val:  67.08%, val_best:  72.08%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.323367/  3.637273, val:  61.67%, val_best:  72.08%, tr:  97.34%, tr_best:  98.98%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.329626/  3.638529, val:  63.75%, val_best:  72.08%, tr:  97.24%, tr_best:  98.98%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.330990/  3.282558, val:  67.92%, val_best:  72.08%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.237532/  3.319922, val:  66.25%, val_best:  72.08%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.275969/  3.809332, val:  62.08%, val_best:  72.08%, tr:  98.37%, tr_best:  99.08%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.316076/  3.724105, val:  67.08%, val_best:  72.08%, tr:  98.37%, tr_best:  99.08%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.338036/  3.697685, val:  61.25%, val_best:  72.08%, tr:  97.75%, tr_best:  99.08%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.541695/  3.231476, val:  65.00%, val_best:  72.08%, tr:  94.89%, tr_best:  99.08%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.342641/  3.074763, val:  67.92%, val_best:  72.08%, tr:  97.14%, tr_best:  99.08%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.227427/  3.333588, val:  68.33%, val_best:  72.08%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.176962/  3.647682, val:  67.50%, val_best:  72.08%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.120252/  3.678953, val:  69.17%, val_best:  72.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.131653/  3.921410, val:  67.08%, val_best:  72.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.128706/  4.401853, val:  67.50%, val_best:  72.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.259358/  3.989718, val:  68.75%, val_best:  72.08%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.164324/  3.983726, val:  69.17%, val_best:  72.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.107641/  4.076209, val:  69.17%, val_best:  72.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.082105/  4.203533, val:  69.58%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.055182/  4.711540, val:  68.33%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.068693/  4.783784, val:  67.08%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.074087/  4.958800, val:  69.17%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.077338/  4.786754, val:  69.17%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.093968/  4.973845, val:  67.50%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.072462/  4.879532, val:  70.00%, val_best:  72.08%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.143601/  4.757074, val:  70.00%, val_best:  72.08%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.173354/  4.435720, val:  71.67%, val_best:  72.08%, tr:  98.77%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.115845/  4.764021, val:  72.08%, val_best:  72.08%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.094336/  4.852642, val:  72.50%, val_best:  72.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.092228/  5.087584, val:  71.67%, val_best:  72.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.090358/  5.754245, val:  66.25%, val_best:  72.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.196149/  5.179730, val:  68.75%, val_best:  72.50%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.273635/  5.011939, val:  67.08%, val_best:  72.50%, tr:  98.67%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.161262/  4.558245, val:  71.67%, val_best:  72.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.111676/  4.691028, val:  72.50%, val_best:  72.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.070753/  4.741692, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.065236/  5.320204, val:  68.33%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.075516/  5.051980, val:  69.58%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.049472/  5.158499, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.046775/  5.142035, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.069552/  5.251357, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.055618/  5.524862, val:  68.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.035587/  5.382466, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.029241/  5.315379, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.025646/  5.236147, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.036487/  5.247715, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.035830/  5.643130, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.065815/  5.770515, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.053981/  5.635405, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.106071/  5.711889, val:  69.58%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.064357/  5.981776, val:  69.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.052607/  5.809990, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.024226/  5.933393, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.030291/  5.751246, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.025911/  5.830955, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.032581/  5.977849, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.034913/  5.958279, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.029846/  5.917603, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.020876/  5.839124, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.037728/  5.996630, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.036944/  5.923603, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.037972/  5.861948, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.023463/  5.804123, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.071713/  6.429636, val:  69.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8b096f4ec040c2833703a7c7704d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▄▅▆█▅█████▇███▇██████▇███████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▅█▅▅▅▄▅▆▆▅▆▅▇▇▆▇▇▇▇▇▇▇█▇█▇█▇▇█▇█▇█▇█</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▆▇▇▇▇█▇██████▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▃▃▃▃▂▃▂▂▂▂▂▂▃▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▅█▅▅▅▄▅▆▆▅▆▅▇▇▆▇▇▇▇▇▇▇█▇█▇█▇▇█▇█▇█▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▂▃▄▄▄▄▅▄▄▅▅▅▆▆▆▇▇▆▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.07171</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.69583</td></tr><tr><td>val_loss</td><td>6.42964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-140</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/57wy53d4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/57wy53d4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_024207-57wy53d4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5w7z144r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_024823-5w7z144r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5w7z144r' target=\"_blank\">jumping-sweep-144</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5w7z144r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5w7z144r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.274191/  2.218580, val:  25.00%, val_best:  25.00%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.075346/  1.972411, val:  47.50%, val_best:  47.50%, tr:  33.09%, tr_best:  33.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.756007/  1.739949, val:  51.67%, val_best:  51.67%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.552190/  1.630692, val:  53.33%, val_best:  53.33%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.445712/  1.578947, val:  55.83%, val_best:  55.83%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.355659/  1.513748, val:  59.17%, val_best:  59.17%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.298607/  1.495619, val:  59.58%, val_best:  59.58%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.254347/  1.449809, val:  58.75%, val_best:  59.58%, tr:  63.94%, tr_best:  64.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.208795/  1.409656, val:  62.08%, val_best:  62.08%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.177571/  1.412178, val:  60.00%, val_best:  62.08%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.147070/  1.396901, val:  56.25%, val_best:  62.08%, tr:  67.21%, tr_best:  67.62%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.112069/  1.354416, val:  62.92%, val_best:  62.92%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.096676/  1.344656, val:  59.58%, val_best:  62.92%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.077895/  1.319699, val:  62.08%, val_best:  62.92%, tr:  69.46%, tr_best:  69.56%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.031875/  1.362107, val:  56.67%, val_best:  62.92%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.028225/  1.320042, val:  64.17%, val_best:  64.17%, tr:  69.97%, tr_best:  70.99%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.010160/  1.293994, val:  63.75%, val_best:  64.17%, tr:  70.79%, tr_best:  70.99%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.976378/  1.284030, val:  65.83%, val_best:  65.83%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.960143/  1.313055, val:  60.00%, val_best:  65.83%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.959531/  1.308789, val:  60.83%, val_best:  65.83%, tr:  72.42%, tr_best:  73.75%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.928179/  1.284169, val:  63.33%, val_best:  65.83%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.916651/  1.262569, val:  65.83%, val_best:  65.83%, tr:  75.08%, tr_best:  75.49%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.915391/  1.279294, val:  63.33%, val_best:  65.83%, tr:  73.44%, tr_best:  75.49%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.883316/  1.271851, val:  65.42%, val_best:  65.83%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.863569/  1.277230, val:  63.33%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.852133/  1.254971, val:  67.92%, val_best:  67.92%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.845096/  1.252516, val:  65.42%, val_best:  67.92%, tr:  77.02%, tr_best:  79.88%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.827716/  1.291874, val:  64.17%, val_best:  67.92%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.820895/  1.234459, val:  65.83%, val_best:  67.92%, tr:  78.65%, tr_best:  81.61%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.811412/  1.277113, val:  62.08%, val_best:  67.92%, tr:  81.41%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.793039/  1.266493, val:  64.17%, val_best:  67.92%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.798810/  1.303115, val:  62.50%, val_best:  67.92%, tr:  79.26%, tr_best:  81.92%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.782557/  1.282359, val:  65.83%, val_best:  67.92%, tr:  80.90%, tr_best:  81.92%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.772575/  1.269219, val:  68.75%, val_best:  68.75%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.757120/  1.289704, val:  65.83%, val_best:  68.75%, tr:  84.37%, tr_best:  84.98%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.760014/  1.307997, val:  66.67%, val_best:  68.75%, tr:  82.94%, tr_best:  84.98%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.734718/  1.261122, val:  70.00%, val_best:  70.00%, tr:  84.27%, tr_best:  84.98%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.738601/  1.288741, val:  72.08%, val_best:  72.08%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.721352/  1.292264, val:  70.00%, val_best:  72.08%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.710615/  1.291598, val:  68.33%, val_best:  72.08%, tr:  87.95%, tr_best:  88.15%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.707907/  1.281552, val:  69.17%, val_best:  72.08%, tr:  84.88%, tr_best:  88.15%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.687178/  1.335739, val:  67.08%, val_best:  72.08%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.676278/  1.304975, val:  67.08%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.663939/  1.310527, val:  70.00%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.658724/  1.326202, val:  69.58%, val_best:  72.08%, tr:  88.15%, tr_best:  89.79%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.642301/  1.310706, val:  70.42%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.641415/  1.337583, val:  65.83%, val_best:  72.08%, tr:  90.09%, tr_best:  91.83%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.628301/  1.370839, val:  70.00%, val_best:  72.08%, tr:  90.70%, tr_best:  91.83%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.629010/  1.324082, val:  69.17%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.620537/  1.319781, val:  75.00%, val_best:  75.00%, tr:  90.19%, tr_best:  91.83%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.615928/  1.352340, val:  74.17%, val_best:  75.00%, tr:  90.50%, tr_best:  91.83%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.603395/  1.377992, val:  70.42%, val_best:  75.00%, tr:  91.11%, tr_best:  91.83%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.590253/  1.438112, val:  63.33%, val_best:  75.00%, tr:  91.32%, tr_best:  91.83%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.592096/  1.405250, val:  70.00%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.580699/  1.383874, val:  71.25%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.567805/  1.391743, val:  71.25%, val_best:  75.00%, tr:  92.54%, tr_best:  93.05%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.564567/  1.474526, val:  65.42%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.577867/  1.390273, val:  68.75%, val_best:  75.00%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.547812/  1.455299, val:  65.42%, val_best:  75.00%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.553900/  1.433185, val:  75.42%, val_best:  75.42%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.539167/  1.435867, val:  70.00%, val_best:  75.42%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.528375/  1.467913, val:  66.25%, val_best:  75.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.525013/  1.456464, val:  71.67%, val_best:  75.42%, tr:  94.89%, tr_best:  95.81%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.515302/  1.425273, val:  70.83%, val_best:  75.42%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.517663/  1.497600, val:  69.17%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.509702/  1.484637, val:  72.50%, val_best:  75.42%, tr:  95.81%, tr_best:  96.94%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.500092/  1.494254, val:  69.58%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.501544/  1.501006, val:  70.42%, val_best:  75.42%, tr:  96.12%, tr_best:  96.94%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.490964/  1.502536, val:  68.75%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.490592/  1.530194, val:  66.25%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.479384/  1.517751, val:  72.08%, val_best:  75.42%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.480564/  1.547641, val:  66.67%, val_best:  75.42%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.473086/  1.558800, val:  69.17%, val_best:  75.42%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.480731/  1.543317, val:  73.33%, val_best:  75.42%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.461853/  1.534527, val:  72.50%, val_best:  75.42%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.455817/  1.571643, val:  65.83%, val_best:  75.42%, tr:  95.61%, tr_best:  97.04%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.447568/  1.577328, val:  66.67%, val_best:  75.42%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.461766/  1.571505, val:  71.25%, val_best:  75.42%, tr:  95.81%, tr_best:  97.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.452556/  1.546493, val:  74.17%, val_best:  75.42%, tr:  96.42%, tr_best:  97.65%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.439795/  1.534450, val:  74.17%, val_best:  75.42%, tr:  96.94%, tr_best:  97.65%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.426617/  1.551494, val:  75.00%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.429164/  1.578474, val:  74.58%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424351/  1.598652, val:  71.67%, val_best:  75.42%, tr:  97.24%, tr_best:  97.75%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.421248/  1.653961, val:  72.50%, val_best:  75.42%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.417699/  1.599366, val:  70.83%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406182/  1.632522, val:  73.33%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.406919/  1.666832, val:  72.92%, val_best:  75.42%, tr:  96.63%, tr_best:  97.96%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.403068/  1.639962, val:  73.33%, val_best:  75.42%, tr:  97.65%, tr_best:  97.96%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.388461/  1.656087, val:  72.08%, val_best:  75.42%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.377699/  1.681610, val:  72.92%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.388125/  1.643831, val:  74.58%, val_best:  75.42%, tr:  97.96%, tr_best:  99.08%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.372250/  1.668326, val:  75.83%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.367953/  1.707927, val:  72.92%, val_best:  75.83%, tr:  98.26%, tr_best:  99.08%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.368874/  1.667787, val:  72.08%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.365060/  1.681595, val:  74.58%, val_best:  75.83%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.361291/  1.740701, val:  74.17%, val_best:  75.83%, tr:  98.16%, tr_best:  99.08%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.361938/  1.779347, val:  67.92%, val_best:  75.83%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.371085/  1.662928, val:  73.33%, val_best:  75.83%, tr:  97.24%, tr_best:  99.08%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.343872/  1.729346, val:  71.67%, val_best:  75.83%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.356393/  1.748094, val:  71.67%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5a7be2f0184ce0a7e7fb7fb78dcf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▄▂▅▅▂▃▆▇▇▅▆▅▇█▇▇▇▇▇▆▇███▇▇▇██▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98979</td></tr><tr><td>tr_epoch_loss</td><td>0.35639</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.71667</td></tr><tr><td>val_loss</td><td>1.74809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-sweep-144</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5w7z144r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5w7z144r</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_024823-5w7z144r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l1vq5vto with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_025507-l1vq5vto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l1vq5vto' target=\"_blank\">fast-sweep-147</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l1vq5vto' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l1vq5vto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.296237/  2.276956, val:  20.42%, val_best:  20.42%, tr:  14.20%, tr_best:  14.20%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.256141/  2.240716, val:  25.00%, val_best:  25.00%, tr:  23.60%, tr_best:  23.60%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.211246/  2.197888, val:  27.50%, val_best:  27.50%, tr:  28.19%, tr_best:  28.19%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.150449/  2.137187, val:  31.25%, val_best:  31.25%, tr:  32.38%, tr_best:  32.38%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.075456/  2.067997, val:  32.50%, val_best:  32.50%, tr:  35.34%, tr_best:  35.34%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.985543/  1.986416, val:  41.67%, val_best:  41.67%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.896733/  1.902687, val:  48.33%, val_best:  48.33%, tr:  47.50%, tr_best:  47.50%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.795009/  1.825896, val:  47.08%, val_best:  48.33%, tr:  52.20%, tr_best:  52.20%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.713530/  1.755731, val:  51.25%, val_best:  51.25%, tr:  54.75%, tr_best:  54.75%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.635979/  1.697541, val:  49.58%, val_best:  51.25%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.576602/  1.649126, val:  50.42%, val_best:  51.25%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.523986/  1.607644, val:  51.25%, val_best:  51.25%, tr:  58.32%, tr_best:  58.32%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.480505/  1.569276, val:  55.42%, val_best:  55.42%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.442345/  1.536660, val:  53.75%, val_best:  55.42%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.403050/  1.510211, val:  55.00%, val_best:  55.42%, tr:  61.59%, tr_best:  61.80%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.365176/  1.486763, val:  57.08%, val_best:  57.08%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.335704/  1.461843, val:  57.08%, val_best:  57.08%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.315090/  1.440239, val:  62.08%, val_best:  62.08%, tr:  65.78%, tr_best:  65.78%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.285806/  1.426497, val:  58.75%, val_best:  62.08%, tr:  64.15%, tr_best:  65.78%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.261214/  1.417154, val:  59.58%, val_best:  62.08%, tr:  64.15%, tr_best:  65.78%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.236499/  1.400781, val:  59.17%, val_best:  62.08%, tr:  64.45%, tr_best:  65.78%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.220245/  1.390003, val:  62.08%, val_best:  62.08%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.199935/  1.375063, val:  63.33%, val_best:  63.33%, tr:  65.07%, tr_best:  66.60%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.178748/  1.364379, val:  63.75%, val_best:  63.75%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.164248/  1.356623, val:  65.42%, val_best:  65.42%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.146839/  1.346968, val:  65.00%, val_best:  65.42%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.134107/  1.331161, val:  67.50%, val_best:  67.50%, tr:  68.34%, tr_best:  69.36%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.117829/  1.318979, val:  67.50%, val_best:  67.50%, tr:  70.58%, tr_best:  70.58%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.114895/  1.317476, val:  67.50%, val_best:  67.50%, tr:  68.44%, tr_best:  70.58%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.088375/  1.314530, val:  67.92%, val_best:  67.92%, tr:  69.66%, tr_best:  70.58%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.080805/  1.312318, val:  66.25%, val_best:  67.92%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.061738/  1.304375, val:  70.42%, val_best:  70.42%, tr:  69.66%, tr_best:  70.99%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.052786/  1.301050, val:  66.67%, val_best:  70.42%, tr:  70.89%, tr_best:  70.99%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.051723/  1.290796, val:  67.08%, val_best:  70.42%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.031903/  1.288062, val:  69.17%, val_best:  70.42%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.018153/  1.278000, val:  71.67%, val_best:  71.67%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.011324/  1.279128, val:  67.08%, val_best:  71.67%, tr:  72.93%, tr_best:  73.34%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.003722/  1.274775, val:  72.08%, val_best:  72.08%, tr:  72.73%, tr_best:  73.34%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.996701/  1.273019, val:  68.75%, val_best:  72.08%, tr:  72.63%, tr_best:  73.34%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.988977/  1.268471, val:  72.92%, val_best:  72.92%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.969566/  1.266646, val:  70.00%, val_best:  72.92%, tr:  73.44%, tr_best:  74.67%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.977939/  1.253464, val:  70.42%, val_best:  72.92%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.953912/  1.249381, val:  72.08%, val_best:  72.92%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.948039/  1.246401, val:  67.08%, val_best:  72.92%, tr:  76.81%, tr_best:  77.02%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.939590/  1.243747, val:  66.25%, val_best:  72.92%, tr:  75.69%, tr_best:  77.02%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.932991/  1.235165, val:  71.25%, val_best:  72.92%, tr:  74.97%, tr_best:  77.02%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.921949/  1.234610, val:  70.00%, val_best:  72.92%, tr:  76.81%, tr_best:  77.02%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.925189/  1.236155, val:  68.75%, val_best:  72.92%, tr:  74.57%, tr_best:  77.02%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.913221/  1.232003, val:  71.25%, val_best:  72.92%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.905344/  1.226900, val:  68.33%, val_best:  72.92%, tr:  76.00%, tr_best:  77.12%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.901373/  1.223835, val:  68.33%, val_best:  72.92%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.892340/  1.222181, val:  68.75%, val_best:  72.92%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.884859/  1.217515, val:  67.50%, val_best:  72.92%, tr:  76.51%, tr_best:  77.73%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.876587/  1.218513, val:  69.17%, val_best:  72.92%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.871061/  1.227200, val:  65.00%, val_best:  72.92%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.865994/  1.219256, val:  68.33%, val_best:  72.92%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.849900/  1.216973, val:  66.25%, val_best:  72.92%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.847596/  1.220241, val:  69.58%, val_best:  72.92%, tr:  80.18%, tr_best:  81.61%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.839512/  1.214408, val:  69.17%, val_best:  72.92%, tr:  78.55%, tr_best:  81.61%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.838407/  1.211132, val:  69.17%, val_best:  72.92%, tr:  81.51%, tr_best:  81.61%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.832431/  1.215039, val:  66.25%, val_best:  72.92%, tr:  78.65%, tr_best:  81.61%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.831468/  1.210750, val:  67.08%, val_best:  72.92%, tr:  81.10%, tr_best:  81.61%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.823514/  1.207944, val:  67.50%, val_best:  72.92%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.812744/  1.206914, val:  68.33%, val_best:  72.92%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.803110/  1.210454, val:  65.42%, val_best:  72.92%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.805393/  1.206814, val:  67.92%, val_best:  72.92%, tr:  82.74%, tr_best:  83.35%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.798887/  1.195765, val:  70.00%, val_best:  72.92%, tr:  82.94%, tr_best:  83.35%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.800148/  1.199396, val:  67.08%, val_best:  72.92%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.782797/  1.199071, val:  68.33%, val_best:  72.92%, tr:  82.84%, tr_best:  84.37%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.779254/  1.194436, val:  69.17%, val_best:  72.92%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.774635/  1.196621, val:  67.08%, val_best:  72.92%, tr:  83.96%, tr_best:  84.37%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.770102/  1.197184, val:  69.17%, val_best:  72.92%, tr:  84.17%, tr_best:  84.37%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.759729/  1.196795, val:  69.17%, val_best:  72.92%, tr:  83.55%, tr_best:  84.37%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.758349/  1.188432, val:  66.25%, val_best:  72.92%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.748175/  1.191733, val:  68.75%, val_best:  72.92%, tr:  85.09%, tr_best:  85.60%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.747345/  1.187442, val:  67.08%, val_best:  72.92%, tr:  85.29%, tr_best:  85.60%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.735381/  1.193082, val:  69.58%, val_best:  72.92%, tr:  84.27%, tr_best:  85.60%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.740601/  1.197638, val:  69.17%, val_best:  72.92%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.732107/  1.189203, val:  68.75%, val_best:  72.92%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.729840/  1.188064, val:  67.08%, val_best:  72.92%, tr:  86.31%, tr_best:  87.03%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.720687/  1.189372, val:  70.00%, val_best:  72.92%, tr:  86.62%, tr_best:  87.03%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.720842/  1.188912, val:  70.83%, val_best:  72.92%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.709457/  1.186439, val:  71.25%, val_best:  72.92%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.708579/  1.183959, val:  70.00%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.705255/  1.190975, val:  69.58%, val_best:  72.92%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.703053/  1.187304, val:  71.25%, val_best:  72.92%, tr:  88.05%, tr_best:  89.07%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.690614/  1.190613, val:  70.83%, val_best:  72.92%, tr:  87.64%, tr_best:  89.07%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.688491/  1.184887, val:  71.25%, val_best:  72.92%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.682669/  1.194525, val:  67.50%, val_best:  72.92%, tr:  88.56%, tr_best:  89.99%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.674598/  1.195341, val:  69.17%, val_best:  72.92%, tr:  87.84%, tr_best:  89.99%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.678811/  1.193582, val:  70.00%, val_best:  72.92%, tr:  88.15%, tr_best:  89.99%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.663705/  1.191776, val:  72.50%, val_best:  72.92%, tr:  89.27%, tr_best:  89.99%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.664736/  1.193843, val:  70.42%, val_best:  72.92%, tr:  88.97%, tr_best:  89.99%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.660909/  1.189798, val:  71.25%, val_best:  72.92%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.658193/  1.191118, val:  71.25%, val_best:  72.92%, tr:  90.19%, tr_best:  90.60%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.645321/  1.199736, val:  72.92%, val_best:  72.92%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.643196/  1.200610, val:  70.42%, val_best:  72.92%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.636831/  1.205059, val:  70.00%, val_best:  72.92%, tr:  89.89%, tr_best:  91.83%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.636045/  1.199260, val:  68.33%, val_best:  72.92%, tr:  89.27%, tr_best:  91.83%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.632608/  1.206164, val:  71.25%, val_best:  72.92%, tr:  89.99%, tr_best:  91.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53761c459a0046b898b62f46346e29c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▂▃▄▅▅▄▃▆▇▇▅▅▆▆▆▆█▆▆▆▅▇▇▇█▇█▇▇▇▇▇█▆▆▇██</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▅▅▆▆▇▆▇▇▇▇▇████▇▇▇▇▇█▇▇▇▇▇▇▇▇▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▂▃▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▅▅▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▅▅▆▆▇▆▇▇▇▇▇████▇▇▇▇▇█▇▇▇▇▇▇▇▇▇███▇███</td></tr><tr><td>val_loss</td><td>█▇▇▅▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.8999</td></tr><tr><td>tr_epoch_loss</td><td>0.63261</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.7125</td></tr><tr><td>val_loss</td><td>1.20616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-147</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l1vq5vto' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l1vq5vto</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_025507-l1vq5vto/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m0y65hb6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_030117-m0y65hb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0y65hb6' target=\"_blank\">comfy-sweep-149</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0y65hb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0y65hb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.144575/  1.817533, val:  41.25%, val_best:  41.25%, tr:  21.25%, tr_best:  21.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.491291/  1.456961, val:  53.75%, val_best:  53.75%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.279740/  1.418671, val:  53.75%, val_best:  53.75%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.175622/  1.402506, val:  55.83%, val_best:  55.83%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.119980/  1.366083, val:  58.75%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.060521/  1.300567, val:  65.83%, val_best:  65.83%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.000824/  1.301821, val:  61.25%, val_best:  65.83%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.985290/  1.314859, val:  61.25%, val_best:  65.83%, tr:  69.05%, tr_best:  70.68%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.949520/  1.354883, val:  64.58%, val_best:  65.83%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934873/  1.356147, val:  57.92%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.923953/  1.396143, val:  56.67%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.875370/  1.339741, val:  62.50%, val_best:  65.83%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.883515/  1.354796, val:  62.50%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.864338/  1.359563, val:  63.75%, val_best:  65.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.817443/  1.511845, val:  62.50%, val_best:  65.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.809220/  1.439581, val:  61.67%, val_best:  65.83%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.819770/  1.386554, val:  64.17%, val_best:  65.83%, tr:  81.10%, tr_best:  81.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.783346/  1.407303, val:  67.08%, val_best:  67.08%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.762966/  1.542733, val:  59.17%, val_best:  67.08%, tr:  84.07%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.764121/  1.509853, val:  67.08%, val_best:  67.08%, tr:  83.96%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.738797/  1.569989, val:  62.92%, val_best:  67.08%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.716952/  1.523091, val:  64.17%, val_best:  67.08%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.725320/  1.552056, val:  63.33%, val_best:  67.08%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698502/  1.585925, val:  65.00%, val_best:  67.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.677743/  1.635015, val:  64.58%, val_best:  67.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.680546/  1.617494, val:  67.92%, val_best:  67.92%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.685079/  1.622059, val:  68.33%, val_best:  68.33%, tr:  90.09%, tr_best:  91.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.668759/  1.668863, val:  67.50%, val_best:  68.33%, tr:  90.91%, tr_best:  91.11%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.670493/  1.717578, val:  68.33%, val_best:  68.33%, tr:  91.01%, tr_best:  91.11%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.621386/  1.749446, val:  64.17%, val_best:  68.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.624418/  1.789540, val:  65.83%, val_best:  68.33%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.636828/  1.767424, val:  65.00%, val_best:  68.33%, tr:  92.03%, tr_best:  93.77%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.626651/  1.795750, val:  65.83%, val_best:  68.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.638346/  1.848629, val:  63.33%, val_best:  68.33%, tr:  92.24%, tr_best:  93.87%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.597420/  1.957576, val:  63.33%, val_best:  68.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.611032/  1.996146, val:  63.33%, val_best:  68.33%, tr:  93.46%, tr_best:  95.10%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.591873/  1.939366, val:  65.83%, val_best:  68.33%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.591366/  1.982105, val:  65.00%, val_best:  68.33%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.582523/  2.001446, val:  68.33%, val_best:  68.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.564702/  2.022887, val:  67.50%, val_best:  68.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.565151/  2.120297, val:  67.92%, val_best:  68.33%, tr:  95.71%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.557068/  2.140752, val:  65.83%, val_best:  68.33%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.525257/  2.118379, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.539178/  2.197912, val:  63.75%, val_best:  68.33%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.522206/  2.220392, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.512232/  2.242227, val:  66.67%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.501202/  2.228575, val:  67.08%, val_best:  68.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.494333/  2.312970, val:  65.42%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.494586/  2.318042, val:  66.25%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.508738/  2.396864, val:  64.58%, val_best:  68.33%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.490841/  2.432610, val:  65.00%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.501619/  2.443867, val:  65.42%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.482933/  2.479905, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.477838/  2.538728, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.479183/  2.583109, val:  65.83%, val_best:  68.33%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.468027/  2.644629, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.473856/  2.653191, val:  65.42%, val_best:  68.33%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.480465/  2.618025, val:  68.33%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.452467/  2.733135, val:  62.50%, val_best:  68.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.458238/  2.680492, val:  67.92%, val_best:  68.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.466325/  2.711759, val:  67.08%, val_best:  68.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.461355/  2.762516, val:  67.50%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.448615/  2.830178, val:  65.00%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.442779/  2.875696, val:  66.25%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.452675/  2.929097, val:  65.42%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.441500/  2.885522, val:  65.83%, val_best:  68.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.448056/  2.954639, val:  64.58%, val_best:  68.33%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.472065/  2.912072, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.455693/  3.063578, val:  63.75%, val_best:  68.33%, tr:  98.67%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.457066/  3.023675, val:  68.75%, val_best:  68.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.445481/  3.087715, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.458703/  3.106065, val:  62.92%, val_best:  68.75%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.456814/  3.125111, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.452207/  3.070091, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.436011/  3.146578, val:  64.58%, val_best:  68.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.432641/  3.278949, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.430715/  3.224578, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.435468/  3.271761, val:  65.83%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.444355/  3.210975, val:  66.67%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.419681/  3.283675, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.430523/  3.323857, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.411631/  3.358387, val:  67.50%, val_best:  68.75%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424088/  3.491949, val:  64.58%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.428729/  3.484405, val:  64.17%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.420097/  3.429357, val:  66.25%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406717/  3.461854, val:  65.42%, val_best:  68.75%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.403112/  3.600858, val:  66.67%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.411629/  3.637316, val:  63.75%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.412038/  3.625228, val:  66.25%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.406560/  3.561375, val:  65.42%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.414159/  3.600652, val:  65.83%, val_best:  68.75%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.415171/  3.754240, val:  63.75%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.403950/  3.739951, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.415218/  3.729659, val:  65.42%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.422088/  3.777289, val:  64.17%, val_best:  68.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.404644/  3.859814, val:  66.25%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.400590/  3.955474, val:  63.75%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.398874/  3.932581, val:  64.58%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.372370/  3.934501, val:  65.00%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.389008/  4.001581, val:  63.75%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f003f8aa404de299ca047a5b4940cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▅▅▂▅███▇▅███▇██▇██████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.38901</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.00158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-149</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0y65hb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0y65hb6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_030117-m0y65hb6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gnuts5m8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_030813-gnuts5m8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gnuts5m8' target=\"_blank\">vague-sweep-151</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gnuts5m8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gnuts5m8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302747/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302738/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302605, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302685/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302820/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302609, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302779/  2.302603, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302691/  2.302607, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302883/  2.302611, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302826/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302753/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.302773/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302603, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.302739/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.302776/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.302690/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.302775/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.302693/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.302906/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.302793/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.302770/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.302866/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.11%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.302885/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.11%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.302852/  2.302598, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.302803/  2.302592, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.302764/  2.302594, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302596, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.302876/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.302864/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.302786/  2.302591, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.302822/  2.302595, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302598, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.11%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.302728/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.302796/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  10.42%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.302846/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.302759/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.302730/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.42%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.302802/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.302804/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.302787/  2.302590, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302593, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  10.42%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  2.302809/  2.302600, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.42%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  2.302807/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.42%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.42%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  2.302812/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  2.302837/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.42%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.42%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  2.302818/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7476a45a642a4a8eb38ee034184eb34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▄▅▅▁▇▅█▄▁▄▅▄▅▁▇▂▇▄▁▄▅▂▁▁▄▂▂▁▇▁▄▄▁▂</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▃▇▂▄▁▁▄▁▆▄▇▃▅▇▇▃▄█▇▇▇▂▆▁</td></tr><tr><td>tr_epoch_loss</td><td>█▇█▄▁▂▅▂▂▄▃▃▁▃▂▃▂▂▂▃▂▃▂▃▃▂▂▃▃▃▃▃▃▂▂▃▃▃▂▃</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30282</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.3026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-sweep-151</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gnuts5m8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gnuts5m8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_030813-gnuts5m8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: onivad5r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399f26c29f8d4b83b21e0eae963970e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113662220951583, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_031433-onivad5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/onivad5r' target=\"_blank\">dandy-sweep-153</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/onivad5r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/onivad5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.039334/  2.791271, val:  36.67%, val_best:  36.67%, tr:  34.93%, tr_best:  34.93%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.068956/  2.632457, val:  48.33%, val_best:  48.33%, tr:  51.17%, tr_best:  51.17%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.901756/  2.088793, val:  49.17%, val_best:  49.17%, tr:  59.75%, tr_best:  59.75%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.608730/  2.748190, val:  46.67%, val_best:  49.17%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.473452/  1.862546, val:  57.08%, val_best:  57.08%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.241083/  2.746403, val:  41.67%, val_best:  57.08%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.966793/  2.836197, val:  52.92%, val_best:  57.08%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.176010/  2.422297, val:  63.75%, val_best:  63.75%, tr:  78.04%, tr_best:  78.14%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.718919/  2.099146, val:  62.50%, val_best:  63.75%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.495097/  1.964072, val:  65.00%, val_best:  65.00%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.358160/  2.106000, val:  66.25%, val_best:  66.25%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.326799/  2.035097, val:  70.83%, val_best:  70.83%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.167601/  2.114269, val:  72.50%, val_best:  72.50%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.112690/  2.163447, val:  72.08%, val_best:  72.50%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.072971/  2.340167, val:  69.58%, val_best:  72.50%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.049223/  2.278597, val:  73.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.059039/  2.227492, val:  77.08%, val_best:  77.08%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.031342/  2.257385, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.028285/  2.336130, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.015495/  2.409792, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.013408/  2.415245, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.013519/  2.387465, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.009276/  2.422426, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.007731/  2.416537, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.007015/  2.440051, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.005825/  2.457234, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.006281/  2.490226, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.005219/  2.579002, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.005074/  2.508501, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.004648/  2.528129, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.004052/  2.539980, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.003911/  2.591680, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.003567/  2.546924, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.003483/  2.556633, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.003180/  2.591563, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.003427/  2.588223, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.003277/  2.606022, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.002735/  2.613694, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.002517/  2.646086, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.002772/  2.656393, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.002183/  2.666197, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.002024/  2.657723, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.001816/  2.683296, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.001929/  2.686760, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.001899/  2.663975, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.001806/  2.678936, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.001552/  2.705987, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.001599/  2.705704, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.001601/  2.693036, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.001670/  2.696901, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001483/  2.726016, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001650/  2.727540, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001443/  2.737865, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001344/  2.720375, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001243/  2.736029, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.001253/  2.744405, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001196/  2.764337, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001144/  2.754185, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001176/  2.766218, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.001126/  2.762977, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001175/  2.775682, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001109/  2.774211, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001134/  2.774494, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001118/  2.787103, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001131/  2.794264, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001074/  2.798886, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001111/  2.794921, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001168/  2.806707, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001131/  2.798911, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001063/  2.816800, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001050/  2.825716, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001125/  2.824403, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001048/  2.826323, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001060/  2.818097, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000985/  2.832090, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.001072/  2.832541, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001053/  2.835793, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.001048/  2.824627, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.001094/  2.830410, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000998/  2.826441, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000957/  2.843487, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000815/  2.839175, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000822/  2.857540, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.001055/  2.849998, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000835/  2.857588, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000815/  2.863348, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000906/  2.897466, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000765/  2.870039, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000716/  2.886126, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000701/  2.879063, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000696/  2.878245, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000671/  2.887712, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000654/  2.891245, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000671/  2.900320, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000681/  2.893122, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000667/  2.905478, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000671/  2.910563, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000628/  2.925778, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000598/  2.926085, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000606/  2.933337, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630fa5ffe4ca40d9b3084c3be46d8587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▆▇▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▆▇▇█▇███████▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▆▇▇█▇███████▇███████████████████████</td></tr><tr><td>val_loss</td><td>▇▂▁▅▂▃▄▄▅▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00061</td></tr><tr><td>val_acc_best</td><td>0.77083</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>2.93334</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sweep-153</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/onivad5r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/onivad5r</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_031433-onivad5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6z9n2r3u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_032134-6z9n2r3u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6z9n2r3u' target=\"_blank\">soft-sweep-155</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6z9n2r3u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6z9n2r3u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305344/  2.302583, val:  12.50%, val_best:  12.50%, tr:   8.48%, tr_best:   8.48%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.280006/  2.193274, val:  18.75%, val_best:  18.75%, tr:  13.48%, tr_best:  13.48%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.929697/  1.806261, val:  44.17%, val_best:  44.17%, tr:  34.32%, tr_best:  34.32%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.577424/  1.645911, val:  47.92%, val_best:  47.92%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.452248/  1.586141, val:  51.25%, val_best:  51.25%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.377474/  1.531930, val:  53.75%, val_best:  53.75%, tr:  58.22%, tr_best:  58.22%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.322015/  1.494381, val:  54.17%, val_best:  54.17%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.288789/  1.474628, val:  56.25%, val_best:  56.25%, tr:  60.47%, tr_best:  60.98%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.248797/  1.465584, val:  60.00%, val_best:  60.00%, tr:  62.10%, tr_best:  62.10%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.228225/  1.449148, val:  60.00%, val_best:  60.00%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.210993/  1.470081, val:  59.17%, val_best:  60.00%, tr:  63.43%, tr_best:  64.35%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.176099/  1.430048, val:  64.58%, val_best:  64.58%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.170115/  1.453197, val:  59.17%, val_best:  64.58%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.167907/  1.467122, val:  61.67%, val_best:  64.58%, tr:  65.37%, tr_best:  67.62%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.115016/  1.558899, val:  56.25%, val_best:  64.58%, tr:  67.11%, tr_best:  67.62%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.109227/  1.450490, val:  65.42%, val_best:  65.42%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.108909/  1.472863, val:  59.17%, val_best:  65.42%, tr:  68.74%, tr_best:  70.79%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.075833/  1.448629, val:  65.42%, val_best:  65.42%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.060293/  1.534199, val:  62.92%, val_best:  65.42%, tr:  70.79%, tr_best:  72.11%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.056745/  1.491422, val:  61.67%, val_best:  65.42%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.035993/  1.529398, val:  60.00%, val_best:  65.42%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.028484/  1.497560, val:  63.75%, val_best:  65.42%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.033368/  1.530040, val:  65.00%, val_best:  65.42%, tr:  74.36%, tr_best:  75.59%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.991597/  1.545261, val:  63.75%, val_best:  65.42%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.982821/  1.574606, val:  60.83%, val_best:  65.42%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.974054/  1.540448, val:  68.75%, val_best:  68.75%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.965231/  1.537931, val:  67.08%, val_best:  68.75%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.944671/  1.602278, val:  64.58%, val_best:  68.75%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.951495/  1.604136, val:  67.50%, val_best:  68.75%, tr:  81.92%, tr_best:  82.33%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.914077/  1.686408, val:  62.92%, val_best:  68.75%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.909614/  1.702746, val:  61.67%, val_best:  68.75%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.942418/  1.716699, val:  62.08%, val_best:  68.75%, tr:  82.94%, tr_best:  85.90%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.917751/  1.683949, val:  67.50%, val_best:  68.75%, tr:  84.68%, tr_best:  85.90%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.907302/  1.762390, val:  65.83%, val_best:  68.75%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.889463/  1.786423, val:  64.17%, val_best:  68.75%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.908197/  1.841666, val:  62.08%, val_best:  68.75%, tr:  86.01%, tr_best:  88.05%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.867434/  1.818351, val:  62.50%, val_best:  68.75%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.883480/  1.827181, val:  67.50%, val_best:  68.75%, tr:  89.27%, tr_best:  89.58%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.864061/  1.852200, val:  65.83%, val_best:  68.75%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.862570/  1.900163, val:  65.42%, val_best:  68.75%, tr:  90.50%, tr_best:  91.11%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.856339/  1.956114, val:  66.67%, val_best:  68.75%, tr:  89.79%, tr_best:  91.11%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.858542/  1.966296, val:  65.42%, val_best:  68.75%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.832022/  1.986607, val:  65.00%, val_best:  68.75%, tr:  91.83%, tr_best:  92.34%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.847113/  2.012318, val:  66.25%, val_best:  68.75%, tr:  92.13%, tr_best:  92.34%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.841434/  2.036220, val:  67.92%, val_best:  68.75%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.834051/  2.063269, val:  66.25%, val_best:  68.75%, tr:  92.34%, tr_best:  92.44%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.821446/  2.107348, val:  65.83%, val_best:  68.75%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.819566/  2.127361, val:  67.08%, val_best:  68.75%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.824676/  2.129135, val:  69.58%, val_best:  69.58%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.830560/  2.184565, val:  66.25%, val_best:  69.58%, tr:  93.97%, tr_best:  94.28%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.813268/  2.235341, val:  66.67%, val_best:  69.58%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.822280/  2.232743, val:  67.50%, val_best:  69.58%, tr:  93.36%, tr_best:  94.59%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.809874/  2.289936, val:  65.83%, val_best:  69.58%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.816395/  2.329069, val:  66.67%, val_best:  69.58%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.799599/  2.375962, val:  66.67%, val_best:  69.58%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.807723/  2.400328, val:  63.75%, val_best:  69.58%, tr:  94.69%, tr_best:  95.40%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.801136/  2.478459, val:  64.58%, val_best:  69.58%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.793196/  2.437919, val:  65.83%, val_best:  69.58%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.781703/  2.532867, val:  65.83%, val_best:  69.58%, tr:  95.30%, tr_best:  96.12%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.787650/  2.564034, val:  66.67%, val_best:  69.58%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.795299/  2.561027, val:  67.50%, val_best:  69.58%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.797766/  2.615556, val:  67.50%, val_best:  69.58%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.806941/  2.650561, val:  66.25%, val_best:  69.58%, tr:  95.61%, tr_best:  96.53%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.774485/  2.657165, val:  66.25%, val_best:  69.58%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.783547/  2.767449, val:  65.83%, val_best:  69.58%, tr:  95.51%, tr_best:  96.94%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.785958/  2.787132, val:  67.08%, val_best:  69.58%, tr:  96.53%, tr_best:  96.94%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.784679/  2.816609, val:  65.83%, val_best:  69.58%, tr:  96.63%, tr_best:  96.94%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.815486/  2.837100, val:  69.17%, val_best:  69.58%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.775737/  2.901237, val:  66.67%, val_best:  69.58%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.785939/  2.886686, val:  65.00%, val_best:  69.58%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.778024/  2.925082, val:  67.50%, val_best:  69.58%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.776987/  2.993684, val:  64.17%, val_best:  69.58%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.782160/  3.015372, val:  66.67%, val_best:  69.58%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.781610/  2.960672, val:  66.25%, val_best:  69.58%, tr:  96.63%, tr_best:  97.24%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.760752/  3.079110, val:  67.50%, val_best:  69.58%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.766247/  3.165600, val:  66.25%, val_best:  69.58%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.763923/  3.234519, val:  65.83%, val_best:  69.58%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.772700/  3.264218, val:  67.92%, val_best:  69.58%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.763076/  3.267651, val:  67.92%, val_best:  69.58%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.748141/  3.276524, val:  68.33%, val_best:  69.58%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.737365/  3.334477, val:  67.08%, val_best:  69.58%, tr:  97.45%, tr_best:  98.57%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.759483/  3.327692, val:  70.83%, val_best:  70.83%, tr:  97.55%, tr_best:  98.57%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.758955/  3.413928, val:  69.17%, val_best:  70.83%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.756574/  3.451363, val:  67.50%, val_best:  70.83%, tr:  97.85%, tr_best:  98.57%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.746870/  3.479187, val:  68.33%, val_best:  70.83%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.743584/  3.556207, val:  67.92%, val_best:  70.83%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.745464/  3.605806, val:  68.75%, val_best:  70.83%, tr:  97.24%, tr_best:  98.57%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.749480/  3.656265, val:  68.33%, val_best:  70.83%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.725492/  3.649271, val:  69.17%, val_best:  70.83%, tr:  98.26%, tr_best:  98.57%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.716370/  3.763506, val:  68.33%, val_best:  70.83%, tr:  98.47%, tr_best:  98.57%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.740535/  3.709390, val:  65.83%, val_best:  70.83%, tr:  98.26%, tr_best:  98.57%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.736634/  3.804344, val:  68.33%, val_best:  70.83%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.726177/  3.835994, val:  66.25%, val_best:  70.83%, tr:  98.47%, tr_best:  98.57%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.731570/  3.881778, val:  66.25%, val_best:  70.83%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.743374/  3.915851, val:  65.83%, val_best:  70.83%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.736581/  3.955319, val:  68.33%, val_best:  70.83%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.733887/  4.071505, val:  67.08%, val_best:  70.83%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.736162/  4.013613, val:  68.75%, val_best:  70.83%, tr:  98.26%, tr_best:  98.67%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.710910/  4.060417, val:  67.08%, val_best:  70.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.747210/  4.145762, val:  67.92%, val_best:  70.83%, tr:  98.67%, tr_best:  98.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1db5a343c414e23b0ea338efc39a9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▄▅▆▇▃▆████▇▇████▇████████████▇███▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▆█▇▇▇█▇█▇██▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▆█▇▇▇█▇█▇██▇██████████████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98672</td></tr><tr><td>tr_epoch_loss</td><td>0.74721</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.67917</td></tr><tr><td>val_loss</td><td>4.14576</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-155</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6z9n2r3u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6z9n2r3u</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_032134-6z9n2r3u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: givo8nxr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_032831-givo8nxr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/givo8nxr' target=\"_blank\">rosy-sweep-157</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/givo8nxr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/givo8nxr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.599227/  1.506520, val:  50.00%, val_best:  50.00%, tr:  46.99%, tr_best:  46.99%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.146320/  1.404815, val:  50.42%, val_best:  50.42%, tr:  57.51%, tr_best:  57.51%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  0.990633/  1.276272, val:  55.83%, val_best:  55.83%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.775253/  1.271234, val:  59.17%, val_best:  59.17%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.682817/  1.291421, val:  65.83%, val_best:  65.83%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.620082/  1.291219, val:  57.92%, val_best:  65.83%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.578682/  1.264368, val:  61.67%, val_best:  65.83%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.498473/  1.464317, val:  65.00%, val_best:  65.83%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.422155/  1.419013, val:  65.42%, val_best:  65.83%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.351244/  1.437938, val:  72.50%, val_best:  72.50%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.370454/  1.341472, val:  72.50%, val_best:  72.50%, tr:  88.56%, tr_best:  88.76%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.342554/  1.304693, val:  76.25%, val_best:  76.25%, tr:  90.50%, tr_best:  90.50%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.206807/  1.540171, val:  73.75%, val_best:  76.25%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.286932/  1.581516, val:  66.67%, val_best:  76.25%, tr:  94.28%, tr_best:  96.63%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.197793/  1.559105, val:  72.92%, val_best:  76.25%, tr:  96.53%, tr_best:  96.63%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.116138/  1.496912, val:  77.08%, val_best:  77.08%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.144324/  1.677297, val:  72.92%, val_best:  77.08%, tr:  97.75%, tr_best:  98.98%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.116584/  1.554917, val:  76.25%, val_best:  77.08%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.184583/  1.487829, val:  75.83%, val_best:  77.08%, tr:  96.22%, tr_best:  98.98%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.107160/  1.633199, val:  72.50%, val_best:  77.08%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.107465/  1.654300, val:  75.00%, val_best:  77.08%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.060795/  1.650702, val:  76.67%, val_best:  77.08%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.025583/  1.682878, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.017076/  1.634061, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.008132/  1.729649, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.004839/  1.630432, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.002047/  1.700205, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.001488/  1.714999, val:  82.50%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.001098/  1.725621, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.000955/  1.731407, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.000872/  1.750727, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.000747/  1.763307, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.000705/  1.769502, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.000659/  1.790551, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.000592/  1.799685, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.000568/  1.799327, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.000521/  1.812410, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.000487/  1.812816, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.000488/  1.813114, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.000461/  1.826436, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.000436/  1.835266, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.000414/  1.834924, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.000385/  1.844263, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.000387/  1.833322, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.000360/  1.841220, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.000351/  1.847795, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.000339/  1.853136, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.000340/  1.863415, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.000321/  1.868032, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.000313/  1.858174, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.000306/  1.865859, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.000292/  1.867110, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.000282/  1.860915, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.000284/  1.866411, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.000269/  1.868979, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.000262/  1.873110, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.000260/  1.881944, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.000256/  1.890273, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000247/  1.892348, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000241/  1.890510, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000236/  1.893043, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.000233/  1.893240, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.000225/  1.897722, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000220/  1.905798, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000217/  1.910071, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000217/  1.919232, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000208/  1.921905, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000215/  1.926337, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000200/  1.925115, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000197/  1.927765, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000204/  1.931760, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000191/  1.932457, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000187/  1.933606, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000182/  1.937076, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000177/  1.932251, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000176/  1.934753, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000172/  1.939298, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000169/  1.944214, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000170/  1.949153, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000164/  1.952129, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000164/  1.953444, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000162/  1.955097, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000162/  1.953147, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000158/  1.954422, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000161/  1.957801, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000153/  1.957482, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000154/  1.964478, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000149/  1.955380, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000147/  1.962104, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000145/  1.959857, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000141/  1.962034, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000138/  1.959049, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000139/  1.961238, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000138/  1.960432, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000136/  1.960591, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000135/  1.956969, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000131/  1.962480, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000130/  1.964112, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000129/  1.970256, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000125/  1.972287, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17075ee70b6b4897b4761aae65e5fafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▅▇▇▇▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▄▆▆▆▇▆▇▇█████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▄▆▆▆▇▆▇▇█████████████████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▃▄▄▄▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00012</td></tr><tr><td>val_acc_best</td><td>0.82917</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>1.97229</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-157</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/givo8nxr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/givo8nxr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_032831-givo8nxr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 21l84yjp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_033434-21l84yjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/21l84yjp' target=\"_blank\">comic-sweep-159</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/21l84yjp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/21l84yjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.171685/  1.939210, val:  36.25%, val_best:  36.25%, tr:  22.47%, tr_best:  22.47%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.621844/  1.541284, val:  54.17%, val_best:  54.17%, tr:  49.85%, tr_best:  49.85%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.354803/  1.450764, val:  56.67%, val_best:  56.67%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.216515/  1.422869, val:  57.92%, val_best:  57.92%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.131277/  1.334904, val:  61.67%, val_best:  61.67%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.067340/  1.276509, val:  66.25%, val_best:  66.25%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.982291/  1.264849, val:  64.17%, val_best:  66.25%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.939030/  1.249328, val:  64.58%, val_best:  66.25%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.890927/  1.277308, val:  67.92%, val_best:  67.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.851565/  1.278152, val:  69.17%, val_best:  69.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.817180/  1.329848, val:  61.67%, val_best:  69.17%, tr:  76.71%, tr_best:  76.81%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.763637/  1.271973, val:  66.25%, val_best:  69.17%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.762023/  1.304075, val:  67.50%, val_best:  69.17%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.716789/  1.290398, val:  70.00%, val_best:  70.00%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.674030/  1.487452, val:  63.33%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.656183/  1.460425, val:  66.25%, val_best:  70.00%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.674356/  1.404640, val:  72.92%, val_best:  72.92%, tr:  83.35%, tr_best:  87.13%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.616153/  1.436483, val:  69.17%, val_best:  72.92%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.590110/  1.491326, val:  68.33%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.581243/  1.580922, val:  69.58%, val_best:  72.92%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.546291/  1.788240, val:  64.17%, val_best:  72.92%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.523050/  1.728070, val:  66.25%, val_best:  72.92%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.517421/  1.667494, val:  68.33%, val_best:  72.92%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.482034/  1.768815, val:  69.17%, val_best:  72.92%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.445291/  1.844117, val:  67.08%, val_best:  72.92%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.422460/  1.801451, val:  69.17%, val_best:  72.92%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.436038/  1.814350, val:  72.08%, val_best:  72.92%, tr:  94.48%, tr_best:  96.73%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.394656/  1.998184, val:  68.33%, val_best:  72.92%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.374210/  2.034269, val:  71.25%, val_best:  72.92%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.352478/  2.178277, val:  64.58%, val_best:  72.92%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.358228/  2.224992, val:  63.75%, val_best:  72.92%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.350179/  2.204949, val:  69.58%, val_best:  72.92%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.348462/  2.267724, val:  68.75%, val_best:  72.92%, tr:  97.55%, tr_best:  98.37%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.347200/  2.274864, val:  67.92%, val_best:  72.92%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.300957/  2.381616, val:  71.25%, val_best:  72.92%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.273994/  2.367782, val:  69.58%, val_best:  72.92%, tr:  98.26%, tr_best:  98.77%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.259537/  2.397668, val:  72.50%, val_best:  72.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.247068/  2.521375, val:  71.25%, val_best:  72.92%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.291445/  2.519568, val:  70.00%, val_best:  72.92%, tr:  97.96%, tr_best:  99.39%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.267967/  2.628446, val:  65.83%, val_best:  72.92%, tr:  98.26%, tr_best:  99.39%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.242018/  2.548463, val:  72.08%, val_best:  72.92%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.261542/  2.584147, val:  67.50%, val_best:  72.92%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.251111/  2.586621, val:  69.17%, val_best:  72.92%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.205285/  2.723351, val:  73.33%, val_best:  73.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.197054/  2.695456, val:  69.58%, val_best:  73.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.174418/  2.817561, val:  69.58%, val_best:  73.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.207716/  3.018691, val:  67.08%, val_best:  73.33%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.224678/  2.897947, val:  67.50%, val_best:  73.33%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.190125/  2.842748, val:  71.67%, val_best:  73.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.180621/  2.923074, val:  70.42%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.154642/  3.052419, val:  71.67%, val_best:  73.33%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.125384/  3.078991, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.109707/  3.209902, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.096294/  3.347186, val:  67.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.101236/  3.267787, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.099928/  3.280765, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.092752/  3.348931, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.119839/  3.546086, val:  67.08%, val_best:  73.33%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.143104/  3.363721, val:  70.00%, val_best:  73.33%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.090922/  3.532093, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.077555/  3.412517, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.063032/  3.565017, val:  72.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.057973/  3.606620, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.078920/  3.740801, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.088231/  3.716120, val:  70.00%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.060542/  3.676481, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.061349/  3.700572, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.061031/  3.748271, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.054575/  3.836080, val:  72.08%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.045712/  3.724943, val:  72.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.038067/  3.813421, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.050200/  3.898097, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.051428/  3.927264, val:  67.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.040651/  3.886523, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.040598/  3.919543, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.036730/  4.048180, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.033669/  4.022572, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.034150/  4.022195, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.041735/  4.005802, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.032826/  4.088327, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.037009/  4.173483, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.038093/  4.212887, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.042943/  4.174215, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.046095/  4.258922, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.028690/  4.177032, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.022189/  4.149436, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.025171/  4.169371, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.026543/  4.251194, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.018566/  4.319327, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.017056/  4.247110, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.017528/  4.339809, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.014918/  4.369236, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.015519/  4.291276, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.017901/  4.288105, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.016951/  4.310196, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.015973/  4.314384, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.017733/  4.416017, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.014998/  4.489508, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.019799/  4.434060, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.026518/  4.489629, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c87ec6469c4a1493bdc6bbef2af654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▁▅▇▃▆███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇█▆▇▇█▇▇▇▇█▇█▇▇████▇▇▇██████▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▆▇▇▇▇█▆▇▇█▇▇▇▇█▇█▇▇████▇▇▇██████▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02652</td></tr><tr><td>val_acc_best</td><td>0.73333</td></tr><tr><td>val_acc_now</td><td>0.70833</td></tr><tr><td>val_loss</td><td>4.48963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-sweep-159</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/21l84yjp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/21l84yjp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_033434-21l84yjp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: smx7dmdk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_034041-smx7dmdk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/smx7dmdk' target=\"_blank\">fast-sweep-161</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/smx7dmdk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/smx7dmdk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.404437/  4.558285, val:  34.58%, val_best:  34.58%, tr:  36.98%, tr_best:  36.98%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  4.238758/  3.815928, val:  48.75%, val_best:  48.75%, tr:  40.76%, tr_best:  40.76%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  5.040178/  5.583548, val:  39.17%, val_best:  48.75%, tr:  49.85%, tr_best:  49.85%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  4.438509/  7.197920, val:  40.00%, val_best:  48.75%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  5.116058/  4.787646, val:  57.08%, val_best:  57.08%, tr:  55.16%, tr_best:  56.59%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.850521/  7.307991, val:  43.33%, val_best:  57.08%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  3.608642/  5.621719, val:  54.58%, val_best:  57.08%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  3.105979/  6.750975, val:  42.08%, val_best:  57.08%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  3.504254/  5.454688, val:  58.33%, val_best:  58.33%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  3.367450/  7.606502, val:  49.58%, val_best:  58.33%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  3.854855/  5.376884, val:  66.67%, val_best:  66.67%, tr:  71.30%, tr_best:  71.81%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  3.595485/  7.993799, val:  50.83%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  3.640210/  6.531739, val:  61.25%, val_best:  66.67%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  2.960310/  8.582464, val:  53.33%, val_best:  66.67%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  2.691011/  9.029378, val:  53.33%, val_best:  66.67%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  2.229223/  7.469010, val:  63.33%, val_best:  66.67%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  2.055640/  9.341347, val:  55.42%, val_best:  66.67%, tr:  88.36%, tr_best:  89.48%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  2.249474/  7.595907, val:  63.75%, val_best:  66.67%, tr:  87.64%, tr_best:  89.48%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  1.968905/  8.023549, val:  66.25%, val_best:  66.67%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  1.726606/  8.157428, val:  60.83%, val_best:  66.67%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  3.117876/ 14.395778, val:  49.58%, val_best:  66.67%, tr:  86.52%, tr_best:  93.56%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  2.848840/ 11.552250, val:  58.75%, val_best:  66.67%, tr:  87.74%, tr_best:  93.56%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  1.781577/  8.860072, val:  70.00%, val_best:  70.00%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  1.406917/  9.021591, val:  70.83%, val_best:  70.83%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  1.348658/  9.376975, val:  61.25%, val_best:  70.83%, tr:  96.53%, tr_best:  97.24%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  1.535445/  9.244185, val:  67.08%, val_best:  70.83%, tr:  96.94%, tr_best:  97.24%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  1.336133/  9.988915, val:  61.25%, val_best:  70.83%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  1.349802/  9.457597, val:  69.17%, val_best:  70.83%, tr:  97.34%, tr_best:  97.65%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  1.331964/  9.451285, val:  73.33%, val_best:  73.33%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  1.149152/  9.701818, val:  67.92%, val_best:  73.33%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  1.377018/  9.898383, val:  70.00%, val_best:  73.33%, tr:  96.02%, tr_best:  98.37%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  1.349416/ 10.915026, val:  68.75%, val_best:  73.33%, tr:  96.42%, tr_best:  98.37%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  1.347605/ 10.559249, val:  69.58%, val_best:  73.33%, tr:  96.63%, tr_best:  98.37%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  1.833359/ 11.635153, val:  66.67%, val_best:  73.33%, tr:  95.30%, tr_best:  98.37%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  1.367165/ 11.961126, val:  69.58%, val_best:  73.33%, tr:  97.55%, tr_best:  98.37%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.862873/ 12.183513, val:  72.08%, val_best:  73.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.806370/ 11.511201, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.901981/ 13.500430, val:  62.08%, val_best:  74.17%, tr:  98.77%, tr_best:  99.90%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  1.000759/ 13.372886, val:  65.83%, val_best:  74.17%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  1.268033/ 12.492623, val:  72.08%, val_best:  74.17%, tr:  97.85%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.876320/ 12.370630, val:  72.08%, val_best:  74.17%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.799754/ 12.959406, val:  72.08%, val_best:  74.17%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.667611/ 12.808617, val:  70.83%, val_best:  74.17%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.716477/ 13.028799, val:  72.92%, val_best:  74.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.934935/ 13.886310, val:  69.58%, val_best:  74.17%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.700886/ 13.546153, val:  70.83%, val_best:  74.17%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.543754/ 13.756000, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.585861/ 13.838625, val:  71.25%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.625313/ 14.237896, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.703703/ 14.312798, val:  75.83%, val_best:  75.83%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.503076/ 14.365847, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.498481/ 14.365595, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.606056/ 14.684003, val:  74.17%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.468067/ 15.167913, val:  69.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.479878/ 15.128506, val:  75.00%, val_best:  75.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.468826/ 15.372179, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.465963/ 15.264128, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.651297/ 15.661937, val:  72.50%, val_best:  75.83%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.457783/ 16.155344, val:  72.92%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.479390/ 16.049482, val:  72.50%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.367373/ 15.844421, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.336326/ 16.457705, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.377151/ 16.365881, val:  75.42%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.302115/ 16.023432, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.331540/ 16.580402, val:  75.42%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.324760/ 16.401030, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.476278/ 16.925287, val:  73.33%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.464765/ 17.564642, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.288068/ 17.111277, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.275701/ 16.910944, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.253561/ 16.720264, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.291265/ 17.349733, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.267190/ 17.877110, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.230528/ 17.875713, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.199625/ 17.521523, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.201564/ 17.942818, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.226443/ 18.507746, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.296582/ 18.452271, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.239278/ 18.668436, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.191267/ 18.418983, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.185560/ 18.232155, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.177465/ 18.692139, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.186568/ 18.650166, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.132076/ 18.591236, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.170493/ 18.961554, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.179957/ 18.969269, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.156215/ 19.232304, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.181450/ 19.512693, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.161744/ 18.962906, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.150455/ 19.124264, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.192970/ 19.321817, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.176268/ 20.089186, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.144100/ 19.905327, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.156065/ 19.367140, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.141542/ 19.836840, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.155162/ 19.680599, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.175770/ 19.756418, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.208458/ 19.808920, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.167405/ 19.880398, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.170283/ 20.513062, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175806f81d9c4dcd8ab8c562a41dafba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▅▅▄▆▇▇▆███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▂▃▅▄▆▅▅▅▅▆▇▇▅▇▇▇▇█▇█▇▇████▇█▇██▇█████</td></tr><tr><td>tr_acc</td><td>▁▂▃▄▅▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▄██▅▆▆▅▄▃▅▃▃▂▃▂▂▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▂▃▅▄▆▅▅▅▅▆▇▇▅▇▇▇▇█▇█▇▇████▇█▇██▇█████</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▂▃▂▃▄▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.17028</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>20.51306</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-161</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/smx7dmdk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/smx7dmdk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_034041-smx7dmdk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fn7vq7hy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817dcf3dcd284f199f8396abe67c84cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113329221391015, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_034737-fn7vq7hy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fn7vq7hy' target=\"_blank\">glorious-sweep-163</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fn7vq7hy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fn7vq7hy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.248861/  2.667758, val:  40.42%, val_best:  40.42%, tr:  17.98%, tr_best:  17.98%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.366982/  3.267172, val:  47.92%, val_best:  47.92%, tr:  48.11%, tr_best:  48.11%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.049823/  3.471527, val:  55.83%, val_best:  55.83%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.472599/  4.146235, val:  51.25%, val_best:  55.83%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.785893/  3.565689, val:  60.83%, val_best:  60.83%, tr:  59.75%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.684518/  4.544769, val:  45.42%, val_best:  60.83%, tr:  63.94%, tr_best:  64.04%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.636332/  3.973356, val:  60.42%, val_best:  60.83%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.946011/  4.787565, val:  45.83%, val_best:  60.83%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.779784/  4.160346, val:  53.75%, val_best:  60.83%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  4.060404/  5.500981, val:  53.33%, val_best:  60.83%, tr:  64.86%, tr_best:  68.03%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  3.931152/  4.308151, val:  58.33%, val_best:  60.83%, tr:  67.31%, tr_best:  68.03%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  2.961879/  5.128603, val:  54.58%, val_best:  60.83%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  3.708739/  4.499297, val:  63.75%, val_best:  63.75%, tr:  70.99%, tr_best:  72.11%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  3.650454/  5.872627, val:  55.83%, val_best:  63.75%, tr:  69.25%, tr_best:  72.11%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  3.435667/  7.133919, val:  61.25%, val_best:  63.75%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  3.857404/  6.807220, val:  60.42%, val_best:  63.75%, tr:  72.83%, tr_best:  74.57%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  3.568015/  6.868984, val:  66.25%, val_best:  66.25%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  3.399048/  6.733247, val:  64.17%, val_best:  66.25%, tr:  79.57%, tr_best:  79.57%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  3.717371/  7.336455, val:  65.42%, val_best:  66.25%, tr:  78.04%, tr_best:  79.57%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  3.307688/  7.729817, val:  57.08%, val_best:  66.25%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  4.447016/  7.709795, val:  59.58%, val_best:  66.25%, tr:  78.04%, tr_best:  83.15%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  3.825204/ 10.582808, val:  57.08%, val_best:  66.25%, tr:  80.80%, tr_best:  83.15%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  3.738674/  8.360978, val:  67.50%, val_best:  67.50%, tr:  81.72%, tr_best:  83.15%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  3.470684/  8.321149, val:  64.17%, val_best:  67.50%, tr:  85.09%, tr_best:  85.09%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  3.652210/  9.393998, val:  63.75%, val_best:  67.50%, tr:  84.58%, tr_best:  85.09%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  3.498861/  9.321345, val:  69.58%, val_best:  69.58%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  4.088438/ 10.366593, val:  61.25%, val_best:  69.58%, tr:  84.07%, tr_best:  86.52%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  3.476831/ 10.723817, val:  62.50%, val_best:  69.58%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  3.583399/ 10.248230, val:  67.08%, val_best:  69.58%, tr:  87.33%, tr_best:  88.56%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  3.331533/ 10.616611, val:  65.00%, val_best:  69.58%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  3.796370/ 10.374738, val:  72.50%, val_best:  72.50%, tr:  89.79%, tr_best:  91.73%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  3.282671/ 10.834937, val:  70.83%, val_best:  72.50%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  4.096747/ 12.822742, val:  60.00%, val_best:  72.50%, tr:  86.82%, tr_best:  92.65%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  4.141007/ 12.311191, val:  69.17%, val_best:  72.50%, tr:  88.46%, tr_best:  92.65%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  3.976665/ 12.234592, val:  64.17%, val_best:  72.50%, tr:  90.70%, tr_best:  92.65%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  3.337005/ 12.447107, val:  67.50%, val_best:  72.50%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  3.342251/ 12.636512, val:  67.92%, val_best:  72.50%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  4.068354/ 13.799987, val:  67.08%, val_best:  72.50%, tr:  90.81%, tr_best:  93.77%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  3.585717/ 13.937893, val:  63.75%, val_best:  72.50%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  3.684990/ 12.868070, val:  75.83%, val_best:  75.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  3.659925/ 14.592381, val:  69.17%, val_best:  75.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  3.898297/ 14.229830, val:  70.42%, val_best:  75.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  3.769832/ 13.865275, val:  75.00%, val_best:  75.83%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  3.857573/ 16.058407, val:  63.75%, val_best:  75.83%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  4.334520/ 15.023449, val:  73.33%, val_best:  75.83%, tr:  91.11%, tr_best:  95.71%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  3.583699/ 14.748281, val:  73.33%, val_best:  75.83%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  3.875942/ 15.730561, val:  71.67%, val_best:  75.83%, tr:  94.48%, tr_best:  96.02%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  3.686482/ 15.795173, val:  70.42%, val_best:  75.83%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  4.000770/ 15.734606, val:  75.83%, val_best:  75.83%, tr:  93.97%, tr_best:  96.63%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  3.593433/ 15.811653, val:  76.67%, val_best:  76.67%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  3.369184/ 18.252081, val:  67.08%, val_best:  76.67%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  3.868322/ 18.312799, val:  67.08%, val_best:  76.67%, tr:  95.30%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  3.597279/ 17.708164, val:  75.00%, val_best:  76.67%, tr:  97.55%, tr_best:  97.85%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  3.674134/ 18.534637, val:  73.33%, val_best:  76.67%, tr:  97.65%, tr_best:  97.85%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  3.453210/ 18.901991, val:  73.33%, val_best:  76.67%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  3.711675/ 18.728903, val:  71.67%, val_best:  76.67%, tr:  97.24%, tr_best:  98.57%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  3.443137/ 20.022003, val:  70.00%, val_best:  76.67%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  4.015780/ 19.814148, val:  71.25%, val_best:  76.67%, tr:  96.94%, tr_best:  98.57%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  3.554418/ 19.658808, val:  72.50%, val_best:  76.67%, tr:  97.65%, tr_best:  98.57%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  3.687976/ 20.019451, val:  73.75%, val_best:  76.67%, tr:  98.26%, tr_best:  98.57%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  3.489256/ 20.866350, val:  68.75%, val_best:  76.67%, tr:  97.45%, tr_best:  98.57%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  4.139174/ 20.970919, val:  71.67%, val_best:  76.67%, tr:  96.22%, tr_best:  98.57%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  4.042053/ 21.716106, val:  72.92%, val_best:  76.67%, tr:  95.51%, tr_best:  98.57%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  3.352024/ 21.662020, val:  75.42%, val_best:  76.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  3.355595/ 21.369434, val:  72.92%, val_best:  76.67%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  3.285906/ 21.166075, val:  76.25%, val_best:  76.67%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  3.275964/ 21.710020, val:  76.25%, val_best:  76.67%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  3.202703/ 21.849928, val:  75.42%, val_best:  76.67%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  3.348936/ 22.752193, val:  72.50%, val_best:  76.67%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  3.436665/ 22.856617, val:  75.00%, val_best:  76.67%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  3.543193/ 22.694227, val:  77.08%, val_best:  77.08%, tr:  98.77%, tr_best:  99.28%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  3.591347/ 24.413977, val:  73.75%, val_best:  77.08%, tr:  98.67%, tr_best:  99.28%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  3.418713/ 24.018309, val:  73.33%, val_best:  77.08%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  3.768957/ 24.718777, val:  72.92%, val_best:  77.08%, tr:  98.16%, tr_best:  99.28%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  3.503982/ 24.154278, val:  76.25%, val_best:  77.08%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  3.321894/ 24.340710, val:  74.58%, val_best:  77.08%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  3.198700/ 24.203384, val:  76.25%, val_best:  77.08%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  3.631665/ 25.190634, val:  75.00%, val_best:  77.08%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  3.563269/ 25.419054, val:  75.83%, val_best:  77.08%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  3.461954/ 25.360525, val:  74.17%, val_best:  77.08%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  3.379520/ 25.544863, val:  76.67%, val_best:  77.08%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  3.391128/ 25.622030, val:  76.67%, val_best:  77.08%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  3.522193/ 26.374807, val:  75.42%, val_best:  77.08%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  3.751605/ 26.913979, val:  75.00%, val_best:  77.08%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  3.478699/ 26.396793, val:  77.92%, val_best:  77.92%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  3.505344/ 26.861338, val:  76.25%, val_best:  77.92%, tr:  98.88%, tr_best:  99.69%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  3.458751/ 28.510130, val:  69.58%, val_best:  77.92%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  3.519760/ 28.483782, val:  75.00%, val_best:  77.92%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  3.203944/ 28.213181, val:  75.83%, val_best:  77.92%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  3.316241/ 28.870716, val:  77.92%, val_best:  77.92%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  3.644195/ 29.020973, val:  75.83%, val_best:  77.92%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  3.148702/ 28.700731, val:  76.25%, val_best:  77.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  3.151083/ 29.609627, val:  76.25%, val_best:  77.92%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  3.466473/ 29.818897, val:  73.75%, val_best:  77.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  3.215472/ 29.872383, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  3.425114/ 30.636974, val:  76.25%, val_best:  77.92%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  3.256045/ 31.568359, val:  74.58%, val_best:  77.92%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  3.152277/ 30.917282, val:  77.92%, val_best:  77.92%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  3.172077/ 31.725407, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  3.270382/ 31.183500, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f46ba76a5348a7afa6eb9f794a0661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▅▄▃▇▃▅▇█▇█▆▇██▇█▇███▇████████████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▂▃▅▅▅▄▄▅▅▆▅▆▆█▇▇▇█▇▇▇▇▇███▇▇▇▇██▇████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇██▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁▄▃▃▇▆▅▅▅▆▆▇▅▇▅▇▆▆█▆▆▆▅▇▆▇▄▄▅▅▅▆▅▅▅▅▅▄▅▄</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▂▃▅▅▅▄▄▅▅▆▅▆▆█▇▇▇█▇▇▇▇▇███▇▇▇▇██▇████</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▁▂▂▂▃▃▃▃▄▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>3.27038</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.74583</td></tr><tr><td>val_loss</td><td>31.1835</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-163</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fn7vq7hy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fn7vq7hy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_034737-fn7vq7hy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kbnl5bdo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_035435-kbnl5bdo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kbnl5bdo' target=\"_blank\">worthy-sweep-165</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kbnl5bdo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kbnl5bdo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.693139/  5.022769, val:  31.25%, val_best:  31.25%, tr:  32.18%, tr_best:  32.18%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  3.681275/  2.795865, val:  30.00%, val_best:  31.25%, tr:  33.91%, tr_best:  33.91%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  3.353093/  2.925930, val:  27.92%, val_best:  31.25%, tr:  32.28%, tr_best:  33.91%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  3.829011/  3.556257, val:  30.42%, val_best:  31.25%, tr:  26.46%, tr_best:  33.91%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  3.775996/  4.600660, val:  29.58%, val_best:  31.25%, tr:  24.11%, tr_best:  33.91%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  3.468230/  5.142252, val:  26.67%, val_best:  31.25%, tr:  26.46%, tr_best:  33.91%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  3.681540/  2.826066, val:  28.75%, val_best:  31.25%, tr:  25.54%, tr_best:  33.91%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  3.248091/  3.344886, val:  34.17%, val_best:  34.17%, tr:  27.37%, tr_best:  33.91%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  2.845649/  4.552152, val:  27.08%, val_best:  34.17%, tr:  29.52%, tr_best:  33.91%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  3.556700/  3.046369, val:  40.83%, val_best:  40.83%, tr:  29.01%, tr_best:  33.91%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  3.714558/  6.234499, val:  17.50%, val_best:  40.83%, tr:  30.44%, tr_best:  33.91%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  4.141612/  5.202781, val:  21.67%, val_best:  40.83%, tr:  26.05%, tr_best:  33.91%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  3.285832/  3.010180, val:  37.50%, val_best:  40.83%, tr:  30.54%, tr_best:  33.91%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  3.894226/  3.853063, val:  21.25%, val_best:  40.83%, tr:  28.19%, tr_best:  33.91%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  3.851278/  4.905468, val:  26.67%, val_best:  40.83%, tr:  29.42%, tr_best:  33.91%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  3.753289/  3.431162, val:  22.92%, val_best:  40.83%, tr:  29.21%, tr_best:  33.91%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  3.611213/  2.898862, val:  28.75%, val_best:  40.83%, tr:  28.40%, tr_best:  33.91%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  3.447554/  3.559986, val:  26.67%, val_best:  40.83%, tr:  28.19%, tr_best:  33.91%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  4.911778/  4.900586, val:  20.42%, val_best:  40.83%, tr:  27.37%, tr_best:  33.91%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  3.810620/  6.484372, val:  15.00%, val_best:  40.83%, tr:  29.62%, tr_best:  33.91%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  4.474758/  6.315786, val:  18.75%, val_best:  40.83%, tr:  30.03%, tr_best:  33.91%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  4.185885/  5.226422, val:  20.00%, val_best:  40.83%, tr:  26.97%, tr_best:  33.91%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  4.640384/  2.562227, val:  39.17%, val_best:  40.83%, tr:  24.92%, tr_best:  33.91%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  3.868801/  5.632475, val:  28.75%, val_best:  40.83%, tr:  29.83%, tr_best:  33.91%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  3.591417/  3.797962, val:  34.17%, val_best:  40.83%, tr:  31.36%, tr_best:  33.91%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  2.984782/  3.294474, val:  29.58%, val_best:  40.83%, tr:  30.64%, tr_best:  33.91%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  3.543137/  3.674818, val:  31.67%, val_best:  40.83%, tr:  31.77%, tr_best:  33.91%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  3.049765/  4.133624, val:  19.58%, val_best:  40.83%, tr:  30.75%, tr_best:  33.91%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  4.307669/  5.253704, val:  32.08%, val_best:  40.83%, tr:  25.94%, tr_best:  33.91%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  3.325349/  3.601499, val:  20.83%, val_best:  40.83%, tr:  23.80%, tr_best:  33.91%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  3.359204/  3.468708, val:  32.50%, val_best:  40.83%, tr:  26.76%, tr_best:  33.91%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  3.217900/  4.536567, val:  17.50%, val_best:  40.83%, tr:  31.26%, tr_best:  33.91%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  4.168448/  4.172020, val:  32.50%, val_best:  40.83%, tr:  28.70%, tr_best:  33.91%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  4.226868/  4.173841, val:  29.58%, val_best:  40.83%, tr:  27.78%, tr_best:  33.91%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  4.220754/  5.812451, val:  25.83%, val_best:  40.83%, tr:  29.21%, tr_best:  33.91%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  4.204314/  4.372641, val:  27.92%, val_best:  40.83%, tr:  27.89%, tr_best:  33.91%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  3.252047/  2.842547, val:  37.08%, val_best:  40.83%, tr:  30.75%, tr_best:  33.91%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  3.606245/  4.146578, val:  20.00%, val_best:  40.83%, tr:  31.36%, tr_best:  33.91%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  2.972003/  2.805007, val:  30.00%, val_best:  40.83%, tr:  32.48%, tr_best:  33.91%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  3.639627/  4.575899, val:  22.92%, val_best:  40.83%, tr:  30.75%, tr_best:  33.91%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  3.020939/  3.409466, val:  23.33%, val_best:  40.83%, tr:  33.40%, tr_best:  33.91%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  3.446008/  3.423347, val:  30.00%, val_best:  40.83%, tr:  29.42%, tr_best:  33.91%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  3.385801/  3.668654, val:  23.75%, val_best:  40.83%, tr:  29.93%, tr_best:  33.91%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  3.135112/  3.618618, val:  31.67%, val_best:  40.83%, tr:  31.56%, tr_best:  33.91%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  3.062025/  3.091548, val:  35.00%, val_best:  40.83%, tr:  33.09%, tr_best:  33.91%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  3.205533/  3.966206, val:  31.67%, val_best:  40.83%, tr:  30.54%, tr_best:  33.91%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  3.493219/  5.050272, val:  21.25%, val_best:  40.83%, tr:  29.93%, tr_best:  33.91%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  3.461750/  5.106231, val:  32.50%, val_best:  40.83%, tr:  25.94%, tr_best:  33.91%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  4.522010/  4.398935, val:  32.92%, val_best:  40.83%, tr:  29.72%, tr_best:  33.91%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  3.800553/  4.222116, val:  32.08%, val_best:  40.83%, tr:  28.19%, tr_best:  33.91%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  3.091614/  2.786220, val:  23.33%, val_best:  40.83%, tr:  33.09%, tr_best:  33.91%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  3.207467/  3.999791, val:  32.08%, val_best:  40.83%, tr:  28.80%, tr_best:  33.91%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  3.370493/  4.456894, val:  34.58%, val_best:  40.83%, tr:  30.44%, tr_best:  33.91%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  3.115318/  5.185705, val:  28.33%, val_best:  40.83%, tr:  31.87%, tr_best:  33.91%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  3.249313/  3.533655, val:  25.83%, val_best:  40.83%, tr:  31.05%, tr_best:  33.91%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  3.154349/  3.171417, val:  28.33%, val_best:  40.83%, tr:  31.05%, tr_best:  33.91%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  3.493321/  6.309699, val:  20.00%, val_best:  40.83%, tr:  26.86%, tr_best:  33.91%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  4.539706/  3.515683, val:  26.25%, val_best:  40.83%, tr:  29.32%, tr_best:  33.91%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  2.718191/  4.389539, val:  29.58%, val_best:  40.83%, tr:  32.99%, tr_best:  33.91%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  4.209753/  6.814843, val:  17.92%, val_best:  40.83%, tr:  23.29%, tr_best:  33.91%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  4.066997/  4.781527, val:  23.33%, val_best:  40.83%, tr:  26.56%, tr_best:  33.91%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  4.239348/  3.202589, val:  36.25%, val_best:  40.83%, tr:  29.21%, tr_best:  33.91%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  4.512533/  3.379801, val:  23.33%, val_best:  40.83%, tr:  26.05%, tr_best:  33.91%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  4.101872/  3.811080, val:  31.67%, val_best:  40.83%, tr:  28.50%, tr_best:  33.91%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  3.698952/  2.426866, val:  38.33%, val_best:  40.83%, tr:  31.77%, tr_best:  33.91%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  3.534675/  4.473914, val:  19.58%, val_best:  40.83%, tr:  30.44%, tr_best:  33.91%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  3.747102/  3.823768, val:  20.83%, val_best:  40.83%, tr:  31.97%, tr_best:  33.91%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  3.666871/  3.519232, val:  32.08%, val_best:  40.83%, tr:  28.09%, tr_best:  33.91%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  3.590766/  4.669499, val:  32.08%, val_best:  40.83%, tr:  28.60%, tr_best:  33.91%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  3.983231/  3.678967, val:  28.33%, val_best:  40.83%, tr:  31.46%, tr_best:  33.91%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  3.820036/  3.954235, val:  29.58%, val_best:  40.83%, tr:  29.01%, tr_best:  33.91%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  3.215096/  4.061747, val:  30.00%, val_best:  40.83%, tr:  30.03%, tr_best:  33.91%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  3.220311/  2.434271, val:  23.75%, val_best:  40.83%, tr:  30.13%, tr_best:  33.91%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  2.867577/  4.488261, val:  28.33%, val_best:  40.83%, tr:  30.44%, tr_best:  33.91%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  3.664619/  4.336827, val:  22.08%, val_best:  40.83%, tr:  29.32%, tr_best:  33.91%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  3.686652/  4.404365, val:  15.83%, val_best:  40.83%, tr:  33.61%, tr_best:  33.91%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  3.101645/  4.236806, val:  18.75%, val_best:  40.83%, tr:  31.97%, tr_best:  33.91%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  3.134576/  6.298186, val:  17.92%, val_best:  40.83%, tr:  27.89%, tr_best:  33.91%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  4.145879/  4.432402, val:  22.50%, val_best:  40.83%, tr:  26.66%, tr_best:  33.91%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  4.310355/  4.032897, val:  37.08%, val_best:  40.83%, tr:  32.07%, tr_best:  33.91%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  3.270884/  3.766227, val:  32.92%, val_best:  40.83%, tr:  31.05%, tr_best:  33.91%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  3.415631/  4.004796, val:  28.75%, val_best:  40.83%, tr:  28.40%, tr_best:  33.91%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  3.114982/  5.040326, val:  18.33%, val_best:  40.83%, tr:  31.97%, tr_best:  33.91%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  3.545969/  3.406003, val:  37.08%, val_best:  40.83%, tr:  30.34%, tr_best:  33.91%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  3.722000/  3.448984, val:  20.42%, val_best:  40.83%, tr:  33.09%, tr_best:  33.91%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  2.818151/  3.502192, val:  21.67%, val_best:  40.83%, tr:  30.13%, tr_best:  33.91%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  3.585192/  2.861545, val:  29.17%, val_best:  40.83%, tr:  32.38%, tr_best:  33.91%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  3.014838/  2.550321, val:  34.58%, val_best:  40.83%, tr:  32.07%, tr_best:  33.91%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  2.940348/  4.307367, val:  31.67%, val_best:  40.83%, tr:  32.07%, tr_best:  33.91%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  3.650791/  4.779198, val:  37.50%, val_best:  40.83%, tr:  31.66%, tr_best:  33.91%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  3.549036/  3.710018, val:  29.17%, val_best:  40.83%, tr:  34.01%, tr_best:  34.01%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  3.419555/  4.241098, val:  33.75%, val_best:  40.83%, tr:  27.37%, tr_best:  34.01%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  3.206821/  3.480551, val:  27.50%, val_best:  40.83%, tr:  33.09%, tr_best:  34.01%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  3.351869/  4.004045, val:  17.92%, val_best:  40.83%, tr:  27.48%, tr_best:  34.01%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  3.766177/  3.713781, val:  27.92%, val_best:  40.83%, tr:  28.19%, tr_best:  34.01%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  3.895169/  4.907316, val:  22.08%, val_best:  40.83%, tr:  28.60%, tr_best:  34.01%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  4.368445/  2.787934, val:  34.58%, val_best:  40.83%, tr:  30.85%, tr_best:  34.01%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  3.610272/  3.762171, val:  17.92%, val_best:  40.83%, tr:  28.60%, tr_best:  34.01%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  4.144132/  4.969719, val:  19.17%, val_best:  40.83%, tr:  28.91%, tr_best:  34.01%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  4.551428/  3.948245, val:  28.33%, val_best:  40.83%, tr:  32.48%, tr_best:  34.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49e4980ec0c47c08ba920f0532deab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▅▄▅▅▅▄▄▆▄▂▃▅█▄▅▅▅▅▅▃▄▄▆▅▆▅▅▆▄▅▂▄▅▅▂▅▅▁▁▅</td></tr><tr><td>summary_val_acc</td><td>▅▅▅▆█▇▄▄▁▂▆▆▃▆▅▂▃▃▆▆▆▆▄▄▂▇▂▆▅▃▁▂▇▂▂▆▇▄▃▂</td></tr><tr><td>tr_acc</td><td>▇▇▂▄▅▆▅▄▅▃▆▇▁▅▄▆▆▆█▃▄▆▆▅▁▅▆▄▅▆█▄▇▇█▇▇█▅▅</td></tr><tr><td>tr_epoch_loss</td><td>▁▄▅▃▄▃▅▄▅▇▄▄▃▇▇▄▅▄▂▄▅▄▃█▇▇▄▅▅▃▅▃▇▃▅▂▅▃▆▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▃████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▅▅▅▆█▇▄▄▁▂▆▆▃▆▅▂▃▃▆▆▆▆▄▄▂▇▂▆▅▃▁▂▇▂▂▆▇▄▃▂</td></tr><tr><td>val_loss</td><td>▅▂▄▂▂▂▅▃▇▅▃▃▃▄▄▄▄▃▂▅▄▄▃▃█▂▄▃▃▁▄▇▄▅▃▁▅▃▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.32482</td></tr><tr><td>tr_epoch_loss</td><td>4.55143</td></tr><tr><td>val_acc_best</td><td>0.40833</td></tr><tr><td>val_acc_now</td><td>0.28333</td></tr><tr><td>val_loss</td><td>3.94825</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-165</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kbnl5bdo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kbnl5bdo</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_035435-kbnl5bdo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: he0catwh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c838502037d49f698d5528e5f673db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113501945510506, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_040044-he0catwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/he0catwh' target=\"_blank\">devout-sweep-167</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/he0catwh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/he0catwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304023/  2.299483, val:   9.17%, val_best:  10.00%, tr:   8.68%, tr_best:   8.68%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.247988/  2.163225, val:  28.75%, val_best:  28.75%, tr:  16.55%, tr_best:  16.55%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.971662/  1.915094, val:  47.92%, val_best:  47.92%, tr:  40.96%, tr_best:  40.96%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.740502/  1.820242, val:  47.08%, val_best:  47.92%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.630152/  1.763770, val:  52.50%, val_best:  52.50%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.586850/  1.759087, val:  51.67%, val_best:  52.50%, tr:  59.04%, tr_best:  59.04%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.553782/  1.743201, val:  53.33%, val_best:  53.33%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.530662/  1.759414, val:  56.67%, val_best:  56.67%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.526717/  1.738886, val:  52.92%, val_best:  56.67%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.516619/  1.752630, val:  55.00%, val_best:  56.67%, tr:  61.49%, tr_best:  62.21%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.508934/  1.742341, val:  58.75%, val_best:  58.75%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.492939/  1.758470, val:  55.42%, val_best:  58.75%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.490583/  1.768046, val:  56.25%, val_best:  58.75%, tr:  62.31%, tr_best:  64.25%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.453037/  1.812386, val:  56.25%, val_best:  58.75%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.450584/  1.761131, val:  61.25%, val_best:  61.25%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.448493/  1.759056, val:  56.25%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.432802/  1.724262, val:  59.58%, val_best:  61.25%, tr:  67.42%, tr_best:  67.42%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.426922/  1.771915, val:  55.00%, val_best:  61.25%, tr:  67.01%, tr_best:  67.42%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.425046/  1.799273, val:  58.33%, val_best:  61.25%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.407584/  1.784496, val:  58.33%, val_best:  61.25%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.403372/  1.793284, val:  64.17%, val_best:  64.17%, tr:  67.21%, tr_best:  70.07%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.437408/  1.809172, val:  58.33%, val_best:  64.17%, tr:  67.52%, tr_best:  70.07%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.401442/  1.816575, val:  63.33%, val_best:  64.17%, tr:  69.77%, tr_best:  70.07%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.384393/  1.838307, val:  59.58%, val_best:  64.17%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.392825/  1.814998, val:  61.67%, val_best:  64.17%, tr:  69.56%, tr_best:  70.28%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.389328/  1.797169, val:  63.33%, val_best:  64.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.382821/  1.871841, val:  60.83%, val_best:  64.17%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.402229/  1.820623, val:  62.08%, val_best:  64.17%, tr:  72.63%, tr_best:  72.63%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.376550/  1.860241, val:  60.00%, val_best:  64.17%, tr:  72.11%, tr_best:  72.63%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.373121/  1.879039, val:  61.25%, val_best:  64.17%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.411383/  1.931507, val:  58.33%, val_best:  64.17%, tr:  71.09%, tr_best:  74.16%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.393972/  1.911953, val:  58.75%, val_best:  64.17%, tr:  72.73%, tr_best:  74.16%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.389818/  1.937002, val:  62.50%, val_best:  64.17%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.384894/  1.935036, val:  59.17%, val_best:  64.17%, tr:  73.65%, tr_best:  75.38%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.407703/  1.989298, val:  57.92%, val_best:  64.17%, tr:  70.89%, tr_best:  75.38%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.383087/  1.945194, val:  59.17%, val_best:  64.17%, tr:  74.26%, tr_best:  75.38%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.400933/  1.937508, val:  64.17%, val_best:  64.17%, tr:  74.46%, tr_best:  75.38%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.377689/  1.937038, val:  62.92%, val_best:  64.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.384661/  1.971044, val:  60.42%, val_best:  64.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.399218/  2.053935, val:  63.33%, val_best:  64.17%, tr:  75.28%, tr_best:  76.81%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.399321/  2.051042, val:  59.58%, val_best:  64.17%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.392421/  2.024456, val:  60.00%, val_best:  64.17%, tr:  76.30%, tr_best:  77.73%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.384192/  2.112726, val:  61.67%, val_best:  64.17%, tr:  77.12%, tr_best:  77.73%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.391166/  2.097123, val:  70.00%, val_best:  70.00%, tr:  77.32%, tr_best:  77.73%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.387178/  2.093740, val:  65.83%, val_best:  70.00%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.387729/  2.153835, val:  66.25%, val_best:  70.00%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.390917/  2.126054, val:  67.50%, val_best:  70.00%, tr:  79.47%, tr_best:  79.88%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.426528/  2.146048, val:  64.58%, val_best:  70.00%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.414787/  2.126124, val:  67.08%, val_best:  70.00%, tr:  79.26%, tr_best:  79.98%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.424625/  2.200828, val:  65.00%, val_best:  70.00%, tr:  79.47%, tr_best:  79.98%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.451233/  2.239240, val:  64.58%, val_best:  70.00%, tr:  77.63%, tr_best:  79.98%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.399229/  2.283255, val:  63.33%, val_best:  70.00%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.450128/  2.248738, val:  64.17%, val_best:  70.00%, tr:  80.80%, tr_best:  82.94%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.428791/  2.324573, val:  65.83%, val_best:  70.00%, tr:  82.43%, tr_best:  82.94%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.428553/  2.364084, val:  64.58%, val_best:  70.00%, tr:  81.21%, tr_best:  82.94%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.434527/  2.473168, val:  63.75%, val_best:  70.00%, tr:  82.12%, tr_best:  82.94%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.438949/  2.374652, val:  60.42%, val_best:  70.00%, tr:  80.69%, tr_best:  82.94%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.423706/  2.440246, val:  64.58%, val_best:  70.00%, tr:  81.31%, tr_best:  82.94%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.447475/  2.435520, val:  70.00%, val_best:  70.00%, tr:  82.33%, tr_best:  82.94%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.459897/  2.437910, val:  65.83%, val_best:  70.00%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.466812/  2.499320, val:  63.75%, val_best:  70.00%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.465745/  2.582308, val:  62.50%, val_best:  70.00%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.465059/  2.510567, val:  66.67%, val_best:  70.00%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.473555/  2.714738, val:  62.92%, val_best:  70.00%, tr:  83.25%, tr_best:  86.11%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.468071/  2.631240, val:  66.67%, val_best:  70.00%, tr:  84.78%, tr_best:  86.11%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.482318/  2.681554, val:  66.67%, val_best:  70.00%, tr:  84.78%, tr_best:  86.11%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.526751/  2.708952, val:  63.33%, val_best:  70.00%, tr:  84.98%, tr_best:  86.11%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.476844/  2.731166, val:  66.67%, val_best:  70.00%, tr:  85.39%, tr_best:  86.11%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.500068/  2.808863, val:  65.00%, val_best:  70.00%, tr:  84.68%, tr_best:  86.11%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.510003/  2.795389, val:  68.75%, val_best:  70.00%, tr:  84.88%, tr_best:  86.11%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.499595/  2.917290, val:  63.33%, val_best:  70.00%, tr:  86.01%, tr_best:  86.11%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.495682/  2.857286, val:  66.67%, val_best:  70.00%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.533204/  2.906518, val:  67.08%, val_best:  70.00%, tr:  85.29%, tr_best:  86.82%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.528149/  2.914869, val:  67.50%, val_best:  70.00%, tr:  86.62%, tr_best:  86.82%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.549756/  3.002241, val:  65.00%, val_best:  70.00%, tr:  85.29%, tr_best:  86.82%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.574907/  3.082034, val:  63.75%, val_best:  70.00%, tr:  83.96%, tr_best:  86.82%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.603874/  3.012792, val:  69.17%, val_best:  70.00%, tr:  84.68%, tr_best:  86.82%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.627595/  2.988839, val:  67.50%, val_best:  70.00%, tr:  83.15%, tr_best:  86.82%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.582574/  3.028387, val:  70.83%, val_best:  70.83%, tr:  86.52%, tr_best:  86.82%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.576972/  3.139945, val:  69.17%, val_best:  70.83%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.619009/  3.121417, val:  71.25%, val_best:  71.25%, tr:  86.41%, tr_best:  87.74%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.638952/  3.232161, val:  67.50%, val_best:  71.25%, tr:  85.90%, tr_best:  87.74%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.609714/  3.255276, val:  68.75%, val_best:  71.25%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.649583/  3.233428, val:  71.25%, val_best:  71.25%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.628333/  3.287552, val:  66.67%, val_best:  71.25%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.645252/  3.373320, val:  70.00%, val_best:  71.25%, tr:  88.87%, tr_best:  89.68%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.661843/  3.407024, val:  70.42%, val_best:  71.25%, tr:  88.15%, tr_best:  89.68%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.670887/  3.443332, val:  68.75%, val_best:  71.25%, tr:  88.46%, tr_best:  89.68%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.644925/  3.502590, val:  67.92%, val_best:  71.25%, tr:  89.48%, tr_best:  89.68%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.701753/  3.432389, val:  70.42%, val_best:  71.25%, tr:  89.48%, tr_best:  89.68%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.688900/  3.489356, val:  66.67%, val_best:  71.25%, tr:  87.03%, tr_best:  89.68%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.686704/  3.634516, val:  68.75%, val_best:  71.25%, tr:  88.15%, tr_best:  89.68%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.731330/  3.596739, val:  68.75%, val_best:  71.25%, tr:  88.46%, tr_best:  89.68%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.739369/  3.673677, val:  67.92%, val_best:  71.25%, tr:  89.07%, tr_best:  89.68%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.731380/  3.742771, val:  68.75%, val_best:  71.25%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.735975/  3.922603, val:  66.25%, val_best:  71.25%, tr:  88.87%, tr_best:  89.68%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.781478/  3.738813, val:  67.92%, val_best:  71.25%, tr:  86.11%, tr_best:  89.68%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.781159/  3.806236, val:  67.08%, val_best:  71.25%, tr:  88.15%, tr_best:  89.68%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.781383/  3.833534, val:  64.58%, val_best:  71.25%, tr:  88.05%, tr_best:  89.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7c97f4701d4d64ab241be4a5e730a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▅▄▄▆▃▅▆▅█▇▆▆▇█▆▇▇▇▇▆██▇█▇█▇▇▇▆▇▇▆▅▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇███▇▇▇█▇▇▇█▇▇█████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇███▇▇▇█▇▇▇█▇▇█████████</td></tr><tr><td>val_loss</td><td>▃▃▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.88049</td></tr><tr><td>tr_epoch_loss</td><td>1.78138</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.64583</td></tr><tr><td>val_loss</td><td>3.83353</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-167</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/he0catwh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/he0catwh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_040044-he0catwh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y4jrszim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_040739-y4jrszim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y4jrszim' target=\"_blank\">olive-sweep-169</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y4jrszim' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y4jrszim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.170330/  2.925608, val:  46.25%, val_best:  46.25%, tr:  32.48%, tr_best:  32.48%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.501762/  3.771071, val:  45.42%, val_best:  46.25%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.057720/  3.342115, val:  49.58%, val_best:  49.58%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.347908/  3.532340, val:  49.17%, val_best:  49.58%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.190383/  3.119938, val:  58.33%, val_best:  58.33%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.309960/  3.836203, val:  44.58%, val_best:  58.33%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.344152/  3.805277, val:  60.00%, val_best:  60.00%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.592000/  3.714749, val:  51.25%, val_best:  60.00%, tr:  64.45%, tr_best:  67.21%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.059478/  3.059596, val:  53.75%, val_best:  60.00%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.460022/  3.840724, val:  58.75%, val_best:  60.00%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  2.067660/  2.960407, val:  59.17%, val_best:  60.00%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  2.042217/  3.616059, val:  61.25%, val_best:  61.25%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  2.246590/  2.779495, val:  69.17%, val_best:  69.17%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.576627/  3.848621, val:  57.08%, val_best:  69.17%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  1.747302/  3.330912, val:  64.58%, val_best:  69.17%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  1.522660/  3.551427, val:  60.42%, val_best:  69.17%, tr:  81.21%, tr_best:  81.21%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  1.516389/  3.547489, val:  63.75%, val_best:  69.17%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  1.402305/  4.003067, val:  62.50%, val_best:  69.17%, tr:  85.70%, tr_best:  85.70%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  1.329067/  4.008951, val:  62.50%, val_best:  69.17%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  1.041583/  3.764840, val:  63.75%, val_best:  69.17%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  1.817243/  3.915733, val:  68.33%, val_best:  69.17%, tr:  85.50%, tr_best:  91.42%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  1.421451/  5.890642, val:  58.33%, val_best:  69.17%, tr:  85.29%, tr_best:  91.42%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  1.284890/  4.270765, val:  67.08%, val_best:  69.17%, tr:  89.89%, tr_best:  91.42%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  1.121703/  4.585346, val:  64.58%, val_best:  69.17%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  1.138166/  4.933407, val:  67.50%, val_best:  69.17%, tr:  92.95%, tr_best:  93.05%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  1.193980/  4.535292, val:  68.75%, val_best:  69.17%, tr:  91.73%, tr_best:  93.05%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  1.062680/  4.704195, val:  67.92%, val_best:  69.17%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  1.011097/  4.732346, val:  69.17%, val_best:  69.17%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  1.213348/  4.869172, val:  71.67%, val_best:  71.67%, tr:  92.75%, tr_best:  93.87%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.998304/  5.225735, val:  68.33%, val_best:  71.67%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.881681/  4.954787, val:  69.58%, val_best:  71.67%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.913221/  5.442165, val:  66.67%, val_best:  71.67%, tr:  95.81%, tr_best:  96.53%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.905491/  6.049129, val:  65.00%, val_best:  71.67%, tr:  96.32%, tr_best:  96.53%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  1.056813/  6.460462, val:  65.00%, val_best:  71.67%, tr:  93.77%, tr_best:  96.53%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.997937/  5.747472, val:  68.75%, val_best:  71.67%, tr:  95.61%, tr_best:  96.53%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.816471/  6.341067, val:  65.00%, val_best:  71.67%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.729958/  6.051116, val:  71.25%, val_best:  71.67%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.924323/  6.571939, val:  68.75%, val_best:  71.67%, tr:  96.94%, tr_best:  98.98%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.819589/  7.042242, val:  68.33%, val_best:  71.67%, tr:  97.96%, tr_best:  98.98%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.934120/  6.483194, val:  70.00%, val_best:  71.67%, tr:  97.04%, tr_best:  98.98%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  1.006073/  6.536671, val:  70.00%, val_best:  71.67%, tr:  95.81%, tr_best:  98.98%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.756202/  6.642794, val:  70.83%, val_best:  71.67%, tr:  98.26%, tr_best:  98.98%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.737387/  6.673036, val:  72.92%, val_best:  72.92%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.772453/  7.135272, val:  68.33%, val_best:  72.92%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.862036/  7.319224, val:  70.00%, val_best:  72.92%, tr:  96.83%, tr_best:  98.98%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.789748/  7.333279, val:  69.58%, val_best:  72.92%, tr:  98.26%, tr_best:  98.98%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.779366/  7.713172, val:  67.92%, val_best:  72.92%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.808804/  7.614387, val:  74.17%, val_best:  74.17%, tr:  98.37%, tr_best:  99.18%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  1.001706/  7.773737, val:  72.50%, val_best:  74.17%, tr:  97.04%, tr_best:  99.18%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.824883/  7.585585, val:  75.83%, val_best:  75.83%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.704025/  8.289359, val:  66.67%, val_best:  75.83%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.893840/  8.002738, val:  72.92%, val_best:  75.83%, tr:  97.85%, tr_best:  99.18%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.669222/  8.289675, val:  68.75%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.822729/  8.646371, val:  67.50%, val_best:  75.83%, tr:  98.77%, tr_best:  99.90%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.998267/  8.896778, val:  70.42%, val_best:  75.83%, tr:  98.06%, tr_best:  99.90%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.849333/  9.197827, val:  72.50%, val_best:  75.83%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.799656/  9.089681, val:  70.83%, val_best:  75.83%, tr:  98.88%, tr_best:  99.90%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.756961/  8.679712, val:  71.67%, val_best:  75.83%, tr:  98.57%, tr_best:  99.90%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.713454/  9.543543, val:  69.58%, val_best:  75.83%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.980611/  9.092491, val:  73.33%, val_best:  75.83%, tr:  97.55%, tr_best:  99.90%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.733548/  9.142233, val:  72.08%, val_best:  75.83%, tr:  98.77%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.739362/ 10.052552, val:  70.00%, val_best:  75.83%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.784339/ 10.015778, val:  70.42%, val_best:  75.83%, tr:  98.77%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.690962/ 10.052180, val:  72.92%, val_best:  75.83%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.689517/  9.754586, val:  75.00%, val_best:  75.83%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.597550/ 10.241829, val:  72.50%, val_best:  75.83%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.604733/ 10.412066, val:  73.75%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.615313/ 10.296650, val:  75.00%, val_best:  75.83%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.749562/ 10.911889, val:  70.42%, val_best:  75.83%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.705378/ 11.082677, val:  69.17%, val_best:  75.83%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.684731/ 11.316739, val:  70.83%, val_best:  75.83%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.771979/ 11.178895, val:  72.92%, val_best:  75.83%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.718486/ 11.743539, val:  70.83%, val_best:  75.83%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.662229/ 11.752463, val:  69.17%, val_best:  75.83%, tr:  99.18%, tr_best:  99.90%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.724768/ 11.626212, val:  73.33%, val_best:  75.83%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.649222/ 11.972357, val:  73.75%, val_best:  75.83%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.736497/ 11.899567, val:  74.17%, val_best:  75.83%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.736610/ 11.758979, val:  72.92%, val_best:  75.83%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.616684/ 12.506046, val:  68.75%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.660433/ 12.198030, val:  74.58%, val_best:  75.83%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.687989/ 12.326988, val:  75.83%, val_best:  75.83%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.599982/ 12.131748, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.660774/ 12.556686, val:  73.75%, val_best:  75.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.816780/ 13.156972, val:  70.00%, val_best:  75.83%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.654799/ 12.573656, val:  70.00%, val_best:  75.83%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.587045/ 12.839304, val:  74.17%, val_best:  75.83%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.591993/ 13.140508, val:  71.67%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.674163/ 13.336426, val:  75.00%, val_best:  75.83%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.565297/ 13.107656, val:  77.08%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.551515/ 13.593313, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.561415/ 13.655969, val:  74.58%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.565766/ 13.847641, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.490633/ 13.855359, val:  72.50%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.575796/ 14.016898, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.613286/ 14.645682, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.701310/ 14.709033, val:  71.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.842818/ 14.721840, val:  76.67%, val_best:  77.08%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.673719/ 15.310431, val:  73.33%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.634604/ 15.293712, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.757596/ 15.461773, val:  73.75%, val_best:  77.08%, tr:  99.59%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd17f867a36c4e3a98101214d3a903f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▄▅▄▇▇▅██▇▇▇██▇████████████▇██████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▂▄▆▅▅▅▄▆▆▆▅▅▆▇▇▇██▆▇▇▇▇▇█▇▇█▇██▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▄▅▅▆▇▇▆▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆█▆▇▆▆▄▃▃▄▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▂▁▂▁▁▁▂▁▁▂▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▂▄▆▅▅▅▄▆▆▆▅▅▆▇▇▇██▆▇▇▇▇▇█▇▇█▇██▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▁▁▂▂▃▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99591</td></tr><tr><td>tr_epoch_loss</td><td>0.7576</td></tr><tr><td>val_acc_best</td><td>0.77083</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>15.46177</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-169</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y4jrszim' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y4jrszim</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_040739-y4jrszim/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h0dil84u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_041437-h0dil84u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h0dil84u' target=\"_blank\">lilac-sweep-171</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h0dil84u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h0dil84u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.521025/  2.623674, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  2.493251/  2.401668, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  10.11%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  2.471030/  2.441476, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.11%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  2.438038/  2.464993, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  2.435606/  2.453039, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  2.476113/  2.438021, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  2.473328/  2.466004, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  2.467133/  2.461899, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.11%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  2.441164/  2.368249, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  2.425792/  2.485260, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  2.458742/  2.376372, val:  10.00%, val_best:  10.00%, tr:  10.62%, tr_best:  10.62%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  2.451229/  2.414626, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  10.62%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  2.431249/  2.397279, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.62%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  2.449168/  2.426764, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.62%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  2.429092/  2.594516, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.62%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  2.468597/  2.423184, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.62%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  2.495309/  2.347171, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.62%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  2.464427/  2.479951, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.62%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  2.455464/  2.348071, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.62%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  2.458870/  2.634810, val:  10.00%, val_best:  10.00%, tr:  12.16%, tr_best:  12.16%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  2.532136/  2.630572, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  12.16%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  2.469809/  2.483881, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  2.461555/  2.482759, val:  10.00%, val_best:  10.00%, tr:  10.93%, tr_best:  12.16%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  2.477140/  2.466634, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  12.16%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  2.456871/  2.388859, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  2.456265/  2.433586, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  12.16%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  2.501490/  2.344921, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  12.16%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  2.454522/  2.404290, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  12.16%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  2.434424/  2.400815, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  12.16%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  2.412901/  2.418111, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  12.16%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  2.445441/  2.436164, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  12.16%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  2.433619/  2.442688, val:  10.00%, val_best:  10.00%, tr:  11.03%, tr_best:  12.16%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  2.522616/  2.481343, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  12.16%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  2.509247/  2.416504, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  2.487263/  2.553780, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  12.16%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  2.492729/  2.449025, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  12.16%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  2.446717/  2.395209, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  2.473824/  2.632330, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  12.16%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  2.493902/  2.432965, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  2.467361/  2.406721, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  12.16%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  2.513397/  2.540425, val:  10.00%, val_best:  10.00%, tr:  10.52%, tr_best:  12.16%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  2.518451/  2.505286, val:  10.00%, val_best:  10.00%, tr:  11.03%, tr_best:  12.16%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  2.514067/  2.395865, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  12.16%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  2.499207/  2.696059, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  12.16%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  2.522714/  2.515920, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  12.16%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  2.478578/  2.442224, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  12.16%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  2.504034/  2.360473, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  12.16%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  2.447176/  2.486052, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  12.16%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  2.491940/  2.418895, val:  10.00%, val_best:  10.00%, tr:   7.56%, tr_best:  12.16%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  2.443237/  2.339746, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  2.434119/  2.539275, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  12.16%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  2.478645/  2.349289, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  12.16%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  2.445746/  2.427385, val:  10.00%, val_best:  10.00%, tr:  10.73%, tr_best:  12.16%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  2.430613/  2.369613, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  12.16%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  2.454437/  2.403330, val:  10.00%, val_best:  10.00%, tr:  10.93%, tr_best:  12.16%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  2.488044/  2.367314, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  12.16%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  2.432323/  2.550211, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  12.16%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  2.514803/  2.424870, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:  12.16%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  2.499758/  2.403315, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  12.16%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  2.465906/  2.430620, val:  10.00%, val_best:  10.00%, tr:  10.62%, tr_best:  12.16%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  2.475043/  2.453509, val:  10.00%, val_best:  10.00%, tr:  10.52%, tr_best:  12.16%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  2.549381/  2.397437, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  12.16%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  2.499790/  2.493794, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  2.446735/  2.381926, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  12.16%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  2.424499/  2.391928, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  12.16%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  2.439331/  2.378643, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  12.16%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  2.469206/  2.384904, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  12.16%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  2.469288/  2.343184, val:  10.00%, val_best:  10.00%, tr:  10.83%, tr_best:  12.16%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  2.409304/  2.465325, val:  10.00%, val_best:  10.00%, tr:  11.13%, tr_best:  12.16%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  2.487381/  2.429583, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  12.16%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  2.452406/  2.391922, val:  10.00%, val_best:  10.00%, tr:  10.62%, tr_best:  12.16%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  2.482408/  2.467104, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  12.16%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  2.527320/  2.480932, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  2.479205/  2.480726, val:  10.00%, val_best:  10.00%, tr:  10.83%, tr_best:  12.16%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  2.477507/  2.345716, val:  10.00%, val_best:  10.00%, tr:  11.03%, tr_best:  12.16%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  2.493409/  2.556630, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  2.454170/  2.432463, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  12.16%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  2.490857/  2.434645, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  12.16%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  2.463014/  2.595895, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  12.16%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  2.508440/  2.478057, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  12.16%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  2.421750/  2.417755, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  12.16%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  2.482896/  2.511716, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  12.16%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  2.528684/  2.642655, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  2.477893/  2.486252, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  2.489694/  2.640080, val:  10.00%, val_best:  10.00%, tr:  10.52%, tr_best:  12.16%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  2.458414/  2.434928, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  12.16%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  2.435616/  2.556397, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  12.16%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  2.441567/  2.417959, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  12.16%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  2.466650/  2.553967, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  12.16%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  2.461328/  2.407372, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  12.16%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  2.459862/  2.420143, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  12.16%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  2.478359/  2.570884, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  12.16%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  2.444057/  2.349605, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  12.16%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  2.427895/  2.393444, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  12.16%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  2.470145/  2.520800, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  12.16%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  2.432628/  2.381572, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  12.16%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  2.468352/  2.435434, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  12.16%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  2.457888/  2.466409, val:  10.00%, val_best:  10.00%, tr:  11.44%, tr_best:  12.16%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  2.474241/  2.495883, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  12.16%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  2.501154/  2.424966, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  12.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df46000980ff4494bc4fe4c00b8fe9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▅▅▂▂█▁▄▄▂▆▄▁▅▂▂▅▆▆▂▄▅▂▄▂▅▂▁▂▄▅▄▄▂▆▂▁▁▁█▂</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▅▃▄▄▄▄▅▃█▃▅▄▄▂▅▄▃▄▂▄▃▆▆▁▆▅▃▆▆▅▃▅▄▃▆▅▅▃▃▇</td></tr><tr><td>tr_epoch_loss</td><td>▇▄▂▄▂▂▂▄▃▄▃▆▁▇▅▄▄▆▇▃▃▃▃▆▄█▂▄▃▇▅▅▆▇▅▂▃▃▂▃</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▄▄▄▂▇▄█▄▂▁▃▄▄█▃▂▅▄▁▃▂▃▃▂▂▁▂▄▆▃▄██▃▃▁▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09806</td></tr><tr><td>tr_epoch_loss</td><td>2.50115</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.42497</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-sweep-171</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h0dil84u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h0dil84u</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_041437-h0dil84u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: obqkdvwd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd856e05a8e4bb3882b82e46edfdc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113166343420744, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_042048-obqkdvwd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obqkdvwd' target=\"_blank\">distinctive-sweep-173</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obqkdvwd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obqkdvwd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.018195/  1.654364, val:  46.25%, val_best:  46.25%, tr:  28.09%, tr_best:  28.09%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.311398/  1.533616, val:  52.08%, val_best:  52.08%, tr:  54.44%, tr_best:  54.44%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.189469/  1.449419, val:  57.08%, val_best:  57.08%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.946961/  1.454277, val:  53.75%, val_best:  57.08%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.879553/  1.473036, val:  55.83%, val_best:  57.08%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.839958/  1.713196, val:  47.08%, val_best:  57.08%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.739053/  1.333846, val:  58.75%, val_best:  58.75%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.673827/  1.458598, val:  60.83%, val_best:  60.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.763666/  1.464498, val:  62.92%, val_best:  62.92%, tr:  73.54%, tr_best:  77.22%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.622556/  1.511910, val:  63.33%, val_best:  63.33%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.561590/  1.572830, val:  59.17%, val_best:  63.33%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.596909/  1.407848, val:  69.17%, val_best:  69.17%, tr:  79.57%, tr_best:  80.80%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.515136/  1.468037, val:  66.67%, val_best:  69.17%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.592805/  1.563921, val:  64.58%, val_best:  69.17%, tr:  83.15%, tr_best:  84.88%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.605425/  1.766476, val:  60.42%, val_best:  69.17%, tr:  84.17%, tr_best:  84.88%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.511615/  1.743498, val:  58.75%, val_best:  69.17%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.509477/  1.568308, val:  71.67%, val_best:  71.67%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.495553/  1.657485, val:  67.50%, val_best:  71.67%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.514040/  1.962200, val:  59.17%, val_best:  71.67%, tr:  86.72%, tr_best:  89.38%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.528324/  1.744067, val:  65.00%, val_best:  71.67%, tr:  85.29%, tr_best:  89.38%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.517609/  2.016747, val:  61.67%, val_best:  71.67%, tr:  87.74%, tr_best:  89.38%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.492153/  1.955298, val:  60.42%, val_best:  71.67%, tr:  88.66%, tr_best:  89.38%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.449735/  1.716003, val:  69.17%, val_best:  71.67%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.409610/  1.891823, val:  70.00%, val_best:  71.67%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.339448/  1.824354, val:  74.17%, val_best:  74.17%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.362388/  1.861882, val:  70.00%, val_best:  74.17%, tr:  93.87%, tr_best:  93.97%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.421844/  1.855121, val:  72.50%, val_best:  74.17%, tr:  92.24%, tr_best:  93.97%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.465909/  2.264741, val:  63.33%, val_best:  74.17%, tr:  92.34%, tr_best:  93.97%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.495490/  1.948435, val:  71.67%, val_best:  74.17%, tr:  91.22%, tr_best:  93.97%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.447108/  2.119026, val:  63.33%, val_best:  74.17%, tr:  93.87%, tr_best:  93.97%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.472640/  2.202501, val:  67.08%, val_best:  74.17%, tr:  92.34%, tr_best:  93.97%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.512546/  2.390023, val:  61.67%, val_best:  74.17%, tr:  91.52%, tr_best:  93.97%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.553492/  2.064005, val:  70.42%, val_best:  74.17%, tr:  89.79%, tr_best:  93.97%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.506128/  2.019606, val:  70.83%, val_best:  74.17%, tr:  92.44%, tr_best:  93.97%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.443665/  2.553336, val:  65.42%, val_best:  74.17%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.496177/  2.413510, val:  64.17%, val_best:  74.17%, tr:  91.52%, tr_best:  94.38%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.437392/  2.457640, val:  70.00%, val_best:  74.17%, tr:  93.67%, tr_best:  94.38%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.468745/  2.548547, val:  60.42%, val_best:  74.17%, tr:  93.67%, tr_best:  94.38%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.443558/  2.064203, val:  72.92%, val_best:  74.17%, tr:  92.85%, tr_best:  94.38%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.415148/  2.083177, val:  70.00%, val_best:  74.17%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.404536/  2.559175, val:  66.25%, val_best:  74.17%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.423753/  2.754531, val:  63.33%, val_best:  74.17%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.486907/  2.704069, val:  60.83%, val_best:  74.17%, tr:  94.08%, tr_best:  95.61%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.488159/  2.665060, val:  61.67%, val_best:  74.17%, tr:  91.93%, tr_best:  95.61%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.561283/  2.614566, val:  62.92%, val_best:  74.17%, tr:  92.24%, tr_best:  95.61%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.496691/  2.346451, val:  67.92%, val_best:  74.17%, tr:  94.28%, tr_best:  95.61%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.498121/  2.626222, val:  65.42%, val_best:  74.17%, tr:  93.87%, tr_best:  95.61%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.459300/  2.407516, val:  67.92%, val_best:  74.17%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.504871/  2.295665, val:  64.17%, val_best:  74.17%, tr:  93.67%, tr_best:  95.91%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.530384/  2.305112, val:  65.42%, val_best:  74.17%, tr:  93.77%, tr_best:  95.91%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.570973/  2.470430, val:  70.83%, val_best:  74.17%, tr:  93.05%, tr_best:  95.91%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.626559/  2.320313, val:  69.58%, val_best:  74.17%, tr:  91.52%, tr_best:  95.91%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.590476/  1.962200, val:  70.00%, val_best:  74.17%, tr:  91.83%, tr_best:  95.91%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.566359/  2.173732, val:  69.17%, val_best:  74.17%, tr:  93.46%, tr_best:  95.91%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.550745/  2.386848, val:  65.00%, val_best:  74.17%, tr:  93.05%, tr_best:  95.91%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.600394/  2.259999, val:  64.17%, val_best:  74.17%, tr:  92.85%, tr_best:  95.91%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.595106/  2.156847, val:  67.92%, val_best:  74.17%, tr:  91.01%, tr_best:  95.91%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.643005/  2.273146, val:  65.42%, val_best:  74.17%, tr:  90.70%, tr_best:  95.91%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.611486/  2.239813, val:  69.17%, val_best:  74.17%, tr:  92.24%, tr_best:  95.91%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.584978/  2.346515, val:  66.67%, val_best:  74.17%, tr:  92.65%, tr_best:  95.91%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.555967/  2.124213, val:  66.67%, val_best:  74.17%, tr:  94.28%, tr_best:  95.91%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.554290/  2.200666, val:  66.25%, val_best:  74.17%, tr:  93.26%, tr_best:  95.91%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.460449/  2.407516, val:  63.33%, val_best:  74.17%, tr:  94.28%, tr_best:  95.91%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.434238/  2.293506, val:  71.67%, val_best:  74.17%, tr:  95.71%, tr_best:  95.91%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.470641/  2.770988, val:  62.92%, val_best:  74.17%, tr:  93.56%, tr_best:  95.91%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.598837/  2.564299, val:  65.42%, val_best:  74.17%, tr:  91.93%, tr_best:  95.91%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.538889/  2.711089, val:  60.83%, val_best:  74.17%, tr:  94.38%, tr_best:  95.91%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.632383/  2.599088, val:  67.08%, val_best:  74.17%, tr:  92.75%, tr_best:  95.91%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.743738/  2.665418, val:  64.17%, val_best:  74.17%, tr:  91.42%, tr_best:  95.91%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.800905/  2.726923, val:  62.50%, val_best:  74.17%, tr:  86.52%, tr_best:  95.91%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.811373/  2.741111, val:  61.25%, val_best:  74.17%, tr:  89.79%, tr_best:  95.91%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.688982/  2.289099, val:  67.50%, val_best:  74.17%, tr:  91.11%, tr_best:  95.91%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.699593/  2.730890, val:  65.00%, val_best:  74.17%, tr:  91.93%, tr_best:  95.91%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.658990/  2.390004, val:  65.83%, val_best:  74.17%, tr:  92.24%, tr_best:  95.91%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.573207/  2.432370, val:  67.08%, val_best:  74.17%, tr:  93.67%, tr_best:  95.91%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.605596/  2.460289, val:  63.75%, val_best:  74.17%, tr:  93.46%, tr_best:  95.91%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.639032/  2.399309, val:  62.50%, val_best:  74.17%, tr:  90.50%, tr_best:  95.91%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.665033/  2.350417, val:  66.25%, val_best:  74.17%, tr:  91.32%, tr_best:  95.91%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.653959/  2.429188, val:  62.50%, val_best:  74.17%, tr:  90.70%, tr_best:  95.91%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.564078/  2.533648, val:  69.17%, val_best:  74.17%, tr:  93.97%, tr_best:  95.91%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.613514/  2.721154, val:  63.33%, val_best:  74.17%, tr:  91.93%, tr_best:  95.91%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.653464/  2.675758, val:  65.00%, val_best:  74.17%, tr:  91.73%, tr_best:  95.91%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.640807/  2.637326, val:  69.17%, val_best:  74.17%, tr:  92.24%, tr_best:  95.91%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.732226/  2.816515, val:  62.50%, val_best:  74.17%, tr:  90.30%, tr_best:  95.91%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.638111/  2.759261, val:  67.08%, val_best:  74.17%, tr:  91.22%, tr_best:  95.91%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.607110/  2.929047, val:  65.00%, val_best:  74.17%, tr:  92.85%, tr_best:  95.91%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.711734/  2.360057, val:  64.17%, val_best:  74.17%, tr:  88.36%, tr_best:  95.91%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.678677/  2.412178, val:  66.25%, val_best:  74.17%, tr:  88.36%, tr_best:  95.91%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.669995/  2.562583, val:  65.42%, val_best:  74.17%, tr:  91.73%, tr_best:  95.91%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.619360/  2.661510, val:  66.67%, val_best:  74.17%, tr:  92.13%, tr_best:  95.91%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.620122/  2.478945, val:  66.25%, val_best:  74.17%, tr:  91.52%, tr_best:  95.91%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.585106/  2.554719, val:  65.00%, val_best:  74.17%, tr:  91.83%, tr_best:  95.91%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.619091/  2.614818, val:  67.50%, val_best:  74.17%, tr:  91.52%, tr_best:  95.91%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.544684/  2.394050, val:  70.00%, val_best:  74.17%, tr:  93.26%, tr_best:  95.91%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.507013/  2.462267, val:  72.08%, val_best:  74.17%, tr:  95.71%, tr_best:  95.91%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.522587/  2.745824, val:  65.00%, val_best:  74.17%, tr:  95.40%, tr_best:  95.91%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.554428/  2.469487, val:  65.00%, val_best:  74.17%, tr:  94.89%, tr_best:  95.91%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.610627/  2.629034, val:  67.08%, val_best:  74.17%, tr:  92.44%, tr_best:  95.91%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.615730/  2.692667, val:  66.25%, val_best:  74.17%, tr:  93.05%, tr_best:  95.91%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.643775/  2.712689, val:  65.83%, val_best:  74.17%, tr:  93.46%, tr_best:  95.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c2aa4e7f4945bcb5795dd0060fecaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▅▅▇▃▇▇██▇▆▆▇▇▇█▅▇▇▇▇▇█▇▇▇▇▅▇▅▆▇▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▄▃▅▅▆▅▆▆▅██▅▇▅▅▇▅▅▆▆▇▆▆▆▆▆▆▅▆▅▆▇▇▆▆▆▆▆▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇▇▇███▇█████████▇████▇██████▇████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▃▂▂▂▂▂▂▂▁▁▁▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▅▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▃▅▅▆▅▆▆▅██▅▇▅▅▇▅▅▆▆▇▆▆▆▆▆▆▅▆▅▆▇▇▆▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▃▂▃▄▃▃▅▄▆▇▄█▇▆▆▄▆▅▆▅▇▇██▆▆▇▇█▆▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.93463</td></tr><tr><td>tr_epoch_loss</td><td>0.64377</td></tr><tr><td>val_acc_best</td><td>0.74167</td></tr><tr><td>val_acc_now</td><td>0.65833</td></tr><tr><td>val_loss</td><td>2.71269</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-173</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obqkdvwd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/obqkdvwd</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_042048-obqkdvwd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3jsmzvff with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_042701-3jsmzvff</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3jsmzvff' target=\"_blank\">fanciful-sweep-175</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3jsmzvff' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3jsmzvff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.285162/  2.246997, val:  22.92%, val_best:  22.92%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.194879/  2.158071, val:  31.25%, val_best:  31.25%, tr:  25.23%, tr_best:  25.23%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.058222/  2.027631, val:  46.25%, val_best:  46.25%, tr:  34.22%, tr_best:  34.22%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.892397/  1.895572, val:  45.83%, val_best:  46.25%, tr:  43.31%, tr_best:  43.31%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.736376/  1.784785, val:  49.58%, val_best:  49.58%, tr:  48.62%, tr_best:  48.62%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.602388/  1.693480, val:  52.50%, val_best:  52.50%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.515977/  1.636335, val:  51.25%, val_best:  52.50%, tr:  55.67%, tr_best:  55.67%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.443774/  1.579062, val:  52.08%, val_best:  52.50%, tr:  58.43%, tr_best:  58.43%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.388473/  1.546263, val:  58.75%, val_best:  58.75%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.344815/  1.521111, val:  53.33%, val_best:  58.75%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.307049/  1.492817, val:  55.83%, val_best:  58.75%, tr:  61.08%, tr_best:  61.49%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.272731/  1.469022, val:  57.92%, val_best:  58.75%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.258018/  1.451022, val:  54.58%, val_best:  58.75%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.233566/  1.438328, val:  56.67%, val_best:  58.75%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.193966/  1.431025, val:  55.00%, val_best:  58.75%, tr:  64.66%, tr_best:  65.27%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.180924/  1.417508, val:  57.50%, val_best:  58.75%, tr:  64.15%, tr_best:  65.27%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.156110/  1.403341, val:  55.00%, val_best:  58.75%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.134611/  1.375010, val:  58.75%, val_best:  58.75%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.117950/  1.380535, val:  57.50%, val_best:  58.75%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.107544/  1.371753, val:  56.25%, val_best:  58.75%, tr:  65.37%, tr_best:  67.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.081598/  1.358347, val:  58.33%, val_best:  58.75%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.068302/  1.348091, val:  62.50%, val_best:  62.50%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.066151/  1.353974, val:  58.33%, val_best:  62.50%, tr:  66.39%, tr_best:  69.66%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.042111/  1.341249, val:  61.25%, val_best:  62.50%, tr:  69.25%, tr_best:  69.66%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.020808/  1.323961, val:  61.25%, val_best:  62.50%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.010414/  1.323007, val:  60.00%, val_best:  62.50%, tr:  71.50%, tr_best:  72.01%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.001524/  1.294533, val:  63.33%, val_best:  63.33%, tr:  70.99%, tr_best:  72.01%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.985251/  1.309709, val:  58.75%, val_best:  63.33%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.979259/  1.294789, val:  60.00%, val_best:  63.33%, tr:  73.24%, tr_best:  74.26%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.964533/  1.289025, val:  60.00%, val_best:  63.33%, tr:  73.95%, tr_best:  74.26%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.955157/  1.279537, val:  61.25%, val_best:  63.33%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.946000/  1.293662, val:  61.25%, val_best:  63.33%, tr:  74.16%, tr_best:  74.57%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.932004/  1.306781, val:  61.67%, val_best:  63.33%, tr:  76.30%, tr_best:  76.30%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.924869/  1.293976, val:  63.75%, val_best:  63.75%, tr:  76.20%, tr_best:  76.30%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.916668/  1.267001, val:  64.58%, val_best:  64.58%, tr:  76.20%, tr_best:  76.30%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.906489/  1.280384, val:  60.00%, val_best:  64.58%, tr:  75.79%, tr_best:  76.30%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.898783/  1.274122, val:  59.17%, val_best:  64.58%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.892515/  1.256926, val:  67.08%, val_best:  67.08%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.885288/  1.251080, val:  65.42%, val_best:  67.08%, tr:  79.57%, tr_best:  79.57%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.875862/  1.246953, val:  66.67%, val_best:  67.08%, tr:  78.75%, tr_best:  79.57%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.860077/  1.253816, val:  66.25%, val_best:  67.08%, tr:  77.73%, tr_best:  79.57%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.865173/  1.246533, val:  65.00%, val_best:  67.08%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.847321/  1.251267, val:  62.92%, val_best:  67.08%, tr:  80.49%, tr_best:  80.69%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.842709/  1.258154, val:  65.42%, val_best:  67.08%, tr:  80.90%, tr_best:  80.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.840348/  1.245816, val:  67.08%, val_best:  67.08%, tr:  77.53%, tr_best:  80.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.825578/  1.239936, val:  66.67%, val_best:  67.08%, tr:  80.49%, tr_best:  80.90%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.820034/  1.250315, val:  65.00%, val_best:  67.08%, tr:  80.18%, tr_best:  80.90%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.818604/  1.249998, val:  64.17%, val_best:  67.08%, tr:  80.18%, tr_best:  80.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.811683/  1.235168, val:  66.25%, val_best:  67.08%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.809864/  1.231004, val:  66.25%, val_best:  67.08%, tr:  79.16%, tr_best:  82.43%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.791285/  1.252541, val:  65.00%, val_best:  67.08%, tr:  82.23%, tr_best:  82.43%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.785997/  1.251140, val:  69.17%, val_best:  69.17%, tr:  81.72%, tr_best:  82.43%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.793629/  1.263866, val:  61.25%, val_best:  69.17%, tr:  80.59%, tr_best:  82.43%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.780776/  1.246045, val:  67.92%, val_best:  69.17%, tr:  81.82%, tr_best:  82.43%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.775024/  1.259491, val:  67.92%, val_best:  69.17%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.768174/  1.255573, val:  69.58%, val_best:  69.58%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.752876/  1.267409, val:  68.75%, val_best:  69.58%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.753970/  1.253390, val:  66.67%, val_best:  69.58%, tr:  84.88%, tr_best:  86.11%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.740971/  1.276602, val:  64.17%, val_best:  69.58%, tr:  83.66%, tr_best:  86.11%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.745032/  1.253611, val:  70.00%, val_best:  70.00%, tr:  83.55%, tr_best:  86.11%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.737400/  1.249627, val:  69.17%, val_best:  70.00%, tr:  82.84%, tr_best:  86.11%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.735608/  1.267719, val:  66.25%, val_best:  70.00%, tr:  85.80%, tr_best:  86.11%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.727953/  1.262802, val:  65.00%, val_best:  70.00%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.720249/  1.259190, val:  66.67%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.711095/  1.289083, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.710960/  1.276661, val:  68.75%, val_best:  70.00%, tr:  86.41%, tr_best:  87.74%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.709253/  1.253702, val:  72.92%, val_best:  72.92%, tr:  86.82%, tr_best:  87.74%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.710972/  1.284143, val:  67.50%, val_best:  72.92%, tr:  87.64%, tr_best:  87.74%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.695192/  1.283617, val:  66.25%, val_best:  72.92%, tr:  85.19%, tr_best:  87.74%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.687996/  1.289404, val:  68.75%, val_best:  72.92%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.682339/  1.285546, val:  68.33%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.672306/  1.320168, val:  63.75%, val_best:  72.92%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.670199/  1.314962, val:  64.17%, val_best:  72.92%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.680731/  1.297450, val:  66.67%, val_best:  72.92%, tr:  89.07%, tr_best:  89.17%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.660733/  1.296611, val:  67.92%, val_best:  72.92%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.667978/  1.281122, val:  69.17%, val_best:  72.92%, tr:  87.74%, tr_best:  89.27%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.647320/  1.299213, val:  68.75%, val_best:  72.92%, tr:  88.46%, tr_best:  89.27%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.664804/  1.306831, val:  67.08%, val_best:  72.92%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.656877/  1.288231, val:  70.83%, val_best:  72.92%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.643267/  1.294443, val:  66.25%, val_best:  72.92%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.633116/  1.315517, val:  66.25%, val_best:  72.92%, tr:  90.91%, tr_best:  91.01%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.642006/  1.296139, val:  67.08%, val_best:  72.92%, tr:  88.97%, tr_best:  91.01%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.630239/  1.316738, val:  69.17%, val_best:  72.92%, tr:  90.30%, tr_best:  91.01%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.630062/  1.321607, val:  70.42%, val_best:  72.92%, tr:  90.91%, tr_best:  91.01%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.621428/  1.305100, val:  67.08%, val_best:  72.92%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.617052/  1.328486, val:  67.92%, val_best:  72.92%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.616524/  1.313845, val:  70.83%, val_best:  72.92%, tr:  91.73%, tr_best:  92.44%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.610247/  1.314419, val:  70.00%, val_best:  72.92%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.599308/  1.327938, val:  65.83%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.592963/  1.348696, val:  65.00%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.604122/  1.302993, val:  70.83%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.590591/  1.321245, val:  69.58%, val_best:  72.92%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.595547/  1.374575, val:  66.25%, val_best:  72.92%, tr:  91.52%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.595471/  1.346859, val:  67.08%, val_best:  72.92%, tr:  92.03%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.588534/  1.365387, val:  65.83%, val_best:  72.92%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.582649/  1.358145, val:  66.67%, val_best:  72.92%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.582228/  1.371293, val:  68.33%, val_best:  72.92%, tr:  93.05%, tr_best:  93.46%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.583159/  1.341817, val:  70.42%, val_best:  72.92%, tr:  91.42%, tr_best:  93.46%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.570048/  1.375337, val:  66.67%, val_best:  72.92%, tr:  92.95%, tr_best:  93.46%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.585408/  1.349667, val:  68.33%, val_best:  72.92%, tr:  93.46%, tr_best:  93.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5896186c5454419d8092d0bb2dc7e5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▄▃▅▆▃▄▆▅▇▆▅▅▆▆▅█▇▆▆▆▆▇█▇▇▇▅▇▇▅▇▇▇▇██▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▆▇▆█▇▇█▇▇▇█▇█▇███▇██▇███▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▆▇▆█▇▇█▇▇▇█▇█▇███▇██▇███▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▅▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.93463</td></tr><tr><td>tr_epoch_loss</td><td>0.58541</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>1.34967</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fanciful-sweep-175</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3jsmzvff' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3jsmzvff</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_042701-3jsmzvff/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lp57p0qx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc4a9a9ffb14a7da95edcb8838bd990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113062211208873, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_043308-lp57p0qx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lp57p0qx' target=\"_blank\">olive-sweep-177</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lp57p0qx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lp57p0qx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.947063/  2.583659, val:  43.33%, val_best:  43.33%, tr:  36.98%, tr_best:  36.98%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.079648/  2.552214, val:  47.50%, val_best:  47.50%, tr:  47.29%, tr_best:  47.29%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.440152/  2.816056, val:  45.83%, val_best:  47.50%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.702359/  2.608184, val:  52.92%, val_best:  52.92%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.648370/  2.152824, val:  57.08%, val_best:  57.08%, tr:  60.78%, tr_best:  62.72%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.372454/  2.120130, val:  53.75%, val_best:  57.08%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.257514/  2.235948, val:  52.92%, val_best:  57.08%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.479639/  2.026428, val:  60.42%, val_best:  60.42%, tr:  69.46%, tr_best:  69.87%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.345928/  2.244302, val:  56.67%, val_best:  60.42%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.163936/  2.243655, val:  57.50%, val_best:  60.42%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.767419/  2.108367, val:  61.25%, val_best:  61.25%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.782014/  2.150752, val:  66.67%, val_best:  66.67%, tr:  85.70%, tr_best:  85.70%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.809035/  1.881654, val:  70.00%, val_best:  70.00%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.490000/  2.047878, val:  64.17%, val_best:  70.00%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.602303/  2.149295, val:  66.25%, val_best:  70.00%, tr:  89.99%, tr_best:  93.56%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.421047/  2.358446, val:  62.92%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.283697/  2.149677, val:  67.92%, val_best:  70.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.269014/  2.198613, val:  66.67%, val_best:  70.00%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.253144/  2.299058, val:  63.75%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.215981/  2.380569, val:  65.42%, val_best:  70.00%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.269208/  2.371109, val:  67.50%, val_best:  70.00%, tr:  97.34%, tr_best:  98.88%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.296773/  2.467595, val:  67.08%, val_best:  70.00%, tr:  97.04%, tr_best:  98.88%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.197454/  2.494197, val:  65.00%, val_best:  70.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.199544/  2.525805, val:  65.42%, val_best:  70.00%, tr:  98.26%, tr_best:  98.98%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.121712/  2.518055, val:  65.42%, val_best:  70.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.105059/  2.547200, val:  68.33%, val_best:  70.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.140324/  2.644401, val:  71.25%, val_best:  71.25%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.118367/  2.690570, val:  67.08%, val_best:  71.25%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.097341/  2.629523, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.066782/  2.792109, val:  65.00%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.054899/  2.694873, val:  65.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.055294/  2.741685, val:  67.92%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.054127/  2.822275, val:  68.33%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.047943/  3.015274, val:  67.08%, val_best:  71.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.052964/  2.910452, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.047462/  3.032295, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.039342/  2.946103, val:  65.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.036214/  3.058408, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.031958/  3.087567, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.030418/  3.076407, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.027841/  3.191187, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.028268/  3.168085, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.023311/  3.148622, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.026996/  3.222005, val:  69.17%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.019917/  3.228605, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.019810/  3.256931, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.020579/  3.224712, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.019091/  3.364685, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.017728/  3.282560, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.017268/  3.358269, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.016092/  3.378391, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.017236/  3.440042, val:  70.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.015482/  3.453836, val:  66.25%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.013622/  3.440531, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.016058/  3.461158, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.012311/  3.482852, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.011529/  3.511669, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.012265/  3.516227, val:  70.00%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.013941/  3.531119, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.012117/  3.550353, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.011595/  3.589346, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.011694/  3.607108, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.008965/  3.640304, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.010437/  3.634798, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.009229/  3.657750, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.008733/  3.669555, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.007859/  3.707500, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.007726/  3.707732, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.009183/  3.730491, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.008799/  3.735664, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.006790/  3.742037, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.005902/  3.752804, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.005665/  3.781719, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.006805/  3.786261, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.006740/  3.796135, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.005500/  3.814090, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.005156/  3.800385, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.005119/  3.805919, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.005025/  3.857177, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.006399/  3.839622, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.007174/  3.840463, val:  66.67%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.006505/  3.886342, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.004989/  3.888637, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.005003/  3.929216, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.005964/  3.934155, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.005697/  3.925625, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.005226/  3.940145, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.004293/  3.954563, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.004775/  3.990067, val:  66.67%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.005401/  3.978949, val:  66.25%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.004253/  3.997873, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.004022/  3.964737, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.004516/  3.978841, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.004277/  3.971360, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.003521/  4.006979, val:  69.17%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.003075/  4.020681, val:  69.58%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.003473/  4.061898, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.003235/  4.054733, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.002490/  4.038857, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.002922/  4.071185, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411f19706b074337b3432fe24c814aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▅▅▆█▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅█▇▇▇▇▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅█▇▇▇▇▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>▃▄▂▁▂▁▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00292</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>4.07119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-177</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lp57p0qx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lp57p0qx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_043308-lp57p0qx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l4eb035r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_044006-l4eb035r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l4eb035r' target=\"_blank\">balmy-sweep-179</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l4eb035r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l4eb035r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302747/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302738/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302605, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302685/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302820/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302609, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302779/  2.302603, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302691/  2.302607, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302883/  2.302611, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302826/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302753/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.302773/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302603, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.302739/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.302776/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.302685/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.302769/  2.302591, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.302684/  2.302589, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302518, val:  10.42%, val_best:  10.42%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.302776/  2.302472, val:  10.83%, val_best:  10.83%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.302748/  2.302479, val:  10.42%, val_best:  10.83%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.302831/  2.302471, val:  10.42%, val_best:  10.83%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302434, val:  10.42%, val_best:  10.83%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.302714/  2.302363, val:  10.42%, val_best:  10.83%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.302546/  2.302254, val:  10.42%, val_best:  10.83%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.302311/  2.302028, val:  11.25%, val_best:  11.25%, tr:   9.81%, tr_best:  10.11%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.302202/  2.301835, val:  12.08%, val_best:  12.08%, tr:  11.54%, tr_best:  11.54%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.301894/  2.301568, val:  11.25%, val_best:  12.08%, tr:  12.05%, tr_best:  12.05%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.301265/  2.301414, val:  10.83%, val_best:  12.08%, tr:  11.03%, tr_best:  12.05%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.300392/  2.300788, val:  10.42%, val_best:  12.08%, tr:  12.87%, tr_best:  12.87%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.299133/  2.300266, val:  10.83%, val_best:  12.08%, tr:  13.07%, tr_best:  13.07%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.297213/  2.299128, val:  14.17%, val_best:  14.17%, tr:  12.36%, tr_best:  13.07%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.294265/  2.297536, val:  14.58%, val_best:  14.58%, tr:  15.12%, tr_best:  15.12%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.290618/  2.294584, val:  11.25%, val_best:  14.58%, tr:  15.02%, tr_best:  15.12%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.284880/  2.290067, val:  12.50%, val_best:  14.58%, tr:  14.71%, tr_best:  15.12%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.276310/  2.284372, val:  11.67%, val_best:  14.58%, tr:  14.10%, tr_best:  15.12%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.265587/  2.276422, val:  11.25%, val_best:  14.58%, tr:  13.79%, tr_best:  15.12%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.253083/  2.268075, val:  11.25%, val_best:  14.58%, tr:  13.69%, tr_best:  15.12%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.235626/  2.258014, val:  13.75%, val_best:  14.58%, tr:  14.30%, tr_best:  15.12%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.225443/  2.249752, val:  11.25%, val_best:  14.58%, tr:  13.89%, tr_best:  15.12%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.216130/  2.241745, val:  18.75%, val_best:  18.75%, tr:  16.24%, tr_best:  16.24%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.205881/  2.234850, val:  19.58%, val_best:  19.58%, tr:  20.53%, tr_best:  20.53%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  2.197616/  2.229174, val:  21.67%, val_best:  21.67%, tr:  21.04%, tr_best:  21.04%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  2.186113/  2.222968, val:  22.92%, val_best:  22.92%, tr:  22.78%, tr_best:  22.78%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  2.186550/  2.218661, val:  24.17%, val_best:  24.17%, tr:  22.37%, tr_best:  22.78%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  2.177871/  2.212904, val:  23.33%, val_best:  24.17%, tr:  22.37%, tr_best:  22.78%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  2.171453/  2.206509, val:  24.17%, val_best:  24.17%, tr:  23.90%, tr_best:  23.90%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  2.159947/  2.199936, val:  25.83%, val_best:  25.83%, tr:  25.13%, tr_best:  25.13%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  2.147252/  2.191722, val:  25.83%, val_best:  25.83%, tr:  25.54%, tr_best:  25.54%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  2.145864/  2.184250, val:  24.58%, val_best:  25.83%, tr:  25.43%, tr_best:  25.54%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  2.138214/  2.175202, val:  25.42%, val_best:  25.83%, tr:  28.70%, tr_best:  28.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eff9c806625460ab37ea1a76b82d4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▄▅▅▁▇▅█▄▁▄▅▄▅▁▇▂▇▄▁▄▅▂▁▁▅▂▅▄▂▅█▄▁█</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▃▅▇▇█</td></tr><tr><td>tr_acc</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▂▁▂▂▂▂▃▄▃▃▄▇▇█</td></tr><tr><td>tr_epoch_loss</td><td>█████████████████████████████████▇▇▅▄▃▂▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▅▇▇█</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▃▅▇▇█</td></tr><tr><td>val_loss</td><td>█████████████████████████████████▇▇▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.28703</td></tr><tr><td>tr_epoch_loss</td><td>2.13821</td></tr><tr><td>val_acc_best</td><td>0.25833</td></tr><tr><td>val_acc_now</td><td>0.25417</td></tr><tr><td>val_loss</td><td>2.1752</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-sweep-179</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l4eb035r' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/l4eb035r</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_044006-l4eb035r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tqogolns with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_044613-tqogolns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tqogolns' target=\"_blank\">toasty-sweep-181</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tqogolns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tqogolns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304866/  2.302069, val:   7.92%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.291182/  2.257805, val:  18.33%, val_best:  18.33%, tr:  11.44%, tr_best:  11.44%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.127549/  2.033066, val:  37.92%, val_best:  37.92%, tr:  31.26%, tr_best:  31.26%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.856634/  1.821985, val:  46.25%, val_best:  46.25%, tr:  44.13%, tr_best:  44.13%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.649979/  1.708334, val:  50.42%, val_best:  50.42%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.562437/  1.657492, val:  51.67%, val_best:  51.67%, tr:  56.18%, tr_best:  56.18%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.499264/  1.611927, val:  54.17%, val_best:  54.17%, tr:  55.98%, tr_best:  56.18%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.449089/  1.584853, val:  57.92%, val_best:  57.92%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.418374/  1.565120, val:  57.50%, val_best:  57.92%, tr:  59.86%, tr_best:  59.86%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.388786/  1.553536, val:  55.42%, val_best:  57.92%, tr:  59.24%, tr_best:  59.86%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.370210/  1.511962, val:  57.92%, val_best:  57.92%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.357440/  1.509884, val:  57.50%, val_best:  57.92%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.342602/  1.514555, val:  58.33%, val_best:  58.33%, tr:  60.78%, tr_best:  62.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.305215/  1.537346, val:  55.42%, val_best:  58.33%, tr:  61.70%, tr_best:  62.51%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.302316/  1.485492, val:  59.58%, val_best:  59.58%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.284428/  1.474774, val:  61.25%, val_best:  61.25%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.259987/  1.460601, val:  61.25%, val_best:  61.25%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.241964/  1.475400, val:  59.17%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.240879/  1.503373, val:  55.42%, val_best:  61.25%, tr:  65.58%, tr_best:  66.50%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.220163/  1.464319, val:  60.00%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.213697/  1.454909, val:  61.25%, val_best:  61.25%, tr:  65.47%, tr_best:  66.50%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.221104/  1.443046, val:  61.67%, val_best:  61.67%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.181027/  1.441109, val:  63.33%, val_best:  63.33%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.162847/  1.455854, val:  61.67%, val_best:  63.33%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.167728/  1.412543, val:  67.92%, val_best:  67.92%, tr:  67.01%, tr_best:  68.54%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.153586/  1.391479, val:  68.33%, val_best:  68.33%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.135177/  1.423039, val:  65.42%, val_best:  68.33%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.140573/  1.399903, val:  69.17%, val_best:  69.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.109663/  1.417845, val:  63.33%, val_best:  69.17%, tr:  70.17%, tr_best:  70.48%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.099673/  1.426477, val:  61.25%, val_best:  69.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.122352/  1.438461, val:  62.08%, val_best:  69.17%, tr:  68.74%, tr_best:  70.48%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.103809/  1.425450, val:  65.42%, val_best:  69.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.098189/  1.406904, val:  68.75%, val_best:  69.17%, tr:  71.40%, tr_best:  71.40%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.069862/  1.426177, val:  62.08%, val_best:  69.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.096516/  1.432182, val:  61.67%, val_best:  69.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.057844/  1.397995, val:  66.25%, val_best:  69.17%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.062569/  1.396652, val:  65.83%, val_best:  69.17%, tr:  73.44%, tr_best:  73.54%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.051041/  1.394145, val:  67.08%, val_best:  69.17%, tr:  75.18%, tr_best:  75.18%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.037509/  1.416767, val:  65.83%, val_best:  69.17%, tr:  76.51%, tr_best:  76.51%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.040144/  1.402977, val:  65.83%, val_best:  69.17%, tr:  75.18%, tr_best:  76.51%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.034511/  1.435016, val:  63.33%, val_best:  69.17%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.015900/  1.395543, val:  67.08%, val_best:  69.17%, tr:  74.97%, tr_best:  78.55%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.015039/  1.423531, val:  62.92%, val_best:  69.17%, tr:  76.40%, tr_best:  78.55%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.992370/  1.417143, val:  67.92%, val_best:  69.17%, tr:  77.43%, tr_best:  78.55%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.988180/  1.411350, val:  65.00%, val_best:  69.17%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.984562/  1.405432, val:  68.75%, val_best:  69.17%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.979875/  1.409449, val:  70.42%, val_best:  70.42%, tr:  79.16%, tr_best:  81.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.993695/  1.411551, val:  68.33%, val_best:  70.42%, tr:  79.67%, tr_best:  81.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.977868/  1.397911, val:  68.75%, val_best:  70.42%, tr:  79.16%, tr_best:  81.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.970257/  1.432657, val:  66.67%, val_best:  70.42%, tr:  78.45%, tr_best:  81.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.987519/  1.424328, val:  67.50%, val_best:  70.42%, tr:  77.32%, tr_best:  81.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.943998/  1.453337, val:  65.83%, val_best:  70.42%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.948366/  1.428699, val:  69.58%, val_best:  70.42%, tr:  81.72%, tr_best:  82.23%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.934680/  1.425228, val:  70.83%, val_best:  70.83%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.936092/  1.429318, val:  70.00%, val_best:  70.83%, tr:  81.92%, tr_best:  83.66%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.928002/  1.498770, val:  62.92%, val_best:  70.83%, tr:  82.43%, tr_best:  83.66%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.936448/  1.422120, val:  68.75%, val_best:  70.83%, tr:  83.45%, tr_best:  83.66%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.910573/  1.469010, val:  67.92%, val_best:  70.83%, tr:  82.94%, tr_best:  83.66%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.911871/  1.430249, val:  73.75%, val_best:  73.75%, tr:  83.55%, tr_best:  83.66%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.912011/  1.415647, val:  70.42%, val_best:  73.75%, tr:  83.25%, tr_best:  83.66%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.913183/  1.475398, val:  64.17%, val_best:  73.75%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.902948/  1.463507, val:  68.33%, val_best:  73.75%, tr:  85.19%, tr_best:  85.80%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.889743/  1.414555, val:  69.58%, val_best:  73.75%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.887326/  1.484771, val:  67.08%, val_best:  73.75%, tr:  84.37%, tr_best:  87.03%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.887590/  1.448018, val:  71.25%, val_best:  73.75%, tr:  84.58%, tr_best:  87.03%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.882209/  1.469138, val:  67.50%, val_best:  73.75%, tr:  85.60%, tr_best:  87.03%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.877611/  1.462659, val:  68.75%, val_best:  73.75%, tr:  86.82%, tr_best:  87.03%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.861277/  1.500203, val:  69.58%, val_best:  73.75%, tr:  85.80%, tr_best:  87.03%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.879053/  1.486644, val:  66.67%, val_best:  73.75%, tr:  85.60%, tr_best:  87.03%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.861990/  1.457009, val:  71.25%, val_best:  73.75%, tr:  86.82%, tr_best:  87.03%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.863927/  1.511866, val:  67.92%, val_best:  73.75%, tr:  86.41%, tr_best:  87.03%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.851772/  1.479541, val:  71.25%, val_best:  73.75%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.859869/  1.497649, val:  70.00%, val_best:  73.75%, tr:  86.01%, tr_best:  87.84%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.847316/  1.478438, val:  70.83%, val_best:  73.75%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.849938/  1.494172, val:  67.92%, val_best:  73.75%, tr:  86.21%, tr_best:  89.17%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.839509/  1.534878, val:  65.83%, val_best:  73.75%, tr:  86.52%, tr_best:  89.17%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.855750/  1.489117, val:  70.83%, val_best:  73.75%, tr:  86.31%, tr_best:  89.17%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.847236/  1.495279, val:  71.25%, val_best:  73.75%, tr:  86.01%, tr_best:  89.17%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.832905/  1.482776, val:  72.08%, val_best:  73.75%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.817946/  1.511226, val:  68.75%, val_best:  73.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.827399/  1.478066, val:  72.08%, val_best:  73.75%, tr:  88.36%, tr_best:  89.89%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.819834/  1.506966, val:  66.25%, val_best:  73.75%, tr:  88.36%, tr_best:  89.89%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.818009/  1.521518, val:  71.25%, val_best:  73.75%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.821352/  1.479230, val:  71.25%, val_best:  73.75%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.804476/  1.529843, val:  66.25%, val_best:  73.75%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.803580/  1.517577, val:  70.83%, val_best:  73.75%, tr:  89.79%, tr_best:  91.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.807015/  1.560798, val:  68.75%, val_best:  73.75%, tr:  89.17%, tr_best:  91.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.785917/  1.522126, val:  73.75%, val_best:  73.75%, tr:  91.01%, tr_best:  91.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.778291/  1.531748, val:  73.75%, val_best:  73.75%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.785248/  1.510074, val:  68.33%, val_best:  73.75%, tr:  90.70%, tr_best:  92.13%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.786164/  1.535146, val:  67.92%, val_best:  73.75%, tr:  90.19%, tr_best:  92.13%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.772392/  1.551012, val:  72.50%, val_best:  73.75%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.773888/  1.536079, val:  70.42%, val_best:  73.75%, tr:  91.01%, tr_best:  92.13%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.776216/  1.543640, val:  70.83%, val_best:  73.75%, tr:  91.22%, tr_best:  92.13%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.771211/  1.587912, val:  69.58%, val_best:  73.75%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.780185/  1.657034, val:  64.17%, val_best:  73.75%, tr:  89.89%, tr_best:  92.13%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.772233/  1.565321, val:  69.58%, val_best:  73.75%, tr:  88.76%, tr_best:  92.13%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.755529/  1.574369, val:  67.92%, val_best:  73.75%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.767645/  1.560743, val:  69.58%, val_best:  73.75%, tr:  91.01%, tr_best:  92.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6388273f40b94614a8bf2b2c5f2e577f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▂▄▃▅▇▃▄▆▅▇▅▆▅▇█▆█▆▆█▇██▇▇▇█▆▇▇▅█▇▆▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇██▇██▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇██▇██▇█▇████</td></tr><tr><td>val_loss</td><td>██▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91011</td></tr><tr><td>tr_epoch_loss</td><td>0.76765</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.69583</td></tr><tr><td>val_loss</td><td>1.56074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-sweep-181</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tqogolns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tqogolns</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_044613-tqogolns/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zz15ft4x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_045314-zz15ft4x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zz15ft4x' target=\"_blank\">kind-sweep-183</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zz15ft4x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zz15ft4x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.947063/  2.583659, val:  43.33%, val_best:  43.33%, tr:  36.98%, tr_best:  36.98%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.079648/  2.552214, val:  47.50%, val_best:  47.50%, tr:  47.29%, tr_best:  47.29%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.440152/  2.816056, val:  45.83%, val_best:  47.50%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.702359/  2.608184, val:  52.92%, val_best:  52.92%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.648370/  2.152824, val:  57.08%, val_best:  57.08%, tr:  60.78%, tr_best:  62.72%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.372454/  2.120130, val:  53.75%, val_best:  57.08%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.257514/  2.235948, val:  52.92%, val_best:  57.08%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.479639/  2.026428, val:  60.42%, val_best:  60.42%, tr:  69.46%, tr_best:  69.87%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.345928/  2.244302, val:  56.67%, val_best:  60.42%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.163936/  2.243655, val:  57.50%, val_best:  60.42%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.767419/  2.108367, val:  61.25%, val_best:  61.25%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.782014/  2.150752, val:  66.67%, val_best:  66.67%, tr:  85.70%, tr_best:  85.70%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.809035/  1.881654, val:  70.00%, val_best:  70.00%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.490000/  2.047878, val:  64.17%, val_best:  70.00%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.602303/  2.149295, val:  66.25%, val_best:  70.00%, tr:  89.99%, tr_best:  93.56%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.421047/  2.358446, val:  62.92%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.283697/  2.149677, val:  67.92%, val_best:  70.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.269014/  2.198613, val:  66.67%, val_best:  70.00%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.253144/  2.299058, val:  63.75%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.215981/  2.380569, val:  65.42%, val_best:  70.00%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.269208/  2.371109, val:  67.50%, val_best:  70.00%, tr:  97.34%, tr_best:  98.88%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.296773/  2.467595, val:  67.08%, val_best:  70.00%, tr:  97.04%, tr_best:  98.88%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.197454/  2.494197, val:  65.00%, val_best:  70.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.199544/  2.525805, val:  65.42%, val_best:  70.00%, tr:  98.26%, tr_best:  98.98%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.121712/  2.518055, val:  65.42%, val_best:  70.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.105059/  2.547200, val:  68.33%, val_best:  70.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.140324/  2.644401, val:  71.25%, val_best:  71.25%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.118367/  2.690570, val:  67.08%, val_best:  71.25%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.097341/  2.629523, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.066782/  2.792109, val:  65.00%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.054899/  2.694873, val:  65.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.055294/  2.741685, val:  67.92%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.054127/  2.822275, val:  68.33%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.047943/  3.015274, val:  67.08%, val_best:  71.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.052964/  2.910452, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.047462/  3.032295, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.039342/  2.946103, val:  65.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.036214/  3.058408, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.031958/  3.087567, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.030418/  3.076407, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.027841/  3.191187, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.028268/  3.168085, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.023311/  3.148622, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.026996/  3.222005, val:  69.17%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.019917/  3.228605, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.019810/  3.256931, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.020579/  3.224712, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.019091/  3.364685, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.017728/  3.282560, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.017268/  3.358269, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.016092/  3.378391, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.017236/  3.440042, val:  70.42%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.015482/  3.453836, val:  66.25%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.013622/  3.440531, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.016058/  3.461158, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.012311/  3.482852, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.011529/  3.511669, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.012265/  3.516227, val:  70.00%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.013941/  3.531119, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.012117/  3.550353, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.011595/  3.589346, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.011694/  3.607108, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.008965/  3.640304, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.010437/  3.634798, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.009229/  3.657750, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.008733/  3.669555, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.007859/  3.707500, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.007726/  3.707732, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.009183/  3.730491, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.008799/  3.735664, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.006790/  3.742037, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.005902/  3.752804, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.005665/  3.781719, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.006805/  3.786261, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.006740/  3.796135, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.005500/  3.814090, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.005156/  3.800385, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.005119/  3.805919, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.005025/  3.857177, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.006399/  3.839622, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.007174/  3.840463, val:  66.67%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.006505/  3.886342, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.004989/  3.888637, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.005003/  3.929216, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.005964/  3.934155, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.005697/  3.925625, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.005226/  3.940145, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.004293/  3.954563, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.004775/  3.990067, val:  66.67%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.005401/  3.978949, val:  66.25%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.004253/  3.997873, val:  67.08%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.004022/  3.964737, val:  67.50%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.004516/  3.978841, val:  67.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.004277/  3.971360, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.003521/  4.006979, val:  69.17%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.003075/  4.020681, val:  69.58%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.003473/  4.061898, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.003235/  4.054733, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.002490/  4.038857, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.002922/  4.071185, val:  68.33%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e332fcf828a4e08985cd9fb1a80e5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▅▅▆█▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅█▇▇▇▇▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅█▇▇▇▇▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>▃▄▂▁▂▁▂▂▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00292</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>4.07119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-183</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zz15ft4x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zz15ft4x</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_045314-zz15ft4x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rx6yjmay with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_050020-rx6yjmay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rx6yjmay' target=\"_blank\">graceful-sweep-185</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rx6yjmay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rx6yjmay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305096/  2.302658, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304764/  2.302583, val:  10.83%, val_best:  10.83%, tr:   8.17%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304108/  2.301949, val:  10.00%, val_best:  10.83%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.303110/  2.300555, val:  11.67%, val_best:  11.67%, tr:  11.64%, tr_best:  11.64%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.297648/  2.295352, val:  16.67%, val_best:  16.67%, tr:  13.18%, tr_best:  13.18%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.279468/  2.279875, val:  15.83%, val_best:  16.67%, tr:  16.75%, tr_best:  16.75%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.244174/  2.255273, val:  21.25%, val_best:  21.25%, tr:  18.59%, tr_best:  18.59%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.202443/  2.223512, val:  28.33%, val_best:  28.33%, tr:  22.37%, tr_best:  22.37%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.155884/  2.175553, val:  36.25%, val_best:  36.25%, tr:  27.48%, tr_best:  27.48%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.082253/  2.093220, val:  38.75%, val_best:  38.75%, tr:  35.85%, tr_best:  35.85%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.969021/  1.987634, val:  40.42%, val_best:  40.42%, tr:  43.51%, tr_best:  43.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.845898/  1.887970, val:  48.33%, val_best:  48.33%, tr:  45.35%, tr_best:  45.35%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.731291/  1.805317, val:  48.75%, val_best:  48.75%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.640273/  1.731377, val:  49.58%, val_best:  49.58%, tr:  51.69%, tr_best:  51.69%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.568917/  1.671375, val:  49.58%, val_best:  49.58%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.501940/  1.634598, val:  48.33%, val_best:  49.58%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.456175/  1.607936, val:  48.75%, val_best:  49.58%, tr:  55.36%, tr_best:  57.20%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.412154/  1.575655, val:  48.33%, val_best:  49.58%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.372841/  1.554667, val:  51.25%, val_best:  51.25%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.355471/  1.532932, val:  53.33%, val_best:  53.33%, tr:  58.32%, tr_best:  58.63%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.315694/  1.508384, val:  50.42%, val_best:  53.33%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.290979/  1.494020, val:  53.33%, val_best:  53.33%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.270141/  1.462083, val:  55.83%, val_best:  55.83%, tr:  61.80%, tr_best:  62.31%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.250724/  1.435709, val:  56.25%, val_best:  56.25%, tr:  60.27%, tr_best:  62.31%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.229350/  1.421818, val:  57.08%, val_best:  57.08%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.218200/  1.411407, val:  56.67%, val_best:  57.08%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.197459/  1.402075, val:  55.83%, val_best:  57.08%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.181881/  1.400040, val:  55.00%, val_best:  57.08%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.171957/  1.381776, val:  55.83%, val_best:  57.08%, tr:  63.53%, tr_best:  64.25%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.154694/  1.394811, val:  59.17%, val_best:  59.17%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.146358/  1.375470, val:  57.50%, val_best:  59.17%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.130311/  1.347824, val:  59.58%, val_best:  59.58%, tr:  65.68%, tr_best:  66.29%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.110353/  1.356374, val:  57.92%, val_best:  59.58%, tr:  65.88%, tr_best:  66.29%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.107481/  1.347598, val:  58.33%, val_best:  59.58%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.094237/  1.329283, val:  62.08%, val_best:  62.08%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.087206/  1.327825, val:  58.75%, val_best:  62.08%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.076208/  1.319117, val:  59.58%, val_best:  62.08%, tr:  68.44%, tr_best:  68.74%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.061619/  1.317894, val:  58.75%, val_best:  62.08%, tr:  67.82%, tr_best:  68.74%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.057338/  1.315534, val:  61.67%, val_best:  62.08%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.039782/  1.304278, val:  63.33%, val_best:  63.33%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.037823/  1.305005, val:  60.83%, val_best:  63.33%, tr:  69.36%, tr_best:  71.20%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.028168/  1.293521, val:  59.17%, val_best:  63.33%, tr:  68.95%, tr_best:  71.20%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.012406/  1.290553, val:  62.50%, val_best:  63.33%, tr:  71.09%, tr_best:  71.20%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.007120/  1.303748, val:  60.00%, val_best:  63.33%, tr:  70.68%, tr_best:  71.20%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.006931/  1.283756, val:  62.08%, val_best:  63.33%, tr:  69.66%, tr_best:  71.20%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.995081/  1.277798, val:  62.50%, val_best:  63.33%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.988918/  1.267120, val:  61.25%, val_best:  63.33%, tr:  69.97%, tr_best:  72.01%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.976777/  1.282294, val:  60.42%, val_best:  63.33%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.971477/  1.274745, val:  62.50%, val_best:  63.33%, tr:  72.32%, tr_best:  72.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.967830/  1.271485, val:  62.92%, val_best:  63.33%, tr:  70.48%, tr_best:  72.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.960934/  1.269077, val:  64.58%, val_best:  64.58%, tr:  72.63%, tr_best:  72.63%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.955846/  1.263673, val:  60.83%, val_best:  64.58%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.951295/  1.262338, val:  62.50%, val_best:  64.58%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.941338/  1.261093, val:  62.92%, val_best:  64.58%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.934506/  1.255893, val:  61.67%, val_best:  64.58%, tr:  73.85%, tr_best:  74.97%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.928522/  1.262231, val:  62.50%, val_best:  64.58%, tr:  73.75%, tr_best:  74.97%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.932937/  1.246776, val:  62.08%, val_best:  64.58%, tr:  73.14%, tr_best:  74.97%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.922331/  1.242424, val:  60.00%, val_best:  64.58%, tr:  72.01%, tr_best:  74.97%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.927630/  1.252295, val:  61.25%, val_best:  64.58%, tr:  73.65%, tr_best:  74.97%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.919937/  1.237889, val:  63.33%, val_best:  64.58%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.906111/  1.230172, val:  58.75%, val_best:  64.58%, tr:  73.75%, tr_best:  75.79%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.900287/  1.258694, val:  61.67%, val_best:  64.58%, tr:  74.46%, tr_best:  75.79%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.900471/  1.242647, val:  62.92%, val_best:  64.58%, tr:  74.46%, tr_best:  75.79%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.896941/  1.223915, val:  67.50%, val_best:  67.50%, tr:  75.18%, tr_best:  75.79%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.906210/  1.244170, val:  62.08%, val_best:  67.50%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.888872/  1.241760, val:  61.25%, val_best:  67.50%, tr:  74.36%, tr_best:  76.71%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.882140/  1.231780, val:  67.08%, val_best:  67.50%, tr:  75.49%, tr_best:  76.71%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.879181/  1.238455, val:  62.50%, val_best:  67.50%, tr:  75.79%, tr_best:  76.71%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.869433/  1.250386, val:  62.92%, val_best:  67.50%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.862235/  1.259092, val:  62.50%, val_best:  67.50%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.868671/  1.237282, val:  60.83%, val_best:  67.50%, tr:  75.28%, tr_best:  76.92%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.857247/  1.240453, val:  61.67%, val_best:  67.50%, tr:  74.57%, tr_best:  76.92%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.860618/  1.229734, val:  64.58%, val_best:  67.50%, tr:  76.51%, tr_best:  76.92%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.842753/  1.245531, val:  64.17%, val_best:  67.50%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.849976/  1.262758, val:  60.00%, val_best:  67.50%, tr:  76.71%, tr_best:  78.24%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.845735/  1.244547, val:  67.92%, val_best:  67.92%, tr:  77.53%, tr_best:  78.24%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.835075/  1.260167, val:  60.83%, val_best:  67.92%, tr:  76.00%, tr_best:  78.24%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.829617/  1.232015, val:  61.67%, val_best:  67.92%, tr:  75.89%, tr_best:  78.24%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.832165/  1.246413, val:  61.67%, val_best:  67.92%, tr:  75.89%, tr_best:  78.24%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.820799/  1.249053, val:  67.08%, val_best:  67.92%, tr:  78.04%, tr_best:  78.24%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.817419/  1.241693, val:  67.50%, val_best:  67.92%, tr:  79.57%, tr_best:  79.57%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.819789/  1.243441, val:  62.08%, val_best:  67.92%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.812491/  1.254008, val:  62.50%, val_best:  67.92%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.805454/  1.247182, val:  65.42%, val_best:  67.92%, tr:  78.86%, tr_best:  80.39%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.805582/  1.240115, val:  67.08%, val_best:  67.92%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.793152/  1.260102, val:  62.50%, val_best:  67.92%, tr:  79.26%, tr_best:  80.69%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.784192/  1.285646, val:  59.17%, val_best:  67.92%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.793666/  1.250211, val:  62.92%, val_best:  67.92%, tr:  78.75%, tr_best:  81.31%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.777654/  1.245639, val:  65.83%, val_best:  67.92%, tr:  80.29%, tr_best:  81.31%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.782696/  1.257532, val:  62.08%, val_best:  67.92%, tr:  78.14%, tr_best:  81.31%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.781053/  1.256205, val:  65.00%, val_best:  67.92%, tr:  80.29%, tr_best:  81.31%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.780280/  1.262112, val:  68.75%, val_best:  68.75%, tr:  79.98%, tr_best:  81.31%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.771178/  1.258531, val:  64.17%, val_best:  68.75%, tr:  81.21%, tr_best:  81.31%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.766061/  1.264429, val:  64.58%, val_best:  68.75%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.768297/  1.241145, val:  70.42%, val_best:  70.42%, tr:  79.37%, tr_best:  83.96%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.760433/  1.273827, val:  61.25%, val_best:  70.42%, tr:  82.33%, tr_best:  83.96%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.763880/  1.251539, val:  65.42%, val_best:  70.42%, tr:  81.31%, tr_best:  83.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2342785fcc444449bf1ca5c9fc714289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▂▃▅▄▃▆▆▇▇▅▅▅▆▆▇▇▆▆▅▅▇█▇▇▆▅▇▇▅▆▆▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▂▂▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇███████</td></tr><tr><td>tr_epoch_loss</td><td>█████▇▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▂▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▂▂▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>val_loss</td><td>█████▇▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.81307</td></tr><tr><td>tr_epoch_loss</td><td>0.76388</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.65417</td></tr><tr><td>val_loss</td><td>1.25154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-185</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rx6yjmay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rx6yjmay</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_050020-rx6yjmay/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t9gl6x6l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_050638-t9gl6x6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t9gl6x6l' target=\"_blank\">blooming-sweep-187</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t9gl6x6l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t9gl6x6l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.259325/  2.166692, val:  25.42%, val_best:  25.42%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.951459/  1.832348, val:  47.92%, val_best:  47.92%, tr:  37.90%, tr_best:  37.90%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.623138/  1.666077, val:  55.42%, val_best:  55.42%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.460078/  1.635147, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.385512/  1.555451, val:  60.42%, val_best:  60.42%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.316895/  1.531080, val:  59.58%, val_best:  60.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.249793/  1.511024, val:  59.58%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.203278/  1.482369, val:  61.67%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.161125/  1.456793, val:  65.83%, val_best:  65.83%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.130679/  1.528863, val:  60.00%, val_best:  65.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.108387/  1.563280, val:  55.00%, val_best:  65.83%, tr:  68.95%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054601/  1.435886, val:  68.33%, val_best:  68.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.048901/  1.472334, val:  59.17%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.017672/  1.569106, val:  62.50%, val_best:  68.33%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.974325/  1.656879, val:  59.58%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980752/  1.572125, val:  60.83%, val_best:  68.33%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.983020/  1.537963, val:  64.58%, val_best:  68.33%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.914581/  1.668934, val:  62.08%, val_best:  68.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.931618/  1.708934, val:  62.50%, val_best:  68.33%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.924997/  1.702797, val:  65.42%, val_best:  68.33%, tr:  77.83%, tr_best:  78.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.895528/  1.803627, val:  62.08%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.870973/  1.802069, val:  61.25%, val_best:  68.33%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.875475/  1.817097, val:  62.50%, val_best:  68.33%, tr:  80.08%, tr_best:  82.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.852028/  1.992823, val:  60.00%, val_best:  68.33%, tr:  82.02%, tr_best:  82.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.817858/  1.996159, val:  59.58%, val_best:  68.33%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.836069/  1.881631, val:  67.50%, val_best:  68.33%, tr:  83.76%, tr_best:  84.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.846120/  1.998041, val:  70.00%, val_best:  70.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.806404/  2.054228, val:  62.92%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.791962/  2.007748, val:  68.75%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.819494/  2.359427, val:  60.42%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.782672/  2.213522, val:  62.08%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.785682/  2.318455, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  87.74%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.812352/  2.263149, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.814710/  2.259653, val:  67.92%, val_best:  70.00%, tr:  87.54%, tr_best:  87.74%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.742937/  2.467701, val:  60.42%, val_best:  70.00%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.757479/  2.534710, val:  59.58%, val_best:  70.00%, tr:  86.21%, tr_best:  88.46%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.681546/  2.297895, val:  67.50%, val_best:  70.00%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.701446/  2.512144, val:  63.75%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.710612/  2.657074, val:  65.00%, val_best:  70.00%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.657503/  2.521472, val:  63.75%, val_best:  70.00%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.682582/  2.741191, val:  62.92%, val_best:  70.00%, tr:  91.32%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.655606/  2.770979, val:  59.17%, val_best:  70.00%, tr:  93.05%, tr_best:  93.26%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.632359/  2.721785, val:  67.08%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.633759/  2.736447, val:  65.00%, val_best:  70.00%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.632607/  2.656749, val:  67.92%, val_best:  70.00%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.615663/  2.725739, val:  68.75%, val_best:  70.00%, tr:  94.79%, tr_best:  94.99%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594888/  2.853819, val:  66.25%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.578222/  3.049881, val:  65.42%, val_best:  70.00%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.607904/  2.996387, val:  67.92%, val_best:  70.00%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.567040/  3.018704, val:  69.58%, val_best:  70.00%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.532360/  3.186153, val:  66.25%, val_best:  70.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.575075/  3.053903, val:  67.08%, val_best:  70.00%, tr:  94.18%, tr_best:  97.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.514349/  3.110004, val:  67.08%, val_best:  70.00%, tr:  96.83%, tr_best:  97.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.518154/  3.457839, val:  65.83%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.505677/  3.216293, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.527777/  3.308029, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.491510/  3.531652, val:  64.17%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.559684/  3.381672, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.539413/  3.329102, val:  67.08%, val_best:  70.00%, tr:  94.48%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.516434/  3.457018, val:  70.83%, val_best:  70.83%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.485153/  3.732556, val:  64.17%, val_best:  70.83%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.535130/  3.417022, val:  71.25%, val_best:  71.25%, tr:  96.83%, tr_best:  98.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.446230/  3.361158, val:  69.17%, val_best:  71.25%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.424834/  3.410936, val:  73.75%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.435740/  3.347567, val:  71.67%, val_best:  73.75%, tr:  97.65%, tr_best:  98.88%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.381304/  3.313588, val:  71.25%, val_best:  73.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.393611/  3.409695, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.414356/  3.359644, val:  73.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.412061/  3.412950, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.420847/  3.498824, val:  72.08%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.378566/  3.353256, val:  71.25%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.437227/  3.585583, val:  72.50%, val_best:  73.75%, tr:  98.06%, tr_best:  99.49%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.419239/  3.353722, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.389243/  3.548229, val:  67.92%, val_best:  73.75%, tr:  98.37%, tr_best:  99.49%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.355405/  3.541240, val:  72.92%, val_best:  73.75%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.352597/  3.526462, val:  70.42%, val_best:  73.75%, tr:  98.47%, tr_best:  99.49%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.337224/  3.475421, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.360251/  3.710256, val:  69.58%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.380566/  3.617064, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.325451/  3.572766, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.308370/  3.665858, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.266245/  3.580417, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.278189/  3.626280, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.352835/  3.735754, val:  70.83%, val_best:  73.75%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.314501/  3.713542, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.353990/  3.794341, val:  70.42%, val_best:  73.75%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.290747/  3.757254, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.318437/  3.547390, val:  72.50%, val_best:  73.75%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.290242/  3.610040, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.257004/  3.746444, val:  73.75%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.253982/  3.726433, val:  70.83%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.232963/  3.734505, val:  72.08%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.194844/  3.748441, val:  72.50%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.219133/  3.755011, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.205211/  3.758615, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.236082/  3.739775, val:  73.33%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.224297/  3.839006, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.232116/  3.776063, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.197325/  3.764912, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.181913/  3.835845, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7951af35b064925bde0b9ce015c7012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▄▅▇▁▄▇█▆█▇▇▇█▆█▇███████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.18191</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.83585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-187</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t9gl6x6l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t9gl6x6l</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_050638-t9gl6x6l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i622qhr7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68bf02730494b8caefe6d4d23329afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112920919226275, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_051251-i622qhr7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/i622qhr7' target=\"_blank\">lucky-sweep-189</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/i622qhr7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/i622qhr7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.939126/  1.555109, val:  44.58%, val_best:  44.58%, tr:  26.66%, tr_best:  26.66%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.266303/  1.399368, val:  55.00%, val_best:  55.00%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.102898/  1.364615, val:  57.50%, val_best:  57.50%, tr:  60.78%, tr_best:  60.78%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.959962/  1.390627, val:  58.75%, val_best:  58.75%, tr:  66.80%, tr_best:  66.80%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.879352/  1.252432, val:  62.50%, val_best:  62.50%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.832203/  1.238258, val:  65.00%, val_best:  65.00%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.761140/  1.244493, val:  62.50%, val_best:  65.00%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.700634/  1.338266, val:  61.67%, val_best:  65.00%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.658134/  1.337354, val:  67.08%, val_best:  67.08%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.597211/  1.450041, val:  62.50%, val_best:  67.08%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.566377/  1.490052, val:  63.75%, val_best:  67.08%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.489797/  1.414084, val:  71.67%, val_best:  71.67%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.454322/  1.451078, val:  70.42%, val_best:  71.67%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.420612/  1.499742, val:  69.17%, val_best:  71.67%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.381960/  1.673630, val:  66.67%, val_best:  71.67%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.348172/  1.709571, val:  67.08%, val_best:  71.67%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.342509/  1.668944, val:  69.58%, val_best:  71.67%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.304539/  1.706447, val:  71.25%, val_best:  71.67%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.290492/  1.831481, val:  67.92%, val_best:  71.67%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.278869/  1.895210, val:  70.00%, val_best:  71.67%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.251164/  1.957802, val:  68.75%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.239022/  1.998075, val:  67.08%, val_best:  71.67%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.219042/  2.043891, val:  70.00%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.217369/  2.049850, val:  67.92%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.190840/  2.132448, val:  70.42%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.179023/  2.167128, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.182081/  2.200595, val:  67.92%, val_best:  71.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.160219/  2.304557, val:  69.58%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.154911/  2.304292, val:  69.17%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.144163/  2.412052, val:  67.08%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.138747/  2.431521, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.145144/  2.464483, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.122900/  2.515623, val:  69.58%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.124250/  2.531158, val:  69.58%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.112625/  2.626509, val:  68.75%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.108468/  2.621334, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.105955/  2.688521, val:  67.08%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.099282/  2.725507, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.101333/  2.736617, val:  68.33%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.098720/  2.759874, val:  69.17%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.092872/  2.851403, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.089120/  2.855229, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.077590/  2.854327, val:  68.33%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.072767/  2.922274, val:  68.33%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.073325/  2.932111, val:  68.75%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.073827/  3.026763, val:  68.33%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.064708/  3.004169, val:  72.08%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.065049/  3.037349, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.065938/  3.034595, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.059193/  3.085534, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.057866/  3.113441, val:  68.75%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.056905/  3.158618, val:  69.58%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.062444/  3.206569, val:  68.75%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.055094/  3.168176, val:  69.17%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.057350/  3.210254, val:  69.58%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.051656/  3.249365, val:  69.58%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.051449/  3.266230, val:  68.75%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.052062/  3.259743, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.048807/  3.298891, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.049774/  3.325804, val:  69.17%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.045525/  3.308283, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.043285/  3.351806, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.040012/  3.381456, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.039877/  3.388254, val:  72.08%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.041725/  3.464017, val:  70.42%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.036978/  3.433099, val:  72.08%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.037088/  3.402927, val:  72.08%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.037527/  3.472410, val:  70.83%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.035831/  3.494019, val:  70.00%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.035144/  3.513234, val:  69.17%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.036518/  3.530067, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.044056/  3.556553, val:  70.42%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.033856/  3.589930, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.035239/  3.590400, val:  71.25%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.030825/  3.662799, val:  70.42%, val_best:  72.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.032041/  3.625891, val:  72.92%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.030189/  3.698810, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.030668/  3.697097, val:  70.42%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.044260/  3.706729, val:  71.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.033828/  3.747203, val:  72.92%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.033504/  3.775888, val:  72.08%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.029121/  3.803312, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.026881/  3.846243, val:  70.00%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.025050/  3.849633, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.025866/  3.882656, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.026440/  3.884025, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.024448/  3.895056, val:  70.00%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.025393/  3.900929, val:  73.33%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.026282/  3.889643, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.024631/  3.908233, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.024929/  3.964874, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.024208/  3.993883, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.024373/  3.993747, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.027061/  4.032817, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.028562/  4.047827, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.025048/  4.030667, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.022766/  4.047190, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.025265/  4.045099, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.026535/  4.094501, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.027741/  4.109032, val:  69.17%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ef8522f60f442d84f9d8a057a76e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▆▇█▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█████▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█████▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02774</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.69167</td></tr><tr><td>val_loss</td><td>4.10903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-189</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/i622qhr7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/i622qhr7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_051251-i622qhr7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b9y8msns with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_051946-b9y8msns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b9y8msns' target=\"_blank\">faithful-sweep-192</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b9y8msns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b9y8msns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.285162/  2.246997, val:  22.92%, val_best:  22.92%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.194879/  2.158071, val:  31.25%, val_best:  31.25%, tr:  25.23%, tr_best:  25.23%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.058222/  2.027631, val:  46.25%, val_best:  46.25%, tr:  34.22%, tr_best:  34.22%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.892397/  1.895572, val:  45.83%, val_best:  46.25%, tr:  43.31%, tr_best:  43.31%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.736376/  1.784785, val:  49.58%, val_best:  49.58%, tr:  48.62%, tr_best:  48.62%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.602388/  1.693480, val:  52.50%, val_best:  52.50%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.515977/  1.636335, val:  51.25%, val_best:  52.50%, tr:  55.67%, tr_best:  55.67%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.443774/  1.579062, val:  52.08%, val_best:  52.50%, tr:  58.43%, tr_best:  58.43%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.388473/  1.546263, val:  58.75%, val_best:  58.75%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.344815/  1.521111, val:  53.33%, val_best:  58.75%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.307049/  1.492817, val:  55.83%, val_best:  58.75%, tr:  61.08%, tr_best:  61.49%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.272731/  1.469022, val:  57.92%, val_best:  58.75%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.258018/  1.451022, val:  54.58%, val_best:  58.75%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.233566/  1.438328, val:  56.67%, val_best:  58.75%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.193966/  1.431025, val:  55.00%, val_best:  58.75%, tr:  64.66%, tr_best:  65.27%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.180924/  1.417508, val:  57.50%, val_best:  58.75%, tr:  64.15%, tr_best:  65.27%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.156110/  1.403341, val:  55.00%, val_best:  58.75%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.134611/  1.375010, val:  58.75%, val_best:  58.75%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.117950/  1.380535, val:  57.50%, val_best:  58.75%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.107544/  1.371753, val:  56.25%, val_best:  58.75%, tr:  65.37%, tr_best:  67.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.081598/  1.358347, val:  58.33%, val_best:  58.75%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.068302/  1.348091, val:  62.50%, val_best:  62.50%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.066151/  1.353974, val:  58.33%, val_best:  62.50%, tr:  66.39%, tr_best:  69.66%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.042111/  1.341249, val:  61.25%, val_best:  62.50%, tr:  69.25%, tr_best:  69.66%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.020808/  1.323961, val:  61.25%, val_best:  62.50%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.010414/  1.323007, val:  60.00%, val_best:  62.50%, tr:  71.50%, tr_best:  72.01%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.001524/  1.294533, val:  63.33%, val_best:  63.33%, tr:  70.99%, tr_best:  72.01%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.985251/  1.309709, val:  58.75%, val_best:  63.33%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.979259/  1.294789, val:  60.00%, val_best:  63.33%, tr:  73.24%, tr_best:  74.26%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.964533/  1.289025, val:  60.00%, val_best:  63.33%, tr:  73.95%, tr_best:  74.26%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.955157/  1.279537, val:  61.25%, val_best:  63.33%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.946000/  1.293662, val:  61.25%, val_best:  63.33%, tr:  74.16%, tr_best:  74.57%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.932004/  1.306781, val:  61.67%, val_best:  63.33%, tr:  76.30%, tr_best:  76.30%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.924869/  1.293976, val:  63.75%, val_best:  63.75%, tr:  76.20%, tr_best:  76.30%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.916668/  1.267001, val:  64.58%, val_best:  64.58%, tr:  76.20%, tr_best:  76.30%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.906489/  1.280384, val:  60.00%, val_best:  64.58%, tr:  75.79%, tr_best:  76.30%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.898783/  1.274122, val:  59.17%, val_best:  64.58%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.892515/  1.256926, val:  67.08%, val_best:  67.08%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.885288/  1.251080, val:  65.42%, val_best:  67.08%, tr:  79.57%, tr_best:  79.57%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.875862/  1.246953, val:  66.67%, val_best:  67.08%, tr:  78.75%, tr_best:  79.57%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.860077/  1.253816, val:  66.25%, val_best:  67.08%, tr:  77.73%, tr_best:  79.57%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.865173/  1.246533, val:  65.00%, val_best:  67.08%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.847321/  1.251267, val:  62.92%, val_best:  67.08%, tr:  80.49%, tr_best:  80.69%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.842709/  1.258154, val:  65.42%, val_best:  67.08%, tr:  80.90%, tr_best:  80.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.840348/  1.245816, val:  67.08%, val_best:  67.08%, tr:  77.53%, tr_best:  80.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.825578/  1.239936, val:  66.67%, val_best:  67.08%, tr:  80.49%, tr_best:  80.90%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.820034/  1.250315, val:  65.00%, val_best:  67.08%, tr:  80.18%, tr_best:  80.90%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.818604/  1.249998, val:  64.17%, val_best:  67.08%, tr:  80.18%, tr_best:  80.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.811683/  1.235168, val:  66.25%, val_best:  67.08%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.809864/  1.231004, val:  66.25%, val_best:  67.08%, tr:  79.16%, tr_best:  82.43%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.791285/  1.252541, val:  65.00%, val_best:  67.08%, tr:  82.23%, tr_best:  82.43%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.785997/  1.251140, val:  69.17%, val_best:  69.17%, tr:  81.72%, tr_best:  82.43%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.793629/  1.263866, val:  61.25%, val_best:  69.17%, tr:  80.59%, tr_best:  82.43%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.780776/  1.246045, val:  67.92%, val_best:  69.17%, tr:  81.82%, tr_best:  82.43%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.775024/  1.259491, val:  67.92%, val_best:  69.17%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.768174/  1.255573, val:  69.58%, val_best:  69.58%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.752876/  1.267409, val:  68.75%, val_best:  69.58%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.753970/  1.253390, val:  66.67%, val_best:  69.58%, tr:  84.88%, tr_best:  86.11%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.740971/  1.276602, val:  64.17%, val_best:  69.58%, tr:  83.66%, tr_best:  86.11%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.745032/  1.253611, val:  70.00%, val_best:  70.00%, tr:  83.55%, tr_best:  86.11%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.737400/  1.249627, val:  69.17%, val_best:  70.00%, tr:  82.84%, tr_best:  86.11%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.735608/  1.267719, val:  66.25%, val_best:  70.00%, tr:  85.80%, tr_best:  86.11%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.727953/  1.262802, val:  65.00%, val_best:  70.00%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.720249/  1.259190, val:  66.67%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.711095/  1.289083, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.710960/  1.276661, val:  68.75%, val_best:  70.00%, tr:  86.41%, tr_best:  87.74%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.709253/  1.253702, val:  72.92%, val_best:  72.92%, tr:  86.82%, tr_best:  87.74%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.710972/  1.284143, val:  67.50%, val_best:  72.92%, tr:  87.64%, tr_best:  87.74%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.695192/  1.283617, val:  66.25%, val_best:  72.92%, tr:  85.19%, tr_best:  87.74%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.687996/  1.289404, val:  68.75%, val_best:  72.92%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.682339/  1.285546, val:  68.33%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.672306/  1.320168, val:  63.75%, val_best:  72.92%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.670199/  1.314962, val:  64.17%, val_best:  72.92%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.680731/  1.297450, val:  66.67%, val_best:  72.92%, tr:  89.07%, tr_best:  89.17%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.660733/  1.296611, val:  67.92%, val_best:  72.92%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.667978/  1.281122, val:  69.17%, val_best:  72.92%, tr:  87.74%, tr_best:  89.27%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.647320/  1.299213, val:  68.75%, val_best:  72.92%, tr:  88.46%, tr_best:  89.27%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.664804/  1.306831, val:  67.08%, val_best:  72.92%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.656877/  1.288231, val:  70.83%, val_best:  72.92%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.643267/  1.294443, val:  66.25%, val_best:  72.92%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.633116/  1.315517, val:  66.25%, val_best:  72.92%, tr:  90.91%, tr_best:  91.01%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.642006/  1.296139, val:  67.08%, val_best:  72.92%, tr:  88.97%, tr_best:  91.01%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.630239/  1.316738, val:  69.17%, val_best:  72.92%, tr:  90.30%, tr_best:  91.01%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.630062/  1.321607, val:  70.42%, val_best:  72.92%, tr:  90.91%, tr_best:  91.01%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.621428/  1.305100, val:  67.08%, val_best:  72.92%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.617052/  1.328486, val:  67.92%, val_best:  72.92%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.616524/  1.313845, val:  70.83%, val_best:  72.92%, tr:  91.73%, tr_best:  92.44%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.610247/  1.314419, val:  70.00%, val_best:  72.92%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.599308/  1.327938, val:  65.83%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.592963/  1.348696, val:  65.00%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.604122/  1.302993, val:  70.83%, val_best:  72.92%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.590591/  1.321245, val:  69.58%, val_best:  72.92%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.595547/  1.374575, val:  66.25%, val_best:  72.92%, tr:  91.52%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.595471/  1.346859, val:  67.08%, val_best:  72.92%, tr:  92.03%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.588534/  1.365387, val:  65.83%, val_best:  72.92%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.582649/  1.358145, val:  66.67%, val_best:  72.92%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.582228/  1.371293, val:  68.33%, val_best:  72.92%, tr:  93.05%, tr_best:  93.46%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.583159/  1.341817, val:  70.42%, val_best:  72.92%, tr:  91.42%, tr_best:  93.46%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.570048/  1.375337, val:  66.67%, val_best:  72.92%, tr:  92.95%, tr_best:  93.46%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.585408/  1.349667, val:  68.33%, val_best:  72.92%, tr:  93.46%, tr_best:  93.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c92d4a5dc184eb1b6169c52ba3ef49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▄▃▅▆▃▄▆▅▇▆▅▅▆▆▅█▇▆▆▆▆▇█▇▇▇▅▇▇▅▇▇▇▇██▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▆▇▆█▇▇█▇▇▇█▇█▇███▇██▇███▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▆▇▆█▇▇█▇▇▇█▇█▇███▇██▇███▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▅▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.93463</td></tr><tr><td>tr_epoch_loss</td><td>0.58541</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.68333</td></tr><tr><td>val_loss</td><td>1.34967</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-192</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b9y8msns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b9y8msns</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_051946-b9y8msns/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wu46dyvi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_052555-wu46dyvi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wu46dyvi' target=\"_blank\">royal-sweep-193</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wu46dyvi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wu46dyvi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.249688/  2.086843, val:  30.42%, val_best:  30.42%, tr:  13.07%, tr_best:  13.07%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.765588/  1.660657, val:  55.42%, val_best:  55.42%, tr:  47.09%, tr_best:  47.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.483854/  1.581530, val:  55.00%, val_best:  55.42%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.386709/  1.594645, val:  57.92%, val_best:  57.92%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.345829/  1.579688, val:  58.33%, val_best:  58.33%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.299947/  1.525339, val:  61.67%, val_best:  61.67%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.261400/  1.525917, val:  58.75%, val_best:  61.67%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.233940/  1.508984, val:  60.42%, val_best:  61.67%, tr:  66.70%, tr_best:  68.54%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.201495/  1.499626, val:  61.67%, val_best:  61.67%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.193981/  1.533095, val:  58.33%, val_best:  61.67%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.196877/  1.543401, val:  55.00%, val_best:  61.67%, tr:  68.54%, tr_best:  69.05%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.175961/  1.516275, val:  59.17%, val_best:  61.67%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.181185/  1.537432, val:  61.25%, val_best:  61.67%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.179085/  1.576012, val:  62.92%, val_best:  62.92%, tr:  69.87%, tr_best:  72.52%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.138338/  1.677289, val:  59.17%, val_best:  62.92%, tr:  72.11%, tr_best:  72.52%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.149489/  1.625042, val:  64.17%, val_best:  64.17%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.163525/  1.611856, val:  62.08%, val_best:  64.17%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.125450/  1.625416, val:  63.75%, val_best:  64.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.134050/  1.738672, val:  58.75%, val_best:  64.17%, tr:  75.89%, tr_best:  76.81%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.153451/  1.678366, val:  60.83%, val_best:  64.17%, tr:  74.67%, tr_best:  76.81%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.135502/  1.701033, val:  58.75%, val_best:  64.17%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.130076/  1.720966, val:  61.67%, val_best:  64.17%, tr:  76.61%, tr_best:  76.92%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.163562/  1.741799, val:  64.17%, val_best:  64.17%, tr:  75.59%, tr_best:  76.92%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.146374/  1.730862, val:  60.83%, val_best:  64.17%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.123061/  1.792816, val:  62.08%, val_best:  64.17%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.134208/  1.787250, val:  63.75%, val_best:  64.17%, tr:  77.53%, tr_best:  79.47%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.143269/  1.814676, val:  62.50%, val_best:  64.17%, tr:  78.65%, tr_best:  79.47%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.132403/  1.890875, val:  61.67%, val_best:  64.17%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.153525/  1.827217, val:  65.42%, val_best:  65.42%, tr:  79.57%, tr_best:  79.78%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.143086/  1.949143, val:  60.42%, val_best:  65.42%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.139841/  1.978809, val:  58.33%, val_best:  65.42%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.178879/  1.964509, val:  59.58%, val_best:  65.42%, tr:  78.86%, tr_best:  81.41%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.184489/  2.049477, val:  63.75%, val_best:  65.42%, tr:  80.18%, tr_best:  81.41%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.183146/  2.074434, val:  62.50%, val_best:  65.42%, tr:  80.49%, tr_best:  81.41%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.178063/  2.067715, val:  59.58%, val_best:  65.42%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.209885/  2.140364, val:  57.50%, val_best:  65.42%, tr:  78.04%, tr_best:  81.61%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.183079/  2.095544, val:  62.08%, val_best:  65.42%, tr:  80.90%, tr_best:  81.61%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.184770/  2.146307, val:  61.67%, val_best:  65.42%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.217671/  2.159943, val:  60.83%, val_best:  65.42%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.217097/  2.229299, val:  60.00%, val_best:  65.42%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.236371/  2.309313, val:  62.50%, val_best:  65.42%, tr:  81.51%, tr_best:  83.45%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.224400/  2.302989, val:  56.25%, val_best:  65.42%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.202619/  2.264207, val:  63.33%, val_best:  65.42%, tr:  84.07%, tr_best:  85.19%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.202395/  2.357728, val:  61.67%, val_best:  65.42%, tr:  83.96%, tr_best:  85.19%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.199564/  2.369157, val:  60.83%, val_best:  65.42%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.179768/  2.413094, val:  62.08%, val_best:  65.42%, tr:  85.50%, tr_best:  85.60%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.187522/  2.424812, val:  65.00%, val_best:  65.42%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.204694/  2.461926, val:  62.50%, val_best:  65.42%, tr:  85.60%, tr_best:  86.93%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.246797/  2.442895, val:  63.33%, val_best:  65.42%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.225912/  2.457179, val:  64.58%, val_best:  65.42%, tr:  84.37%, tr_best:  87.03%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.215997/  2.562309, val:  62.08%, val_best:  65.42%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.267083/  2.561768, val:  62.08%, val_best:  65.42%, tr:  83.25%, tr_best:  87.03%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.197785/  2.557398, val:  58.75%, val_best:  65.42%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.242027/  2.560267, val:  64.17%, val_best:  65.42%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.243283/  2.622912, val:  62.50%, val_best:  65.42%, tr:  87.03%, tr_best:  88.56%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.229242/  2.689175, val:  58.75%, val_best:  65.42%, tr:  87.03%, tr_best:  88.56%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.247518/  2.768139, val:  56.25%, val_best:  65.42%, tr:  87.33%, tr_best:  88.56%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.287959/  2.646809, val:  61.25%, val_best:  65.42%, tr:  87.64%, tr_best:  88.56%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.263312/  2.755226, val:  62.08%, val_best:  65.42%, tr:  86.11%, tr_best:  88.56%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.266731/  2.791077, val:  62.50%, val_best:  65.42%, tr:  87.44%, tr_best:  88.56%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.267159/  2.786042, val:  60.42%, val_best:  65.42%, tr:  87.95%, tr_best:  88.56%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.294323/  2.783850, val:  61.67%, val_best:  65.42%, tr:  88.46%, tr_best:  88.56%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.274477/  2.806093, val:  64.58%, val_best:  65.42%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.265724/  2.821729, val:  61.67%, val_best:  65.42%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.290131/  2.991645, val:  61.67%, val_best:  65.42%, tr:  86.21%, tr_best:  88.97%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.273423/  2.865278, val:  65.00%, val_best:  65.42%, tr:  87.74%, tr_best:  88.97%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.292002/  2.951731, val:  63.75%, val_best:  65.42%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.305833/  2.953071, val:  63.75%, val_best:  65.42%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.269004/  3.147831, val:  62.92%, val_best:  65.42%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.288325/  3.016754, val:  63.33%, val_best:  65.42%, tr:  87.95%, tr_best:  89.79%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.308914/  2.982117, val:  65.00%, val_best:  65.42%, tr:  89.38%, tr_best:  89.79%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.310362/  3.198519, val:  60.83%, val_best:  65.42%, tr:  88.76%, tr_best:  89.79%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.307446/  3.240734, val:  60.83%, val_best:  65.42%, tr:  88.36%, tr_best:  89.79%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.399593/  3.159294, val:  60.83%, val_best:  65.42%, tr:  85.50%, tr_best:  89.79%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.351373/  3.231224, val:  62.08%, val_best:  65.42%, tr:  86.72%, tr_best:  89.79%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.369988/  3.302769, val:  60.00%, val_best:  65.42%, tr:  87.03%, tr_best:  89.79%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.336734/  3.356052, val:  61.67%, val_best:  65.42%, tr:  87.54%, tr_best:  89.79%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.394391/  3.374965, val:  65.83%, val_best:  65.83%, tr:  86.11%, tr_best:  89.79%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.372764/  3.351156, val:  65.00%, val_best:  65.83%, tr:  87.84%, tr_best:  89.79%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.346701/  3.323825, val:  64.58%, val_best:  65.83%, tr:  89.58%, tr_best:  89.79%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.300065/  3.434783, val:  64.17%, val_best:  65.83%, tr:  89.17%, tr_best:  89.79%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.351488/  3.398349, val:  64.58%, val_best:  65.83%, tr:  89.07%, tr_best:  89.79%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.381360/  3.553397, val:  61.67%, val_best:  65.83%, tr:  87.74%, tr_best:  89.79%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.383744/  3.733177, val:  61.25%, val_best:  65.83%, tr:  88.15%, tr_best:  89.79%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.378951/  3.476229, val:  67.92%, val_best:  67.92%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.369744/  3.540482, val:  62.92%, val_best:  67.92%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.385034/  3.730007, val:  62.50%, val_best:  67.92%, tr:  91.11%, tr_best:  92.34%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.408858/  3.585234, val:  67.08%, val_best:  67.92%, tr:  91.52%, tr_best:  92.34%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.381719/  3.715673, val:  66.67%, val_best:  67.92%, tr:  91.32%, tr_best:  92.34%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.393335/  3.793804, val:  62.92%, val_best:  67.92%, tr:  91.83%, tr_best:  92.34%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.404123/  3.640363, val:  67.08%, val_best:  67.92%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.403269/  3.821787, val:  60.42%, val_best:  67.92%, tr:  90.19%, tr_best:  92.65%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.398819/  3.808229, val:  62.08%, val_best:  67.92%, tr:  90.19%, tr_best:  92.65%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.417491/  3.754564, val:  63.75%, val_best:  67.92%, tr:  89.27%, tr_best:  92.65%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.446484/  3.903407, val:  65.00%, val_best:  67.92%, tr:  90.81%, tr_best:  92.65%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.450996/  3.838077, val:  65.00%, val_best:  67.92%, tr:  91.32%, tr_best:  92.65%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.427751/  4.144279, val:  61.67%, val_best:  67.92%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.475739/  3.919349, val:  67.50%, val_best:  67.92%, tr:  89.58%, tr_best:  93.46%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.432446/  4.001995, val:  63.33%, val_best:  67.92%, tr:  91.42%, tr_best:  93.46%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.489653/  4.055667, val:  63.75%, val_best:  67.92%, tr:  90.70%, tr_best:  93.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8afa6b23d84f23b51638cc5a2b2eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▃▃▄▅▁▄▆▇█▆▆▃▇▆▆▇▇▅█▆▇█▆▆▇█▆▆█▄█▆▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████████▇████████</td></tr><tr><td>tr_epoch_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▂▁▂▂▂▂▂▂▂▂▃▃▂▃▃▃▃▃▃▃</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇█</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.90705</td></tr><tr><td>tr_epoch_loss</td><td>1.48965</td></tr><tr><td>val_acc_best</td><td>0.67917</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.05567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-193</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wu46dyvi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wu46dyvi</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_052555-wu46dyvi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s9rmbyjh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_053249-s9rmbyjh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s9rmbyjh' target=\"_blank\">confused-sweep-195</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s9rmbyjh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s9rmbyjh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.190902/  1.961192, val:  35.00%, val_best:  35.00%, tr:  19.10%, tr_best:  19.10%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.618378/  1.554988, val:  57.50%, val_best:  57.50%, tr:  50.46%, tr_best:  50.46%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.339626/  1.455492, val:  57.50%, val_best:  57.50%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.192087/  1.428398, val:  55.83%, val_best:  57.50%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.098621/  1.333594, val:  59.58%, val_best:  59.58%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.023855/  1.293839, val:  60.83%, val_best:  60.83%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.940010/  1.246892, val:  63.33%, val_best:  63.33%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.899955/  1.226216, val:  64.17%, val_best:  64.17%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.846104/  1.242660, val:  66.25%, val_best:  66.25%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.812283/  1.266602, val:  68.75%, val_best:  68.75%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.787167/  1.338933, val:  62.50%, val_best:  68.75%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.738453/  1.209105, val:  71.25%, val_best:  71.25%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.731595/  1.211331, val:  67.08%, val_best:  71.25%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.697051/  1.338130, val:  64.17%, val_best:  71.25%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.670362/  1.422701, val:  64.58%, val_best:  71.25%, tr:  81.92%, tr_best:  82.12%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.650281/  1.416575, val:  66.67%, val_best:  71.25%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.651784/  1.285193, val:  70.42%, val_best:  71.25%, tr:  83.25%, tr_best:  84.78%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.597441/  1.382636, val:  67.08%, val_best:  71.25%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.587305/  1.401168, val:  65.83%, val_best:  71.25%, tr:  86.93%, tr_best:  88.66%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.574933/  1.386433, val:  72.92%, val_best:  72.92%, tr:  87.74%, tr_best:  88.66%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.525687/  1.557779, val:  62.92%, val_best:  72.92%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.509551/  1.594126, val:  64.17%, val_best:  72.92%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.482590/  1.570524, val:  68.33%, val_best:  72.92%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.468441/  1.656544, val:  70.00%, val_best:  72.92%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.434325/  1.715924, val:  66.25%, val_best:  72.92%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.408511/  1.743608, val:  68.33%, val_best:  72.92%, tr:  96.42%, tr_best:  96.83%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.450720/  1.790374, val:  70.42%, val_best:  72.92%, tr:  93.97%, tr_best:  96.83%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.402821/  1.856260, val:  70.83%, val_best:  72.92%, tr:  96.32%, tr_best:  96.83%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.386557/  1.815409, val:  70.83%, val_best:  72.92%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.377984/  1.988874, val:  67.92%, val_best:  72.92%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.334292/  1.940450, val:  69.17%, val_best:  72.92%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.334084/  1.947743, val:  73.33%, val_best:  73.33%, tr:  97.65%, tr_best:  97.75%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.359850/  2.006987, val:  71.67%, val_best:  73.33%, tr:  96.12%, tr_best:  97.75%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.366063/  1.894424, val:  73.33%, val_best:  73.33%, tr:  95.61%, tr_best:  97.75%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.326891/  2.092924, val:  71.67%, val_best:  73.33%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.310706/  2.167902, val:  69.58%, val_best:  73.33%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.295132/  2.111407, val:  70.83%, val_best:  73.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.249180/  2.296690, val:  71.25%, val_best:  73.33%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.257953/  2.349625, val:  69.17%, val_best:  73.33%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.285537/  2.252834, val:  72.50%, val_best:  73.33%, tr:  98.47%, tr_best:  99.08%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.228045/  2.373467, val:  70.00%, val_best:  73.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.232944/  2.436866, val:  72.08%, val_best:  73.33%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.190837/  2.439079, val:  72.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.184123/  2.422801, val:  73.75%, val_best:  73.75%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.194245/  2.420772, val:  76.25%, val_best:  76.25%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.156602/  2.495857, val:  73.75%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.201811/  2.482832, val:  73.75%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.182733/  2.522701, val:  72.50%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.181503/  2.588482, val:  72.50%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.158014/  2.605100, val:  71.25%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.144041/  2.691577, val:  72.50%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.164789/  2.650766, val:  74.58%, val_best:  76.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.137708/  2.750324, val:  70.83%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.136509/  2.690194, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.124814/  2.688763, val:  75.42%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.122494/  2.806058, val:  74.17%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.102121/  2.943331, val:  70.00%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.103498/  2.815566, val:  72.92%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.103790/  2.884426, val:  72.92%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.106815/  2.989863, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.136324/  2.893096, val:  74.58%, val_best:  76.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.115678/  2.995101, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.099014/  2.905687, val:  74.17%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.088169/  2.998097, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.095353/  3.024362, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.097337/  3.052035, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.080141/  3.104299, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.069949/  3.182161, val:  70.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.066385/  3.229569, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.061608/  3.198809, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.073361/  3.296443, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.068784/  3.266131, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.057088/  3.407590, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.061484/  3.374448, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.064212/  3.411427, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.052157/  3.400023, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.049832/  3.373211, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.052863/  3.437601, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.069199/  3.503913, val:  68.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.050329/  3.440759, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.038431/  3.455597, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.032672/  3.472691, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.051298/  3.477180, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.040990/  3.592794, val:  69.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.042725/  3.553339, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.061819/  3.630310, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.069919/  3.636790, val:  73.75%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.077374/  3.579933, val:  74.17%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.070083/  3.617106, val:  70.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.050126/  3.639291, val:  70.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.047511/  3.611835, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.043734/  3.618654, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.039092/  3.672755, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.030298/  3.647829, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.034990/  3.720583, val:  71.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.021266/  3.809618, val:  70.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.027448/  3.779503, val:  70.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.030007/  3.803383, val:  70.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.028156/  3.782381, val:  70.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.022618/  3.855109, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f360437670e74d059179666e7e1995f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▂▃▅▃▇▁▇▇███▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▇▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇█▇██▇▇█▇▇▇▇█▇█▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▇▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇█▇██▇▇█▇▇▇▇█▇█▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▁▁▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02262</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.72083</td></tr><tr><td>val_loss</td><td>3.85511</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-195</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s9rmbyjh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s9rmbyjh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_053249-s9rmbyjh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 24l7uwmx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_053857-24l7uwmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/24l7uwmx' target=\"_blank\">golden-sweep-198</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/24l7uwmx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/24l7uwmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.303858/  2.292209, val:  15.00%, val_best:  15.00%, tr:   9.50%, tr_best:   9.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.168602/  1.992253, val:  37.08%, val_best:  37.08%, tr:  21.86%, tr_best:  21.86%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.713968/  1.647874, val:  47.92%, val_best:  47.92%, tr:  47.19%, tr_best:  47.19%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.452438/  1.512744, val:  52.50%, val_best:  52.50%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.337565/  1.458885, val:  53.75%, val_best:  53.75%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.261509/  1.392988, val:  58.33%, val_best:  58.33%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.216334/  1.368062, val:  57.08%, val_best:  58.33%, tr:  61.70%, tr_best:  61.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.174295/  1.341409, val:  59.17%, val_best:  59.17%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.129948/  1.313629, val:  62.92%, val_best:  62.92%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.107322/  1.306988, val:  62.08%, val_best:  62.92%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.081254/  1.321232, val:  61.25%, val_best:  62.92%, tr:  66.29%, tr_best:  67.72%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054062/  1.280520, val:  63.75%, val_best:  63.75%, tr:  65.68%, tr_best:  67.72%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.041023/  1.279126, val:  62.50%, val_best:  63.75%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.033543/  1.278092, val:  65.00%, val_best:  65.00%, tr:  68.54%, tr_best:  69.05%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.989860/  1.329947, val:  61.25%, val_best:  65.00%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980014/  1.254902, val:  67.50%, val_best:  67.50%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.966145/  1.250206, val:  67.50%, val_best:  67.50%, tr:  70.79%, tr_best:  71.50%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.941172/  1.227785, val:  68.75%, val_best:  68.75%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.921471/  1.277983, val:  64.17%, val_best:  68.75%, tr:  73.95%, tr_best:  75.38%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.918174/  1.272566, val:  62.08%, val_best:  68.75%, tr:  72.52%, tr_best:  75.38%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.890179/  1.251075, val:  65.42%, val_best:  68.75%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.884067/  1.233335, val:  68.33%, val_best:  68.75%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.884414/  1.243220, val:  69.58%, val_best:  69.58%, tr:  74.97%, tr_best:  77.12%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.849258/  1.236265, val:  65.83%, val_best:  69.58%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.836306/  1.246835, val:  64.17%, val_best:  69.58%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.819415/  1.236825, val:  68.33%, val_best:  69.58%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.810173/  1.229143, val:  65.83%, val_best:  69.58%, tr:  80.49%, tr_best:  81.51%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.787963/  1.263792, val:  65.00%, val_best:  69.58%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.788478/  1.233977, val:  70.00%, val_best:  70.00%, tr:  83.35%, tr_best:  83.86%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.757254/  1.276831, val:  64.17%, val_best:  70.00%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.748509/  1.268789, val:  65.83%, val_best:  70.00%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.759583/  1.291382, val:  64.17%, val_best:  70.00%, tr:  82.94%, tr_best:  86.82%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.737192/  1.268540, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  86.82%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.727287/  1.283121, val:  69.17%, val_best:  70.00%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.707743/  1.300245, val:  65.42%, val_best:  70.00%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.714024/  1.307082, val:  66.67%, val_best:  70.00%, tr:  87.13%, tr_best:  87.95%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.684764/  1.297185, val:  67.92%, val_best:  70.00%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.676598/  1.297166, val:  69.58%, val_best:  70.00%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.673878/  1.310000, val:  67.08%, val_best:  70.00%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.661789/  1.311705, val:  66.25%, val_best:  70.00%, tr:  91.01%, tr_best:  91.22%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.649481/  1.337699, val:  66.67%, val_best:  70.00%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.651048/  1.323981, val:  67.92%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.628668/  1.346223, val:  65.42%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.628663/  1.370083, val:  69.58%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.616885/  1.360376, val:  65.83%, val_best:  70.00%, tr:  91.93%, tr_best:  92.54%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.608133/  1.369783, val:  69.17%, val_best:  70.00%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594606/  1.390755, val:  66.67%, val_best:  70.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.593019/  1.397860, val:  66.25%, val_best:  70.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.591661/  1.384358, val:  66.25%, val_best:  70.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.588464/  1.404226, val:  67.08%, val_best:  70.00%, tr:  94.38%, tr_best:  95.20%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.578967/  1.419142, val:  66.67%, val_best:  70.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.568588/  1.436009, val:  68.75%, val_best:  70.00%, tr:  95.10%, tr_best:  95.20%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.557804/  1.456308, val:  65.42%, val_best:  70.00%, tr:  94.59%, tr_best:  95.20%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.563919/  1.424584, val:  66.67%, val_best:  70.00%, tr:  94.79%, tr_best:  95.20%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.542692/  1.452152, val:  68.75%, val_best:  70.00%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.545610/  1.446335, val:  67.08%, val_best:  70.00%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.534482/  1.477798, val:  67.08%, val_best:  70.00%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.525847/  1.470864, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.513014/  1.486675, val:  68.33%, val_best:  70.00%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.511854/  1.482582, val:  69.17%, val_best:  70.00%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.512199/  1.495999, val:  68.75%, val_best:  70.00%, tr:  96.12%, tr_best:  96.73%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.503474/  1.504888, val:  66.25%, val_best:  70.00%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.504339/  1.527805, val:  66.25%, val_best:  70.00%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.493393/  1.517191, val:  67.92%, val_best:  70.00%, tr:  96.73%, tr_best:  97.34%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.494963/  1.551601, val:  67.50%, val_best:  70.00%, tr:  96.63%, tr_best:  97.34%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.488975/  1.538453, val:  69.58%, val_best:  70.00%, tr:  96.63%, tr_best:  97.34%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.486834/  1.527778, val:  69.58%, val_best:  70.00%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.488077/  1.539855, val:  67.08%, val_best:  70.00%, tr:  97.34%, tr_best:  97.45%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.473360/  1.537810, val:  69.17%, val_best:  70.00%, tr:  97.04%, tr_best:  97.45%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.470352/  1.574325, val:  66.25%, val_best:  70.00%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.464616/  1.567242, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.464008/  1.585060, val:  67.50%, val_best:  70.00%, tr:  97.04%, tr_best:  98.26%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.461141/  1.603534, val:  66.25%, val_best:  70.00%, tr:  97.34%, tr_best:  98.26%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.463213/  1.577845, val:  68.33%, val_best:  70.00%, tr:  98.06%, tr_best:  98.26%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.450254/  1.598994, val:  67.92%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.448290/  1.590328, val:  69.17%, val_best:  70.00%, tr:  97.75%, tr_best:  98.37%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.434239/  1.624148, val:  67.08%, val_best:  70.00%, tr:  97.85%, tr_best:  98.37%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.440506/  1.625061, val:  66.67%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.446341/  1.627461, val:  69.17%, val_best:  70.00%, tr:  98.06%, tr_best:  98.37%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.422506/  1.618093, val:  70.42%, val_best:  70.42%, tr:  97.96%, tr_best:  98.37%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.415443/  1.639280, val:  66.67%, val_best:  70.42%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.421654/  1.637445, val:  69.17%, val_best:  70.42%, tr:  97.96%, tr_best:  98.37%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.417395/  1.652725, val:  66.25%, val_best:  70.42%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.412329/  1.672570, val:  69.17%, val_best:  70.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.402966/  1.650104, val:  68.75%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406237/  1.674207, val:  70.00%, val_best:  70.42%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.400451/  1.670149, val:  69.17%, val_best:  70.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.398935/  1.708671, val:  69.17%, val_best:  70.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.391107/  1.679298, val:  69.17%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.383078/  1.702215, val:  66.67%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.393304/  1.689408, val:  70.00%, val_best:  70.42%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.382427/  1.718399, val:  70.00%, val_best:  70.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.379787/  1.727420, val:  66.25%, val_best:  70.42%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.382630/  1.709301, val:  69.17%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.375821/  1.759670, val:  69.58%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.375501/  1.738552, val:  68.33%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.372641/  1.773629, val:  68.75%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.369117/  1.741970, val:  71.25%, val_best:  71.25%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.358245/  1.755338, val:  68.33%, val_best:  71.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.368107/  1.771012, val:  70.00%, val_best:  71.25%, tr:  99.28%, tr_best:  99.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a35e0ad03643f390a2df3f9d23e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▃▃▅▆▂▄▆▇▇▇▆▆▇█▇█▇██▇██████▆█▇▆██▇▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇█▇█▇█▇██▇▇██</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇█▇█▇█▇██▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99285</td></tr><tr><td>tr_epoch_loss</td><td>0.36811</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.77101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-198</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/24l7uwmx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/24l7uwmx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_053857-24l7uwmx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ly4xgrwu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_054606-ly4xgrwu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ly4xgrwu' target=\"_blank\">divine-sweep-199</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ly4xgrwu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ly4xgrwu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 26.132973/ 51.684196, val:  37.08%, val_best:  37.08%, tr:  29.52%, tr_best:  29.52%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 36.846046/ 50.827095, val:  23.33%, val_best:  37.08%, tr:  45.05%, tr_best:  45.05%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 33.196102/ 29.059265, val:  41.25%, val_best:  41.25%, tr:  49.34%, tr_best:  49.34%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 19.378311/ 21.690306, val:  47.50%, val_best:  47.50%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 25.303928/ 31.971518, val:  52.50%, val_best:  52.50%, tr:  52.50%, tr_best:  57.30%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 21.920509/ 34.592876, val:  40.42%, val_best:  52.50%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 25.152653/ 30.638510, val:  57.92%, val_best:  57.92%, tr:  59.75%, tr_best:  59.75%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 19.254681/ 33.225281, val:  47.92%, val_best:  57.92%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 23.442484/ 32.875721, val:  54.58%, val_best:  57.92%, tr:  60.98%, tr_best:  64.25%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 22.615826/ 19.396692, val:  61.25%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 16.707026/ 31.429382, val:  57.08%, val_best:  61.25%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 12.304878/ 39.947418, val:  49.58%, val_best:  61.25%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 22.985704/ 35.006382, val:  59.58%, val_best:  61.25%, tr:  71.81%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 12.415695/ 27.734907, val:  62.92%, val_best:  62.92%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  9.720244/ 27.716848, val:  66.67%, val_best:  66.67%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  9.233609/ 32.303143, val:  54.58%, val_best:  66.67%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  8.048508/ 26.834940, val:  68.75%, val_best:  68.75%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  7.050452/ 25.689859, val:  70.42%, val_best:  70.42%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  6.233935/ 31.080807, val:  62.92%, val_best:  70.42%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  5.450795/ 27.704905, val:  64.58%, val_best:  70.42%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  6.562860/ 30.416216, val:  72.08%, val_best:  72.08%, tr:  91.62%, tr_best:  93.36%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  5.079121/ 35.516953, val:  62.50%, val_best:  72.08%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  3.678463/ 37.203461, val:  63.75%, val_best:  72.08%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  4.772810/ 34.548965, val:  70.42%, val_best:  72.08%, tr:  95.91%, tr_best:  96.94%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  3.653251/ 33.534531, val:  69.58%, val_best:  72.08%, tr:  96.53%, tr_best:  96.94%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  2.416392/ 38.127552, val:  64.17%, val_best:  72.08%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  2.190498/ 31.242466, val:  71.25%, val_best:  72.08%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  1.918946/ 36.177803, val:  70.00%, val_best:  72.08%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  1.191290/ 34.722424, val:  70.83%, val_best:  72.08%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  1.143528/ 34.434986, val:  74.58%, val_best:  74.58%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.814933/ 32.568718, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.868799/ 31.330269, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  1.081200/ 35.858398, val:  71.25%, val_best:  75.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.900562/ 37.246216, val:  69.58%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.879448/ 35.617580, val:  73.33%, val_best:  75.00%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.742277/ 34.424496, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.367103/ 33.181683, val:  76.67%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.393107/ 34.373085, val:  71.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.382592/ 33.771439, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.414182/ 34.021568, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.513997/ 33.109287, val:  74.17%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.284731/ 32.647270, val:  73.75%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.441077/ 34.052692, val:  73.75%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.376988/ 33.958584, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.378570/ 37.544182, val:  70.83%, val_best:  76.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.290927/ 35.176514, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.179240/ 36.174847, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.259603/ 35.442406, val:  74.17%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.188209/ 35.871284, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.187067/ 38.352886, val:  70.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.244252/ 35.835526, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.110462/ 36.354595, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.209247/ 37.039715, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.258929/ 38.945496, val:  70.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.193393/ 36.619747, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.139499/ 38.184597, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.150313/ 36.664528, val:  74.17%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.143028/ 38.511688, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.090697/ 37.885620, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.071173/ 38.495060, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.098225/ 36.911076, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.097410/ 37.910046, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.088862/ 36.434052, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.100115/ 36.703205, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.061673/ 36.475140, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.098862/ 37.363789, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.098402/ 37.822163, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.050815/ 37.227333, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.064347/ 38.296196, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.183211/ 40.219643, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.069266/ 38.016445, val:  71.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.051548/ 37.299911, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.122993/ 37.160137, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.028107/ 37.896099, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.052942/ 37.161724, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.059924/ 36.878666, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.100946/ 38.374538, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.070094/ 38.497753, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.101621/ 38.227215, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.063958/ 36.881088, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.063980/ 36.793663, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.102710/ 38.922009, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.075492/ 38.212364, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.061001/ 39.566429, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.055357/ 39.518322, val:  71.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.031066/ 38.462189, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.015166/ 39.368111, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.015630/ 38.984997, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.059743/ 38.832180, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.051743/ 38.824146, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.058719/ 38.187336, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.082293/ 41.317585, val:  70.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.034188/ 39.548897, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.047424/ 39.440281, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.025301/ 38.788792, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.019481/ 39.280758, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.037831/ 40.032566, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.034817/ 38.042641, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.029285/ 39.744186, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.015354/ 40.409492, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fc17111e7f47ddac75b04ffc4ba3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▂▄▄▆▆▆████▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▃▅▅▆▇▆▆▇▇█▇▇▇██▇█▇███████▇█████▇█████</td></tr><tr><td>tr_acc</td><td>▁▃▃▄▅▅▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▅▆▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▅▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▃▅▅▆▇▆▆▇▇█▇▇▇██▇█▇███████▇█████▇█████</td></tr><tr><td>val_loss</td><td>█▃▄▄▁▄▃▂▃▄▄▄▄▅▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01535</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>40.40949</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-199</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ly4xgrwu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ly4xgrwu</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_054606-ly4xgrwu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2l9v75yr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_055253-2l9v75yr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l9v75yr' target=\"_blank\">graceful-sweep-202</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l9v75yr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l9v75yr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.212517/  3.442651, val:  32.92%, val_best:  32.92%, tr:  33.50%, tr_best:  33.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.417575/  2.823373, val:  44.58%, val_best:  44.58%, tr:  47.80%, tr_best:  47.80%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.423273/  2.694598, val:  49.17%, val_best:  49.17%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.065602/  2.410695, val:  48.75%, val_best:  49.17%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.708500/  2.535792, val:  57.08%, val_best:  57.08%, tr:  63.53%, tr_best:  63.53%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.829138/  2.796714, val:  50.83%, val_best:  57.08%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.048142/  2.108891, val:  66.67%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.861757/  2.706281, val:  48.75%, val_best:  66.67%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.806389/  2.318466, val:  56.25%, val_best:  66.67%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.014609/  2.692507, val:  65.42%, val_best:  66.67%, tr:  84.47%, tr_best:  84.78%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.643528/  2.359138, val:  61.67%, val_best:  66.67%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.530232/  2.486243, val:  66.25%, val_best:  66.67%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.438304/  2.105812, val:  74.58%, val_best:  74.58%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.301887/  2.175591, val:  75.00%, val_best:  75.00%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.233666/  2.331037, val:  70.83%, val_best:  75.00%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.166850/  2.320513, val:  71.25%, val_best:  75.00%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.167203/  2.723333, val:  69.58%, val_best:  75.00%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.178072/  2.291267, val:  77.50%, val_best:  77.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.131346/  2.321377, val:  80.00%, val_best:  80.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.086724/  2.383587, val:  76.25%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.051204/  2.432794, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.037810/  2.466272, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.031024/  2.522445, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.031448/  2.558514, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.023237/  2.587413, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.019419/  2.617845, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.015912/  2.665649, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.013581/  2.731645, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.010726/  2.712156, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.010324/  2.733888, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.008792/  2.769008, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.007517/  2.776324, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.006522/  2.809243, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.006266/  2.849944, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.005794/  2.860604, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.005730/  2.856730, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.005027/  2.866205, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.005169/  2.866027, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.005859/  2.898084, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.004406/  2.880821, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.003911/  2.891849, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.003509/  2.929490, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.004684/  2.958037, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.004319/  2.953186, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.003866/  2.938460, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.003509/  2.963450, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.002893/  2.984104, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.002713/  2.985497, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002475/  2.989914, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002295/  2.974999, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.002710/  2.992969, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.002487/  3.026740, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.002229/  3.030620, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.002215/  3.025777, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.002279/  3.030626, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.002045/  3.025046, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.002039/  3.038850, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.002168/  3.041540, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001922/  3.092152, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.001714/  3.081734, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001664/  3.080120, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001844/  3.086825, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001761/  3.078923, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001660/  3.080009, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001495/  3.100622, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001455/  3.121654, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001426/  3.133242, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001505/  3.130351, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001468/  3.124062, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001387/  3.140421, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001467/  3.141939, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001327/  3.152230, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001296/  3.135962, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001249/  3.147618, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.001446/  3.168566, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.001444/  3.162172, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001388/  3.168259, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.001378/  3.178508, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.001635/  3.152913, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.001467/  3.161248, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.001266/  3.168734, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001111/  3.181070, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.001176/  3.182685, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.001098/  3.184164, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.001161/  3.205371, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.001206/  3.200452, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.001107/  3.204673, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.001020/  3.213379, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.001029/  3.221446, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000975/  3.220671, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000955/  3.230337, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000979/  3.234960, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000989/  3.247226, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.001209/  3.243289, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.001118/  3.258136, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000944/  3.254681, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000944/  3.249970, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000912/  3.263617, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000931/  3.245214, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000896/  3.270121, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81292105cd9647fbb5dcbbac248d38ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▇▇███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▃▆▇▇█▇█████▇██████████▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▃▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▃▆▇▇█▇█████▇██████████▇██████████████</td></tr><tr><td>val_loss</td><td>█▄▃▄▄▁▂▂▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0009</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>3.27012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-202</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l9v75yr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l9v75yr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_055253-2l9v75yr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8x86vawf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_055955-8x86vawf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8x86vawf' target=\"_blank\">laced-sweep-204</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8x86vawf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8x86vawf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.302143/  2.275703, val:  12.92%, val_best:  12.92%, tr:   9.19%, tr_best:   9.19%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.018816/  1.774139, val:  47.50%, val_best:  47.50%, tr:  28.40%, tr_best:  28.40%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.513552/  1.563510, val:  54.17%, val_best:  54.17%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.327564/  1.522441, val:  56.67%, val_best:  56.67%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.250662/  1.474620, val:  59.17%, val_best:  59.17%, tr:  61.39%, tr_best:  62.21%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.179366/  1.393761, val:  61.67%, val_best:  61.67%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.120398/  1.370665, val:  60.42%, val_best:  61.67%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.091616/  1.341764, val:  60.00%, val_best:  61.67%, tr:  65.17%, tr_best:  67.52%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.048211/  1.317358, val:  64.17%, val_best:  64.17%, tr:  66.80%, tr_best:  67.52%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.027993/  1.307989, val:  62.92%, val_best:  64.17%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.013522/  1.328961, val:  56.25%, val_best:  64.17%, tr:  67.72%, tr_best:  69.05%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.977560/  1.281994, val:  61.25%, val_best:  64.17%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.967206/  1.270535, val:  61.25%, val_best:  64.17%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.955154/  1.281053, val:  62.92%, val_best:  64.17%, tr:  70.99%, tr_best:  71.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.908413/  1.377845, val:  62.08%, val_best:  64.17%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.905142/  1.261297, val:  67.50%, val_best:  67.50%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.899928/  1.249391, val:  62.50%, val_best:  67.50%, tr:  73.75%, tr_best:  75.08%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.857703/  1.237012, val:  67.08%, val_best:  67.50%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.848926/  1.305095, val:  62.08%, val_best:  67.50%, tr:  77.43%, tr_best:  78.35%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.836219/  1.261745, val:  64.17%, val_best:  67.50%, tr:  77.32%, tr_best:  78.35%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.815356/  1.246155, val:  66.67%, val_best:  67.50%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.795694/  1.223154, val:  68.33%, val_best:  68.33%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.791058/  1.236381, val:  70.00%, val_best:  70.00%, tr:  80.90%, tr_best:  82.64%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.764304/  1.249705, val:  70.83%, val_best:  70.83%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.740911/  1.248815, val:  67.50%, val_best:  70.83%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.729220/  1.211217, val:  69.17%, val_best:  70.83%, tr:  86.21%, tr_best:  86.62%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.718237/  1.207151, val:  71.25%, val_best:  71.25%, tr:  86.11%, tr_best:  86.62%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.699692/  1.262047, val:  67.50%, val_best:  71.25%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.696999/  1.231103, val:  70.83%, val_best:  71.25%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.673252/  1.288741, val:  67.92%, val_best:  71.25%, tr:  89.68%, tr_best:  90.09%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.663493/  1.270396, val:  70.83%, val_best:  71.25%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.676400/  1.293150, val:  70.00%, val_best:  71.25%, tr:  86.21%, tr_best:  90.70%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.657138/  1.284512, val:  69.58%, val_best:  71.25%, tr:  89.58%, tr_best:  90.70%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.647034/  1.282282, val:  69.58%, val_best:  71.25%, tr:  90.50%, tr_best:  90.70%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.626037/  1.277803, val:  70.42%, val_best:  71.25%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.633261/  1.314586, val:  68.33%, val_best:  71.25%, tr:  90.81%, tr_best:  92.34%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.600130/  1.297610, val:  70.83%, val_best:  71.25%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.601211/  1.293390, val:  72.50%, val_best:  72.50%, tr:  93.36%, tr_best:  93.46%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.585048/  1.280120, val:  72.50%, val_best:  72.50%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.579648/  1.293408, val:  72.50%, val_best:  72.50%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.566120/  1.325075, val:  69.58%, val_best:  72.50%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.563255/  1.311594, val:  72.08%, val_best:  72.50%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.559769/  1.280876, val:  72.08%, val_best:  72.50%, tr:  94.28%, tr_best:  95.51%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.543994/  1.339060, val:  68.33%, val_best:  72.50%, tr:  94.99%, tr_best:  95.51%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.542929/  1.317356, val:  72.50%, val_best:  72.50%, tr:  94.69%, tr_best:  95.51%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.527550/  1.320898, val:  70.42%, val_best:  72.50%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.521755/  1.296706, val:  70.83%, val_best:  72.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.514164/  1.319878, val:  72.92%, val_best:  72.92%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.516351/  1.311078, val:  71.25%, val_best:  72.92%, tr:  96.12%, tr_best:  96.53%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.512571/  1.333861, val:  72.08%, val_best:  72.92%, tr:  96.02%, tr_best:  96.53%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.501958/  1.343796, val:  71.25%, val_best:  72.92%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.505823/  1.346590, val:  70.42%, val_best:  72.92%, tr:  96.42%, tr_best:  97.14%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.480693/  1.371162, val:  71.25%, val_best:  72.92%, tr:  96.02%, tr_best:  97.14%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.475938/  1.334505, val:  75.00%, val_best:  75.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.474698/  1.371646, val:  72.08%, val_best:  75.00%, tr:  97.45%, tr_best:  97.55%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.458409/  1.378837, val:  71.25%, val_best:  75.00%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.458605/  1.407330, val:  71.25%, val_best:  75.00%, tr:  97.24%, tr_best:  97.65%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.458609/  1.361614, val:  72.92%, val_best:  75.00%, tr:  97.14%, tr_best:  97.65%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.450455/  1.417588, val:  70.42%, val_best:  75.00%, tr:  97.34%, tr_best:  97.65%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.437232/  1.389785, val:  75.42%, val_best:  75.42%, tr:  97.34%, tr_best:  97.65%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.439982/  1.384259, val:  74.17%, val_best:  75.42%, tr:  97.14%, tr_best:  97.65%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.432561/  1.404141, val:  72.50%, val_best:  75.42%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.426807/  1.413753, val:  72.92%, val_best:  75.42%, tr:  97.85%, tr_best:  98.06%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.420636/  1.392962, val:  72.92%, val_best:  75.42%, tr:  97.96%, tr_best:  98.06%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.417405/  1.477721, val:  70.83%, val_best:  75.42%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.410001/  1.423042, val:  75.00%, val_best:  75.42%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.409582/  1.421242, val:  72.92%, val_best:  75.42%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.408276/  1.425968, val:  75.42%, val_best:  75.42%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.396231/  1.438789, val:  75.00%, val_best:  75.42%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.390873/  1.466562, val:  71.25%, val_best:  75.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.397459/  1.463143, val:  75.00%, val_best:  75.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.396328/  1.499568, val:  72.08%, val_best:  75.42%, tr:  98.26%, tr_best:  98.67%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.383315/  1.495891, val:  72.92%, val_best:  75.42%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.397660/  1.477999, val:  72.08%, val_best:  75.42%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.381764/  1.482253, val:  74.58%, val_best:  75.42%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.373959/  1.520389, val:  72.08%, val_best:  75.42%, tr:  98.37%, tr_best:  98.67%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.366494/  1.521122, val:  71.67%, val_best:  75.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.376365/  1.516308, val:  73.33%, val_best:  75.42%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.378218/  1.542395, val:  72.92%, val_best:  75.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.364422/  1.517383, val:  72.08%, val_best:  75.42%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.359648/  1.542612, val:  73.75%, val_best:  75.42%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.358061/  1.530787, val:  74.17%, val_best:  75.42%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.355153/  1.569844, val:  74.17%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.349711/  1.591070, val:  72.08%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.340692/  1.530499, val:  75.83%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.345795/  1.562865, val:  74.58%, val_best:  75.83%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.338309/  1.557384, val:  72.50%, val_best:  75.83%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.344346/  1.584842, val:  75.83%, val_best:  75.83%, tr:  98.77%, tr_best:  99.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.326956/  1.595676, val:  74.58%, val_best:  75.83%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.322994/  1.574880, val:  76.67%, val_best:  76.67%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.331712/  1.570451, val:  75.83%, val_best:  76.67%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.321653/  1.583066, val:  76.67%, val_best:  76.67%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.319138/  1.639422, val:  75.42%, val_best:  76.67%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.317666/  1.600095, val:  73.33%, val_best:  76.67%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.315391/  1.628379, val:  76.67%, val_best:  76.67%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.319535/  1.629692, val:  73.33%, val_best:  76.67%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.316619/  1.656585, val:  72.08%, val_best:  76.67%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.320192/  1.615323, val:  74.58%, val_best:  76.67%, tr:  98.88%, tr_best:  99.59%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.301758/  1.668604, val:  72.92%, val_best:  76.67%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.311411/  1.655537, val:  73.75%, val_best:  76.67%, tr:  99.49%, tr_best:  99.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4ab2e7a0b44c45b013a33deb9922fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▅▄▆▆▃▆▇▇█▇▆▆▇█▇█▇██████▇██▇██▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇██▇▇▇███████▇█▇███████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇██▇▇▇███████▇█▇███████</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▁▂▁▁▁▁▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99489</td></tr><tr><td>tr_epoch_loss</td><td>0.31141</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>1.65554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-204</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8x86vawf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8x86vawf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_055955-8x86vawf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dwpa3bqv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_060656-dwpa3bqv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dwpa3bqv' target=\"_blank\">twilight-sweep-206</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dwpa3bqv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dwpa3bqv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.069655/  1.660617, val:  42.92%, val_best:  42.92%, tr:  22.68%, tr_best:  22.68%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.413331/  1.546749, val:  50.42%, val_best:  50.42%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.286786/  1.540555, val:  55.42%, val_best:  55.42%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.166334/  1.589133, val:  55.42%, val_best:  55.42%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.106688/  1.402593, val:  65.42%, val_best:  65.42%, tr:  66.19%, tr_best:  66.19%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.083226/  1.428254, val:  62.50%, val_best:  65.42%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.030667/  1.459876, val:  60.42%, val_best:  65.42%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.013507/  1.593310, val:  59.58%, val_best:  65.42%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.022416/  1.520947, val:  61.67%, val_best:  65.42%, tr:  70.68%, tr_best:  71.09%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.971792/  1.623063, val:  57.50%, val_best:  65.42%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.985687/  1.777358, val:  53.75%, val_best:  65.42%, tr:  75.79%, tr_best:  77.53%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.899811/  1.536452, val:  70.83%, val_best:  70.83%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.900712/  1.661612, val:  69.58%, val_best:  70.83%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.880851/  1.755301, val:  67.50%, val_best:  70.83%, tr:  82.43%, tr_best:  83.66%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.838045/  1.831374, val:  65.00%, val_best:  70.83%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.814410/  1.884745, val:  67.08%, val_best:  70.83%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.787492/  1.919112, val:  68.75%, val_best:  70.83%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.784587/  1.987455, val:  68.33%, val_best:  70.83%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.801176/  2.144347, val:  62.08%, val_best:  70.83%, tr:  91.01%, tr_best:  91.62%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.796245/  2.194486, val:  60.83%, val_best:  70.83%, tr:  90.60%, tr_best:  91.62%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.777934/  2.189251, val:  67.08%, val_best:  70.83%, tr:  90.70%, tr_best:  91.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.735636/  2.465343, val:  60.00%, val_best:  70.83%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.716937/  2.317643, val:  62.50%, val_best:  70.83%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.752546/  2.286655, val:  72.50%, val_best:  72.50%, tr:  92.65%, tr_best:  93.77%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.690918/  2.325485, val:  71.25%, val_best:  72.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.696642/  2.457562, val:  65.00%, val_best:  72.50%, tr:  95.81%, tr_best:  95.91%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.749232/  2.402833, val:  70.83%, val_best:  72.50%, tr:  93.16%, tr_best:  95.91%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.699547/  2.681791, val:  65.83%, val_best:  72.50%, tr:  95.61%, tr_best:  95.91%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.666904/  2.555112, val:  71.67%, val_best:  72.50%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.651386/  2.779361, val:  65.83%, val_best:  72.50%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.644191/  2.715840, val:  66.25%, val_best:  72.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.632446/  2.800310, val:  67.92%, val_best:  72.50%, tr:  96.22%, tr_best:  97.24%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.695831/  2.963401, val:  66.67%, val_best:  72.50%, tr:  94.59%, tr_best:  97.24%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.684342/  2.940669, val:  66.25%, val_best:  72.50%, tr:  95.71%, tr_best:  97.24%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.617022/  3.126891, val:  63.75%, val_best:  72.50%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.626431/  3.066089, val:  64.58%, val_best:  72.50%, tr:  96.12%, tr_best:  97.55%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.596755/  3.022992, val:  66.25%, val_best:  72.50%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.588535/  3.259335, val:  62.50%, val_best:  72.50%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.618076/  3.109408, val:  70.00%, val_best:  72.50%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.569726/  3.089443, val:  69.17%, val_best:  72.50%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.558546/  3.224356, val:  68.75%, val_best:  72.50%, tr:  97.96%, tr_best:  98.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.538278/  3.322783, val:  66.67%, val_best:  72.50%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.541005/  3.252391, val:  68.33%, val_best:  72.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.538891/  3.426498, val:  65.83%, val_best:  72.50%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.526975/  3.508643, val:  69.58%, val_best:  72.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.525947/  3.379385, val:  72.50%, val_best:  72.50%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.527748/  3.551934, val:  67.50%, val_best:  72.50%, tr:  98.77%, tr_best:  99.28%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.484083/  3.567724, val:  70.42%, val_best:  72.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.486783/  3.533693, val:  72.08%, val_best:  72.50%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.479591/  3.608354, val:  71.25%, val_best:  72.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.466524/  3.740891, val:  67.50%, val_best:  72.50%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.467138/  3.733702, val:  67.92%, val_best:  72.50%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.470166/  3.781563, val:  72.08%, val_best:  72.50%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.421574/  3.840404, val:  70.00%, val_best:  72.50%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.433229/  3.855908, val:  72.92%, val_best:  72.92%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.442275/  3.870203, val:  70.42%, val_best:  72.92%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.434444/  3.939378, val:  71.25%, val_best:  72.92%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.448070/  3.932909, val:  72.08%, val_best:  72.92%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.411043/  4.026453, val:  71.67%, val_best:  72.92%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.430867/  4.024980, val:  73.33%, val_best:  73.33%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.416831/  4.117602, val:  73.75%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.446244/  4.285240, val:  71.25%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.417399/  4.357931, val:  70.83%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.414242/  4.396373, val:  72.50%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.412037/  4.494936, val:  72.08%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.387441/  4.476055, val:  71.67%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.369956/  4.497488, val:  72.92%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.377404/  4.590220, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.366861/  4.616471, val:  70.00%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.398273/  4.580151, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.372878/  4.677860, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.397583/  4.730765, val:  71.67%, val_best:  74.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.372673/  4.853373, val:  69.17%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.357692/  4.937323, val:  70.00%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.347149/  4.960984, val:  70.83%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.342774/  5.002822, val:  71.25%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.343710/  5.073651, val:  71.25%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.333063/  5.077907, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.346812/  5.139278, val:  70.83%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.330966/  5.136530, val:  69.17%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.336446/  5.200790, val:  71.25%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.309070/  5.268852, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.290381/  5.401300, val:  67.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.309266/  5.475286, val:  67.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.271790/  5.421241, val:  70.00%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.276598/  5.487405, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.271630/  5.540856, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.319191/  5.526140, val:  70.00%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.275111/  5.577537, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.247775/  5.720234, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.259738/  5.641908, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.251623/  5.778403, val:  69.58%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.239932/  5.741596, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.255974/  5.788427, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.251153/  5.876006, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.258602/  5.980645, val:  67.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.259026/  5.970490, val:  69.58%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.259046/  5.981966, val:  70.00%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.248586/  6.092314, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.244740/  6.024011, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee58129c963485392327970e15bf93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▃▃▄▆▃▆▇█▇█▆▇██████████▇██████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▅▄▇▆▇▅▅▇▇▆▆▆▅▇▇▇▇▇████▇▇██▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▅▄▇▆▇▅▅▇▇▆▆▆▅▇▇▇▇▇████▇▇██▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▂▂▂▃▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.24474</td></tr><tr><td>val_acc_best</td><td>0.74167</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>6.02401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-206</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dwpa3bqv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dwpa3bqv</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_060656-dwpa3bqv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lh2kt0d2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_061402-lh2kt0d2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lh2kt0d2' target=\"_blank\">brisk-sweep-208</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lh2kt0d2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lh2kt0d2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.918928/  1.766139, val:  39.17%, val_best:  39.17%, tr:  35.44%, tr_best:  35.44%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.522685/  1.543822, val:  50.83%, val_best:  50.83%, tr:  52.91%, tr_best:  52.91%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.462469/  1.636292, val:  52.92%, val_best:  52.92%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.281721/  1.938516, val:  53.75%, val_best:  53.75%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.126337/  1.658042, val:  59.17%, val_best:  59.17%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.018088/  1.819451, val:  53.33%, val_best:  59.17%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.038540/  1.501869, val:  53.75%, val_best:  59.17%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.008938/  1.842198, val:  60.42%, val_best:  60.42%, tr:  70.38%, tr_best:  72.52%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.857188/  2.073047, val:  59.58%, val_best:  60.42%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.839671/  1.819092, val:  59.17%, val_best:  60.42%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.781858/  2.256654, val:  60.42%, val_best:  60.42%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.747109/  2.108664, val:  61.67%, val_best:  61.67%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.771433/  2.266287, val:  63.33%, val_best:  63.33%, tr:  83.96%, tr_best:  84.47%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.687038/  2.226135, val:  62.50%, val_best:  63.33%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.604021/  2.787884, val:  65.42%, val_best:  65.42%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.604279/  3.010901, val:  57.08%, val_best:  65.42%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.644402/  3.275545, val:  60.00%, val_best:  65.42%, tr:  90.19%, tr_best:  91.11%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.593072/  3.144130, val:  61.67%, val_best:  65.42%, tr:  90.70%, tr_best:  91.11%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.576419/  3.461953, val:  65.42%, val_best:  65.42%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.612530/  3.032167, val:  66.25%, val_best:  66.25%, tr:  92.95%, tr_best:  95.51%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.560269/  3.147925, val:  59.58%, val_best:  66.25%, tr:  90.70%, tr_best:  95.51%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.549513/  4.055676, val:  58.75%, val_best:  66.25%, tr:  92.34%, tr_best:  95.51%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.446635/  3.748050, val:  67.08%, val_best:  67.08%, tr:  94.79%, tr_best:  95.51%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.374753/  3.908740, val:  69.58%, val_best:  69.58%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.331600/  4.694147, val:  67.50%, val_best:  69.58%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.302272/  4.962029, val:  69.58%, val_best:  69.58%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.306453/  4.787845, val:  67.92%, val_best:  69.58%, tr:  98.37%, tr_best:  99.08%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.289604/  5.392651, val:  70.42%, val_best:  70.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.306489/  4.994055, val:  74.17%, val_best:  74.17%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.418544/  5.169416, val:  69.58%, val_best:  74.17%, tr:  97.45%, tr_best:  99.59%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.374993/  5.118289, val:  69.58%, val_best:  74.17%, tr:  98.47%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.482845/  6.281351, val:  66.67%, val_best:  74.17%, tr:  96.73%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.325347/  6.057112, val:  70.42%, val_best:  74.17%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.292414/  6.262801, val:  67.92%, val_best:  74.17%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.172655/  6.787322, val:  70.42%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.215183/  6.903999, val:  65.00%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.155477/  6.730012, val:  68.75%, val_best:  74.17%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.182143/  7.162552, val:  69.58%, val_best:  74.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.154279/  8.126884, val:  65.00%, val_best:  74.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.134517/  7.263245, val:  70.00%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.165561/  8.013510, val:  66.25%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.342180/  7.149689, val:  72.08%, val_best:  74.17%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.327178/  7.403661, val:  72.08%, val_best:  74.17%, tr:  99.18%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.265342/  7.805858, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.240346/  7.795413, val:  70.42%, val_best:  74.17%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.257350/  8.125592, val:  73.75%, val_best:  74.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.205008/  8.164701, val:  68.75%, val_best:  74.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.223306/  8.122765, val:  70.83%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.120668/  8.106123, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.091019/  9.479704, val:  65.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.215194/  9.543746, val:  67.50%, val_best:  74.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.124792/  9.061197, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.141938/  9.138510, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.094822/  9.471572, val:  71.67%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.079540/  8.510228, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.077092/  9.029275, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.040456/  8.908908, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.035308/  9.318087, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.024130/  9.503648, val:  73.75%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.027410/  9.269972, val:  72.92%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.041191/  9.043299, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.039206/  8.913521, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.032279/  8.912433, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.035388/  9.046085, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.024662/  9.146474, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.018013/  9.655587, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.018147/ 10.230427, val:  70.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.028161/  9.262878, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.025980/ 10.319134, val:  73.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.045143/  9.934521, val:  73.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.032037/  9.717352, val:  75.00%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.028002/ 10.136204, val:  72.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.029250/ 10.047707, val:  74.17%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.017235/ 10.117302, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.025970/  9.955523, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.033109/  9.898630, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.019482/ 10.564024, val:  72.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.017105/ 10.816905, val:  73.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.012609/ 10.423601, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.023236/ 10.987548, val:  71.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.061219/ 10.943596, val:  72.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.063914/ 10.064816, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.089410/ 10.161430, val:  76.25%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.111885/ 10.942340, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.054662/ 10.727261, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.134882/ 11.398153, val:  68.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.502878/ 10.731090, val:  69.17%, val_best:  78.33%, tr:  98.57%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.541182/ 10.847183, val:  72.92%, val_best:  78.33%, tr:  98.77%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.289717/ 11.954197, val:  70.42%, val_best:  78.33%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.311020/ 10.565401, val:  72.08%, val_best:  78.33%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.140438/ 10.575635, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.091025/ 10.555671, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.095556/ 10.379284, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.133565/ 10.715814, val:  76.67%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.163438/ 11.130771, val:  74.17%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.086392/ 11.202976, val:  73.75%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.112169/ 11.486547, val:  71.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.124501/ 11.004600, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.064566/ 11.264848, val:  75.00%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.059380/ 11.852772, val:  75.00%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe1472039ac466ba4e4f3d5d5774d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▅▇▅▆██▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▅▅▆▅▆▄▆▆▆▇▆▆▇▇▇▇▆▇█▇▇█▇█▇▇█▇▇█▇▇▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▅▅▆▅▆▄▆▆▆▇▆▆▇▇▇▇▆▇█▇▇█▇█▇▇█▇▇█▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▅▅▅▆▆▇▆▆▇▇▆▇▇▇▇▇██▇███▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.05938</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>11.85277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-208</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lh2kt0d2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lh2kt0d2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_061402-lh2kt0d2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e8urp5ek with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_062024-e8urp5ek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e8urp5ek' target=\"_blank\">clear-sweep-210</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e8urp5ek' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e8urp5ek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.022131/  1.630452, val:  45.83%, val_best:  45.83%, tr:  23.19%, tr_best:  23.19%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.383419/  1.550417, val:  53.75%, val_best:  53.75%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.264192/  1.517305, val:  55.00%, val_best:  55.00%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.126297/  1.578175, val:  55.42%, val_best:  55.42%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.069246/  1.418065, val:  61.25%, val_best:  61.25%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.056916/  1.475378, val:  57.50%, val_best:  61.25%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.014596/  1.437956, val:  60.00%, val_best:  61.25%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.975924/  1.585245, val:  60.00%, val_best:  61.25%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.980116/  1.436251, val:  62.50%, val_best:  62.50%, tr:  70.38%, tr_best:  71.71%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.931740/  1.515913, val:  60.83%, val_best:  62.50%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.937258/  1.658189, val:  58.75%, val_best:  62.50%, tr:  78.04%, tr_best:  78.35%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.852396/  1.449891, val:  71.25%, val_best:  71.25%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.817342/  1.512977, val:  69.17%, val_best:  71.25%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.814244/  1.537678, val:  71.67%, val_best:  71.67%, tr:  83.86%, tr_best:  87.74%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.742249/  1.676572, val:  69.17%, val_best:  71.67%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.738363/  1.695405, val:  70.00%, val_best:  71.67%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.704494/  1.688321, val:  71.25%, val_best:  71.67%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.691019/  1.703141, val:  71.67%, val_best:  71.67%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.709775/  1.896230, val:  65.42%, val_best:  71.67%, tr:  89.99%, tr_best:  93.16%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.649018/  1.931372, val:  67.50%, val_best:  71.67%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.630190/  1.920093, val:  67.08%, val_best:  71.67%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.606272/  2.049451, val:  63.75%, val_best:  71.67%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.584824/  1.942456, val:  70.83%, val_best:  71.67%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.583699/  1.971234, val:  71.25%, val_best:  71.67%, tr:  95.91%, tr_best:  96.83%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.544764/  2.005070, val:  70.83%, val_best:  71.67%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.515397/  2.058934, val:  72.50%, val_best:  72.50%, tr:  97.14%, tr_best:  97.65%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.596811/  2.090208, val:  71.67%, val_best:  72.50%, tr:  94.28%, tr_best:  97.65%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.536753/  2.204282, val:  67.92%, val_best:  72.50%, tr:  97.24%, tr_best:  97.65%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.485468/  2.136481, val:  74.58%, val_best:  74.58%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.468029/  2.422787, val:  69.58%, val_best:  74.58%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.468815/  2.260465, val:  72.92%, val_best:  74.58%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.452684/  2.274758, val:  77.08%, val_best:  77.08%, tr:  98.47%, tr_best:  98.57%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.475387/  2.372153, val:  73.33%, val_best:  77.08%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.468278/  2.384038, val:  73.33%, val_best:  77.08%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.428431/  2.530059, val:  67.92%, val_best:  77.08%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.433888/  2.492935, val:  72.08%, val_best:  77.08%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.428424/  2.450366, val:  73.75%, val_best:  77.08%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.419209/  2.579550, val:  75.42%, val_best:  77.08%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.433129/  2.543867, val:  73.33%, val_best:  77.08%, tr:  98.88%, tr_best:  99.59%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.426828/  2.495982, val:  75.00%, val_best:  77.08%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.413604/  2.553228, val:  75.83%, val_best:  77.08%, tr:  98.37%, tr_best:  99.59%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.394051/  2.669062, val:  75.00%, val_best:  77.08%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.387436/  2.574790, val:  78.33%, val_best:  78.33%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.392408/  2.748375, val:  71.67%, val_best:  78.33%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.381790/  2.630829, val:  77.50%, val_best:  78.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.365639/  2.713720, val:  77.50%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.354842/  2.731050, val:  75.00%, val_best:  78.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.339082/  2.799896, val:  74.58%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.343770/  2.769613, val:  78.33%, val_best:  78.33%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.350294/  2.826802, val:  78.75%, val_best:  78.75%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.337476/  2.981396, val:  74.58%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.347404/  2.994026, val:  75.42%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.328465/  2.962405, val:  77.50%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.311915/  3.148767, val:  74.17%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.322189/  3.069924, val:  80.00%, val_best:  80.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.305563/  3.127694, val:  75.42%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.302130/  3.225927, val:  73.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.314344/  3.152190, val:  77.08%, val_best:  80.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.284057/  3.180535, val:  76.67%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.291663/  3.167394, val:  77.50%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.274894/  3.116722, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.278482/  3.278345, val:  76.67%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.240771/  3.276977, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.257429/  3.240726, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.263793/  3.337663, val:  76.25%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.237741/  3.339894, val:  79.17%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.235857/  3.445549, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.237515/  3.421323, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.249792/  3.397072, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.232181/  3.448359, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.220716/  3.433212, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.246938/  3.451987, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.229277/  3.539661, val:  77.50%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.211537/  3.552943, val:  79.17%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.218447/  3.545587, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.205870/  3.612009, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.204850/  3.676742, val:  77.08%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.200369/  3.625744, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.190644/  3.647678, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.206109/  3.746094, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.195133/  3.717267, val:  78.33%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.206839/  3.760180, val:  78.75%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.192001/  3.839563, val:  76.67%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.190367/  3.952398, val:  75.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.192088/  3.926052, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.203457/  4.015936, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.184146/  3.959567, val:  76.67%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.180882/  4.011615, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.178198/  3.968433, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.180362/  4.076682, val:  77.50%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.169162/  4.095328, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.157902/  4.194372, val:  76.67%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.156726/  4.200919, val:  75.42%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.161996/  4.141944, val:  75.42%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.171341/  4.261172, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.170289/  4.206444, val:  77.08%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.182218/  4.263485, val:  74.58%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.171521/  4.219181, val:  75.83%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.164306/  4.291311, val:  75.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.178525/  4.249558, val:  76.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9257e6da899443c98218021902fd3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▂▅▄▇▂▇████▇███████████████▇██████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▄▆▆▆▅▅▆▆▆▇▆▇▇█▇▇█▇█▇▇▇█▇█▇███▇██▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇██▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▄▆▆▆▅▅▆▆▆▇▆▇▇█▇▇█▇█▇▇▇█▇█▇███▇██▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▃▂▃▄▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.17853</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.7625</td></tr><tr><td>val_loss</td><td>4.24956</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-210</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e8urp5ek' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/e8urp5ek</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_062024-e8urp5ek/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1og0rjv8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_062730-1og0rjv8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1og0rjv8' target=\"_blank\">earnest-sweep-212</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1og0rjv8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1og0rjv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.259325/  2.166692, val:  25.42%, val_best:  25.42%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.951459/  1.832348, val:  47.92%, val_best:  47.92%, tr:  37.90%, tr_best:  37.90%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.623138/  1.666077, val:  55.42%, val_best:  55.42%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.460078/  1.635147, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.385512/  1.555451, val:  60.42%, val_best:  60.42%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.316895/  1.531080, val:  59.58%, val_best:  60.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.249793/  1.511024, val:  59.58%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.203278/  1.482369, val:  61.67%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.161125/  1.456793, val:  65.83%, val_best:  65.83%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.130679/  1.528863, val:  60.00%, val_best:  65.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.108387/  1.563280, val:  55.00%, val_best:  65.83%, tr:  68.95%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054601/  1.435886, val:  68.33%, val_best:  68.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.048901/  1.472334, val:  59.17%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.017672/  1.569106, val:  62.50%, val_best:  68.33%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.974325/  1.656879, val:  59.58%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980752/  1.572125, val:  60.83%, val_best:  68.33%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.983020/  1.537963, val:  64.58%, val_best:  68.33%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.914581/  1.668934, val:  62.08%, val_best:  68.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.931618/  1.708934, val:  62.50%, val_best:  68.33%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.924997/  1.702797, val:  65.42%, val_best:  68.33%, tr:  77.83%, tr_best:  78.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.895528/  1.803627, val:  62.08%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.870973/  1.802069, val:  61.25%, val_best:  68.33%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.875475/  1.817097, val:  62.50%, val_best:  68.33%, tr:  80.08%, tr_best:  82.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.852028/  1.992823, val:  60.00%, val_best:  68.33%, tr:  82.02%, tr_best:  82.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.817858/  1.996159, val:  59.58%, val_best:  68.33%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.836069/  1.881631, val:  67.50%, val_best:  68.33%, tr:  83.76%, tr_best:  84.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.846120/  1.998041, val:  70.00%, val_best:  70.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.806404/  2.054228, val:  62.92%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.791962/  2.007748, val:  68.75%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.819494/  2.359427, val:  60.42%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.782672/  2.213522, val:  62.08%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.785682/  2.318455, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  87.74%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.812352/  2.263149, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.814710/  2.259653, val:  67.92%, val_best:  70.00%, tr:  87.54%, tr_best:  87.74%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.742937/  2.467701, val:  60.42%, val_best:  70.00%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.757479/  2.534710, val:  59.58%, val_best:  70.00%, tr:  86.21%, tr_best:  88.46%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.681546/  2.297895, val:  67.50%, val_best:  70.00%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.701446/  2.512144, val:  63.75%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.710612/  2.657074, val:  65.00%, val_best:  70.00%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.657503/  2.521472, val:  63.75%, val_best:  70.00%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.682582/  2.741191, val:  62.92%, val_best:  70.00%, tr:  91.32%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.655606/  2.770979, val:  59.17%, val_best:  70.00%, tr:  93.05%, tr_best:  93.26%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.632359/  2.721785, val:  67.08%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.633759/  2.736447, val:  65.00%, val_best:  70.00%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.632607/  2.656749, val:  67.92%, val_best:  70.00%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.615663/  2.725739, val:  68.75%, val_best:  70.00%, tr:  94.79%, tr_best:  94.99%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594888/  2.853819, val:  66.25%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.578222/  3.049881, val:  65.42%, val_best:  70.00%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.607904/  2.996387, val:  67.92%, val_best:  70.00%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.567040/  3.018704, val:  69.58%, val_best:  70.00%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.532360/  3.186153, val:  66.25%, val_best:  70.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.575075/  3.053903, val:  67.08%, val_best:  70.00%, tr:  94.18%, tr_best:  97.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.514349/  3.110004, val:  67.08%, val_best:  70.00%, tr:  96.83%, tr_best:  97.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.518154/  3.457839, val:  65.83%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.505677/  3.216293, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.527777/  3.308029, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.491510/  3.531652, val:  64.17%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.559684/  3.381672, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.539413/  3.329102, val:  67.08%, val_best:  70.00%, tr:  94.48%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.516434/  3.457018, val:  70.83%, val_best:  70.83%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.485153/  3.732556, val:  64.17%, val_best:  70.83%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.535130/  3.417022, val:  71.25%, val_best:  71.25%, tr:  96.83%, tr_best:  98.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.446230/  3.361158, val:  69.17%, val_best:  71.25%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.424834/  3.410936, val:  73.75%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.435740/  3.347567, val:  71.67%, val_best:  73.75%, tr:  97.65%, tr_best:  98.88%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.381304/  3.313588, val:  71.25%, val_best:  73.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.393611/  3.409695, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.414356/  3.359644, val:  73.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.412061/  3.412950, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.420847/  3.498824, val:  72.08%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.378566/  3.353256, val:  71.25%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.437227/  3.585583, val:  72.50%, val_best:  73.75%, tr:  98.06%, tr_best:  99.49%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.419239/  3.353722, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.389243/  3.548229, val:  67.92%, val_best:  73.75%, tr:  98.37%, tr_best:  99.49%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.355405/  3.541240, val:  72.92%, val_best:  73.75%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.352597/  3.526462, val:  70.42%, val_best:  73.75%, tr:  98.47%, tr_best:  99.49%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.337224/  3.475421, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.360251/  3.710256, val:  69.58%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.380566/  3.617064, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.325451/  3.572766, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.308370/  3.665858, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.266245/  3.580417, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.278189/  3.626280, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.352835/  3.735754, val:  70.83%, val_best:  73.75%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.314501/  3.713542, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.353990/  3.794341, val:  70.42%, val_best:  73.75%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.290747/  3.757254, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.318437/  3.547390, val:  72.50%, val_best:  73.75%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.290242/  3.610040, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.257004/  3.746444, val:  73.75%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.253982/  3.726433, val:  70.83%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.232963/  3.734505, val:  72.08%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.194844/  3.748441, val:  72.50%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.219133/  3.755011, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.205211/  3.758615, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.236082/  3.739775, val:  73.33%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.224297/  3.839006, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.232116/  3.776063, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.197325/  3.764912, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.181913/  3.835845, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b28810ba88f45eca6b5ed0c0f777182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▄▅▇▁▄▇█▆█▇▇▇█▆█▇███████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.18191</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.83585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-212</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1og0rjv8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1og0rjv8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_062730-1og0rjv8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hxsuvl1v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_063342-hxsuvl1v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hxsuvl1v' target=\"_blank\">sleek-sweep-214</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hxsuvl1v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hxsuvl1v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  3.315597/  4.786579, val:  33.33%, val_best:  33.33%, tr:  32.28%, tr_best:  32.28%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  5.180536/  4.590707, val:  48.75%, val_best:  48.75%, tr:  42.70%, tr_best:  42.70%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  4.948162/  5.779668, val:  45.00%, val_best:  48.75%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  3.753012/  6.646512, val:  40.00%, val_best:  48.75%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  4.376871/  5.555490, val:  55.00%, val_best:  55.00%, tr:  59.96%, tr_best:  60.67%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.628884/  6.367018, val:  48.33%, val_best:  55.00%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.253217/  4.150631, val:  60.83%, val_best:  60.83%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.771107/  5.879029, val:  55.42%, val_best:  60.83%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.266003/  5.080351, val:  57.08%, val_best:  60.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.839190/  7.216139, val:  62.50%, val_best:  62.50%, tr:  78.35%, tr_best:  79.37%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.801585/  5.156327, val:  70.42%, val_best:  70.42%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.694191/  6.241440, val:  64.17%, val_best:  70.42%, tr:  87.95%, tr_best:  88.66%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.577108/  5.271259, val:  77.08%, val_best:  77.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.017231/  6.058364, val:  70.42%, val_best:  77.08%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.718480/  6.141181, val:  66.25%, val_best:  77.08%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.706082/  6.924497, val:  67.92%, val_best:  77.08%, tr:  97.14%, tr_best:  97.55%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.703793/  6.407065, val:  72.50%, val_best:  77.08%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.418612/  6.492408, val:  75.00%, val_best:  77.08%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.596671/  6.506639, val:  74.58%, val_best:  77.08%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.323114/  6.708823, val:  71.25%, val_best:  77.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.293359/  6.906110, val:  74.58%, val_best:  77.08%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.278957/  7.186599, val:  72.08%, val_best:  77.08%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.203839/  6.886444, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.154869/  7.024320, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.145169/  7.322946, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.145555/  7.183438, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.156083/  7.570466, val:  73.75%, val_best:  78.75%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.111534/  7.598411, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.089358/  7.408143, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.071977/  7.612912, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.046787/  7.634065, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.055257/  7.678881, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.045452/  7.702252, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.046779/  8.027308, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.049463/  8.320916, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.057307/  7.993902, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.035875/  8.024028, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.028704/  8.208544, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.027127/  8.040525, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.051027/  8.274283, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.027726/  8.105695, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.027449/  8.298999, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.028103/  8.608747, val:  74.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.018214/  8.352696, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.020623/  8.299809, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.025721/  8.477394, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.018041/  8.340431, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.015959/  8.291317, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.012796/  8.405458, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.013392/  8.590008, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.009571/  8.576027, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.014251/  8.568779, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.011287/  8.553861, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.010587/  8.692531, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.009141/  8.536346, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.005989/  8.679896, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.005817/  8.663319, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.009394/  8.643597, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.010925/  8.757649, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.010021/  8.907081, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.008231/  8.930914, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.009017/  8.881335, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.007303/  8.789383, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.004515/  8.906450, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.005139/  9.062725, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.004348/  9.095988, val:  74.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.006884/  9.052547, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.005267/  9.002442, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.004669/  8.999044, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.004639/  9.096434, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.004254/  9.183752, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.003649/  9.018975, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001932/  9.068118, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001677/  9.014030, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.003822/  9.078734, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.005760/  9.017717, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.003692/  8.982939, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.003900/  9.068336, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.005841/  9.012677, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.005999/  9.083748, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.004764/  9.039901, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001287/  9.026299, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.001110/  8.982339, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.002811/  9.011061, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.007231/  9.044498, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.004651/  9.098385, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.006003/  9.125720, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.002491/  9.141427, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.008133/  9.260819, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.010716/  9.165481, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.006203/  9.129243, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.003599/  9.099571, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.002947/  9.205583, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.005022/  9.175008, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.002551/  9.261844, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.004911/  9.217731, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.004655/  9.137176, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.001414/  9.153036, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000584/  9.151198, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000720/  9.281549, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48967edcc0542189c9ee9b835209d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▅▇▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▅█▆▇▇▇█▇█████▇███▇██▇█▇█▇█▇█████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆█▇▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▅███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▅█▆▇▇▇█▇█████▇███▇██▇█▇█▇█▇█████████</td></tr><tr><td>val_loss</td><td>▁▃▂▃▅▂▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00072</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>9.28155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-214</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hxsuvl1v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hxsuvl1v</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_063342-hxsuvl1v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q4jdo9vw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39a1ff3b5a549288028ff879272ffc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111310724582937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_064038-q4jdo9vw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q4jdo9vw' target=\"_blank\">celestial-sweep-216</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q4jdo9vw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q4jdo9vw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.096589/  1.696667, val:  48.33%, val_best:  48.33%, tr:  21.14%, tr_best:  21.14%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.402306/  1.498014, val:  55.00%, val_best:  55.00%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.228683/  1.449726, val:  55.42%, val_best:  55.42%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.114747/  1.432845, val:  56.25%, val_best:  56.25%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.056240/  1.359940, val:  62.08%, val_best:  62.08%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.016324/  1.307576, val:  61.67%, val_best:  62.08%, tr:  65.47%, tr_best:  66.39%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.955725/  1.341051, val:  60.00%, val_best:  62.08%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.951516/  1.341892, val:  58.75%, val_best:  62.08%, tr:  69.05%, tr_best:  69.97%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.920585/  1.345503, val:  64.17%, val_best:  64.17%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.905326/  1.388613, val:  55.42%, val_best:  64.17%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.890476/  1.429028, val:  52.08%, val_best:  64.17%, tr:  73.34%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.837207/  1.282250, val:  66.67%, val_best:  66.67%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.825512/  1.280854, val:  64.17%, val_best:  66.67%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.806575/  1.336441, val:  64.17%, val_best:  66.67%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.768214/  1.514016, val:  64.58%, val_best:  66.67%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.766790/  1.393650, val:  65.00%, val_best:  66.67%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.775469/  1.339215, val:  66.67%, val_best:  66.67%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.707681/  1.385211, val:  66.25%, val_best:  66.67%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.713861/  1.538893, val:  61.25%, val_best:  66.67%, tr:  86.72%, tr_best:  87.23%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.731255/  1.450260, val:  67.08%, val_best:  67.08%, tr:  85.90%, tr_best:  87.23%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.714004/  1.577367, val:  63.75%, val_best:  67.08%, tr:  84.88%, tr_best:  87.23%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.698870/  1.502367, val:  65.00%, val_best:  67.08%, tr:  86.93%, tr_best:  87.23%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.659909/  1.597225, val:  61.67%, val_best:  67.08%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.679170/  1.594809, val:  67.08%, val_best:  67.08%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.641857/  1.644811, val:  62.08%, val_best:  67.08%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.644439/  1.566210, val:  67.92%, val_best:  67.92%, tr:  91.11%, tr_best:  92.54%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.666123/  1.618842, val:  65.00%, val_best:  67.92%, tr:  89.58%, tr_best:  92.54%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.633958/  1.696515, val:  61.67%, val_best:  67.92%, tr:  92.13%, tr_best:  92.54%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.639267/  1.696404, val:  69.17%, val_best:  69.17%, tr:  90.50%, tr_best:  92.54%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.613480/  1.782937, val:  61.67%, val_best:  69.17%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.596732/  1.782046, val:  62.08%, val_best:  69.17%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.607107/  1.793110, val:  65.42%, val_best:  69.17%, tr:  92.34%, tr_best:  94.08%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.615252/  1.814600, val:  65.42%, val_best:  69.17%, tr:  93.26%, tr_best:  94.08%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.637626/  1.812728, val:  64.58%, val_best:  69.17%, tr:  90.91%, tr_best:  94.08%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.577463/  1.863082, val:  65.00%, val_best:  69.17%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.594687/  1.875233, val:  65.00%, val_best:  69.17%, tr:  93.05%, tr_best:  94.59%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.587534/  1.796554, val:  68.33%, val_best:  69.17%, tr:  94.28%, tr_best:  94.59%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.601771/  1.980787, val:  65.42%, val_best:  69.17%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.583491/  1.943850, val:  65.83%, val_best:  69.17%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.570486/  1.901969, val:  66.25%, val_best:  69.17%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.546648/  1.944585, val:  66.67%, val_best:  69.17%, tr:  95.10%, tr_best:  95.61%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.535378/  1.981388, val:  65.42%, val_best:  69.17%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.554059/  1.910898, val:  68.75%, val_best:  69.17%, tr:  95.91%, tr_best:  96.83%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.549671/  2.011567, val:  68.75%, val_best:  69.17%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.551838/  2.050116, val:  69.17%, val_best:  69.17%, tr:  95.71%, tr_best:  96.83%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.518050/  2.026741, val:  68.75%, val_best:  69.17%, tr:  96.63%, tr_best:  96.83%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.530153/  2.001516, val:  70.00%, val_best:  70.00%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.512708/  2.036574, val:  72.08%, val_best:  72.08%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.529711/  2.016115, val:  72.08%, val_best:  72.08%, tr:  96.73%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.509533/  2.027750, val:  72.92%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.487125/  2.079347, val:  70.42%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.513431/  2.116364, val:  72.50%, val_best:  72.92%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.471009/  2.105737, val:  73.33%, val_best:  73.33%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.474431/  2.169151, val:  70.83%, val_best:  73.33%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.500935/  2.238964, val:  73.33%, val_best:  73.33%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.458538/  2.257398, val:  70.42%, val_best:  73.33%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.493196/  2.328326, val:  69.58%, val_best:  73.33%, tr:  97.14%, tr_best:  98.16%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.499855/  2.229045, val:  74.58%, val_best:  74.58%, tr:  97.04%, tr_best:  98.16%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.496695/  2.411724, val:  69.58%, val_best:  74.58%, tr:  96.94%, tr_best:  98.16%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.485623/  2.336427, val:  75.42%, val_best:  75.42%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.454313/  2.337089, val:  72.50%, val_best:  75.42%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.486076/  2.407667, val:  72.08%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.452783/  2.377891, val:  72.08%, val_best:  75.42%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.434806/  2.402891, val:  74.17%, val_best:  75.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.446249/  2.447223, val:  74.17%, val_best:  75.42%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.454807/  2.393776, val:  71.67%, val_best:  75.42%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.425114/  2.469238, val:  71.67%, val_best:  75.42%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.442987/  2.479203, val:  73.75%, val_best:  75.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.449480/  2.562901, val:  70.00%, val_best:  75.42%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.444445/  2.536687, val:  70.42%, val_best:  75.42%, tr:  98.37%, tr_best:  98.77%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.427545/  2.527987, val:  70.83%, val_best:  75.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.448239/  2.728068, val:  67.92%, val_best:  75.42%, tr:  98.47%, tr_best:  98.98%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.445309/  2.644156, val:  72.08%, val_best:  75.42%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.464778/  2.776425, val:  69.17%, val_best:  75.42%, tr:  97.85%, tr_best:  98.98%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.455143/  2.711345, val:  68.33%, val_best:  75.42%, tr:  97.85%, tr_best:  98.98%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.436100/  2.825577, val:  65.42%, val_best:  75.42%, tr:  97.96%, tr_best:  98.98%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.423074/  2.723932, val:  66.25%, val_best:  75.42%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.433361/  2.660647, val:  70.00%, val_best:  75.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.417561/  2.725543, val:  71.25%, val_best:  75.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.415548/  2.723648, val:  70.83%, val_best:  75.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.412004/  2.803539, val:  69.17%, val_best:  75.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.442471/  2.817372, val:  69.58%, val_best:  75.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.432058/  2.970409, val:  65.83%, val_best:  75.42%, tr:  98.37%, tr_best:  99.39%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.436525/  2.962376, val:  68.75%, val_best:  75.42%, tr:  98.57%, tr_best:  99.39%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.403974/  2.853273, val:  72.50%, val_best:  75.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.410058/  2.913912, val:  71.25%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.400376/  2.997666, val:  68.75%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.430539/  2.894315, val:  72.50%, val_best:  75.42%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.404294/  2.940016, val:  72.50%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.393621/  2.983871, val:  72.08%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.418274/  2.987765, val:  71.25%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.417608/  2.993801, val:  72.08%, val_best:  75.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.406763/  3.062874, val:  70.42%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.406812/  3.114444, val:  70.00%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.397157/  3.064453, val:  71.25%, val_best:  75.42%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.412029/  3.092029, val:  70.00%, val_best:  75.42%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.396741/  3.219587, val:  67.50%, val_best:  75.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.410793/  3.260687, val:  69.17%, val_best:  75.42%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.395357/  3.280419, val:  68.33%, val_best:  75.42%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.406782/  3.300207, val:  67.92%, val_best:  75.42%, tr:  99.28%, tr_best:  99.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd765e3ae38447f990c938fe35e50475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▅▄▅▆▄▆█▇▇▇▇▇██▇▇▇▇█▇▇████████████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▄▃▅▅▆▆▅▅▅▄▅▅▅▆▆▆▇▇▇▇██▇▇█▇▇▅▇▇▆▇▇▇▇▇▆</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▄▃▅▅▆▆▅▅▅▄▅▅▅▆▆▆▇▇▇▇██▇▇█▇▇▅▇▇▆▇▇▇▇▇▆</td></tr><tr><td>val_loss</td><td>▂▂▁▁▁▁▂▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99285</td></tr><tr><td>tr_epoch_loss</td><td>0.40678</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.67917</td></tr><tr><td>val_loss</td><td>3.30021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-216</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q4jdo9vw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q4jdo9vw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_064038-q4jdo9vw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sy98e9w9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_064732-sy98e9w9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sy98e9w9' target=\"_blank\">azure-sweep-218</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sy98e9w9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sy98e9w9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.291226/  2.262563, val:  21.67%, val_best:  21.67%, tr:  12.87%, tr_best:  12.87%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.226794/  2.197138, val:  30.00%, val_best:  30.00%, tr:  24.92%, tr_best:  24.92%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.122399/  2.090609, val:  43.33%, val_best:  43.33%, tr:  32.89%, tr_best:  32.89%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.981584/  1.970841, val:  48.33%, val_best:  48.33%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.838591/  1.864843, val:  52.08%, val_best:  52.08%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.708440/  1.771031, val:  49.58%, val_best:  52.08%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.619611/  1.705889, val:  53.33%, val_best:  53.33%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.546571/  1.663146, val:  55.42%, val_best:  55.42%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.497638/  1.623710, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.454307/  1.600733, val:  55.00%, val_best:  56.67%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.419487/  1.571013, val:  58.75%, val_best:  58.75%, tr:  60.47%, tr_best:  61.18%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.388129/  1.559669, val:  56.25%, val_best:  58.75%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.370566/  1.545035, val:  60.00%, val_best:  60.00%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.345960/  1.527287, val:  57.50%, val_best:  60.00%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.312908/  1.510120, val:  55.83%, val_best:  60.00%, tr:  63.23%, tr_best:  65.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.302367/  1.505145, val:  58.33%, val_best:  60.00%, tr:  62.41%, tr_best:  65.37%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.280016/  1.494407, val:  55.42%, val_best:  60.00%, tr:  64.35%, tr_best:  65.37%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.262773/  1.468826, val:  59.58%, val_best:  60.00%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.243869/  1.469148, val:  57.08%, val_best:  60.00%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.234196/  1.453676, val:  57.08%, val_best:  60.00%, tr:  64.15%, tr_best:  66.60%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.206181/  1.445538, val:  58.33%, val_best:  60.00%, tr:  66.09%, tr_best:  66.60%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.194310/  1.433717, val:  61.25%, val_best:  61.25%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.190008/  1.437136, val:  58.75%, val_best:  61.25%, tr:  65.17%, tr_best:  67.62%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.171175/  1.427524, val:  62.08%, val_best:  62.08%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.149975/  1.414636, val:  59.58%, val_best:  62.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.145411/  1.407644, val:  63.75%, val_best:  63.75%, tr:  69.15%, tr_best:  69.77%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.133959/  1.392657, val:  64.17%, val_best:  64.17%, tr:  68.95%, tr_best:  69.77%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.117488/  1.402194, val:  61.25%, val_best:  64.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.114650/  1.384160, val:  61.67%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.096739/  1.380825, val:  58.75%, val_best:  64.17%, tr:  70.79%, tr_best:  71.81%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.091045/  1.371749, val:  60.83%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.081943/  1.377722, val:  62.50%, val_best:  64.17%, tr:  70.99%, tr_best:  71.81%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.069469/  1.389074, val:  61.25%, val_best:  64.17%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.063368/  1.375488, val:  62.50%, val_best:  64.17%, tr:  72.73%, tr_best:  73.95%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.052292/  1.350606, val:  64.58%, val_best:  64.58%, tr:  72.42%, tr_best:  73.95%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.038437/  1.369132, val:  61.25%, val_best:  64.58%, tr:  73.03%, tr_best:  73.95%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.033957/  1.362166, val:  60.42%, val_best:  64.58%, tr:  73.75%, tr_best:  73.95%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.028793/  1.338969, val:  64.58%, val_best:  64.58%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.021361/  1.322225, val:  65.00%, val_best:  65.00%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.011171/  1.323596, val:  67.50%, val_best:  67.50%, tr:  74.77%, tr_best:  75.49%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.996047/  1.330288, val:  64.17%, val_best:  67.50%, tr:  73.75%, tr_best:  75.49%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.994030/  1.319227, val:  65.83%, val_best:  67.50%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.978745/  1.313682, val:  64.58%, val_best:  67.50%, tr:  77.22%, tr_best:  78.45%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.976769/  1.314901, val:  63.33%, val_best:  67.50%, tr:  75.69%, tr_best:  78.45%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.973642/  1.312907, val:  68.33%, val_best:  68.33%, tr:  74.16%, tr_best:  78.45%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.957314/  1.300470, val:  66.25%, val_best:  68.33%, tr:  77.73%, tr_best:  78.45%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.953706/  1.316113, val:  67.08%, val_best:  68.33%, tr:  78.04%, tr_best:  78.45%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.949879/  1.311043, val:  65.00%, val_best:  68.33%, tr:  76.61%, tr_best:  78.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.951113/  1.311507, val:  67.50%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.942748/  1.294629, val:  65.42%, val_best:  68.33%, tr:  75.59%, tr_best:  80.29%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.929699/  1.307492, val:  65.00%, val_best:  68.33%, tr:  79.57%, tr_best:  80.29%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.924737/  1.313879, val:  68.33%, val_best:  68.33%, tr:  77.83%, tr_best:  80.29%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.920991/  1.313448, val:  60.83%, val_best:  68.33%, tr:  78.14%, tr_best:  80.29%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.918137/  1.294773, val:  67.92%, val_best:  68.33%, tr:  77.73%, tr_best:  80.29%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.910030/  1.311904, val:  66.67%, val_best:  68.33%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.899498/  1.316216, val:  67.92%, val_best:  68.33%, tr:  79.26%, tr_best:  80.49%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.889800/  1.316038, val:  64.17%, val_best:  68.33%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.893640/  1.301918, val:  63.33%, val_best:  68.33%, tr:  82.23%, tr_best:  83.15%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.875685/  1.327973, val:  63.75%, val_best:  68.33%, tr:  80.18%, tr_best:  83.15%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.881230/  1.308731, val:  69.17%, val_best:  69.17%, tr:  80.90%, tr_best:  83.15%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.876863/  1.307161, val:  65.83%, val_best:  69.17%, tr:  79.67%, tr_best:  83.15%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.872204/  1.323400, val:  65.83%, val_best:  69.17%, tr:  82.33%, tr_best:  83.15%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.869627/  1.319818, val:  67.92%, val_best:  69.17%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.859880/  1.300537, val:  68.33%, val_best:  69.17%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.846593/  1.354111, val:  63.33%, val_best:  69.17%, tr:  83.86%, tr_best:  84.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.848980/  1.343405, val:  64.58%, val_best:  69.17%, tr:  82.74%, tr_best:  84.47%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.848458/  1.317158, val:  70.42%, val_best:  70.42%, tr:  82.33%, tr_best:  84.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.852612/  1.330100, val:  64.58%, val_best:  70.42%, tr:  84.17%, tr_best:  84.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.834399/  1.330367, val:  64.58%, val_best:  70.42%, tr:  81.61%, tr_best:  84.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.826423/  1.335395, val:  67.50%, val_best:  70.42%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.827093/  1.346238, val:  67.50%, val_best:  70.42%, tr:  84.47%, tr_best:  85.39%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.816498/  1.368155, val:  60.83%, val_best:  70.42%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.811053/  1.376341, val:  61.67%, val_best:  70.42%, tr:  85.90%, tr_best:  86.41%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.825768/  1.347697, val:  65.00%, val_best:  70.42%, tr:  85.09%, tr_best:  86.41%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.807949/  1.346545, val:  66.25%, val_best:  70.42%, tr:  86.01%, tr_best:  86.41%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.816280/  1.343462, val:  68.33%, val_best:  70.42%, tr:  83.96%, tr_best:  86.41%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.795494/  1.356621, val:  67.92%, val_best:  70.42%, tr:  85.60%, tr_best:  86.41%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.813072/  1.367792, val:  63.75%, val_best:  70.42%, tr:  86.31%, tr_best:  86.41%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.797813/  1.350766, val:  69.58%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.792662/  1.358648, val:  64.58%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.786989/  1.367459, val:  68.33%, val_best:  70.42%, tr:  85.80%, tr_best:  87.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.791787/  1.356481, val:  65.83%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.780600/  1.355493, val:  67.50%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.783068/  1.348840, val:  70.42%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.775147/  1.362694, val:  67.92%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.772074/  1.382532, val:  66.67%, val_best:  70.42%, tr:  89.07%, tr_best:  89.17%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.761540/  1.353581, val:  71.25%, val_best:  71.25%, tr:  86.93%, tr_best:  89.17%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.760388/  1.354806, val:  68.75%, val_best:  71.25%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.750785/  1.367211, val:  67.50%, val_best:  71.25%, tr:  89.38%, tr_best:  89.68%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.747085/  1.403151, val:  65.00%, val_best:  71.25%, tr:  88.76%, tr_best:  89.68%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.749522/  1.348405, val:  70.42%, val_best:  71.25%, tr:  88.46%, tr_best:  89.68%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.738451/  1.353116, val:  72.08%, val_best:  72.08%, tr:  89.17%, tr_best:  89.68%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.737961/  1.395453, val:  65.83%, val_best:  72.08%, tr:  88.66%, tr_best:  89.68%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.747235/  1.374128, val:  64.58%, val_best:  72.08%, tr:  87.74%, tr_best:  89.68%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.743427/  1.372280, val:  67.92%, val_best:  72.08%, tr:  88.25%, tr_best:  89.68%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.736625/  1.386616, val:  70.00%, val_best:  72.08%, tr:  89.48%, tr_best:  89.68%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.732772/  1.414046, val:  69.17%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.737089/  1.340491, val:  72.92%, val_best:  72.92%, tr:  86.62%, tr_best:  90.09%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.720904/  1.374116, val:  65.83%, val_best:  72.92%, tr:  89.58%, tr_best:  90.09%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.739165/  1.351306, val:  70.00%, val_best:  72.92%, tr:  88.25%, tr_best:  90.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382819dc27e4487f8b49608ef1543ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▄▂▅▆▃▄▅▅▆▆▅▅▆▆▅▇▇▆▇▅▆▇█▇▇▇▅▆▇▅▆▆▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.88253</td></tr><tr><td>tr_epoch_loss</td><td>0.73917</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.35131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-sweep-218</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sy98e9w9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sy98e9w9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_064732-sy98e9w9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8sskzrwc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_065351-8sskzrwc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8sskzrwc' target=\"_blank\">exalted-sweep-220</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8sskzrwc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8sskzrwc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 19.492006/ 24.925041, val:  40.42%, val_best:  40.42%, tr:  27.07%, tr_best:  27.07%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 21.752596/ 30.846842, val:  34.58%, val_best:  40.42%, tr:  43.31%, tr_best:  43.31%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 20.438950/ 31.329468, val:  46.67%, val_best:  46.67%, tr:  52.09%, tr_best:  52.09%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 17.400526/ 13.995081, val:  45.83%, val_best:  46.67%, tr:  56.08%, tr_best:  56.08%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 17.521301/ 27.458693, val:  48.75%, val_best:  48.75%, tr:  58.43%, tr_best:  58.43%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 14.285870/ 24.032524, val:  47.92%, val_best:  48.75%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 10.681841/ 19.103954, val:  55.83%, val_best:  55.83%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  8.761154/ 13.437865, val:  59.17%, val_best:  59.17%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  5.857863/ 14.932174, val:  56.25%, val_best:  59.17%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  5.649784/ 17.658754, val:  57.08%, val_best:  59.17%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  3.493065/ 12.730514, val:  70.83%, val_best:  70.83%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  3.120324/ 14.794093, val:  68.33%, val_best:  70.83%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  2.495167/ 13.728962, val:  72.50%, val_best:  72.50%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  1.862848/ 13.233733, val:  75.42%, val_best:  75.42%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  1.706442/ 16.107244, val:  71.67%, val_best:  75.42%, tr:  96.02%, tr_best:  96.22%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  1.150652/ 14.173688, val:  72.50%, val_best:  75.42%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  1.104730/ 13.600637, val:  72.92%, val_best:  75.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  0.600846/ 13.336327, val:  74.58%, val_best:  75.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.526594/ 14.162884, val:  75.83%, val_best:  75.83%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.338823/ 13.958343, val:  73.33%, val_best:  75.83%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.174100/ 13.924384, val:  77.92%, val_best:  77.92%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.141166/ 13.995344, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.141824/ 13.698087, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.256667/ 14.991755, val:  72.08%, val_best:  77.92%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.097524/ 14.389263, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.052960/ 14.124271, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.081892/ 13.883464, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.042270/ 14.177569, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.045684/ 14.002277, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.041125/ 14.218357, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.028065/ 13.727837, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.015355/ 14.402541, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.018187/ 13.741685, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.044222/ 14.200899, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.024860/ 14.301953, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.013661/ 14.559512, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.021675/ 14.307425, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.011111/ 14.335514, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.004883/ 14.483067, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.016793/ 13.972253, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.015633/ 14.223593, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.008012/ 14.190360, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.009294/ 13.667612, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.005618/ 13.843977, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.001900/ 14.020092, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.003468/ 13.756652, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.003077/ 13.884551, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.006781/ 13.950608, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.004414/ 13.933332, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.016405/ 14.157502, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.007263/ 14.096677, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.005993/ 14.458195, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.006168/ 14.172655, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.004114/ 14.332994, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.004978/ 14.159115, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.002597/ 13.991678, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.004186/ 13.931104, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.010190/ 14.050923, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.004541/ 14.463580, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.006437/ 14.407969, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.002811/ 14.361989, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.003020/ 14.232228, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.002776/ 14.529378, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.002574/ 14.293284, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.004073/ 14.233249, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.004845/ 14.040286, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.005134/ 14.254866, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.003204/ 14.733547, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.019465/ 14.764458, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.006250/ 14.668485, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.002914/ 14.459341, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.004477/ 14.499601, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.002254/ 15.031194, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.003644/ 14.569346, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.001612/ 14.364840, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.002879/ 14.438311, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.001634/ 14.393322, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.001161/ 14.452110, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.002328/ 14.429814, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000825/ 14.516822, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000032/ 14.437377, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000006/ 14.424967, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000006/ 14.418242, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000005/ 14.410483, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000005/ 14.408130, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.396242, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.387143, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.387894, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.375842, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.375052, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.380306, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000004/ 14.375839, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000748/ 14.409760, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.002788/ 14.416893, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000875/ 14.465215, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000929/ 14.516248, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000689/ 14.590699, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.001076/ 14.659199, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000130/ 14.640340, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000744/ 14.350735, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2e8ba349d948fdbf037ab44a7311a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▅█▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▄▄▇▆▇▇▇▇█▇█▇▇████▇█▇█▇████▇█████▇▇██▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▄▄▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▄▄▇▆▇▇▇▇█▇█▇▇████▇█▇█▇████▇█████▇▇██▇</td></tr><tr><td>val_loss</td><td>▆█▆▁▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00074</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>14.35073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-220</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8sskzrwc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8sskzrwc</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_065351-8sskzrwc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p9j3s2gb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_070055-p9j3s2gb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p9j3s2gb' target=\"_blank\">fast-sweep-222</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p9j3s2gb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p9j3s2gb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.957073/  1.538933, val:  54.58%, val_best:  54.58%, tr:  31.15%, tr_best:  31.15%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.291305/  1.396871, val:  55.83%, val_best:  55.83%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.101060/  1.289411, val:  58.75%, val_best:  58.75%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.920764/  1.387030, val:  60.83%, val_best:  60.83%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.808189/  1.329958, val:  61.25%, val_best:  61.25%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.733569/  1.266379, val:  69.58%, val_best:  69.58%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.664230/  1.248816, val:  67.50%, val_best:  69.58%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.590696/  1.337065, val:  63.75%, val_best:  69.58%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.551449/  1.362797, val:  64.17%, val_best:  69.58%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.445037/  1.383757, val:  67.08%, val_best:  69.58%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.408753/  1.507142, val:  67.08%, val_best:  69.58%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.344364/  1.529292, val:  75.00%, val_best:  75.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.288097/  1.527572, val:  73.33%, val_best:  75.00%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.252045/  1.606242, val:  74.58%, val_best:  75.00%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.186839/  1.795442, val:  70.83%, val_best:  75.00%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.161989/  1.857511, val:  67.92%, val_best:  75.00%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.115854/  1.953218, val:  71.25%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.141981/  1.990165, val:  72.08%, val_best:  75.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.097326/  1.964939, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.087319/  1.982119, val:  75.42%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.061569/  2.013613, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.043610/  2.136260, val:  72.50%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.033305/  2.083334, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.025353/  2.117206, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.020841/  2.163277, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.021782/  2.188435, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.021976/  2.243493, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.013368/  2.260771, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.012100/  2.277853, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.008842/  2.303206, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.007924/  2.270687, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.007363/  2.288495, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.006937/  2.347878, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.005396/  2.352182, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.005570/  2.372597, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.004986/  2.362289, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.004246/  2.363674, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.003764/  2.363402, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.003686/  2.376322, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.004391/  2.375667, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.003993/  2.409364, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.003237/  2.401194, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.002814/  2.431450, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.002773/  2.457448, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.002912/  2.433091, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.002546/  2.441670, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.002368/  2.461489, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002264/  2.449035, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002513/  2.469102, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002477/  2.464642, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002158/  2.479714, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002563/  2.493438, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.002200/  2.482085, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.002049/  2.475434, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.001813/  2.493677, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.001651/  2.485032, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002425/  2.497836, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.001717/  2.481738, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.001511/  2.494472, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.001696/  2.486559, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001551/  2.506783, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001360/  2.513916, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001326/  2.506241, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001349/  2.493743, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001306/  2.498175, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001431/  2.522136, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001188/  2.525834, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001369/  2.531277, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001499/  2.537018, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001262/  2.536241, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001130/  2.553225, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001139/  2.542223, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001075/  2.555832, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001047/  2.554490, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001110/  2.561623, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001061/  2.561861, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001309/  2.574905, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001281/  2.577984, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001159/  2.575677, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001113/  2.583035, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.000960/  2.586264, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.000972/  2.590423, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.000951/  2.594494, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.000959/  2.573489, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.000928/  2.593845, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.000863/  2.582112, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000866/  2.596251, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001306/  2.585508, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001432/  2.605535, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001202/  2.612906, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.000950/  2.630672, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.000880/  2.623271, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000863/  2.624882, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.000839/  2.611538, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.000881/  2.630229, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.000767/  2.619477, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.000805/  2.623837, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001266/  2.640125, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.000922/  2.654451, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000850/  2.633842, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e954cbb86c7489ea130c9f4700a5c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▆▇▅▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▄▅▇▆▆▇▆▇▇▆▇████▇█▇▇▇███▇▇▇████▇▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▅▅▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▄▅▇▆▆▇▆▇▇▆▇████▇█▇▇▇███▇▇▇████▇▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00085</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.63384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-222</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p9j3s2gb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p9j3s2gb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_070055-p9j3s2gb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nf3hfrm5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_070711-nf3hfrm5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nf3hfrm5' target=\"_blank\">dainty-sweep-224</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nf3hfrm5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nf3hfrm5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.890403/  1.667534, val:  44.58%, val_best:  44.58%, tr:  38.10%, tr_best:  38.10%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.349822/  1.502327, val:  52.92%, val_best:  52.92%, tr:  55.46%, tr_best:  55.46%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.214151/  1.394459, val:  55.83%, val_best:  55.83%, tr:  59.75%, tr_best:  59.75%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.036723/  1.458438, val:  53.33%, val_best:  55.83%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.964649/  1.308096, val:  62.50%, val_best:  62.50%, tr:  66.91%, tr_best:  67.52%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.881368/  1.326519, val:  62.08%, val_best:  62.50%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.866657/  1.239163, val:  60.83%, val_best:  62.50%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.799554/  1.337981, val:  65.00%, val_best:  65.00%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.731130/  1.259540, val:  64.17%, val_best:  65.00%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.685438/  1.238760, val:  66.25%, val_best:  66.25%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.620810/  1.346020, val:  63.33%, val_best:  66.25%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.574323/  1.360029, val:  70.00%, val_best:  70.00%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.577663/  1.210018, val:  76.67%, val_best:  76.67%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.536643/  1.422153, val:  67.92%, val_best:  76.67%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.464359/  1.421205, val:  71.67%, val_best:  76.67%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.433848/  1.429351, val:  72.08%, val_best:  76.67%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.394562/  1.423003, val:  72.50%, val_best:  76.67%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.403955/  1.440519, val:  75.83%, val_best:  76.67%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.335432/  1.527772, val:  73.33%, val_best:  76.67%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.347017/  1.466028, val:  72.50%, val_best:  76.67%, tr:  94.89%, tr_best:  95.71%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.291067/  1.527743, val:  74.17%, val_best:  76.67%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.252304/  1.765976, val:  68.75%, val_best:  76.67%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.226288/  1.766526, val:  75.42%, val_best:  76.67%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.326287/  1.576854, val:  74.58%, val_best:  76.67%, tr:  96.02%, tr_best:  99.08%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.212945/  1.731358, val:  75.42%, val_best:  76.67%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.222221/  1.746025, val:  78.75%, val_best:  78.75%, tr:  98.26%, tr_best:  99.08%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.237464/  1.785007, val:  75.42%, val_best:  78.75%, tr:  97.34%, tr_best:  99.08%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.181977/  1.771480, val:  78.75%, val_best:  78.75%, tr:  98.77%, tr_best:  99.08%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.141673/  1.892092, val:  76.25%, val_best:  78.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.120131/  2.011315, val:  72.50%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.111989/  2.019335, val:  74.58%, val_best:  78.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.104622/  2.131638, val:  72.50%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.123747/  2.025450, val:  79.17%, val_best:  79.17%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.101415/  2.149413, val:  76.25%, val_best:  79.17%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.072384/  2.235230, val:  74.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.068258/  2.301017, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.069432/  2.262925, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.063490/  2.535014, val:  74.17%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.067473/  2.489873, val:  74.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.070015/  2.325679, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.080079/  2.443718, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.057466/  2.485702, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.039928/  2.432165, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.032150/  2.555501, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.029249/  2.556931, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.033008/  2.673413, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.026859/  2.597721, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.027634/  2.707729, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.026106/  2.700874, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.017860/  2.680171, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.016546/  2.740379, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.012990/  2.771725, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.011926/  2.836774, val:  75.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.013910/  2.863395, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.020183/  2.887614, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.023655/  2.916814, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.017818/  2.921180, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.014759/  2.857227, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.015968/  2.964841, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.013193/  2.988418, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.018575/  2.946063, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.012781/  3.002388, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.016292/  2.937699, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.014587/  3.046891, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.017806/  2.991764, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.013475/  3.091021, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.009955/  3.154451, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.010537/  3.139192, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.010409/  3.177585, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.007352/  3.175470, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.009112/  3.225933, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.014249/  3.193999, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.022916/  3.175955, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.027208/  3.115655, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.017428/  3.249905, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.012519/  3.118913, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.010860/  3.098183, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.012516/  3.065250, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.028892/  3.271783, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.024398/  3.106677, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.021577/  3.233150, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.019151/  3.243110, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.029542/  3.324734, val:  74.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.031797/  3.164316, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.022097/  3.137462, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.021068/  3.092892, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.016043/  3.101795, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.008843/  3.086174, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.007530/  3.096158, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.007461/  3.146590, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.007147/  3.135463, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.005502/  3.245006, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.006036/  3.188360, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.005788/  3.162526, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.007607/  3.241321, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.006180/  3.263452, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.006214/  3.297911, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.004204/  3.301578, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.004028/  3.264019, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.005340/  3.311540, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bcd91b4fc04de5b4f8f8c1872de029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▄▅▅▇▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▅▇▆▇▇▆▇▇▇██▇▇██▇█▇███████████▇██████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▅▇▆▇▇▆▇▇▇██▇▇██▇█▇███████████▇██████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▃▃▃▄▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇██▇▇▇█▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00534</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>3.31154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-sweep-224</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nf3hfrm5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nf3hfrm5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_070711-nf3hfrm5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iddp9o9s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba562cfca6440128540653eaea0db6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011124903832872709, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_071329-iddp9o9s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iddp9o9s' target=\"_blank\">true-sweep-226</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iddp9o9s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iddp9o9s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.479650/  2.993446, val:  21.25%, val_best:  21.25%, tr:  17.57%, tr_best:  17.57%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  4.107057/  8.108621, val:  10.42%, val_best:  21.25%, tr:  37.28%, tr_best:  37.28%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  7.242069/  5.777037, val:  48.75%, val_best:  48.75%, tr:  40.14%, tr_best:  40.14%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  7.498746/  7.666617, val:  45.83%, val_best:  48.75%, tr:  44.23%, tr_best:  44.23%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  8.080771/  9.581013, val:  34.58%, val_best:  48.75%, tr:  48.11%, tr_best:  48.11%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  8.480063/ 13.312517, val:  43.33%, val_best:  48.75%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  7.079949/  8.488198, val:  52.50%, val_best:  52.50%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  6.694595/ 13.880443, val:  40.83%, val_best:  52.50%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  7.018615/ 10.609278, val:  45.42%, val_best:  52.50%, tr:  60.16%, tr_best:  60.27%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  7.870876/ 10.894213, val:  49.17%, val_best:  52.50%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  6.803474/ 10.242477, val:  54.58%, val_best:  54.58%, tr:  60.67%, tr_best:  61.90%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  6.234993/ 12.612011, val:  43.33%, val_best:  54.58%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  8.761994/  9.460828, val:  52.50%, val_best:  54.58%, tr:  61.29%, tr_best:  65.27%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  8.313912/ 13.430494, val:  45.00%, val_best:  54.58%, tr:  62.41%, tr_best:  65.27%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  5.680099/ 13.832152, val:  49.17%, val_best:  54.58%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  6.462449/ 12.766828, val:  51.67%, val_best:  54.58%, tr:  69.15%, tr_best:  72.73%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  6.491979/ 15.568536, val:  51.67%, val_best:  54.58%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  7.081317/ 15.896900, val:  58.75%, val_best:  58.75%, tr:  70.17%, tr_best:  73.54%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  8.170728/ 13.384056, val:  61.25%, val_best:  61.25%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  6.701017/ 14.572326, val:  55.83%, val_best:  61.25%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  6.467099/ 15.665622, val:  55.00%, val_best:  61.25%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  7.352414/ 17.519480, val:  59.17%, val_best:  61.25%, tr:  77.94%, tr_best:  78.96%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  6.277777/ 14.119860, val:  63.33%, val_best:  63.33%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  6.043256/ 16.062000, val:  56.67%, val_best:  63.33%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  5.158538/ 15.577402, val:  65.83%, val_best:  65.83%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  5.605557/ 17.692366, val:  62.08%, val_best:  65.83%, tr:  86.41%, tr_best:  90.30%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  5.462774/ 17.559893, val:  66.67%, val_best:  66.67%, tr:  89.58%, tr_best:  90.30%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  5.282489/ 18.533310, val:  61.67%, val_best:  66.67%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  5.204866/ 17.467260, val:  67.50%, val_best:  67.50%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  5.482911/ 21.296762, val:  60.83%, val_best:  67.50%, tr:  90.91%, tr_best:  91.83%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  5.096535/ 20.433662, val:  65.42%, val_best:  67.50%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  4.398180/ 18.688246, val:  71.25%, val_best:  71.25%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  5.427049/ 23.568096, val:  64.58%, val_best:  71.25%, tr:  93.05%, tr_best:  96.94%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  6.011375/ 22.251278, val:  72.50%, val_best:  72.50%, tr:  91.83%, tr_best:  96.94%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  5.169461/ 24.946884, val:  63.75%, val_best:  72.50%, tr:  96.12%, tr_best:  96.94%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  4.613302/ 23.282854, val:  67.92%, val_best:  72.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  4.867965/ 23.837454, val:  68.75%, val_best:  72.50%, tr:  95.81%, tr_best:  97.24%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  5.075202/ 26.761637, val:  67.92%, val_best:  72.50%, tr:  96.73%, tr_best:  97.24%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  5.724993/ 25.907959, val:  69.17%, val_best:  72.50%, tr:  95.61%, tr_best:  97.24%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  5.264899/ 26.417667, val:  69.17%, val_best:  72.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  4.445087/ 26.978519, val:  74.17%, val_best:  74.17%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  4.590026/ 28.898249, val:  66.67%, val_best:  74.17%, tr:  98.06%, tr_best:  98.37%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  4.532638/ 29.560472, val:  68.33%, val_best:  74.17%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  4.348337/ 29.428093, val:  72.08%, val_best:  74.17%, tr:  97.04%, tr_best:  98.67%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  3.775542/ 29.145948, val:  67.50%, val_best:  74.17%, tr:  98.26%, tr_best:  98.67%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  3.545681/ 30.365831, val:  75.00%, val_best:  75.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  3.914960/ 31.847410, val:  67.50%, val_best:  75.00%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  3.657470/ 32.099026, val:  70.00%, val_best:  75.00%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  4.019835/ 32.716244, val:  67.92%, val_best:  75.00%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  3.680421/ 34.375908, val:  71.25%, val_best:  75.00%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  3.650151/ 35.048992, val:  69.58%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  4.030113/ 37.621952, val:  66.25%, val_best:  75.00%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  4.147552/ 38.609150, val:  67.50%, val_best:  75.00%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  3.915763/ 37.505402, val:  69.17%, val_best:  75.00%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  3.487345/ 38.715401, val:  70.42%, val_best:  75.00%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  3.761055/ 38.414116, val:  68.33%, val_best:  75.00%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  3.672261/ 40.111786, val:  65.83%, val_best:  75.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  3.481564/ 40.337391, val:  66.25%, val_best:  75.00%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  3.306478/ 41.295334, val:  63.75%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  3.602021/ 40.112427, val:  65.42%, val_best:  75.00%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  3.957043/ 40.675457, val:  71.67%, val_best:  75.00%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  3.449193/ 40.851334, val:  72.92%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  3.487130/ 42.178131, val:  70.42%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  3.253699/ 43.399933, val:  72.92%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  3.626119/ 44.274120, val:  71.67%, val_best:  75.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  3.339926/ 43.941563, val:  71.67%, val_best:  75.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  3.122819/ 44.478714, val:  69.17%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  2.935009/ 45.089806, val:  68.75%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  3.319137/ 44.674351, val:  69.58%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  3.248793/ 46.614178, val:  70.83%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  3.153820/ 47.461090, val:  67.08%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  3.302810/ 48.621227, val:  68.75%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  3.337395/ 50.804646, val:  68.33%, val_best:  75.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  3.383861/ 48.916416, val:  69.58%, val_best:  75.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  3.638249/ 49.180744, val:  69.58%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  3.611159/ 50.425884, val:  67.08%, val_best:  75.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  3.333563/ 52.207821, val:  68.33%, val_best:  75.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  2.980093/ 53.114555, val:  64.58%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  3.049456/ 52.940514, val:  68.75%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  3.420209/ 56.665657, val:  65.42%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  3.247947/ 53.142368, val:  73.75%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  2.782830/ 53.549244, val:  70.00%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  2.756633/ 53.269825, val:  72.50%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  3.335035/ 55.849274, val:  67.92%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  3.112998/ 53.542007, val:  71.25%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  3.335958/ 54.631981, val:  67.92%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  3.040011/ 53.425091, val:  70.42%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  2.911891/ 54.343124, val:  70.83%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  2.844394/ 55.524723, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  2.642151/ 56.614193, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  2.974586/ 56.990955, val:  70.83%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  2.760375/ 57.374249, val:  71.67%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  2.513775/ 56.905010, val:  69.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  2.477070/ 55.713890, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  2.426879/ 57.112900, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  2.512061/ 58.666718, val:  70.83%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  2.234900/ 60.173756, val:  68.33%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  2.389233/ 58.595825, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  2.339033/ 57.542648, val:  70.42%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  2.476833/ 57.963139, val:  74.17%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17836e2825dd425e9043f0141da75ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▃▂▅▆▄▇▇▇██▆▇▇█▇██████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▃▄▅▅▅▆▆▆▇▇▆▇▇▇▇▇▇██▇█▇▇██▇▇▇▇▇▇███████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▅▆▆▇▇▇▇██████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁▆▇▆▇█▅▆▆▆▄▄▄▄▃▄▄▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▅▅▅▆▆▆▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▃▄▅▅▅▆▆▆▇▇▆▇▇▇▇▇▇██▇█▇▇██▇▇▇▇▇▇███████</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▂▂▃▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99898</td></tr><tr><td>tr_epoch_loss</td><td>2.47683</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>57.96314</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-226</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iddp9o9s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iddp9o9s</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_071329-iddp9o9s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x8nd60t9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_072035-x8nd60t9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x8nd60t9' target=\"_blank\">dutiful-sweep-228</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x8nd60t9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x8nd60t9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.144575/  1.817533, val:  41.25%, val_best:  41.25%, tr:  21.25%, tr_best:  21.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.491291/  1.456961, val:  53.75%, val_best:  53.75%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.279740/  1.418671, val:  53.75%, val_best:  53.75%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.175622/  1.402506, val:  55.83%, val_best:  55.83%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.119980/  1.366083, val:  58.75%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.060521/  1.300567, val:  65.83%, val_best:  65.83%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.000824/  1.301821, val:  61.25%, val_best:  65.83%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.985290/  1.314859, val:  61.25%, val_best:  65.83%, tr:  69.05%, tr_best:  70.68%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.949520/  1.354883, val:  64.58%, val_best:  65.83%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934873/  1.356147, val:  57.92%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.923953/  1.396143, val:  56.67%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.875370/  1.339741, val:  62.50%, val_best:  65.83%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.883515/  1.354796, val:  62.50%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.864338/  1.359563, val:  63.75%, val_best:  65.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.817443/  1.511845, val:  62.50%, val_best:  65.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.809220/  1.439581, val:  61.67%, val_best:  65.83%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.819770/  1.386554, val:  64.17%, val_best:  65.83%, tr:  81.10%, tr_best:  81.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.783346/  1.407303, val:  67.08%, val_best:  67.08%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.762966/  1.542733, val:  59.17%, val_best:  67.08%, tr:  84.07%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.764121/  1.509853, val:  67.08%, val_best:  67.08%, tr:  83.96%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.738797/  1.569989, val:  62.92%, val_best:  67.08%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.716952/  1.523091, val:  64.17%, val_best:  67.08%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.725320/  1.552056, val:  63.33%, val_best:  67.08%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698502/  1.585925, val:  65.00%, val_best:  67.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.677743/  1.635015, val:  64.58%, val_best:  67.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.680546/  1.617494, val:  67.92%, val_best:  67.92%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.685079/  1.622059, val:  68.33%, val_best:  68.33%, tr:  90.09%, tr_best:  91.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.668759/  1.668863, val:  67.50%, val_best:  68.33%, tr:  90.91%, tr_best:  91.11%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.670493/  1.717578, val:  68.33%, val_best:  68.33%, tr:  91.01%, tr_best:  91.11%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.621386/  1.749446, val:  64.17%, val_best:  68.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.624418/  1.789540, val:  65.83%, val_best:  68.33%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.636828/  1.767424, val:  65.00%, val_best:  68.33%, tr:  92.03%, tr_best:  93.77%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.626651/  1.795750, val:  65.83%, val_best:  68.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.638346/  1.848629, val:  63.33%, val_best:  68.33%, tr:  92.24%, tr_best:  93.87%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.597420/  1.957576, val:  63.33%, val_best:  68.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.611032/  1.996146, val:  63.33%, val_best:  68.33%, tr:  93.46%, tr_best:  95.10%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.591873/  1.939366, val:  65.83%, val_best:  68.33%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.591366/  1.982105, val:  65.00%, val_best:  68.33%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.582523/  2.001446, val:  68.33%, val_best:  68.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.564702/  2.022887, val:  67.50%, val_best:  68.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.565151/  2.120297, val:  67.92%, val_best:  68.33%, tr:  95.71%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.557068/  2.140752, val:  65.83%, val_best:  68.33%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.525257/  2.118379, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.539178/  2.197912, val:  63.75%, val_best:  68.33%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.522206/  2.220392, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.512232/  2.242227, val:  66.67%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.501202/  2.228575, val:  67.08%, val_best:  68.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.494333/  2.312970, val:  65.42%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.494586/  2.318042, val:  66.25%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.508738/  2.396864, val:  64.58%, val_best:  68.33%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.490841/  2.432610, val:  65.00%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.501619/  2.443867, val:  65.42%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.482933/  2.479905, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.477838/  2.538728, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.479183/  2.583109, val:  65.83%, val_best:  68.33%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.468027/  2.644629, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.473856/  2.653191, val:  65.42%, val_best:  68.33%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.480465/  2.618025, val:  68.33%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.452467/  2.733135, val:  62.50%, val_best:  68.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.458238/  2.680492, val:  67.92%, val_best:  68.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.466325/  2.711759, val:  67.08%, val_best:  68.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.461355/  2.762516, val:  67.50%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.448615/  2.830178, val:  65.00%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.442779/  2.875696, val:  66.25%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.452675/  2.929097, val:  65.42%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.441500/  2.885522, val:  65.83%, val_best:  68.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.448056/  2.954639, val:  64.58%, val_best:  68.33%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.472065/  2.912072, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.455693/  3.063578, val:  63.75%, val_best:  68.33%, tr:  98.67%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.457066/  3.023675, val:  68.75%, val_best:  68.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.445481/  3.087715, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.458703/  3.106065, val:  62.92%, val_best:  68.75%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.456814/  3.125111, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.452207/  3.070091, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.436011/  3.146578, val:  64.58%, val_best:  68.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.432641/  3.278949, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.430715/  3.224578, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.435468/  3.271761, val:  65.83%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.444355/  3.210975, val:  66.67%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.419681/  3.283675, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.430523/  3.323857, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.411631/  3.358387, val:  67.50%, val_best:  68.75%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424088/  3.491949, val:  64.58%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.428729/  3.484405, val:  64.17%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.420097/  3.429357, val:  66.25%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406717/  3.461854, val:  65.42%, val_best:  68.75%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.403112/  3.600858, val:  66.67%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.411629/  3.637316, val:  63.75%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.412038/  3.625228, val:  66.25%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.406560/  3.561375, val:  65.42%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.414159/  3.600652, val:  65.83%, val_best:  68.75%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.415171/  3.754240, val:  63.75%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.403950/  3.739951, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.415218/  3.729659, val:  65.42%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.422088/  3.777289, val:  64.17%, val_best:  68.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.404644/  3.859814, val:  66.25%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.400590/  3.955474, val:  63.75%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.398874/  3.932581, val:  64.58%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.372370/  3.934501, val:  65.00%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.389008/  4.001581, val:  63.75%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe311d737ec497ebe0eff747f03ac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▅▅▂▅███▇▅███▇██▇██████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.38901</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.00158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-228</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x8nd60t9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x8nd60t9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_072035-x8nd60t9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h114f824 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_072740-h114f824</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h114f824' target=\"_blank\">young-sweep-231</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h114f824' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h114f824</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.094250/  3.294857, val:  41.25%, val_best:  41.25%, tr:  38.51%, tr_best:  38.51%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.367397/  2.427882, val:  43.33%, val_best:  43.33%, tr:  49.74%, tr_best:  49.74%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.498442/  2.381335, val:  53.33%, val_best:  53.33%, tr:  52.91%, tr_best:  52.91%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.188078/  2.969939, val:  47.50%, val_best:  53.33%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.118493/  2.681616, val:  52.50%, val_best:  53.33%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.175186/  2.724231, val:  51.67%, val_best:  53.33%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.455878/  2.158605, val:  60.83%, val_best:  60.83%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.225920/  2.566000, val:  47.50%, val_best:  60.83%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.106806/  1.732099, val:  66.25%, val_best:  66.25%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.308130/  3.035214, val:  54.58%, val_best:  66.25%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.192407/  2.211750, val:  63.75%, val_best:  66.25%, tr:  79.16%, tr_best:  81.10%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.034682/  3.285844, val:  48.33%, val_best:  66.25%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.145919/  2.400250, val:  64.58%, val_best:  66.25%, tr:  82.23%, tr_best:  84.68%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.932410/  2.955026, val:  60.42%, val_best:  66.25%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  1.011308/  2.784669, val:  66.67%, val_best:  66.67%, tr:  86.11%, tr_best:  86.52%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.987416/  2.653951, val:  69.17%, val_best:  69.17%, tr:  86.11%, tr_best:  86.52%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.816604/  2.489654, val:  72.50%, val_best:  72.50%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.621122/  2.707951, val:  63.75%, val_best:  72.50%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.601794/  2.718535, val:  69.58%, val_best:  72.50%, tr:  92.85%, tr_best:  93.77%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.597865/  2.634878, val:  70.42%, val_best:  72.50%, tr:  93.16%, tr_best:  93.77%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.445717/  2.731243, val:  66.25%, val_best:  72.50%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.712321/  2.932344, val:  70.00%, val_best:  72.50%, tr:  90.60%, tr_best:  95.20%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.489694/  3.029558, val:  65.42%, val_best:  72.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.566656/  3.093782, val:  66.25%, val_best:  72.50%, tr:  94.28%, tr_best:  95.91%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.309665/  2.863394, val:  71.67%, val_best:  72.50%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.289522/  2.512579, val:  77.50%, val_best:  77.50%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.283843/  2.809909, val:  71.67%, val_best:  77.50%, tr:  97.55%, tr_best:  98.57%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.288838/  2.895334, val:  72.92%, val_best:  77.50%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.295404/  2.674529, val:  75.42%, val_best:  77.50%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.464941/  2.971591, val:  71.25%, val_best:  77.50%, tr:  95.61%, tr_best:  98.57%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.195911/  2.673456, val:  78.33%, val_best:  78.33%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.127901/  2.840378, val:  72.50%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.146038/  2.779009, val:  72.50%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.125592/  2.827093, val:  76.25%, val_best:  78.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.100962/  2.949701, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.091520/  2.891922, val:  75.83%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.088837/  2.804749, val:  75.42%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.111230/  2.878716, val:  76.25%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.079889/  2.953648, val:  73.75%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.070800/  2.980651, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.058680/  2.944419, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.051151/  2.984052, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.052841/  3.021832, val:  77.50%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.050766/  3.111216, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.044544/  3.122291, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.041958/  3.124017, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.047929/  3.114327, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.038536/  3.133325, val:  77.92%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.037690/  3.088305, val:  76.67%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.031065/  3.090871, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.025630/  3.203345, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.022745/  3.196448, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.020347/  3.154758, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.020921/  3.216019, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.019968/  3.145110, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.018525/  3.183621, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.016791/  3.233181, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.017065/  3.214424, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.016010/  3.273798, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.015035/  3.270730, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.016938/  3.271034, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.014768/  3.331501, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.013329/  3.322555, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.011792/  3.351944, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.011908/  3.386855, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.012237/  3.405166, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.011100/  3.399595, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.011214/  3.447018, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.010617/  3.435578, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.009601/  3.442814, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.011320/  3.444812, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.012109/  3.503750, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.019227/  3.546960, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.013801/  3.514605, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.009583/  3.495657, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.009001/  3.497153, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.009497/  3.544178, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.010912/  3.596246, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.009084/  3.591234, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.009058/  3.599465, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.007916/  3.569847, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.006604/  3.554199, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.008930/  3.615921, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.008399/  3.610737, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.008725/  3.602313, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.006650/  3.564742, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.009139/  3.566262, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.010264/  3.666370, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.007684/  3.630007, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.007189/  3.669089, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.008616/  3.634579, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.008218/  3.677475, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.005708/  3.668527, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.004900/  3.695651, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.005864/  3.678808, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.005113/  3.660759, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.004968/  3.686032, val:  79.58%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.004516/  3.669384, val:  80.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.004312/  3.679521, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.004619/  3.707420, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b514fb34bb794f71a885cdc2a4bc9c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▂▇▄▅▇▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▂▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>tr_acc</td><td>▁▃▃▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▇▄▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▂▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>val_loss</td><td>▆▁▃▂▅▁▃▃▂▄▄▃▄▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00462</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>3.70742</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-231</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h114f824' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h114f824</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_072740-h114f824/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kijn5c1a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_073441-kijn5c1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kijn5c1a' target=\"_blank\">magic-sweep-233</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kijn5c1a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kijn5c1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.144575/  1.817533, val:  41.25%, val_best:  41.25%, tr:  21.25%, tr_best:  21.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.491291/  1.456961, val:  53.75%, val_best:  53.75%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.279740/  1.418671, val:  53.75%, val_best:  53.75%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.175622/  1.402506, val:  55.83%, val_best:  55.83%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.119980/  1.366083, val:  58.75%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.060521/  1.300567, val:  65.83%, val_best:  65.83%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.000824/  1.301821, val:  61.25%, val_best:  65.83%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.985290/  1.314859, val:  61.25%, val_best:  65.83%, tr:  69.05%, tr_best:  70.68%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.949520/  1.354883, val:  64.58%, val_best:  65.83%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934873/  1.356147, val:  57.92%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.923953/  1.396143, val:  56.67%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.875370/  1.339741, val:  62.50%, val_best:  65.83%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.883515/  1.354796, val:  62.50%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.864338/  1.359563, val:  63.75%, val_best:  65.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.817443/  1.511845, val:  62.50%, val_best:  65.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.809220/  1.439581, val:  61.67%, val_best:  65.83%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.819770/  1.386554, val:  64.17%, val_best:  65.83%, tr:  81.10%, tr_best:  81.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.783346/  1.407303, val:  67.08%, val_best:  67.08%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.762966/  1.542733, val:  59.17%, val_best:  67.08%, tr:  84.07%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.764121/  1.509853, val:  67.08%, val_best:  67.08%, tr:  83.96%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.738797/  1.569989, val:  62.92%, val_best:  67.08%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.716952/  1.523091, val:  64.17%, val_best:  67.08%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.725320/  1.552056, val:  63.33%, val_best:  67.08%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698502/  1.585925, val:  65.00%, val_best:  67.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.677743/  1.635015, val:  64.58%, val_best:  67.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.680546/  1.617494, val:  67.92%, val_best:  67.92%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.685079/  1.622059, val:  68.33%, val_best:  68.33%, tr:  90.09%, tr_best:  91.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.668759/  1.668863, val:  67.50%, val_best:  68.33%, tr:  90.91%, tr_best:  91.11%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.670493/  1.717578, val:  68.33%, val_best:  68.33%, tr:  91.01%, tr_best:  91.11%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.621386/  1.749446, val:  64.17%, val_best:  68.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.624418/  1.789540, val:  65.83%, val_best:  68.33%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.636828/  1.767424, val:  65.00%, val_best:  68.33%, tr:  92.03%, tr_best:  93.77%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.626651/  1.795750, val:  65.83%, val_best:  68.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.638346/  1.848629, val:  63.33%, val_best:  68.33%, tr:  92.24%, tr_best:  93.87%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.597420/  1.957576, val:  63.33%, val_best:  68.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.611032/  1.996146, val:  63.33%, val_best:  68.33%, tr:  93.46%, tr_best:  95.10%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.591873/  1.939366, val:  65.83%, val_best:  68.33%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.591366/  1.982105, val:  65.00%, val_best:  68.33%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.582523/  2.001446, val:  68.33%, val_best:  68.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.564702/  2.022887, val:  67.50%, val_best:  68.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.565151/  2.120297, val:  67.92%, val_best:  68.33%, tr:  95.71%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.557068/  2.140752, val:  65.83%, val_best:  68.33%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.525257/  2.118379, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.539178/  2.197912, val:  63.75%, val_best:  68.33%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.522206/  2.220392, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.512232/  2.242227, val:  66.67%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.501202/  2.228575, val:  67.08%, val_best:  68.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.494333/  2.312970, val:  65.42%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.494586/  2.318042, val:  66.25%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.508738/  2.396864, val:  64.58%, val_best:  68.33%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.490841/  2.432610, val:  65.00%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.501619/  2.443867, val:  65.42%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.482933/  2.479905, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.477838/  2.538728, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.479183/  2.583109, val:  65.83%, val_best:  68.33%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.468027/  2.644629, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.473856/  2.653191, val:  65.42%, val_best:  68.33%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.480465/  2.618025, val:  68.33%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.452467/  2.733135, val:  62.50%, val_best:  68.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.458238/  2.680492, val:  67.92%, val_best:  68.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.466325/  2.711759, val:  67.08%, val_best:  68.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.461355/  2.762516, val:  67.50%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.448615/  2.830178, val:  65.00%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.442779/  2.875696, val:  66.25%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.452675/  2.929097, val:  65.42%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.441500/  2.885522, val:  65.83%, val_best:  68.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.448056/  2.954639, val:  64.58%, val_best:  68.33%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.472065/  2.912072, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.455693/  3.063578, val:  63.75%, val_best:  68.33%, tr:  98.67%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.457066/  3.023675, val:  68.75%, val_best:  68.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.445481/  3.087715, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.458703/  3.106065, val:  62.92%, val_best:  68.75%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.456814/  3.125111, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.452207/  3.070091, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.436011/  3.146578, val:  64.58%, val_best:  68.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.432641/  3.278949, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.430715/  3.224578, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.435468/  3.271761, val:  65.83%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.444355/  3.210975, val:  66.67%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.419681/  3.283675, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.430523/  3.323857, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.411631/  3.358387, val:  67.50%, val_best:  68.75%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424088/  3.491949, val:  64.58%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.428729/  3.484405, val:  64.17%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.420097/  3.429357, val:  66.25%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406717/  3.461854, val:  65.42%, val_best:  68.75%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.403112/  3.600858, val:  66.67%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.411629/  3.637316, val:  63.75%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.412038/  3.625228, val:  66.25%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.406560/  3.561375, val:  65.42%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.414159/  3.600652, val:  65.83%, val_best:  68.75%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.415171/  3.754240, val:  63.75%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.403950/  3.739951, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.415218/  3.729659, val:  65.42%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.422088/  3.777289, val:  64.17%, val_best:  68.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.404644/  3.859814, val:  66.25%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.400590/  3.955474, val:  63.75%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.398874/  3.932581, val:  64.58%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.372370/  3.934501, val:  65.00%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.389008/  4.001581, val:  63.75%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf4559ff1124c02a6eeecb5630e7130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▅▅▂▅███▇▅███▇██▇██████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.38901</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.00158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-sweep-233</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kijn5c1a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kijn5c1a</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_073441-kijn5c1a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 65oqew6b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587846c0ddbe47c599bfe1e72d19d6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113537444422643, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_074142-65oqew6b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/65oqew6b' target=\"_blank\">curious-sweep-235</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/65oqew6b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/65oqew6b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.797782/  1.696068, val:  46.67%, val_best:  46.67%, tr:  42.49%, tr_best:  42.49%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.307692/  1.403304, val:  54.58%, val_best:  54.58%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.132484/  1.431624, val:  54.17%, val_best:  54.58%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.942977/  1.367330, val:  55.00%, val_best:  55.00%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.884871/  1.270446, val:  67.08%, val_best:  67.08%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.793003/  1.370166, val:  59.17%, val_best:  67.08%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.759183/  1.312311, val:  60.42%, val_best:  67.08%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.706946/  1.326433, val:  65.83%, val_best:  67.08%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.605652/  1.265076, val:  67.92%, val_best:  67.92%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.549964/  1.393651, val:  69.58%, val_best:  69.58%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.508516/  1.361990, val:  66.67%, val_best:  69.58%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.446665/  1.406483, val:  70.83%, val_best:  70.83%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.367867/  1.313341, val:  79.17%, val_best:  79.17%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.347614/  1.382715, val:  75.42%, val_best:  79.17%, tr:  94.08%, tr_best:  96.02%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.286374/  1.432561, val:  75.42%, val_best:  79.17%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.268290/  1.501689, val:  71.67%, val_best:  79.17%, tr:  96.42%, tr_best:  96.63%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.210560/  1.623021, val:  74.17%, val_best:  79.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.166799/  1.628274, val:  79.17%, val_best:  79.17%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.164081/  1.742159, val:  76.67%, val_best:  79.17%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.168280/  1.738995, val:  75.42%, val_best:  79.17%, tr:  98.77%, tr_best:  99.39%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.131349/  1.700485, val:  79.58%, val_best:  79.58%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.080022/  1.835946, val:  80.42%, val_best:  80.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.059258/  1.982935, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.086632/  2.008571, val:  80.00%, val_best:  80.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.062305/  1.977407, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.042143/  2.085122, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.046242/  2.143405, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.043256/  2.171574, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.035691/  2.143276, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.031444/  2.250022, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.046379/  2.172349, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.045305/  2.172130, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.061158/  2.399097, val:  77.08%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.122167/  2.310177, val:  76.67%, val_best:  80.83%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.101444/  2.198455, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.052380/  2.200867, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.028304/  2.136631, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.016874/  2.240060, val:  78.33%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.009458/  2.242340, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.006385/  2.254449, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.006257/  2.253845, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.003873/  2.280989, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.003837/  2.306387, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.002717/  2.351060, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.002312/  2.354199, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.001720/  2.389207, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.001872/  2.389309, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.001666/  2.417983, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002223/  2.433015, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002133/  2.421168, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001327/  2.455834, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001390/  2.463011, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001523/  2.490609, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001407/  2.495970, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001851/  2.523372, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.001245/  2.516623, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001586/  2.533159, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001090/  2.511035, val:  80.42%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001121/  2.534946, val:  80.42%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000988/  2.531456, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000859/  2.536772, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.000854/  2.552091, val:  80.00%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001063/  2.580180, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000983/  2.577788, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000731/  2.596882, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000890/  2.599435, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000848/  2.592478, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000642/  2.604430, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000878/  2.584235, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000628/  2.603283, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000856/  2.590712, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000825/  2.601172, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000955/  2.642989, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000963/  2.596395, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000639/  2.603691, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000687/  2.627295, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001350/  2.621650, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000581/  2.623182, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000458/  2.635096, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000499/  2.641593, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000480/  2.628582, val:  80.42%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000697/  2.660810, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000556/  2.649919, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000462/  2.675338, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000488/  2.673865, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000554/  2.671196, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000479/  2.679729, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000722/  2.677822, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000532/  2.678084, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000431/  2.687783, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000691/  2.668307, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000915/  2.682436, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000488/  2.680450, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000467/  2.678327, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000421/  2.678168, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000351/  2.680520, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000343/  2.692182, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000309/  2.687812, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000368/  2.691352, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000371/  2.706834, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce4a2ad977945feaa13e08680257333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▆▆██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▅▅▇▇▇▇██▇█▇▇▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▅▅▇▇▇▇██▇█▇▇▇████████████████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▂▁▂▃▃▄▄▅▆▇▆▆▆▆▆▇▇▇▇▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00037</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>2.70683</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-sweep-235</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/65oqew6b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/65oqew6b</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_074142-65oqew6b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u6xf1kz7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_074805-u6xf1kz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6xf1kz7' target=\"_blank\">twilight-sweep-237</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6xf1kz7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6xf1kz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304519/  2.300979, val:   9.58%, val_best:  10.00%, tr:   8.48%, tr_best:   8.48%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.272663/  2.205419, val:  15.42%, val_best:  15.42%, tr:  13.79%, tr_best:  13.79%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.015529/  1.918488, val:  44.17%, val_best:  44.17%, tr:  37.49%, tr_best:  37.49%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.736972/  1.792305, val:  46.67%, val_best:  46.67%, tr:  49.95%, tr_best:  49.95%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.588995/  1.704618, val:  53.75%, val_best:  53.75%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.516230/  1.680387, val:  56.67%, val_best:  56.67%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.459571/  1.624196, val:  58.33%, val_best:  58.33%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.418112/  1.602123, val:  61.25%, val_best:  61.25%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.392421/  1.586267, val:  57.08%, val_best:  61.25%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.362151/  1.583033, val:  54.58%, val_best:  61.25%, tr:  61.80%, tr_best:  63.33%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.334544/  1.533192, val:  59.17%, val_best:  61.25%, tr:  63.02%, tr_best:  63.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.316791/  1.524695, val:  57.08%, val_best:  61.25%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.303966/  1.531841, val:  56.67%, val_best:  61.25%, tr:  63.43%, tr_best:  64.86%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.260537/  1.594641, val:  59.17%, val_best:  61.25%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.257315/  1.505544, val:  60.00%, val_best:  61.25%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.251526/  1.493610, val:  57.92%, val_best:  61.25%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.213971/  1.460185, val:  62.50%, val_best:  62.50%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.205570/  1.492737, val:  60.42%, val_best:  62.50%, tr:  66.91%, tr_best:  68.64%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.200380/  1.489442, val:  57.50%, val_best:  62.50%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.171859/  1.468630, val:  56.67%, val_best:  62.50%, tr:  69.25%, tr_best:  69.46%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.167596/  1.450476, val:  64.17%, val_best:  64.17%, tr:  67.82%, tr_best:  69.46%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.171286/  1.449023, val:  65.83%, val_best:  65.83%, tr:  68.54%, tr_best:  69.46%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.138800/  1.446135, val:  59.58%, val_best:  65.83%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.115137/  1.466555, val:  60.83%, val_best:  65.83%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.119989/  1.403637, val:  64.58%, val_best:  65.83%, tr:  69.05%, tr_best:  73.34%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.108253/  1.402394, val:  66.67%, val_best:  66.67%, tr:  72.22%, tr_best:  73.34%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.085579/  1.432778, val:  65.83%, val_best:  66.67%, tr:  72.93%, tr_best:  73.34%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.084736/  1.391667, val:  66.25%, val_best:  66.67%, tr:  72.63%, tr_best:  73.34%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.062330/  1.435008, val:  62.50%, val_best:  66.67%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.050391/  1.437046, val:  62.50%, val_best:  66.67%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.073470/  1.441693, val:  62.08%, val_best:  66.67%, tr:  72.83%, tr_best:  75.69%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.059105/  1.433031, val:  63.33%, val_best:  66.67%, tr:  75.08%, tr_best:  75.69%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.043474/  1.402574, val:  67.50%, val_best:  67.50%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.013885/  1.428844, val:  62.08%, val_best:  67.50%, tr:  75.59%, tr_best:  75.89%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.039249/  1.424164, val:  60.42%, val_best:  67.50%, tr:  73.14%, tr_best:  75.89%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.993643/  1.387237, val:  69.17%, val_best:  69.17%, tr:  76.30%, tr_best:  76.30%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.007656/  1.384586, val:  68.33%, val_best:  69.17%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.984529/  1.383487, val:  69.58%, val_best:  69.58%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.973780/  1.399875, val:  62.92%, val_best:  69.58%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.977910/  1.404070, val:  67.08%, val_best:  69.58%, tr:  78.65%, tr_best:  82.02%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.964302/  1.447416, val:  62.92%, val_best:  69.58%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.952580/  1.385076, val:  68.75%, val_best:  69.58%, tr:  81.00%, tr_best:  82.12%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.937137/  1.431051, val:  65.83%, val_best:  69.58%, tr:  82.02%, tr_best:  82.12%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.929427/  1.405995, val:  69.58%, val_best:  69.58%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.915702/  1.387647, val:  68.75%, val_best:  69.58%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.915374/  1.390938, val:  70.83%, val_best:  70.83%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.900161/  1.384334, val:  72.50%, val_best:  72.50%, tr:  85.29%, tr_best:  85.60%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.912778/  1.386498, val:  69.58%, val_best:  72.50%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.898807/  1.371642, val:  72.50%, val_best:  72.50%, tr:  84.78%, tr_best:  87.33%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.888266/  1.401627, val:  66.67%, val_best:  72.50%, tr:  85.39%, tr_best:  87.33%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.902113/  1.394628, val:  71.67%, val_best:  72.50%, tr:  83.04%, tr_best:  87.33%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.862232/  1.443746, val:  68.75%, val_best:  72.50%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.868382/  1.400006, val:  71.67%, val_best:  72.50%, tr:  87.13%, tr_best:  87.74%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.858880/  1.395726, val:  70.83%, val_best:  72.50%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.853264/  1.406176, val:  72.92%, val_best:  72.92%, tr:  86.82%, tr_best:  88.97%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.845387/  1.472061, val:  67.50%, val_best:  72.92%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.857637/  1.384708, val:  74.58%, val_best:  74.58%, tr:  88.36%, tr_best:  89.58%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.831807/  1.440104, val:  70.00%, val_best:  74.58%, tr:  87.23%, tr_best:  89.58%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.830770/  1.414168, val:  74.58%, val_best:  74.58%, tr:  88.66%, tr_best:  89.58%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.825893/  1.381819, val:  74.17%, val_best:  74.58%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.829152/  1.431475, val:  71.67%, val_best:  74.58%, tr:  89.38%, tr_best:  89.58%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.818758/  1.434004, val:  71.67%, val_best:  74.58%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.811559/  1.396004, val:  72.08%, val_best:  74.58%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.806133/  1.447448, val:  72.50%, val_best:  74.58%, tr:  89.38%, tr_best:  90.70%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.795401/  1.420239, val:  73.75%, val_best:  74.58%, tr:  90.09%, tr_best:  90.70%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.789744/  1.428641, val:  72.08%, val_best:  74.58%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.797667/  1.424905, val:  73.33%, val_best:  74.58%, tr:  91.22%, tr_best:  91.83%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.774407/  1.435935, val:  69.58%, val_best:  74.58%, tr:  91.22%, tr_best:  91.83%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.783054/  1.408238, val:  74.17%, val_best:  74.58%, tr:  91.42%, tr_best:  91.83%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.769906/  1.408195, val:  73.33%, val_best:  74.58%, tr:  91.42%, tr_best:  91.83%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.766449/  1.450102, val:  67.50%, val_best:  74.58%, tr:  91.62%, tr_best:  91.83%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.761406/  1.438566, val:  72.92%, val_best:  74.58%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.771474/  1.436231, val:  74.58%, val_best:  74.58%, tr:  91.62%, tr_best:  92.54%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.752565/  1.434267, val:  74.58%, val_best:  74.58%, tr:  92.13%, tr_best:  92.54%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.752346/  1.438323, val:  69.58%, val_best:  74.58%, tr:  90.50%, tr_best:  92.54%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.740816/  1.433881, val:  72.08%, val_best:  74.58%, tr:  91.42%, tr_best:  92.54%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.749766/  1.449566, val:  72.92%, val_best:  74.58%, tr:  92.34%, tr_best:  92.54%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.741442/  1.429336, val:  75.83%, val_best:  75.83%, tr:  92.13%, tr_best:  92.54%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.737209/  1.421001, val:  76.67%, val_best:  76.67%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.725255/  1.470482, val:  74.17%, val_best:  76.67%, tr:  91.73%, tr_best:  92.75%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.726609/  1.432094, val:  75.42%, val_best:  76.67%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.727394/  1.453684, val:  73.75%, val_best:  76.67%, tr:  92.54%, tr_best:  92.85%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.720302/  1.470599, val:  74.17%, val_best:  76.67%, tr:  92.44%, tr_best:  92.85%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.716955/  1.428873, val:  75.42%, val_best:  76.67%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.705238/  1.473496, val:  72.92%, val_best:  76.67%, tr:  93.77%, tr_best:  94.08%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.699761/  1.487514, val:  74.17%, val_best:  76.67%, tr:  91.52%, tr_best:  94.08%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.703827/  1.490512, val:  75.83%, val_best:  76.67%, tr:  93.26%, tr_best:  94.08%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.686809/  1.491231, val:  73.33%, val_best:  76.67%, tr:  93.67%, tr_best:  94.08%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.678737/  1.485506, val:  72.50%, val_best:  76.67%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.685286/  1.449695, val:  75.42%, val_best:  76.67%, tr:  93.26%, tr_best:  94.48%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.680342/  1.483806, val:  72.92%, val_best:  76.67%, tr:  93.77%, tr_best:  94.48%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.672309/  1.533525, val:  72.08%, val_best:  76.67%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.675730/  1.494658, val:  75.00%, val_best:  76.67%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.672584/  1.520620, val:  72.08%, val_best:  76.67%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.664319/  1.547939, val:  72.50%, val_best:  76.67%, tr:  94.69%, tr_best:  95.20%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.671441/  1.559071, val:  72.92%, val_best:  76.67%, tr:  93.77%, tr_best:  95.20%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.666062/  1.499931, val:  74.58%, val_best:  76.67%, tr:  93.36%, tr_best:  95.20%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.649175/  1.550741, val:  70.00%, val_best:  76.67%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.668856/  1.506998, val:  73.75%, val_best:  76.67%, tr:  94.48%, tr_best:  95.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e465423db644263b463aba40a597809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▅▅▅▆▃▅▆▅▇▇▆▅██▆██▇█▇███▇██▆██▅██▇▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▆▆▆▇▆▇▆▇▇▇▆▇▇▇▇██▇▇██▇████▇█████████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▆▆▆▇▆▇▆▇▇▇▆▇▇▇▇██▇▇██▇████▇█████████</td></tr><tr><td>val_loss</td><td>█▇▄▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂▁▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.94484</td></tr><tr><td>tr_epoch_loss</td><td>0.66886</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>1.507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-237</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6xf1kz7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6xf1kz7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_074805-u6xf1kz7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gkzt3vrb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8cec593ab74e948c9cc7f81ab1cb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112993081203766, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_075511-gkzt3vrb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gkzt3vrb' target=\"_blank\">astral-sweep-239</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gkzt3vrb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gkzt3vrb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  3.350648/  4.231153, val:  37.92%, val_best:  37.92%, tr:  34.53%, tr_best:  34.53%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.880305/  4.195690, val:  47.08%, val_best:  47.08%, tr:  45.15%, tr_best:  45.15%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.433810/  3.789607, val:  44.58%, val_best:  47.08%, tr:  55.98%, tr_best:  55.98%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.237616/  4.372087, val:  51.67%, val_best:  51.67%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.634813/  3.785199, val:  57.08%, val_best:  57.08%, tr:  63.43%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.330441/  4.590106, val:  45.83%, val_best:  57.08%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.422461/  3.264041, val:  60.00%, val_best:  60.00%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.157748/  4.184642, val:  56.25%, val_best:  60.00%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.824362/  2.668815, val:  67.08%, val_best:  67.08%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.898790/  3.452676, val:  64.58%, val_best:  67.08%, tr:  86.52%, tr_best:  87.84%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.570974/  3.137360, val:  65.42%, val_best:  67.08%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.805181/  3.229999, val:  73.33%, val_best:  73.33%, tr:  92.75%, tr_best:  93.56%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.477957/  4.007881, val:  70.83%, val_best:  73.33%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.297631/  3.974550, val:  68.33%, val_best:  73.33%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.204366/  4.357526, val:  69.17%, val_best:  73.33%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.131616/  4.063835, val:  68.33%, val_best:  73.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.131110/  4.096120, val:  68.75%, val_best:  73.33%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.079165/  4.079432, val:  69.17%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.066978/  4.196502, val:  70.83%, val_best:  73.33%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.041267/  4.396893, val:  69.58%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.019760/  4.149798, val:  72.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.018938/  4.194882, val:  72.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.014833/  4.318002, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.011532/  4.207015, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.011033/  4.325696, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.005258/  4.183952, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.006322/  4.246120, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.003632/  4.492140, val:  71.67%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.002796/  4.363113, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.003122/  4.394731, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.002209/  4.364627, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.002021/  4.399893, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.002933/  4.255877, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.001727/  4.288094, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.002050/  4.359846, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.002109/  4.327977, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.001719/  4.313793, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.001156/  4.360212, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.002264/  4.388103, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.002990/  4.352994, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.002263/  4.375723, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.001705/  4.321013, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.000880/  4.353938, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.000995/  4.383521, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.000659/  4.397507, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.000695/  4.467480, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.000998/  4.476290, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.001325/  4.466804, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.001606/  4.431275, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.001420/  4.459236, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.002088/  4.383687, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001304/  4.384222, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001026/  4.446352, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001753/  4.439179, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.000622/  4.432076, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.000399/  4.422641, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.000389/  4.446411, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.000401/  4.432817, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000410/  4.431351, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000386/  4.485992, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000587/  4.464972, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.000606/  4.418636, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.000435/  4.447237, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000317/  4.446254, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000254/  4.448384, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000396/  4.447445, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000340/  4.462398, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000315/  4.460598, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000268/  4.462912, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000284/  4.479538, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000434/  4.463969, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000282/  4.480925, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000403/  4.519650, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000406/  4.503523, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000317/  4.493036, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000295/  4.503700, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000235/  4.497013, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000222/  4.499890, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000197/  4.506059, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000211/  4.475709, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000217/  4.490239, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000249/  4.507730, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000333/  4.497074, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000241/  4.477827, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000215/  4.453167, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000246/  4.476802, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000790/  4.500331, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000655/  4.497442, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000451/  4.515829, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000298/  4.502857, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000200/  4.509302, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000216/  4.508364, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000185/  4.510771, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000221/  4.505730, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000236/  4.520416, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000191/  4.542999, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000192/  4.531324, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000159/  4.502276, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000149/  4.509714, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000149/  4.496577, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4043b11006124998834012fba720019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▅▇▇███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▄▆▇▇▇▇▇▇█▇▇█▇▇██▇▇▇██▇████████▇██████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▄▆▇▇▇▇▇▇█▇▇█▇▇██▇▇▇██▇████████▇██████</td></tr><tr><td>val_loss</td><td>▆▃▃▆▁▅▇▅▇▆▇▆▇▆▇▇▇▇▇█▇▇▇▇█▇▇▇▇█████▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00015</td></tr><tr><td>val_acc_best</td><td>0.77083</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>4.49658</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-239</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gkzt3vrb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gkzt3vrb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_075511-gkzt3vrb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zbvrk0ny with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_080205-zbvrk0ny</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zbvrk0ny' target=\"_blank\">royal-sweep-241</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zbvrk0ny' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zbvrk0ny</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.258329/  2.185657, val:  22.08%, val_best:  22.08%, tr:  16.55%, tr_best:  16.55%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.070678/  1.994207, val:  43.75%, val_best:  43.75%, tr:  32.28%, tr_best:  32.28%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.827131/  1.781687, val:  50.42%, val_best:  50.42%, tr:  45.45%, tr_best:  45.45%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.612403/  1.644061, val:  50.83%, val_best:  50.83%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.480760/  1.558312, val:  48.75%, val_best:  50.83%, tr:  55.87%, tr_best:  55.87%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.382379/  1.490326, val:  52.92%, val_best:  52.92%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.327662/  1.460172, val:  54.17%, val_best:  54.17%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.275188/  1.431983, val:  52.92%, val_best:  54.17%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.229615/  1.395916, val:  58.75%, val_best:  58.75%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.197316/  1.383456, val:  58.33%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.162269/  1.369667, val:  59.58%, val_best:  59.58%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.133309/  1.342807, val:  59.58%, val_best:  59.58%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.119812/  1.327337, val:  62.50%, val_best:  62.50%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.101203/  1.313184, val:  62.08%, val_best:  62.50%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.059963/  1.325646, val:  58.75%, val_best:  62.50%, tr:  67.93%, tr_best:  68.95%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.050496/  1.301086, val:  64.17%, val_best:  64.17%, tr:  68.34%, tr_best:  68.95%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.031540/  1.298246, val:  60.83%, val_best:  64.17%, tr:  68.74%, tr_best:  68.95%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.006583/  1.274865, val:  64.58%, val_best:  64.58%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.987005/  1.287561, val:  60.83%, val_best:  64.58%, tr:  72.93%, tr_best:  73.85%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.979343/  1.278622, val:  62.50%, val_best:  64.58%, tr:  69.77%, tr_best:  73.85%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.954590/  1.272791, val:  65.00%, val_best:  65.00%, tr:  73.54%, tr_best:  73.85%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.945487/  1.263742, val:  64.58%, val_best:  65.00%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.940878/  1.275009, val:  64.17%, val_best:  65.00%, tr:  70.89%, tr_best:  74.67%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.914117/  1.266916, val:  67.92%, val_best:  67.92%, tr:  74.77%, tr_best:  74.77%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.902402/  1.265811, val:  64.17%, val_best:  67.92%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.882813/  1.247316, val:  68.75%, val_best:  68.75%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.873973/  1.226906, val:  72.08%, val_best:  72.08%, tr:  76.51%, tr_best:  79.26%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.858674/  1.269770, val:  66.25%, val_best:  72.08%, tr:  81.21%, tr_best:  81.21%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.857041/  1.236560, val:  65.83%, val_best:  72.08%, tr:  78.96%, tr_best:  81.21%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.831453/  1.258809, val:  64.17%, val_best:  72.08%, tr:  79.67%, tr_best:  81.21%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.829341/  1.252060, val:  66.25%, val_best:  72.08%, tr:  80.59%, tr_best:  81.21%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.816059/  1.270901, val:  71.25%, val_best:  72.08%, tr:  79.88%, tr_best:  81.21%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.808832/  1.260703, val:  66.25%, val_best:  72.08%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.796282/  1.259209, val:  66.67%, val_best:  72.08%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.786913/  1.249356, val:  66.67%, val_best:  72.08%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.783088/  1.288288, val:  63.33%, val_best:  72.08%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.760886/  1.265723, val:  62.50%, val_best:  72.08%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.752310/  1.258592, val:  70.42%, val_best:  72.08%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.750609/  1.249504, val:  67.08%, val_best:  72.08%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.738366/  1.262529, val:  68.33%, val_best:  72.08%, tr:  84.88%, tr_best:  86.93%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.719489/  1.258334, val:  70.83%, val_best:  72.08%, tr:  85.90%, tr_best:  86.93%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.723882/  1.268457, val:  72.50%, val_best:  72.50%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.698070/  1.265736, val:  68.75%, val_best:  72.50%, tr:  87.95%, tr_best:  88.05%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.693806/  1.280962, val:  70.83%, val_best:  72.50%, tr:  87.84%, tr_best:  88.05%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.685427/  1.296082, val:  66.67%, val_best:  72.50%, tr:  86.21%, tr_best:  88.05%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.672109/  1.272791, val:  70.42%, val_best:  72.50%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.658689/  1.303271, val:  69.58%, val_best:  72.50%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.658943/  1.333590, val:  67.92%, val_best:  72.50%, tr:  88.05%, tr_best:  90.60%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.646415/  1.297124, val:  71.67%, val_best:  72.50%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.644235/  1.299167, val:  74.58%, val_best:  74.58%, tr:  88.56%, tr_best:  91.62%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.633596/  1.310518, val:  72.50%, val_best:  74.58%, tr:  89.68%, tr_best:  91.62%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.619932/  1.334365, val:  70.83%, val_best:  74.58%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.616768/  1.334833, val:  66.67%, val_best:  74.58%, tr:  90.09%, tr_best:  91.62%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.616268/  1.314886, val:  73.75%, val_best:  74.58%, tr:  91.01%, tr_best:  91.62%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.602557/  1.345385, val:  72.50%, val_best:  74.58%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.599626/  1.348698, val:  73.33%, val_best:  74.58%, tr:  91.83%, tr_best:  92.95%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.586211/  1.346354, val:  72.50%, val_best:  74.58%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.583869/  1.365284, val:  70.00%, val_best:  74.58%, tr:  93.05%, tr_best:  93.56%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.567141/  1.384269, val:  70.83%, val_best:  74.58%, tr:  92.95%, tr_best:  93.56%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.565495/  1.378146, val:  71.25%, val_best:  74.58%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.554026/  1.383870, val:  70.00%, val_best:  74.58%, tr:  92.85%, tr_best:  93.56%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.548116/  1.406182, val:  72.50%, val_best:  74.58%, tr:  93.26%, tr_best:  93.56%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.547654/  1.409912, val:  71.67%, val_best:  74.58%, tr:  93.36%, tr_best:  93.56%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.527634/  1.392947, val:  72.50%, val_best:  74.58%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.528162/  1.438132, val:  70.83%, val_best:  74.58%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.516559/  1.455075, val:  70.42%, val_best:  74.58%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.514268/  1.432689, val:  73.75%, val_best:  74.58%, tr:  95.30%, tr_best:  95.40%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.512158/  1.471542, val:  70.42%, val_best:  74.58%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.496017/  1.463638, val:  72.08%, val_best:  74.58%, tr:  94.79%, tr_best:  95.81%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.493060/  1.482654, val:  71.67%, val_best:  74.58%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.485604/  1.474523, val:  72.92%, val_best:  74.58%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.479128/  1.498232, val:  72.08%, val_best:  74.58%, tr:  95.91%, tr_best:  96.83%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.467728/  1.519377, val:  69.58%, val_best:  74.58%, tr:  96.73%, tr_best:  96.83%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.474599/  1.501132, val:  70.00%, val_best:  74.58%, tr:  96.32%, tr_best:  96.83%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.460503/  1.523956, val:  71.67%, val_best:  74.58%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.463692/  1.543778, val:  71.67%, val_best:  74.58%, tr:  96.02%, tr_best:  97.04%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.446346/  1.567195, val:  69.17%, val_best:  74.58%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.449891/  1.563891, val:  70.00%, val_best:  74.58%, tr:  96.73%, tr_best:  97.45%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.445558/  1.560536, val:  71.25%, val_best:  74.58%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.434279/  1.551278, val:  71.25%, val_best:  74.58%, tr:  97.14%, tr_best:  97.85%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.422398/  1.578572, val:  70.42%, val_best:  74.58%, tr:  97.55%, tr_best:  97.85%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.425007/  1.594184, val:  72.08%, val_best:  74.58%, tr:  97.24%, tr_best:  97.85%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.422987/  1.600520, val:  69.17%, val_best:  74.58%, tr:  97.75%, tr_best:  97.85%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.420515/  1.625107, val:  72.50%, val_best:  74.58%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.412172/  1.610455, val:  71.25%, val_best:  74.58%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.409300/  1.629562, val:  70.83%, val_best:  74.58%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.404310/  1.636674, val:  73.33%, val_best:  74.58%, tr:  97.34%, tr_best:  98.57%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.397696/  1.655323, val:  70.83%, val_best:  74.58%, tr:  97.96%, tr_best:  98.57%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.386758/  1.634789, val:  70.42%, val_best:  74.58%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.379775/  1.695720, val:  69.58%, val_best:  74.58%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.389686/  1.671819, val:  72.08%, val_best:  74.58%, tr:  98.37%, tr_best:  98.77%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.380799/  1.677746, val:  71.67%, val_best:  74.58%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.378837/  1.691192, val:  70.83%, val_best:  74.58%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.381315/  1.730227, val:  67.50%, val_best:  74.58%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.372925/  1.747318, val:  65.83%, val_best:  74.58%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.362422/  1.717837, val:  69.17%, val_best:  74.58%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.361365/  1.786091, val:  69.17%, val_best:  74.58%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.368939/  1.747324, val:  70.83%, val_best:  74.58%, tr:  97.04%, tr_best:  99.39%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.350134/  1.742312, val:  68.33%, val_best:  74.58%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.351976/  1.739537, val:  70.00%, val_best:  74.58%, tr:  98.77%, tr_best:  99.39%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b19d2be4ea64735a9dc61185287411a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▁▂▂▅▇▂▂▆▇█▅▅▅▇▇▇▇▇▇▇▇▇█▇█▇█▇██▇███▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▅▆▆▆▇▆▇▇█▇▇▆▇▇▇▇▇█▇█▇██▇▇█▇█▇█▇█▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▅▆▆▆▇▆▇▇█▇▇▆▇▇▇▇▇█▇█▇██▇▇█▇█▇█▇█▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98774</td></tr><tr><td>tr_epoch_loss</td><td>0.35198</td></tr><tr><td>val_acc_best</td><td>0.74583</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.73954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-241</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zbvrk0ny' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zbvrk0ny</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_080205-zbvrk0ny/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: deh1geb6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_080817-deh1geb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/deh1geb6' target=\"_blank\">fragrant-sweep-243</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/deh1geb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/deh1geb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303367/  2.303053, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303474/  2.303229, val:  10.42%, val_best:  10.42%, tr:  10.21%, tr_best:  10.21%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.302912/  2.302301, val:  10.83%, val_best:  10.83%, tr:  11.34%, tr_best:  11.34%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.300310/  2.298883, val:  12.92%, val_best:  12.92%, tr:  14.50%, tr_best:  14.50%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.294261/  2.290743, val:  15.42%, val_best:  15.42%, tr:  15.83%, tr_best:  15.83%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.278310/  2.273734, val:  16.25%, val_best:  16.25%, tr:  14.81%, tr_best:  15.83%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.250033/  2.241744, val:  15.83%, val_best:  16.25%, tr:  14.50%, tr_best:  15.83%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.200514/  2.190363, val:  25.42%, val_best:  25.42%, tr:  20.33%, tr_best:  20.33%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.135875/  2.125684, val:  33.75%, val_best:  33.75%, tr:  29.11%, tr_best:  29.11%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.056864/  2.054949, val:  37.50%, val_best:  37.50%, tr:  29.93%, tr_best:  29.93%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.979510/  1.985519, val:  38.75%, val_best:  38.75%, tr:  38.51%, tr_best:  38.51%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.895341/  1.914214, val:  42.08%, val_best:  42.08%, tr:  44.64%, tr_best:  44.64%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.816495/  1.852450, val:  42.50%, val_best:  42.50%, tr:  48.01%, tr_best:  48.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.751248/  1.799283, val:  42.08%, val_best:  42.50%, tr:  49.85%, tr_best:  49.85%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.692113/  1.754171, val:  42.92%, val_best:  42.92%, tr:  50.46%, tr_best:  50.46%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.642959/  1.718479, val:  45.83%, val_best:  45.83%, tr:  54.24%, tr_best:  54.24%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.604184/  1.683517, val:  50.00%, val_best:  50.00%, tr:  56.69%, tr_best:  56.69%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.568226/  1.652946, val:  50.83%, val_best:  50.83%, tr:  58.12%, tr_best:  58.12%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.531949/  1.628514, val:  55.00%, val_best:  55.00%, tr:  58.43%, tr_best:  58.43%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.503783/  1.610976, val:  50.42%, val_best:  55.00%, tr:  57.10%, tr_best:  58.43%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.476147/  1.583720, val:  54.58%, val_best:  55.00%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.454246/  1.571072, val:  53.75%, val_best:  55.00%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.435869/  1.555967, val:  54.58%, val_best:  55.00%, tr:  59.04%, tr_best:  60.37%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.409055/  1.542694, val:  57.50%, val_best:  57.50%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.391466/  1.533788, val:  57.08%, val_best:  57.50%, tr:  63.13%, tr_best:  63.23%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.380308/  1.526734, val:  57.50%, val_best:  57.50%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.365672/  1.517722, val:  55.83%, val_best:  57.50%, tr:  63.64%, tr_best:  64.35%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.348312/  1.501180, val:  58.75%, val_best:  58.75%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.346543/  1.496659, val:  57.08%, val_best:  58.75%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.327875/  1.492760, val:  56.67%, val_best:  58.75%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.317640/  1.488796, val:  56.67%, val_best:  58.75%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.303018/  1.479169, val:  57.50%, val_best:  58.75%, tr:  63.94%, tr_best:  65.47%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.297257/  1.474609, val:  57.50%, val_best:  58.75%, tr:  66.19%, tr_best:  66.19%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.294536/  1.469838, val:  57.92%, val_best:  58.75%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.275541/  1.465175, val:  59.58%, val_best:  59.58%, tr:  66.09%, tr_best:  67.21%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.264202/  1.457385, val:  60.83%, val_best:  60.83%, tr:  66.39%, tr_best:  67.21%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.260712/  1.456611, val:  58.75%, val_best:  60.83%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.251901/  1.452682, val:  59.58%, val_best:  60.83%, tr:  66.39%, tr_best:  67.21%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.247396/  1.447921, val:  60.00%, val_best:  60.83%, tr:  66.50%, tr_best:  67.21%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.241946/  1.446835, val:  60.00%, val_best:  60.83%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.226913/  1.445442, val:  61.25%, val_best:  61.25%, tr:  66.70%, tr_best:  67.21%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.231215/  1.441594, val:  60.00%, val_best:  61.25%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.214738/  1.438498, val:  60.42%, val_best:  61.25%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.214316/  1.433258, val:  58.75%, val_best:  61.25%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.205799/  1.433271, val:  60.42%, val_best:  61.25%, tr:  67.42%, tr_best:  68.23%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.202014/  1.426841, val:  59.58%, val_best:  61.25%, tr:  68.03%, tr_best:  68.23%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.192889/  1.424354, val:  63.75%, val_best:  63.75%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.193669/  1.420087, val:  59.58%, val_best:  63.75%, tr:  67.62%, tr_best:  68.44%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.188709/  1.415971, val:  60.83%, val_best:  63.75%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.181252/  1.411615, val:  61.25%, val_best:  63.75%, tr:  69.05%, tr_best:  69.87%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.174374/  1.405826, val:  62.92%, val_best:  63.75%, tr:  69.66%, tr_best:  69.87%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.172395/  1.406115, val:  65.42%, val_best:  65.42%, tr:  69.25%, tr_best:  69.87%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.165098/  1.396703, val:  63.75%, val_best:  65.42%, tr:  69.15%, tr_best:  69.87%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.157984/  1.396033, val:  66.25%, val_best:  66.25%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.155445/  1.398701, val:  65.42%, val_best:  66.25%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.151550/  1.399345, val:  64.58%, val_best:  66.25%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.140811/  1.396188, val:  65.83%, val_best:  66.25%, tr:  72.11%, tr_best:  72.73%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.142527/  1.395051, val:  64.58%, val_best:  66.25%, tr:  72.22%, tr_best:  72.73%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.129808/  1.388572, val:  65.00%, val_best:  66.25%, tr:  70.48%, tr_best:  72.73%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.132655/  1.386749, val:  63.33%, val_best:  66.25%, tr:  72.11%, tr_best:  72.73%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.130197/  1.386540, val:  64.17%, val_best:  66.25%, tr:  70.48%, tr_best:  72.73%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.131236/  1.385506, val:  63.33%, val_best:  66.25%, tr:  70.38%, tr_best:  72.73%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.125891/  1.385842, val:  65.00%, val_best:  66.25%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.111688/  1.380177, val:  67.50%, val_best:  67.50%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.107704/  1.372796, val:  64.58%, val_best:  67.50%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.109959/  1.372190, val:  67.08%, val_best:  67.50%, tr:  73.24%, tr_best:  74.16%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.107408/  1.367692, val:  65.83%, val_best:  67.50%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.102987/  1.369220, val:  67.08%, val_best:  67.50%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.094855/  1.368904, val:  65.00%, val_best:  67.50%, tr:  70.89%, tr_best:  74.36%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.091399/  1.366073, val:  65.42%, val_best:  67.50%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.085314/  1.365080, val:  68.75%, val_best:  68.75%, tr:  74.67%, tr_best:  74.87%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.084867/  1.361003, val:  63.33%, val_best:  68.75%, tr:  73.95%, tr_best:  74.87%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.075441/  1.362671, val:  67.50%, val_best:  68.75%, tr:  73.24%, tr_best:  74.87%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.076681/  1.356544, val:  67.92%, val_best:  68.75%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.068866/  1.359781, val:  64.58%, val_best:  68.75%, tr:  74.46%, tr_best:  75.08%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.069694/  1.357591, val:  67.08%, val_best:  68.75%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.058506/  1.360759, val:  63.75%, val_best:  68.75%, tr:  74.67%, tr_best:  76.10%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.066324/  1.357388, val:  68.33%, val_best:  68.75%, tr:  75.79%, tr_best:  76.10%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.058157/  1.355496, val:  66.67%, val_best:  68.75%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.062077/  1.355417, val:  65.83%, val_best:  68.75%, tr:  76.40%, tr_best:  76.92%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.050937/  1.349094, val:  66.25%, val_best:  68.75%, tr:  75.38%, tr_best:  76.92%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.049385/  1.351562, val:  69.58%, val_best:  69.58%, tr:  76.20%, tr_best:  76.92%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.045896/  1.344983, val:  68.33%, val_best:  69.58%, tr:  76.51%, tr_best:  76.92%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.048240/  1.343614, val:  69.17%, val_best:  69.58%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.046117/  1.346420, val:  67.08%, val_best:  69.58%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.039916/  1.346230, val:  65.83%, val_best:  69.58%, tr:  77.22%, tr_best:  78.55%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.032715/  1.342553, val:  67.92%, val_best:  69.58%, tr:  75.79%, tr_best:  78.55%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.032125/  1.340675, val:  68.75%, val_best:  69.58%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.027259/  1.348452, val:  65.42%, val_best:  69.58%, tr:  77.43%, tr_best:  79.37%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.024058/  1.345634, val:  68.75%, val_best:  69.58%, tr:  76.61%, tr_best:  79.37%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.021206/  1.343548, val:  68.33%, val_best:  69.58%, tr:  77.83%, tr_best:  79.37%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.009577/  1.343431, val:  69.58%, val_best:  69.58%, tr:  79.06%, tr_best:  79.37%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.018047/  1.345743, val:  67.08%, val_best:  69.58%, tr:  77.32%, tr_best:  79.37%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.021009/  1.342454, val:  69.17%, val_best:  69.58%, tr:  78.45%, tr_best:  79.37%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.011135/  1.343999, val:  68.33%, val_best:  69.58%, tr:  78.45%, tr_best:  79.37%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.006708/  1.342707, val:  68.75%, val_best:  69.58%, tr:  78.86%, tr_best:  79.37%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.003870/  1.341431, val:  69.17%, val_best:  69.58%, tr:  79.16%, tr_best:  79.37%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.000486/  1.340047, val:  68.75%, val_best:  69.58%, tr:  78.65%, tr_best:  79.37%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.002035/  1.338741, val:  69.17%, val_best:  69.58%, tr:  77.94%, tr_best:  79.37%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.999523/  1.336003, val:  67.92%, val_best:  69.58%, tr:  78.24%, tr_best:  79.37%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178047015f9248879e7a66e08ba1c08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▃▃▄▅▄▃▅▆▇▅▅▅▆▇▅▆▅▆▅▄▅▆▆▆▇▇▅▇▆▇▆▆▅▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▁▂▂▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>tr_epoch_loss</td><td>███▇▇▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇▇██████████████</td></tr><tr><td>val_loss</td><td>███▇▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.78243</td></tr><tr><td>tr_epoch_loss</td><td>0.99952</td></tr><tr><td>val_acc_best</td><td>0.69583</td></tr><tr><td>val_acc_now</td><td>0.67917</td></tr><tr><td>val_loss</td><td>1.336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-sweep-243</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/deh1geb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/deh1geb6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_080817-deh1geb6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: decbgmjc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_081523-decbgmjc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/decbgmjc' target=\"_blank\">fresh-sweep-245</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/decbgmjc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/decbgmjc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.023028/  2.870544, val:  46.25%, val_best:  46.25%, tr:  34.93%, tr_best:  34.93%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.838609/  2.554711, val:  45.83%, val_best:  46.25%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.907106/  1.743940, val:  54.17%, val_best:  54.17%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.377378/  1.908317, val:  53.33%, val_best:  54.17%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.355641/  1.820783, val:  63.75%, val_best:  63.75%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.360239/  1.923836, val:  50.00%, val_best:  63.75%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.306146/  2.229992, val:  57.50%, val_best:  63.75%, tr:  72.63%, tr_best:  72.63%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.263208/  1.844085, val:  67.92%, val_best:  67.92%, tr:  71.50%, tr_best:  72.63%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.931413/  1.705837, val:  65.42%, val_best:  67.92%, tr:  80.90%, tr_best:  80.90%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.017505/  2.591532, val:  53.33%, val_best:  67.92%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.834082/  1.660965, val:  71.67%, val_best:  71.67%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.730302/  1.898916, val:  64.58%, val_best:  71.67%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.580967/  1.647376, val:  75.00%, val_best:  75.00%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.468987/  1.978013, val:  67.92%, val_best:  75.00%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.500822/  1.777437, val:  71.25%, val_best:  75.00%, tr:  91.73%, tr_best:  93.87%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.326972/  1.957317, val:  68.75%, val_best:  75.00%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.269755/  1.958646, val:  68.33%, val_best:  75.00%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.225386/  1.942483, val:  72.08%, val_best:  75.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.226701/  2.020084, val:  70.42%, val_best:  75.00%, tr:  98.16%, tr_best:  98.37%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.257524/  2.049046, val:  70.83%, val_best:  75.00%, tr:  97.75%, tr_best:  98.37%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.187187/  2.063513, val:  72.92%, val_best:  75.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.142683/  2.147875, val:  72.50%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.115456/  2.151727, val:  71.67%, val_best:  75.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.118718/  2.102377, val:  73.75%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.095573/  2.182470, val:  73.75%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.096620/  2.231738, val:  72.92%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.092864/  2.320354, val:  74.17%, val_best:  75.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.088378/  2.383904, val:  72.08%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.074368/  2.318674, val:  73.33%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.061692/  2.501488, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.059292/  2.515426, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.059936/  2.522643, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.064625/  2.666604, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.063208/  2.623963, val:  73.33%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.051016/  2.684077, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.036434/  2.695403, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.046492/  2.678466, val:  71.67%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.035811/  2.787768, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.035211/  2.712335, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.032243/  2.683863, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.029838/  2.692404, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.027768/  2.771133, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.026514/  2.808978, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.029203/  2.804583, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.027335/  2.825350, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.026074/  2.823514, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.030414/  2.828659, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.021997/  2.923251, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.021019/  2.872471, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.022607/  2.863217, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.026144/  2.960771, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.019590/  2.942108, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.018222/  2.972596, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.020665/  3.013647, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.017054/  2.957832, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.016092/  3.015329, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.014195/  3.012360, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.016776/  3.061144, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.016953/  3.140559, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.013130/  3.059187, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.013918/  3.103696, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.013821/  3.108747, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.013463/  3.157295, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.014107/  3.155088, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.012809/  3.165425, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.013467/  3.162542, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.013169/  3.119930, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.011095/  3.139961, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.012468/  3.189714, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.012154/  3.235949, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.010031/  3.152050, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.014769/  3.202305, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.016092/  3.233512, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.029665/  3.263924, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.019290/  3.202538, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.012878/  3.182883, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.013949/  3.198795, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.010784/  3.182464, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.008922/  3.235144, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.010291/  3.170767, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.008020/  3.224731, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.008743/  3.208834, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.008173/  3.241704, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.009228/  3.289766, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.009453/  3.266198, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.010207/  3.287602, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.009525/  3.276365, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.007585/  3.333415, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.006629/  3.302727, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.007447/  3.327740, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.009617/  3.299056, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.010426/  3.304883, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.008411/  3.308479, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.007314/  3.336052, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.006344/  3.341000, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.007140/  3.329372, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.006045/  3.358213, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.006219/  3.377014, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.005573/  3.362131, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.006629/  3.352963, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70ed72bffd340f5b7083e7334a525ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▇▇▇█▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▃█▇▇▇▇██▇█▇▇▇█▇██▇█▇▇▇▇██████████▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▅▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▃█▇▇▇▇██▇█▇▇▇█▇██▇█▇▇▇▇██████████▇▇▇</td></tr><tr><td>val_loss</td><td>▆▁▂▂▅▁▂▂▃▃▃▄▄▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00663</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.73333</td></tr><tr><td>val_loss</td><td>3.35296</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-245</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/decbgmjc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/decbgmjc</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_081523-decbgmjc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kzfji9s2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_082228-kzfji9s2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kzfji9s2' target=\"_blank\">fragrant-sweep-247</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kzfji9s2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kzfji9s2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305873/  2.302719, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.304917/  2.302315, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.303519/  2.301042, val:  10.83%, val_best:  10.83%, tr:   9.91%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.298351/  2.295816, val:  11.67%, val_best:  11.67%, tr:  12.67%, tr_best:  12.67%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.276868/  2.276582, val:  12.08%, val_best:  12.08%, tr:  14.91%, tr_best:  14.91%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.241996/  2.258532, val:  17.92%, val_best:  17.92%, tr:  14.61%, tr_best:  14.91%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  2.216386/  2.244762, val:  19.17%, val_best:  19.17%, tr:  20.84%, tr_best:  20.84%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  2.185325/  2.226056, val:  23.33%, val_best:  23.33%, tr:  22.57%, tr_best:  22.57%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  2.162480/  2.196062, val:  26.67%, val_best:  26.67%, tr:  23.39%, tr_best:  23.39%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  2.129465/  2.159636, val:  31.25%, val_best:  31.25%, tr:  25.94%, tr_best:  25.94%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  2.079184/  2.105203, val:  40.42%, val_best:  40.42%, tr:  33.09%, tr_best:  33.09%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  2.006249/  2.015915, val:  47.92%, val_best:  47.92%, tr:  41.16%, tr_best:  41.16%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.887431/  1.895111, val:  47.50%, val_best:  47.92%, tr:  46.68%, tr_best:  46.68%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.764788/  1.785568, val:  52.08%, val_best:  52.08%, tr:  49.64%, tr_best:  49.64%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.653377/  1.734743, val:  53.33%, val_best:  53.33%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.603215/  1.678865, val:  58.75%, val_best:  58.75%, tr:  55.98%, tr_best:  55.98%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.536255/  1.673838, val:  56.67%, val_best:  58.75%, tr:  58.32%, tr_best:  58.32%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.517949/  1.659768, val:  55.83%, val_best:  58.75%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.496742/  1.634248, val:  59.58%, val_best:  59.58%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.475523/  1.629277, val:  56.67%, val_best:  59.58%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.460929/  1.614465, val:  60.00%, val_best:  60.00%, tr:  62.00%, tr_best:  62.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.445989/  1.632234, val:  58.33%, val_best:  60.00%, tr:  60.27%, tr_best:  62.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.429722/  1.614829, val:  59.58%, val_best:  60.00%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.417258/  1.632570, val:  58.75%, val_best:  60.00%, tr:  63.64%, tr_best:  64.35%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.410541/  1.665760, val:  59.17%, val_best:  60.00%, tr:  62.82%, tr_best:  64.35%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.411429/  1.667196, val:  57.08%, val_best:  60.00%, tr:  64.25%, tr_best:  64.35%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.390831/  1.622798, val:  58.75%, val_best:  60.00%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.378933/  1.657394, val:  60.00%, val_best:  60.00%, tr:  64.04%, tr_best:  64.35%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.374956/  1.644237, val:  60.42%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.370326/  1.635354, val:  60.42%, val_best:  60.42%, tr:  63.94%, tr_best:  65.88%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.367262/  1.646195, val:  62.92%, val_best:  62.92%, tr:  64.04%, tr_best:  65.88%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.350691/  1.684215, val:  55.42%, val_best:  62.92%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.342953/  1.706870, val:  54.58%, val_best:  62.92%, tr:  65.88%, tr_best:  67.01%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.344558/  1.730491, val:  54.17%, val_best:  62.92%, tr:  66.39%, tr_best:  67.01%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.341387/  1.715039, val:  57.50%, val_best:  62.92%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.328457/  1.761631, val:  54.58%, val_best:  62.92%, tr:  67.21%, tr_best:  67.31%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.328845/  1.765131, val:  55.83%, val_best:  62.92%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.306593/  1.778231, val:  55.83%, val_best:  62.92%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.301676/  1.786105, val:  54.58%, val_best:  62.92%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.286859/  1.792278, val:  57.08%, val_best:  62.92%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.299402/  1.794777, val:  59.17%, val_best:  62.92%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.277224/  1.807241, val:  57.08%, val_best:  62.92%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.289613/  1.852583, val:  55.83%, val_best:  62.92%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.288016/  1.832622, val:  56.67%, val_best:  62.92%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.267655/  1.800706, val:  59.17%, val_best:  62.92%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.249718/  1.896564, val:  55.83%, val_best:  62.92%, tr:  68.95%, tr_best:  71.71%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.256822/  1.868487, val:  56.25%, val_best:  62.92%, tr:  69.05%, tr_best:  71.71%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.261209/  1.845480, val:  60.83%, val_best:  62.92%, tr:  70.99%, tr_best:  71.71%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.268439/  1.866562, val:  60.83%, val_best:  62.92%, tr:  69.77%, tr_best:  71.71%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.243931/  1.877863, val:  59.17%, val_best:  62.92%, tr:  69.25%, tr_best:  71.71%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.231221/  1.910800, val:  58.75%, val_best:  62.92%, tr:  70.99%, tr_best:  71.71%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.237516/  1.897110, val:  61.25%, val_best:  62.92%, tr:  70.48%, tr_best:  71.71%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.226895/  2.021851, val:  55.42%, val_best:  62.92%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.221485/  1.963437, val:  56.67%, val_best:  62.92%, tr:  71.91%, tr_best:  72.73%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.250367/  1.929610, val:  61.67%, val_best:  62.92%, tr:  71.20%, tr_best:  72.73%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.209300/  1.947104, val:  62.50%, val_best:  62.92%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.222906/  1.963248, val:  61.25%, val_best:  62.92%, tr:  72.22%, tr_best:  73.54%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.206121/  2.018772, val:  56.67%, val_best:  62.92%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.222738/  2.061297, val:  60.83%, val_best:  62.92%, tr:  72.93%, tr_best:  73.85%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.226710/  1.978052, val:  60.42%, val_best:  62.92%, tr:  73.24%, tr_best:  73.85%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.199845/  1.981278, val:  64.17%, val_best:  64.17%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.185827/  2.050735, val:  58.33%, val_best:  64.17%, tr:  73.54%, tr_best:  74.06%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.209380/  2.016631, val:  62.08%, val_best:  64.17%, tr:  71.81%, tr_best:  74.06%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.192050/  2.075593, val:  57.50%, val_best:  64.17%, tr:  73.54%, tr_best:  74.06%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.198470/  2.170313, val:  59.58%, val_best:  64.17%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.213663/  2.098780, val:  60.83%, val_best:  64.17%, tr:  73.95%, tr_best:  75.79%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.186365/  2.178376, val:  57.50%, val_best:  64.17%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.208746/  2.149297, val:  61.67%, val_best:  64.17%, tr:  73.65%, tr_best:  75.89%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.187051/  2.199060, val:  58.75%, val_best:  64.17%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.177931/  2.145118, val:  60.42%, val_best:  64.17%, tr:  73.44%, tr_best:  76.10%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.169706/  2.268363, val:  60.00%, val_best:  64.17%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.198239/  2.139318, val:  63.33%, val_best:  64.17%, tr:  74.97%, tr_best:  76.20%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.183243/  2.260498, val:  60.00%, val_best:  64.17%, tr:  73.75%, tr_best:  76.20%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.171317/  2.378960, val:  58.75%, val_best:  64.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.186295/  2.399497, val:  60.42%, val_best:  64.17%, tr:  76.71%, tr_best:  76.81%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.219860/  2.301299, val:  60.00%, val_best:  64.17%, tr:  73.95%, tr_best:  76.81%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.187703/  2.361601, val:  58.75%, val_best:  64.17%, tr:  75.18%, tr_best:  76.81%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.205300/  2.621287, val:  56.25%, val_best:  64.17%, tr:  73.85%, tr_best:  76.81%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.237467/  2.428061, val:  59.17%, val_best:  64.17%, tr:  73.95%, tr_best:  76.81%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.186000/  2.498026, val:  57.50%, val_best:  64.17%, tr:  76.71%, tr_best:  76.81%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.231178/  2.375399, val:  60.00%, val_best:  64.17%, tr:  75.79%, tr_best:  76.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9cbc65e7084fc7a0d12d80d83680e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▁▁▁▁▁▄▂▅▄▅▅▅▅▇▅▅▆▆▅▇▆▆▆▆▅▇▇▅▇▆▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▅▆▇▇▇▇▇██▇▇▇▇▇▇██▇███▇█▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>tr_epoch_loss</td><td>███████████▇▇▅▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▅▆▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▅▆▇▇▇▇▇██▇▇▇▇▇▇██▇███▇█▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▇▇▇▇▇▇▇▇▇▇▇▆▅▂▂▁▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▅▄▅▅▆▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.75792</td></tr><tr><td>tr_epoch_loss</td><td>1.23118</td></tr><tr><td>val_acc_best</td><td>0.64167</td></tr><tr><td>val_acc_now</td><td>0.6</td></tr><tr><td>val_loss</td><td>2.3754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-sweep-247</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kzfji9s2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kzfji9s2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_082228-kzfji9s2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ndjsiaxm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_082843-ndjsiaxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ndjsiaxm' target=\"_blank\">valiant-sweep-249</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ndjsiaxm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ndjsiaxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.185388/  1.953995, val:  39.58%, val_best:  39.58%, tr:  21.65%, tr_best:  21.65%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.631786/  1.548397, val:  55.83%, val_best:  55.83%, tr:  52.60%, tr_best:  52.60%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.365721/  1.449115, val:  57.08%, val_best:  57.08%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.225300/  1.430301, val:  58.75%, val_best:  58.75%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.147487/  1.343770, val:  63.75%, val_best:  63.75%, tr:  64.96%, tr_best:  65.37%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.080473/  1.293350, val:  65.00%, val_best:  65.00%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.006375/  1.280098, val:  66.67%, val_best:  66.67%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.966871/  1.266460, val:  63.33%, val_best:  66.67%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.923951/  1.276804, val:  66.67%, val_best:  66.67%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.895835/  1.292640, val:  66.67%, val_best:  66.67%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.865744/  1.346816, val:  62.08%, val_best:  66.67%, tr:  74.87%, tr_best:  76.40%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.811206/  1.249282, val:  65.42%, val_best:  66.67%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.803857/  1.265766, val:  66.25%, val_best:  66.67%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.770453/  1.301781, val:  65.42%, val_best:  66.67%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.731615/  1.391628, val:  60.83%, val_best:  66.67%, tr:  81.72%, tr_best:  81.82%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.703273/  1.358759, val:  68.75%, val_best:  68.75%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.710856/  1.284859, val:  69.17%, val_best:  69.17%, tr:  82.64%, tr_best:  85.19%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.651377/  1.316934, val:  70.42%, val_best:  70.42%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.626479/  1.365201, val:  66.67%, val_best:  70.42%, tr:  87.74%, tr_best:  88.36%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.616617/  1.365178, val:  70.42%, val_best:  70.42%, tr:  85.50%, tr_best:  88.36%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.575669/  1.384170, val:  65.42%, val_best:  70.42%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.553762/  1.407160, val:  66.67%, val_best:  70.42%, tr:  89.58%, tr_best:  90.30%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.550838/  1.392679, val:  70.00%, val_best:  70.42%, tr:  89.79%, tr_best:  90.30%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.510358/  1.435957, val:  70.00%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.472209/  1.476634, val:  68.75%, val_best:  70.42%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.460284/  1.485863, val:  71.25%, val_best:  71.25%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.460730/  1.485591, val:  72.92%, val_best:  72.92%, tr:  93.36%, tr_best:  95.40%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.425683/  1.530734, val:  69.58%, val_best:  72.92%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.410814/  1.501347, val:  72.92%, val_best:  72.92%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.394781/  1.601103, val:  68.75%, val_best:  72.92%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.368170/  1.593626, val:  71.25%, val_best:  72.92%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.370819/  1.632266, val:  71.25%, val_best:  72.92%, tr:  96.63%, tr_best:  98.26%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.359842/  1.655125, val:  71.67%, val_best:  72.92%, tr:  97.65%, tr_best:  98.26%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.344807/  1.643029, val:  72.92%, val_best:  72.92%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.328783/  1.722455, val:  68.33%, val_best:  72.92%, tr:  97.85%, tr_best:  98.57%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.325792/  1.701831, val:  72.08%, val_best:  72.92%, tr:  97.85%, tr_best:  98.57%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.294247/  1.677153, val:  74.58%, val_best:  74.58%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.279357/  1.730737, val:  71.67%, val_best:  74.58%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.275394/  1.735416, val:  71.25%, val_best:  74.58%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.254375/  1.732976, val:  72.50%, val_best:  74.58%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.254364/  1.819641, val:  71.67%, val_best:  74.58%, tr:  98.47%, tr_best:  99.69%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.236409/  1.825167, val:  72.50%, val_best:  74.58%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.215655/  1.825068, val:  73.75%, val_best:  74.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.216858/  1.905315, val:  70.83%, val_best:  74.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.211179/  1.873549, val:  73.75%, val_best:  74.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.193643/  1.864648, val:  75.42%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.180116/  1.927731, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.173874/  1.912330, val:  77.50%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.173420/  1.933530, val:  76.25%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.157793/  1.953565, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.141236/  2.030754, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.143288/  2.031038, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.139232/  1.982779, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.130939/  2.090399, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.118132/  2.107708, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.117554/  2.101778, val:  75.42%, val_best:  77.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.114696/  2.129805, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.124388/  2.107877, val:  75.00%, val_best:  77.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.113057/  2.147144, val:  75.83%, val_best:  77.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.098443/  2.172183, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.088535/  2.208841, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.095382/  2.218567, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.084061/  2.228013, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.079405/  2.252248, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.087201/  2.296426, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.074065/  2.313872, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.069903/  2.326783, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.064701/  2.344017, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.063557/  2.385467, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.061966/  2.379107, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.055436/  2.394763, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.063448/  2.406173, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.052629/  2.444074, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.052617/  2.438284, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.050518/  2.451897, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.049765/  2.489810, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.048292/  2.535080, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.045604/  2.541323, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.043395/  2.519506, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.042654/  2.498291, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.039626/  2.535225, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.038009/  2.532586, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.038500/  2.579136, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.036031/  2.602077, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.033328/  2.583726, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.033444/  2.622647, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.034348/  2.616670, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.032919/  2.638202, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.029980/  2.642679, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.029969/  2.669199, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.031522/  2.683905, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.029393/  2.743812, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.026151/  2.717625, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.026408/  2.708025, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.022883/  2.738179, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.024513/  2.768614, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.022385/  2.776782, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.024087/  2.730427, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.022285/  2.799921, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.021625/  2.763212, val:  73.33%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ad6a9f09c2487f946e8d20ddd594e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▁▆▄▅▆▁▇███▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▆▆▅▇▇▆▆▇▆▇▇▇▇▇▇███▇▇█▇▇▇▇▇▇▇█▇▇▇██▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▆▆▅▇▇▆▆▇▆▇▇▇▇▇▇███▇▇█▇▇▇▇▇▇▇█▇▇▇██▇▇</td></tr><tr><td>val_loss</td><td>▄▂▁▁▁▁▂▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02162</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.73333</td></tr><tr><td>val_loss</td><td>2.76321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-sweep-249</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ndjsiaxm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ndjsiaxm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_082843-ndjsiaxm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9nckogps with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_083501-9nckogps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9nckogps' target=\"_blank\">graceful-sweep-251</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9nckogps' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9nckogps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.301699/  2.293462, val:  14.17%, val_best:  14.17%, tr:  12.67%, tr_best:  12.67%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.267146/  2.237372, val:  15.83%, val_best:  15.83%, tr:  17.88%, tr_best:  17.88%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.168726/  2.122107, val:  25.83%, val_best:  25.83%, tr:  25.13%, tr_best:  25.13%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.004907/  1.955490, val:  44.58%, val_best:  44.58%, tr:  39.53%, tr_best:  39.53%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.821105/  1.808884, val:  42.50%, val_best:  44.58%, tr:  46.58%, tr_best:  46.58%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.667764/  1.699044, val:  45.42%, val_best:  45.42%, tr:  50.97%, tr_best:  50.97%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.572432/  1.620485, val:  48.33%, val_best:  48.33%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.478754/  1.560837, val:  49.58%, val_best:  49.58%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.418513/  1.520512, val:  52.50%, val_best:  52.50%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.369066/  1.494136, val:  52.50%, val_best:  52.50%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.323847/  1.480761, val:  54.58%, val_best:  54.58%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.295126/  1.456693, val:  56.67%, val_best:  56.67%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.274677/  1.441506, val:  56.25%, val_best:  56.67%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.243227/  1.429128, val:  55.83%, val_best:  56.67%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.210924/  1.412267, val:  57.08%, val_best:  57.08%, tr:  66.09%, tr_best:  66.60%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.188280/  1.401385, val:  57.50%, val_best:  57.50%, tr:  65.37%, tr_best:  66.60%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.155299/  1.389001, val:  58.33%, val_best:  58.33%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.143291/  1.377216, val:  59.17%, val_best:  59.17%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.126387/  1.365885, val:  60.00%, val_best:  60.00%, tr:  69.36%, tr_best:  69.46%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.104672/  1.352080, val:  61.25%, val_best:  61.25%, tr:  66.50%, tr_best:  69.46%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.091595/  1.347787, val:  61.25%, val_best:  61.25%, tr:  69.15%, tr_best:  69.46%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.075159/  1.338453, val:  60.42%, val_best:  61.25%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.060849/  1.334280, val:  64.17%, val_best:  64.17%, tr:  68.95%, tr_best:  69.97%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.042114/  1.323889, val:  62.08%, val_best:  64.17%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.032602/  1.311436, val:  62.50%, val_best:  64.17%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.016160/  1.304829, val:  64.17%, val_best:  64.17%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.006845/  1.294932, val:  63.75%, val_best:  64.17%, tr:  71.71%, tr_best:  74.16%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  0.992757/  1.291054, val:  66.25%, val_best:  66.25%, tr:  74.06%, tr_best:  74.16%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  0.999471/  1.280135, val:  66.67%, val_best:  66.67%, tr:  74.06%, tr_best:  74.16%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  0.980750/  1.277197, val:  65.83%, val_best:  66.67%, tr:  75.18%, tr_best:  75.18%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  0.966052/  1.275123, val:  65.42%, val_best:  66.67%, tr:  75.18%, tr_best:  75.18%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  0.960121/  1.273124, val:  66.67%, val_best:  66.67%, tr:  74.36%, tr_best:  75.18%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  0.952255/  1.277983, val:  63.75%, val_best:  66.67%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  0.950326/  1.270534, val:  67.08%, val_best:  67.08%, tr:  76.51%, tr_best:  77.02%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.931472/  1.262439, val:  67.50%, val_best:  67.50%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.922366/  1.266103, val:  66.67%, val_best:  67.50%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.917290/  1.264741, val:  67.92%, val_best:  67.92%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.906269/  1.258352, val:  66.67%, val_best:  67.92%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.904286/  1.256546, val:  67.92%, val_best:  67.92%, tr:  79.06%, tr_best:  79.26%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.893715/  1.252089, val:  68.75%, val_best:  68.75%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.883443/  1.256330, val:  65.83%, val_best:  68.75%, tr:  79.88%, tr_best:  82.12%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.884636/  1.254397, val:  68.33%, val_best:  68.75%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.867368/  1.255299, val:  67.92%, val_best:  68.75%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.866088/  1.255748, val:  67.50%, val_best:  68.75%, tr:  83.15%, tr_best:  84.17%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.859149/  1.254288, val:  65.83%, val_best:  68.75%, tr:  82.43%, tr_best:  84.17%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.848930/  1.249466, val:  67.08%, val_best:  68.75%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.841540/  1.254059, val:  71.25%, val_best:  71.25%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.842365/  1.246485, val:  68.75%, val_best:  71.25%, tr:  83.76%, tr_best:  85.80%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.831201/  1.249818, val:  70.00%, val_best:  71.25%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.821722/  1.251887, val:  68.75%, val_best:  71.25%, tr:  86.11%, tr_best:  87.33%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.817037/  1.252041, val:  70.42%, val_best:  71.25%, tr:  86.11%, tr_best:  87.33%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.810406/  1.243966, val:  72.50%, val_best:  72.50%, tr:  86.31%, tr_best:  87.33%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.803822/  1.249615, val:  70.00%, val_best:  72.50%, tr:  86.41%, tr_best:  87.33%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.792639/  1.246788, val:  70.00%, val_best:  72.50%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.784673/  1.257361, val:  70.83%, val_best:  72.50%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.777986/  1.252650, val:  72.08%, val_best:  72.50%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.764280/  1.250750, val:  70.83%, val_best:  72.50%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.763933/  1.259331, val:  70.00%, val_best:  72.50%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.751236/  1.265284, val:  69.58%, val_best:  72.50%, tr:  89.38%, tr_best:  89.58%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.749959/  1.256739, val:  70.42%, val_best:  72.50%, tr:  88.66%, tr_best:  89.58%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.744298/  1.251574, val:  71.67%, val_best:  72.50%, tr:  88.76%, tr_best:  89.58%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.742630/  1.255977, val:  71.25%, val_best:  72.50%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.733425/  1.250521, val:  72.92%, val_best:  72.92%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.724067/  1.253869, val:  71.67%, val_best:  72.92%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.714984/  1.263421, val:  71.25%, val_best:  72.92%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.715509/  1.261243, val:  72.92%, val_best:  72.92%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.709412/  1.250870, val:  74.58%, val_best:  74.58%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.708559/  1.259201, val:  72.50%, val_best:  74.58%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.691943/  1.254722, val:  72.50%, val_best:  74.58%, tr:  91.83%, tr_best:  92.54%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.687097/  1.256830, val:  71.25%, val_best:  74.58%, tr:  92.34%, tr_best:  92.54%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.682399/  1.264193, val:  72.92%, val_best:  74.58%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.672537/  1.258524, val:  72.50%, val_best:  74.58%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.666548/  1.266342, val:  70.83%, val_best:  74.58%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.663452/  1.254865, val:  74.58%, val_best:  74.58%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.655003/  1.261425, val:  72.08%, val_best:  74.58%, tr:  92.95%, tr_best:  93.26%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.654483/  1.261325, val:  72.92%, val_best:  74.58%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.637588/  1.278718, val:  70.83%, val_best:  74.58%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.644431/  1.270249, val:  72.08%, val_best:  74.58%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.634950/  1.262169, val:  74.17%, val_best:  74.58%, tr:  93.77%, tr_best:  94.18%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.630334/  1.274109, val:  73.75%, val_best:  74.58%, tr:  93.77%, tr_best:  94.18%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.621132/  1.273504, val:  72.92%, val_best:  74.58%, tr:  93.87%, tr_best:  94.18%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.616629/  1.281302, val:  72.50%, val_best:  74.58%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.612305/  1.280267, val:  72.92%, val_best:  74.58%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.612824/  1.280347, val:  73.75%, val_best:  74.58%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.607474/  1.282776, val:  73.33%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.602318/  1.292875, val:  72.50%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.596550/  1.292846, val:  73.33%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.595466/  1.289216, val:  73.33%, val_best:  74.58%, tr:  94.69%, tr_best:  95.30%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.587321/  1.294447, val:  74.58%, val_best:  74.58%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.577490/  1.315069, val:  74.58%, val_best:  74.58%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.580038/  1.297669, val:  73.33%, val_best:  74.58%, tr:  95.40%, tr_best:  95.81%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.563453/  1.302465, val:  73.33%, val_best:  74.58%, tr:  95.61%, tr_best:  95.81%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.566912/  1.305524, val:  72.92%, val_best:  74.58%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.561437/  1.309526, val:  72.92%, val_best:  74.58%, tr:  96.32%, tr_best:  96.53%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.562008/  1.311438, val:  73.75%, val_best:  74.58%, tr:  96.12%, tr_best:  96.53%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.549117/  1.312980, val:  74.17%, val_best:  74.58%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.546164/  1.319488, val:  73.75%, val_best:  74.58%, tr:  96.12%, tr_best:  96.53%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.543582/  1.316131, val:  73.75%, val_best:  74.58%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.540205/  1.312302, val:  75.42%, val_best:  75.42%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.537388/  1.330879, val:  72.50%, val_best:  75.42%, tr:  96.63%, tr_best:  96.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abb63438cfb417ea44097e203167829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▁▃▅▅▅▅▃▆▇▇▅▆▅▇█▆█▇▇▇▆██████▇█▇▇▇▇▇▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>val_loss</td><td>█▇▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96629</td></tr><tr><td>tr_epoch_loss</td><td>0.53739</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>1.33088</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-251</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9nckogps' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9nckogps</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_083501-9nckogps/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zujpk0j6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_084154-zujpk0j6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zujpk0j6' target=\"_blank\">apricot-sweep-253</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zujpk0j6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zujpk0j6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.243242/  2.124186, val:  28.33%, val_best:  28.33%, tr:  17.26%, tr_best:  17.26%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.864803/  1.757179, val:  50.83%, val_best:  50.83%, tr:  40.96%, tr_best:  40.96%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.521397/  1.569973, val:  51.67%, val_best:  51.67%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.351221/  1.527105, val:  56.67%, val_best:  56.67%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.264221/  1.438615, val:  59.17%, val_best:  59.17%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.188069/  1.391747, val:  61.67%, val_best:  61.67%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.108269/  1.374183, val:  60.00%, val_best:  61.67%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.065224/  1.341167, val:  59.17%, val_best:  61.67%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.007178/  1.310837, val:  66.25%, val_best:  66.25%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.975028/  1.330811, val:  61.25%, val_best:  66.25%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.952237/  1.380338, val:  55.83%, val_best:  66.25%, tr:  69.87%, tr_best:  71.09%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.906371/  1.268516, val:  64.17%, val_best:  66.25%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.889389/  1.286184, val:  59.58%, val_best:  66.25%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.858184/  1.310512, val:  65.00%, val_best:  66.25%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.821835/  1.380808, val:  62.08%, val_best:  66.25%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.800791/  1.373180, val:  63.75%, val_best:  66.25%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.827191/  1.296533, val:  66.67%, val_best:  66.67%, tr:  75.59%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.772485/  1.333233, val:  63.75%, val_best:  66.67%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.747060/  1.429825, val:  63.75%, val_best:  66.67%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.751238/  1.417867, val:  66.67%, val_best:  66.67%, tr:  80.59%, tr_best:  82.33%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.720116/  1.420429, val:  67.92%, val_best:  67.92%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.699841/  1.423842, val:  65.83%, val_best:  67.92%, tr:  84.37%, tr_best:  84.88%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.715861/  1.433404, val:  67.92%, val_best:  67.92%, tr:  83.15%, tr_best:  84.88%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.685908/  1.459699, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.659097/  1.466386, val:  66.25%, val_best:  67.92%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.648164/  1.478790, val:  68.75%, val_best:  68.75%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.651217/  1.521018, val:  67.08%, val_best:  68.75%, tr:  87.13%, tr_best:  87.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.611899/  1.564894, val:  69.17%, val_best:  69.17%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.624858/  1.512855, val:  70.00%, val_best:  70.00%, tr:  87.95%, tr_best:  89.38%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.606112/  1.705009, val:  64.17%, val_best:  70.00%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.578967/  1.667041, val:  67.50%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.587257/  1.687154, val:  67.92%, val_best:  70.00%, tr:  89.48%, tr_best:  92.54%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.613017/  1.677269, val:  70.00%, val_best:  70.00%, tr:  90.70%, tr_best:  92.54%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.613487/  1.663072, val:  66.25%, val_best:  70.00%, tr:  91.62%, tr_best:  92.54%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.569194/  1.789078, val:  66.67%, val_best:  70.00%, tr:  91.52%, tr_best:  92.54%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.580293/  1.845011, val:  66.67%, val_best:  70.00%, tr:  89.17%, tr_best:  92.54%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.521068/  1.697164, val:  70.42%, val_best:  70.42%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.507637/  1.833766, val:  68.33%, val_best:  70.42%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.530018/  1.933958, val:  66.25%, val_best:  70.42%, tr:  94.59%, tr_best:  95.10%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.501346/  1.851378, val:  69.58%, val_best:  70.42%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.506107/  1.922060, val:  69.58%, val_best:  70.42%, tr:  93.56%, tr_best:  95.40%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.489477/  1.989336, val:  68.75%, val_best:  70.42%, tr:  95.20%, tr_best:  95.40%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.471262/  1.951523, val:  70.83%, val_best:  70.83%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.461584/  2.020993, val:  66.67%, val_best:  70.83%, tr:  94.99%, tr_best:  96.02%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.461115/  1.962519, val:  65.83%, val_best:  70.83%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.440820/  2.004915, val:  68.75%, val_best:  70.83%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.450386/  2.151669, val:  66.67%, val_best:  70.83%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.406636/  2.164783, val:  67.92%, val_best:  70.83%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.420317/  2.174956, val:  68.33%, val_best:  70.83%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.429699/  2.121202, val:  68.75%, val_best:  70.83%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.388140/  2.245872, val:  68.75%, val_best:  70.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.462284/  2.170427, val:  71.67%, val_best:  71.67%, tr:  94.69%, tr_best:  98.37%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.365864/  2.289234, val:  68.33%, val_best:  71.67%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.359126/  2.404623, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.348281/  2.307922, val:  69.58%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.361034/  2.443887, val:  69.17%, val_best:  71.67%, tr:  98.26%, tr_best:  98.88%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.349044/  2.487273, val:  67.92%, val_best:  71.67%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.359885/  2.505711, val:  69.58%, val_best:  71.67%, tr:  97.75%, tr_best:  98.88%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.339618/  2.492781, val:  68.33%, val_best:  71.67%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.329144/  2.607036, val:  67.50%, val_best:  71.67%, tr:  98.77%, tr_best:  98.88%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.312389/  2.642590, val:  66.67%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.325251/  2.597434, val:  65.42%, val_best:  71.67%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.323082/  2.599294, val:  67.50%, val_best:  71.67%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.284650/  2.684657, val:  67.08%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.282754/  2.802027, val:  67.50%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.291464/  2.812501, val:  65.00%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.276671/  2.786575, val:  65.83%, val_best:  71.67%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.258991/  2.857569, val:  67.08%, val_best:  71.67%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.264946/  2.958286, val:  66.25%, val_best:  71.67%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.280527/  3.043354, val:  64.17%, val_best:  71.67%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.234249/  2.915497, val:  65.00%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.233587/  3.172272, val:  63.75%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.237163/  3.103238, val:  63.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.268257/  3.077068, val:  67.08%, val_best:  71.67%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.225738/  3.136847, val:  65.83%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.223096/  3.231972, val:  66.67%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.220988/  3.110435, val:  65.42%, val_best:  71.67%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.263986/  3.246860, val:  66.67%, val_best:  71.67%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.280463/  3.234407, val:  66.25%, val_best:  71.67%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.248444/  3.156211, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.209407/  3.240279, val:  65.42%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.207473/  3.201180, val:  67.92%, val_best:  71.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.235370/  3.239149, val:  67.50%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.273124/  3.437421, val:  65.83%, val_best:  71.67%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.215331/  3.306569, val:  70.00%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.214575/  3.467093, val:  66.67%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.182948/  3.345486, val:  68.75%, val_best:  71.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.195729/  3.396218, val:  68.33%, val_best:  71.67%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.181826/  3.446512, val:  67.50%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.165390/  3.546609, val:  66.67%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.194697/  3.544030, val:  66.67%, val_best:  71.67%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.197478/  3.558749, val:  66.25%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.178992/  3.519618, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.175679/  3.575575, val:  67.08%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.161661/  3.649698, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.158628/  3.667777, val:  65.83%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.146545/  3.738120, val:  67.08%, val_best:  71.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.159661/  3.732493, val:  66.25%, val_best:  71.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.124277/  3.781419, val:  67.92%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.144722/  3.838679, val:  67.50%, val_best:  71.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5182a8e3a8384370bbb2746457ed2a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▂▄▆▁▄███▇▇▇█▇▇███████████▇███▇██▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇███▇█████▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▃▄▄▄▅▅▅▅▆▆▇▇▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.14472</td></tr><tr><td>val_acc_best</td><td>0.71667</td></tr><tr><td>val_acc_now</td><td>0.675</td></tr><tr><td>val_loss</td><td>3.83868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-253</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zujpk0j6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zujpk0j6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_084154-zujpk0j6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kpc950jz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de74b9199a445a793b2725ca650582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112898712356885, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_084810-kpc950jz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kpc950jz' target=\"_blank\">proud-sweep-255</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kpc950jz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kpc950jz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305421/  2.301930, val:  12.08%, val_best:  12.08%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.232267/  2.054792, val:  28.75%, val_best:  28.75%, tr:  17.06%, tr_best:  17.06%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.764527/  1.661139, val:  47.08%, val_best:  47.08%, tr:  43.62%, tr_best:  43.62%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.471248/  1.573581, val:  55.00%, val_best:  55.00%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.368678/  1.576366, val:  59.58%, val_best:  59.58%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.308345/  1.539834, val:  62.50%, val_best:  62.50%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.222791/  1.530743, val:  60.83%, val_best:  62.50%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.196677/  1.500341, val:  65.42%, val_best:  65.42%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.146195/  1.550992, val:  63.33%, val_best:  65.42%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.117561/  1.553078, val:  64.17%, val_best:  65.42%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.103590/  1.636919, val:  60.00%, val_best:  65.42%, tr:  72.22%, tr_best:  73.85%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.022436/  1.607798, val:  67.50%, val_best:  67.50%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.019101/  1.656517, val:  64.17%, val_best:  67.50%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.989147/  1.699292, val:  64.17%, val_best:  67.50%, tr:  80.90%, tr_best:  81.00%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.914086/  1.894002, val:  64.58%, val_best:  67.50%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.896792/  1.799311, val:  67.08%, val_best:  67.50%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.883374/  1.782570, val:  73.75%, val_best:  73.75%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.806420/  1.860772, val:  71.67%, val_best:  73.75%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.770284/  1.959273, val:  70.00%, val_best:  73.75%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.749957/  1.958598, val:  73.33%, val_best:  73.75%, tr:  92.34%, tr_best:  93.05%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.705909/  2.086792, val:  70.42%, val_best:  73.75%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.697589/  2.136744, val:  70.42%, val_best:  73.75%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.693019/  2.184541, val:  73.75%, val_best:  73.75%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.660592/  2.271872, val:  73.33%, val_best:  73.75%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.614047/  2.354091, val:  75.42%, val_best:  75.42%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.588672/  2.360204, val:  75.83%, val_best:  75.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.603671/  2.487494, val:  76.67%, val_best:  76.67%, tr:  96.94%, tr_best:  98.26%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.536761/  2.577038, val:  76.67%, val_best:  76.67%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.523166/  2.613013, val:  76.67%, val_best:  76.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.500503/  2.719820, val:  72.92%, val_best:  76.67%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.484980/  2.744065, val:  76.25%, val_best:  76.67%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.476361/  2.823750, val:  74.17%, val_best:  76.67%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.446354/  2.862709, val:  75.83%, val_best:  76.67%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.435957/  2.946568, val:  75.83%, val_best:  76.67%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.427384/  3.012042, val:  75.42%, val_best:  76.67%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.400467/  3.107027, val:  75.42%, val_best:  76.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.381524/  3.140943, val:  78.33%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.374965/  3.213683, val:  77.08%, val_best:  78.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.369815/  3.268889, val:  78.75%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.351361/  3.431359, val:  76.67%, val_best:  78.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.347186/  3.445166, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.329004/  3.527858, val:  77.08%, val_best:  78.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.307258/  3.567184, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.293493/  3.698624, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.279032/  3.743318, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.276817/  3.832233, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.261440/  3.857187, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.261335/  3.913499, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.264156/  3.967743, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.249526/  4.065042, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.233833/  4.138327, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.227245/  4.145787, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.234273/  4.258533, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.225575/  4.203343, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.216985/  4.362624, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.213557/  4.378163, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.201729/  4.469839, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.211575/  4.453057, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.192059/  4.511151, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.190123/  4.566477, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.198204/  4.600033, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.179196/  4.694234, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.171160/  4.677919, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.169308/  4.735870, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.180270/  4.795314, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.169980/  4.797355, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.178599/  4.912406, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.181496/  4.923919, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.169991/  4.930745, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.160369/  5.014086, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.152203/  5.070110, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.168389/  5.106311, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.164477/  5.178230, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.135398/  5.183074, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.138206/  5.233105, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.131713/  5.328681, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.126327/  5.316539, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.127051/  5.399606, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.127734/  5.381164, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.131625/  5.418076, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.136690/  5.395747, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.121675/  5.454359, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.117968/  5.551033, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.131310/  5.602678, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.119729/  5.555190, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.126269/  5.658952, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.112440/  5.679550, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.112979/  5.679608, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.118996/  5.721935, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.114126/  5.766365, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.112350/  5.703468, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.117664/  5.882695, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.088443/  5.893390, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.094665/  5.859564, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.104446/  5.888567, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.094004/  5.989358, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.097730/  6.079072, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.102675/  5.998694, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.095598/  6.026530, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.093448/  6.116590, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bb6bee806d4d66be76e34958cab2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▄▄▇▇▆▇▇██████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▇▇▇▇▇▇██▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▇▇▇▇▇▇██▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.09345</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>6.11659</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-255</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kpc950jz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kpc950jz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_084810-kpc950jz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: thxhz0sl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966a017b83d841bd8e41f46976e4e0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113209732704693, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_085506-thxhz0sl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/thxhz0sl' target=\"_blank\">laced-sweep-257</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/thxhz0sl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/thxhz0sl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.992836/  1.530355, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.270813/  1.365592, val:  54.58%, val_best:  54.58%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.069424/  1.281831, val:  57.08%, val_best:  57.08%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.933384/  1.251486, val:  61.25%, val_best:  61.25%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.866738/  1.182627, val:  65.83%, val_best:  65.83%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.786886/  1.128070, val:  68.33%, val_best:  68.33%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.703391/  1.155334, val:  62.50%, val_best:  68.33%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.662856/  1.105658, val:  74.17%, val_best:  74.17%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.586745/  1.165156, val:  70.00%, val_best:  74.17%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.531940/  1.184574, val:  71.25%, val_best:  74.17%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.481265/  1.274785, val:  68.33%, val_best:  74.17%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.411131/  1.205037, val:  71.25%, val_best:  74.17%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.380376/  1.218549, val:  72.92%, val_best:  74.17%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.355044/  1.233106, val:  73.33%, val_best:  74.17%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.313360/  1.399375, val:  67.08%, val_best:  74.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.281016/  1.315073, val:  68.75%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.276405/  1.278273, val:  71.67%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.230744/  1.304451, val:  73.33%, val_best:  74.17%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.217097/  1.367440, val:  72.50%, val_best:  74.17%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.189200/  1.388709, val:  72.92%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.168005/  1.429032, val:  71.67%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.156738/  1.423135, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.155678/  1.448348, val:  72.50%, val_best:  74.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.137104/  1.465722, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.117735/  1.489887, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.113048/  1.494661, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.111899/  1.517547, val:  74.58%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.094039/  1.552814, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.085773/  1.558714, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.080534/  1.610260, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.074078/  1.616008, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.076707/  1.639017, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.064758/  1.633267, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.065957/  1.667854, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.062587/  1.702203, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.057386/  1.693906, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.053166/  1.707784, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.051085/  1.738894, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.050181/  1.742640, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.047369/  1.752363, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.044923/  1.768679, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.040334/  1.768954, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.039417/  1.797302, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.038766/  1.812773, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.038489/  1.810026, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.035944/  1.837535, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.032449/  1.834346, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.031562/  1.855415, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.030469/  1.863177, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.028516/  1.870352, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.027792/  1.918565, val:  71.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.026748/  1.908998, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.026891/  1.912619, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.028077/  1.918764, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.025418/  1.924893, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.023315/  1.923090, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.022478/  1.936789, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.021557/  1.945426, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.021156/  1.942656, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.019743/  1.953326, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.020329/  1.953163, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.019369/  1.960923, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.017890/  1.973290, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.017283/  1.984569, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.016926/  1.986783, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.016638/  2.007506, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.016184/  2.003598, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.015977/  2.000960, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.015402/  2.013381, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.014964/  2.022342, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.014858/  2.019135, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.015367/  2.032981, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.014025/  2.042576, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.013691/  2.045029, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.013978/  2.043543, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.013692/  2.051186, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.012567/  2.055531, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.012612/  2.053025, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.011796/  2.063824, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.011929/  2.070036, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.011806/  2.073155, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.011632/  2.079894, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.011438/  2.081168, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.011136/  2.092202, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.011016/  2.103305, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.010949/  2.107349, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.010504/  2.118123, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.010123/  2.105605, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.010164/  2.123651, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.009368/  2.132211, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.009824/  2.126709, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.009035/  2.133195, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.009100/  2.135625, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.009616/  2.147619, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.009408/  2.143027, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.009128/  2.150978, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.008981/  2.144156, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.008209/  2.152747, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.008215/  2.172714, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.008785/  2.173029, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f89a8838ed48d495bf109a05da327c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▇▆▇█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▄▂▂▁▂▂▃▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00878</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>2.17303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-257</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/thxhz0sl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/thxhz0sl</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_085506-thxhz0sl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: didir6b7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_090204-didir6b7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/didir6b7' target=\"_blank\">radiant-sweep-259</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/didir6b7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/didir6b7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.108000/  1.678063, val:  45.42%, val_best:  45.42%, tr:  22.17%, tr_best:  22.17%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.348517/  1.428548, val:  55.83%, val_best:  55.83%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.113585/  1.347255, val:  60.83%, val_best:  60.83%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.933912/  1.418307, val:  55.00%, val_best:  60.83%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.871925/  1.251740, val:  66.25%, val_best:  66.25%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.813309/  1.348479, val:  61.67%, val_best:  66.25%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.720905/  1.175410, val:  67.50%, val_best:  67.50%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.678788/  1.201644, val:  65.83%, val_best:  67.50%, tr:  74.36%, tr_best:  76.81%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.577464/  1.250541, val:  67.50%, val_best:  67.50%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.488856/  1.305171, val:  68.75%, val_best:  68.75%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.440951/  1.360780, val:  69.58%, val_best:  69.58%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.408995/  1.619242, val:  66.25%, val_best:  69.58%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.400800/  1.296508, val:  76.25%, val_best:  76.25%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.371932/  1.298455, val:  80.00%, val_best:  80.00%, tr:  91.52%, tr_best:  92.03%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.274463/  1.489119, val:  76.25%, val_best:  80.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.228154/  1.408268, val:  75.42%, val_best:  80.00%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.190929/  1.429895, val:  79.58%, val_best:  80.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.128917/  1.550310, val:  77.50%, val_best:  80.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.109575/  1.571578, val:  76.67%, val_best:  80.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.143069/  1.629960, val:  73.75%, val_best:  80.00%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.095371/  1.693677, val:  80.00%, val_best:  80.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.072315/  1.894151, val:  74.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.056132/  1.758482, val:  78.75%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.038552/  1.774001, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.039247/  1.780650, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.034460/  1.823584, val:  79.58%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.022469/  1.804462, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.013474/  1.876846, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.015234/  1.857413, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.012072/  1.934949, val:  79.17%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.016815/  1.956463, val:  80.42%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.031171/  1.860737, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.067534/  1.846981, val:  81.67%, val_best:  82.92%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.028983/  1.973074, val:  79.58%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.016490/  1.941417, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.008969/  1.967972, val:  83.75%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.005626/  1.974356, val:  81.67%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.004715/  1.933210, val:  85.00%, val_best:  85.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.054567/  2.159551, val:  76.67%, val_best:  85.00%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.141347/  1.932041, val:  76.67%, val_best:  85.00%, tr:  98.26%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.052285/  1.856472, val:  77.50%, val_best:  85.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.032439/  1.991521, val:  81.25%, val_best:  85.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.014813/  1.811926, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.010239/  1.898745, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.006841/  1.808423, val:  84.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.003311/  1.883454, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.004094/  1.930302, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.003903/  1.896642, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002533/  1.925471, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002244/  1.927891, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001746/  1.926110, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.002348/  1.925651, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.002203/  1.934552, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001600/  1.949998, val:  85.00%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001374/  1.959960, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.001484/  1.944955, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001167/  1.947506, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001131/  1.963233, val:  85.00%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001942/  1.964121, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.001034/  1.964685, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001312/  1.970951, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001057/  2.001346, val:  84.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001504/  2.002924, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001035/  1.994656, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001566/  1.991336, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001221/  1.997544, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000884/  1.988649, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001072/  1.996658, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001008/  2.005605, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000695/  2.002361, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000667/  1.999834, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.002607/  2.006060, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.002712/  2.049756, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001731/  2.031856, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.001658/  2.047103, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000825/  2.060419, val:  82.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001010/  2.033190, val:  85.00%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000727/  2.014752, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000540/  2.036674, val:  84.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000538/  2.049654, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000452/  2.046768, val:  84.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000369/  2.050238, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000401/  2.064673, val:  84.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000400/  2.076760, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000419/  2.077190, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000365/  2.095081, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000476/  2.090294, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000359/  2.101482, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000330/  2.110383, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000298/  2.121909, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000350/  2.121342, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000292/  2.122877, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000286/  2.120981, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000273/  2.129264, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000268/  2.132500, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000301/  2.127344, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000261/  2.132302, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000268/  2.144508, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000453/  2.142059, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000278/  2.147703, val:  84.17%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd0d04e69c64febb958196585759787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▄▅▅▇█████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▆▆▇▆▆▇▇▇▇██▆███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▅▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▆▆▇▆▆▇▇▇▇██▆███████████████████████</td></tr><tr><td>val_loss</td><td>▅▂▁▁▂▂▃▄▄▆▅▅▆▆▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00028</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.84167</td></tr><tr><td>val_loss</td><td>2.1477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-259</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/didir6b7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/didir6b7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_090204-didir6b7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uebgvnr2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_090814-uebgvnr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uebgvnr2' target=\"_blank\">comic-sweep-261</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uebgvnr2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uebgvnr2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.284438/  2.109812, val:  24.17%, val_best:  24.17%, tr:   9.81%, tr_best:   9.81%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.653030/  1.588679, val:  52.92%, val_best:  52.92%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.333509/  1.533693, val:  55.00%, val_best:  55.00%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.192845/  1.519600, val:  57.08%, val_best:  57.08%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.116519/  1.416001, val:  60.83%, val_best:  60.83%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.080117/  1.341814, val:  61.67%, val_best:  61.67%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.003328/  1.399074, val:  60.00%, val_best:  61.67%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.994429/  1.373959, val:  62.08%, val_best:  62.08%, tr:  68.64%, tr_best:  69.36%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.955637/  1.402709, val:  67.92%, val_best:  67.92%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934807/  1.394291, val:  59.17%, val_best:  67.92%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.906546/  1.482131, val:  57.92%, val_best:  67.92%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.848273/  1.393369, val:  66.25%, val_best:  67.92%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.837714/  1.396477, val:  64.17%, val_best:  67.92%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.824691/  1.432465, val:  64.58%, val_best:  67.92%, tr:  80.90%, tr_best:  82.43%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.769235/  1.664894, val:  64.17%, val_best:  67.92%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.760738/  1.537316, val:  65.00%, val_best:  67.92%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.771930/  1.485499, val:  67.50%, val_best:  67.92%, tr:  85.09%, tr_best:  85.90%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.712188/  1.532985, val:  65.42%, val_best:  67.92%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.692624/  1.708888, val:  62.08%, val_best:  67.92%, tr:  89.79%, tr_best:  91.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.692377/  1.624332, val:  67.08%, val_best:  67.92%, tr:  89.48%, tr_best:  91.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.664214/  1.781572, val:  61.25%, val_best:  67.92%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.657118/  1.680564, val:  66.67%, val_best:  67.92%, tr:  90.70%, tr_best:  91.93%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.616810/  1.703850, val:  70.42%, val_best:  70.42%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.626313/  1.756889, val:  67.92%, val_best:  70.42%, tr:  93.05%, tr_best:  93.56%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.582983/  1.741290, val:  69.17%, val_best:  70.42%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.570992/  1.799967, val:  68.33%, val_best:  70.42%, tr:  94.89%, tr_best:  95.71%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.626329/  1.816780, val:  69.58%, val_best:  70.42%, tr:  92.03%, tr_best:  95.71%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.562403/  1.841389, val:  69.58%, val_best:  70.42%, tr:  95.10%, tr_best:  95.71%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.547196/  1.845125, val:  70.83%, val_best:  70.83%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.534238/  2.003724, val:  66.25%, val_best:  70.83%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.531631/  1.886789, val:  70.42%, val_best:  70.83%, tr:  96.22%, tr_best:  96.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.524054/  1.999068, val:  70.42%, val_best:  70.83%, tr:  95.61%, tr_best:  96.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.543622/  2.062558, val:  71.67%, val_best:  71.67%, tr:  95.91%, tr_best:  96.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.529121/  2.086286, val:  70.42%, val_best:  71.67%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.507286/  2.104996, val:  69.17%, val_best:  71.67%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.496600/  2.224729, val:  70.00%, val_best:  71.67%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.473855/  2.126294, val:  71.67%, val_best:  71.67%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.472142/  2.339891, val:  68.75%, val_best:  71.67%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.487210/  2.266432, val:  69.58%, val_best:  71.67%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.475445/  2.290019, val:  70.83%, val_best:  71.67%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.452874/  2.355073, val:  70.00%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.452309/  2.459893, val:  69.58%, val_best:  71.67%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.444040/  2.411304, val:  70.42%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.453037/  2.606485, val:  69.58%, val_best:  71.67%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.449663/  2.539390, val:  70.00%, val_best:  71.67%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.415449/  2.574585, val:  71.25%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.417245/  2.571409, val:  73.33%, val_best:  73.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.418554/  2.639767, val:  70.83%, val_best:  73.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.415570/  2.623053, val:  71.25%, val_best:  73.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.408440/  2.685894, val:  71.25%, val_best:  73.33%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.385202/  2.723778, val:  70.83%, val_best:  73.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.403790/  2.783764, val:  70.42%, val_best:  73.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.388395/  2.838592, val:  71.67%, val_best:  73.33%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.362923/  2.880138, val:  70.83%, val_best:  73.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.386900/  2.908173, val:  70.83%, val_best:  73.33%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.379174/  2.938439, val:  71.25%, val_best:  73.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.374211/  3.005418, val:  72.50%, val_best:  73.33%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.397676/  2.992896, val:  71.67%, val_best:  73.33%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.367904/  3.067449, val:  70.83%, val_best:  73.33%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.353390/  3.113835, val:  71.25%, val_best:  73.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.354414/  3.094555, val:  69.17%, val_best:  73.33%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.331966/  3.155092, val:  72.92%, val_best:  73.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.334417/  3.127499, val:  74.17%, val_best:  74.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.335382/  3.196282, val:  72.50%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.314106/  3.298356, val:  71.25%, val_best:  74.17%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.323310/  3.284461, val:  73.33%, val_best:  74.17%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.322623/  3.303090, val:  72.50%, val_best:  74.17%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.328684/  3.287883, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.319059/  3.376392, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.316031/  3.412154, val:  72.08%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.312103/  3.468009, val:  73.75%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.324003/  3.421182, val:  74.17%, val_best:  74.17%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.313989/  3.576118, val:  71.25%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.325470/  3.561282, val:  73.33%, val_best:  74.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.307655/  3.517884, val:  73.75%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.281335/  3.653274, val:  74.17%, val_best:  74.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.290174/  3.603874, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.308117/  3.698151, val:  73.75%, val_best:  74.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.325072/  3.664919, val:  74.58%, val_best:  74.58%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.284674/  3.794841, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.288401/  3.739623, val:  74.58%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.275124/  3.744802, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.275970/  3.823705, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.281717/  3.973137, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.271890/  3.961079, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.288444/  3.939897, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.285243/  4.122099, val:  70.83%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.274928/  3.998939, val:  76.25%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.248887/  4.019872, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.248968/  4.111683, val:  75.00%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.261103/  4.117242, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.244645/  4.227849, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.242393/  4.182146, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.248516/  4.210605, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.244102/  4.264716, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.231498/  4.233533, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.233675/  4.332769, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.247114/  4.403549, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.221064/  4.500523, val:  71.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.225686/  4.486770, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2ff929bd234e6487719c71475878fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▃▃▇▇▃▆███▇▆██▇███████████████▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇███████▇██</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇███████▇██</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▁▂▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.22569</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>4.48677</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-sweep-261</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uebgvnr2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uebgvnr2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_090814-uebgvnr2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9420e67p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_091515-9420e67p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9420e67p' target=\"_blank\">still-sweep-263</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9420e67p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9420e67p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303385/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.302999/  2.302758, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302884/  2.302676, val:  10.42%, val_best:  10.42%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.302937/  2.302622, val:  10.83%, val_best:  10.83%, tr:  10.32%, tr_best:  10.52%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302510/  2.302466, val:  11.25%, val_best:  11.25%, tr:  11.54%, tr_best:  11.54%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302069/  2.302081, val:  12.50%, val_best:  12.50%, tr:  12.46%, tr_best:  12.46%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.302145/  2.301618, val:  10.00%, val_best:  12.50%, tr:  11.75%, tr_best:  12.46%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.301182/  2.300749, val:  10.42%, val_best:  12.50%, tr:  11.85%, tr_best:  12.46%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.299289/  2.299141, val:  10.00%, val_best:  12.50%, tr:  13.89%, tr_best:  13.89%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.296365/  2.296639, val:  12.50%, val_best:  12.50%, tr:  13.99%, tr_best:  13.99%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.292319/  2.292144, val:  12.08%, val_best:  12.50%, tr:  14.50%, tr_best:  14.50%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.284315/  2.285668, val:  14.17%, val_best:  14.17%, tr:  14.91%, tr_best:  14.91%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.274568/  2.274913, val:  14.17%, val_best:  14.17%, tr:  13.59%, tr_best:  14.91%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.257969/  2.260733, val:  17.08%, val_best:  17.08%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.236376/  2.239287, val:  20.00%, val_best:  20.00%, tr:  19.00%, tr_best:  19.00%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.207176/  2.216041, val:  24.17%, val_best:  24.17%, tr:  22.98%, tr_best:  22.98%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.175920/  2.185832, val:  23.33%, val_best:  24.17%, tr:  24.72%, tr_best:  24.72%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.137046/  2.153112, val:  30.42%, val_best:  30.42%, tr:  28.60%, tr_best:  28.60%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.100350/  2.122704, val:  31.67%, val_best:  31.67%, tr:  33.71%, tr_best:  33.71%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.065196/  2.090460, val:  33.33%, val_best:  33.33%, tr:  35.65%, tr_best:  35.65%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.027109/  2.058760, val:  38.33%, val_best:  38.33%, tr:  37.28%, tr_best:  37.28%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.991935/  2.025528, val:  41.25%, val_best:  41.25%, tr:  40.55%, tr_best:  40.55%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.950905/  1.994202, val:  42.08%, val_best:  42.08%, tr:  44.02%, tr_best:  44.02%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.911328/  1.961835, val:  42.50%, val_best:  42.50%, tr:  44.64%, tr_best:  44.64%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.878763/  1.928056, val:  43.75%, val_best:  43.75%, tr:  46.68%, tr_best:  46.68%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.838106/  1.894669, val:  42.50%, val_best:  43.75%, tr:  48.01%, tr_best:  48.01%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.804025/  1.865112, val:  43.75%, val_best:  43.75%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.763242/  1.836773, val:  42.08%, val_best:  43.75%, tr:  49.95%, tr_best:  49.95%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.727479/  1.809641, val:  42.50%, val_best:  43.75%, tr:  50.46%, tr_best:  50.46%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.703662/  1.786343, val:  45.83%, val_best:  45.83%, tr:  51.17%, tr_best:  51.17%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.679972/  1.763433, val:  43.75%, val_best:  45.83%, tr:  51.79%, tr_best:  51.79%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.646387/  1.744075, val:  45.83%, val_best:  45.83%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.626353/  1.724657, val:  44.17%, val_best:  45.83%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.606478/  1.706433, val:  45.00%, val_best:  45.83%, tr:  53.52%, tr_best:  53.93%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.588147/  1.691136, val:  44.17%, val_best:  45.83%, tr:  54.55%, tr_best:  54.55%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.572647/  1.677410, val:  47.08%, val_best:  47.08%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.549720/  1.664349, val:  44.17%, val_best:  47.08%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.535283/  1.648630, val:  45.00%, val_best:  47.08%, tr:  58.12%, tr_best:  58.12%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.519009/  1.637509, val:  46.25%, val_best:  47.08%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.509553/  1.625227, val:  47.92%, val_best:  47.92%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.492961/  1.614434, val:  48.75%, val_best:  48.75%, tr:  57.30%, tr_best:  58.94%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.484063/  1.605855, val:  48.75%, val_best:  48.75%, tr:  57.81%, tr_best:  58.94%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.465103/  1.592090, val:  49.58%, val_best:  49.58%, tr:  58.73%, tr_best:  58.94%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.457727/  1.584098, val:  50.00%, val_best:  50.00%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.445830/  1.571961, val:  52.50%, val_best:  52.50%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.438472/  1.562812, val:  52.92%, val_best:  52.92%, tr:  58.02%, tr_best:  59.96%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.427315/  1.553786, val:  50.42%, val_best:  52.92%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.416676/  1.550790, val:  52.92%, val_best:  52.92%, tr:  60.16%, tr_best:  60.67%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.404887/  1.542407, val:  53.75%, val_best:  53.75%, tr:  59.96%, tr_best:  60.67%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.398384/  1.536589, val:  54.17%, val_best:  54.17%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.391913/  1.530380, val:  55.83%, val_best:  55.83%, tr:  60.88%, tr_best:  61.59%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.381779/  1.523501, val:  56.25%, val_best:  56.25%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.369507/  1.517961, val:  55.00%, val_best:  56.25%, tr:  62.51%, tr_best:  62.72%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.369595/  1.514389, val:  58.75%, val_best:  58.75%, tr:  62.41%, tr_best:  62.72%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.353787/  1.509668, val:  55.83%, val_best:  58.75%, tr:  60.88%, tr_best:  62.72%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.354373/  1.504657, val:  57.92%, val_best:  58.75%, tr:  61.39%, tr_best:  62.72%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.346911/  1.499307, val:  56.25%, val_best:  58.75%, tr:  61.39%, tr_best:  62.72%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.345516/  1.493930, val:  57.92%, val_best:  58.75%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.338707/  1.489630, val:  57.08%, val_best:  58.75%, tr:  62.72%, tr_best:  63.43%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.326416/  1.487149, val:  56.25%, val_best:  58.75%, tr:  62.82%, tr_best:  63.43%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.316465/  1.481256, val:  57.50%, val_best:  58.75%, tr:  63.13%, tr_best:  63.43%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.318961/  1.476951, val:  57.50%, val_best:  58.75%, tr:  63.13%, tr_best:  63.43%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.313264/  1.476341, val:  56.67%, val_best:  58.75%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.308202/  1.473343, val:  57.92%, val_best:  58.75%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.296274/  1.466686, val:  56.25%, val_best:  58.75%, tr:  62.41%, tr_best:  63.43%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.297400/  1.459043, val:  57.92%, val_best:  58.75%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.290336/  1.454976, val:  58.33%, val_best:  58.75%, tr:  64.04%, tr_best:  65.17%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.284018/  1.452057, val:  57.92%, val_best:  58.75%, tr:  63.23%, tr_best:  65.17%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.277087/  1.448907, val:  58.75%, val_best:  58.75%, tr:  62.92%, tr_best:  65.17%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.271181/  1.444814, val:  58.75%, val_best:  58.75%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.265088/  1.443850, val:  58.33%, val_best:  58.75%, tr:  62.51%, tr_best:  65.47%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.265444/  1.440282, val:  59.58%, val_best:  59.58%, tr:  63.94%, tr_best:  65.47%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.261984/  1.434208, val:  58.75%, val_best:  59.58%, tr:  63.94%, tr_best:  65.47%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.260119/  1.433017, val:  59.58%, val_best:  59.58%, tr:  63.94%, tr_best:  65.47%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.254975/  1.429463, val:  59.17%, val_best:  59.58%, tr:  64.45%, tr_best:  65.47%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.255700/  1.426156, val:  57.50%, val_best:  59.58%, tr:  64.66%, tr_best:  65.47%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.244677/  1.422965, val:  60.83%, val_best:  60.83%, tr:  64.25%, tr_best:  65.47%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.248790/  1.421648, val:  61.25%, val_best:  61.25%, tr:  65.27%, tr_best:  65.47%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.240613/  1.419371, val:  60.42%, val_best:  61.25%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.241135/  1.417874, val:  60.00%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.240056/  1.415753, val:  60.83%, val_best:  61.25%, tr:  64.45%, tr_best:  66.50%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.238025/  1.412904, val:  60.42%, val_best:  61.25%, tr:  64.86%, tr_best:  66.50%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.225889/  1.410465, val:  59.17%, val_best:  61.25%, tr:  64.66%, tr_best:  66.50%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.228369/  1.410762, val:  60.83%, val_best:  61.25%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.223306/  1.409378, val:  60.00%, val_best:  61.25%, tr:  66.80%, tr_best:  67.62%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.216402/  1.409564, val:  60.00%, val_best:  61.25%, tr:  66.29%, tr_best:  67.62%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.217195/  1.407600, val:  60.83%, val_best:  61.25%, tr:  67.31%, tr_best:  67.62%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.203808/  1.405875, val:  61.25%, val_best:  61.25%, tr:  66.29%, tr_best:  67.62%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.209737/  1.401118, val:  60.42%, val_best:  61.25%, tr:  66.70%, tr_best:  67.62%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.212175/  1.403679, val:  60.83%, val_best:  61.25%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.198833/  1.397734, val:  61.25%, val_best:  61.25%, tr:  67.11%, tr_best:  67.93%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.200905/  1.395111, val:  62.08%, val_best:  62.08%, tr:  65.88%, tr_best:  67.93%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.191531/  1.394050, val:  61.25%, val_best:  62.08%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.192198/  1.388378, val:  61.25%, val_best:  62.08%, tr:  67.31%, tr_best:  67.93%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.193458/  1.390504, val:  61.25%, val_best:  62.08%, tr:  66.39%, tr_best:  67.93%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.183497/  1.386864, val:  61.25%, val_best:  62.08%, tr:  68.44%, tr_best:  68.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ebcd6a95b140529a67bfdcbe22e8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▁▁▁▂▄▂▂▃▄▃▃▆▃▄▄▆▄▅▅▄▅▄▆▅▆▅▆▆▄▆▅▇▆▃▆█▅</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇█▇▇▇▇▇███▇███████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▂▂▃▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>tr_epoch_loss</td><td>████████▇▇▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▂▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇█▇▇▇▇▇███▇███████</td></tr><tr><td>val_loss</td><td>████████▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.68437</td></tr><tr><td>tr_epoch_loss</td><td>1.1835</td></tr><tr><td>val_acc_best</td><td>0.62083</td></tr><tr><td>val_acc_now</td><td>0.6125</td></tr><tr><td>val_loss</td><td>1.38686</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-sweep-263</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9420e67p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9420e67p</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_091515-9420e67p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b5sss8t7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_092210-b5sss8t7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b5sss8t7' target=\"_blank\">clear-sweep-266</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b5sss8t7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b5sss8t7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.455352/  2.658956, val:  27.50%, val_best:  27.50%, tr:  16.75%, tr_best:  16.75%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  3.184269/  4.009812, val:  25.83%, val_best:  27.50%, tr:  34.42%, tr_best:  34.42%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  2.610301/  3.182303, val:  33.75%, val_best:  33.75%, tr:  46.07%, tr_best:  46.07%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  3.014575/  3.000587, val:  35.83%, val_best:  35.83%, tr:  49.13%, tr_best:  49.13%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  3.662230/  4.057269, val:  56.67%, val_best:  56.67%, tr:  46.68%, tr_best:  49.13%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  3.717206/  3.720099, val:  48.75%, val_best:  56.67%, tr:  51.58%, tr_best:  51.58%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  2.704930/  3.789451, val:  42.08%, val_best:  56.67%, tr:  56.49%, tr_best:  56.49%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  3.259342/  5.997844, val:  30.42%, val_best:  56.67%, tr:  52.60%, tr_best:  56.49%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  3.183531/  3.661570, val:  47.50%, val_best:  56.67%, tr:  55.57%, tr_best:  56.49%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  3.283571/  4.841383, val:  55.42%, val_best:  56.67%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  3.259270/  5.117418, val:  41.67%, val_best:  56.67%, tr:  57.41%, tr_best:  60.67%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  2.737125/  5.222969, val:  49.58%, val_best:  56.67%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  2.610288/  3.628651, val:  50.00%, val_best:  56.67%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  2.739886/  5.800323, val:  39.58%, val_best:  56.67%, tr:  60.47%, tr_best:  65.37%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  3.154010/  5.563673, val:  45.83%, val_best:  56.67%, tr:  64.86%, tr_best:  65.37%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  2.828226/  5.082974, val:  53.33%, val_best:  56.67%, tr:  64.66%, tr_best:  65.37%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  2.981059/  3.945197, val:  64.17%, val_best:  64.17%, tr:  64.96%, tr_best:  65.37%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  2.305293/  4.866488, val:  53.33%, val_best:  64.17%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  2.530411/  4.008444, val:  57.92%, val_best:  64.17%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  2.129142/  5.400728, val:  45.42%, val_best:  64.17%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  2.043235/  3.998971, val:  50.42%, val_best:  64.17%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  1.814955/  3.707218, val:  59.17%, val_best:  64.17%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  1.758044/  4.691989, val:  49.17%, val_best:  64.17%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  1.756369/  3.791964, val:  62.92%, val_best:  64.17%, tr:  79.16%, tr_best:  79.67%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  1.234727/  3.496139, val:  59.17%, val_best:  64.17%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  1.285174/  3.613049, val:  65.00%, val_best:  65.00%, tr:  84.07%, tr_best:  86.31%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  1.235726/  3.396385, val:  66.67%, val_best:  66.67%, tr:  86.01%, tr_best:  86.31%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  1.328656/  4.508213, val:  53.75%, val_best:  66.67%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  1.637051/  3.923764, val:  62.50%, val_best:  66.67%, tr:  85.19%, tr_best:  86.31%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  1.094716/  3.686028, val:  61.25%, val_best:  66.67%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  1.026206/  3.283523, val:  67.50%, val_best:  67.50%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  1.033893/  4.325826, val:  63.75%, val_best:  67.50%, tr:  89.68%, tr_best:  92.65%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  1.382128/  4.300523, val:  63.33%, val_best:  67.50%, tr:  88.15%, tr_best:  92.65%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  1.160349/  4.520746, val:  57.92%, val_best:  67.50%, tr:  90.81%, tr_best:  92.65%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  1.189649/  3.838521, val:  69.58%, val_best:  69.58%, tr:  90.19%, tr_best:  92.65%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.841484/  3.694790, val:  66.25%, val_best:  69.58%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.654266/  3.695116, val:  59.58%, val_best:  69.58%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  1.233841/  5.291497, val:  52.50%, val_best:  69.58%, tr:  87.84%, tr_best:  96.42%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  1.167333/  4.783337, val:  58.75%, val_best:  69.58%, tr:  91.73%, tr_best:  96.42%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.837437/  3.899461, val:  65.42%, val_best:  69.58%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.742419/  3.820357, val:  62.08%, val_best:  69.58%, tr:  95.51%, tr_best:  96.63%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.789770/  4.226920, val:  52.08%, val_best:  69.58%, tr:  93.16%, tr_best:  96.63%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.825587/  4.152294, val:  64.58%, val_best:  69.58%, tr:  94.89%, tr_best:  96.63%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.709384/  3.753949, val:  67.08%, val_best:  69.58%, tr:  95.40%, tr_best:  96.63%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.985024/  4.689168, val:  55.83%, val_best:  69.58%, tr:  93.05%, tr_best:  96.63%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.639738/  3.927127, val:  59.58%, val_best:  69.58%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.715000/  4.128728, val:  66.67%, val_best:  69.58%, tr:  94.69%, tr_best:  97.55%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.684694/  4.077741, val:  66.67%, val_best:  69.58%, tr:  96.63%, tr_best:  97.55%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.716879/  3.917392, val:  70.83%, val_best:  70.83%, tr:  96.63%, tr_best:  97.55%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.611993/  3.907090, val:  62.92%, val_best:  70.83%, tr:  97.24%, tr_best:  97.55%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.479156/  3.779302, val:  60.00%, val_best:  70.83%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.411620/  3.484888, val:  67.92%, val_best:  70.83%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.389393/  3.370485, val:  65.83%, val_best:  70.83%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.471434/  3.642219, val:  66.67%, val_best:  70.83%, tr:  97.75%, tr_best:  99.18%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.517819/  4.361666, val:  55.83%, val_best:  70.83%, tr:  97.14%, tr_best:  99.18%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.542046/  4.001684, val:  63.75%, val_best:  70.83%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.413408/  3.643000, val:  70.42%, val_best:  70.83%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.445718/  3.647925, val:  67.92%, val_best:  70.83%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.367918/  3.426391, val:  69.58%, val_best:  70.83%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.352281/  3.399967, val:  71.67%, val_best:  71.67%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.272353/  4.319684, val:  53.75%, val_best:  71.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.415581/  3.648935, val:  68.75%, val_best:  71.67%, tr:  98.37%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.362426/  3.576533, val:  68.75%, val_best:  71.67%, tr:  98.77%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.306048/  4.019059, val:  59.17%, val_best:  71.67%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.285126/  4.102968, val:  66.25%, val_best:  71.67%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.242597/  3.611477, val:  72.50%, val_best:  72.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.259498/  3.445181, val:  74.58%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.310698/  3.589989, val:  72.08%, val_best:  74.58%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.381868/  3.937472, val:  69.58%, val_best:  74.58%, tr:  97.96%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.264910/  3.879350, val:  65.42%, val_best:  74.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.297144/  3.584724, val:  69.17%, val_best:  74.58%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.245730/  3.862907, val:  64.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.216980/  3.563008, val:  71.67%, val_best:  74.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.221658/  3.729283, val:  67.92%, val_best:  74.58%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.226806/  3.590094, val:  67.92%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.242684/  3.606248, val:  68.33%, val_best:  74.58%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.184700/  3.642021, val:  70.42%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.224680/  3.617875, val:  69.17%, val_best:  74.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.254276/  3.797261, val:  64.58%, val_best:  74.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.214977/  3.649323, val:  70.42%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.207504/  3.526593, val:  70.00%, val_best:  74.58%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.177938/  3.561941, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.189371/  3.895146, val:  66.25%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.180088/  3.715230, val:  71.67%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.160125/  3.454518, val:  72.92%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.160722/  3.684721, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.173904/  3.600708, val:  71.25%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.151824/  3.590068, val:  70.00%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.144722/  3.464793, val:  71.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.123557/  3.547704, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.140958/  3.627721, val:  70.42%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.173075/  3.978842, val:  66.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.132485/  3.616510, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.139885/  3.750947, val:  72.50%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.151448/  3.786464, val:  70.00%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.127589/  3.617079, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.133908/  3.605619, val:  72.50%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.140385/  3.666183, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.142092/  3.792035, val:  70.00%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.160237/  3.864705, val:  70.00%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5164944ba3534625b92ed9ab48bb4c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▂▂▂▄▅▆▆▆██▇▆▇▇███▆████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▁▅▄▄▅▄▆▆▇▆▇▇▅▇▇▅▇▆▇▅▇█▇██▇█▇▇█▇██████</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▅▅▅▆▆▆▇▇▇▇█▇██▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆▆█▇▇▆▇▅▅▄▃▃▃▃▂▃▂▂▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▁▅▄▄▅▄▆▆▇▆▇▇▅▇▇▅▇▆▇▅▇█▇██▇█▇▇█▇██████</td></tr><tr><td>val_loss</td><td>▁▂▄█▆▃▇▆▇▃▃▃▃▄▃▇▄▄▅▄▄▂▅▃▃▃▃▃▃▃▃▃▃▄▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.16024</td></tr><tr><td>val_acc_best</td><td>0.74583</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>3.8647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-sweep-266</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b5sss8t7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b5sss8t7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_092210-b5sss8t7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qkmwe77u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_092913-qkmwe77u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qkmwe77u' target=\"_blank\">genial-sweep-268</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qkmwe77u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qkmwe77u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302740/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302768/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302738/  2.302565, val:  10.42%, val_best:  10.42%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302766/  2.302584, val:  10.00%, val_best:  10.42%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302680/  2.302563, val:  10.42%, val_best:  10.42%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302783/  2.302580, val:  10.42%, val_best:  10.42%, tr:   9.40%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302732/  2.302577, val:  10.42%, val_best:  10.42%, tr:   9.91%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302724/  2.302581, val:  10.42%, val_best:  10.42%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302689/  2.302541, val:  10.42%, val_best:  10.42%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302551/  2.302510, val:  10.42%, val_best:  10.42%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302691/  2.302477, val:  10.42%, val_best:  10.42%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302573/  2.302427, val:  10.42%, val_best:  10.42%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302343/  2.302262, val:  10.00%, val_best:  10.42%, tr:   9.40%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.302190/  2.302135, val:  10.00%, val_best:  10.42%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.302159/  2.301987, val:  10.42%, val_best:  10.42%, tr:  10.62%, tr_best:  10.62%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.301833/  2.301864, val:  10.42%, val_best:  10.42%, tr:   9.50%, tr_best:  10.62%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.301515/  2.301711, val:  10.83%, val_best:  10.83%, tr:  11.24%, tr_best:  11.24%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.301293/  2.301321, val:  12.08%, val_best:  12.08%, tr:  13.07%, tr_best:  13.07%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.300558/  2.301033, val:  12.92%, val_best:  12.92%, tr:  13.28%, tr_best:  13.28%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.299907/  2.300712, val:  12.50%, val_best:  12.92%, tr:  14.40%, tr_best:  14.40%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.299047/  2.300235, val:  11.67%, val_best:  12.92%, tr:  13.89%, tr_best:  14.40%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.297891/  2.299435, val:  12.92%, val_best:  12.92%, tr:  15.42%, tr_best:  15.42%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.295794/  2.298902, val:  11.25%, val_best:  12.92%, tr:  14.40%, tr_best:  15.42%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.294690/  2.297929, val:  12.08%, val_best:  12.92%, tr:  15.53%, tr_best:  15.53%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.292622/  2.297033, val:  12.50%, val_best:  12.92%, tr:  16.14%, tr_best:  16.14%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.290354/  2.295654, val:  12.50%, val_best:  12.92%, tr:  13.99%, tr_best:  16.14%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.285732/  2.294121, val:  12.08%, val_best:  12.92%, tr:  16.04%, tr_best:  16.14%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.282847/  2.291546, val:  11.25%, val_best:  12.92%, tr:  15.63%, tr_best:  16.14%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.278059/  2.288420, val:  12.92%, val_best:  12.92%, tr:  14.40%, tr_best:  16.14%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.273171/  2.284875, val:  14.17%, val_best:  14.17%, tr:  13.69%, tr_best:  16.14%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.266757/  2.281509, val:  14.58%, val_best:  14.58%, tr:  15.42%, tr_best:  16.14%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.257088/  2.278077, val:  16.25%, val_best:  16.25%, tr:  19.00%, tr_best:  19.00%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.251849/  2.272895, val:  22.08%, val_best:  22.08%, tr:  16.85%, tr_best:  19.00%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.243933/  2.268084, val:  16.67%, val_best:  22.08%, tr:  15.93%, tr_best:  19.00%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.236962/  2.262784, val:  21.25%, val_best:  22.08%, tr:  20.84%, tr_best:  20.84%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.230527/  2.258214, val:  22.08%, val_best:  22.08%, tr:  19.31%, tr_best:  20.84%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.223529/  2.252542, val:  23.75%, val_best:  23.75%, tr:  22.37%, tr_best:  22.37%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.216411/  2.248482, val:  25.00%, val_best:  25.00%, tr:  21.55%, tr_best:  22.37%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.210343/  2.243749, val:  25.00%, val_best:  25.00%, tr:  24.51%, tr_best:  24.51%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.204121/  2.239038, val:  23.33%, val_best:  25.00%, tr:  25.43%, tr_best:  25.43%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.197347/  2.233609, val:  23.33%, val_best:  25.00%, tr:  26.05%, tr_best:  26.05%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.191887/  2.229416, val:  25.00%, val_best:  25.00%, tr:  26.56%, tr_best:  26.56%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.184593/  2.223622, val:  24.58%, val_best:  25.00%, tr:  28.50%, tr_best:  28.50%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.178216/  2.218103, val:  25.00%, val_best:  25.00%, tr:  28.40%, tr_best:  28.50%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.172335/  2.211360, val:  27.92%, val_best:  27.92%, tr:  30.85%, tr_best:  30.85%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.160994/  2.204952, val:  26.67%, val_best:  27.92%, tr:  31.05%, tr_best:  31.05%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.156946/  2.198263, val:  28.75%, val_best:  28.75%, tr:  32.48%, tr_best:  32.48%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.149663/  2.190454, val:  31.25%, val_best:  31.25%, tr:  33.40%, tr_best:  33.40%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.139354/  2.181036, val:  30.83%, val_best:  31.25%, tr:  34.42%, tr_best:  34.42%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  2.130111/  2.170189, val:  34.17%, val_best:  34.17%, tr:  36.67%, tr_best:  36.67%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  2.113734/  2.160351, val:  36.67%, val_best:  36.67%, tr:  35.65%, tr_best:  36.67%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  2.106742/  2.148621, val:  39.17%, val_best:  39.17%, tr:  38.51%, tr_best:  38.51%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  2.092616/  2.135796, val:  40.00%, val_best:  40.00%, tr:  39.63%, tr_best:  39.63%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  2.077926/  2.119972, val:  40.42%, val_best:  40.42%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  2.054174/  2.103735, val:  38.75%, val_best:  40.42%, tr:  43.00%, tr_best:  43.00%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  2.034653/  2.083827, val:  41.67%, val_best:  41.67%, tr:  41.47%, tr_best:  43.00%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  2.017818/  2.067446, val:  42.08%, val_best:  42.08%, tr:  42.29%, tr_best:  43.00%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.999142/  2.049407, val:  42.08%, val_best:  42.08%, tr:  44.64%, tr_best:  44.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068859dd9d7e40e49345eae695c9ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▂▂▂▃▃▄▄▁▅▄▅▃▁▃▄▃▄▁▅▂▅▃▂▂▅▃▄▄▅▅▅▄▆▇█▇▆▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▄▄▄▄▅▆▇██</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▂▂▂▃▃▄▅▅▆▆▇██</td></tr><tr><td>tr_epoch_loss</td><td>████████████████████████████▇▇▆▆▆▅▅▄▄▃▂▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▄▄▄▄▄▅▆▇██</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▄▄▄▄▅▆▇██</td></tr><tr><td>val_loss</td><td>█████████████████████████████▇▇▇▆▆▅▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.44637</td></tr><tr><td>tr_epoch_loss</td><td>1.99914</td></tr><tr><td>val_acc_best</td><td>0.42083</td></tr><tr><td>val_acc_now</td><td>0.42083</td></tr><tr><td>val_loss</td><td>2.04941</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-268</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qkmwe77u' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qkmwe77u</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_092913-qkmwe77u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2h4jawpy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_093530-2h4jawpy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2h4jawpy' target=\"_blank\">deep-sweep-270</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2h4jawpy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2h4jawpy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304866/  2.302069, val:   7.92%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.291182/  2.257805, val:  18.33%, val_best:  18.33%, tr:  11.44%, tr_best:  11.44%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.127549/  2.033066, val:  37.92%, val_best:  37.92%, tr:  31.26%, tr_best:  31.26%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.856634/  1.821985, val:  46.25%, val_best:  46.25%, tr:  44.13%, tr_best:  44.13%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.649979/  1.708334, val:  50.42%, val_best:  50.42%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.562437/  1.657492, val:  51.67%, val_best:  51.67%, tr:  56.18%, tr_best:  56.18%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.499264/  1.611927, val:  54.17%, val_best:  54.17%, tr:  55.98%, tr_best:  56.18%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.449089/  1.584853, val:  57.92%, val_best:  57.92%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.418374/  1.565120, val:  57.50%, val_best:  57.92%, tr:  59.86%, tr_best:  59.86%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.388786/  1.553536, val:  55.42%, val_best:  57.92%, tr:  59.24%, tr_best:  59.86%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.370210/  1.511962, val:  57.92%, val_best:  57.92%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.357440/  1.509884, val:  57.50%, val_best:  57.92%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.342602/  1.514555, val:  58.33%, val_best:  58.33%, tr:  60.78%, tr_best:  62.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.305215/  1.537346, val:  55.42%, val_best:  58.33%, tr:  61.70%, tr_best:  62.51%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.302316/  1.485492, val:  59.58%, val_best:  59.58%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.284428/  1.474774, val:  61.25%, val_best:  61.25%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.259987/  1.460601, val:  61.25%, val_best:  61.25%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.241964/  1.475400, val:  59.17%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.240879/  1.503373, val:  55.42%, val_best:  61.25%, tr:  65.58%, tr_best:  66.50%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.220163/  1.464319, val:  60.00%, val_best:  61.25%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.213697/  1.454909, val:  61.25%, val_best:  61.25%, tr:  65.47%, tr_best:  66.50%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.221104/  1.443046, val:  61.67%, val_best:  61.67%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.181027/  1.441109, val:  63.33%, val_best:  63.33%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.162847/  1.455854, val:  61.67%, val_best:  63.33%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.167728/  1.412543, val:  67.92%, val_best:  67.92%, tr:  67.01%, tr_best:  68.54%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.153586/  1.391479, val:  68.33%, val_best:  68.33%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.135177/  1.423039, val:  65.42%, val_best:  68.33%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.140573/  1.399903, val:  69.17%, val_best:  69.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.109663/  1.417845, val:  63.33%, val_best:  69.17%, tr:  70.17%, tr_best:  70.48%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.099673/  1.426477, val:  61.25%, val_best:  69.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.122352/  1.438461, val:  62.08%, val_best:  69.17%, tr:  68.74%, tr_best:  70.48%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.103809/  1.425450, val:  65.42%, val_best:  69.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.098189/  1.406904, val:  68.75%, val_best:  69.17%, tr:  71.40%, tr_best:  71.40%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.069862/  1.426177, val:  62.08%, val_best:  69.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.096516/  1.432182, val:  61.67%, val_best:  69.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.057844/  1.397995, val:  66.25%, val_best:  69.17%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.062569/  1.396652, val:  65.83%, val_best:  69.17%, tr:  73.44%, tr_best:  73.54%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.051041/  1.394145, val:  67.08%, val_best:  69.17%, tr:  75.18%, tr_best:  75.18%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.037509/  1.416767, val:  65.83%, val_best:  69.17%, tr:  76.51%, tr_best:  76.51%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.040144/  1.402977, val:  65.83%, val_best:  69.17%, tr:  75.18%, tr_best:  76.51%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.034511/  1.435016, val:  63.33%, val_best:  69.17%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.015900/  1.395543, val:  67.08%, val_best:  69.17%, tr:  74.97%, tr_best:  78.55%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.015039/  1.423531, val:  62.92%, val_best:  69.17%, tr:  76.40%, tr_best:  78.55%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.992370/  1.417143, val:  67.92%, val_best:  69.17%, tr:  77.43%, tr_best:  78.55%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.988180/  1.411350, val:  65.00%, val_best:  69.17%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.984562/  1.405432, val:  68.75%, val_best:  69.17%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.979875/  1.409449, val:  70.42%, val_best:  70.42%, tr:  79.16%, tr_best:  81.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.993695/  1.411551, val:  68.33%, val_best:  70.42%, tr:  79.67%, tr_best:  81.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.977868/  1.397911, val:  68.75%, val_best:  70.42%, tr:  79.16%, tr_best:  81.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.970257/  1.432657, val:  66.67%, val_best:  70.42%, tr:  78.45%, tr_best:  81.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.987519/  1.424328, val:  67.50%, val_best:  70.42%, tr:  77.32%, tr_best:  81.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.943998/  1.453337, val:  65.83%, val_best:  70.42%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.948366/  1.428699, val:  69.58%, val_best:  70.42%, tr:  81.72%, tr_best:  82.23%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.934680/  1.425228, val:  70.83%, val_best:  70.83%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.936092/  1.429318, val:  70.00%, val_best:  70.83%, tr:  81.92%, tr_best:  83.66%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.928002/  1.498770, val:  62.92%, val_best:  70.83%, tr:  82.43%, tr_best:  83.66%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.936448/  1.422120, val:  68.75%, val_best:  70.83%, tr:  83.45%, tr_best:  83.66%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.910573/  1.469010, val:  67.92%, val_best:  70.83%, tr:  82.94%, tr_best:  83.66%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.911871/  1.430249, val:  73.75%, val_best:  73.75%, tr:  83.55%, tr_best:  83.66%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.912011/  1.415647, val:  70.42%, val_best:  73.75%, tr:  83.25%, tr_best:  83.66%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.913183/  1.475398, val:  64.17%, val_best:  73.75%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.902948/  1.463507, val:  68.33%, val_best:  73.75%, tr:  85.19%, tr_best:  85.80%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.889743/  1.414555, val:  69.58%, val_best:  73.75%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.887326/  1.484771, val:  67.08%, val_best:  73.75%, tr:  84.37%, tr_best:  87.03%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.887590/  1.448018, val:  71.25%, val_best:  73.75%, tr:  84.58%, tr_best:  87.03%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.882209/  1.469138, val:  67.50%, val_best:  73.75%, tr:  85.60%, tr_best:  87.03%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.877611/  1.462659, val:  68.75%, val_best:  73.75%, tr:  86.82%, tr_best:  87.03%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.861277/  1.500203, val:  69.58%, val_best:  73.75%, tr:  85.80%, tr_best:  87.03%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.879053/  1.486644, val:  66.67%, val_best:  73.75%, tr:  85.60%, tr_best:  87.03%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.861990/  1.457009, val:  71.25%, val_best:  73.75%, tr:  86.82%, tr_best:  87.03%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.863927/  1.511866, val:  67.92%, val_best:  73.75%, tr:  86.41%, tr_best:  87.03%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.851772/  1.479541, val:  71.25%, val_best:  73.75%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.859869/  1.497649, val:  70.00%, val_best:  73.75%, tr:  86.01%, tr_best:  87.84%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.847316/  1.478438, val:  70.83%, val_best:  73.75%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.849938/  1.494172, val:  67.92%, val_best:  73.75%, tr:  86.21%, tr_best:  89.17%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.839509/  1.534878, val:  65.83%, val_best:  73.75%, tr:  86.52%, tr_best:  89.17%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.855750/  1.489117, val:  70.83%, val_best:  73.75%, tr:  86.31%, tr_best:  89.17%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.847236/  1.495279, val:  71.25%, val_best:  73.75%, tr:  86.01%, tr_best:  89.17%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.832905/  1.482776, val:  72.08%, val_best:  73.75%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.817946/  1.511226, val:  68.75%, val_best:  73.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.827399/  1.478066, val:  72.08%, val_best:  73.75%, tr:  88.36%, tr_best:  89.89%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.819834/  1.506966, val:  66.25%, val_best:  73.75%, tr:  88.36%, tr_best:  89.89%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.818009/  1.521518, val:  71.25%, val_best:  73.75%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.821352/  1.479230, val:  71.25%, val_best:  73.75%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.804476/  1.529843, val:  66.25%, val_best:  73.75%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.803580/  1.517577, val:  70.83%, val_best:  73.75%, tr:  89.79%, tr_best:  91.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.807015/  1.560798, val:  68.75%, val_best:  73.75%, tr:  89.17%, tr_best:  91.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.785917/  1.522126, val:  73.75%, val_best:  73.75%, tr:  91.01%, tr_best:  91.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.778291/  1.531748, val:  73.75%, val_best:  73.75%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.785248/  1.510074, val:  68.33%, val_best:  73.75%, tr:  90.70%, tr_best:  92.13%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.786164/  1.535146, val:  67.92%, val_best:  73.75%, tr:  90.19%, tr_best:  92.13%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.772392/  1.551012, val:  72.50%, val_best:  73.75%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.773888/  1.536079, val:  70.42%, val_best:  73.75%, tr:  91.01%, tr_best:  92.13%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.776216/  1.543640, val:  70.83%, val_best:  73.75%, tr:  91.22%, tr_best:  92.13%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.771211/  1.587912, val:  69.58%, val_best:  73.75%, tr:  91.42%, tr_best:  92.13%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.780185/  1.657034, val:  64.17%, val_best:  73.75%, tr:  89.89%, tr_best:  92.13%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.772233/  1.565321, val:  69.58%, val_best:  73.75%, tr:  88.76%, tr_best:  92.13%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.755529/  1.574369, val:  67.92%, val_best:  73.75%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.767645/  1.560743, val:  69.58%, val_best:  73.75%, tr:  91.01%, tr_best:  92.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f62c17f74ee44118eb26531feb5db1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▂▄▃▅▇▃▄▆▅▇▅▆▅▇█▆█▆▆█▇██▇▇▇█▆▇▇▅█▇▆▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇██▇██▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇██▇██▇█▇████</td></tr><tr><td>val_loss</td><td>██▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91011</td></tr><tr><td>tr_epoch_loss</td><td>0.76765</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.69583</td></tr><tr><td>val_loss</td><td>1.56074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-270</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2h4jawpy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2h4jawpy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_093530-2h4jawpy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gndil2e8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_094237-gndil2e8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gndil2e8' target=\"_blank\">dauntless-sweep-272</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gndil2e8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gndil2e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.957073/  1.538933, val:  54.58%, val_best:  54.58%, tr:  31.15%, tr_best:  31.15%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.291305/  1.396871, val:  55.83%, val_best:  55.83%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.101060/  1.289411, val:  58.75%, val_best:  58.75%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.920764/  1.387030, val:  60.83%, val_best:  60.83%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.808189/  1.329958, val:  61.25%, val_best:  61.25%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.733569/  1.266379, val:  69.58%, val_best:  69.58%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.664230/  1.248816, val:  67.50%, val_best:  69.58%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.590696/  1.337065, val:  63.75%, val_best:  69.58%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.551449/  1.362797, val:  64.17%, val_best:  69.58%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.445037/  1.383757, val:  67.08%, val_best:  69.58%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.408753/  1.507142, val:  67.08%, val_best:  69.58%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.344364/  1.529292, val:  75.00%, val_best:  75.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.288097/  1.527572, val:  73.33%, val_best:  75.00%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.252045/  1.606242, val:  74.58%, val_best:  75.00%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.186839/  1.795442, val:  70.83%, val_best:  75.00%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.161989/  1.857511, val:  67.92%, val_best:  75.00%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.115854/  1.953218, val:  71.25%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.141981/  1.990165, val:  72.08%, val_best:  75.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.097326/  1.964939, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.087319/  1.982119, val:  75.42%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.061569/  2.013613, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.043610/  2.136260, val:  72.50%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.033305/  2.083334, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.025353/  2.117206, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.020841/  2.163277, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.021782/  2.188435, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.021976/  2.243493, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.013368/  2.260771, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.012100/  2.277853, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.008842/  2.303206, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.007924/  2.270687, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.007363/  2.288495, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.006937/  2.347878, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.005396/  2.352182, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.005570/  2.372597, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.004986/  2.362289, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.004246/  2.363674, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.003764/  2.363402, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.003686/  2.376322, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.004391/  2.375667, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.003993/  2.409364, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.003237/  2.401194, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.002814/  2.431450, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.002773/  2.457448, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.002912/  2.433091, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.002546/  2.441670, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.002368/  2.461489, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002264/  2.449035, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002513/  2.469102, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002477/  2.464642, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002158/  2.479714, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002563/  2.493438, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.002200/  2.482085, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.002049/  2.475434, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.001813/  2.493677, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.001651/  2.485032, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002425/  2.497836, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.001717/  2.481738, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.001511/  2.494472, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.001696/  2.486559, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001551/  2.506783, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001360/  2.513916, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001326/  2.506241, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001349/  2.493743, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001306/  2.498175, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001431/  2.522136, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001188/  2.525834, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001369/  2.531277, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001499/  2.537018, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001262/  2.536241, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001130/  2.553225, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001139/  2.542223, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001075/  2.555832, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001047/  2.554490, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001110/  2.561623, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001061/  2.561861, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001309/  2.574905, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001281/  2.577984, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.001159/  2.575677, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001113/  2.583035, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.000960/  2.586264, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.000972/  2.590423, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.000951/  2.594494, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.000959/  2.573489, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.000928/  2.593845, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.000863/  2.582112, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000866/  2.596251, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.001306/  2.585508, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.001432/  2.605535, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.001202/  2.612906, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.000950/  2.630672, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.000880/  2.623271, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000863/  2.624882, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.000839/  2.611538, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.000881/  2.630229, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.000767/  2.619477, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.000805/  2.623837, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001266/  2.640125, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.000922/  2.654451, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.000850/  2.633842, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649728db84e943f5943010f59ebeeea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▆▇▅▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▄▅▇▆▆▇▆▇▇▆▇████▇█▇▇▇███▇▇▇████▇▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▅▅▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▄▅▇▆▆▇▆▇▇▆▇████▇█▇▇▇███▇▇▇████▇▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00085</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.63384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-272</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gndil2e8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gndil2e8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_094237-gndil2e8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: icqzxhel with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_094910-icqzxhel</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icqzxhel' target=\"_blank\">comfy-sweep-274</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icqzxhel' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icqzxhel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.299678/  2.281486, val:  17.92%, val_best:  17.92%, tr:  12.97%, tr_best:  12.97%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.235559/  2.175359, val:  22.08%, val_best:  22.08%, tr:  17.06%, tr_best:  17.06%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.037565/  1.959421, val:  41.67%, val_best:  41.67%, tr:  33.09%, tr_best:  33.09%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  1.773244/  1.763377, val:  46.67%, val_best:  46.67%, tr:  45.97%, tr_best:  45.97%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.577888/  1.633445, val:  50.42%, val_best:  50.42%, tr:  50.87%, tr_best:  50.87%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.431611/  1.536901, val:  57.50%, val_best:  57.50%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.342111/  1.478646, val:  58.75%, val_best:  58.75%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.260255/  1.437364, val:  57.50%, val_best:  58.75%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.202737/  1.401579, val:  61.25%, val_best:  61.25%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.153924/  1.389476, val:  59.58%, val_best:  61.25%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.116390/  1.374403, val:  60.00%, val_best:  61.25%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.092737/  1.353713, val:  60.00%, val_best:  61.25%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.079535/  1.338026, val:  60.83%, val_best:  61.25%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.047515/  1.316453, val:  63.33%, val_best:  63.33%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.013879/  1.315523, val:  60.42%, val_best:  63.33%, tr:  69.87%, tr_best:  70.28%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.000986/  1.305858, val:  60.00%, val_best:  63.33%, tr:  69.05%, tr_best:  70.28%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  0.976022/  1.293979, val:  60.00%, val_best:  63.33%, tr:  69.66%, tr_best:  70.28%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  0.966999/  1.277838, val:  60.42%, val_best:  63.33%, tr:  72.32%, tr_best:  72.32%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  0.955247/  1.283906, val:  58.75%, val_best:  63.33%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  0.936324/  1.276503, val:  60.00%, val_best:  63.33%, tr:  70.38%, tr_best:  72.42%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  0.925073/  1.265620, val:  59.17%, val_best:  63.33%, tr:  71.81%, tr_best:  72.42%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  0.906756/  1.259803, val:  60.42%, val_best:  63.33%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  0.896961/  1.274219, val:  60.83%, val_best:  63.33%, tr:  72.22%, tr_best:  74.26%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  0.885418/  1.257938, val:  62.08%, val_best:  63.33%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  0.869991/  1.255989, val:  61.25%, val_best:  63.33%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  0.855720/  1.249142, val:  63.75%, val_best:  63.75%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  0.849057/  1.240840, val:  63.33%, val_best:  63.75%, tr:  76.40%, tr_best:  79.37%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  0.834196/  1.247236, val:  64.58%, val_best:  64.58%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  0.840484/  1.235925, val:  63.33%, val_best:  64.58%, tr:  78.86%, tr_best:  79.47%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  0.819739/  1.241372, val:  66.67%, val_best:  66.67%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  0.807535/  1.235978, val:  65.00%, val_best:  66.67%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  0.802212/  1.251640, val:  62.92%, val_best:  66.67%, tr:  79.67%, tr_best:  80.39%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  0.787210/  1.246376, val:  63.75%, val_best:  66.67%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  0.782414/  1.241761, val:  65.00%, val_best:  66.67%, tr:  82.74%, tr_best:  83.15%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.770460/  1.217314, val:  65.83%, val_best:  66.67%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.762600/  1.229568, val:  65.83%, val_best:  66.67%, tr:  83.55%, tr_best:  84.47%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.752161/  1.245413, val:  61.67%, val_best:  66.67%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.743955/  1.225150, val:  66.25%, val_best:  66.67%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.744532/  1.223212, val:  67.08%, val_best:  67.08%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.730716/  1.222093, val:  67.50%, val_best:  67.50%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.713400/  1.225677, val:  68.75%, val_best:  68.75%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.716847/  1.224208, val:  69.17%, val_best:  69.17%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.695911/  1.218817, val:  68.33%, val_best:  69.17%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.692733/  1.223670, val:  68.75%, val_best:  69.17%, tr:  88.25%, tr_best:  88.76%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.682906/  1.219441, val:  69.17%, val_best:  69.17%, tr:  87.74%, tr_best:  88.76%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.676242/  1.214421, val:  71.67%, val_best:  71.67%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.665293/  1.226123, val:  67.08%, val_best:  71.67%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.666532/  1.231026, val:  68.75%, val_best:  71.67%, tr:  89.48%, tr_best:  90.60%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.652708/  1.220614, val:  70.83%, val_best:  71.67%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.642459/  1.235215, val:  68.33%, val_best:  71.67%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.635532/  1.239044, val:  67.92%, val_best:  71.67%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.626440/  1.236419, val:  69.17%, val_best:  71.67%, tr:  90.50%, tr_best:  91.83%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.620991/  1.249172, val:  70.42%, val_best:  71.67%, tr:  91.52%, tr_best:  91.83%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.612719/  1.245602, val:  70.42%, val_best:  71.67%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.607658/  1.260822, val:  70.83%, val_best:  71.67%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.600857/  1.266346, val:  68.75%, val_best:  71.67%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.585610/  1.257392, val:  70.42%, val_best:  71.67%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.580258/  1.273154, val:  70.00%, val_best:  71.67%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.571184/  1.281659, val:  70.83%, val_best:  71.67%, tr:  94.18%, tr_best:  94.89%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.568960/  1.270735, val:  70.42%, val_best:  71.67%, tr:  93.46%, tr_best:  94.89%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.563908/  1.270384, val:  69.17%, val_best:  71.67%, tr:  94.59%, tr_best:  94.89%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.561797/  1.279518, val:  71.67%, val_best:  71.67%, tr:  94.59%, tr_best:  94.89%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.554229/  1.283197, val:  69.58%, val_best:  71.67%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.544467/  1.281217, val:  71.25%, val_best:  71.67%, tr:  95.10%, tr_best:  95.51%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.542755/  1.296206, val:  72.08%, val_best:  72.08%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.537094/  1.290050, val:  69.17%, val_best:  72.08%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.535074/  1.284156, val:  71.67%, val_best:  72.08%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.536494/  1.292696, val:  72.50%, val_best:  72.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.521106/  1.296582, val:  73.33%, val_best:  73.33%, tr:  95.40%, tr_best:  95.91%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.516417/  1.306632, val:  69.58%, val_best:  73.33%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.513940/  1.317156, val:  72.50%, val_best:  73.33%, tr:  95.40%, tr_best:  96.22%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.508687/  1.305396, val:  70.42%, val_best:  73.33%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.499321/  1.320716, val:  72.92%, val_best:  73.33%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.495544/  1.319495, val:  72.92%, val_best:  73.33%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.487350/  1.331272, val:  71.67%, val_best:  73.33%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.488401/  1.328044, val:  70.00%, val_best:  73.33%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.477655/  1.342255, val:  70.83%, val_best:  73.33%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.484395/  1.346983, val:  70.42%, val_best:  73.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.472613/  1.341430, val:  70.83%, val_best:  73.33%, tr:  96.63%, tr_best:  96.94%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.467242/  1.360091, val:  70.83%, val_best:  73.33%, tr:  96.53%, tr_best:  96.94%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.459385/  1.362625, val:  71.67%, val_best:  73.33%, tr:  96.63%, tr_best:  96.94%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.464096/  1.360961, val:  70.83%, val_best:  73.33%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.454967/  1.389074, val:  70.42%, val_best:  73.33%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.459059/  1.378742, val:  70.83%, val_best:  73.33%, tr:  96.83%, tr_best:  97.34%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.448600/  1.370245, val:  70.83%, val_best:  73.33%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.451467/  1.401706, val:  71.67%, val_best:  73.33%, tr:  96.94%, tr_best:  97.34%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.444081/  1.390321, val:  70.00%, val_best:  73.33%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.440636/  1.395271, val:  70.42%, val_best:  73.33%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.438226/  1.399757, val:  72.08%, val_best:  73.33%, tr:  97.34%, tr_best:  97.45%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.429637/  1.419666, val:  70.00%, val_best:  73.33%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.429543/  1.416734, val:  70.42%, val_best:  73.33%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.421567/  1.414019, val:  71.25%, val_best:  73.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.422002/  1.427942, val:  71.25%, val_best:  73.33%, tr:  97.55%, tr_best:  97.75%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.421001/  1.434649, val:  71.25%, val_best:  73.33%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.420952/  1.429230, val:  70.42%, val_best:  73.33%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.417284/  1.431675, val:  72.08%, val_best:  73.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.409195/  1.442498, val:  71.25%, val_best:  73.33%, tr:  98.16%, tr_best:  98.47%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.407214/  1.443179, val:  72.08%, val_best:  73.33%, tr:  97.85%, tr_best:  98.47%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.402887/  1.449414, val:  70.83%, val_best:  73.33%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.402473/  1.446369, val:  71.25%, val_best:  73.33%, tr:  98.67%, tr_best:  98.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54855a4cba9e4b1eb9101e847fe74efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▂▄▄▅▆▃▄▅▆▆▆▆▆▇█▇▇▇▇▇▆▇██▇██▇█▇▆▇█▇███▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇███████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇███████████████████</td></tr><tr><td>val_loss</td><td>█▆▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98672</td></tr><tr><td>tr_epoch_loss</td><td>0.40247</td></tr><tr><td>val_acc_best</td><td>0.73333</td></tr><tr><td>val_acc_now</td><td>0.7125</td></tr><tr><td>val_loss</td><td>1.44637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-274</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icqzxhel' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icqzxhel</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_094910-icqzxhel/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bzdxgjxn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_095556-bzdxgjxn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bzdxgjxn' target=\"_blank\">morning-sweep-276</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bzdxgjxn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bzdxgjxn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304984/  2.302542, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.301807/  2.289460, val:  15.00%, val_best:  15.00%, tr:   9.30%, tr_best:   9.30%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.175741/  2.092241, val:  36.25%, val_best:  36.25%, tr:  28.40%, tr_best:  28.40%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.899848/  1.879166, val:  43.75%, val_best:  43.75%, tr:  42.80%, tr_best:  42.80%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.680244/  1.772781, val:  46.67%, val_best:  46.67%, tr:  50.56%, tr_best:  50.56%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.588042/  1.722585, val:  50.42%, val_best:  50.42%, tr:  55.87%, tr_best:  55.87%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.528829/  1.686890, val:  50.42%, val_best:  50.42%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.484766/  1.686280, val:  54.17%, val_best:  54.17%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.458718/  1.657659, val:  51.67%, val_best:  54.17%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.430638/  1.646386, val:  48.75%, val_best:  54.17%, tr:  58.73%, tr_best:  59.55%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.415297/  1.622123, val:  52.08%, val_best:  54.17%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.396992/  1.625361, val:  50.83%, val_best:  54.17%, tr:  61.70%, tr_best:  61.70%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.377116/  1.613522, val:  55.00%, val_best:  55.00%, tr:  60.78%, tr_best:  61.70%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.333788/  1.636024, val:  52.92%, val_best:  55.00%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.324573/  1.589640, val:  55.42%, val_best:  55.42%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.314246/  1.578417, val:  53.33%, val_best:  55.42%, tr:  64.45%, tr_best:  64.45%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.288279/  1.549596, val:  55.00%, val_best:  55.42%, tr:  64.45%, tr_best:  64.45%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.269562/  1.583635, val:  53.33%, val_best:  55.42%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.262707/  1.589198, val:  53.33%, val_best:  55.42%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.235741/  1.555690, val:  50.83%, val_best:  55.42%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.226169/  1.547455, val:  55.83%, val_best:  55.83%, tr:  67.11%, tr_best:  67.11%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.249317/  1.556114, val:  55.00%, val_best:  55.83%, tr:  65.27%, tr_best:  67.11%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.210769/  1.530766, val:  55.83%, val_best:  55.83%, tr:  67.42%, tr_best:  67.42%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.186689/  1.552426, val:  54.58%, val_best:  55.83%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.181007/  1.540987, val:  57.08%, val_best:  57.08%, tr:  67.01%, tr_best:  68.95%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.172631/  1.515165, val:  56.67%, val_best:  57.08%, tr:  68.64%, tr_best:  68.95%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.157858/  1.556353, val:  57.92%, val_best:  57.92%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.166567/  1.524940, val:  57.08%, val_best:  57.92%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.137807/  1.548395, val:  55.83%, val_best:  57.92%, tr:  70.48%, tr_best:  71.60%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.134979/  1.542549, val:  55.00%, val_best:  57.92%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.153757/  1.569591, val:  55.42%, val_best:  57.92%, tr:  70.28%, tr_best:  73.34%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.126752/  1.546844, val:  57.50%, val_best:  57.92%, tr:  72.83%, tr_best:  73.34%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.124371/  1.581380, val:  59.58%, val_best:  59.58%, tr:  72.63%, tr_best:  73.34%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.116337/  1.576225, val:  58.75%, val_best:  59.58%, tr:  72.22%, tr_best:  73.34%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.140065/  1.588676, val:  58.75%, val_best:  59.58%, tr:  69.46%, tr_best:  73.34%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.108490/  1.580708, val:  58.33%, val_best:  59.58%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.116080/  1.565061, val:  60.42%, val_best:  60.42%, tr:  74.06%, tr_best:  74.36%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.100940/  1.569946, val:  62.50%, val_best:  62.50%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.088784/  1.588488, val:  59.58%, val_best:  62.50%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.091537/  1.617658, val:  61.25%, val_best:  62.50%, tr:  75.89%, tr_best:  77.32%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.092222/  1.618323, val:  57.92%, val_best:  62.50%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.077538/  1.600817, val:  62.50%, val_best:  62.50%, tr:  76.10%, tr_best:  78.65%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.063262/  1.651207, val:  62.08%, val_best:  62.50%, tr:  78.04%, tr_best:  78.65%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.056551/  1.634426, val:  64.58%, val_best:  64.58%, tr:  77.83%, tr_best:  78.65%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.062104/  1.623782, val:  65.00%, val_best:  65.00%, tr:  78.55%, tr_best:  78.65%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.053984/  1.685676, val:  62.92%, val_best:  65.00%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.051328/  1.669589, val:  63.33%, val_best:  65.00%, tr:  81.00%, tr_best:  81.31%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.060515/  1.642223, val:  62.92%, val_best:  65.00%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.061377/  1.651443, val:  64.17%, val_best:  65.00%, tr:  79.57%, tr_best:  81.51%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.055183/  1.695929, val:  63.33%, val_best:  65.00%, tr:  80.90%, tr_best:  81.51%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.058530/  1.710351, val:  65.00%, val_best:  65.00%, tr:  80.49%, tr_best:  81.51%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.037702/  1.778687, val:  62.92%, val_best:  65.00%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.044626/  1.709212, val:  64.17%, val_best:  65.00%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.022717/  1.757843, val:  62.50%, val_best:  65.00%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.027789/  1.759550, val:  63.33%, val_best:  65.00%, tr:  82.43%, tr_best:  84.68%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.016804/  1.833141, val:  62.92%, val_best:  65.00%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.027920/  1.791076, val:  60.83%, val_best:  65.00%, tr:  83.55%, tr_best:  84.78%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.018172/  1.835589, val:  63.33%, val_best:  65.00%, tr:  84.17%, tr_best:  84.78%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.025910/  1.802442, val:  65.42%, val_best:  65.42%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.025687/  1.793814, val:  65.42%, val_best:  65.42%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.023244/  1.853149, val:  63.75%, val_best:  65.42%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.030384/  1.856566, val:  63.33%, val_best:  65.42%, tr:  85.39%, tr_best:  86.11%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.033834/  1.831769, val:  65.00%, val_best:  65.42%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.025349/  1.924195, val:  64.58%, val_best:  65.42%, tr:  85.29%, tr_best:  86.62%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.029448/  1.902651, val:  65.83%, val_best:  65.83%, tr:  84.88%, tr_best:  86.62%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.020403/  1.884287, val:  67.08%, val_best:  67.08%, tr:  86.41%, tr_best:  86.62%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.045324/  1.895043, val:  64.58%, val_best:  67.08%, tr:  86.52%, tr_best:  86.62%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.007166/  1.934359, val:  65.42%, val_best:  67.08%, tr:  86.21%, tr_best:  86.62%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.025249/  1.905017, val:  64.58%, val_best:  67.08%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.025693/  1.923333, val:  65.00%, val_best:  67.08%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.013843/  1.974247, val:  65.83%, val_best:  67.08%, tr:  87.23%, tr_best:  87.95%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.010289/  2.002821, val:  64.17%, val_best:  67.08%, tr:  87.74%, tr_best:  87.95%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.034054/  1.972192, val:  68.75%, val_best:  68.75%, tr:  87.33%, tr_best:  87.95%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.024801/  1.958319, val:  68.33%, val_best:  68.75%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.027100/  1.988202, val:  67.08%, val_best:  68.75%, tr:  87.64%, tr_best:  88.56%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.017698/  2.040088, val:  66.67%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.038667/  2.048507, val:  66.67%, val_best:  68.75%, tr:  88.36%, tr_best:  88.76%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.032459/  2.013379, val:  65.42%, val_best:  68.75%, tr:  87.13%, tr_best:  88.76%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.017353/  2.050128, val:  67.50%, val_best:  68.75%, tr:  88.56%, tr_best:  88.76%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.003445/  2.090027, val:  67.50%, val_best:  68.75%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.023870/  2.040602, val:  69.58%, val_best:  69.58%, tr:  88.36%, tr_best:  89.07%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.024078/  2.096702, val:  67.50%, val_best:  69.58%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.013467/  2.099638, val:  67.08%, val_best:  69.58%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.018691/  2.124816, val:  67.08%, val_best:  69.58%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.015100/  2.145598, val:  68.33%, val_best:  69.58%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.033675/  2.143863, val:  70.00%, val_best:  70.00%, tr:  89.79%, tr_best:  91.11%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.014908/  2.186161, val:  66.67%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.008612/  2.184294, val:  67.92%, val_best:  70.00%, tr:  91.01%, tr_best:  91.73%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.990348/  2.249678, val:  66.67%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.007162/  2.169208, val:  67.50%, val_best:  70.00%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.004619/  2.210513, val:  65.83%, val_best:  70.00%, tr:  91.73%, tr_best:  92.13%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.005943/  2.300921, val:  67.08%, val_best:  70.00%, tr:  90.81%, tr_best:  92.13%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.031422/  2.295119, val:  65.42%, val_best:  70.00%, tr:  91.73%, tr_best:  92.13%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.019678/  2.357552, val:  65.42%, val_best:  70.00%, tr:  91.93%, tr_best:  92.13%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.017827/  2.336990, val:  70.00%, val_best:  70.00%, tr:  91.01%, tr_best:  92.13%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.020276/  2.374606, val:  69.17%, val_best:  70.00%, tr:  91.22%, tr_best:  92.13%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.037207/  2.363904, val:  67.92%, val_best:  70.00%, tr:  90.19%, tr_best:  92.13%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.013337/  2.383400, val:  67.08%, val_best:  70.00%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.038410/  2.416487, val:  67.92%, val_best:  70.00%, tr:  91.42%, tr_best:  92.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28735c336420458b9c53a78db084d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▂▅▃▅▆▃▅▆▄█▆▅▆▇█▇▇▇▆█▅▇██▇▇█▆██▆██▇█▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██████████</td></tr><tr><td>tr_acc</td><td>▁▁▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██████████</td></tr><tr><td>val_loss</td><td>▇▇▄▂▂▂▂▁▂▁▁▁▁▁▂▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.9142</td></tr><tr><td>tr_epoch_loss</td><td>1.03841</td></tr><tr><td>val_acc_best</td><td>0.7</td></tr><tr><td>val_acc_now</td><td>0.67917</td></tr><tr><td>val_loss</td><td>2.41649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-276</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bzdxgjxn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bzdxgjxn</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_095556-bzdxgjxn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kdegt4a0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca3bf6ea4ce4ab389f66f9048ea87e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113391899400287, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_100258-kdegt4a0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kdegt4a0' target=\"_blank\">warm-sweep-278</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kdegt4a0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kdegt4a0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.266704/  4.001255, val:  44.58%, val_best:  44.58%, tr:  38.82%, tr_best:  38.82%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.017327/  5.052432, val:  48.33%, val_best:  48.33%, tr:  49.64%, tr_best:  49.64%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  4.538775/  6.458039, val:  46.25%, val_best:  48.33%, tr:  53.52%, tr_best:  53.52%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  3.608266/  4.491246, val:  46.25%, val_best:  48.33%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  3.485008/  3.423576, val:  57.50%, val_best:  57.50%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.742605/  6.722138, val:  46.25%, val_best:  57.50%, tr:  58.73%, tr_best:  61.80%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  3.261400/  4.857804, val:  59.58%, val_best:  59.58%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  3.876178/ 11.551793, val:  33.75%, val_best:  59.58%, tr:  61.70%, tr_best:  63.13%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  4.679958/  4.542853, val:  57.50%, val_best:  59.58%, tr:  61.18%, tr_best:  63.13%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  4.522553/ 10.057282, val:  45.83%, val_best:  59.58%, tr:  62.61%, tr_best:  63.13%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  5.269765/  5.649603, val:  58.75%, val_best:  59.58%, tr:  62.31%, tr_best:  63.13%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  4.222803/ 10.147297, val:  41.25%, val_best:  59.58%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  4.391339/  5.832880, val:  50.00%, val_best:  59.58%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  4.748509/  9.557524, val:  48.33%, val_best:  59.58%, tr:  66.50%, tr_best:  69.46%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  3.860688/  5.568928, val:  59.17%, val_best:  59.58%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  2.967992/  6.621643, val:  52.50%, val_best:  59.58%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  3.831720/  8.112243, val:  55.42%, val_best:  59.58%, tr:  73.85%, tr_best:  76.40%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  3.397060/  8.760357, val:  54.17%, val_best:  59.58%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  4.018588/  7.896219, val:  57.92%, val_best:  59.58%, tr:  75.59%, tr_best:  76.61%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  2.698782/  6.277733, val:  55.42%, val_best:  59.58%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  2.611003/  6.969414, val:  57.08%, val_best:  59.58%, tr:  82.53%, tr_best:  82.64%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  2.769577/  7.210834, val:  56.25%, val_best:  59.58%, tr:  82.12%, tr_best:  82.64%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  2.932908/  7.342147, val:  55.00%, val_best:  59.58%, tr:  82.23%, tr_best:  82.64%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  3.010837/  6.956712, val:  65.00%, val_best:  65.00%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  2.979462/  8.714815, val:  59.58%, val_best:  65.00%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  2.661945/  7.912468, val:  60.83%, val_best:  65.00%, tr:  85.09%, tr_best:  85.09%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  3.503094/ 10.324692, val:  55.83%, val_best:  65.00%, tr:  81.72%, tr_best:  85.09%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  3.162741/  9.510179, val:  59.58%, val_best:  65.00%, tr:  84.37%, tr_best:  85.09%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  3.230182/  7.917077, val:  67.50%, val_best:  67.50%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  2.293604/  8.532235, val:  61.67%, val_best:  67.50%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  2.680141/  8.302860, val:  68.33%, val_best:  68.33%, tr:  90.81%, tr_best:  92.75%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  2.226172/  9.950930, val:  58.75%, val_best:  68.33%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  3.470644/ 10.597169, val:  60.42%, val_best:  68.33%, tr:  85.60%, tr_best:  94.69%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  3.544769/  9.016484, val:  69.58%, val_best:  69.58%, tr:  85.39%, tr_best:  94.69%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  4.017544/  9.398105, val:  69.17%, val_best:  69.58%, tr:  86.01%, tr_best:  94.69%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  2.224288/  9.917053, val:  67.92%, val_best:  69.58%, tr:  94.59%, tr_best:  94.69%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  1.989296/  8.747776, val:  72.50%, val_best:  72.50%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  3.313784/ 10.609116, val:  66.25%, val_best:  72.50%, tr:  90.60%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  2.254483/ 10.729080, val:  63.75%, val_best:  72.50%, tr:  94.79%, tr_best:  96.53%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  2.228902/  9.335532, val:  72.50%, val_best:  72.50%, tr:  95.71%, tr_best:  96.53%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  1.981429/ 11.479642, val:  65.00%, val_best:  72.50%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  2.577973/ 10.376537, val:  68.33%, val_best:  72.50%, tr:  93.26%, tr_best:  96.53%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  2.190448/ 10.836289, val:  64.58%, val_best:  72.50%, tr:  95.30%, tr_best:  96.53%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  2.401412/ 11.273045, val:  64.17%, val_best:  72.50%, tr:  95.10%, tr_best:  96.53%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  2.513961/ 11.678286, val:  64.17%, val_best:  72.50%, tr:  92.34%, tr_best:  96.53%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  2.153162/ 10.504354, val:  73.75%, val_best:  73.75%, tr:  96.32%, tr_best:  96.53%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  2.209268/ 11.863584, val:  66.25%, val_best:  73.75%, tr:  95.30%, tr_best:  96.53%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  2.156986/ 11.412278, val:  70.83%, val_best:  73.75%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  2.299986/ 11.186337, val:  70.00%, val_best:  73.75%, tr:  95.61%, tr_best:  97.24%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  1.855132/ 10.873833, val:  72.08%, val_best:  73.75%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  1.892005/ 12.289576, val:  64.58%, val_best:  73.75%, tr:  97.65%, tr_best:  98.16%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  1.880628/ 12.550871, val:  68.33%, val_best:  73.75%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  2.153861/ 12.105399, val:  69.17%, val_best:  73.75%, tr:  96.53%, tr_best:  98.37%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  1.990365/ 11.995812, val:  69.17%, val_best:  73.75%, tr:  97.45%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  2.010362/ 12.638893, val:  67.92%, val_best:  73.75%, tr:  97.96%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  2.147582/ 13.397220, val:  65.42%, val_best:  73.75%, tr:  97.55%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  1.682378/ 13.052221, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  2.014869/ 13.336113, val:  69.17%, val_best:  73.75%, tr:  97.85%, tr_best:  99.28%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  1.971669/ 12.998545, val:  72.92%, val_best:  73.75%, tr:  96.83%, tr_best:  99.28%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  1.803738/ 13.323996, val:  71.67%, val_best:  73.75%, tr:  98.67%, tr_best:  99.28%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  1.705339/ 14.270063, val:  66.25%, val_best:  73.75%, tr:  98.88%, tr_best:  99.28%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  2.124750/ 13.730031, val:  70.83%, val_best:  73.75%, tr:  97.55%, tr_best:  99.28%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  1.966944/ 13.570789, val:  68.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.28%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  1.673325/ 13.890814, val:  70.00%, val_best:  73.75%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  1.738249/ 15.155579, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  1.987034/ 14.278414, val:  71.67%, val_best:  73.75%, tr:  97.04%, tr_best:  99.28%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  1.527714/ 14.155625, val:  70.83%, val_best:  73.75%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  1.780487/ 14.549748, val:  71.67%, val_best:  73.75%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  1.695564/ 14.494345, val:  72.50%, val_best:  73.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  1.481129/ 14.934054, val:  70.00%, val_best:  73.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  1.437507/ 14.600348, val:  72.92%, val_best:  73.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  1.652606/ 14.872039, val:  72.92%, val_best:  73.75%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  1.703502/ 15.799743, val:  68.33%, val_best:  73.75%, tr:  98.57%, tr_best:  99.69%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  1.686193/ 15.486025, val:  71.67%, val_best:  73.75%, tr:  98.47%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  1.635712/ 15.148136, val:  72.08%, val_best:  73.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  1.496146/ 15.317532, val:  75.42%, val_best:  75.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  1.505322/ 15.910439, val:  70.42%, val_best:  75.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  1.623882/ 15.808568, val:  74.17%, val_best:  75.42%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  2.083889/ 17.953190, val:  71.67%, val_best:  75.42%, tr:  97.45%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  1.600910/ 16.630701, val:  70.83%, val_best:  75.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  1.440893/ 16.834806, val:  69.58%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  1.642953/ 16.814892, val:  71.25%, val_best:  75.42%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  1.694113/ 17.637657, val:  69.17%, val_best:  75.42%, tr:  98.57%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  1.791222/ 18.031000, val:  70.83%, val_best:  75.42%, tr:  98.37%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  1.515104/ 17.380629, val:  67.08%, val_best:  75.42%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  1.562432/ 17.117083, val:  71.67%, val_best:  75.42%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  1.637555/ 17.986252, val:  67.92%, val_best:  75.42%, tr:  98.57%, tr_best:  99.69%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  1.426297/ 16.914232, val:  72.08%, val_best:  75.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  1.334471/ 18.842405, val:  65.83%, val_best:  75.42%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  1.338108/ 17.317417, val:  72.50%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  1.257049/ 18.362997, val:  70.42%, val_best:  75.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  1.319416/ 18.180986, val:  70.42%, val_best:  75.42%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  1.339180/ 18.183817, val:  71.67%, val_best:  75.42%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  1.213713/ 18.263901, val:  70.00%, val_best:  75.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  1.186795/ 18.438301, val:  73.33%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  1.657526/ 18.643818, val:  70.00%, val_best:  75.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  1.320250/ 19.798775, val:  69.58%, val_best:  75.42%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  1.306133/ 19.091415, val:  70.42%, val_best:  75.42%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  1.204281/ 18.946693, val:  69.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  1.390991/ 19.473606, val:  71.25%, val_best:  75.42%, tr:  99.59%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debca0c993f54ea19770dce050db385b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▂▄▂▆▆▅▅█▇▇▅███▇▇▇██▇█████████████████</td></tr><tr><td>summary_val_acc</td><td>▃▃▅▁▃▄▅▄▅▅▅▅▆▅▇▆█▆▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇█▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▄▅▅▅▆▆▆▆▇▆▇▇█▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▃█▆▇██▇▆▄▄▅▆▃▆▃▅▃▃▄▃▂▃▃▃▂▃▂▂▁▂▁▂▂▂▁▁▁▁▂▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▄▄▄▄▄▄▆▆▆▆▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▃▃▅▁▃▄▅▄▅▅▅▅▆▅▇▆█▆▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>▁▂▁▅▄▂▂▃▂▃▃▄▃▄▄▄▄▄▅▅▄▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99591</td></tr><tr><td>tr_epoch_loss</td><td>1.39099</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.7125</td></tr><tr><td>val_loss</td><td>19.47361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-sweep-278</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kdegt4a0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kdegt4a0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_100258-kdegt4a0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u6ags5b9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2bd244c1fc4670a8d99f3869e2914a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113078819794788, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_101015-u6ags5b9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6ags5b9' target=\"_blank\">classic-sweep-280</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6ags5b9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6ags5b9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.259325/  2.166692, val:  25.42%, val_best:  25.42%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.951459/  1.832348, val:  47.92%, val_best:  47.92%, tr:  37.90%, tr_best:  37.90%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.623138/  1.666077, val:  55.42%, val_best:  55.42%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.460078/  1.635147, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.385512/  1.555451, val:  60.42%, val_best:  60.42%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.316895/  1.531080, val:  59.58%, val_best:  60.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.249793/  1.511024, val:  59.58%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.203278/  1.482369, val:  61.67%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.161125/  1.456793, val:  65.83%, val_best:  65.83%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.130679/  1.528863, val:  60.00%, val_best:  65.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.108387/  1.563280, val:  55.00%, val_best:  65.83%, tr:  68.95%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054601/  1.435886, val:  68.33%, val_best:  68.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.048901/  1.472334, val:  59.17%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.017672/  1.569106, val:  62.50%, val_best:  68.33%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.974325/  1.656879, val:  59.58%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980752/  1.572125, val:  60.83%, val_best:  68.33%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.983020/  1.537963, val:  64.58%, val_best:  68.33%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.914581/  1.668934, val:  62.08%, val_best:  68.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.931618/  1.708934, val:  62.50%, val_best:  68.33%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.924997/  1.702797, val:  65.42%, val_best:  68.33%, tr:  77.83%, tr_best:  78.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.895528/  1.803627, val:  62.08%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.870973/  1.802069, val:  61.25%, val_best:  68.33%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.875475/  1.817097, val:  62.50%, val_best:  68.33%, tr:  80.08%, tr_best:  82.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.852028/  1.992823, val:  60.00%, val_best:  68.33%, tr:  82.02%, tr_best:  82.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.817858/  1.996159, val:  59.58%, val_best:  68.33%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.836069/  1.881631, val:  67.50%, val_best:  68.33%, tr:  83.76%, tr_best:  84.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.846120/  1.998041, val:  70.00%, val_best:  70.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.806404/  2.054228, val:  62.92%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.791962/  2.007748, val:  68.75%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.819494/  2.359427, val:  60.42%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.782672/  2.213522, val:  62.08%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.785682/  2.318455, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  87.74%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.812352/  2.263149, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.814710/  2.259653, val:  67.92%, val_best:  70.00%, tr:  87.54%, tr_best:  87.74%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.742937/  2.467701, val:  60.42%, val_best:  70.00%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.757479/  2.534710, val:  59.58%, val_best:  70.00%, tr:  86.21%, tr_best:  88.46%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.681546/  2.297895, val:  67.50%, val_best:  70.00%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.701446/  2.512144, val:  63.75%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.710612/  2.657074, val:  65.00%, val_best:  70.00%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.657503/  2.521472, val:  63.75%, val_best:  70.00%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.682582/  2.741191, val:  62.92%, val_best:  70.00%, tr:  91.32%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.655606/  2.770979, val:  59.17%, val_best:  70.00%, tr:  93.05%, tr_best:  93.26%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.632359/  2.721785, val:  67.08%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.633759/  2.736447, val:  65.00%, val_best:  70.00%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.632607/  2.656749, val:  67.92%, val_best:  70.00%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.615663/  2.725739, val:  68.75%, val_best:  70.00%, tr:  94.79%, tr_best:  94.99%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594888/  2.853819, val:  66.25%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.578222/  3.049881, val:  65.42%, val_best:  70.00%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.607904/  2.996387, val:  67.92%, val_best:  70.00%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.567040/  3.018704, val:  69.58%, val_best:  70.00%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.532360/  3.186153, val:  66.25%, val_best:  70.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.575075/  3.053903, val:  67.08%, val_best:  70.00%, tr:  94.18%, tr_best:  97.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.514349/  3.110004, val:  67.08%, val_best:  70.00%, tr:  96.83%, tr_best:  97.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.518154/  3.457839, val:  65.83%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.505677/  3.216293, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.527777/  3.308029, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.491510/  3.531652, val:  64.17%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.559684/  3.381672, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.539413/  3.329102, val:  67.08%, val_best:  70.00%, tr:  94.48%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.516434/  3.457018, val:  70.83%, val_best:  70.83%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.485153/  3.732556, val:  64.17%, val_best:  70.83%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.535130/  3.417022, val:  71.25%, val_best:  71.25%, tr:  96.83%, tr_best:  98.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.446230/  3.361158, val:  69.17%, val_best:  71.25%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.424834/  3.410936, val:  73.75%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.435740/  3.347567, val:  71.67%, val_best:  73.75%, tr:  97.65%, tr_best:  98.88%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.381304/  3.313588, val:  71.25%, val_best:  73.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.393611/  3.409695, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.414356/  3.359644, val:  73.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.412061/  3.412950, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.420847/  3.498824, val:  72.08%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.378566/  3.353256, val:  71.25%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.437227/  3.585583, val:  72.50%, val_best:  73.75%, tr:  98.06%, tr_best:  99.49%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.419239/  3.353722, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.389243/  3.548229, val:  67.92%, val_best:  73.75%, tr:  98.37%, tr_best:  99.49%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.355405/  3.541240, val:  72.92%, val_best:  73.75%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.352597/  3.526462, val:  70.42%, val_best:  73.75%, tr:  98.47%, tr_best:  99.49%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.337224/  3.475421, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.360251/  3.710256, val:  69.58%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.380566/  3.617064, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.325451/  3.572766, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.308370/  3.665858, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.266245/  3.580417, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.278189/  3.626280, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.352835/  3.735754, val:  70.83%, val_best:  73.75%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.314501/  3.713542, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.353990/  3.794341, val:  70.42%, val_best:  73.75%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.290747/  3.757254, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.318437/  3.547390, val:  72.50%, val_best:  73.75%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.290242/  3.610040, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.257004/  3.746444, val:  73.75%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.253982/  3.726433, val:  70.83%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.232963/  3.734505, val:  72.08%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.194844/  3.748441, val:  72.50%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.219133/  3.755011, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.205211/  3.758615, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.236082/  3.739775, val:  73.33%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.224297/  3.839006, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.232116/  3.776063, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.197325/  3.764912, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.181913/  3.835845, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbc64e4b53741e69ec81db0b4cade17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▄▅▇▁▄▇█▆█▇▇▇█▆█▇███████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.18191</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.83585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-280</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6ags5b9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u6ags5b9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_101015-u6ags5b9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u9to705s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d317c7747b7b41eeb9b1e13d82e27eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113379388633701, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_101656-u9to705s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u9to705s' target=\"_blank\">trim-sweep-282</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u9to705s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u9to705s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.225008/  2.061628, val:  32.50%, val_best:  32.50%, tr:  18.79%, tr_best:  18.79%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.742177/  1.642808, val:  51.67%, val_best:  51.67%, tr:  47.80%, tr_best:  47.80%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.414673/  1.482957, val:  58.75%, val_best:  58.75%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.256586/  1.430187, val:  57.92%, val_best:  58.75%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.173905/  1.354171, val:  59.17%, val_best:  59.17%, tr:  64.25%, tr_best:  64.35%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.093850/  1.306460, val:  59.58%, val_best:  59.58%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.022667/  1.276226, val:  60.00%, val_best:  60.00%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.978792/  1.249010, val:  62.92%, val_best:  62.92%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.925068/  1.213356, val:  66.67%, val_best:  66.67%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.895877/  1.206226, val:  64.58%, val_best:  66.67%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.869339/  1.232593, val:  58.33%, val_best:  66.67%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.833617/  1.156173, val:  67.08%, val_best:  67.08%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.815570/  1.159171, val:  65.42%, val_best:  67.08%, tr:  76.51%, tr_best:  76.51%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.783349/  1.157072, val:  64.58%, val_best:  67.08%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.739906/  1.214747, val:  62.50%, val_best:  67.08%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.725399/  1.184040, val:  65.83%, val_best:  67.08%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.731916/  1.128919, val:  67.92%, val_best:  67.92%, tr:  78.75%, tr_best:  81.10%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.676834/  1.126190, val:  70.83%, val_best:  70.83%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.658328/  1.193499, val:  64.17%, val_best:  70.83%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.648549/  1.193997, val:  66.25%, val_best:  70.83%, tr:  81.72%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.614639/  1.133336, val:  69.58%, val_best:  70.83%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.596076/  1.173818, val:  69.58%, val_best:  70.83%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.604594/  1.199674, val:  70.00%, val_best:  70.83%, tr:  84.78%, tr_best:  88.87%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.577314/  1.196597, val:  67.92%, val_best:  70.83%, tr:  88.25%, tr_best:  88.87%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.546249/  1.201059, val:  69.58%, val_best:  70.83%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.531000/  1.207027, val:  70.42%, val_best:  70.83%, tr:  88.97%, tr_best:  89.79%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.516354/  1.205359, val:  72.50%, val_best:  72.50%, tr:  89.17%, tr_best:  89.79%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.492594/  1.250916, val:  70.00%, val_best:  72.50%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.491804/  1.230684, val:  73.75%, val_best:  73.75%, tr:  92.34%, tr_best:  92.85%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.463334/  1.323817, val:  67.08%, val_best:  73.75%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.435513/  1.302707, val:  71.25%, val_best:  73.75%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.442146/  1.297600, val:  70.83%, val_best:  73.75%, tr:  93.16%, tr_best:  94.48%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.438742/  1.307105, val:  72.50%, val_best:  73.75%, tr:  93.67%, tr_best:  94.48%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.429002/  1.322077, val:  70.42%, val_best:  73.75%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.404508/  1.365270, val:  70.83%, val_best:  73.75%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.415794/  1.428111, val:  69.58%, val_best:  73.75%, tr:  93.77%, tr_best:  96.02%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.382693/  1.314622, val:  74.17%, val_best:  74.17%, tr:  95.91%, tr_best:  96.02%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.358404/  1.398728, val:  70.42%, val_best:  74.17%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.351872/  1.409188, val:  69.17%, val_best:  74.17%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.338411/  1.374449, val:  70.83%, val_best:  74.17%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.333973/  1.413689, val:  71.67%, val_best:  74.17%, tr:  97.14%, tr_best:  98.57%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.321533/  1.443361, val:  71.25%, val_best:  74.17%, tr:  97.96%, tr_best:  98.57%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.309437/  1.430500, val:  73.75%, val_best:  74.17%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.290729/  1.466098, val:  70.83%, val_best:  74.17%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.287849/  1.489512, val:  70.42%, val_best:  74.17%, tr:  98.47%, tr_best:  98.88%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.273282/  1.474451, val:  72.50%, val_best:  74.17%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.269727/  1.474841, val:  75.42%, val_best:  75.42%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.247768/  1.512185, val:  73.33%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.249862/  1.471660, val:  75.00%, val_best:  75.42%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.236545/  1.523215, val:  74.58%, val_best:  75.42%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.229200/  1.569832, val:  71.67%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.247485/  1.542523, val:  72.50%, val_best:  75.42%, tr:  98.47%, tr_best:  99.69%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.207070/  1.567691, val:  74.17%, val_best:  75.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.207362/  1.616978, val:  71.25%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.205603/  1.556761, val:  75.00%, val_best:  75.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.191522/  1.654293, val:  73.33%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.190568/  1.664068, val:  75.00%, val_best:  75.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.185981/  1.595482, val:  74.17%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.189077/  1.680074, val:  72.50%, val_best:  75.42%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.174976/  1.669021, val:  74.17%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.172148/  1.658600, val:  73.75%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.164461/  1.665886, val:  75.83%, val_best:  75.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.163476/  1.685649, val:  74.17%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.152500/  1.696279, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.146771/  1.713285, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.147780/  1.697965, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.143443/  1.726117, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.143793/  1.749628, val:  74.58%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.139429/  1.808198, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.132723/  1.789543, val:  71.25%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.129045/  1.801112, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.129092/  1.809102, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.119751/  1.859180, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.119355/  1.828580, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.121109/  1.851680, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.111190/  1.897917, val:  71.25%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.104873/  1.865433, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.104803/  1.879669, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.104413/  1.891502, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.094219/  1.885059, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.095595/  1.942579, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.095685/  1.896157, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.093661/  1.927576, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.100550/  1.967762, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.093006/  1.962427, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.090703/  1.982812, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.086038/  2.027785, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.094605/  1.973067, val:  77.92%, val_best:  77.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.078503/  1.981794, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.073087/  1.994672, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.071776/  1.991911, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.078624/  2.043368, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.071367/  2.001678, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.072229/  2.022643, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.064670/  2.109625, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.065263/  2.101840, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.064128/  2.111934, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.067915/  2.083738, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.057432/  2.108721, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.057489/  2.143454, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed835294b0d4c53b22273a7e5efe3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▆▃▅▃▅▇▁▅███▇▇▇██▇██████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██▇█████</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▇▆▇▇▇█▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██▇█████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▇▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.05749</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>2.14345</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sweep-282</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u9to705s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u9to705s</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_101656-u9to705s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p3e525fp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_102320-p3e525fp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p3e525fp' target=\"_blank\">sandy-sweep-284</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p3e525fp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p3e525fp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '1', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302733, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302753, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303003/  2.302711, val:  10.42%, val_best:  10.42%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302609/  2.302531, val:  10.83%, val_best:  10.83%, tr:  10.73%, tr_best:  10.73%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302553/  2.302428, val:  11.25%, val_best:  11.25%, tr:  11.44%, tr_best:  11.44%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.302353/  2.302140, val:  11.25%, val_best:  11.25%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.301510/  2.301367, val:  10.00%, val_best:  11.25%, tr:  13.07%, tr_best:  13.07%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.300422/  2.300640, val:  12.50%, val_best:  12.50%, tr:  12.97%, tr_best:  13.07%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.298781/  2.299399, val:  12.08%, val_best:  12.50%, tr:  13.38%, tr_best:  13.38%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.296100/  2.296855, val:  13.33%, val_best:  13.33%, tr:  13.28%, tr_best:  13.38%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.291113/  2.292578, val:  15.00%, val_best:  15.00%, tr:  14.20%, tr_best:  14.20%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.285335/  2.285974, val:  13.75%, val_best:  15.00%, tr:  13.38%, tr_best:  14.20%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.276087/  2.277460, val:  14.17%, val_best:  15.00%, tr:  13.28%, tr_best:  14.20%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.261826/  2.264483, val:  17.50%, val_best:  17.50%, tr:  15.12%, tr_best:  15.12%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.244597/  2.248030, val:  16.25%, val_best:  17.50%, tr:  16.34%, tr_best:  16.34%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.221111/  2.227574, val:  16.25%, val_best:  17.50%, tr:  19.31%, tr_best:  19.31%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.193615/  2.202354, val:  27.50%, val_best:  27.50%, tr:  22.27%, tr_best:  22.27%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.159574/  2.176171, val:  29.58%, val_best:  29.58%, tr:  29.83%, tr_best:  29.83%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.127591/  2.148782, val:  30.00%, val_best:  30.00%, tr:  31.05%, tr_best:  31.05%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.095743/  2.121776, val:  29.58%, val_best:  30.00%, tr:  33.71%, tr_best:  33.71%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.060196/  2.095060, val:  32.08%, val_best:  32.08%, tr:  36.98%, tr_best:  36.98%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.029568/  2.067292, val:  37.50%, val_best:  37.50%, tr:  37.59%, tr_best:  37.59%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.992993/  2.037751, val:  39.17%, val_best:  39.17%, tr:  42.49%, tr_best:  42.49%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.957014/  2.009418, val:  42.50%, val_best:  42.50%, tr:  42.39%, tr_best:  42.49%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.925720/  1.981997, val:  45.00%, val_best:  45.00%, tr:  45.76%, tr_best:  45.76%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.897392/  1.955970, val:  47.50%, val_best:  47.50%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.856965/  1.933336, val:  46.67%, val_best:  47.50%, tr:  49.95%, tr_best:  49.95%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.830889/  1.911557, val:  46.67%, val_best:  47.50%, tr:  51.69%, tr_best:  51.69%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.805258/  1.894116, val:  46.25%, val_best:  47.50%, tr:  51.48%, tr_best:  51.69%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.780056/  1.875737, val:  45.00%, val_best:  47.50%, tr:  52.60%, tr_best:  52.60%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.763628/  1.856167, val:  47.08%, val_best:  47.50%, tr:  53.42%, tr_best:  53.42%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.739392/  1.842616, val:  46.67%, val_best:  47.50%, tr:  54.24%, tr_best:  54.24%\n"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "        \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "        \"epoch_num\": {\"values\": [100]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [True]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [True]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [True]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"1\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  unique_name_hyper,\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "                        ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = '6pj3lh8j'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
