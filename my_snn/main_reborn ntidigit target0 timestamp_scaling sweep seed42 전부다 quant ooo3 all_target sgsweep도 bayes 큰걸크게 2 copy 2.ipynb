{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9901/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAIhCAYAAACfVbSSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA78ElEQVR4nO3deXhU5d3/8c8kmAlLEtaEICHEpTUSMZi4sPngQloKiHWBorIIWDAsshQhD1YUKhFUpBVBkU1kMVJAUCmaahWsIDGyuBYVJEGJEUQCCAmZOb8/KPk9QwIy48x9mJn367rOdTV3zpzzTarw9XPf5z4Oy7IsAQAAIOAi7C4AAAAgXNB4AQAAGELjBQAAYAiNFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBPli4cKEcDkfVUatWLSUmJuoPf/iDvvjiC9vqeuihh+RwOGy7/6kKCws1dOhQXXbZZYqJiVFCQoJuvPFGvfXWW9XO7d+/v8fvtG7dumrZsqVuuukmLViwQOXl5V7ff/To0XI4HOrWrZs/fhwA+MVovIBfYMGCBdq4caP++c9/atiwYVqzZo06dOigAwcO2F3aOWHZsmXavHmzBgwYoNWrV2vu3LlyOp264YYbtGjRomrn165dWxs3btTGjRv16quvatKkSapbt67uueceZWRkaM+ePWd97+PHj2vx4sWSpHXr1umbb77x288FAD6zAHhtwYIFliSroKDAY/zhhx+2JFnz58+3pa6JEyda59K/1t999121scrKSqt169bWhRde6DHer18/q27dujVe5/XXX7fOO+886+qrrz7rey9fvtySZHXt2tWSZD3yyCNn9bmKigrr+PHjNX7vyJEjZ31/AKgJiRfgR5mZmZKk7777rmrs2LFjGjNmjNLT0xUXF6eGDRuqbdu2Wr16dbXPOxwODRs2TC+88IJSU1NVp04dXX755Xr11Vernfvaa68pPT1dTqdTKSkpevzxx2us6dixY8rJyVFKSoqioqJ0/vnna+jQofrxxx89zmvZsqW6deumV199VW3atFHt2rWVmppade+FCxcqNTVVdevW1VVXXaUPPvjgZ38f8fHx1cYiIyOVkZGh4uLin/38SVlZWbrnnnv0/vvva/369Wf1mXnz5ikqKkoLFixQUlKSFixYIMuyPM55++235XA49MILL2jMmDE6//zz5XQ69eWXX6p///6qV6+ePvroI2VlZSkmJkY33HCDJCk/P189evRQ8+bNFR0drYsuukiDBw/Wvn37qq69YcMGORwOLVu2rFptixYtksPhUEFBwVn/DgCEBhovwI927dolSfrVr35VNVZeXq4ffvhBf/rTn/Tyyy9r2bJl6tChg2655ZYap9tee+01zZw5U5MmTdKKFSvUsGFD/f73v9fOnTurznnzzTfVo0cPxcTE6MUXX9Rjjz2ml156SQsWLPC4lmVZuvnmm/X444+rT58+eu211zR69Gg9//zzuv7666utm9q2bZtycnI0btw4rVy5UnFxcbrllls0ceJEzZ07V1OmTNGSJUt08OBBdevWTUePHvX6d1RZWakNGzaoVatWXn3upptukqSzarz27NmjN954Qz169FCTJk3Ur18/ffnll6f9bE5OjoqKivTMM8/olVdeqWoYKyoqdNNNN+n666/X6tWr9fDDD0uSvvrqK7Vt21azZ8/WG2+8oQcffFDvv/++OnTooOPHj0uSOnbsqDZt2ujpp5+udr+ZM2fqyiuv1JVXXunV7wBACLA7cgOC0cmpxk2bNlnHjx+3Dh06ZK1bt85q2rSpde211552qsqyTky1HT9+3Bo4cKDVpk0bj+9JshISEqyysrKqsZKSEisiIsLKzc2tGrv66qutZs2aWUePHq0aKysrsxo2bOgx1bhu3TpLkjVt2jSP++Tl5VmSrDlz5lSNJScnW7Vr17b27NlTNbZ161ZLkpWYmOgxzfbyyy9bkqw1a9acza/Lw4QJEyxJ1ssvv+wxfqapRsuyrM8++8ySZN17770/e49JkyZZkqx169ZZlmVZO3futBwOh9WnTx+P8/71r39Zkqxrr7222jX69et3VtPGbrfbOn78uLV7925LkrV69eqq753852TLli1VY5s3b7YkWc8///zP/hwAQg+JF/ALXHPNNTrvvPMUExOj3/72t2rQoIFWr16tWrVqeZy3fPlytW/fXvXq1VOtWrV03nnnad68efrss8+qXfO6665TTExM1dcJCQmKj4/X7t27JUlHjhxRQUGBbrnlFkVHR1edFxMTo+7du3tc6+TTg/379/cYv/3221W3bl29+eabHuPp6ek6//zzq75OTU2VJHXq1El16tSpNn6yprM1d+5cPfLIIxozZox69Ojh1WetU6YJz3TeyenFzp07S5JSUlLUqVMnrVixQmVlZdU+c+utt572ejV9r7S0VEOGDFFSUlLV/5/JycmS5PH/ae/evRUfH++Rej311FNq0qSJevXqdVY/D4DQQuMF/AKLFi1SQUGB3nrrLQ0ePFifffaZevfu7XHOypUr1bNnT51//vlavHixNm7cqIKCAg0YMEDHjh2rds1GjRpVG3M6nVXTegcOHJDb7VbTpk2rnXfq2P79+1WrVi01adLEY9zhcKhp06bav3+/x3jDhg09vo6KijrjeE31n86CBQs0ePBg/fGPf9Rjjz121p876WST16xZszOe99Zbb2nXrl26/fbbVVZWph9//FE//vijevbsqZ9++qnGNVeJiYk1XqtOnTqKjY31GHO73crKytLKlSt1//33680339TmzZu1adMmSfKYfnU6nRo8eLCWLl2qH3/8Ud9//71eeuklDRo0SE6n06ufH0BoqPXzpwA4ndTU1KoF9dddd51cLpfmzp2rv//977rtttskSYsXL1ZKSory8vI89tjyZV8qSWrQoIEcDodKSkqqfe/UsUaNGqmyslLff/+9R/NlWZZKSkqMrTFasGCBBg0apH79+umZZ57xaa+xNWvWSDqRvp3JvHnzJEnTp0/X9OnTa/z+4MGDPcZOV09N4x9//LG2bdumhQsXql+/flXjX375ZY3XuPfee/Xoo49q/vz5OnbsmCorKzVkyJAz/gwAQheJF+BH06ZNU4MGDfTggw/K7XZLOvGXd1RUlMdf4iUlJTU+1Xg2Tj5VuHLlSo/E6dChQ3rllVc8zj35FN7J/axOWrFihY4cOVL1/UBauHChBg0apLvuuktz5871qenKz8/X3Llz1a5dO3Xo0OG05x04cECrVq1S+/bt9a9//avaceedd6qgoEAff/yxzz/PyfpPTayeffbZGs9PTEzU7bffrlmzZumZZ55R9+7d1aJFC5/vDyC4kXgBftSgQQPl5OTo/vvv19KlS3XXXXepW7duWrlypbKzs3XbbbepuLhYkydPVmJios+73E+ePFm//e1v1blzZ40ZM0Yul0tTp05V3bp19cMPP1Sd17lzZ/3mN7/RuHHjVFZWpvbt22v79u2aOHGi2rRpoz59+vjrR6/R8uXLNXDgQKWnp2vw4MHavHmzx/fbtGnj0cC43e6qKbvy8nIVFRXpH//4h1566SWlpqbqpZdeOuP9lixZomPHjmnEiBE1JmONGjXSkiVLNG/ePD355JM+/UyXXHKJLrzwQo0fP16WZalhw4Z65ZVXlJ+ff9rP3Hfffbr66qslqdqTpwDCjL1r+4HgdLoNVC3Lso4ePWq1aNHCuvjii63KykrLsizr0UcftVq2bGk5nU4rNTXVeu6552rc7FSSNXTo0GrXTE5Otvr16+cxtmbNGqt169ZWVFSU1aJFC+vRRx+t8ZpHjx61xo0bZyUnJ1vnnXeelZiYaN17773WgQMHqt2ja9eu1e5dU027du2yJFmPPfbYaX9HlvX/nww83bFr167Tnlu7dm2rRYsWVvfu3a358+db5eXlZ7yXZVlWenq6FR8ff8Zzr7nmGqtx48ZWeXl51VONy5cvr7H20z1l+emnn1qdO3e2YmJirAYNGli33367VVRUZEmyJk6cWONnWrZsaaWmpv7szwAgtDks6ywfFQIA+GT79u26/PLL9fTTTys7O9vucgDYiMYLAALkq6++0u7du/W///u/Kioq0pdffumxLQeA8MPiegAIkMmTJ6tz5846fPiwli9fTtMFgMQLAADAFBIvAAAAQ2i8AAAADKHxAgAAMCSoN1B1u9369ttvFRMT49Nu2AAAhBPLsnTo0CE1a9ZMERHms5djx46poqIiINeOiopSdHR0QK7tT0HdeH377bdKSkqyuwwAAIJKcXGxmjdvbvSex44dU0pyPZWUugJy/aZNm2rXrl3nfPMV1I1XTEyMJKnZ9PGKqO38mbPPLU3fCM5ffexXh+0uwWdjF+fZXYJPIhWcDx7/bW/g3wMZKA2jjthdgk8GNn7X7hJ8klir0u4SfDb4rgF2l+CVSle5NmydXvX3p0kVFRUqKXVpd2FLxcb4N20rO+RWcsbXqqiooPEKpJPTixG1nYqofW7/ok9V67zg/NXXijxudwk+q+vnf9FNCdbG67yyKLtL8FmUMzj/Oa8XpP+Mx9QKzrolqVZkcP3dc5Kdy3PqxThUL8a/93creJYbBeff/gAAICi5LLdcfv7vSZfl9u8FAyh4/zMDAAAgyJB4AQAAY9yy5PbzEgp/Xy+QSLwAAAAMIfECAADGuOWWv1dk+f+KgUPiBQAAYAiJFwAAMMZlWXJZ/l2T5e/rBRKJFwAAgCEkXgAAwJhwf6qRxgsAABjjliVXGDdeTDUCAAAYQuIFAACMCfepRhIvAAAAQ0i8AACAMWwnAQAAACNIvAAAgDHu/x7+vmawsD3xmjVrllJSUhQdHa2MjAxt2LDB7pIAAAACwtbGKy8vTyNHjtSECRO0ZcsWdezYUV26dFFRUZGdZQEAgABx/XcfL38fwcLWxmv69OkaOHCgBg0apNTUVM2YMUNJSUmaPXu2nWUBAIAAcVmBOYKFbY1XRUWFCgsLlZWV5TGelZWl9957r8bPlJeXq6yszOMAAAAIFrY1Xvv27ZPL5VJCQoLHeEJCgkpKSmr8TG5uruLi4qqOpKQkE6UCAAA/cQfoCBa2L653OBweX1uWVW3spJycHB08eLDqKC4uNlEiAACAX9i2nUTjxo0VGRlZLd0qLS2tloKd5HQ65XQ6TZQHAAACwC2HXKo5YPkl1wwWtiVeUVFRysjIUH5+vsd4fn6+2rVrZ1NVAAAAgWPrBqqjR49Wnz59lJmZqbZt22rOnDkqKirSkCFD7CwLAAAEiNs6cfj7msHC1sarV69e2r9/vyZNmqS9e/cqLS1Na9euVXJysp1lAQAABITtrwzKzs5Wdna23WUAAAADXAFY4+Xv6wWS7Y0XAAAIH+HeeNm+nQQAAEC4IPECAADGuC2H3Jaft5Pw8/UCicQLAADAEBIvAABgDGu8AAAAYASJFwAAMMalCLn8nPu4/Hq1wCLxAgAAMITECwAAGGMF4KlGK4ieaqTxAgAAxrC4HgAAAEaQeAEAAGNcVoRclp8X11t+vVxAkXgBAAAYQuIFAACMccsht59zH7eCJ/Ii8QIAADAkJBKv2l86Fel02l2GV64Zv8nuEnzyj5evsbsEn921bojdJfjk2awFdpfgk89f+5XdJfjs38OesLsEn/zneHD+kd6/zU12l+Czo9fUtrsEr1Qet//pP55qBAAAgBHB+Z9HAAAgKAXmqcbgWeNF4wUAAIw5sbjev1OD/r5eIDHVCAAAYAiJFwAAMMatCLnYTgIAAACBRuIFAACMCffF9SReAAAAhpB4AQAAY9yK4JVBAAAACDwSLwAAYIzLcshl+fmVQX6+XiDReAEAAGNcAdhOwsVUIwAAAE5F4gUAAIxxWxFy+3k7CTfbSQAAAOBUJF4AAMAY1ngBAADACBIvAABgjFv+3/7B7derBRaJFwAAgCEkXgAAwJjAvDIoeHIkGi8AAGCMy4qQy8/bSfj7eoEUPJUCAAAEORIvAABgjFsOueXvxfXB865GEi8AAABDSLwAAIAxrPECAACAESReAADAmMC8Mih4cqTgqRQAACDIkXgBAABj3JZDbn+/MsjP1wskEi8AAABDSLwAAIAx7gCs8eKVQQAAADVwWxFy+3n7B39fL5CCp1IAAIAgR+IFAACMcckhl59f8ePv6wUSiRcAAIAhJF4AAMAY1ngBAADACBIvAABgjEv+X5Pl8uvVAovECwAAwBASLwAAYEy4r/Gi8QIAAMa4rAi5/Nwo+ft6gRQ8lQIAAAQ5Ei8AAGCMJYfcfl5cb7GBKgAAwLlt1qxZSklJUXR0tDIyMrRhw4Yznr9kyRJdfvnlqlOnjhITE3X33Xdr//79Xt2TxgsAABhzco2Xvw9v5eXlaeTIkZowYYK2bNmijh07qkuXLioqKqrx/HfffVd9+/bVwIED9cknn2j58uUqKCjQoEGDvLovjRcAAAg706dP18CBAzVo0CClpqZqxowZSkpK0uzZs2s8f9OmTWrZsqVGjBihlJQUdejQQYMHD9YHH3zg1X1DYo1Xi5e/U61Ip91leGVlywy7S/BN8+N2V+Cz1HE77C7BJ4Mj7ra7BJ98NGy63SX47Nbmbe0uwSdfPH+F3SX45OL9W+wuwWd7rr/Y7hK84j4WIa2zuQbLIbfl3zVZJ69XVlbmMe50OuV0Vu8PKioqVFhYqPHjx3uMZ2Vl6b333qvxHu3atdOECRO0du1adenSRaWlpfr73/+url27elUriRcAAAgJSUlJiouLqzpyc3NrPG/fvn1yuVxKSEjwGE9ISFBJSUmNn2nXrp2WLFmiXr16KSoqSk2bNlX9+vX11FNPeVVjSCReAAAgOLgUIZefc5+T1ysuLlZsbGzVeE1p1//lcHgmb5ZlVRs76dNPP9WIESP04IMP6je/+Y327t2rsWPHasiQIZo3b95Z10rjBQAAjAnkVGNsbKxH43U6jRs3VmRkZLV0q7S0tFoKdlJubq7at2+vsWPHSpJat26tunXrqmPHjvrLX/6ixMTEs6qVqUYAABBWoqKilJGRofz8fI/x/Px8tWvXrsbP/PTTT4qI8GybIiMjJZ1Iys4WiRcAADDGrQi5/Zz7+HK90aNHq0+fPsrMzFTbtm01Z84cFRUVaciQIZKknJwcffPNN1q0aJEkqXv37rrnnns0e/bsqqnGkSNH6qqrrlKzZs3O+r40XgAAIOz06tVL+/fv16RJk7R3716lpaVp7dq1Sk5OliTt3bvXY0+v/v3769ChQ5o5c6bGjBmj+vXr6/rrr9fUqVO9ui+NFwAAMMZlOeTy8xovX6+XnZ2t7OzsGr+3cOHCamPDhw/X8OHDfbrXSazxAgAAMITECwAAGBPIpxqDAYkXAACAISReAADAGMuKkNuHl1r/3DWDBY0XAAAwxiWHXPLz4no/Xy+QgqdFBAAACHIkXgAAwBi35f/F8O6z3zjediReAAAAhpB4AQAAY9wBWFzv7+sFUvBUCgAAEORIvAAAgDFuOeT281OI/r5eINmaeOXm5urKK69UTEyM4uPjdfPNN+s///mPnSUBAAAEjK2N1zvvvKOhQ4dq06ZNys/PV2VlpbKysnTkyBE7ywIAAAFy8iXZ/j6Cha1TjevWrfP4esGCBYqPj1dhYaGuvfZam6oCAACBEu6L68+pNV4HDx6UJDVs2LDG75eXl6u8vLzq67KyMiN1AQAA+MM50yJalqXRo0erQ4cOSktLq/Gc3NxcxcXFVR1JSUmGqwQAAL+EWw65LT8fLK733rBhw7R9+3YtW7bstOfk5OTo4MGDVUdxcbHBCgEAAH6Zc2Kqcfjw4VqzZo3Wr1+v5s2bn/Y8p9Mpp9NpsDIAAOBPVgC2k7CCKPGytfGyLEvDhw/XqlWr9PbbbyslJcXOcgAAAALK1sZr6NChWrp0qVavXq2YmBiVlJRIkuLi4lS7dm07SwMAAAFwcl2Wv68ZLGxd4zV79mwdPHhQnTp1UmJiYtWRl5dnZ1kAAAABYftUIwAACB/s4wUAAGAIU40AAAAwgsQLAAAY4w7AdhJsoAoAAIBqSLwAAIAxrPECAACAESReAADAGBIvAAAAGEHiBQAAjAn3xIvGCwAAGBPujRdTjQAAAIaQeAEAAGMs+X/D02B68zOJFwAAgCEkXgAAwBjWeAEAAMAIEi8AAGBMuCdeIdF4HU+MlVUr2u4yvHLpQ8V2l+CTypLv7C7BZ30//9ruEnyyvqzc7hJ8csxy2V2Czybs3Gp3CT75vLzU7hJ80vnrHXaX4LOhWRfaXYJXKl3lKrK7iDAXEo0XAAAIDiReAAAAhoR748XiegAAAENIvAAAgDGW5ZDl54TK39cLJBIvAAAAQ0i8AACAMW45/P7KIH9fL5BIvAAAAAwh8QIAAMbwVCMAAACMIPECAADG8FQjAAAAjCDxAgAAxoT7Gi8aLwAAYAxTjQAAADCCxAsAABhjBWCqkcQLAAAA1ZB4AQAAYyxJluX/awYLEi8AAABDSLwAAIAxbjnk4CXZAAAACDQSLwAAYEy47+NF4wUAAIxxWw45wnjneqYaAQAADCHxAgAAxlhWALaTCKL9JEi8AAAADCHxAgAAxoT74noSLwAAAENIvAAAgDEkXgAAADCCxAsAABgT7vt40XgBAABj2E4CAAAARpB4AQAAY04kXv5eXO/XywUUiRcAAIAhJF4AAMAYtpMAAACAESReAADAGOu/h7+vGSxIvAAAAAwh8QIAAMaE+xovGi8AAGBOmM81MtUIAABgCIkXAAAwJwBTjQqiqUYSLwAAAENIvAAAgDG8JBsAACAMzZo1SykpKYqOjlZGRoY2bNhwxvPLy8s1YcIEJScny+l06sILL9T8+fO9umdIJF4H7/tJkXVcdpfhlXfS19hdgk9+92lPu0vw2R9itthdgk+uiH7T7hJ8cuXr99ldgs8uWlhpdwk++XbUcbtL8Mk1GTvtLsFnn2c3trsEr7iPHpPG2VvDubKdRF5enkaOHKlZs2apffv2evbZZ9WlSxd9+umnatGiRY2f6dmzp7777jvNmzdPF110kUpLS1VZ6d2fFyHReAEAAHhj+vTpGjhwoAYNGiRJmjFjhl5//XXNnj1bubm51c5ft26d3nnnHe3cuVMNGzaUJLVs2dLr+zLVCAAAzLEcgTkklZWVeRzl5eU1llBRUaHCwkJlZWV5jGdlZem9996r8TNr1qxRZmampk2bpvPPP1+/+tWv9Kc//UlHjx716scn8QIAAMYEcnF9UlKSx/jEiRP10EMPVTt/3759crlcSkhI8BhPSEhQSUlJjffYuXOn3n33XUVHR2vVqlXat2+fsrOz9cMPP3i1zovGCwAAhITi4mLFxsZWfe10Os94vsPhuTbMsqxqYye53W45HA4tWbJEcXFxkk5MV9522216+umnVbt27bOqkcYLAACYE8BXBsXGxno0XqfTuHFjRUZGVku3SktLq6VgJyUmJur888+varokKTU1VZZlac+ePbr44ovPqlTWeAEAgLASFRWljIwM5efne4zn5+erXbt2NX6mffv2+vbbb3X48OGqsR07digiIkLNmzc/63vTeAEAAGNObifh78Nbo0eP1ty5czV//nx99tlnGjVqlIqKijRkyBBJUk5Ojvr27Vt1/h133KFGjRrp7rvv1qeffqr169dr7NixGjBgwFlPM0pMNQIAgDDUq1cv7d+/X5MmTdLevXuVlpamtWvXKjk5WZK0d+9eFRUVVZ1fr1495efna/jw4crMzFSjRo3Us2dP/eUvf/HqvjReAADArHPkFT/Z2dnKzs6u8XsLFy6sNnbJJZdUm570FlONAAAAhpB4AQAAY86VVwbZhcYLAACYE8DtJIIBU40AAACGkHgBAACDHP89/H3N4EDiBQAAYAiJFwAAMIc1XgAAADCBxAsAAJhD4gUAAAATzpnGKzc3Vw6HQyNHjrS7FAAAECiWIzBHkDgnphoLCgo0Z84ctW7d2u5SAABAAFnWicPf1wwWtidehw8f1p133qnnnntODRo0sLscAACAgLG98Ro6dKi6du2qG2+88WfPLS8vV1lZmccBAACCiBWgI0jYOtX44osv6sMPP1RBQcFZnZ+bm6uHH344wFUBAAAEhm2JV3Fxse677z4tXrxY0dHRZ/WZnJwcHTx4sOooLi4OcJUAAMCvWFxvj8LCQpWWliojI6NqzOVyaf369Zo5c6bKy8sVGRnp8Rmn0ymn02m6VAAAAL+wrfG64YYb9NFHH3mM3X333brkkks0bty4ak0XAAAIfg7rxOHvawYL2xqvmJgYpaWleYzVrVtXjRo1qjYOAAAQCrxe4/X888/rtddeq/r6/vvvV/369dWuXTvt3r3br8UBAIAQE+ZPNXrdeE2ZMkW1a9eWJG3cuFEzZ87UtGnT1LhxY40aNeoXFfP2229rxowZv+gaAADgHMbieu8UFxfroosukiS9/PLLuu222/THP/5R7du3V6dOnfxdHwAAQMjwOvGqV6+e9u/fL0l64403qjY+jY6O1tGjR/1bHQAACC1hPtXodeLVuXNnDRo0SG3atNGOHTvUtWtXSdInn3yili1b+rs+AACAkOF14vX000+rbdu2+v7777VixQo1atRI0ol9uXr37u33AgEAQAgh8fJO/fr1NXPmzGrjvMoHAADgzM6q8dq+fbvS0tIUERGh7du3n/Hc1q1b+6UwAAAQggKRUIVa4pWenq6SkhLFx8crPT1dDodDlvX/f8qTXzscDrlcroAVCwAAEMzOqvHatWuXmjRpUvW/AQAAfBKIfbdCbR+v5OTkGv/3qf5vCgYAAABPXj/V2KdPHx0+fLja+Ndff61rr73WL0UBAIDQdPIl2f4+goXXjdenn36qyy67TP/+97+rxp5//nldfvnlSkhI8GtxAAAgxLCdhHfef/99PfDAA7r++us1ZswYffHFF1q3bp3++te/asCAAYGoEQAAICR43XjVqlVLjz76qJxOpyZPnqxatWrpnXfeUdu2bQNRHwAAQMjweqrx+PHjGjNmjKZOnaqcnBy1bdtWv//977V27dpA1AcAABAyvE68MjMz9dNPP+ntt9/WNddcI8uyNG3aNN1yyy0aMGCAZs2aFYg6AQBACHDI/4vhg2czCR8br7/97W+qW7eupBObp44bN06/+c1vdNddd/m9wLMRvTBOtc6LtuXevvrn4/XtLsEnRSUN7S7BZ1ctvdfuEnzictpdgY+uqbC7Ap992d/rPxrPCauueNbuEnwyvksfu0vw2UUNjtpdglcqK4+p2O4iwpzXf7rMmzevxvH09HQVFhb+4oIAAEAIYwNV3x09elTHjx/3GHM6g/U/zwEAAALL68X1R44c0bBhwxQfH6969eqpQYMGHgcAAMBphfk+Xl43Xvfff7/eeustzZo1S06nU3PnztXDDz+sZs2aadGiRYGoEQAAhIowb7y8nmp85ZVXtGjRInXq1EkDBgxQx44dddFFFyk5OVlLlizRnXfeGYg6AQAAgp7XidcPP/yglJQUSVJsbKx++OEHSVKHDh20fv16/1YHAABCCu9q9NIFF1ygr7/+WpJ06aWX6qWXXpJ0IgmrX7++P2sDAAAIKV43Xnfffbe2bdsmScrJyala6zVq1CiNHTvW7wUCAIAQwhov74waNarqf1933XX6/PPP9cEHH+jCCy/U5Zdf7tfiAAAAQskv3p65RYsWatGihT9qAQAAoS4QCVUQJV5eTzUCAADAN8H5QjIAABCUAvEUYkg+1bhnz55A1gEAAMLByXc1+vsIEmfdeKWlpemFF14IZC0AAAAh7awbrylTpmjo0KG69dZbtX///kDWBAAAQlWYbydx1o1Xdna2tm3bpgMHDqhVq1Zas2ZNIOsCAAAIOV4trk9JSdFbb72lmTNn6tZbb1Vqaqpq1fK8xIcffujXAgEAQOgI98X1Xj/VuHv3bq1YsUINGzZUjx49qjVeAAAAqJlXXdNzzz2nMWPG6MYbb9THH3+sJk2aBKouAAAQisJ8A9Wzbrx++9vfavPmzZo5c6b69u0byJoAAABC0lk3Xi6XS9u3b1fz5s0DWQ8AAAhlAVjjFZKJV35+fiDrAAAA4SDMpxp5VyMAAIAhPJIIAADMIfECAACACSReAADAmHDfQJXECwAAwBAaLwAAAENovAAAAAxhjRcAADAnzJ9qpPECAADGsLgeAAAARpB4AQAAs4IoofI3Ei8AAABDSLwAAIA5Yb64nsQLAADAEBIvAABgDE81AgAAwAgSLwAAYE6Yr/Gi8QIAAMYw1QgAAAAjSLwAAIA5YT7VSOIFAABgCIkXAAAwh8QLAAAAJpB4AQAAY8L9qcaQaLwuHvOZoupF2V2GV9KdpXaX4JNG/3LaXYLPDjd32F2CTzretMXuEnzybvEFdpfgs58O1La7BJ88XXq93SX4ZGfvxnaX4LOUvx+wuwSvWK4Ku0s4p8yaNUuPPfaY9u7dq1atWmnGjBnq2LHjz37u3//+t/7nf/5HaWlp2rp1q1f3ZKoRAACYYwXo8FJeXp5GjhypCRMmaMuWLerYsaO6dOmioqKiM37u4MGD6tu3r2644QbvbyoaLwAAYNI50nhNnz5dAwcO1KBBg5SamqoZM2YoKSlJs2fPPuPnBg8erDvuuENt27b1/qai8QIAACGirKzM4ygvL6/xvIqKChUWFiorK8tjPCsrS++9995pr79gwQJ99dVXmjhxos810ngBAABjTi6u9/chSUlJSYqLi6s6cnNza6xh3759crlcSkhI8BhPSEhQSUlJjZ/54osvNH78eC1ZskS1avm+RD4kFtcDAAAUFxcrNja26mun88wPhDkcng9dWZZVbUySXC6X7rjjDj388MP61a9+9YtqpPECAADmBHAD1djYWI/G63QaN26syMjIaulWaWlptRRMkg4dOqQPPvhAW7Zs0bBhwyRJbrdblmWpVq1aeuONN3T99Wf3VDFTjQAAIKxERUUpIyND+fn5HuP5+flq165dtfNjY2P10UcfaevWrVXHkCFD9Otf/1pbt27V1Vdffdb3JvECAADGnCsbqI4ePVp9+vRRZmam2rZtqzlz5qioqEhDhgyRJOXk5Oibb77RokWLFBERobS0NI/Px8fHKzo6utr4z6HxAgAAYadXr17av3+/Jk2apL179yotLU1r165VcnKyJGnv3r0/u6eXL2i8AACAOefQS7Kzs7OVnZ1d4/cWLlx4xs8+9NBDeuihh7y+J40XAAAw5xxqvOzA4noAAABDSLwAAIAxjv8e/r5msCDxAgAAMITECwAAmMMaLwAAAJhA4gUAAIw5VzZQtQuJFwAAgCG2N17ffPON7rrrLjVq1Eh16tRRenq6CgsL7S4LAAAEghWgI0jYOtV44MABtW/fXtddd53+8Y9/KD4+Xl999ZXq169vZ1kAACCQgqhR8jdbG6+pU6cqKSlJCxYsqBpr2bKlfQUBAAAEkK1TjWvWrFFmZqZuv/12xcfHq02bNnruuedOe355ebnKyso8DgAAEDxOLq739xEsbG28du7cqdmzZ+viiy/W66+/riFDhmjEiBFatGhRjefn5uYqLi6u6khKSjJcMQAAgO9sbbzcbreuuOIKTZkyRW3atNHgwYN1zz33aPbs2TWen5OTo4MHD1YdxcXFhisGAAC/SJgvrre18UpMTNSll17qMZaamqqioqIaz3c6nYqNjfU4AAAAgoWti+vbt2+v//znPx5jO3bsUHJysk0VAQCAQGIDVRuNGjVKmzZt0pQpU/Tll19q6dKlmjNnjoYOHWpnWQAAAAFha+N15ZVXatWqVVq2bJnS0tI0efJkzZgxQ3feeaedZQEAgEAJ8zVetr+rsVu3burWrZvdZQAAAASc7Y0XAAAIH+G+xovGCwAAmBOIqcEgarxsf0k2AABAuCDxAgAA5pB4AQAAwAQSLwAAYEy4L64n8QIAADCExAsAAJjDGi8AAACYQOIFAACMcViWHJZ/Iyp/Xy+QaLwAAIA5TDUCAADABBIvAABgDNtJAAAAwAgSLwAAYA5rvAAAAGBCSCRe215IU2RUtN1leGXQxxfZXYJPDnd22F2Cz5q022t3CT7Jf7+13SX4pPPV2+0uwWetU/fYXYJPHn+7i90l+CTaFbx/rly6YIfdJXil/PBxvXWtvTWwxgsAAABGhETiBQAAgkSYr/Gi8QIAAMYw1QgAAAAjSLwAAIA5YT7VSOIFAABgCIkXAAAwKpjWZPkbiRcAAIAhJF4AAMAcyzpx+PuaQYLECwAAwBASLwAAYEy47+NF4wUAAMxhOwkAAACYQOIFAACMcbhPHP6+ZrAg8QIAADCExAsAAJjDGi8AAACYQOIFAACMCfftJEi8AAAADCHxAgAA5oT5K4NovAAAgDFMNQIAAMAIEi8AAGAO20kAAADABBIvAABgDGu8AAAAYASJFwAAMCfMt5Mg8QIAADCExAsAABgT7mu8aLwAAIA5bCcBAAAAE0i8AACAMeE+1UjiBQAAYAiJFwAAMMdtnTj8fc0gQeIFAABgCIkXAAAwh6caAQAAYAKJFwAAMMahADzV6N/LBRSNFwAAMId3NQIAAMAEEi8AAGAMG6gCAADACBIvAABgDttJAAAAwAQSLwAAYIzDsuTw81OI/r5eIIVE45XYc7fOqxtldxlemZq80u4SfPK71++zuwSfDUt5y+4SfLLw9svtLsEnb49Nt7sEn328vbXdJfjEmRZpdwk+iWpzwO4SfLby/Uy7S/CK++gxSavsLiOshUTjBQAAgoT7v4e/rxkkWOMFAACMOTnV6O/DF7NmzVJKSoqio6OVkZGhDRs2nPbclStXqnPnzmrSpIliY2PVtm1bvf76617fk8YLAACEnby8PI0cOVITJkzQli1b1LFjR3Xp0kVFRUU1nr9+/Xp17txZa9euVWFhoa677jp1795dW7Zs8eq+TDUCAABzAridRFlZmcew0+mU0+ms8SPTp0/XwIEDNWjQIEnSjBkz9Prrr2v27NnKzc2tdv6MGTM8vp4yZYpWr16tV155RW3atDnrUkm8AABASEhKSlJcXFzVUVMDJUkVFRUqLCxUVlaWx3hWVpbee++9s7qX2+3WoUOH1LBhQ69qJPECAADmBPAl2cXFxYqNja0aPl3atW/fPrlcLiUkJHiMJyQkqKSk5Kxu+cQTT+jIkSPq2bOnV6XSeAEAgJAQGxvr0Xj9HIfD4fG1ZVnVxmqybNkyPfTQQ1q9erXi4+O9qpHGCwAAGHMuvCS7cePGioyMrJZulZaWVkvBTpWXl6eBAwdq+fLluvHGG70tlTVeAAAgvERFRSkjI0P5+fke4/n5+WrXrt1pP7ds2TL1799fS5cuVdeuXX26N4kXAAAwJ4BrvLwxevRo9enTR5mZmWrbtq3mzJmjoqIiDRkyRJKUk5Ojb775RosWLZJ0ounq27ev/vrXv+qaa66pSstq166tuLi4s74vjRcAAAg7vXr10v79+zVp0iTt3btXaWlpWrt2rZKTkyVJe/fu9djT69lnn1VlZaWGDh2qoUOHVo3369dPCxcuPOv70ngBAABjHO4Th7+v6Yvs7GxlZ2fX+L1Tm6m3337bt5ucgsYLAACYc45MNdqFxfUAAACGkHgBAABzAvjKoGBA4gUAAGAIiRcAADDGYVly+HlNlr+vF0gkXgAAAIaQeAEAAHN4qtE+lZWVeuCBB5SSkqLatWvrggsu0KRJk+R2+3mDDwAAgHOArYnX1KlT9cwzz+j5559Xq1at9MEHH+juu+9WXFyc7rvvPjtLAwAAgWBJ8ne+EjyBl72N18aNG9WjR4+qF022bNlSy5Yt0wcffFDj+eXl5SovL6/6uqyszEidAADAP1hcb6MOHTrozTff1I4dOyRJ27Zt07vvvqvf/e53NZ6fm5uruLi4qiMpKclkuQAAAL+IrYnXuHHjdPDgQV1yySWKjIyUy+XSI488ot69e9d4fk5OjkaPHl31dVlZGc0XAADBxFIAFtf793KBZGvjlZeXp8WLF2vp0qVq1aqVtm7dqpEjR6pZs2bq169ftfOdTqecTqcNlQIAAPxytjZeY8eO1fjx4/WHP/xBknTZZZdp9+7dys3NrbHxAgAAQY7tJOzz008/KSLCs4TIyEi2kwAAACHJ1sSre/fueuSRR9SiRQu1atVKW7Zs0fTp0zVgwAA7ywIAAIHiluQIwDWDhK2N11NPPaU///nPys7OVmlpqZo1a6bBgwfrwQcftLMsAACAgLC18YqJidGMGTM0Y8YMO8sAAACGhPs+XryrEQAAmMPiegAAAJhA4gUAAMwh8QIAAIAJJF4AAMAcEi8AAACYQOIFAADMCfMNVEm8AAAADCHxAgAAxrCBKgAAgCksrgcAAIAJJF4AAMActyU5/JxQuUm8AAAAcAoSLwAAYA5rvAAAAGACiRcAADAoAImXgifxConGa8e38YqoE213GV7pN3+M3SX45OIdP9ldgs8mfnun3SX45Nhfy+0uwSd1dvh7a2pzylpG2l2CT+q02W93CT5p2rfE7hJ8duTPqXaX4BXHMSa67BYSjRcAAAgSYb7Gi8YLAACY47bk96lBtpMAAADAqUi8AACAOZb7xOHvawYJEi8AAABDSLwAAIA5Yb64nsQLAADAEBIvAABgDk81AgAAwAQSLwAAYE6Yr/Gi8QIAAOZYCkDj5d/LBRJTjQAAAIaQeAEAAHPCfKqRxAsAAMAQEi8AAGCO2y3Jz6/4cfPKIAAAAJyCxAsAAJjDGi8AAACYQOIFAADMCfPEi8YLAACYw7saAQAAYAKJFwAAMMay3LIs/27/4O/rBRKJFwAAgCEkXgAAwBzL8v+arCBaXE/iBQAAYAiJFwAAMMcKwFONJF4AAAA4FYkXAAAwx+2WHH5+CjGInmqk8QIAAOYw1QgAAAATSLwAAIAxltsty89TjWygCgAAgGpIvAAAgDms8QIAAIAJJF4AAMActyU5SLwAAAAQYCReAADAHMuS5O8NVEm8AAAAcAoSLwAAYIzltmT5eY2XFUSJF40XAAAwx3LL/1ONbKAKAACAU5B4AQAAY8J9qpHECwAAwBASLwAAYE6Yr/EK6sbrZLToPlpucyXec1U47C7BJ5WVx+wuwWeuY5F2l+CTYPznW5Jc5cET/Z/KqrS7At9E/BSc/6xUWhV2l+Az97Hg+jPxZL12Ts1V6rjfX9VYqeP+vWAAOaxgmhg9xZ49e5SUlGR3GQAABJXi4mI1b97c6D2PHTumlJQUlZSUBOT6TZs21a5duxQdHR2Q6/tLUDdebrdb3377rWJiYuRw+DdBKisrU1JSkoqLixUbG+vXa6Nm/M7N4vdtFr9v8/idV2dZlg4dOqRmzZopIsL8Mu9jx46poiIwCWdUVNQ533RJQT7VGBEREfCOPTY2ln9hDeN3bha/b7P4fZvH79xTXFycbfeOjo4OiuYokHiqEQAAwBAaLwAAAENovE7D6XRq4sSJcjqddpcSNvidm8Xv2yx+3+bxO8e5KKgX1wMAAAQTEi8AAABDaLwAAAAMofECAAAwhMYLAADAEBqv05g1a5ZSUlIUHR2tjIwMbdiwwe6SQlJubq6uvPJKxcTEKD4+XjfffLP+85//2F1W2MjNzZXD4dDIkSPtLiWkffPNN7rrrrvUqFEj1alTR+np6SosLLS7rJBUWVmpBx54QCkpKapdu7YuuOACTZo0SW538LxEGaGNxqsGeXl5GjlypCZMmKAtW7aoY8eO6tKli4qKiuwuLeS88847Gjp0qDZt2qT8/HxVVlYqKytLR44csbu0kFdQUKA5c+aodevWdpcS0g4cOKD27dvrvPPO0z/+8Q99+umneuKJJ1S/fn27SwtJU6dO1TPPPKOZM2fqs88+07Rp0/TYY4/pqaeesrs0QBLbSdTo6quv1hVXXKHZs2dXjaWmpurmm29Wbm6ujZWFvu+//17x8fF65513dO2119pdTsg6fPiwrrjiCs2aNUt/+ctflJ6erhkzZthdVkgaP368/v3vf5OaG9KtWzclJCRo3rx5VWO33nqr6tSpoxdeeMHGyoATSLxOUVFRocLCQmVlZXmMZ2Vl6b333rOpqvBx8OBBSVLDhg1triS0DR06VF27dtWNN95odykhb82aNcrMzNTtt9+u+Ph4tWnTRs8995zdZYWsDh066M0339SOHTskSdu2bdO7776r3/3udzZXBpwQ1C/JDoR9+/bJ5XIpISHBYzwhIUElJSU2VRUeLMvS6NGj1aFDB6WlpdldTsh68cUX9eGHH6qgoMDuUsLCzp07NXv2bI0ePVr/+7//q82bN2vEiBFyOp3q27ev3eWFnHHjxungwYO65JJLFBkZKZfLpUceeUS9e/e2uzRAEo3XaTkcDo+vLcuqNgb/GjZsmLZv3653333X7lJCVnFxse677z698cYbio6OtrucsOB2u5WZmakpU6ZIktq0aaNPPvlEs2fPpvEKgLy8PC1evFhLly5Vq1attHXrVo0cOVLNmjVTv3797C4PoPE6VePGjRUZGVkt3SotLa2WgsF/hg8frjVr1mj9+vVq3ry53eWErMLCQpWWliojI6NqzOVyaf369Zo5c6bKy8sVGRlpY4WhJzExUZdeeqnHWGpqqlasWGFTRaFt7NixGj9+vP7whz9Iki677DLt3r1bubm5NF44J7DG6xRRUVHKyMhQfn6+x3h+fr7atWtnU1Why7IsDRs2TCtXrtRbb72llJQUu0sKaTfccIM++ugjbd26terIzMzUnXfeqa1bt9J0BUD79u2rbZGyY8cOJScn21RRaPvpp58UEeH5V1tkZCTbSeCcQeJVg9GjR6tPnz7KzMxU27ZtNWfOHBUVFWnIkCF2lxZyhg4dqqVLl2r16tWKiYmpShrj4uJUu3Ztm6sLPTExMdXWz9WtW1eNGjViXV2AjBo1Su3atdOUKVPUs2dPbd68WXPmzNGcOXPsLi0kde/eXY888ohatGihVq1aacuWLZo+fboGDBhgd2mAJLaTOK1Zs2Zp2rRp2rt3r9LS0vTkk0+yvUEAnG7d3IIFC9S/f3+zxYSpTp06sZ1EgL366qvKycnRF198oZSUFI0ePVr33HOP3WWFpEOHDunPf/6zVq1apdLSUjVr1ky9e/fWgw8+qKioKLvLA2i8AAAATGGNFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuMFAABgCI0XANs5HA69/PLLdpcBAAFH4wVALpdL7dq106233uoxfvDgQSUlJemBBx4I6P337t2rLl26BPQeAHAu4JVBACRJX3zxhdLT0zVnzhzdeeedkqS+fftq27ZtKigo4D13AOAHJF4AJEkXX3yxcnNzNXz4cH377bdavXq1XnzxRT3//PNnbLoWL16szMxMxcTEqGnTprrjjjtUWlpa9f1JkyapWbNm2r9/f9XYTTfdpGuvvVZut1uS51RjRUWFhg0bpsTEREVHR6tly5bKzc0NzA8NAIaReAGoYlmWrr/+ekVGRuqjjz7S8OHDf3aacf78+UpMTNSvf/1rlZaWatSoUWrQoIHWrl0r6cQ0ZseOHZWQkKBVq1bpmWee0fjx47Vt2zYlJydLOtF4rVq1SjfffLMef/xx/e1vf9OSJUvUokULFRcXq7i4WL179w74zw8AgUbjBcDD559/rtTUVF122WX68MMPVatWLa8+X1BQoKuuukqHDh1SvXr1JEk7d+5Uenq6srOz9dRTT3lMZ0qejdeIESP0ySef6J///KccDodffzYAsBtTjQA8zJ8/X3Xq1NGuXbu0Z8+enz1/y5Yt6tGjh5KTkxUTE6NOnTpJkoqKiqrOueCCC/T4449r6tSp6t69u0fTdar+/ftr69at+vWvf60RI0bojTfe+MU/EwCcK2i8AFTZuHGjnnzySa1evVpt27bVwIEDdaZQ/MiRI8rKylK9evW0ePFiFRQUaNWqVZJOrNX6v9avX6/IyEh9/fXXqqysPO01r7jiCu3atUuTJ0/W0aNH1bNnT912223++QEBwGY0XgAkSUePHlW/fv00ePBg3XjjjZo7d64KCgr07LPPnvYzn3/+ufbt26dHH31UHTt21CWXXOKxsP6kvLw8rVy5Um+//baKi4s1efLkM9YSGxurXr166bnnnlNeXp5WrFihH3744Rf/jABgNxovAJKk8ePHy+12a+rUqZKkFi1a6IknntDYsWP19ddf1/iZFi1aKCoqSk899ZR27typNWvWVGuq9uzZo3vvvVdTp05Vhw4dtHDhQuXm5mrTpk01XvPJJ5/Uiy++qM8//1w7duzQ8uXL1bRpU9WvX9+fPy4A2ILGC4DeeecdPf3001q4cKHq1q1bNX7PPfeoXbt2p51ybNKkiRYuXKjly5fr0ksv1aOPPqrHH3+86vuWZal///666qqrNGzYMElS586dNWzYMN111106fPhwtWvWq1dPU6dOVWZmpq688kp9/fXXWrt2rSIi+OMKQPDjqUYAAABD+E9IAAAAQ2i8AAAADKHxAgAAMITGCwAAwBAaLwAAAENovAAAAAyh8QIAADCExgsAAMAQGi8AAABDaLwAAAAMofECAAAw5P8Bb8yqdXRelicAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "    #         return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    input_argmin = input_slice.argmax(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    input_argmin = input_slice.argmax(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient Î∞©Ìñ•ÏùÑ argmin Ï™ΩÏúºÎ°ú\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    ooo_fifo = 3\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "            #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "            #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 Ï§ë ÌïòÎÇò ÏÑ†ÌÉù\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                    optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch ÌÅ¨Í∏∞ ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "                        #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "                        #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "#                 BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 # n_tidigits_tonic 8\n",
    "\n",
    "#                 # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "#                 which_data = 'n_tidigits_tonic',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.03125,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "#                 lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "#                 synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "#                 # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 1000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 1, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 0, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "#                 # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "#                 # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 9, \n",
    "\n",
    "#                 num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "#                 chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 8, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "#                 # quantize_bit_list=[],\n",
    "#                 # scale_exp=[], \n",
    "#                 timestep_sums_threshold = 0,\n",
    "# # 1w -11~-9\n",
    "# # 1b -11~ -7\n",
    "# # 2w -10~-8\n",
    "# # 2b -10~-8\n",
    "# # 3w -10\n",
    "# # 3b -10\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# # average pooling  \n",
    "# # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xdv5nqlk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001220703125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250722_024803-xdv5nqlk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdv5nqlk' target=\"_blank\">treasured-sweep-9</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdv5nqlk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdv5nqlk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250722_024811_630', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0001220703125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 6, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-11, -11], [-11, -11], [-10, -10]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 6\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -11\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -11\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-11, -11], [-11, -11], [-10, -10]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0001220703125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-0   lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.80 seconds, 4.45 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-1   lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.44 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-2   lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.64 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-3   lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.57 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-4   lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.14 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-5   lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.66 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-6   lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.36 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-7   lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.84 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-8   lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.73 seconds, 4.45 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-9   lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 267.48 seconds, 4.46 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-10  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.14 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-11  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.55 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-12  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.98 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-13  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.25 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-14  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.23 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-15  lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.48 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-16  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.86 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-17  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.44 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-18  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.05 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-19  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.46 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-20  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.52 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-21  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.60 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-22  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.94 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-23  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.64 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-24  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.23 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-25  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.99 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-26  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.06 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-27  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.01 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-28  lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.07 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-29  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.62 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-30  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.76 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-31  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.09 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-32  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.00 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-33  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.28 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-34  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.61 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-35  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.31 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-36  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.61 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-37  lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.05 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-38  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.44 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-39  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.90 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-40  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.21 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-41  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.23 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-42  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.89 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-43  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.51 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-44  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.31 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-45  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.02 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-46  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.48 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-47  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.38 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-48  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.41 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-49  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.91 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-50  lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.82 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-51  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.53 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-52  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.37 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-53  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.35 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-54  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.82 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-55  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.02 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-56  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.25 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-57  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.93 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-58  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.29 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-59  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.15 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-60  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.99 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-61  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.28 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-62  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.31 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-63  lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.68 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-64  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.60 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-65  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.07 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-66  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.91 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-67  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.77 seconds, 4.36 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-68  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.80 seconds, 4.36 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-69  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.47 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-70  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.68 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-71  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.96 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-72  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.14 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-73  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.15 seconds, 4.35 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-74  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.68 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-75  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.31 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-76  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.85 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-77  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.25 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-78  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.35 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-79  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.50 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-80  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.39 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-81  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.63 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-82  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.94 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-83  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.16 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-84  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.18 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-85  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.13 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-86  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.64 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-87  lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.11 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-88  lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.48 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-89  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.96 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-90  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.84 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-91  lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.51 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-92  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 268.03 seconds, 4.47 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-93  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.95 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-94  lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.51 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-95  lr=['0.0001221'], tr/val_loss:  2.341441/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.29 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-96  lr=['0.0001221'], tr/val_loss:  2.341442/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.74 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-97  lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.23 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-98  lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.25 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-99  lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.80 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-100 lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.59 seconds, 4.36 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-101 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.32 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-102 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.80 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-103 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.31 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-104 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.58 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-105 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.72 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-106 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.45 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-107 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.53 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-108 lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.15 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-109 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.80 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-110 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.09 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-111 lr=['0.0001221'], tr/val_loss:  2.341441/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.51 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-112 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.00 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-113 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.00 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-114 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.01 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-115 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.60 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-116 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.02 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-117 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.92 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-118 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.04 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-119 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.05 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-120 lr=['0.0001221'], tr/val_loss:  2.341442/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.46 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-121 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.23 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-122 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.64 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-123 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.39 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-124 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.93 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-125 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.78 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-126 lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 269.01 seconds, 4.48 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-127 lr=['0.0001221'], tr/val_loss:  2.341441/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.27 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-128 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.77 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-129 lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.74 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-130 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.47 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-131 lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.10 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-132 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.99 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-133 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.49 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-134 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.73 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-135 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.24 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-136 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.70 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-137 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.48 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-138 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.57 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-139 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.00 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-140 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.95 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-141 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.91 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-142 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.82 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-143 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.86 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-144 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.96 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-145 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.91 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-146 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.48 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-147 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.80 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-148 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.22 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-149 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.86 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-150 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.05 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-151 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.79 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-152 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.36 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-153 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.71 seconds, 4.45 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-154 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 266.15 seconds, 4.44 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-155 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.48 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-156 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.21 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-157 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.65 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-158 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.84 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-159 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.15 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-160 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 260.29 seconds, 4.34 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-161 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.60 seconds, 4.36 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-162 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.69 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-163 lr=['0.0001221'], tr/val_loss:  2.341433/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.26 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-164 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.15 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-165 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 259.75 seconds, 4.33 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-166 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.87 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-167 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.04 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-168 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.60 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-169 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.14 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-170 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.72 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-171 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.29 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-172 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.53 seconds, 4.43 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-173 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.95 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-174 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.43 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-175 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.19 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-176 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.05 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-177 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.76 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-178 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.54 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-179 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.08 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-180 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 265.18 seconds, 4.42 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-181 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.85 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-182 lr=['0.0001221'], tr/val_loss:  2.341434/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.01 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-183 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.29 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-184 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.93 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-185 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 260.38 seconds, 4.34 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-186 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.70 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-187 lr=['0.0001221'], tr/val_loss:  2.341439/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.20 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-188 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.01 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-189 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.10 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-190 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 261.90 seconds, 4.37 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-191 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.97 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-192 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.78 seconds, 4.41 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-193 lr=['0.0001221'], tr/val_loss:  2.341440/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.00 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-194 lr=['0.0001221'], tr/val_loss:  2.341437/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 264.08 seconds, 4.40 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-195 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.69 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-196 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 262.67 seconds, 4.38 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-197 lr=['0.0001221'], tr/val_loss:  2.341438/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 259.88 seconds, 4.33 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-198 lr=['0.0001221'], tr/val_loss:  2.341435/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.67 seconds, 4.39 minutes\n",
      "train - Value 0: 2627 occurrences\n",
      "train - Value 1: 1403 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-199 lr=['0.0001221'], tr/val_loss:  2.341436/  2.338320, val:  50.44%, val_best:  50.44%, tr:  49.38%, tr_best:  49.38%, epoch time: 263.62 seconds, 4.39 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dd685c0f8d4f4d8a8e05a52a7452e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÑ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.4938</td></tr><tr><td>tr_epoch_loss</td><td>2.34144</td></tr><tr><td>val_acc_best</td><td>0.50442</td></tr><tr><td>val_acc_now</td><td>0.50442</td></tr><tr><td>val_loss</td><td>2.33832</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-sweep-9</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdv5nqlk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdv5nqlk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250722_024803-xdv5nqlk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4t5vhh7z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000244140625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250722_172900-4t5vhh7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4t5vhh7z' target=\"_blank\">driven-sweep-18</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4t5vhh7z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4t5vhh7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250722_172909_440', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 6, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.000244140625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 4, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 4\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.000244140625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 1897 occurrences\n",
      "train - Value 1: 2133 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-0   lr=['0.0002441'], tr/val_loss:  2.246053/  2.201220, val:  86.95%, val_best:  86.95%, tr:  75.38%, tr_best:  75.38%, epoch time: 165.19 seconds, 2.75 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-1   lr=['0.0002441'], tr/val_loss:  2.173139/  2.172313, val:  55.75%, val_best:  86.95%, tr:  82.06%, tr_best:  82.06%, epoch time: 164.24 seconds, 2.74 minutes\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-2   lr=['0.0002441'], tr/val_loss:  2.160970/  2.169774, val:  92.26%, val_best:  92.26%, tr:  82.36%, tr_best:  82.36%, epoch time: 163.15 seconds, 2.72 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-3   lr=['0.0002441'], tr/val_loss:  2.153679/  2.165492, val:  69.91%, val_best:  92.26%, tr:  85.04%, tr_best:  85.04%, epoch time: 163.64 seconds, 2.73 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 379 occurrences\n",
      "test - Value 1: 73 occurrences\n",
      "epoch-4   lr=['0.0002441'], tr/val_loss:  2.149441/  2.158822, val:  66.15%, val_best:  92.26%, tr:  84.74%, tr_best:  85.04%, epoch time: 163.92 seconds, 2.73 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-5   lr=['0.0002441'], tr/val_loss:  2.151593/  2.173075, val:  84.73%, val_best:  92.26%, tr:  86.45%, tr_best:  86.45%, epoch time: 164.12 seconds, 2.74 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 275 occurrences\n",
      "test - Value 1: 177 occurrences\n",
      "epoch-6   lr=['0.0002441'], tr/val_loss:  2.150858/  2.163371, val:  88.72%, val_best:  92.26%, tr:  85.93%, tr_best:  86.45%, epoch time: 162.29 seconds, 2.70 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-7   lr=['0.0002441'], tr/val_loss:  2.150179/  2.167471, val:  92.48%, val_best:  92.48%, tr:  86.50%, tr_best:  86.50%, epoch time: 163.16 seconds, 2.72 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-8   lr=['0.0002441'], tr/val_loss:  2.150261/  2.164398, val:  90.49%, val_best:  92.48%, tr:  86.72%, tr_best:  86.72%, epoch time: 163.46 seconds, 2.72 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-9   lr=['0.0002441'], tr/val_loss:  2.149393/  2.170903, val:  55.75%, val_best:  92.48%, tr:  86.75%, tr_best:  86.75%, epoch time: 163.81 seconds, 2.73 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 349 occurrences\n",
      "test - Value 1: 103 occurrences\n",
      "epoch-10  lr=['0.0002441'], tr/val_loss:  2.147547/  2.155942, val:  72.35%, val_best:  92.48%, tr:  86.92%, tr_best:  86.92%, epoch time: 162.59 seconds, 2.71 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-11  lr=['0.0002441'], tr/val_loss:  2.147353/  2.158952, val:  85.84%, val_best:  92.48%, tr:  86.82%, tr_best:  86.92%, epoch time: 162.87 seconds, 2.71 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-12  lr=['0.0002441'], tr/val_loss:  2.148407/  2.160917, val:  88.05%, val_best:  92.48%, tr:  86.48%, tr_best:  86.92%, epoch time: 163.91 seconds, 2.73 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-13  lr=['0.0002441'], tr/val_loss:  2.147477/  2.162347, val:  91.15%, val_best:  92.48%, tr:  87.32%, tr_best:  87.32%, epoch time: 165.97 seconds, 2.77 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-14  lr=['0.0002441'], tr/val_loss:  2.146874/  2.165010, val:  92.70%, val_best:  92.70%, tr:  86.75%, tr_best:  87.32%, epoch time: 164.25 seconds, 2.74 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-15  lr=['0.0002441'], tr/val_loss:  2.147025/  2.161147, val:  88.50%, val_best:  92.70%, tr:  87.39%, tr_best:  87.39%, epoch time: 163.36 seconds, 2.72 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-16  lr=['0.0002441'], tr/val_loss:  2.145930/  2.165689, val:  91.37%, val_best:  92.70%, tr:  86.87%, tr_best:  87.39%, epoch time: 162.58 seconds, 2.71 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-17  lr=['0.0002441'], tr/val_loss:  2.146777/  2.165658, val:  91.81%, val_best:  92.70%, tr:  87.02%, tr_best:  87.39%, epoch time: 163.99 seconds, 2.73 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-18  lr=['0.0002441'], tr/val_loss:  2.146311/  2.168537, val:  64.38%, val_best:  92.70%, tr:  86.58%, tr_best:  87.39%, epoch time: 162.93 seconds, 2.72 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-19  lr=['0.0002441'], tr/val_loss:  2.145745/  2.163772, val:  90.27%, val_best:  92.70%, tr:  86.65%, tr_best:  87.39%, epoch time: 161.95 seconds, 2.70 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-20  lr=['0.0002441'], tr/val_loss:  2.146498/  2.159935, val:  83.63%, val_best:  92.70%, tr:  87.27%, tr_best:  87.39%, epoch time: 163.29 seconds, 2.72 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-21  lr=['0.0002441'], tr/val_loss:  2.146919/  2.162122, val:  89.60%, val_best:  92.70%, tr:  87.34%, tr_best:  87.39%, epoch time: 162.12 seconds, 2.70 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['0.0002441'], tr/val_loss:  2.146492/  2.175233, val:  50.00%, val_best:  92.70%, tr:  88.09%, tr_best:  88.09%, epoch time: 157.81 seconds, 2.63 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-23  lr=['0.0002441'], tr/val_loss:  2.146255/  2.159972, val:  79.42%, val_best:  92.70%, tr:  87.30%, tr_best:  88.09%, epoch time: 162.92 seconds, 2.72 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-24  lr=['0.0002441'], tr/val_loss:  2.146098/  2.155047, val:  71.46%, val_best:  92.70%, tr:  87.79%, tr_best:  88.09%, epoch time: 163.78 seconds, 2.73 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-25  lr=['0.0002441'], tr/val_loss:  2.145189/  2.161029, val:  87.83%, val_best:  92.70%, tr:  87.94%, tr_best:  88.09%, epoch time: 166.89 seconds, 2.78 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-26  lr=['0.0002441'], tr/val_loss:  2.145064/  2.162832, val:  92.04%, val_best:  92.70%, tr:  87.42%, tr_best:  88.09%, epoch time: 162.96 seconds, 2.72 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-27  lr=['0.0002441'], tr/val_loss:  2.145768/  2.162996, val:  93.58%, val_best:  93.58%, tr:  86.90%, tr_best:  88.09%, epoch time: 163.80 seconds, 2.73 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['0.0002441'], tr/val_loss:  2.145854/  2.156747, val:  50.00%, val_best:  93.58%, tr:  87.27%, tr_best:  88.09%, epoch time: 162.13 seconds, 2.70 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-29  lr=['0.0002441'], tr/val_loss:  2.145550/  2.164150, val:  93.14%, val_best:  93.58%, tr:  86.95%, tr_best:  88.09%, epoch time: 163.29 seconds, 2.72 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 231 occurrences\n",
      "test - Value 1: 221 occurrences\n",
      "epoch-30  lr=['0.0002441'], tr/val_loss:  2.145966/  2.161364, val:  92.70%, val_best:  93.58%, tr:  87.32%, tr_best:  88.09%, epoch time: 166.13 seconds, 2.77 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 97 occurrences\n",
      "test - Value 1: 355 occurrences\n",
      "epoch-31  lr=['0.0002441'], tr/val_loss:  2.145686/  2.168444, val:  71.46%, val_best:  93.58%, tr:  88.24%, tr_best:  88.24%, epoch time: 162.98 seconds, 2.72 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-32  lr=['0.0002441'], tr/val_loss:  2.145660/  2.167094, val:  81.19%, val_best:  93.58%, tr:  87.12%, tr_best:  88.24%, epoch time: 163.81 seconds, 2.73 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-33  lr=['0.0002441'], tr/val_loss:  2.145510/  2.159149, val:  77.43%, val_best:  93.58%, tr:  87.20%, tr_best:  88.24%, epoch time: 163.96 seconds, 2.73 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-34  lr=['0.0002441'], tr/val_loss:  2.145307/  2.165875, val:  83.19%, val_best:  93.58%, tr:  87.39%, tr_best:  88.24%, epoch time: 162.96 seconds, 2.72 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-35  lr=['0.0002441'], tr/val_loss:  2.144979/  2.168659, val:  59.96%, val_best:  93.58%, tr:  88.36%, tr_best:  88.36%, epoch time: 164.48 seconds, 2.74 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-36  lr=['0.0002441'], tr/val_loss:  2.143584/  2.155697, val:  58.63%, val_best:  93.58%, tr:  87.44%, tr_best:  88.36%, epoch time: 163.13 seconds, 2.72 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0002441'], tr/val_loss:  2.143456/  2.173879, val:  50.00%, val_best:  93.58%, tr:  87.47%, tr_best:  88.36%, epoch time: 162.59 seconds, 2.71 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 421 occurrences\n",
      "test - Value 1: 31 occurrences\n",
      "epoch-38  lr=['0.0002441'], tr/val_loss:  2.144254/  2.152473, val:  56.86%, val_best:  93.58%, tr:  87.34%, tr_best:  88.36%, epoch time: 163.84 seconds, 2.73 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-39  lr=['0.0002441'], tr/val_loss:  2.144424/  2.161358, val:  87.61%, val_best:  93.58%, tr:  87.49%, tr_best:  88.36%, epoch time: 162.94 seconds, 2.72 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-40  lr=['0.0002441'], tr/val_loss:  2.144171/  2.164310, val:  87.61%, val_best:  93.58%, tr:  87.69%, tr_best:  88.36%, epoch time: 164.94 seconds, 2.75 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-41  lr=['0.0002441'], tr/val_loss:  2.143601/  2.159649, val:  92.26%, val_best:  93.58%, tr:  88.26%, tr_best:  88.36%, epoch time: 165.20 seconds, 2.75 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-42  lr=['0.0002441'], tr/val_loss:  2.144121/  2.156502, val:  63.50%, val_best:  93.58%, tr:  86.65%, tr_best:  88.36%, epoch time: 163.82 seconds, 2.73 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-43  lr=['0.0002441'], tr/val_loss:  2.144150/  2.161284, val:  92.70%, val_best:  93.58%, tr:  88.73%, tr_best:  88.73%, epoch time: 164.48 seconds, 2.74 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-44  lr=['0.0002441'], tr/val_loss:  2.143964/  2.152351, val:  58.85%, val_best:  93.58%, tr:  87.34%, tr_best:  88.73%, epoch time: 161.97 seconds, 2.70 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-45  lr=['0.0002441'], tr/val_loss:  2.143612/  2.168225, val:  77.21%, val_best:  93.58%, tr:  88.06%, tr_best:  88.73%, epoch time: 163.56 seconds, 2.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-46  lr=['0.0002441'], tr/val_loss:  2.143621/  2.163608, val:  90.93%, val_best:  93.58%, tr:  87.64%, tr_best:  88.73%, epoch time: 161.21 seconds, 2.69 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-47  lr=['0.0002441'], tr/val_loss:  2.143464/  2.161994, val:  93.14%, val_best:  93.58%, tr:  87.97%, tr_best:  88.73%, epoch time: 161.04 seconds, 2.68 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-48  lr=['0.0002441'], tr/val_loss:  2.143863/  2.163432, val:  88.50%, val_best:  93.58%, tr:  87.97%, tr_best:  88.73%, epoch time: 163.11 seconds, 2.72 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-49  lr=['0.0002441'], tr/val_loss:  2.143828/  2.160767, val:  94.25%, val_best:  94.25%, tr:  87.79%, tr_best:  88.73%, epoch time: 161.34 seconds, 2.69 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-50  lr=['0.0002441'], tr/val_loss:  2.143309/  2.163365, val:  88.50%, val_best:  94.25%, tr:  88.06%, tr_best:  88.73%, epoch time: 160.84 seconds, 2.68 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-51  lr=['0.0002441'], tr/val_loss:  2.143567/  2.162258, val:  93.58%, val_best:  94.25%, tr:  88.04%, tr_best:  88.73%, epoch time: 160.58 seconds, 2.68 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-52  lr=['0.0002441'], tr/val_loss:  2.143660/  2.164300, val:  92.26%, val_best:  94.25%, tr:  87.59%, tr_best:  88.73%, epoch time: 162.39 seconds, 2.71 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-53  lr=['0.0002441'], tr/val_loss:  2.143783/  2.161769, val:  84.96%, val_best:  94.25%, tr:  88.11%, tr_best:  88.73%, epoch time: 162.71 seconds, 2.71 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-54  lr=['0.0002441'], tr/val_loss:  2.143125/  2.161029, val:  92.04%, val_best:  94.25%, tr:  88.36%, tr_best:  88.73%, epoch time: 163.61 seconds, 2.73 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-55  lr=['0.0002441'], tr/val_loss:  2.142999/  2.163013, val:  87.39%, val_best:  94.25%, tr:  87.92%, tr_best:  88.73%, epoch time: 163.08 seconds, 2.72 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-56  lr=['0.0002441'], tr/val_loss:  2.143371/  2.161888, val:  93.14%, val_best:  94.25%, tr:  87.44%, tr_best:  88.73%, epoch time: 163.51 seconds, 2.73 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-57  lr=['0.0002441'], tr/val_loss:  2.142860/  2.165050, val:  81.19%, val_best:  94.25%, tr:  87.99%, tr_best:  88.73%, epoch time: 163.25 seconds, 2.72 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-58  lr=['0.0002441'], tr/val_loss:  2.142843/  2.156330, val:  73.23%, val_best:  94.25%, tr:  87.77%, tr_best:  88.73%, epoch time: 163.82 seconds, 2.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-59  lr=['0.0002441'], tr/val_loss:  2.143437/  2.157546, val:  86.50%, val_best:  94.25%, tr:  87.44%, tr_best:  88.73%, epoch time: 161.98 seconds, 2.70 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-60  lr=['0.0002441'], tr/val_loss:  2.143021/  2.159006, val:  75.66%, val_best:  94.25%, tr:  89.06%, tr_best:  89.06%, epoch time: 161.95 seconds, 2.70 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-61  lr=['0.0002441'], tr/val_loss:  2.142708/  2.155972, val:  53.32%, val_best:  94.25%, tr:  87.17%, tr_best:  89.06%, epoch time: 162.70 seconds, 2.71 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-62  lr=['0.0002441'], tr/val_loss:  2.143899/  2.154302, val:  70.80%, val_best:  94.25%, tr:  87.67%, tr_best:  89.06%, epoch time: 163.13 seconds, 2.72 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-63  lr=['0.0002441'], tr/val_loss:  2.143479/  2.169780, val:  58.19%, val_best:  94.25%, tr:  88.19%, tr_best:  89.06%, epoch time: 164.37 seconds, 2.74 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-64  lr=['0.0002441'], tr/val_loss:  2.143326/  2.164969, val:  89.82%, val_best:  94.25%, tr:  86.95%, tr_best:  89.06%, epoch time: 161.61 seconds, 2.69 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-65  lr=['0.0002441'], tr/val_loss:  2.143369/  2.155795, val:  83.41%, val_best:  94.25%, tr:  87.92%, tr_best:  89.06%, epoch time: 162.67 seconds, 2.71 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-66  lr=['0.0002441'], tr/val_loss:  2.143027/  2.161628, val:  92.26%, val_best:  94.25%, tr:  88.56%, tr_best:  89.06%, epoch time: 163.47 seconds, 2.72 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-67  lr=['0.0002441'], tr/val_loss:  2.142707/  2.159248, val:  93.14%, val_best:  94.25%, tr:  87.77%, tr_best:  89.06%, epoch time: 163.98 seconds, 2.73 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-68  lr=['0.0002441'], tr/val_loss:  2.143088/  2.159026, val:  89.60%, val_best:  94.25%, tr:  87.82%, tr_best:  89.06%, epoch time: 163.87 seconds, 2.73 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-69  lr=['0.0002441'], tr/val_loss:  2.143154/  2.159819, val:  94.03%, val_best:  94.25%, tr:  87.52%, tr_best:  89.06%, epoch time: 160.94 seconds, 2.68 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-70  lr=['0.0002441'], tr/val_loss:  2.143759/  2.156551, val:  73.23%, val_best:  94.25%, tr:  88.66%, tr_best:  89.06%, epoch time: 163.36 seconds, 2.72 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-71  lr=['0.0002441'], tr/val_loss:  2.144469/  2.160546, val:  88.94%, val_best:  94.25%, tr:  87.67%, tr_best:  89.06%, epoch time: 163.97 seconds, 2.73 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-72  lr=['0.0002441'], tr/val_loss:  2.145200/  2.164872, val:  91.37%, val_best:  94.25%, tr:  87.59%, tr_best:  89.06%, epoch time: 162.65 seconds, 2.71 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-73  lr=['0.0002441'], tr/val_loss:  2.144867/  2.159830, val:  88.72%, val_best:  94.25%, tr:  88.26%, tr_best:  89.06%, epoch time: 160.45 seconds, 2.67 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-74  lr=['0.0002441'], tr/val_loss:  2.144749/  2.162451, val:  93.81%, val_best:  94.25%, tr:  87.87%, tr_best:  89.06%, epoch time: 163.31 seconds, 2.72 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-75  lr=['0.0002441'], tr/val_loss:  2.144359/  2.159458, val:  83.19%, val_best:  94.25%, tr:  86.97%, tr_best:  89.06%, epoch time: 162.83 seconds, 2.71 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-76  lr=['0.0002441'], tr/val_loss:  2.144419/  2.162538, val:  91.81%, val_best:  94.25%, tr:  87.47%, tr_best:  89.06%, epoch time: 163.99 seconds, 2.73 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-77  lr=['0.0002441'], tr/val_loss:  2.144676/  2.156265, val:  79.42%, val_best:  94.25%, tr:  87.44%, tr_best:  89.06%, epoch time: 163.94 seconds, 2.73 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-78  lr=['0.0002441'], tr/val_loss:  2.144061/  2.169125, val:  60.18%, val_best:  94.25%, tr:  87.74%, tr_best:  89.06%, epoch time: 163.68 seconds, 2.73 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-79  lr=['0.0002441'], tr/val_loss:  2.144988/  2.162529, val:  91.59%, val_best:  94.25%, tr:  87.30%, tr_best:  89.06%, epoch time: 165.34 seconds, 2.76 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-80  lr=['0.0002441'], tr/val_loss:  2.144400/  2.160052, val:  90.27%, val_best:  94.25%, tr:  87.32%, tr_best:  89.06%, epoch time: 163.05 seconds, 2.72 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-81  lr=['0.0002441'], tr/val_loss:  2.144636/  2.161714, val:  90.27%, val_best:  94.25%, tr:  87.54%, tr_best:  89.06%, epoch time: 164.76 seconds, 2.75 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-82  lr=['0.0002441'], tr/val_loss:  2.144142/  2.166966, val:  88.27%, val_best:  94.25%, tr:  87.97%, tr_best:  89.06%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-83  lr=['0.0002441'], tr/val_loss:  2.144642/  2.162684, val:  93.14%, val_best:  94.25%, tr:  87.39%, tr_best:  89.06%, epoch time: 163.29 seconds, 2.72 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-84  lr=['0.0002441'], tr/val_loss:  2.144549/  2.162790, val:  92.04%, val_best:  94.25%, tr:  87.72%, tr_best:  89.06%, epoch time: 163.51 seconds, 2.73 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-85  lr=['0.0002441'], tr/val_loss:  2.144104/  2.162073, val:  93.81%, val_best:  94.25%, tr:  87.82%, tr_best:  89.06%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-86  lr=['0.0002441'], tr/val_loss:  2.144607/  2.172818, val:  50.88%, val_best:  94.25%, tr:  88.21%, tr_best:  89.06%, epoch time: 163.07 seconds, 2.72 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-87  lr=['0.0002441'], tr/val_loss:  2.144633/  2.164672, val:  91.81%, val_best:  94.25%, tr:  88.01%, tr_best:  89.06%, epoch time: 163.25 seconds, 2.72 minutes\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-88  lr=['0.0002441'], tr/val_loss:  2.144760/  2.164366, val:  89.38%, val_best:  94.25%, tr:  87.82%, tr_best:  89.06%, epoch time: 162.73 seconds, 2.71 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-89  lr=['0.0002441'], tr/val_loss:  2.144613/  2.171142, val:  50.66%, val_best:  94.25%, tr:  87.10%, tr_best:  89.06%, epoch time: 163.81 seconds, 2.73 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-90  lr=['0.0002441'], tr/val_loss:  2.144832/  2.160074, val:  88.50%, val_best:  94.25%, tr:  88.14%, tr_best:  89.06%, epoch time: 164.09 seconds, 2.73 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-91  lr=['0.0002441'], tr/val_loss:  2.144870/  2.161097, val:  84.96%, val_best:  94.25%, tr:  87.89%, tr_best:  89.06%, epoch time: 163.08 seconds, 2.72 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-92  lr=['0.0002441'], tr/val_loss:  2.144800/  2.168207, val:  79.42%, val_best:  94.25%, tr:  87.99%, tr_best:  89.06%, epoch time: 163.96 seconds, 2.73 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-93  lr=['0.0002441'], tr/val_loss:  2.144317/  2.162431, val:  93.58%, val_best:  94.25%, tr:  88.01%, tr_best:  89.06%, epoch time: 163.45 seconds, 2.72 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-94  lr=['0.0002441'], tr/val_loss:  2.143774/  2.158953, val:  81.86%, val_best:  94.25%, tr:  88.46%, tr_best:  89.06%, epoch time: 164.04 seconds, 2.73 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-95  lr=['0.0002441'], tr/val_loss:  2.144609/  2.170411, val:  57.52%, val_best:  94.25%, tr:  86.92%, tr_best:  89.06%, epoch time: 163.99 seconds, 2.73 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-96  lr=['0.0002441'], tr/val_loss:  2.144810/  2.161868, val:  93.58%, val_best:  94.25%, tr:  87.69%, tr_best:  89.06%, epoch time: 163.77 seconds, 2.73 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-97  lr=['0.0002441'], tr/val_loss:  2.144855/  2.161752, val:  92.04%, val_best:  94.25%, tr:  88.93%, tr_best:  89.06%, epoch time: 163.96 seconds, 2.73 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-98  lr=['0.0002441'], tr/val_loss:  2.144677/  2.165191, val:  92.26%, val_best:  94.25%, tr:  88.34%, tr_best:  89.06%, epoch time: 162.81 seconds, 2.71 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-99  lr=['0.0002441'], tr/val_loss:  2.145416/  2.165220, val:  92.92%, val_best:  94.25%, tr:  87.37%, tr_best:  89.06%, epoch time: 164.30 seconds, 2.74 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-100 lr=['0.0002441'], tr/val_loss:  2.145400/  2.169560, val:  62.61%, val_best:  94.25%, tr:  87.74%, tr_best:  89.06%, epoch time: 163.57 seconds, 2.73 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-101 lr=['0.0002441'], tr/val_loss:  2.144556/  2.158764, val:  82.52%, val_best:  94.25%, tr:  87.79%, tr_best:  89.06%, epoch time: 164.11 seconds, 2.74 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-102 lr=['0.0002441'], tr/val_loss:  2.143919/  2.163834, val:  93.14%, val_best:  94.25%, tr:  87.67%, tr_best:  89.06%, epoch time: 162.98 seconds, 2.72 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-103 lr=['0.0002441'], tr/val_loss:  2.144638/  2.168112, val:  65.93%, val_best:  94.25%, tr:  87.77%, tr_best:  89.06%, epoch time: 163.06 seconds, 2.72 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-104 lr=['0.0002441'], tr/val_loss:  2.145153/  2.157843, val:  77.88%, val_best:  94.25%, tr:  88.61%, tr_best:  89.06%, epoch time: 164.43 seconds, 2.74 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-105 lr=['0.0002441'], tr/val_loss:  2.144818/  2.154135, val:  71.46%, val_best:  94.25%, tr:  87.02%, tr_best:  89.06%, epoch time: 163.60 seconds, 2.73 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-106 lr=['0.0002441'], tr/val_loss:  2.144385/  2.168278, val:  73.45%, val_best:  94.25%, tr:  88.16%, tr_best:  89.06%, epoch time: 163.82 seconds, 2.73 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-107 lr=['0.0002441'], tr/val_loss:  2.144599/  2.160777, val:  94.03%, val_best:  94.25%, tr:  87.47%, tr_best:  89.06%, epoch time: 162.98 seconds, 2.72 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-108 lr=['0.0002441'], tr/val_loss:  2.145035/  2.170639, val:  55.75%, val_best:  94.25%, tr:  87.59%, tr_best:  89.06%, epoch time: 162.44 seconds, 2.71 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-109 lr=['0.0002441'], tr/val_loss:  2.144418/  2.155558, val:  67.48%, val_best:  94.25%, tr:  87.15%, tr_best:  89.06%, epoch time: 162.28 seconds, 2.70 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 232 occurrences\n",
      "test - Value 1: 220 occurrences\n",
      "epoch-110 lr=['0.0002441'], tr/val_loss:  2.144333/  2.162898, val:  93.36%, val_best:  94.25%, tr:  87.44%, tr_best:  89.06%, epoch time: 162.53 seconds, 2.71 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 382 occurrences\n",
      "test - Value 1: 70 occurrences\n",
      "epoch-111 lr=['0.0002441'], tr/val_loss:  2.144445/  2.157596, val:  65.04%, val_best:  94.25%, tr:  87.77%, tr_best:  89.06%, epoch time: 164.58 seconds, 2.74 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-112 lr=['0.0002441'], tr/val_loss:  2.144773/  2.165457, val:  92.04%, val_best:  94.25%, tr:  87.20%, tr_best:  89.06%, epoch time: 162.97 seconds, 2.72 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-113 lr=['0.0002441'], tr/val_loss:  2.144737/  2.162139, val:  93.36%, val_best:  94.25%, tr:  87.77%, tr_best:  89.06%, epoch time: 163.69 seconds, 2.73 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-114 lr=['0.0002441'], tr/val_loss:  2.144671/  2.157187, val:  64.16%, val_best:  94.25%, tr:  87.05%, tr_best:  89.06%, epoch time: 162.77 seconds, 2.71 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-115 lr=['0.0002441'], tr/val_loss:  2.144004/  2.166432, val:  71.24%, val_best:  94.25%, tr:  87.62%, tr_best:  89.06%, epoch time: 164.18 seconds, 2.74 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-116 lr=['0.0002441'], tr/val_loss:  2.144080/  2.168101, val:  78.32%, val_best:  94.25%, tr:  87.74%, tr_best:  89.06%, epoch time: 164.23 seconds, 2.74 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-117 lr=['0.0002441'], tr/val_loss:  2.145187/  2.162167, val:  90.71%, val_best:  94.25%, tr:  87.39%, tr_best:  89.06%, epoch time: 164.94 seconds, 2.75 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-118 lr=['0.0002441'], tr/val_loss:  2.144459/  2.165119, val:  89.82%, val_best:  94.25%, tr:  86.97%, tr_best:  89.06%, epoch time: 164.12 seconds, 2.74 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-119 lr=['0.0002441'], tr/val_loss:  2.144433/  2.154702, val:  64.16%, val_best:  94.25%, tr:  87.30%, tr_best:  89.06%, epoch time: 165.22 seconds, 2.75 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-120 lr=['0.0002441'], tr/val_loss:  2.143817/  2.159796, val:  92.92%, val_best:  94.25%, tr:  87.20%, tr_best:  89.06%, epoch time: 166.19 seconds, 2.77 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-121 lr=['0.0002441'], tr/val_loss:  2.144437/  2.160346, val:  78.76%, val_best:  94.25%, tr:  88.09%, tr_best:  89.06%, epoch time: 163.98 seconds, 2.73 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-122 lr=['0.0002441'], tr/val_loss:  2.144957/  2.163859, val:  92.48%, val_best:  94.25%, tr:  87.87%, tr_best:  89.06%, epoch time: 164.55 seconds, 2.74 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-123 lr=['0.0002441'], tr/val_loss:  2.144639/  2.158215, val:  87.83%, val_best:  94.25%, tr:  87.84%, tr_best:  89.06%, epoch time: 164.86 seconds, 2.75 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-124 lr=['0.0002441'], tr/val_loss:  2.144061/  2.162704, val:  92.92%, val_best:  94.25%, tr:  87.49%, tr_best:  89.06%, epoch time: 165.01 seconds, 2.75 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-125 lr=['0.0002441'], tr/val_loss:  2.144297/  2.157009, val:  75.66%, val_best:  94.25%, tr:  86.80%, tr_best:  89.06%, epoch time: 162.94 seconds, 2.72 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-126 lr=['0.0002441'], tr/val_loss:  2.144082/  2.159035, val:  58.41%, val_best:  94.25%, tr:  87.27%, tr_best:  89.06%, epoch time: 162.52 seconds, 2.71 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-127 lr=['0.0002441'], tr/val_loss:  2.144452/  2.165611, val:  91.15%, val_best:  94.25%, tr:  88.44%, tr_best:  89.06%, epoch time: 165.50 seconds, 2.76 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-128 lr=['0.0002441'], tr/val_loss:  2.144621/  2.161605, val:  91.81%, val_best:  94.25%, tr:  86.72%, tr_best:  89.06%, epoch time: 163.47 seconds, 2.72 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-129 lr=['0.0002441'], tr/val_loss:  2.145000/  2.167073, val:  84.07%, val_best:  94.25%, tr:  87.20%, tr_best:  89.06%, epoch time: 164.49 seconds, 2.74 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-130 lr=['0.0002441'], tr/val_loss:  2.144211/  2.162324, val:  91.37%, val_best:  94.25%, tr:  87.92%, tr_best:  89.06%, epoch time: 164.52 seconds, 2.74 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-131 lr=['0.0002441'], tr/val_loss:  2.144203/  2.166298, val:  92.92%, val_best:  94.25%, tr:  87.44%, tr_best:  89.06%, epoch time: 161.51 seconds, 2.69 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-132 lr=['0.0002441'], tr/val_loss:  2.145004/  2.165004, val:  92.92%, val_best:  94.25%, tr:  87.25%, tr_best:  89.06%, epoch time: 163.12 seconds, 2.72 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-133 lr=['0.0002441'], tr/val_loss:  2.144580/  2.158251, val:  69.47%, val_best:  94.25%, tr:  88.29%, tr_best:  89.06%, epoch time: 163.86 seconds, 2.73 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-134 lr=['0.0002441'], tr/val_loss:  2.144639/  2.164127, val:  85.18%, val_best:  94.25%, tr:  86.67%, tr_best:  89.06%, epoch time: 163.98 seconds, 2.73 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 338 occurrences\n",
      "test - Value 1: 114 occurrences\n",
      "epoch-135 lr=['0.0002441'], tr/val_loss:  2.144470/  2.159181, val:  74.78%, val_best:  94.25%, tr:  88.11%, tr_best:  89.06%, epoch time: 164.27 seconds, 2.74 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-136 lr=['0.0002441'], tr/val_loss:  2.144824/  2.159932, val:  93.36%, val_best:  94.25%, tr:  87.77%, tr_best:  89.06%, epoch time: 163.55 seconds, 2.73 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-137 lr=['0.0002441'], tr/val_loss:  2.143848/  2.163844, val:  90.49%, val_best:  94.25%, tr:  88.09%, tr_best:  89.06%, epoch time: 163.55 seconds, 2.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-138 lr=['0.0002441'], tr/val_loss:  2.144389/  2.161303, val:  90.49%, val_best:  94.25%, tr:  87.30%, tr_best:  89.06%, epoch time: 163.61 seconds, 2.73 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-139 lr=['0.0002441'], tr/val_loss:  2.143802/  2.162243, val:  92.04%, val_best:  94.25%, tr:  87.47%, tr_best:  89.06%, epoch time: 163.29 seconds, 2.72 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-140 lr=['0.0002441'], tr/val_loss:  2.144130/  2.169523, val:  61.73%, val_best:  94.25%, tr:  87.49%, tr_best:  89.06%, epoch time: 163.08 seconds, 2.72 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 336 occurrences\n",
      "test - Value 1: 116 occurrences\n",
      "epoch-141 lr=['0.0002441'], tr/val_loss:  2.144491/  2.156433, val:  75.22%, val_best:  94.25%, tr:  87.49%, tr_best:  89.06%, epoch time: 163.70 seconds, 2.73 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 355 occurrences\n",
      "test - Value 1: 97 occurrences\n",
      "epoch-142 lr=['0.0002441'], tr/val_loss:  2.145169/  2.158152, val:  71.02%, val_best:  94.25%, tr:  86.82%, tr_best:  89.06%, epoch time: 164.85 seconds, 2.75 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-143 lr=['0.0002441'], tr/val_loss:  2.144989/  2.157008, val:  86.28%, val_best:  94.25%, tr:  87.72%, tr_best:  89.06%, epoch time: 161.59 seconds, 2.69 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-144 lr=['0.0002441'], tr/val_loss:  2.143488/  2.166691, val:  77.88%, val_best:  94.25%, tr:  88.19%, tr_best:  89.06%, epoch time: 162.19 seconds, 2.70 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-145 lr=['0.0002441'], tr/val_loss:  2.144357/  2.160703, val:  93.36%, val_best:  94.25%, tr:  86.95%, tr_best:  89.06%, epoch time: 164.10 seconds, 2.73 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-146 lr=['0.0002441'], tr/val_loss:  2.144311/  2.163559, val:  92.92%, val_best:  94.25%, tr:  87.99%, tr_best:  89.06%, epoch time: 163.07 seconds, 2.72 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-147 lr=['0.0002441'], tr/val_loss:  2.144308/  2.160108, val:  91.81%, val_best:  94.25%, tr:  87.64%, tr_best:  89.06%, epoch time: 162.28 seconds, 2.70 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-148 lr=['0.0002441'], tr/val_loss:  2.144049/  2.159436, val:  80.97%, val_best:  94.25%, tr:  88.06%, tr_best:  89.06%, epoch time: 163.41 seconds, 2.72 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-149 lr=['0.0002441'], tr/val_loss:  2.145027/  2.163374, val:  90.27%, val_best:  94.25%, tr:  88.16%, tr_best:  89.06%, epoch time: 163.26 seconds, 2.72 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-150 lr=['0.0002441'], tr/val_loss:  2.144242/  2.175361, val:  50.44%, val_best:  94.25%, tr:  88.81%, tr_best:  89.06%, epoch time: 164.54 seconds, 2.74 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-151 lr=['0.0002441'], tr/val_loss:  2.144825/  2.165909, val:  85.84%, val_best:  94.25%, tr:  87.99%, tr_best:  89.06%, epoch time: 164.29 seconds, 2.74 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 377 occurrences\n",
      "test - Value 1: 75 occurrences\n",
      "epoch-152 lr=['0.0002441'], tr/val_loss:  2.144270/  2.156249, val:  66.15%, val_best:  94.25%, tr:  87.74%, tr_best:  89.06%, epoch time: 162.89 seconds, 2.71 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-153 lr=['0.0002441'], tr/val_loss:  2.144418/  2.160010, val:  92.04%, val_best:  94.25%, tr:  88.19%, tr_best:  89.06%, epoch time: 162.64 seconds, 2.71 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-154 lr=['0.0002441'], tr/val_loss:  2.144153/  2.160729, val:  87.61%, val_best:  94.25%, tr:  87.30%, tr_best:  89.06%, epoch time: 161.78 seconds, 2.70 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-155 lr=['0.0002441'], tr/val_loss:  2.144486/  2.163754, val:  91.15%, val_best:  94.25%, tr:  87.07%, tr_best:  89.06%, epoch time: 164.20 seconds, 2.74 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-156 lr=['0.0002441'], tr/val_loss:  2.144618/  2.162072, val:  89.82%, val_best:  94.25%, tr:  87.17%, tr_best:  89.06%, epoch time: 163.04 seconds, 2.72 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-157 lr=['0.0002441'], tr/val_loss:  2.144527/  2.158334, val:  80.53%, val_best:  94.25%, tr:  89.01%, tr_best:  89.06%, epoch time: 162.47 seconds, 2.71 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-158 lr=['0.0002441'], tr/val_loss:  2.143945/  2.157843, val:  89.38%, val_best:  94.25%, tr:  88.21%, tr_best:  89.06%, epoch time: 163.79 seconds, 2.73 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-159 lr=['0.0002441'], tr/val_loss:  2.144185/  2.158080, val:  88.50%, val_best:  94.25%, tr:  87.79%, tr_best:  89.06%, epoch time: 163.87 seconds, 2.73 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-160 lr=['0.0002441'], tr/val_loss:  2.142898/  2.153733, val:  62.83%, val_best:  94.25%, tr:  88.14%, tr_best:  89.06%, epoch time: 163.28 seconds, 2.72 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-161 lr=['0.0002441'], tr/val_loss:  2.144088/  2.164973, val:  89.16%, val_best:  94.25%, tr:  88.59%, tr_best:  89.06%, epoch time: 162.82 seconds, 2.71 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-162 lr=['0.0002441'], tr/val_loss:  2.143379/  2.159492, val:  88.05%, val_best:  94.25%, tr:  88.04%, tr_best:  89.06%, epoch time: 163.37 seconds, 2.72 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-163 lr=['0.0002441'], tr/val_loss:  2.143860/  2.165243, val:  86.50%, val_best:  94.25%, tr:  88.19%, tr_best:  89.06%, epoch time: 163.84 seconds, 2.73 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-164 lr=['0.0002441'], tr/val_loss:  2.144115/  2.165462, val:  80.31%, val_best:  94.25%, tr:  87.99%, tr_best:  89.06%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-165 lr=['0.0002441'], tr/val_loss:  2.144456/  2.162130, val:  91.81%, val_best:  94.25%, tr:  87.67%, tr_best:  89.06%, epoch time: 163.08 seconds, 2.72 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-166 lr=['0.0002441'], tr/val_loss:  2.144741/  2.161781, val:  94.69%, val_best:  94.69%, tr:  87.77%, tr_best:  89.06%, epoch time: 162.58 seconds, 2.71 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-167 lr=['0.0002441'], tr/val_loss:  2.143976/  2.162639, val:  93.58%, val_best:  94.69%, tr:  88.68%, tr_best:  89.06%, epoch time: 162.23 seconds, 2.70 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-168 lr=['0.0002441'], tr/val_loss:  2.144553/  2.158561, val:  67.48%, val_best:  94.69%, tr:  86.60%, tr_best:  89.06%, epoch time: 162.65 seconds, 2.71 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-169 lr=['0.0002441'], tr/val_loss:  2.144132/  2.161773, val:  93.58%, val_best:  94.69%, tr:  88.44%, tr_best:  89.06%, epoch time: 160.59 seconds, 2.68 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-170 lr=['0.0002441'], tr/val_loss:  2.143891/  2.160547, val:  83.41%, val_best:  94.69%, tr:  87.94%, tr_best:  89.06%, epoch time: 163.19 seconds, 2.72 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-171 lr=['0.0002441'], tr/val_loss:  2.144327/  2.161544, val:  88.50%, val_best:  94.69%, tr:  87.79%, tr_best:  89.06%, epoch time: 161.47 seconds, 2.69 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-172 lr=['0.0002441'], tr/val_loss:  2.144353/  2.164878, val:  92.26%, val_best:  94.69%, tr:  88.41%, tr_best:  89.06%, epoch time: 162.72 seconds, 2.71 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-173 lr=['0.0002441'], tr/val_loss:  2.143961/  2.160583, val:  86.95%, val_best:  94.69%, tr:  87.97%, tr_best:  89.06%, epoch time: 162.03 seconds, 2.70 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-174 lr=['0.0002441'], tr/val_loss:  2.145892/  2.162283, val:  93.58%, val_best:  94.69%, tr:  87.34%, tr_best:  89.06%, epoch time: 162.71 seconds, 2.71 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-175 lr=['0.0002441'], tr/val_loss:  2.145578/  2.167705, val:  69.69%, val_best:  94.69%, tr:  87.57%, tr_best:  89.06%, epoch time: 159.72 seconds, 2.66 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 379 occurrences\n",
      "test - Value 1: 73 occurrences\n",
      "epoch-176 lr=['0.0002441'], tr/val_loss:  2.145547/  2.157430, val:  65.71%, val_best:  94.69%, tr:  88.98%, tr_best:  89.06%, epoch time: 159.88 seconds, 2.66 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 393 occurrences\n",
      "test - Value 1: 59 occurrences\n",
      "epoch-177 lr=['0.0002441'], tr/val_loss:  2.145767/  2.158927, val:  62.61%, val_best:  94.69%, tr:  87.54%, tr_best:  89.06%, epoch time: 161.60 seconds, 2.69 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-178 lr=['0.0002441'], tr/val_loss:  2.146201/  2.162939, val:  91.15%, val_best:  94.69%, tr:  86.97%, tr_best:  89.06%, epoch time: 163.14 seconds, 2.72 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-179 lr=['0.0002441'], tr/val_loss:  2.145798/  2.164241, val:  92.70%, val_best:  94.69%, tr:  87.37%, tr_best:  89.06%, epoch time: 162.89 seconds, 2.71 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-180 lr=['0.0002441'], tr/val_loss:  2.145858/  2.162991, val:  92.48%, val_best:  94.69%, tr:  87.87%, tr_best:  89.06%, epoch time: 163.46 seconds, 2.72 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-181 lr=['0.0002441'], tr/val_loss:  2.146030/  2.164358, val:  93.58%, val_best:  94.69%, tr:  86.72%, tr_best:  89.06%, epoch time: 163.93 seconds, 2.73 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-182 lr=['0.0002441'], tr/val_loss:  2.145940/  2.169405, val:  78.98%, val_best:  94.69%, tr:  87.34%, tr_best:  89.06%, epoch time: 164.06 seconds, 2.73 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-183 lr=['0.0002441'], tr/val_loss:  2.146040/  2.163315, val:  92.26%, val_best:  94.69%, tr:  87.87%, tr_best:  89.06%, epoch time: 163.20 seconds, 2.72 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-184 lr=['0.0002441'], tr/val_loss:  2.146042/  2.173726, val:  51.33%, val_best:  94.69%, tr:  88.39%, tr_best:  89.06%, epoch time: 163.03 seconds, 2.72 minutes\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-185 lr=['0.0002441'], tr/val_loss:  2.145809/  2.166368, val:  92.70%, val_best:  94.69%, tr:  87.42%, tr_best:  89.06%, epoch time: 164.58 seconds, 2.74 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-186 lr=['0.0002441'], tr/val_loss:  2.145309/  2.161879, val:  92.48%, val_best:  94.69%, tr:  87.69%, tr_best:  89.06%, epoch time: 164.25 seconds, 2.74 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-187 lr=['0.0002441'], tr/val_loss:  2.146033/  2.173361, val:  51.99%, val_best:  94.69%, tr:  87.72%, tr_best:  89.06%, epoch time: 162.66 seconds, 2.71 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-188 lr=['0.0002441'], tr/val_loss:  2.145986/  2.161134, val:  88.72%, val_best:  94.69%, tr:  87.54%, tr_best:  89.06%, epoch time: 163.60 seconds, 2.73 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-189 lr=['0.0002441'], tr/val_loss:  2.146105/  2.166245, val:  89.60%, val_best:  94.69%, tr:  87.72%, tr_best:  89.06%, epoch time: 164.05 seconds, 2.73 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-190 lr=['0.0002441'], tr/val_loss:  2.145866/  2.161261, val:  83.85%, val_best:  94.69%, tr:  88.19%, tr_best:  89.06%, epoch time: 164.57 seconds, 2.74 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-191 lr=['0.0002441'], tr/val_loss:  2.146016/  2.160563, val:  92.26%, val_best:  94.69%, tr:  88.14%, tr_best:  89.06%, epoch time: 164.22 seconds, 2.74 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-192 lr=['0.0002441'], tr/val_loss:  2.145873/  2.170447, val:  62.39%, val_best:  94.69%, tr:  87.67%, tr_best:  89.06%, epoch time: 164.24 seconds, 2.74 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-193 lr=['0.0002441'], tr/val_loss:  2.145390/  2.158798, val:  72.79%, val_best:  94.69%, tr:  87.77%, tr_best:  89.06%, epoch time: 164.12 seconds, 2.74 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-194 lr=['0.0002441'], tr/val_loss:  2.145927/  2.172243, val:  56.64%, val_best:  94.69%, tr:  87.30%, tr_best:  89.06%, epoch time: 163.13 seconds, 2.72 minutes\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 360 occurrences\n",
      "test - Value 1: 92 occurrences\n",
      "epoch-195 lr=['0.0002441'], tr/val_loss:  2.146177/  2.159783, val:  69.91%, val_best:  94.69%, tr:  86.67%, tr_best:  89.06%, epoch time: 165.21 seconds, 2.75 minutes\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-196 lr=['0.0002441'], tr/val_loss:  2.145840/  2.166050, val:  87.39%, val_best:  94.69%, tr:  86.82%, tr_best:  89.06%, epoch time: 160.68 seconds, 2.68 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-197 lr=['0.0002441'], tr/val_loss:  2.146417/  2.165377, val:  91.81%, val_best:  94.69%, tr:  87.25%, tr_best:  89.06%, epoch time: 163.14 seconds, 2.72 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-198 lr=['0.0002441'], tr/val_loss:  2.146151/  2.161396, val:  79.87%, val_best:  94.69%, tr:  87.05%, tr_best:  89.06%, epoch time: 164.21 seconds, 2.74 minutes\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-199 lr=['0.0002441'], tr/val_loss:  2.146522/  2.156038, val:  65.93%, val_best:  94.69%, tr:  87.94%, tr_best:  89.06%, epoch time: 163.33 seconds, 2.72 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f7e93e6073451293d171e659fd9ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñà‚ñÖ‚ñà‚ñá‚ñÅ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñà‚ñÉ‚ñá‚ñÖ‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñÉ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÇ‚ñà‚ñÖ‚ñà‚ñá‚ñÅ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñà‚ñÉ‚ñá‚ñÖ‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñÉ</td></tr><tr><td>val_loss</td><td>‚ñà‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.8794</td></tr><tr><td>tr_epoch_loss</td><td>2.14652</td></tr><tr><td>val_acc_best</td><td>0.9469</td></tr><tr><td>val_acc_now</td><td>0.65929</td></tr><tr><td>val_loss</td><td>2.15604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">driven-sweep-18</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4t5vhh7z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4t5vhh7z</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250722_172900-4t5vhh7z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vsfi3y2n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250723_023407-vsfi3y2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vsfi3y2n' target=\"_blank\">copper-sweep-25</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vsfi3y2n' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vsfi3y2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250723_023417_062', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 6, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 3, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 3\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.315826/  2.589020, val:  79.87%, val_best:  79.87%, tr:  58.54%, tr_best:  58.54%, epoch time: 266.18 seconds, 4.44 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2110 occurrences\n",
      "train - Value 1: 1920 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.378898/  2.517298, val:  75.66%, val_best:  79.87%, tr:  66.63%, tr_best:  66.63%, epoch time: 263.90 seconds, 4.40 minutes\n",
      "train - Value 0: 2178 occurrences\n",
      "train - Value 1: 1852 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.470912/  2.613890, val:  50.66%, val_best:  79.87%, tr:  68.61%, tr_best:  68.61%, epoch time: 263.56 seconds, 4.39 minutes\n",
      "train - Value 0: 2170 occurrences\n",
      "train - Value 1: 1860 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.483927/  2.406707, val:  51.99%, val_best:  79.87%, tr:  72.58%, tr_best:  72.58%, epoch time: 265.49 seconds, 4.42 minutes\n",
      "train - Value 0: 2149 occurrences\n",
      "train - Value 1: 1881 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 383 occurrences\n",
      "test - Value 1: 69 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.439693/  2.417446, val:  65.27%, val_best:  79.87%, tr:  74.24%, tr_best:  74.24%, epoch time: 262.93 seconds, 4.38 minutes\n",
      "train - Value 0: 2218 occurrences\n",
      "train - Value 1: 1812 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.483186/  2.631613, val:  50.00%, val_best:  79.87%, tr:  74.07%, tr_best:  74.24%, epoch time: 264.03 seconds, 4.40 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.537473/  2.536010, val:  70.13%, val_best:  79.87%, tr:  75.71%, tr_best:  75.71%, epoch time: 264.36 seconds, 4.41 minutes\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.598246/  2.626944, val:  64.60%, val_best:  79.87%, tr:  78.26%, tr_best:  78.26%, epoch time: 266.02 seconds, 4.43 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.551418/  2.526568, val:  77.43%, val_best:  79.87%, tr:  77.62%, tr_best:  78.26%, epoch time: 266.57 seconds, 4.44 minutes\n",
      "train - Value 0: 2102 occurrences\n",
      "train - Value 1: 1928 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.588176/  2.592387, val:  85.84%, val_best:  85.84%, tr:  79.68%, tr_best:  79.68%, epoch time: 263.97 seconds, 4.40 minutes\n",
      "train - Value 0: 2129 occurrences\n",
      "train - Value 1: 1901 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.595857/  2.501348, val:  70.35%, val_best:  85.84%, tr:  79.65%, tr_best:  79.68%, epoch time: 266.26 seconds, 4.44 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.599010/  2.584659, val:  79.87%, val_best:  85.84%, tr:  80.74%, tr_best:  80.74%, epoch time: 264.73 seconds, 4.41 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.623280/  2.547888, val:  80.31%, val_best:  85.84%, tr:  81.79%, tr_best:  81.79%, epoch time: 266.46 seconds, 4.44 minutes\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.625897/  2.638268, val:  63.50%, val_best:  85.84%, tr:  82.61%, tr_best:  82.61%, epoch time: 266.19 seconds, 4.44 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.624233/  2.713034, val:  62.39%, val_best:  85.84%, tr:  83.37%, tr_best:  83.37%, epoch time: 267.60 seconds, 4.46 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.671103/  2.422087, val:  62.83%, val_best:  85.84%, tr:  83.00%, tr_best:  83.37%, epoch time: 266.24 seconds, 4.44 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 232 occurrences\n",
      "test - Value 1: 220 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.613054/  2.769496, val:  83.19%, val_best:  85.84%, tr:  83.67%, tr_best:  83.67%, epoch time: 265.15 seconds, 4.42 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.609647/  2.780033, val:  61.73%, val_best:  85.84%, tr:  83.92%, tr_best:  83.92%, epoch time: 264.90 seconds, 4.41 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.672661/  2.715291, val:  56.42%, val_best:  85.84%, tr:  85.61%, tr_best:  85.61%, epoch time: 266.70 seconds, 4.44 minutes\n",
      "train - Value 0: 2104 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.696376/  2.771138, val:  50.00%, val_best:  85.84%, tr:  85.29%, tr_best:  85.61%, epoch time: 264.08 seconds, 4.40 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.744538/  2.642971, val:  66.15%, val_best:  85.84%, tr:  84.99%, tr_best:  85.61%, epoch time: 265.69 seconds, 4.43 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.699105/  2.554929, val:  63.50%, val_best:  85.84%, tr:  85.96%, tr_best:  85.96%, epoch time: 264.95 seconds, 4.42 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.671468/  2.690792, val:  60.62%, val_best:  85.84%, tr:  86.25%, tr_best:  86.25%, epoch time: 264.28 seconds, 4.40 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.717089/  2.674340, val:  74.34%, val_best:  85.84%, tr:  87.89%, tr_best:  87.89%, epoch time: 266.81 seconds, 4.45 minutes\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.741475/  2.665951, val:  79.20%, val_best:  85.84%, tr:  88.19%, tr_best:  88.19%, epoch time: 265.25 seconds, 4.42 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.788340/  2.853258, val:  79.42%, val_best:  85.84%, tr:  88.56%, tr_best:  88.56%, epoch time: 263.64 seconds, 4.39 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.752657/  2.777380, val:  68.36%, val_best:  85.84%, tr:  89.16%, tr_best:  89.16%, epoch time: 265.05 seconds, 4.42 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 251 occurrences\n",
      "test - Value 1: 201 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.740061/  2.678988, val:  81.64%, val_best:  85.84%, tr:  88.83%, tr_best:  89.16%, epoch time: 264.78 seconds, 4.41 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.710722/  2.876568, val:  82.96%, val_best:  85.84%, tr:  89.35%, tr_best:  89.35%, epoch time: 262.58 seconds, 4.38 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.735172/  2.793192, val:  62.83%, val_best:  85.84%, tr:  89.26%, tr_best:  89.35%, epoch time: 264.17 seconds, 4.40 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.712070/  2.713446, val:  78.54%, val_best:  85.84%, tr:  90.77%, tr_best:  90.77%, epoch time: 264.13 seconds, 4.40 minutes\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.628020/  2.553144, val:  81.42%, val_best:  85.84%, tr:  89.93%, tr_best:  90.77%, epoch time: 262.76 seconds, 4.38 minutes\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.652784/  2.706752, val:  63.27%, val_best:  85.84%, tr:  89.95%, tr_best:  90.77%, epoch time: 262.17 seconds, 4.37 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.695604/  2.595395, val:  73.67%, val_best:  85.84%, tr:  90.72%, tr_best:  90.77%, epoch time: 263.03 seconds, 4.38 minutes\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.671291/  2.767360, val:  67.48%, val_best:  85.84%, tr:  91.59%, tr_best:  91.59%, epoch time: 264.14 seconds, 4.40 minutes\n",
      "train - Value 0: 1925 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.663128/  2.639129, val:  80.09%, val_best:  85.84%, tr:  91.46%, tr_best:  91.59%, epoch time: 262.90 seconds, 4.38 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.710850/  2.676147, val:  84.51%, val_best:  85.84%, tr:  91.29%, tr_best:  91.59%, epoch time: 261.44 seconds, 4.36 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.690182/  2.768296, val:  51.99%, val_best:  85.84%, tr:  91.69%, tr_best:  91.69%, epoch time: 263.56 seconds, 4.39 minutes\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2136 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.667987/  2.586302, val:  78.76%, val_best:  85.84%, tr:  91.49%, tr_best:  91.69%, epoch time: 264.16 seconds, 4.40 minutes\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.694031/  2.748862, val:  60.18%, val_best:  85.84%, tr:  91.96%, tr_best:  91.96%, epoch time: 263.24 seconds, 4.39 minutes\n",
      "train - Value 0: 1879 occurrences\n",
      "train - Value 1: 2151 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.706612/  2.686295, val:  60.18%, val_best:  85.84%, tr:  90.22%, tr_best:  91.96%, epoch time: 261.17 seconds, 4.35 minutes\n",
      "train - Value 0: 1869 occurrences\n",
      "train - Value 1: 2161 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.692120/  2.728642, val:  52.21%, val_best:  85.84%, tr:  91.46%, tr_best:  91.96%, epoch time: 262.68 seconds, 4.38 minutes\n",
      "train - Value 0: 1910 occurrences\n",
      "train - Value 1: 2120 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.674616/  2.526743, val:  72.35%, val_best:  85.84%, tr:  88.91%, tr_best:  91.96%, epoch time: 261.26 seconds, 4.35 minutes\n",
      "train - Value 0: 1927 occurrences\n",
      "train - Value 1: 2103 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.709572/  2.600507, val:  80.09%, val_best:  85.84%, tr:  92.31%, tr_best:  92.31%, epoch time: 259.63 seconds, 4.33 minutes\n",
      "train - Value 0: 1909 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.678607/  2.704793, val:  78.98%, val_best:  85.84%, tr:  91.86%, tr_best:  92.31%, epoch time: 260.05 seconds, 4.33 minutes\n",
      "train - Value 0: 1868 occurrences\n",
      "train - Value 1: 2162 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.676877/  2.810672, val:  54.87%, val_best:  85.84%, tr:  90.84%, tr_best:  92.31%, epoch time: 260.37 seconds, 4.34 minutes\n",
      "train - Value 0: 1859 occurrences\n",
      "train - Value 1: 2171 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.709068/  2.753509, val:  61.95%, val_best:  85.84%, tr:  91.22%, tr_best:  92.31%, epoch time: 261.21 seconds, 4.35 minutes\n",
      "train - Value 0: 1864 occurrences\n",
      "train - Value 1: 2166 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.669577/  2.761026, val:  78.76%, val_best:  85.84%, tr:  92.38%, tr_best:  92.38%, epoch time: 263.15 seconds, 4.39 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 1884 occurrences\n",
      "train - Value 1: 2146 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.671655/  2.682079, val:  54.65%, val_best:  85.84%, tr:  91.74%, tr_best:  92.38%, epoch time: 262.92 seconds, 4.38 minutes\n",
      "train - Value 0: 1886 occurrences\n",
      "train - Value 1: 2144 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.668599/  2.583286, val:  71.68%, val_best:  85.84%, tr:  91.09%, tr_best:  92.38%, epoch time: 261.44 seconds, 4.36 minutes\n",
      "train - Value 0: 1927 occurrences\n",
      "train - Value 1: 2103 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.705909/  2.801167, val:  78.32%, val_best:  85.84%, tr:  92.01%, tr_best:  92.38%, epoch time: 261.37 seconds, 4.36 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.688767/  2.669282, val:  68.14%, val_best:  85.84%, tr:  92.03%, tr_best:  92.38%, epoch time: 260.54 seconds, 4.34 minutes\n",
      "train - Value 0: 1908 occurrences\n",
      "train - Value 1: 2122 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.669986/  2.640276, val:  77.65%, val_best:  85.84%, tr:  90.69%, tr_best:  92.38%, epoch time: 261.95 seconds, 4.37 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.694004/  2.692812, val:  75.00%, val_best:  85.84%, tr:  93.45%, tr_best:  93.45%, epoch time: 263.17 seconds, 4.39 minutes\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.705755/  2.788814, val:  69.25%, val_best:  85.84%, tr:  92.43%, tr_best:  93.45%, epoch time: 263.59 seconds, 4.39 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.679492/  2.663936, val:  81.42%, val_best:  85.84%, tr:  92.26%, tr_best:  93.45%, epoch time: 262.04 seconds, 4.37 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.696211/  2.764106, val:  64.82%, val_best:  85.84%, tr:  91.71%, tr_best:  93.45%, epoch time: 261.86 seconds, 4.36 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.709253/  2.723600, val:  80.31%, val_best:  85.84%, tr:  92.41%, tr_best:  93.45%, epoch time: 262.60 seconds, 4.38 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.733044/  2.661535, val:  73.67%, val_best:  85.84%, tr:  91.99%, tr_best:  93.45%, epoch time: 262.27 seconds, 4.37 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 341 occurrences\n",
      "test - Value 1: 111 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.735247/  2.569702, val:  68.81%, val_best:  85.84%, tr:  92.80%, tr_best:  93.45%, epoch time: 261.99 seconds, 4.37 minutes\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2112 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.767611/  2.705165, val:  73.67%, val_best:  85.84%, tr:  93.23%, tr_best:  93.45%, epoch time: 263.26 seconds, 4.39 minutes\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.718176/  2.761712, val:  75.22%, val_best:  85.84%, tr:  92.83%, tr_best:  93.45%, epoch time: 262.50 seconds, 4.37 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.711516/  2.715825, val:  80.53%, val_best:  85.84%, tr:  92.66%, tr_best:  93.45%, epoch time: 263.51 seconds, 4.39 minutes\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2119 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 28 occurrences\n",
      "test - Value 1: 424 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.702978/  2.861793, val:  56.19%, val_best:  85.84%, tr:  91.91%, tr_best:  93.45%, epoch time: 262.07 seconds, 4.37 minutes\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2124 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.707909/  2.604201, val:  70.80%, val_best:  85.84%, tr:  91.44%, tr_best:  93.45%, epoch time: 261.69 seconds, 4.36 minutes\n",
      "train - Value 0: 1920 occurrences\n",
      "train - Value 1: 2110 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.734881/  2.633825, val:  74.78%, val_best:  85.84%, tr:  93.23%, tr_best:  93.45%, epoch time: 263.28 seconds, 4.39 minutes\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2154 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.708084/  2.580319, val:  73.01%, val_best:  85.84%, tr:  92.63%, tr_best:  93.45%, epoch time: 264.22 seconds, 4.40 minutes\n",
      "train - Value 0: 1879 occurrences\n",
      "train - Value 1: 2151 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.613043/  2.687264, val:  58.41%, val_best:  85.84%, tr:  93.15%, tr_best:  93.45%, epoch time: 262.14 seconds, 4.37 minutes\n",
      "train - Value 0: 1869 occurrences\n",
      "train - Value 1: 2161 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.635603/  2.849604, val:  61.73%, val_best:  85.84%, tr:  93.20%, tr_best:  93.45%, epoch time: 261.78 seconds, 4.36 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.636614/  2.659351, val:  83.85%, val_best:  85.84%, tr:  94.94%, tr_best:  94.94%, epoch time: 264.04 seconds, 4.40 minutes\n",
      "train - Value 0: 1893 occurrences\n",
      "train - Value 1: 2137 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.699523/  2.790294, val:  71.02%, val_best:  85.84%, tr:  94.74%, tr_best:  94.94%, epoch time: 263.08 seconds, 4.38 minutes\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.729968/  2.847021, val:  71.02%, val_best:  85.84%, tr:  94.32%, tr_best:  94.94%, epoch time: 261.88 seconds, 4.36 minutes\n",
      "train - Value 0: 1883 occurrences\n",
      "train - Value 1: 2147 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.675085/  2.628773, val:  80.53%, val_best:  85.84%, tr:  93.25%, tr_best:  94.94%, epoch time: 260.41 seconds, 4.34 minutes\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.683795/  2.572365, val:  75.66%, val_best:  85.84%, tr:  94.57%, tr_best:  94.94%, epoch time: 262.34 seconds, 4.37 minutes\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2094 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.640171/  2.710037, val:  81.64%, val_best:  85.84%, tr:  93.28%, tr_best:  94.94%, epoch time: 262.84 seconds, 4.38 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.673837/  2.738904, val:  76.77%, val_best:  85.84%, tr:  93.82%, tr_best:  94.94%, epoch time: 263.06 seconds, 4.38 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.664080/  2.548257, val:  82.74%, val_best:  85.84%, tr:  92.95%, tr_best:  94.94%, epoch time: 262.90 seconds, 4.38 minutes\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.651327/  2.613085, val:  85.18%, val_best:  85.84%, tr:  92.08%, tr_best:  94.94%, epoch time: 263.55 seconds, 4.39 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.621509/  2.754957, val:  76.11%, val_best:  85.84%, tr:  90.72%, tr_best:  94.94%, epoch time: 263.57 seconds, 4.39 minutes\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.660798/  2.747490, val:  71.02%, val_best:  85.84%, tr:  89.40%, tr_best:  94.94%, epoch time: 262.82 seconds, 4.38 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.634104/  2.760828, val:  61.50%, val_best:  85.84%, tr:  91.27%, tr_best:  94.94%, epoch time: 262.78 seconds, 4.38 minutes\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.682013/  2.588903, val:  59.96%, val_best:  85.84%, tr:  91.89%, tr_best:  94.94%, epoch time: 262.88 seconds, 4.38 minutes\n",
      "train - Value 0: 1902 occurrences\n",
      "train - Value 1: 2128 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.646600/  2.897282, val:  51.11%, val_best:  85.84%, tr:  92.08%, tr_best:  94.94%, epoch time: 261.98 seconds, 4.37 minutes\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2081 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.668491/  2.619481, val:  71.02%, val_best:  85.84%, tr:  92.06%, tr_best:  94.94%, epoch time: 265.55 seconds, 4.43 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.643882/  2.518833, val:  67.26%, val_best:  85.84%, tr:  92.28%, tr_best:  94.94%, epoch time: 264.90 seconds, 4.42 minutes\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.696634/  2.879626, val:  72.79%, val_best:  85.84%, tr:  92.95%, tr_best:  94.94%, epoch time: 265.73 seconds, 4.43 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.630618/  2.833117, val:  50.00%, val_best:  85.84%, tr:  92.73%, tr_best:  94.94%, epoch time: 266.38 seconds, 4.44 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.649326/  2.850854, val:  52.43%, val_best:  85.84%, tr:  93.37%, tr_best:  94.94%, epoch time: 265.12 seconds, 4.42 minutes\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.669572/  2.735325, val:  67.92%, val_best:  85.84%, tr:  93.23%, tr_best:  94.94%, epoch time: 267.23 seconds, 4.45 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.673090/  2.919608, val:  50.22%, val_best:  85.84%, tr:  92.56%, tr_best:  94.94%, epoch time: 266.50 seconds, 4.44 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.720057/  2.724649, val:  67.70%, val_best:  85.84%, tr:  93.60%, tr_best:  94.94%, epoch time: 267.81 seconds, 4.46 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.667993/  2.608975, val:  76.99%, val_best:  85.84%, tr:  92.83%, tr_best:  94.94%, epoch time: 265.89 seconds, 4.43 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.680017/  2.682139, val:  78.98%, val_best:  85.84%, tr:  93.95%, tr_best:  94.94%, epoch time: 264.72 seconds, 4.41 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.670265/  2.633516, val:  61.95%, val_best:  85.84%, tr:  92.75%, tr_best:  94.94%, epoch time: 266.78 seconds, 4.45 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.649052/  2.592079, val:  55.53%, val_best:  85.84%, tr:  93.97%, tr_best:  94.94%, epoch time: 266.47 seconds, 4.44 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.660499/  2.736572, val:  58.19%, val_best:  85.84%, tr:  94.19%, tr_best:  94.94%, epoch time: 265.88 seconds, 4.43 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.687714/  2.729950, val:  66.37%, val_best:  85.84%, tr:  93.77%, tr_best:  94.94%, epoch time: 265.36 seconds, 4.42 minutes\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.697291/  2.850216, val:  75.00%, val_best:  85.84%, tr:  93.77%, tr_best:  94.94%, epoch time: 266.26 seconds, 4.44 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.705682/  2.674579, val:  65.27%, val_best:  85.84%, tr:  94.04%, tr_best:  94.94%, epoch time: 266.06 seconds, 4.43 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.679337/  2.850473, val:  53.54%, val_best:  85.84%, tr:  93.62%, tr_best:  94.94%, epoch time: 266.03 seconds, 4.43 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.757336/  2.867398, val:  50.00%, val_best:  85.84%, tr:  94.86%, tr_best:  94.94%, epoch time: 266.17 seconds, 4.44 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.700586/  2.686741, val:  82.74%, val_best:  85.84%, tr:  95.26%, tr_best:  95.26%, epoch time: 266.44 seconds, 4.44 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.738873/  2.763647, val:  61.50%, val_best:  85.84%, tr:  95.11%, tr_best:  95.26%, epoch time: 265.16 seconds, 4.42 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.685053/  2.652876, val:  65.04%, val_best:  85.84%, tr:  95.01%, tr_best:  95.26%, epoch time: 265.70 seconds, 4.43 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.691702/  2.817155, val:  78.10%, val_best:  85.84%, tr:  94.07%, tr_best:  95.26%, epoch time: 267.13 seconds, 4.45 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.733816/  2.754711, val:  54.20%, val_best:  85.84%, tr:  95.58%, tr_best:  95.58%, epoch time: 265.34 seconds, 4.42 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.665923/  2.751446, val:  59.07%, val_best:  85.84%, tr:  93.18%, tr_best:  95.58%, epoch time: 263.45 seconds, 4.39 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.696946/  2.549771, val:  85.84%, val_best:  85.84%, tr:  93.85%, tr_best:  95.58%, epoch time: 265.06 seconds, 4.42 minutes\n",
      "train - Value 0: 1874 occurrences\n",
      "train - Value 1: 2156 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.732230/  2.724782, val:  50.66%, val_best:  85.84%, tr:  91.79%, tr_best:  95.58%, epoch time: 264.66 seconds, 4.41 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.659107/  2.430678, val:  66.37%, val_best:  85.84%, tr:  93.05%, tr_best:  95.58%, epoch time: 266.29 seconds, 4.44 minutes\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.688957/  2.567673, val:  81.86%, val_best:  85.84%, tr:  93.33%, tr_best:  95.58%, epoch time: 266.32 seconds, 4.44 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.674283/  2.555208, val:  80.31%, val_best:  85.84%, tr:  94.17%, tr_best:  95.58%, epoch time: 264.97 seconds, 4.42 minutes\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.649698/  2.592578, val:  71.68%, val_best:  85.84%, tr:  93.52%, tr_best:  95.58%, epoch time: 263.90 seconds, 4.40 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.630342/  2.841511, val:  60.18%, val_best:  85.84%, tr:  93.08%, tr_best:  95.58%, epoch time: 265.95 seconds, 4.43 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.637167/  2.671877, val:  80.09%, val_best:  85.84%, tr:  94.76%, tr_best:  95.58%, epoch time: 266.46 seconds, 4.44 minutes\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  2.589823/  2.671205, val:  64.16%, val_best:  85.84%, tr:  94.57%, tr_best:  95.58%, epoch time: 264.35 seconds, 4.41 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  2.633358/  2.648427, val:  57.08%, val_best:  85.84%, tr:  93.65%, tr_best:  95.58%, epoch time: 263.49 seconds, 4.39 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  2.714040/  2.533130, val:  75.88%, val_best:  85.84%, tr:  94.52%, tr_best:  95.58%, epoch time: 264.52 seconds, 4.41 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  2.701840/  2.825950, val:  61.06%, val_best:  85.84%, tr:  92.78%, tr_best:  95.58%, epoch time: 264.57 seconds, 4.41 minutes\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  2.739915/  2.452688, val:  70.13%, val_best:  85.84%, tr:  92.66%, tr_best:  95.58%, epoch time: 264.62 seconds, 4.41 minutes\n",
      "train - Value 0: 1937 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  2.767749/  2.722070, val:  51.99%, val_best:  85.84%, tr:  94.14%, tr_best:  95.58%, epoch time: 264.41 seconds, 4.41 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  2.719747/  2.575390, val:  82.30%, val_best:  85.84%, tr:  92.66%, tr_best:  95.58%, epoch time: 264.06 seconds, 4.40 minutes\n",
      "train - Value 0: 1879 occurrences\n",
      "train - Value 1: 2151 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  2.743661/  2.658243, val:  62.83%, val_best:  85.84%, tr:  92.95%, tr_best:  95.58%, epoch time: 265.12 seconds, 4.42 minutes\n",
      "train - Value 0: 1872 occurrences\n",
      "train - Value 1: 2158 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  2.771233/  2.820233, val:  72.35%, val_best:  85.84%, tr:  93.47%, tr_best:  95.58%, epoch time: 264.23 seconds, 4.40 minutes\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  2.736498/  2.783032, val:  59.73%, val_best:  85.84%, tr:  94.59%, tr_best:  95.58%, epoch time: 265.96 seconds, 4.43 minutes\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 307 occurrences\n",
      "test - Value 1: 145 occurrences\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  2.741392/  2.634971, val:  78.54%, val_best:  85.84%, tr:  94.07%, tr_best:  95.58%, epoch time: 264.94 seconds, 4.42 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  2.768119/  2.893983, val:  66.15%, val_best:  85.84%, tr:  94.54%, tr_best:  95.58%, epoch time: 263.79 seconds, 4.40 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  2.804921/  3.043282, val:  57.08%, val_best:  85.84%, tr:  94.39%, tr_best:  95.58%, epoch time: 263.11 seconds, 4.39 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  2.786048/  2.678886, val:  84.73%, val_best:  85.84%, tr:  94.96%, tr_best:  95.58%, epoch time: 263.39 seconds, 4.39 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 89 occurrences\n",
      "test - Value 1: 363 occurrences\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  2.787053/  2.785043, val:  67.04%, val_best:  85.84%, tr:  94.64%, tr_best:  95.58%, epoch time: 265.26 seconds, 4.42 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  2.786386/  2.810620, val:  64.60%, val_best:  85.84%, tr:  94.27%, tr_best:  95.58%, epoch time: 262.49 seconds, 4.37 minutes\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  2.805538/  2.644387, val:  78.76%, val_best:  85.84%, tr:  94.71%, tr_best:  95.58%, epoch time: 263.37 seconds, 4.39 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  2.777056/  2.874723, val:  52.21%, val_best:  85.84%, tr:  94.59%, tr_best:  95.58%, epoch time: 263.21 seconds, 4.39 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 332 occurrences\n",
      "test - Value 1: 120 occurrences\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  2.777081/  2.499245, val:  73.01%, val_best:  85.84%, tr:  93.90%, tr_best:  95.58%, epoch time: 262.25 seconds, 4.37 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  2.635862/  2.749087, val:  57.96%, val_best:  85.84%, tr:  94.34%, tr_best:  95.58%, epoch time: 263.67 seconds, 4.39 minutes\n",
      "train - Value 0: 1927 occurrences\n",
      "train - Value 1: 2103 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  2.689060/  2.650885, val:  83.19%, val_best:  85.84%, tr:  94.69%, tr_best:  95.58%, epoch time: 263.81 seconds, 4.40 minutes\n",
      "train - Value 0: 1925 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  2.694909/  2.615044, val:  75.44%, val_best:  85.84%, tr:  94.74%, tr_best:  95.58%, epoch time: 263.54 seconds, 4.39 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  2.715950/  2.684514, val:  77.65%, val_best:  85.84%, tr:  95.58%, tr_best:  95.58%, epoch time: 264.82 seconds, 4.41 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  2.690504/  2.495538, val:  71.24%, val_best:  85.84%, tr:  95.48%, tr_best:  95.58%, epoch time: 265.25 seconds, 4.42 minutes\n",
      "train - Value 0: 1920 occurrences\n",
      "train - Value 1: 2110 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  2.638887/  2.513659, val:  85.40%, val_best:  85.84%, tr:  94.67%, tr_best:  95.58%, epoch time: 262.19 seconds, 4.37 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  2.666597/  2.694020, val:  53.32%, val_best:  85.84%, tr:  94.96%, tr_best:  95.58%, epoch time: 262.95 seconds, 4.38 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  2.694746/  2.579368, val:  74.78%, val_best:  85.84%, tr:  95.01%, tr_best:  95.58%, epoch time: 263.89 seconds, 4.40 minutes\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  2.674474/  2.622528, val:  77.21%, val_best:  85.84%, tr:  94.94%, tr_best:  95.58%, epoch time: 263.13 seconds, 4.39 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 361 occurrences\n",
      "test - Value 1: 91 occurrences\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  2.682884/  2.418062, val:  67.92%, val_best:  85.84%, tr:  94.37%, tr_best:  95.58%, epoch time: 262.39 seconds, 4.37 minutes\n",
      "train - Value 0: 1938 occurrences\n",
      "train - Value 1: 2092 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  2.677357/  2.786284, val:  82.08%, val_best:  85.84%, tr:  95.46%, tr_best:  95.58%, epoch time: 265.30 seconds, 4.42 minutes\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2107 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  2.666886/  2.581698, val:  83.85%, val_best:  85.84%, tr:  94.79%, tr_best:  95.58%, epoch time: 263.02 seconds, 4.38 minutes\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  2.709284/  2.626570, val:  77.43%, val_best:  85.84%, tr:  94.74%, tr_best:  95.58%, epoch time: 263.43 seconds, 4.39 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  2.659492/  2.797708, val:  53.10%, val_best:  85.84%, tr:  94.79%, tr_best:  95.58%, epoch time: 263.76 seconds, 4.40 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  2.650656/  2.733094, val:  64.38%, val_best:  85.84%, tr:  94.79%, tr_best:  95.58%, epoch time: 262.50 seconds, 4.37 minutes\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  2.638304/  2.725207, val:  60.18%, val_best:  85.84%, tr:  94.67%, tr_best:  95.58%, epoch time: 264.12 seconds, 4.40 minutes\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  2.636729/  2.760707, val:  63.50%, val_best:  85.84%, tr:  94.74%, tr_best:  95.58%, epoch time: 265.19 seconds, 4.42 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  2.621668/  2.560080, val:  75.22%, val_best:  85.84%, tr:  94.62%, tr_best:  95.58%, epoch time: 264.20 seconds, 4.40 minutes\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  2.727855/  2.823843, val:  63.72%, val_best:  85.84%, tr:  96.38%, tr_best:  96.38%, epoch time: 264.54 seconds, 4.41 minutes\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2112 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  2.670987/  2.563638, val:  83.19%, val_best:  85.84%, tr:  95.61%, tr_best:  96.38%, epoch time: 264.46 seconds, 4.41 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  2.686589/  2.616112, val:  79.20%, val_best:  85.84%, tr:  95.38%, tr_best:  96.38%, epoch time: 265.79 seconds, 4.43 minutes\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2084 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  2.705530/  2.681471, val:  81.42%, val_best:  85.84%, tr:  94.81%, tr_best:  96.38%, epoch time: 266.41 seconds, 4.44 minutes\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2119 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  2.681658/  2.579837, val:  72.57%, val_best:  85.84%, tr:  95.09%, tr_best:  96.38%, epoch time: 265.37 seconds, 4.42 minutes\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  2.686296/  2.659386, val:  80.53%, val_best:  85.84%, tr:  95.63%, tr_best:  96.38%, epoch time: 265.62 seconds, 4.43 minutes\n",
      "train - Value 0: 1878 occurrences\n",
      "train - Value 1: 2152 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  2.724425/  2.666692, val:  78.54%, val_best:  85.84%, tr:  94.67%, tr_best:  96.38%, epoch time: 264.32 seconds, 4.41 minutes\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  2.723189/  2.635675, val:  83.63%, val_best:  85.84%, tr:  94.76%, tr_best:  96.38%, epoch time: 265.29 seconds, 4.42 minutes\n",
      "train - Value 0: 1912 occurrences\n",
      "train - Value 1: 2118 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  2.737149/  2.673549, val:  75.66%, val_best:  85.84%, tr:  95.91%, tr_best:  96.38%, epoch time: 267.87 seconds, 4.46 minutes\n",
      "train - Value 0: 1885 occurrences\n",
      "train - Value 1: 2145 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  2.710495/  2.827137, val:  52.88%, val_best:  85.84%, tr:  94.99%, tr_best:  96.38%, epoch time: 265.29 seconds, 4.42 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  2.737760/  2.700580, val:  74.56%, val_best:  85.84%, tr:  95.68%, tr_best:  96.38%, epoch time: 265.71 seconds, 4.43 minutes\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  2.672118/  2.663031, val:  69.91%, val_best:  85.84%, tr:  95.61%, tr_best:  96.38%, epoch time: 265.31 seconds, 4.42 minutes\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  2.679879/  2.688951, val:  76.99%, val_best:  85.84%, tr:  96.35%, tr_best:  96.38%, epoch time: 264.51 seconds, 4.41 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  2.661898/  2.424072, val:  58.63%, val_best:  85.84%, tr:  94.84%, tr_best:  96.38%, epoch time: 263.53 seconds, 4.39 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  2.667356/  2.695458, val:  75.22%, val_best:  85.84%, tr:  93.95%, tr_best:  96.38%, epoch time: 263.98 seconds, 4.40 minutes\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  2.661598/  2.620839, val:  73.67%, val_best:  85.84%, tr:  94.69%, tr_best:  96.38%, epoch time: 264.97 seconds, 4.42 minutes\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  2.583540/  2.636010, val:  76.33%, val_best:  85.84%, tr:  94.64%, tr_best:  96.38%, epoch time: 260.78 seconds, 4.35 minutes\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  2.659431/  2.743449, val:  60.18%, val_best:  85.84%, tr:  95.33%, tr_best:  96.38%, epoch time: 263.05 seconds, 4.38 minutes\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  2.631020/  2.714840, val:  65.04%, val_best:  85.84%, tr:  95.16%, tr_best:  96.38%, epoch time: 264.24 seconds, 4.40 minutes\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  2.685858/  2.658776, val:  80.97%, val_best:  85.84%, tr:  95.71%, tr_best:  96.38%, epoch time: 264.01 seconds, 4.40 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  2.641795/  2.737202, val:  58.85%, val_best:  85.84%, tr:  96.10%, tr_best:  96.38%, epoch time: 261.66 seconds, 4.36 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  2.699184/  2.754881, val:  69.69%, val_best:  85.84%, tr:  95.16%, tr_best:  96.38%, epoch time: 262.55 seconds, 4.38 minutes\n",
      "train - Value 0: 1938 occurrences\n",
      "train - Value 1: 2092 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  2.676814/  2.633596, val:  72.35%, val_best:  85.84%, tr:  95.51%, tr_best:  96.38%, epoch time: 263.84 seconds, 4.40 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  2.678545/  2.721067, val:  54.20%, val_best:  85.84%, tr:  96.03%, tr_best:  96.38%, epoch time: 262.00 seconds, 4.37 minutes\n",
      "train - Value 0: 1938 occurrences\n",
      "train - Value 1: 2092 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  2.639844/  2.483620, val:  82.30%, val_best:  85.84%, tr:  95.56%, tr_best:  96.38%, epoch time: 262.79 seconds, 4.38 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  2.617079/  2.696312, val:  52.88%, val_best:  85.84%, tr:  95.09%, tr_best:  96.38%, epoch time: 262.06 seconds, 4.37 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  2.509757/  2.714517, val:  52.65%, val_best:  85.84%, tr:  95.53%, tr_best:  96.38%, epoch time: 262.88 seconds, 4.38 minutes\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  2.520383/  2.525777, val:  50.88%, val_best:  85.84%, tr:  95.76%, tr_best:  96.38%, epoch time: 263.42 seconds, 4.39 minutes\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  2.383702/  2.532179, val:  77.65%, val_best:  85.84%, tr:  95.73%, tr_best:  96.38%, epoch time: 266.62 seconds, 4.44 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  2.436906/  2.719003, val:  59.07%, val_best:  85.84%, tr:  96.18%, tr_best:  96.38%, epoch time: 261.25 seconds, 4.35 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  2.453269/  2.703968, val:  76.55%, val_best:  85.84%, tr:  95.76%, tr_best:  96.38%, epoch time: 263.84 seconds, 4.40 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  2.446622/  2.581008, val:  55.53%, val_best:  85.84%, tr:  96.08%, tr_best:  96.38%, epoch time: 260.49 seconds, 4.34 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  2.390618/  2.398039, val:  84.96%, val_best:  85.84%, tr:  95.63%, tr_best:  96.38%, epoch time: 265.44 seconds, 4.42 minutes\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  2.411898/  2.414913, val:  61.28%, val_best:  85.84%, tr:  96.58%, tr_best:  96.58%, epoch time: 255.88 seconds, 4.26 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  2.418241/  2.489044, val:  67.70%, val_best:  85.84%, tr:  95.53%, tr_best:  96.58%, epoch time: 262.91 seconds, 4.38 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  2.526289/  2.652668, val:  55.97%, val_best:  85.84%, tr:  96.10%, tr_best:  96.58%, epoch time: 263.01 seconds, 4.38 minutes\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  2.503926/  2.386902, val:  84.51%, val_best:  85.84%, tr:  95.09%, tr_best:  96.58%, epoch time: 261.89 seconds, 4.36 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  2.478157/  2.622799, val:  65.49%, val_best:  85.84%, tr:  94.57%, tr_best:  96.58%, epoch time: 266.83 seconds, 4.45 minutes\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  2.526654/  2.346550, val:  77.65%, val_best:  85.84%, tr:  94.86%, tr_best:  96.58%, epoch time: 266.84 seconds, 4.45 minutes\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2107 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  2.519375/  2.485350, val:  81.86%, val_best:  85.84%, tr:  95.48%, tr_best:  96.58%, epoch time: 267.34 seconds, 4.46 minutes\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  2.519453/  2.670483, val:  51.99%, val_best:  85.84%, tr:  95.76%, tr_best:  96.58%, epoch time: 264.04 seconds, 4.40 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  2.587210/  2.602953, val:  83.41%, val_best:  85.84%, tr:  96.45%, tr_best:  96.58%, epoch time: 265.09 seconds, 4.42 minutes\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  2.584860/  2.636111, val:  71.24%, val_best:  85.84%, tr:  95.93%, tr_best:  96.58%, epoch time: 265.78 seconds, 4.43 minutes\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  2.514480/  2.463711, val:  81.64%, val_best:  85.84%, tr:  95.11%, tr_best:  96.58%, epoch time: 266.38 seconds, 4.44 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  2.535931/  2.577269, val:  79.20%, val_best:  85.84%, tr:  95.38%, tr_best:  96.58%, epoch time: 265.27 seconds, 4.42 minutes\n",
      "train - Value 0: 1897 occurrences\n",
      "train - Value 1: 2133 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  2.508347/  2.428179, val:  79.87%, val_best:  85.84%, tr:  95.58%, tr_best:  96.58%, epoch time: 265.54 seconds, 4.43 minutes\n",
      "train - Value 0: 1871 occurrences\n",
      "train - Value 1: 2159 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  2.494091/  2.485757, val:  72.35%, val_best:  85.84%, tr:  95.33%, tr_best:  96.58%, epoch time: 266.23 seconds, 4.44 minutes\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2154 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  2.548997/  2.590914, val:  88.05%, val_best:  88.05%, tr:  95.46%, tr_best:  96.58%, epoch time: 264.44 seconds, 4.41 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1224cce731774eac94b558df0a8a3b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÑ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÜ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà</td></tr><tr><td>val_loss</td><td>‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.95459</td></tr><tr><td>tr_epoch_loss</td><td>2.549</td></tr><tr><td>val_acc_best</td><td>0.88053</td></tr><tr><td>val_acc_now</td><td>0.88053</td></tr><tr><td>val_loss</td><td>2.59091</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-25</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vsfi3y2n' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vsfi3y2n</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250723_023407-vsfi3y2n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6ohznh6c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009765625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250723_171506-6ohznh6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6ohznh6c' target=\"_blank\">wise-sweep-41</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6ohznh6c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6ohznh6c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250723_171515_434', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 3, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-13, -13], [-13, -13], [-12, -12]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 3\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -13\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-13, -13], [-13, -13], [-12, -12]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2102 occurrences\n",
      "train - Value 1: 1928 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 308 occurrences\n",
      "test - Value 1: 144 occurrences\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  2.308359/  2.347628, val:  76.11%, val_best:  76.11%, tr:  56.70%, tr_best:  56.70%, epoch time: 266.55 seconds, 4.44 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2113 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  2.255488/  2.189008, val:  49.34%, val_best:  76.11%, tr:  58.96%, tr_best:  58.96%, epoch time: 266.69 seconds, 4.44 minutes\n",
      "train - Value 0: 2085 occurrences\n",
      "train - Value 1: 1945 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  2.203933/  2.168978, val:  50.00%, val_best:  76.11%, tr:  59.80%, tr_best:  59.80%, epoch time: 267.33 seconds, 4.46 minutes\n",
      "train - Value 0: 2167 occurrences\n",
      "train - Value 1: 1863 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  2.220188/  2.276527, val:  50.00%, val_best:  76.11%, tr:  58.86%, tr_best:  59.80%, epoch time: 264.80 seconds, 4.41 minutes\n",
      "train - Value 0: 2122 occurrences\n",
      "train - Value 1: 1908 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 313 occurrences\n",
      "test - Value 1: 139 occurrences\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  2.257423/  2.148500, val:  71.02%, val_best:  76.11%, tr:  58.68%, tr_best:  59.80%, epoch time: 265.70 seconds, 4.43 minutes\n",
      "train - Value 0: 2144 occurrences\n",
      "train - Value 1: 1886 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  2.236778/  2.263079, val:  50.00%, val_best:  76.11%, tr:  59.13%, tr_best:  59.80%, epoch time: 265.74 seconds, 4.43 minutes\n",
      "train - Value 0: 2118 occurrences\n",
      "train - Value 1: 1912 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  2.236729/  2.167889, val:  67.26%, val_best:  76.11%, tr:  60.92%, tr_best:  60.92%, epoch time: 266.56 seconds, 4.44 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  2.299613/  2.340761, val:  50.00%, val_best:  76.11%, tr:  61.44%, tr_best:  61.44%, epoch time: 266.88 seconds, 4.45 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  2.295333/  2.313517, val:  50.00%, val_best:  76.11%, tr:  60.89%, tr_best:  61.44%, epoch time: 267.68 seconds, 4.46 minutes\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  2.285988/  2.365557, val:  47.79%, val_best:  76.11%, tr:  61.81%, tr_best:  61.81%, epoch time: 266.21 seconds, 4.44 minutes\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1939 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  2.333567/  2.357526, val:  51.11%, val_best:  76.11%, tr:  59.70%, tr_best:  61.81%, epoch time: 266.08 seconds, 4.43 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  2.304604/  2.300339, val:  55.09%, val_best:  76.11%, tr:  60.92%, tr_best:  61.81%, epoch time: 266.63 seconds, 4.44 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  2.247423/  2.173283, val:  50.00%, val_best:  76.11%, tr:  59.88%, tr_best:  61.81%, epoch time: 263.80 seconds, 4.40 minutes\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  2.234894/  2.317202, val:  50.00%, val_best:  76.11%, tr:  58.66%, tr_best:  61.81%, epoch time: 267.02 seconds, 4.45 minutes\n",
      "train - Value 0: 1904 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  2.280069/  2.293784, val:  50.00%, val_best:  76.11%, tr:  58.93%, tr_best:  61.81%, epoch time: 268.07 seconds, 4.47 minutes\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  2.309032/  2.314095, val:  65.71%, val_best:  76.11%, tr:  59.93%, tr_best:  61.81%, epoch time: 266.09 seconds, 4.43 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 369 occurrences\n",
      "test - Value 1: 83 occurrences\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  2.300839/  2.212226, val:  67.92%, val_best:  76.11%, tr:  59.38%, tr_best:  61.81%, epoch time: 267.21 seconds, 4.45 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  2.361336/  2.311337, val:  65.27%, val_best:  76.11%, tr:  61.04%, tr_best:  61.81%, epoch time: 267.21 seconds, 4.45 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  2.368472/  2.391162, val:  50.00%, val_best:  76.11%, tr:  60.65%, tr_best:  61.81%, epoch time: 269.56 seconds, 4.49 minutes\n",
      "train - Value 0: 2101 occurrences\n",
      "train - Value 1: 1929 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  2.384800/  2.293121, val:  50.00%, val_best:  76.11%, tr:  62.48%, tr_best:  62.48%, epoch time: 267.87 seconds, 4.46 minutes\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  2.210355/  2.309488, val:  57.52%, val_best:  76.11%, tr:  60.57%, tr_best:  62.48%, epoch time: 267.97 seconds, 4.47 minutes\n",
      "train - Value 0: 2159 occurrences\n",
      "train - Value 1: 1871 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  2.298265/  2.364680, val:  56.42%, val_best:  76.11%, tr:  59.60%, tr_best:  62.48%, epoch time: 263.21 seconds, 4.39 minutes\n",
      "train - Value 0: 2183 occurrences\n",
      "train - Value 1: 1847 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  2.318266/  2.322791, val:  50.00%, val_best:  76.11%, tr:  58.81%, tr_best:  62.48%, epoch time: 268.03 seconds, 4.47 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  2.391187/  2.353659, val:  51.33%, val_best:  76.11%, tr:  62.63%, tr_best:  62.63%, epoch time: 263.62 seconds, 4.39 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  2.349630/  2.382170, val:  50.00%, val_best:  76.11%, tr:  60.40%, tr_best:  62.63%, epoch time: 267.07 seconds, 4.45 minutes\n",
      "train - Value 0: 2114 occurrences\n",
      "train - Value 1: 1916 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  2.370551/  2.202216, val:  50.22%, val_best:  76.11%, tr:  62.26%, tr_best:  62.63%, epoch time: 268.04 seconds, 4.47 minutes\n",
      "train - Value 0: 2203 occurrences\n",
      "train - Value 1: 1827 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  2.325671/  2.245300, val:  59.51%, val_best:  76.11%, tr:  61.29%, tr_best:  62.63%, epoch time: 268.14 seconds, 4.47 minutes\n",
      "train - Value 0: 2231 occurrences\n",
      "train - Value 1: 1799 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  2.346721/  2.385438, val:  68.81%, val_best:  76.11%, tr:  61.34%, tr_best:  62.63%, epoch time: 264.06 seconds, 4.40 minutes\n",
      "train - Value 0: 2134 occurrences\n",
      "train - Value 1: 1896 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  2.232864/  2.043776, val:  50.00%, val_best:  76.11%, tr:  59.73%, tr_best:  62.63%, epoch time: 261.64 seconds, 4.36 minutes\n",
      "train - Value 0: 2254 occurrences\n",
      "train - Value 1: 1776 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  2.160356/  2.281199, val:  53.98%, val_best:  76.11%, tr:  61.86%, tr_best:  62.63%, epoch time: 262.72 seconds, 4.38 minutes\n",
      "train - Value 0: 2167 occurrences\n",
      "train - Value 1: 1863 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  2.167720/  2.094233, val:  53.76%, val_best:  76.11%, tr:  62.48%, tr_best:  62.63%, epoch time: 261.43 seconds, 4.36 minutes\n",
      "train - Value 0: 2203 occurrences\n",
      "train - Value 1: 1827 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  2.219501/  2.137100, val:  50.00%, val_best:  76.11%, tr:  61.79%, tr_best:  62.63%, epoch time: 261.60 seconds, 4.36 minutes\n",
      "train - Value 0: 2204 occurrences\n",
      "train - Value 1: 1826 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  2.290504/  2.549716, val:  50.00%, val_best:  76.11%, tr:  61.17%, tr_best:  62.63%, epoch time: 266.54 seconds, 4.44 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  2.492500/  2.115467, val:  50.00%, val_best:  76.11%, tr:  61.59%, tr_best:  62.63%, epoch time: 266.48 seconds, 4.44 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 341 occurrences\n",
      "test - Value 1: 111 occurrences\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  2.236453/  2.117321, val:  70.13%, val_best:  76.11%, tr:  63.15%, tr_best:  63.15%, epoch time: 262.54 seconds, 4.38 minutes\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  2.204709/  2.128374, val:  54.65%, val_best:  76.11%, tr:  62.80%, tr_best:  63.15%, epoch time: 264.99 seconds, 4.42 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  2.160599/  2.074716, val:  50.00%, val_best:  76.11%, tr:  60.74%, tr_best:  63.15%, epoch time: 262.53 seconds, 4.38 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  2.144650/  2.353212, val:  50.00%, val_best:  76.11%, tr:  61.81%, tr_best:  63.15%, epoch time: 260.42 seconds, 4.34 minutes\n",
      "train - Value 0: 2232 occurrences\n",
      "train - Value 1: 1798 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  2.234150/  2.306564, val:  50.00%, val_best:  76.11%, tr:  63.20%, tr_best:  63.20%, epoch time: 260.91 seconds, 4.35 minutes\n",
      "train - Value 0: 2245 occurrences\n",
      "train - Value 1: 1785 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  2.243231/  2.237671, val:  71.90%, val_best:  76.11%, tr:  62.93%, tr_best:  63.20%, epoch time: 266.22 seconds, 4.44 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  2.175457/  2.252904, val:  50.00%, val_best:  76.11%, tr:  62.08%, tr_best:  63.20%, epoch time: 264.46 seconds, 4.41 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  2.157820/  2.310130, val:  50.00%, val_best:  76.11%, tr:  62.46%, tr_best:  63.20%, epoch time: 265.61 seconds, 4.43 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  2.163072/  2.103323, val:  50.00%, val_best:  76.11%, tr:  61.09%, tr_best:  63.20%, epoch time: 263.91 seconds, 4.40 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  2.161891/  2.108917, val:  55.09%, val_best:  76.11%, tr:  62.11%, tr_best:  63.20%, epoch time: 264.49 seconds, 4.41 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 329 occurrences\n",
      "test - Value 1: 123 occurrences\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  2.161649/  2.140760, val:  69.25%, val_best:  76.11%, tr:  63.08%, tr_best:  63.20%, epoch time: 263.89 seconds, 4.40 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  2.163940/  2.256177, val:  50.00%, val_best:  76.11%, tr:  63.50%, tr_best:  63.50%, epoch time: 267.13 seconds, 4.45 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  2.169597/  2.287916, val:  50.00%, val_best:  76.11%, tr:  61.66%, tr_best:  63.50%, epoch time: 265.80 seconds, 4.43 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  2.170516/  2.170054, val:  74.34%, val_best:  76.11%, tr:  62.03%, tr_best:  63.50%, epoch time: 267.43 seconds, 4.46 minutes\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  2.169894/  2.261573, val:  50.00%, val_best:  76.11%, tr:  61.91%, tr_best:  63.50%, epoch time: 266.30 seconds, 4.44 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 276 occurrences\n",
      "test - Value 1: 176 occurrences\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  2.171389/  2.163625, val:  73.45%, val_best:  76.11%, tr:  62.48%, tr_best:  63.50%, epoch time: 264.55 seconds, 4.41 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  2.178161/  2.130233, val:  57.52%, val_best:  76.11%, tr:  61.64%, tr_best:  63.50%, epoch time: 265.03 seconds, 4.42 minutes\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  2.174911/  2.260616, val:  50.44%, val_best:  76.11%, tr:  61.59%, tr_best:  63.50%, epoch time: 267.64 seconds, 4.46 minutes\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  2.176423/  2.082116, val:  50.00%, val_best:  76.11%, tr:  60.84%, tr_best:  63.50%, epoch time: 267.27 seconds, 4.45 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  2.176271/  2.236972, val:  50.00%, val_best:  76.11%, tr:  62.03%, tr_best:  63.50%, epoch time: 264.70 seconds, 4.41 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  2.176266/  2.216990, val:  56.86%, val_best:  76.11%, tr:  62.08%, tr_best:  63.50%, epoch time: 265.26 seconds, 4.42 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  2.183269/  2.386930, val:  50.00%, val_best:  76.11%, tr:  62.41%, tr_best:  63.50%, epoch time: 265.86 seconds, 4.43 minutes\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  2.242178/  2.274314, val:  50.00%, val_best:  76.11%, tr:  61.51%, tr_best:  63.50%, epoch time: 265.93 seconds, 4.43 minutes\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  2.328718/  2.277596, val:  63.94%, val_best:  76.11%, tr:  58.71%, tr_best:  63.50%, epoch time: 268.38 seconds, 4.47 minutes\n",
      "train - Value 0: 2142 occurrences\n",
      "train - Value 1: 1888 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  2.409845/  2.543275, val:  50.66%, val_best:  76.11%, tr:  60.47%, tr_best:  63.50%, epoch time: 264.58 seconds, 4.41 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1944 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  2.416255/  2.472915, val:  54.20%, val_best:  76.11%, tr:  58.83%, tr_best:  63.50%, epoch time: 263.66 seconds, 4.39 minutes\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  2.351356/  2.378047, val:  59.51%, val_best:  76.11%, tr:  60.25%, tr_best:  63.50%, epoch time: 264.41 seconds, 4.41 minutes\n",
      "train - Value 0: 2095 occurrences\n",
      "train - Value 1: 1935 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  2.406882/  2.220643, val:  50.44%, val_best:  76.11%, tr:  59.31%, tr_best:  63.50%, epoch time: 262.47 seconds, 4.37 minutes\n",
      "train - Value 0: 2149 occurrences\n",
      "train - Value 1: 1881 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  2.376990/  2.166594, val:  50.44%, val_best:  76.11%, tr:  59.45%, tr_best:  63.50%, epoch time: 264.40 seconds, 4.41 minutes\n",
      "train - Value 0: 2110 occurrences\n",
      "train - Value 1: 1920 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  2.354409/  2.374164, val:  66.81%, val_best:  76.11%, tr:  60.72%, tr_best:  63.50%, epoch time: 264.00 seconds, 4.40 minutes\n",
      "train - Value 0: 2131 occurrences\n",
      "train - Value 1: 1899 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  2.400396/  2.354849, val:  65.93%, val_best:  76.11%, tr:  60.15%, tr_best:  63.50%, epoch time: 263.94 seconds, 4.40 minutes\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 406 occurrences\n",
      "test - Value 1: 46 occurrences\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  2.345043/  2.412390, val:  60.18%, val_best:  76.11%, tr:  59.13%, tr_best:  63.50%, epoch time: 262.67 seconds, 4.38 minutes\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  2.325624/  2.351986, val:  50.00%, val_best:  76.11%, tr:  59.26%, tr_best:  63.50%, epoch time: 263.92 seconds, 4.40 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  2.339284/  2.589062, val:  50.00%, val_best:  76.11%, tr:  59.35%, tr_best:  63.50%, epoch time: 262.99 seconds, 4.38 minutes\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  2.374374/  2.291816, val:  50.00%, val_best:  76.11%, tr:  57.59%, tr_best:  63.50%, epoch time: 265.40 seconds, 4.42 minutes\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  2.259822/  2.399707, val:  51.99%, val_best:  76.11%, tr:  59.58%, tr_best:  63.50%, epoch time: 263.83 seconds, 4.40 minutes\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  2.238091/  2.172348, val:  53.54%, val_best:  76.11%, tr:  58.83%, tr_best:  63.50%, epoch time: 264.55 seconds, 4.41 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  2.222614/  2.138652, val:  50.00%, val_best:  76.11%, tr:  59.08%, tr_best:  63.50%, epoch time: 265.09 seconds, 4.42 minutes\n",
      "train - Value 0: 2115 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  2.211662/  2.153093, val:  51.99%, val_best:  76.11%, tr:  58.96%, tr_best:  63.50%, epoch time: 265.19 seconds, 4.42 minutes\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  2.194752/  2.152480, val:  50.66%, val_best:  76.11%, tr:  59.78%, tr_best:  63.50%, epoch time: 263.42 seconds, 4.39 minutes\n",
      "train - Value 0: 2075 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  2.194049/  2.151764, val:  55.97%, val_best:  76.11%, tr:  60.60%, tr_best:  63.50%, epoch time: 261.69 seconds, 4.36 minutes\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  2.189433/  2.233968, val:  50.00%, val_best:  76.11%, tr:  60.37%, tr_best:  63.50%, epoch time: 263.20 seconds, 4.39 minutes\n",
      "train - Value 0: 2106 occurrences\n",
      "train - Value 1: 1924 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  2.199018/  2.151350, val:  61.06%, val_best:  76.11%, tr:  58.93%, tr_best:  63.50%, epoch time: 261.92 seconds, 4.37 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1963 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  2.163460/  2.051033, val:  50.00%, val_best:  76.11%, tr:  58.86%, tr_best:  63.50%, epoch time: 264.60 seconds, 4.41 minutes\n",
      "train - Value 0: 2116 occurrences\n",
      "train - Value 1: 1914 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  2.131500/  2.254245, val:  50.00%, val_best:  76.11%, tr:  58.39%, tr_best:  63.50%, epoch time: 265.54 seconds, 4.43 minutes\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1939 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  2.148678/  2.093079, val:  50.00%, val_best:  76.11%, tr:  58.01%, tr_best:  63.50%, epoch time: 263.79 seconds, 4.40 minutes\n",
      "train - Value 0: 2125 occurrences\n",
      "train - Value 1: 1905 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  2.224283/  2.320771, val:  50.00%, val_best:  76.11%, tr:  58.66%, tr_best:  63.50%, epoch time: 264.52 seconds, 4.41 minutes\n",
      "train - Value 0: 2130 occurrences\n",
      "train - Value 1: 1900 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  2.196773/  2.227509, val:  50.00%, val_best:  76.11%, tr:  59.08%, tr_best:  63.50%, epoch time: 263.22 seconds, 4.39 minutes\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  2.144166/  2.218445, val:  50.00%, val_best:  76.11%, tr:  61.39%, tr_best:  63.50%, epoch time: 262.50 seconds, 4.37 minutes\n",
      "train - Value 0: 2108 occurrences\n",
      "train - Value 1: 1922 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  2.317979/  2.352400, val:  50.00%, val_best:  76.11%, tr:  60.12%, tr_best:  63.50%, epoch time: 263.45 seconds, 4.39 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  2.371312/  2.488906, val:  50.22%, val_best:  76.11%, tr:  58.71%, tr_best:  63.50%, epoch time: 264.93 seconds, 4.42 minutes\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  2.412706/  2.508552, val:  50.88%, val_best:  76.11%, tr:  58.96%, tr_best:  63.50%, epoch time: 262.96 seconds, 4.38 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  2.348385/  2.437776, val:  50.00%, val_best:  76.11%, tr:  59.58%, tr_best:  63.50%, epoch time: 265.19 seconds, 4.42 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  2.348683/  2.472240, val:  50.00%, val_best:  76.11%, tr:  59.90%, tr_best:  63.50%, epoch time: 262.09 seconds, 4.37 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  2.394788/  2.429720, val:  50.00%, val_best:  76.11%, tr:  58.76%, tr_best:  63.50%, epoch time: 262.95 seconds, 4.38 minutes\n",
      "train - Value 0: 2126 occurrences\n",
      "train - Value 1: 1904 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  2.489806/  2.521547, val:  50.00%, val_best:  76.11%, tr:  60.32%, tr_best:  63.50%, epoch time: 262.05 seconds, 4.37 minutes\n",
      "train - Value 0: 2112 occurrences\n",
      "train - Value 1: 1918 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  2.407874/  2.459953, val:  71.90%, val_best:  76.11%, tr:  59.33%, tr_best:  63.50%, epoch time: 263.21 seconds, 4.39 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  2.384140/  2.244136, val:  52.65%, val_best:  76.11%, tr:  62.03%, tr_best:  63.50%, epoch time: 263.40 seconds, 4.39 minutes\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  2.372260/  2.359776, val:  50.00%, val_best:  76.11%, tr:  60.99%, tr_best:  63.50%, epoch time: 262.60 seconds, 4.38 minutes\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  2.456236/  2.400065, val:  50.66%, val_best:  76.11%, tr:  59.98%, tr_best:  63.50%, epoch time: 260.92 seconds, 4.35 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  2.336714/  2.337261, val:  50.00%, val_best:  76.11%, tr:  61.14%, tr_best:  63.50%, epoch time: 262.84 seconds, 4.38 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  2.380970/  2.413393, val:  50.00%, val_best:  76.11%, tr:  60.94%, tr_best:  63.50%, epoch time: 262.58 seconds, 4.38 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 397 occurrences\n",
      "test - Value 1: 55 occurrences\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  2.460199/  2.547228, val:  61.73%, val_best:  76.11%, tr:  60.52%, tr_best:  63.50%, epoch time: 262.41 seconds, 4.37 minutes\n",
      "train - Value 0: 2170 occurrences\n",
      "train - Value 1: 1860 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  2.523133/  2.576984, val:  54.20%, val_best:  76.11%, tr:  61.51%, tr_best:  63.50%, epoch time: 261.84 seconds, 4.36 minutes\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  2.513439/  2.463529, val:  50.00%, val_best:  76.11%, tr:  62.13%, tr_best:  63.50%, epoch time: 262.65 seconds, 4.38 minutes\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  2.403270/  2.415642, val:  50.00%, val_best:  76.11%, tr:  58.14%, tr_best:  63.50%, epoch time: 261.94 seconds, 4.37 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  2.301236/  2.341998, val:  50.00%, val_best:  76.11%, tr:  60.94%, tr_best:  63.50%, epoch time: 263.45 seconds, 4.39 minutes\n",
      "train - Value 0: 2151 occurrences\n",
      "train - Value 1: 1879 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  2.363899/  2.613426, val:  50.00%, val_best:  76.11%, tr:  60.10%, tr_best:  63.50%, epoch time: 261.23 seconds, 4.35 minutes\n",
      "train - Value 0: 2103 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  2.438697/  2.435501, val:  50.00%, val_best:  76.11%, tr:  62.08%, tr_best:  63.50%, epoch time: 263.48 seconds, 4.39 minutes\n",
      "train - Value 0: 2103 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  2.429754/  2.481616, val:  50.00%, val_best:  76.11%, tr:  59.95%, tr_best:  63.50%, epoch time: 262.13 seconds, 4.37 minutes\n",
      "train - Value 0: 2113 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  2.517288/  2.323806, val:  52.65%, val_best:  76.11%, tr:  60.15%, tr_best:  63.50%, epoch time: 261.36 seconds, 4.36 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  2.406025/  2.361689, val:  68.81%, val_best:  76.11%, tr:  62.73%, tr_best:  63.50%, epoch time: 262.60 seconds, 4.38 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  2.279197/  2.220092, val:  50.00%, val_best:  76.11%, tr:  60.84%, tr_best:  63.50%, epoch time: 262.30 seconds, 4.37 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  2.218732/  2.371739, val:  50.22%, val_best:  76.11%, tr:  60.65%, tr_best:  63.50%, epoch time: 261.86 seconds, 4.36 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1944 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  2.538297/  2.589739, val:  50.00%, val_best:  76.11%, tr:  60.57%, tr_best:  63.50%, epoch time: 263.27 seconds, 4.39 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  2.643192/  2.614093, val:  52.43%, val_best:  76.11%, tr:  64.00%, tr_best:  64.00%, epoch time: 261.29 seconds, 4.35 minutes\n",
      "train - Value 0: 2190 occurrences\n",
      "train - Value 1: 1840 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  2.570229/  2.528600, val:  50.00%, val_best:  76.11%, tr:  60.47%, tr_best:  64.00%, epoch time: 264.45 seconds, 4.41 minutes\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  2.485512/  2.555621, val:  50.00%, val_best:  76.11%, tr:  58.34%, tr_best:  64.00%, epoch time: 263.68 seconds, 4.39 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  2.592560/  2.606908, val:  50.00%, val_best:  76.11%, tr:  60.52%, tr_best:  64.00%, epoch time: 262.71 seconds, 4.38 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  2.637570/  2.595867, val:  61.73%, val_best:  76.11%, tr:  63.05%, tr_best:  64.00%, epoch time: 262.08 seconds, 4.37 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  2.624697/  2.583413, val:  50.22%, val_best:  76.11%, tr:  62.08%, tr_best:  64.00%, epoch time: 262.32 seconds, 4.37 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  2.619845/  2.577467, val:  50.00%, val_best:  76.11%, tr:  61.27%, tr_best:  64.00%, epoch time: 264.12 seconds, 4.40 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 378 occurrences\n",
      "test - Value 1: 74 occurrences\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  2.613238/  2.570741, val:  65.93%, val_best:  76.11%, tr:  63.20%, tr_best:  64.00%, epoch time: 263.09 seconds, 4.38 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  2.606777/  2.570286, val:  53.32%, val_best:  76.11%, tr:  62.13%, tr_best:  64.00%, epoch time: 262.53 seconds, 4.38 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 396 occurrences\n",
      "test - Value 1: 56 occurrences\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  2.605666/  2.572248, val:  62.39%, val_best:  76.11%, tr:  63.25%, tr_best:  64.00%, epoch time: 263.20 seconds, 4.39 minutes\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  2.601733/  2.574435, val:  59.73%, val_best:  76.11%, tr:  60.25%, tr_best:  64.00%, epoch time: 262.73 seconds, 4.38 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  2.604455/  2.582597, val:  50.00%, val_best:  76.11%, tr:  61.79%, tr_best:  64.00%, epoch time: 263.60 seconds, 4.39 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  2.605117/  2.570110, val:  71.90%, val_best:  76.11%, tr:  61.61%, tr_best:  64.00%, epoch time: 260.36 seconds, 4.34 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  2.605055/  2.581899, val:  50.00%, val_best:  76.11%, tr:  63.80%, tr_best:  64.00%, epoch time: 263.26 seconds, 4.39 minutes\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 335 occurrences\n",
      "test - Value 1: 117 occurrences\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  2.604017/  2.559697, val:  71.90%, val_best:  76.11%, tr:  62.63%, tr_best:  64.00%, epoch time: 261.72 seconds, 4.36 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  2.597507/  2.549789, val:  75.44%, val_best:  76.11%, tr:  63.60%, tr_best:  64.00%, epoch time: 262.97 seconds, 4.38 minutes\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  2.586280/  2.557087, val:  51.33%, val_best:  76.11%, tr:  62.75%, tr_best:  64.00%, epoch time: 262.45 seconds, 4.37 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  2.578089/  2.529274, val:  50.00%, val_best:  76.11%, tr:  61.74%, tr_best:  64.00%, epoch time: 264.15 seconds, 4.40 minutes\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  2.567240/  2.548400, val:  50.00%, val_best:  76.11%, tr:  60.25%, tr_best:  64.00%, epoch time: 264.36 seconds, 4.41 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  2.538997/  2.535840, val:  50.22%, val_best:  76.11%, tr:  62.11%, tr_best:  64.00%, epoch time: 266.86 seconds, 4.45 minutes\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  2.530092/  2.461189, val:  50.00%, val_best:  76.11%, tr:  60.52%, tr_best:  64.00%, epoch time: 264.29 seconds, 4.40 minutes\n",
      "train - Value 0: 2075 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  2.504962/  2.494853, val:  50.00%, val_best:  76.11%, tr:  57.77%, tr_best:  64.00%, epoch time: 264.27 seconds, 4.40 minutes\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 399 occurrences\n",
      "test - Value 1: 53 occurrences\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  2.392738/  2.424781, val:  61.73%, val_best:  76.11%, tr:  59.38%, tr_best:  64.00%, epoch time: 261.96 seconds, 4.37 minutes\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  2.267339/  2.364882, val:  62.39%, val_best:  76.11%, tr:  61.56%, tr_best:  64.00%, epoch time: 263.11 seconds, 4.39 minutes\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  2.240567/  2.091478, val:  51.99%, val_best:  76.11%, tr:  61.46%, tr_best:  64.00%, epoch time: 262.60 seconds, 4.38 minutes\n",
      "train - Value 0: 1922 occurrences\n",
      "train - Value 1: 2108 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  2.164901/  2.176951, val:  50.44%, val_best:  76.11%, tr:  62.56%, tr_best:  64.00%, epoch time: 262.94 seconds, 4.38 minutes\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1910 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  2.258651/  2.233738, val:  52.21%, val_best:  76.11%, tr:  60.42%, tr_best:  64.00%, epoch time: 261.45 seconds, 4.36 minutes\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  2.409898/  2.472647, val:  50.00%, val_best:  76.11%, tr:  60.02%, tr_best:  64.00%, epoch time: 263.24 seconds, 4.39 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  2.552846/  2.526114, val:  50.00%, val_best:  76.11%, tr:  59.68%, tr_best:  64.00%, epoch time: 264.00 seconds, 4.40 minutes\n",
      "train - Value 0: 2150 occurrences\n",
      "train - Value 1: 1880 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  2.566423/  2.537542, val:  50.44%, val_best:  76.11%, tr:  60.97%, tr_best:  64.00%, epoch time: 262.26 seconds, 4.37 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  2.572609/  2.552988, val:  60.84%, val_best:  76.11%, tr:  60.27%, tr_best:  64.00%, epoch time: 262.89 seconds, 4.38 minutes\n",
      "train - Value 0: 2099 occurrences\n",
      "train - Value 1: 1931 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  2.567062/  2.517200, val:  52.43%, val_best:  76.11%, tr:  59.80%, tr_best:  64.00%, epoch time: 263.55 seconds, 4.39 minutes\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  2.553436/  2.572872, val:  68.81%, val_best:  76.11%, tr:  61.17%, tr_best:  64.00%, epoch time: 260.15 seconds, 4.34 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  2.575464/  2.543870, val:  51.77%, val_best:  76.11%, tr:  60.27%, tr_best:  64.00%, epoch time: 261.79 seconds, 4.36 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  2.551411/  2.513417, val:  50.00%, val_best:  76.11%, tr:  61.84%, tr_best:  64.00%, epoch time: 262.32 seconds, 4.37 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  2.541886/  2.488555, val:  76.33%, val_best:  76.33%, tr:  61.32%, tr_best:  64.00%, epoch time: 265.48 seconds, 4.42 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  2.513791/  2.492541, val:  50.44%, val_best:  76.33%, tr:  60.87%, tr_best:  64.00%, epoch time: 261.80 seconds, 4.36 minutes\n",
      "train - Value 0: 2166 occurrences\n",
      "train - Value 1: 1864 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  2.494221/  2.455150, val:  50.00%, val_best:  76.33%, tr:  61.71%, tr_best:  64.00%, epoch time: 263.57 seconds, 4.39 minutes\n",
      "train - Value 0: 2143 occurrences\n",
      "train - Value 1: 1887 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  2.369039/  2.374620, val:  62.61%, val_best:  76.33%, tr:  59.60%, tr_best:  64.00%, epoch time: 263.15 seconds, 4.39 minutes\n",
      "train - Value 0: 2097 occurrences\n",
      "train - Value 1: 1933 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  2.379628/  2.377200, val:  49.78%, val_best:  76.33%, tr:  60.15%, tr_best:  64.00%, epoch time: 264.30 seconds, 4.41 minutes\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  2.368220/  2.421977, val:  25.44%, val_best:  76.33%, tr:  60.30%, tr_best:  64.00%, epoch time: 260.96 seconds, 4.35 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  2.458614/  2.419266, val:  59.07%, val_best:  76.33%, tr:  58.86%, tr_best:  64.00%, epoch time: 263.56 seconds, 4.39 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  2.454671/  2.447778, val:  74.12%, val_best:  76.33%, tr:  58.64%, tr_best:  64.00%, epoch time: 263.04 seconds, 4.38 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  2.436855/  2.396301, val:  50.00%, val_best:  76.33%, tr:  60.25%, tr_best:  64.00%, epoch time: 262.88 seconds, 4.38 minutes\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  2.460060/  2.413857, val:  50.44%, val_best:  76.33%, tr:  61.86%, tr_best:  64.00%, epoch time: 262.00 seconds, 4.37 minutes\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  2.409339/  2.373048, val:  50.66%, val_best:  76.33%, tr:  60.60%, tr_best:  64.00%, epoch time: 261.72 seconds, 4.36 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  2.308441/  2.302345, val:  70.80%, val_best:  76.33%, tr:  62.98%, tr_best:  64.00%, epoch time: 262.30 seconds, 4.37 minutes\n",
      "train - Value 0: 2135 occurrences\n",
      "train - Value 1: 1895 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  2.268682/  2.336095, val:  50.00%, val_best:  76.33%, tr:  62.18%, tr_best:  64.00%, epoch time: 262.81 seconds, 4.38 minutes\n",
      "train - Value 0: 2164 occurrences\n",
      "train - Value 1: 1866 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  2.296455/  2.257746, val:  50.44%, val_best:  76.33%, tr:  60.62%, tr_best:  64.00%, epoch time: 261.81 seconds, 4.36 minutes\n",
      "train - Value 0: 2122 occurrences\n",
      "train - Value 1: 1908 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  2.280853/  2.110226, val:  50.00%, val_best:  76.33%, tr:  59.68%, tr_best:  64.00%, epoch time: 263.94 seconds, 4.40 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  2.198154/  2.034164, val:  60.40%, val_best:  76.33%, tr:  60.84%, tr_best:  64.00%, epoch time: 262.46 seconds, 4.37 minutes\n",
      "train - Value 0: 1884 occurrences\n",
      "train - Value 1: 2146 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  2.156659/  2.149972, val:  55.53%, val_best:  76.33%, tr:  61.76%, tr_best:  64.00%, epoch time: 263.84 seconds, 4.40 minutes\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  2.389669/  2.597994, val:  50.00%, val_best:  76.33%, tr:  62.75%, tr_best:  64.00%, epoch time: 261.94 seconds, 4.37 minutes\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  2.366234/  2.216901, val:  67.70%, val_best:  76.33%, tr:  63.10%, tr_best:  64.00%, epoch time: 263.42 seconds, 4.39 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  2.318490/  2.315478, val:  50.00%, val_best:  76.33%, tr:  62.51%, tr_best:  64.00%, epoch time: 263.26 seconds, 4.39 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  2.321414/  2.364649, val:  58.19%, val_best:  76.33%, tr:  62.90%, tr_best:  64.00%, epoch time: 263.16 seconds, 4.39 minutes\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 422 occurrences\n",
      "test - Value 1: 30 occurrences\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  2.292189/  2.422861, val:  56.64%, val_best:  76.33%, tr:  64.27%, tr_best:  64.27%, epoch time: 263.75 seconds, 4.40 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  2.322147/  2.250022, val:  50.00%, val_best:  76.33%, tr:  64.57%, tr_best:  64.57%, epoch time: 263.09 seconds, 4.38 minutes\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1910 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  2.258881/  2.376194, val:  48.67%, val_best:  76.33%, tr:  61.56%, tr_best:  64.57%, epoch time: 261.54 seconds, 4.36 minutes\n",
      "train - Value 0: 2165 occurrences\n",
      "train - Value 1: 1865 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  2.400075/  2.391958, val:  50.22%, val_best:  76.33%, tr:  61.29%, tr_best:  64.57%, epoch time: 260.29 seconds, 4.34 minutes\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  2.375899/  2.347150, val:  68.58%, val_best:  76.33%, tr:  60.65%, tr_best:  64.57%, epoch time: 264.24 seconds, 4.40 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  2.364821/  2.301357, val:  72.12%, val_best:  76.33%, tr:  60.55%, tr_best:  64.57%, epoch time: 263.44 seconds, 4.39 minutes\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 415 occurrences\n",
      "test - Value 1: 37 occurrences\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  2.306876/  2.136708, val:  58.19%, val_best:  76.33%, tr:  64.02%, tr_best:  64.57%, epoch time: 263.17 seconds, 4.39 minutes\n",
      "train - Value 0: 2075 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  2.163642/  2.160462, val:  76.99%, val_best:  76.99%, tr:  64.62%, tr_best:  64.62%, epoch time: 263.09 seconds, 4.38 minutes\n",
      "train - Value 0: 2214 occurrences\n",
      "train - Value 1: 1816 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  2.218042/  2.085179, val:  50.22%, val_best:  76.99%, tr:  61.02%, tr_best:  64.62%, epoch time: 263.49 seconds, 4.39 minutes\n",
      "train - Value 0: 2088 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  2.203936/  2.388517, val:  50.00%, val_best:  76.99%, tr:  60.47%, tr_best:  64.62%, epoch time: 263.52 seconds, 4.39 minutes\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  2.131423/  2.170233, val:  50.00%, val_best:  76.99%, tr:  63.67%, tr_best:  64.62%, epoch time: 263.70 seconds, 4.39 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  2.089101/  1.976749, val:  50.00%, val_best:  76.99%, tr:  60.89%, tr_best:  64.62%, epoch time: 263.54 seconds, 4.39 minutes\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  2.029071/  2.229371, val:  50.00%, val_best:  76.99%, tr:  61.09%, tr_best:  64.62%, epoch time: 264.91 seconds, 4.42 minutes\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1963 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  2.069770/  2.200526, val:  50.00%, val_best:  76.99%, tr:  62.33%, tr_best:  64.62%, epoch time: 265.16 seconds, 4.42 minutes\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  2.064919/  2.185040, val:  50.00%, val_best:  76.99%, tr:  61.94%, tr_best:  64.62%, epoch time: 262.90 seconds, 4.38 minutes\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  2.161141/  2.292682, val:  70.58%, val_best:  76.99%, tr:  63.37%, tr_best:  64.62%, epoch time: 264.09 seconds, 4.40 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  2.293333/  2.360195, val:  50.22%, val_best:  76.99%, tr:  60.30%, tr_best:  64.62%, epoch time: 262.13 seconds, 4.37 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  2.254961/  2.254118, val:  50.00%, val_best:  76.99%, tr:  59.48%, tr_best:  64.62%, epoch time: 265.06 seconds, 4.42 minutes\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  2.337183/  2.296573, val:  28.32%, val_best:  76.99%, tr:  58.61%, tr_best:  64.62%, epoch time: 265.60 seconds, 4.43 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  2.413941/  2.399519, val:  51.33%, val_best:  76.99%, tr:  62.16%, tr_best:  64.62%, epoch time: 264.98 seconds, 4.42 minutes\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['0.0009766'], tr/val_loss:  2.375190/  2.490992, val:  50.00%, val_best:  76.99%, tr:  60.67%, tr_best:  64.62%, epoch time: 263.78 seconds, 4.40 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['0.0009766'], tr/val_loss:  2.403904/  2.124543, val:  50.00%, val_best:  76.99%, tr:  58.86%, tr_best:  64.62%, epoch time: 263.74 seconds, 4.40 minutes\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['0.0009766'], tr/val_loss:  2.321336/  2.267594, val:  50.00%, val_best:  76.99%, tr:  58.81%, tr_best:  64.62%, epoch time: 263.50 seconds, 4.39 minutes\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-188 lr=['0.0009766'], tr/val_loss:  2.257773/  2.161881, val:  51.55%, val_best:  76.99%, tr:  60.30%, tr_best:  64.62%, epoch time: 263.24 seconds, 4.39 minutes\n",
      "train - Value 0: 2182 occurrences\n",
      "train - Value 1: 1848 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-189 lr=['0.0009766'], tr/val_loss:  2.225532/  2.245402, val:  72.57%, val_best:  76.99%, tr:  61.17%, tr_best:  64.62%, epoch time: 263.80 seconds, 4.40 minutes\n",
      "train - Value 0: 2151 occurrences\n",
      "train - Value 1: 1879 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-190 lr=['0.0009766'], tr/val_loss:  2.314873/  2.184633, val:  51.11%, val_best:  76.99%, tr:  62.18%, tr_best:  64.62%, epoch time: 261.91 seconds, 4.37 minutes\n",
      "train - Value 0: 2088 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-191 lr=['0.0009766'], tr/val_loss:  2.281715/  2.353276, val:  50.00%, val_best:  76.99%, tr:  60.77%, tr_best:  64.62%, epoch time: 264.48 seconds, 4.41 minutes\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-192 lr=['0.0009766'], tr/val_loss:  2.285131/  2.330305, val:  50.00%, val_best:  76.99%, tr:  60.77%, tr_best:  64.62%, epoch time: 265.11 seconds, 4.42 minutes\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-193 lr=['0.0009766'], tr/val_loss:  2.291034/  2.243906, val:  50.22%, val_best:  76.99%, tr:  61.22%, tr_best:  64.62%, epoch time: 263.92 seconds, 4.40 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-194 lr=['0.0009766'], tr/val_loss:  2.295178/  2.313055, val:  70.58%, val_best:  76.99%, tr:  61.19%, tr_best:  64.62%, epoch time: 264.55 seconds, 4.41 minutes\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-195 lr=['0.0009766'], tr/val_loss:  2.371775/  2.293566, val:  50.00%, val_best:  76.99%, tr:  61.99%, tr_best:  64.62%, epoch time: 261.72 seconds, 4.36 minutes\n",
      "train - Value 0: 2182 occurrences\n",
      "train - Value 1: 1848 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['0.0009766'], tr/val_loss:  2.468801/  2.484077, val:  50.00%, val_best:  76.99%, tr:  60.82%, tr_best:  64.62%, epoch time: 263.70 seconds, 4.40 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-197 lr=['0.0009766'], tr/val_loss:  2.514419/  2.192159, val:  51.55%, val_best:  76.99%, tr:  59.01%, tr_best:  64.62%, epoch time: 263.63 seconds, 4.39 minutes\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-198 lr=['0.0009766'], tr/val_loss:  2.338873/  2.236001, val:  50.88%, val_best:  76.99%, tr:  63.47%, tr_best:  64.62%, epoch time: 262.38 seconds, 4.37 minutes\n",
      "train - Value 0: 2155 occurrences\n",
      "train - Value 1: 1875 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-199 lr=['0.0009766'], tr/val_loss:  2.396280/  2.276577, val:  32.96%, val_best:  76.99%, tr:  59.40%, tr_best:  64.62%, epoch time: 263.89 seconds, 4.40 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf1c5bbe65543efa8b052f6b98840ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÇ</td></tr><tr><td>tr_acc</td><td>‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÖ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÇ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÖ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÇ</td></tr><tr><td>val_loss</td><td>‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.59404</td></tr><tr><td>tr_epoch_loss</td><td>2.39628</td></tr><tr><td>val_acc_best</td><td>0.76991</td></tr><tr><td>val_acc_now</td><td>0.32965</td></tr><tr><td>val_loss</td><td>2.27658</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wise-sweep-41</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6ohznh6c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6ohznh6c</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250723_171506-6ohznh6c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2j370d90 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001220703125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250724_075530-2j370d90</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2j370d90' target=\"_blank\">smart-sweep-52</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2j370d90' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2j370d90</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250724_075539_160', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 15, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0001220703125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 4, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 4\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=15, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0001220703125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-0   lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.49 seconds, 2.76 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-1   lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.04 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-2   lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.09 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-3   lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.63 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-4   lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.59 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-5   lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.63 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-6   lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.72 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-7   lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.05 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-8   lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 169.19 seconds, 2.82 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-9   lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.03 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-10  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.82 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-11  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.57 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-12  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.97 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-13  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.71 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-14  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.11 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-15  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.90 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-16  lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.79 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-17  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.24 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-18  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.18 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-19  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.61 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-20  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.65 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-21  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.01 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-22  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.04 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-23  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.35 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-24  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.11 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-25  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 167.45 seconds, 2.79 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-26  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.81 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-27  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.74 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-28  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.31 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-29  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.10 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-30  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 167.33 seconds, 2.79 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-31  lr=['0.0001221'], tr/val_loss:  2.329711/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.73 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-32  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.30 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-33  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.88 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-34  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.00 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-35  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.95 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-36  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.21 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-37  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.56 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-38  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.30 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-39  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.73 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-40  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.91 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-41  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.98 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-42  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.37 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-43  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 160.52 seconds, 2.68 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-44  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.54 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-45  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.32 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-46  lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.63 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-47  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.51 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-48  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.38 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-49  lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.34 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-50  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.35 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-51  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.29 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-52  lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.41 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-53  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.48 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-54  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.31 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-55  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.39 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-56  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.59 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-57  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.67 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-58  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.54 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-59  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.68 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-60  lr=['0.0001221'], tr/val_loss:  2.329712/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.45 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-61  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.43 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-62  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.47 seconds, 2.69 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-63  lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.26 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-64  lr=['0.0001221'], tr/val_loss:  2.329711/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.53 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-65  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.17 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-66  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.34 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-67  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.61 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-68  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.03 seconds, 2.68 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-69  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.65 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-70  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.19 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-71  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.64 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-72  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.15 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-73  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.85 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-74  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.04 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-75  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.75 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-76  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.79 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-77  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.42 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-78  lr=['0.0001221'], tr/val_loss:  2.329703/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.04 seconds, 2.68 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-79  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.04 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-80  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.38 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-81  lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.23 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-82  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.12 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-83  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.16 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-84  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.76 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-85  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.72 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-86  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.00 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-87  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.34 seconds, 2.69 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-88  lr=['0.0001221'], tr/val_loss:  2.329701/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.46 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-89  lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.32 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-90  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.84 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-91  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.53 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-92  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.40 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-93  lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.68 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-94  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.48 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-95  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.08 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-96  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.01 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-97  lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.59 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-98  lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.40 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-99  lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.44 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-100 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.38 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-101 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.00 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-102 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.03 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-103 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.00 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-104 lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.17 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-105 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.80 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-106 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.44 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-107 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.15 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-108 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.11 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-109 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.60 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-110 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.91 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-111 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.68 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-112 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.02 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-113 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.90 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-114 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.67 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-115 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.19 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-116 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.63 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-117 lr=['0.0001221'], tr/val_loss:  2.329711/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.96 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-118 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.43 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-119 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.91 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-120 lr=['0.0001221'], tr/val_loss:  2.329711/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.89 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-121 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.02 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-122 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.07 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-123 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.41 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-124 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.93 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-125 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.67 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-126 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.48 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-127 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.35 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-128 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.93 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-129 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.77 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-130 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.99 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-131 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.82 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-132 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.73 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-133 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.03 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-134 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.73 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-135 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.23 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-136 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.78 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-137 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.37 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-138 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.32 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-139 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.74 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-140 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.97 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-141 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.80 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-142 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.02 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-143 lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.11 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-144 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.14 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-145 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.78 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-146 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.05 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-147 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.00 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-148 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.87 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-149 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.12 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-150 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.60 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-151 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.74 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-152 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.66 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-153 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.66 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-154 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.80 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-155 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.68 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-156 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.69 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-157 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.37 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-158 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.97 seconds, 2.77 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-159 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.31 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-160 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.02 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-161 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.15 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-162 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.99 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-163 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.07 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-164 lr=['0.0001221'], tr/val_loss:  2.329704/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.86 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-165 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.28 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-166 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.97 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-167 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.81 seconds, 2.75 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-168 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.39 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-169 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.06 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-170 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.27 seconds, 2.69 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-171 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.89 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-172 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.58 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-173 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.04 seconds, 2.68 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-174 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 160.87 seconds, 2.68 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-175 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 159.11 seconds, 2.65 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-176 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 159.25 seconds, 2.65 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-177 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 158.92 seconds, 2.65 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-178 lr=['0.0001221'], tr/val_loss:  2.329703/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 158.19 seconds, 2.64 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-179 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 159.88 seconds, 2.66 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-180 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 158.43 seconds, 2.64 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-181 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.77 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-182 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.07 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-183 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-184 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 159.37 seconds, 2.66 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-185 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 160.46 seconds, 2.67 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-186 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.58 seconds, 2.69 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-187 lr=['0.0001221'], tr/val_loss:  2.329711/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 162.00 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-188 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.81 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-189 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 165.56 seconds, 2.76 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-190 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.22 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-191 lr=['0.0001221'], tr/val_loss:  2.329709/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.86 seconds, 2.70 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-192 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 161.33 seconds, 2.69 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-193 lr=['0.0001221'], tr/val_loss:  2.329705/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 160.25 seconds, 2.67 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-194 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.75 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-195 lr=['0.0001221'], tr/val_loss:  2.329708/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.66 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-196 lr=['0.0001221'], tr/val_loss:  2.329707/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.09 seconds, 2.72 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-197 lr=['0.0001221'], tr/val_loss:  2.329706/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 164.43 seconds, 2.74 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-198 lr=['0.0001221'], tr/val_loss:  2.329710/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.64 seconds, 2.73 minutes\n",
      "train - Value 0: 2954 occurrences\n",
      "train - Value 1: 1076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 298 occurrences\n",
      "test - Value 1: 154 occurrences\n",
      "epoch-199 lr=['0.0001221'], tr/val_loss:  2.329702/  2.324330, val:  47.79%, val_best:  47.79%, tr:  54.02%, tr_best:  54.02%, epoch time: 163.98 seconds, 2.73 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1318bfcd0354b84af8b92c378ba33ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.5402</td></tr><tr><td>tr_epoch_loss</td><td>2.3297</td></tr><tr><td>val_acc_best</td><td>0.47788</td></tr><tr><td>val_acc_now</td><td>0.47788</td></tr><tr><td>val_loss</td><td>2.32433</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-sweep-52</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2j370d90' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2j370d90</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250724_075530-2j370d90/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hmm8ryhr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000244140625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250724_170126-hmm8ryhr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hmm8ryhr' target=\"_blank\">scarlet-sweep-59</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hmm8ryhr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hmm8ryhr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250724_170134_963', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 20, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.000244140625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 8, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-12, -12], [-12, -12], [-11, -11]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 8\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -12 -12\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -12\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -11 -11\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=20, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-12, -12], [-12, -12], [-11, -11]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.000244140625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2133 occurrences\n",
      "train - Value 1: 1897 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-0   lr=['0.0002441'], tr/val_loss:  2.302876/  2.307771, val:  49.56%, val_best:  49.56%, tr:  54.44%, tr_best:  54.44%, epoch time: 164.42 seconds, 2.74 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2590 occurrences\n",
      "train - Value 1: 1440 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-1   lr=['0.0002441'], tr/val_loss:  2.310797/  2.313694, val:  50.88%, val_best:  50.88%, tr:  55.51%, tr_best:  55.51%, epoch time: 163.64 seconds, 2.73 minutes\n",
      "train - Value 0: 1898 occurrences\n",
      "train - Value 1: 2132 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 332 occurrences\n",
      "test - Value 1: 120 occurrences\n",
      "epoch-2   lr=['0.0002441'], tr/val_loss:  2.324405/  2.323676, val:  68.58%, val_best:  68.58%, tr:  65.24%, tr_best:  65.24%, epoch time: 163.62 seconds, 2.73 minutes\n",
      "train - Value 0: 1655 occurrences\n",
      "train - Value 1: 2375 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-3   lr=['0.0002441'], tr/val_loss:  2.326816/  2.324595, val:  50.22%, val_best:  68.58%, tr:  72.80%, tr_best:  72.80%, epoch time: 163.05 seconds, 2.72 minutes\n",
      "train - Value 0: 1776 occurrences\n",
      "train - Value 1: 2254 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-4   lr=['0.0002441'], tr/val_loss:  2.330925/  2.322455, val:  77.88%, val_best:  77.88%, tr:  72.78%, tr_best:  72.80%, epoch time: 164.24 seconds, 2.74 minutes\n",
      "train - Value 0: 1756 occurrences\n",
      "train - Value 1: 2274 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-5   lr=['0.0002441'], tr/val_loss:  2.329625/  2.326067, val:  55.53%, val_best:  77.88%, tr:  74.76%, tr_best:  74.76%, epoch time: 163.61 seconds, 2.73 minutes\n",
      "train - Value 0: 1685 occurrences\n",
      "train - Value 1: 2345 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-6   lr=['0.0002441'], tr/val_loss:  2.329982/  2.322507, val:  59.73%, val_best:  77.88%, tr:  75.33%, tr_best:  75.33%, epoch time: 165.40 seconds, 2.76 minutes\n",
      "train - Value 0: 1723 occurrences\n",
      "train - Value 1: 2307 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-7   lr=['0.0002441'], tr/val_loss:  2.329987/  2.327056, val:  80.31%, val_best:  80.31%, tr:  77.27%, tr_best:  77.27%, epoch time: 163.50 seconds, 2.72 minutes\n",
      "train - Value 0: 1707 occurrences\n",
      "train - Value 1: 2323 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-8   lr=['0.0002441'], tr/val_loss:  2.329805/  2.326761, val:  77.88%, val_best:  80.31%, tr:  75.93%, tr_best:  77.27%, epoch time: 162.92 seconds, 2.72 minutes\n",
      "train - Value 0: 1742 occurrences\n",
      "train - Value 1: 2288 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-9   lr=['0.0002441'], tr/val_loss:  2.329728/  2.323449, val:  82.30%, val_best:  82.30%, tr:  77.05%, tr_best:  77.27%, epoch time: 163.70 seconds, 2.73 minutes\n",
      "train - Value 0: 1774 occurrences\n",
      "train - Value 1: 2256 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 383 occurrences\n",
      "test - Value 1: 69 occurrences\n",
      "epoch-10  lr=['0.0002441'], tr/val_loss:  2.328758/  2.325649, val:  60.84%, val_best:  82.30%, tr:  77.89%, tr_best:  77.89%, epoch time: 163.66 seconds, 2.73 minutes\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2241 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-11  lr=['0.0002441'], tr/val_loss:  2.327997/  2.323202, val:  61.50%, val_best:  82.30%, tr:  78.96%, tr_best:  78.96%, epoch time: 162.41 seconds, 2.71 minutes\n",
      "train - Value 0: 1800 occurrences\n",
      "train - Value 1: 2230 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-12  lr=['0.0002441'], tr/val_loss:  2.327643/  2.323890, val:  83.19%, val_best:  83.19%, tr:  80.22%, tr_best:  80.22%, epoch time: 162.38 seconds, 2.71 minutes\n",
      "train - Value 0: 1795 occurrences\n",
      "train - Value 1: 2235 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-13  lr=['0.0002441'], tr/val_loss:  2.328028/  2.326659, val:  75.44%, val_best:  83.19%, tr:  79.16%, tr_best:  80.22%, epoch time: 164.30 seconds, 2.74 minutes\n",
      "train - Value 0: 1788 occurrences\n",
      "train - Value 1: 2242 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-14  lr=['0.0002441'], tr/val_loss:  2.327872/  2.324652, val:  76.99%, val_best:  83.19%, tr:  81.32%, tr_best:  81.32%, epoch time: 163.27 seconds, 2.72 minutes\n",
      "train - Value 0: 1799 occurrences\n",
      "train - Value 1: 2231 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 307 occurrences\n",
      "test - Value 1: 145 occurrences\n",
      "epoch-15  lr=['0.0002441'], tr/val_loss:  2.329063/  2.325930, val:  75.44%, val_best:  83.19%, tr:  80.05%, tr_best:  81.32%, epoch time: 162.73 seconds, 2.71 minutes\n",
      "train - Value 0: 1779 occurrences\n",
      "train - Value 1: 2251 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-16  lr=['0.0002441'], tr/val_loss:  2.329456/  2.326690, val:  54.42%, val_best:  83.19%, tr:  80.15%, tr_best:  81.32%, epoch time: 161.58 seconds, 2.69 minutes\n",
      "train - Value 0: 1792 occurrences\n",
      "train - Value 1: 2238 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-17  lr=['0.0002441'], tr/val_loss:  2.327899/  2.323082, val:  66.15%, val_best:  83.19%, tr:  81.66%, tr_best:  81.66%, epoch time: 163.74 seconds, 2.73 minutes\n",
      "train - Value 0: 1806 occurrences\n",
      "train - Value 1: 2224 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-18  lr=['0.0002441'], tr/val_loss:  2.328877/  2.326430, val:  84.51%, val_best:  84.51%, tr:  81.27%, tr_best:  81.66%, epoch time: 163.13 seconds, 2.72 minutes\n",
      "train - Value 0: 1776 occurrences\n",
      "train - Value 1: 2254 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-19  lr=['0.0002441'], tr/val_loss:  2.328594/  2.324598, val:  80.75%, val_best:  84.51%, tr:  81.66%, tr_best:  81.66%, epoch time: 163.93 seconds, 2.73 minutes\n",
      "train - Value 0: 1825 occurrences\n",
      "train - Value 1: 2205 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 321 occurrences\n",
      "test - Value 1: 131 occurrences\n",
      "epoch-20  lr=['0.0002441'], tr/val_loss:  2.328014/  2.325778, val:  73.67%, val_best:  84.51%, tr:  82.98%, tr_best:  82.98%, epoch time: 163.30 seconds, 2.72 minutes\n",
      "train - Value 0: 1797 occurrences\n",
      "train - Value 1: 2233 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-21  lr=['0.0002441'], tr/val_loss:  2.328507/  2.326507, val:  78.32%, val_best:  84.51%, tr:  82.48%, tr_best:  82.98%, epoch time: 162.92 seconds, 2.72 minutes\n",
      "train - Value 0: 1825 occurrences\n",
      "train - Value 1: 2205 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-22  lr=['0.0002441'], tr/val_loss:  2.328628/  2.327037, val:  74.56%, val_best:  84.51%, tr:  81.94%, tr_best:  82.98%, epoch time: 163.64 seconds, 2.73 minutes\n",
      "train - Value 0: 1806 occurrences\n",
      "train - Value 1: 2224 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-23  lr=['0.0002441'], tr/val_loss:  2.327997/  2.325690, val:  57.30%, val_best:  84.51%, tr:  82.61%, tr_best:  82.98%, epoch time: 163.02 seconds, 2.72 minutes\n",
      "train - Value 0: 1821 occurrences\n",
      "train - Value 1: 2209 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-24  lr=['0.0002441'], tr/val_loss:  2.327464/  2.325879, val:  83.41%, val_best:  84.51%, tr:  83.37%, tr_best:  83.37%, epoch time: 163.88 seconds, 2.73 minutes\n",
      "train - Value 0: 1832 occurrences\n",
      "train - Value 1: 2198 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-25  lr=['0.0002441'], tr/val_loss:  2.327247/  2.323406, val:  83.63%, val_best:  84.51%, tr:  83.90%, tr_best:  83.90%, epoch time: 162.30 seconds, 2.71 minutes\n",
      "train - Value 0: 1792 occurrences\n",
      "train - Value 1: 2238 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-26  lr=['0.0002441'], tr/val_loss:  2.327720/  2.328102, val:  83.41%, val_best:  84.51%, tr:  83.85%, tr_best:  83.90%, epoch time: 163.81 seconds, 2.73 minutes\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-27  lr=['0.0002441'], tr/val_loss:  2.328029/  2.325080, val:  61.06%, val_best:  84.51%, tr:  83.67%, tr_best:  83.90%, epoch time: 163.59 seconds, 2.73 minutes\n",
      "train - Value 0: 1801 occurrences\n",
      "train - Value 1: 2229 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 363 occurrences\n",
      "test - Value 1: 89 occurrences\n",
      "epoch-28  lr=['0.0002441'], tr/val_loss:  2.327752/  2.325761, val:  66.59%, val_best:  84.51%, tr:  83.97%, tr_best:  83.97%, epoch time: 162.93 seconds, 2.72 minutes\n",
      "train - Value 0: 1802 occurrences\n",
      "train - Value 1: 2228 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-29  lr=['0.0002441'], tr/val_loss:  2.328642/  2.326032, val:  50.88%, val_best:  84.51%, tr:  83.50%, tr_best:  83.97%, epoch time: 162.53 seconds, 2.71 minutes\n",
      "train - Value 0: 1816 occurrences\n",
      "train - Value 1: 2214 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-30  lr=['0.0002441'], tr/val_loss:  2.330091/  2.328364, val:  82.08%, val_best:  84.51%, tr:  84.39%, tr_best:  84.39%, epoch time: 162.27 seconds, 2.70 minutes\n",
      "train - Value 0: 1819 occurrences\n",
      "train - Value 1: 2211 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-31  lr=['0.0002441'], tr/val_loss:  2.332739/  2.330043, val:  84.96%, val_best:  84.96%, tr:  85.46%, tr_best:  85.46%, epoch time: 163.24 seconds, 2.72 minutes\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2221 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-32  lr=['0.0002441'], tr/val_loss:  2.333344/  2.330804, val:  53.98%, val_best:  84.96%, tr:  85.51%, tr_best:  85.51%, epoch time: 162.44 seconds, 2.71 minutes\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2221 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-33  lr=['0.0002441'], tr/val_loss:  2.334035/  2.331598, val:  80.97%, val_best:  84.96%, tr:  86.70%, tr_best:  86.70%, epoch time: 163.85 seconds, 2.73 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-34  lr=['0.0002441'], tr/val_loss:  2.334219/  2.330015, val:  67.26%, val_best:  84.96%, tr:  85.88%, tr_best:  86.70%, epoch time: 163.72 seconds, 2.73 minutes\n",
      "train - Value 0: 1796 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-35  lr=['0.0002441'], tr/val_loss:  2.335081/  2.331359, val:  76.77%, val_best:  84.96%, tr:  86.87%, tr_best:  86.87%, epoch time: 162.36 seconds, 2.71 minutes\n",
      "train - Value 0: 1804 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-36  lr=['0.0002441'], tr/val_loss:  2.335167/  2.332512, val:  55.09%, val_best:  84.96%, tr:  86.67%, tr_best:  86.87%, epoch time: 163.70 seconds, 2.73 minutes\n",
      "train - Value 0: 1773 occurrences\n",
      "train - Value 1: 2257 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0002441'], tr/val_loss:  2.334813/  2.331044, val:  50.00%, val_best:  84.96%, tr:  86.60%, tr_best:  86.87%, epoch time: 162.66 seconds, 2.71 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 374 occurrences\n",
      "test - Value 1: 78 occurrences\n",
      "epoch-38  lr=['0.0002441'], tr/val_loss:  2.336125/  2.331532, val:  63.27%, val_best:  84.96%, tr:  86.25%, tr_best:  86.87%, epoch time: 163.25 seconds, 2.72 minutes\n",
      "train - Value 0: 1810 occurrences\n",
      "train - Value 1: 2220 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-39  lr=['0.0002441'], tr/val_loss:  2.335887/  2.332458, val:  84.96%, val_best:  84.96%, tr:  86.63%, tr_best:  86.87%, epoch time: 164.92 seconds, 2.75 minutes\n",
      "train - Value 0: 1808 occurrences\n",
      "train - Value 1: 2222 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-40  lr=['0.0002441'], tr/val_loss:  2.335812/  2.332903, val:  63.27%, val_best:  84.96%, tr:  86.03%, tr_best:  86.87%, epoch time: 163.11 seconds, 2.72 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2199 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-41  lr=['0.0002441'], tr/val_loss:  2.337430/  2.334014, val:  65.27%, val_best:  84.96%, tr:  86.75%, tr_best:  86.87%, epoch time: 163.93 seconds, 2.73 minutes\n",
      "train - Value 0: 1811 occurrences\n",
      "train - Value 1: 2219 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 388 occurrences\n",
      "test - Value 1: 64 occurrences\n",
      "epoch-42  lr=['0.0002441'], tr/val_loss:  2.336548/  2.332792, val:  61.95%, val_best:  84.96%, tr:  86.20%, tr_best:  86.87%, epoch time: 165.57 seconds, 2.76 minutes\n",
      "train - Value 0: 1804 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-43  lr=['0.0002441'], tr/val_loss:  2.337112/  2.333663, val:  57.08%, val_best:  84.96%, tr:  85.38%, tr_best:  86.87%, epoch time: 162.68 seconds, 2.71 minutes\n",
      "train - Value 0: 1813 occurrences\n",
      "train - Value 1: 2217 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-44  lr=['0.0002441'], tr/val_loss:  2.336829/  2.334421, val:  81.86%, val_best:  84.96%, tr:  85.61%, tr_best:  86.87%, epoch time: 163.77 seconds, 2.73 minutes\n",
      "train - Value 0: 1749 occurrences\n",
      "train - Value 1: 2281 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-45  lr=['0.0002441'], tr/val_loss:  2.336472/  2.336921, val:  52.88%, val_best:  84.96%, tr:  86.20%, tr_best:  86.87%, epoch time: 163.25 seconds, 2.72 minutes\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2215 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-46  lr=['0.0002441'], tr/val_loss:  2.336679/  2.335450, val:  51.11%, val_best:  84.96%, tr:  86.45%, tr_best:  86.87%, epoch time: 163.31 seconds, 2.72 minutes\n",
      "train - Value 0: 1770 occurrences\n",
      "train - Value 1: 2260 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-47  lr=['0.0002441'], tr/val_loss:  2.336018/  2.333262, val:  83.19%, val_best:  84.96%, tr:  87.87%, tr_best:  87.87%, epoch time: 163.21 seconds, 2.72 minutes\n",
      "train - Value 0: 1766 occurrences\n",
      "train - Value 1: 2264 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-48  lr=['0.0002441'], tr/val_loss:  2.335845/  2.334807, val:  75.88%, val_best:  84.96%, tr:  87.17%, tr_best:  87.87%, epoch time: 162.45 seconds, 2.71 minutes\n",
      "train - Value 0: 1801 occurrences\n",
      "train - Value 1: 2229 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-49  lr=['0.0002441'], tr/val_loss:  2.336308/  2.330568, val:  78.10%, val_best:  84.96%, tr:  89.23%, tr_best:  89.23%, epoch time: 164.51 seconds, 2.74 minutes\n",
      "train - Value 0: 1783 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-50  lr=['0.0002441'], tr/val_loss:  2.336252/  2.333784, val:  55.97%, val_best:  84.96%, tr:  87.34%, tr_best:  89.23%, epoch time: 164.86 seconds, 2.75 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-51  lr=['0.0002441'], tr/val_loss:  2.336488/  2.334065, val:  51.99%, val_best:  84.96%, tr:  87.39%, tr_best:  89.23%, epoch time: 162.73 seconds, 2.71 minutes\n",
      "train - Value 0: 1759 occurrences\n",
      "train - Value 1: 2271 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-52  lr=['0.0002441'], tr/val_loss:  2.335622/  2.333597, val:  82.96%, val_best:  84.96%, tr:  87.39%, tr_best:  89.23%, epoch time: 163.49 seconds, 2.72 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-53  lr=['0.0002441'], tr/val_loss:  2.336107/  2.335493, val:  82.52%, val_best:  84.96%, tr:  88.21%, tr_best:  89.23%, epoch time: 163.13 seconds, 2.72 minutes\n",
      "train - Value 0: 1755 occurrences\n",
      "train - Value 1: 2275 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-54  lr=['0.0002441'], tr/val_loss:  2.335697/  2.333723, val:  77.65%, val_best:  84.96%, tr:  87.44%, tr_best:  89.23%, epoch time: 164.21 seconds, 2.74 minutes\n",
      "train - Value 0: 1776 occurrences\n",
      "train - Value 1: 2254 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-55  lr=['0.0002441'], tr/val_loss:  2.334777/  2.332610, val:  81.19%, val_best:  84.96%, tr:  87.37%, tr_best:  89.23%, epoch time: 162.26 seconds, 2.70 minutes\n",
      "train - Value 0: 1782 occurrences\n",
      "train - Value 1: 2248 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-56  lr=['0.0002441'], tr/val_loss:  2.334684/  2.333729, val:  82.74%, val_best:  84.96%, tr:  86.18%, tr_best:  89.23%, epoch time: 162.36 seconds, 2.71 minutes\n",
      "train - Value 0: 1804 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-57  lr=['0.0002441'], tr/val_loss:  2.335028/  2.332275, val:  51.99%, val_best:  84.96%, tr:  86.92%, tr_best:  89.23%, epoch time: 164.12 seconds, 2.74 minutes\n",
      "train - Value 0: 1784 occurrences\n",
      "train - Value 1: 2246 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-58  lr=['0.0002441'], tr/val_loss:  2.333978/  2.330718, val:  80.97%, val_best:  84.96%, tr:  88.01%, tr_best:  89.23%, epoch time: 162.95 seconds, 2.72 minutes\n",
      "train - Value 0: 1780 occurrences\n",
      "train - Value 1: 2250 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-59  lr=['0.0002441'], tr/val_loss:  2.335613/  2.336152, val:  78.98%, val_best:  84.96%, tr:  86.67%, tr_best:  89.23%, epoch time: 163.61 seconds, 2.73 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-60  lr=['0.0002441'], tr/val_loss:  2.334651/  2.332813, val:  78.76%, val_best:  84.96%, tr:  87.89%, tr_best:  89.23%, epoch time: 161.78 seconds, 2.70 minutes\n",
      "train - Value 0: 1784 occurrences\n",
      "train - Value 1: 2246 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-61  lr=['0.0002441'], tr/val_loss:  2.334434/  2.333592, val:  81.64%, val_best:  84.96%, tr:  87.17%, tr_best:  89.23%, epoch time: 163.28 seconds, 2.72 minutes\n",
      "train - Value 0: 1824 occurrences\n",
      "train - Value 1: 2206 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-62  lr=['0.0002441'], tr/val_loss:  2.334845/  2.331266, val:  78.76%, val_best:  84.96%, tr:  86.77%, tr_best:  89.23%, epoch time: 159.99 seconds, 2.67 minutes\n",
      "train - Value 0: 1783 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-63  lr=['0.0002441'], tr/val_loss:  2.333771/  2.333610, val:  58.41%, val_best:  84.96%, tr:  88.04%, tr_best:  89.23%, epoch time: 163.00 seconds, 2.72 minutes\n",
      "train - Value 0: 1780 occurrences\n",
      "train - Value 1: 2250 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-64  lr=['0.0002441'], tr/val_loss:  2.333564/  2.333945, val:  83.63%, val_best:  84.96%, tr:  87.82%, tr_best:  89.23%, epoch time: 163.22 seconds, 2.72 minutes\n",
      "train - Value 0: 1792 occurrences\n",
      "train - Value 1: 2238 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-65  lr=['0.0002441'], tr/val_loss:  2.334579/  2.333390, val:  71.24%, val_best:  84.96%, tr:  88.01%, tr_best:  89.23%, epoch time: 162.00 seconds, 2.70 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-66  lr=['0.0002441'], tr/val_loss:  2.334131/  2.331457, val:  55.97%, val_best:  84.96%, tr:  87.89%, tr_best:  89.23%, epoch time: 163.03 seconds, 2.72 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-67  lr=['0.0002441'], tr/val_loss:  2.334374/  2.333291, val:  79.42%, val_best:  84.96%, tr:  88.81%, tr_best:  89.23%, epoch time: 162.55 seconds, 2.71 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2199 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-68  lr=['0.0002441'], tr/val_loss:  2.334807/  2.333746, val:  81.19%, val_best:  84.96%, tr:  87.89%, tr_best:  89.23%, epoch time: 163.86 seconds, 2.73 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-69  lr=['0.0002441'], tr/val_loss:  2.335015/  2.334393, val:  82.74%, val_best:  84.96%, tr:  86.82%, tr_best:  89.23%, epoch time: 161.62 seconds, 2.69 minutes\n",
      "train - Value 0: 1793 occurrences\n",
      "train - Value 1: 2237 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-70  lr=['0.0002441'], tr/val_loss:  2.334788/  2.334685, val:  82.30%, val_best:  84.96%, tr:  88.68%, tr_best:  89.23%, epoch time: 162.63 seconds, 2.71 minutes\n",
      "train - Value 0: 1792 occurrences\n",
      "train - Value 1: 2238 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-71  lr=['0.0002441'], tr/val_loss:  2.335135/  2.333647, val:  74.12%, val_best:  84.96%, tr:  87.97%, tr_best:  89.23%, epoch time: 162.58 seconds, 2.71 minutes\n",
      "train - Value 0: 1820 occurrences\n",
      "train - Value 1: 2210 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-72  lr=['0.0002441'], tr/val_loss:  2.335140/  2.333437, val:  82.30%, val_best:  84.96%, tr:  87.62%, tr_best:  89.23%, epoch time: 162.70 seconds, 2.71 minutes\n",
      "train - Value 0: 1782 occurrences\n",
      "train - Value 1: 2248 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-73  lr=['0.0002441'], tr/val_loss:  2.334223/  2.333138, val:  82.74%, val_best:  84.96%, tr:  88.46%, tr_best:  89.23%, epoch time: 162.77 seconds, 2.71 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-74  lr=['0.0002441'], tr/val_loss:  2.334262/  2.332636, val:  84.07%, val_best:  84.96%, tr:  87.87%, tr_best:  89.23%, epoch time: 162.47 seconds, 2.71 minutes\n",
      "train - Value 0: 1804 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-75  lr=['0.0002441'], tr/val_loss:  2.333920/  2.332709, val:  82.30%, val_best:  84.96%, tr:  88.21%, tr_best:  89.23%, epoch time: 159.91 seconds, 2.67 minutes\n",
      "train - Value 0: 1797 occurrences\n",
      "train - Value 1: 2233 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-76  lr=['0.0002441'], tr/val_loss:  2.334468/  2.331837, val:  80.09%, val_best:  84.96%, tr:  87.74%, tr_best:  89.23%, epoch time: 160.72 seconds, 2.68 minutes\n",
      "train - Value 0: 1781 occurrences\n",
      "train - Value 1: 2249 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-77  lr=['0.0002441'], tr/val_loss:  2.334101/  2.333878, val:  82.08%, val_best:  84.96%, tr:  87.59%, tr_best:  89.23%, epoch time: 162.67 seconds, 2.71 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-78  lr=['0.0002441'], tr/val_loss:  2.334661/  2.333406, val:  64.38%, val_best:  84.96%, tr:  88.73%, tr_best:  89.23%, epoch time: 164.75 seconds, 2.75 minutes\n",
      "train - Value 0: 1777 occurrences\n",
      "train - Value 1: 2253 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-79  lr=['0.0002441'], tr/val_loss:  2.334053/  2.333643, val:  84.51%, val_best:  84.96%, tr:  87.69%, tr_best:  89.23%, epoch time: 163.74 seconds, 2.73 minutes\n",
      "train - Value 0: 1802 occurrences\n",
      "train - Value 1: 2228 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-80  lr=['0.0002441'], tr/val_loss:  2.333659/  2.335491, val:  50.88%, val_best:  84.96%, tr:  88.56%, tr_best:  89.23%, epoch time: 163.91 seconds, 2.73 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-81  lr=['0.0002441'], tr/val_loss:  2.334873/  2.333197, val:  83.41%, val_best:  84.96%, tr:  88.88%, tr_best:  89.23%, epoch time: 165.20 seconds, 2.75 minutes\n",
      "train - Value 0: 1820 occurrences\n",
      "train - Value 1: 2210 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-82  lr=['0.0002441'], tr/val_loss:  2.334243/  2.333757, val:  74.12%, val_best:  84.96%, tr:  88.51%, tr_best:  89.23%, epoch time: 167.75 seconds, 2.80 minutes\n",
      "train - Value 0: 1804 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-83  lr=['0.0002441'], tr/val_loss:  2.334404/  2.332006, val:  81.64%, val_best:  84.96%, tr:  88.96%, tr_best:  89.23%, epoch time: 168.52 seconds, 2.81 minutes\n",
      "train - Value 0: 1776 occurrences\n",
      "train - Value 1: 2254 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-84  lr=['0.0002441'], tr/val_loss:  2.334322/  2.334644, val:  84.07%, val_best:  84.96%, tr:  88.86%, tr_best:  89.23%, epoch time: 168.68 seconds, 2.81 minutes\n",
      "train - Value 0: 1801 occurrences\n",
      "train - Value 1: 2229 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-85  lr=['0.0002441'], tr/val_loss:  2.334746/  2.332721, val:  65.04%, val_best:  84.96%, tr:  88.14%, tr_best:  89.23%, epoch time: 163.95 seconds, 2.73 minutes\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2241 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-86  lr=['0.0002441'], tr/val_loss:  2.334219/  2.332966, val:  52.88%, val_best:  84.96%, tr:  88.09%, tr_best:  89.23%, epoch time: 163.48 seconds, 2.72 minutes\n",
      "train - Value 0: 1795 occurrences\n",
      "train - Value 1: 2235 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-87  lr=['0.0002441'], tr/val_loss:  2.335027/  2.334681, val:  56.64%, val_best:  84.96%, tr:  88.14%, tr_best:  89.23%, epoch time: 162.42 seconds, 2.71 minutes\n",
      "train - Value 0: 1765 occurrences\n",
      "train - Value 1: 2265 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-88  lr=['0.0002441'], tr/val_loss:  2.334863/  2.334056, val:  78.54%, val_best:  84.96%, tr:  87.99%, tr_best:  89.23%, epoch time: 162.23 seconds, 2.70 minutes\n",
      "train - Value 0: 1813 occurrences\n",
      "train - Value 1: 2217 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-89  lr=['0.0002441'], tr/val_loss:  2.334440/  2.331675, val:  63.94%, val_best:  84.96%, tr:  88.24%, tr_best:  89.23%, epoch time: 161.37 seconds, 2.69 minutes\n",
      "train - Value 0: 1774 occurrences\n",
      "train - Value 1: 2256 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-90  lr=['0.0002441'], tr/val_loss:  2.334386/  2.333998, val:  84.29%, val_best:  84.96%, tr:  88.21%, tr_best:  89.23%, epoch time: 161.41 seconds, 2.69 minutes\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2221 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-91  lr=['0.0002441'], tr/val_loss:  2.334648/  2.336598, val:  78.54%, val_best:  84.96%, tr:  89.33%, tr_best:  89.33%, epoch time: 161.09 seconds, 2.68 minutes\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2221 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-92  lr=['0.0002441'], tr/val_loss:  2.334664/  2.336648, val:  61.73%, val_best:  84.96%, tr:  88.24%, tr_best:  89.33%, epoch time: 161.88 seconds, 2.70 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-93  lr=['0.0002441'], tr/val_loss:  2.334177/  2.332781, val:  73.45%, val_best:  84.96%, tr:  88.54%, tr_best:  89.33%, epoch time: 161.60 seconds, 2.69 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-94  lr=['0.0002441'], tr/val_loss:  2.334879/  2.332428, val:  82.30%, val_best:  84.96%, tr:  88.14%, tr_best:  89.33%, epoch time: 163.26 seconds, 2.72 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-95  lr=['0.0002441'], tr/val_loss:  2.334772/  2.331691, val:  50.66%, val_best:  84.96%, tr:  88.88%, tr_best:  89.33%, epoch time: 162.51 seconds, 2.71 minutes\n",
      "train - Value 0: 1798 occurrences\n",
      "train - Value 1: 2232 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-96  lr=['0.0002441'], tr/val_loss:  2.334666/  2.335857, val:  76.33%, val_best:  84.96%, tr:  88.86%, tr_best:  89.33%, epoch time: 161.28 seconds, 2.69 minutes\n",
      "train - Value 0: 1794 occurrences\n",
      "train - Value 1: 2236 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-97  lr=['0.0002441'], tr/val_loss:  2.334434/  2.334009, val:  74.12%, val_best:  84.96%, tr:  87.92%, tr_best:  89.33%, epoch time: 160.86 seconds, 2.68 minutes\n",
      "train - Value 0: 1784 occurrences\n",
      "train - Value 1: 2246 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-98  lr=['0.0002441'], tr/val_loss:  2.333941/  2.332752, val:  72.35%, val_best:  84.96%, tr:  89.06%, tr_best:  89.33%, epoch time: 162.58 seconds, 2.71 minutes\n",
      "train - Value 0: 1802 occurrences\n",
      "train - Value 1: 2228 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-99  lr=['0.0002441'], tr/val_loss:  2.334593/  2.333168, val:  71.46%, val_best:  84.96%, tr:  88.46%, tr_best:  89.33%, epoch time: 161.25 seconds, 2.69 minutes\n",
      "train - Value 0: 1773 occurrences\n",
      "train - Value 1: 2257 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-100 lr=['0.0002441'], tr/val_loss:  2.334675/  2.336030, val:  51.99%, val_best:  84.96%, tr:  88.49%, tr_best:  89.33%, epoch time: 162.32 seconds, 2.71 minutes\n",
      "train - Value 0: 1812 occurrences\n",
      "train - Value 1: 2218 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-101 lr=['0.0002441'], tr/val_loss:  2.335143/  2.333616, val:  83.19%, val_best:  84.96%, tr:  88.76%, tr_best:  89.33%, epoch time: 160.86 seconds, 2.68 minutes\n",
      "train - Value 0: 1774 occurrences\n",
      "train - Value 1: 2256 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-102 lr=['0.0002441'], tr/val_loss:  2.334088/  2.333993, val:  61.73%, val_best:  84.96%, tr:  88.26%, tr_best:  89.33%, epoch time: 161.73 seconds, 2.70 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-103 lr=['0.0002441'], tr/val_loss:  2.334580/  2.334681, val:  74.56%, val_best:  84.96%, tr:  88.78%, tr_best:  89.33%, epoch time: 162.29 seconds, 2.70 minutes\n",
      "train - Value 0: 1788 occurrences\n",
      "train - Value 1: 2242 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-104 lr=['0.0002441'], tr/val_loss:  2.334608/  2.333240, val:  83.63%, val_best:  84.96%, tr:  88.81%, tr_best:  89.33%, epoch time: 162.38 seconds, 2.71 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-105 lr=['0.0002441'], tr/val_loss:  2.334563/  2.334493, val:  77.21%, val_best:  84.96%, tr:  88.68%, tr_best:  89.33%, epoch time: 162.02 seconds, 2.70 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-106 lr=['0.0002441'], tr/val_loss:  2.334649/  2.333944, val:  65.93%, val_best:  84.96%, tr:  88.26%, tr_best:  89.33%, epoch time: 161.35 seconds, 2.69 minutes\n",
      "train - Value 0: 1770 occurrences\n",
      "train - Value 1: 2260 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-107 lr=['0.0002441'], tr/val_loss:  2.333905/  2.334455, val:  76.99%, val_best:  84.96%, tr:  88.31%, tr_best:  89.33%, epoch time: 162.18 seconds, 2.70 minutes\n",
      "train - Value 0: 1759 occurrences\n",
      "train - Value 1: 2271 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-108 lr=['0.0002441'], tr/val_loss:  2.334040/  2.332293, val:  59.96%, val_best:  84.96%, tr:  87.69%, tr_best:  89.33%, epoch time: 162.15 seconds, 2.70 minutes\n",
      "train - Value 0: 1817 occurrences\n",
      "train - Value 1: 2213 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-109 lr=['0.0002441'], tr/val_loss:  2.334038/  2.332539, val:  84.29%, val_best:  84.96%, tr:  90.22%, tr_best:  90.22%, epoch time: 161.53 seconds, 2.69 minutes\n",
      "train - Value 0: 1776 occurrences\n",
      "train - Value 1: 2254 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-110 lr=['0.0002441'], tr/val_loss:  2.334511/  2.334683, val:  80.31%, val_best:  84.96%, tr:  88.41%, tr_best:  90.22%, epoch time: 161.81 seconds, 2.70 minutes\n",
      "train - Value 0: 1814 occurrences\n",
      "train - Value 1: 2216 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-111 lr=['0.0002441'], tr/val_loss:  2.334895/  2.334122, val:  68.81%, val_best:  84.96%, tr:  89.50%, tr_best:  90.22%, epoch time: 162.47 seconds, 2.71 minutes\n",
      "train - Value 0: 1783 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-112 lr=['0.0002441'], tr/val_loss:  2.334050/  2.331630, val:  79.42%, val_best:  84.96%, tr:  89.58%, tr_best:  90.22%, epoch time: 163.06 seconds, 2.72 minutes\n",
      "train - Value 0: 1802 occurrences\n",
      "train - Value 1: 2228 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-113 lr=['0.0002441'], tr/val_loss:  2.333640/  2.332532, val:  64.16%, val_best:  84.96%, tr:  89.16%, tr_best:  90.22%, epoch time: 161.81 seconds, 2.70 minutes\n",
      "train - Value 0: 1796 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-114 lr=['0.0002441'], tr/val_loss:  2.334093/  2.332185, val:  76.77%, val_best:  84.96%, tr:  88.21%, tr_best:  90.22%, epoch time: 162.55 seconds, 2.71 minutes\n",
      "train - Value 0: 1759 occurrences\n",
      "train - Value 1: 2271 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-115 lr=['0.0002441'], tr/val_loss:  2.334740/  2.332631, val:  56.19%, val_best:  84.96%, tr:  88.39%, tr_best:  90.22%, epoch time: 163.28 seconds, 2.72 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-116 lr=['0.0002441'], tr/val_loss:  2.334841/  2.334372, val:  53.54%, val_best:  84.96%, tr:  88.24%, tr_best:  90.22%, epoch time: 161.54 seconds, 2.69 minutes\n",
      "train - Value 0: 1821 occurrences\n",
      "train - Value 1: 2209 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-117 lr=['0.0002441'], tr/val_loss:  2.335091/  2.335920, val:  83.41%, val_best:  84.96%, tr:  88.54%, tr_best:  90.22%, epoch time: 161.41 seconds, 2.69 minutes\n",
      "train - Value 0: 1768 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-118 lr=['0.0002441'], tr/val_loss:  2.334120/  2.334310, val:  60.84%, val_best:  84.96%, tr:  88.36%, tr_best:  90.22%, epoch time: 162.55 seconds, 2.71 minutes\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2215 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-119 lr=['0.0002441'], tr/val_loss:  2.335583/  2.336456, val:  81.19%, val_best:  84.96%, tr:  88.29%, tr_best:  90.22%, epoch time: 162.25 seconds, 2.70 minutes\n",
      "train - Value 0: 1805 occurrences\n",
      "train - Value 1: 2225 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-120 lr=['0.0002441'], tr/val_loss:  2.335080/  2.333771, val:  82.74%, val_best:  84.96%, tr:  88.64%, tr_best:  90.22%, epoch time: 162.25 seconds, 2.70 minutes\n",
      "train - Value 0: 1826 occurrences\n",
      "train - Value 1: 2204 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-121 lr=['0.0002441'], tr/val_loss:  2.335216/  2.332139, val:  66.59%, val_best:  84.96%, tr:  89.50%, tr_best:  90.22%, epoch time: 163.12 seconds, 2.72 minutes\n",
      "train - Value 0: 1827 occurrences\n",
      "train - Value 1: 2203 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-122 lr=['0.0002441'], tr/val_loss:  2.335852/  2.334913, val:  73.01%, val_best:  84.96%, tr:  89.53%, tr_best:  90.22%, epoch time: 162.52 seconds, 2.71 minutes\n",
      "train - Value 0: 1798 occurrences\n",
      "train - Value 1: 2232 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-123 lr=['0.0002441'], tr/val_loss:  2.335883/  2.335245, val:  83.19%, val_best:  84.96%, tr:  89.21%, tr_best:  90.22%, epoch time: 162.67 seconds, 2.71 minutes\n",
      "train - Value 0: 1837 occurrences\n",
      "train - Value 1: 2193 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-124 lr=['0.0002441'], tr/val_loss:  2.336240/  2.336215, val:  61.28%, val_best:  84.96%, tr:  88.59%, tr_best:  90.22%, epoch time: 161.87 seconds, 2.70 minutes\n",
      "train - Value 0: 1821 occurrences\n",
      "train - Value 1: 2209 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-125 lr=['0.0002441'], tr/val_loss:  2.336070/  2.335801, val:  68.58%, val_best:  84.96%, tr:  89.28%, tr_best:  90.22%, epoch time: 162.20 seconds, 2.70 minutes\n",
      "train - Value 0: 1820 occurrences\n",
      "train - Value 1: 2210 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-126 lr=['0.0002441'], tr/val_loss:  2.336003/  2.333338, val:  83.41%, val_best:  84.96%, tr:  89.16%, tr_best:  90.22%, epoch time: 162.65 seconds, 2.71 minutes\n",
      "train - Value 0: 1801 occurrences\n",
      "train - Value 1: 2229 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-127 lr=['0.0002441'], tr/val_loss:  2.335404/  2.333448, val:  71.68%, val_best:  84.96%, tr:  89.63%, tr_best:  90.22%, epoch time: 162.86 seconds, 2.71 minutes\n",
      "train - Value 0: 1763 occurrences\n",
      "train - Value 1: 2267 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-128 lr=['0.0002441'], tr/val_loss:  2.335418/  2.336349, val:  71.90%, val_best:  84.96%, tr:  88.64%, tr_best:  90.22%, epoch time: 162.68 seconds, 2.71 minutes\n",
      "train - Value 0: 1767 occurrences\n",
      "train - Value 1: 2263 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-129 lr=['0.0002441'], tr/val_loss:  2.335480/  2.333409, val:  80.97%, val_best:  84.96%, tr:  89.18%, tr_best:  90.22%, epoch time: 160.92 seconds, 2.68 minutes\n",
      "train - Value 0: 1771 occurrences\n",
      "train - Value 1: 2259 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-130 lr=['0.0002441'], tr/val_loss:  2.335536/  2.335665, val:  83.41%, val_best:  84.96%, tr:  88.73%, tr_best:  90.22%, epoch time: 162.15 seconds, 2.70 minutes\n",
      "train - Value 0: 1807 occurrences\n",
      "train - Value 1: 2223 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-131 lr=['0.0002441'], tr/val_loss:  2.335493/  2.334586, val:  79.20%, val_best:  84.96%, tr:  89.38%, tr_best:  90.22%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 1803 occurrences\n",
      "train - Value 1: 2227 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-132 lr=['0.0002441'], tr/val_loss:  2.335547/  2.335325, val:  56.42%, val_best:  84.96%, tr:  87.84%, tr_best:  90.22%, epoch time: 162.50 seconds, 2.71 minutes\n",
      "train - Value 0: 1797 occurrences\n",
      "train - Value 1: 2233 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-133 lr=['0.0002441'], tr/val_loss:  2.335491/  2.335289, val:  80.31%, val_best:  84.96%, tr:  89.08%, tr_best:  90.22%, epoch time: 161.78 seconds, 2.70 minutes\n",
      "train - Value 0: 1817 occurrences\n",
      "train - Value 1: 2213 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['0.0002441'], tr/val_loss:  2.335512/  2.333670, val:  50.00%, val_best:  84.96%, tr:  88.88%, tr_best:  90.22%, epoch time: 161.40 seconds, 2.69 minutes\n",
      "train - Value 0: 1792 occurrences\n",
      "train - Value 1: 2238 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-135 lr=['0.0002441'], tr/val_loss:  2.336728/  2.337360, val:  80.53%, val_best:  84.96%, tr:  87.97%, tr_best:  90.22%, epoch time: 161.53 seconds, 2.69 minutes\n",
      "train - Value 0: 1795 occurrences\n",
      "train - Value 1: 2235 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-136 lr=['0.0002441'], tr/val_loss:  2.336064/  2.335586, val:  72.57%, val_best:  84.96%, tr:  88.88%, tr_best:  90.22%, epoch time: 161.95 seconds, 2.70 minutes\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2241 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-137 lr=['0.0002441'], tr/val_loss:  2.335943/  2.335043, val:  83.41%, val_best:  84.96%, tr:  88.68%, tr_best:  90.22%, epoch time: 161.31 seconds, 2.69 minutes\n",
      "train - Value 0: 1755 occurrences\n",
      "train - Value 1: 2275 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-138 lr=['0.0002441'], tr/val_loss:  2.335195/  2.334014, val:  83.85%, val_best:  84.96%, tr:  88.78%, tr_best:  90.22%, epoch time: 161.57 seconds, 2.69 minutes\n",
      "train - Value 0: 1810 occurrences\n",
      "train - Value 1: 2220 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 361 occurrences\n",
      "test - Value 1: 91 occurrences\n",
      "epoch-139 lr=['0.0002441'], tr/val_loss:  2.335714/  2.335311, val:  66.15%, val_best:  84.96%, tr:  89.06%, tr_best:  90.22%, epoch time: 163.14 seconds, 2.72 minutes\n",
      "train - Value 0: 1800 occurrences\n",
      "train - Value 1: 2230 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-140 lr=['0.0002441'], tr/val_loss:  2.336148/  2.338111, val:  56.42%, val_best:  84.96%, tr:  88.16%, tr_best:  90.22%, epoch time: 161.98 seconds, 2.70 minutes\n",
      "train - Value 0: 1805 occurrences\n",
      "train - Value 1: 2225 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-141 lr=['0.0002441'], tr/val_loss:  2.335823/  2.334646, val:  82.52%, val_best:  84.96%, tr:  90.02%, tr_best:  90.22%, epoch time: 161.36 seconds, 2.69 minutes\n",
      "train - Value 0: 1812 occurrences\n",
      "train - Value 1: 2218 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 359 occurrences\n",
      "test - Value 1: 93 occurrences\n",
      "epoch-142 lr=['0.0002441'], tr/val_loss:  2.335961/  2.334003, val:  67.04%, val_best:  84.96%, tr:  89.01%, tr_best:  90.22%, epoch time: 162.74 seconds, 2.71 minutes\n",
      "train - Value 0: 1770 occurrences\n",
      "train - Value 1: 2260 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-143 lr=['0.0002441'], tr/val_loss:  2.336073/  2.333048, val:  80.75%, val_best:  84.96%, tr:  89.31%, tr_best:  90.22%, epoch time: 163.04 seconds, 2.72 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-144 lr=['0.0002441'], tr/val_loss:  2.336253/  2.335417, val:  85.40%, val_best:  85.40%, tr:  88.59%, tr_best:  90.22%, epoch time: 162.99 seconds, 2.72 minutes\n",
      "train - Value 0: 1816 occurrences\n",
      "train - Value 1: 2214 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-145 lr=['0.0002441'], tr/val_loss:  2.336249/  2.335184, val:  80.97%, val_best:  85.40%, tr:  88.91%, tr_best:  90.22%, epoch time: 162.86 seconds, 2.71 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-146 lr=['0.0002441'], tr/val_loss:  2.335877/  2.337766, val:  61.06%, val_best:  85.40%, tr:  88.14%, tr_best:  90.22%, epoch time: 161.96 seconds, 2.70 minutes\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2241 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-147 lr=['0.0002441'], tr/val_loss:  2.335787/  2.336948, val:  80.09%, val_best:  85.40%, tr:  88.73%, tr_best:  90.22%, epoch time: 164.35 seconds, 2.74 minutes\n",
      "train - Value 0: 1799 occurrences\n",
      "train - Value 1: 2231 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-148 lr=['0.0002441'], tr/val_loss:  2.336083/  2.335049, val:  79.42%, val_best:  85.40%, tr:  89.23%, tr_best:  90.22%, epoch time: 162.08 seconds, 2.70 minutes\n",
      "train - Value 0: 1793 occurrences\n",
      "train - Value 1: 2237 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-149 lr=['0.0002441'], tr/val_loss:  2.336048/  2.334046, val:  82.30%, val_best:  85.40%, tr:  88.88%, tr_best:  90.22%, epoch time: 162.20 seconds, 2.70 minutes\n",
      "train - Value 0: 1793 occurrences\n",
      "train - Value 1: 2237 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-150 lr=['0.0002441'], tr/val_loss:  2.335570/  2.336532, val:  58.63%, val_best:  85.40%, tr:  89.53%, tr_best:  90.22%, epoch time: 162.89 seconds, 2.71 minutes\n",
      "train - Value 0: 1779 occurrences\n",
      "train - Value 1: 2251 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-151 lr=['0.0002441'], tr/val_loss:  2.335478/  2.334427, val:  83.41%, val_best:  85.40%, tr:  88.78%, tr_best:  90.22%, epoch time: 162.71 seconds, 2.71 minutes\n",
      "train - Value 0: 1810 occurrences\n",
      "train - Value 1: 2220 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-152 lr=['0.0002441'], tr/val_loss:  2.335093/  2.333965, val:  50.44%, val_best:  85.40%, tr:  89.80%, tr_best:  90.22%, epoch time: 162.39 seconds, 2.71 minutes\n",
      "train - Value 0: 1825 occurrences\n",
      "train - Value 1: 2205 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-153 lr=['0.0002441'], tr/val_loss:  2.336375/  2.335929, val:  85.18%, val_best:  85.40%, tr:  88.44%, tr_best:  90.22%, epoch time: 161.12 seconds, 2.69 minutes\n",
      "train - Value 0: 1782 occurrences\n",
      "train - Value 1: 2248 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-154 lr=['0.0002441'], tr/val_loss:  2.335250/  2.332782, val:  80.09%, val_best:  85.40%, tr:  89.01%, tr_best:  90.22%, epoch time: 162.30 seconds, 2.71 minutes\n",
      "train - Value 0: 1819 occurrences\n",
      "train - Value 1: 2211 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-155 lr=['0.0002441'], tr/val_loss:  2.335975/  2.335117, val:  82.96%, val_best:  85.40%, tr:  88.88%, tr_best:  90.22%, epoch time: 162.57 seconds, 2.71 minutes\n",
      "train - Value 0: 1783 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-156 lr=['0.0002441'], tr/val_loss:  2.335648/  2.334154, val:  81.64%, val_best:  85.40%, tr:  89.58%, tr_best:  90.22%, epoch time: 162.51 seconds, 2.71 minutes\n",
      "train - Value 0: 1850 occurrences\n",
      "train - Value 1: 2180 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-157 lr=['0.0002441'], tr/val_loss:  2.335522/  2.333583, val:  76.99%, val_best:  85.40%, tr:  89.35%, tr_best:  90.22%, epoch time: 161.96 seconds, 2.70 minutes\n",
      "train - Value 0: 1788 occurrences\n",
      "train - Value 1: 2242 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-158 lr=['0.0002441'], tr/val_loss:  2.335780/  2.334875, val:  84.96%, val_best:  85.40%, tr:  88.86%, tr_best:  90.22%, epoch time: 162.35 seconds, 2.71 minutes\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2215 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-159 lr=['0.0002441'], tr/val_loss:  2.335314/  2.336464, val:  80.53%, val_best:  85.40%, tr:  89.93%, tr_best:  90.22%, epoch time: 162.39 seconds, 2.71 minutes\n",
      "train - Value 0: 1840 occurrences\n",
      "train - Value 1: 2190 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-160 lr=['0.0002441'], tr/val_loss:  2.336701/  2.335988, val:  84.51%, val_best:  85.40%, tr:  89.21%, tr_best:  90.22%, epoch time: 163.49 seconds, 2.72 minutes\n",
      "train - Value 0: 1843 occurrences\n",
      "train - Value 1: 2187 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-161 lr=['0.0002441'], tr/val_loss:  2.336279/  2.336159, val:  83.85%, val_best:  85.40%, tr:  89.48%, tr_best:  90.22%, epoch time: 163.47 seconds, 2.72 minutes\n",
      "train - Value 0: 1800 occurrences\n",
      "train - Value 1: 2230 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-162 lr=['0.0002441'], tr/val_loss:  2.335356/  2.336552, val:  82.74%, val_best:  85.40%, tr:  89.21%, tr_best:  90.22%, epoch time: 161.80 seconds, 2.70 minutes\n",
      "train - Value 0: 1824 occurrences\n",
      "train - Value 1: 2206 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-163 lr=['0.0002441'], tr/val_loss:  2.334946/  2.332877, val:  78.32%, val_best:  85.40%, tr:  89.35%, tr_best:  90.22%, epoch time: 160.74 seconds, 2.68 minutes\n",
      "train - Value 0: 1808 occurrences\n",
      "train - Value 1: 2222 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-164 lr=['0.0002441'], tr/val_loss:  2.335162/  2.333741, val:  82.08%, val_best:  85.40%, tr:  89.11%, tr_best:  90.22%, epoch time: 162.71 seconds, 2.71 minutes\n",
      "train - Value 0: 1793 occurrences\n",
      "train - Value 1: 2237 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 330 occurrences\n",
      "test - Value 1: 122 occurrences\n",
      "epoch-165 lr=['0.0002441'], tr/val_loss:  2.334774/  2.334281, val:  71.24%, val_best:  85.40%, tr:  90.07%, tr_best:  90.22%, epoch time: 163.10 seconds, 2.72 minutes\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2215 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-166 lr=['0.0002441'], tr/val_loss:  2.335389/  2.334890, val:  79.65%, val_best:  85.40%, tr:  89.23%, tr_best:  90.22%, epoch time: 160.74 seconds, 2.68 minutes\n",
      "train - Value 0: 1813 occurrences\n",
      "train - Value 1: 2217 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-167 lr=['0.0002441'], tr/val_loss:  2.336371/  2.334708, val:  79.65%, val_best:  85.40%, tr:  89.43%, tr_best:  90.22%, epoch time: 162.56 seconds, 2.71 minutes\n",
      "train - Value 0: 1823 occurrences\n",
      "train - Value 1: 2207 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 358 occurrences\n",
      "test - Value 1: 94 occurrences\n",
      "epoch-168 lr=['0.0002441'], tr/val_loss:  2.334961/  2.334436, val:  67.70%, val_best:  85.40%, tr:  89.63%, tr_best:  90.22%, epoch time: 162.33 seconds, 2.71 minutes\n",
      "train - Value 0: 1794 occurrences\n",
      "train - Value 1: 2236 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-169 lr=['0.0002441'], tr/val_loss:  2.335110/  2.332730, val:  80.53%, val_best:  85.40%, tr:  89.31%, tr_best:  90.22%, epoch time: 162.96 seconds, 2.72 minutes\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-170 lr=['0.0002441'], tr/val_loss:  2.334927/  2.332831, val:  75.44%, val_best:  85.40%, tr:  89.13%, tr_best:  90.22%, epoch time: 162.47 seconds, 2.71 minutes\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2215 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-171 lr=['0.0002441'], tr/val_loss:  2.335273/  2.337657, val:  76.11%, val_best:  85.40%, tr:  88.98%, tr_best:  90.22%, epoch time: 162.69 seconds, 2.71 minutes\n",
      "train - Value 0: 1796 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-172 lr=['0.0002441'], tr/val_loss:  2.335136/  2.334071, val:  79.65%, val_best:  85.40%, tr:  89.65%, tr_best:  90.22%, epoch time: 162.00 seconds, 2.70 minutes\n",
      "train - Value 0: 1765 occurrences\n",
      "train - Value 1: 2265 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-173 lr=['0.0002441'], tr/val_loss:  2.335472/  2.334488, val:  79.20%, val_best:  85.40%, tr:  89.18%, tr_best:  90.22%, epoch time: 162.45 seconds, 2.71 minutes\n",
      "train - Value 0: 1798 occurrences\n",
      "train - Value 1: 2232 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-174 lr=['0.0002441'], tr/val_loss:  2.336345/  2.332701, val:  78.10%, val_best:  85.40%, tr:  89.01%, tr_best:  90.22%, epoch time: 162.64 seconds, 2.71 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2199 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-175 lr=['0.0002441'], tr/val_loss:  2.335567/  2.334953, val:  78.10%, val_best:  85.40%, tr:  89.18%, tr_best:  90.22%, epoch time: 161.55 seconds, 2.69 minutes\n",
      "train - Value 0: 1796 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-176 lr=['0.0002441'], tr/val_loss:  2.335868/  2.334160, val:  84.51%, val_best:  85.40%, tr:  89.70%, tr_best:  90.22%, epoch time: 162.42 seconds, 2.71 minutes\n",
      "train - Value 0: 1829 occurrences\n",
      "train - Value 1: 2201 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-177 lr=['0.0002441'], tr/val_loss:  2.335767/  2.334091, val:  82.96%, val_best:  85.40%, tr:  89.83%, tr_best:  90.22%, epoch time: 162.51 seconds, 2.71 minutes\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2221 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-178 lr=['0.0002441'], tr/val_loss:  2.335855/  2.336810, val:  57.30%, val_best:  85.40%, tr:  90.17%, tr_best:  90.22%, epoch time: 162.24 seconds, 2.70 minutes\n",
      "train - Value 0: 1828 occurrences\n",
      "train - Value 1: 2202 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-179 lr=['0.0002441'], tr/val_loss:  2.335732/  2.335516, val:  81.86%, val_best:  85.40%, tr:  90.74%, tr_best:  90.74%, epoch time: 162.44 seconds, 2.71 minutes\n",
      "train - Value 0: 1800 occurrences\n",
      "train - Value 1: 2230 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-180 lr=['0.0002441'], tr/val_loss:  2.335662/  2.333918, val:  74.56%, val_best:  85.40%, tr:  89.06%, tr_best:  90.74%, epoch time: 161.83 seconds, 2.70 minutes\n",
      "train - Value 0: 1844 occurrences\n",
      "train - Value 1: 2186 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-181 lr=['0.0002441'], tr/val_loss:  2.335619/  2.333019, val:  63.05%, val_best:  85.40%, tr:  90.40%, tr_best:  90.74%, epoch time: 162.32 seconds, 2.71 minutes\n",
      "train - Value 0: 1837 occurrences\n",
      "train - Value 1: 2193 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-182 lr=['0.0002441'], tr/val_loss:  2.335950/  2.335085, val:  78.54%, val_best:  85.40%, tr:  89.98%, tr_best:  90.74%, epoch time: 162.18 seconds, 2.70 minutes\n",
      "train - Value 0: 1821 occurrences\n",
      "train - Value 1: 2209 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-183 lr=['0.0002441'], tr/val_loss:  2.336421/  2.334631, val:  80.09%, val_best:  85.40%, tr:  89.13%, tr_best:  90.74%, epoch time: 163.30 seconds, 2.72 minutes\n",
      "train - Value 0: 1829 occurrences\n",
      "train - Value 1: 2201 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-184 lr=['0.0002441'], tr/val_loss:  2.336752/  2.335788, val:  81.42%, val_best:  85.40%, tr:  90.07%, tr_best:  90.74%, epoch time: 160.81 seconds, 2.68 minutes\n",
      "train - Value 0: 1819 occurrences\n",
      "train - Value 1: 2211 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-185 lr=['0.0002441'], tr/val_loss:  2.336232/  2.335076, val:  59.96%, val_best:  85.40%, tr:  89.68%, tr_best:  90.74%, epoch time: 163.46 seconds, 2.72 minutes\n",
      "train - Value 0: 1775 occurrences\n",
      "train - Value 1: 2255 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-186 lr=['0.0002441'], tr/val_loss:  2.336131/  2.336389, val:  65.49%, val_best:  85.40%, tr:  89.98%, tr_best:  90.74%, epoch time: 160.74 seconds, 2.68 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-187 lr=['0.0002441'], tr/val_loss:  2.336343/  2.336306, val:  52.43%, val_best:  85.40%, tr:  88.93%, tr_best:  90.74%, epoch time: 162.01 seconds, 2.70 minutes\n",
      "train - Value 0: 1807 occurrences\n",
      "train - Value 1: 2223 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-188 lr=['0.0002441'], tr/val_loss:  2.336489/  2.336196, val:  64.60%, val_best:  85.40%, tr:  89.78%, tr_best:  90.74%, epoch time: 162.59 seconds, 2.71 minutes\n",
      "train - Value 0: 1816 occurrences\n",
      "train - Value 1: 2214 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 295 occurrences\n",
      "test - Value 1: 157 occurrences\n",
      "epoch-189 lr=['0.0002441'], tr/val_loss:  2.336389/  2.335774, val:  77.21%, val_best:  85.40%, tr:  88.91%, tr_best:  90.74%, epoch time: 161.16 seconds, 2.69 minutes\n",
      "train - Value 0: 1823 occurrences\n",
      "train - Value 1: 2207 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-190 lr=['0.0002441'], tr/val_loss:  2.336397/  2.333303, val:  68.14%, val_best:  85.40%, tr:  88.83%, tr_best:  90.74%, epoch time: 163.30 seconds, 2.72 minutes\n",
      "train - Value 0: 1785 occurrences\n",
      "train - Value 1: 2245 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-191 lr=['0.0002441'], tr/val_loss:  2.336115/  2.333974, val:  82.52%, val_best:  85.40%, tr:  88.83%, tr_best:  90.74%, epoch time: 162.25 seconds, 2.70 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-192 lr=['0.0002441'], tr/val_loss:  2.336409/  2.336923, val:  57.30%, val_best:  85.40%, tr:  89.18%, tr_best:  90.74%, epoch time: 162.30 seconds, 2.71 minutes\n",
      "train - Value 0: 1836 occurrences\n",
      "train - Value 1: 2194 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-193 lr=['0.0002441'], tr/val_loss:  2.336720/  2.336900, val:  83.19%, val_best:  85.40%, tr:  89.16%, tr_best:  90.74%, epoch time: 162.04 seconds, 2.70 minutes\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2199 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-194 lr=['0.0002441'], tr/val_loss:  2.336836/  2.335226, val:  58.85%, val_best:  85.40%, tr:  89.73%, tr_best:  90.74%, epoch time: 161.96 seconds, 2.70 minutes\n",
      "train - Value 0: 1800 occurrences\n",
      "train - Value 1: 2230 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-195 lr=['0.0002441'], tr/val_loss:  2.336685/  2.335480, val:  84.29%, val_best:  85.40%, tr:  89.90%, tr_best:  90.74%, epoch time: 160.60 seconds, 2.68 minutes\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2239 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-196 lr=['0.0002441'], tr/val_loss:  2.336340/  2.336784, val:  84.29%, val_best:  85.40%, tr:  89.93%, tr_best:  90.74%, epoch time: 159.95 seconds, 2.67 minutes\n",
      "train - Value 0: 1813 occurrences\n",
      "train - Value 1: 2217 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-197 lr=['0.0002441'], tr/val_loss:  2.337100/  2.336410, val:  75.88%, val_best:  85.40%, tr:  89.88%, tr_best:  90.74%, epoch time: 160.73 seconds, 2.68 minutes\n",
      "train - Value 0: 1802 occurrences\n",
      "train - Value 1: 2228 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-198 lr=['0.0002441'], tr/val_loss:  2.336942/  2.336830, val:  82.30%, val_best:  85.40%, tr:  90.05%, tr_best:  90.74%, epoch time: 159.12 seconds, 2.65 minutes\n",
      "train - Value 0: 1817 occurrences\n",
      "train - Value 1: 2213 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-199 lr=['0.0002441'], tr/val_loss:  2.337305/  2.336917, val:  80.75%, val_best:  85.40%, tr:  89.63%, tr_best:  90.74%, epoch time: 159.88 seconds, 2.66 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e96c40929844d0bae823eed254c7d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÇ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÅ‚ñà‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÇ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÅ‚ñà‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.89628</td></tr><tr><td>tr_epoch_loss</td><td>2.33731</td></tr><tr><td>val_acc_best</td><td>0.85398</td></tr><tr><td>val_acc_now</td><td>0.80752</td></tr><tr><td>val_loss</td><td>2.33692</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-sweep-59</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hmm8ryhr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hmm8ryhr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250724_170126-hmm8ryhr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rfh9ifsm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0009765625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250725_020417-rfh9ifsm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rfh9ifsm' target=\"_blank\">expert-sweep-67</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rfh9ifsm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rfh9ifsm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250725_020425_846', 'my_seed': 42, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 6, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 5, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 5\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABIqUlEQVR4nO3deVxV9b7/8fcGNmOKIjIlkZmaJZHDcSyFFBxSSysrDSccOjZo6u1knY54rzdLH1kdLet0Fefh1ElPdYrEUtGcErWTwzUyHEDQNAUVRGSv3x9e9q8toLBl2C5fz8eDx6P1Xd+91mftj8SbtddaWAzDMAQAAIAbnlttFwAAAICqQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADbnCffPKJLBaLVq5cWWpdVFSULBaLvv7661LrmjRpotatW1dqX8OGDdPtt9/uVJ2JiYmyWCw6efLkNee+/vrrWr169TXn/fOf/5TFYtEHH3xQ7pyUlBRZLBbNmjWrwrVez3Fer9tvv10Wi0UWi0Vubm7y9/dXixYtNGTIEK1Zs6bM11gsFiUmJlZqP19++WWlX1PWvhYsWCCLxaIdO3ZUelvlOXbsmBITE7V79+5S60r+HQEoG8EOuMFFR0fLYrFo3bp1DuO//fabfvzxR/n5+ZVal5mZqV9++UUxMTGV2tdrr72mVatWXXfN11LRYPfQQw8pJCRE8+fPL3dOUlKSrFar4uPjq7DC6tW5c2dt2bJFmzdv1j/+8Q8999xzysjIUI8ePfTYY4+pqKjIYf6WLVs0cuTISu3jyy+/1NSpUytdmzP7qqxjx45p6tSpZQa7kSNHasuWLdW6f+BGRrADbnCBgYFq2bKl1q9f7zC+YcMGeXh4KCEhoVSwK1mubLBr0qSJWrVqdV31ViUPDw8NGTJE33//vfbs2VNq/ZkzZ7Rq1Sr169dPDRs2rIUKnVOvXj116NBBHTp0UPfu3fXss89q48aNmjJliv7xj3/oz3/+s8P8Dh06qFGjRtVWj2EYKigoqJF9XUujRo3UoUOHWts/4OoIdoAJxMTE6MCBA8rOzraPrV+/Xn/4wx/Uu3dvpaWl6ezZsw7r3N3d9cADD0i6/IP7/fff13333ScfHx/Vr19fjz32mH755ReH/ZT1EeWZM2eUkJCggIAA3XLLLXrooYf0yy+/lPvx4PHjx/XUU0/J399fwcHBGjFihHJzc+3rLRaLzp8/r4ULF9o/koyOji732BMSEiRdPjN3peXLl+vChQsaMWKEJOm9995Tly5dFBQUJD8/P0VGRmrGjBmlzoBd6dChQ7JYLFqwYEGpdWUdZ3p6ugYNGqSgoCB5eXmpRYsWeu+99666j4pITEzUPffcozlz5ujChQvl1pCfn69JkyapcePG8vb2VkBAgNq2bavly5dLutzHknpK3mOLxaJDhw7Zx5577jl98MEHatGihby8vLRw4cJyj1eSTp8+reHDhysgIEB+fn7q27dvqX8/t99+u4YNG1bqtdHR0fYel/y7laThw4fbayvZZ1kfxdpsNs2YMUN33XWXvLy8FBQUpCFDhigzM7PUflq2bKnvv/9eDzzwgHx9fXXHHXfojTfekM1mK/+NB24gBDvABErOvP3+rN26devUtWtXde7cWRaLRRs3bnRY17p1a/n7+0uSxowZo/Hjx6t79+5avXq13n//fe3du1edOnXS8ePHy92vzWZT3759tWzZMv3pT3/SqlWr1L59e/Xs2bPc1zz66KNq1qyZ/vGPf+jll1/WsmXL9OKLL9rXb9myRT4+Purdu7e2bNmiLVu26P333y93e82aNdP999+vJUuWlApoSUlJuvXWW9WjRw9J0sGDBzVo0CAtXrxYX3zxhRISEjRz5kyNGTOm3O1X1r59+/SHP/xBe/bs0VtvvaUvvvhCDz30kF544QWnPvq8Ut++fZWfn3/Va9omTJiguXPn6oUXXlBycrIWL16sxx9/XKdOnZJ0+SP1xx57TJLs7/GWLVsUGhpq38bq1as1d+5c/eUvf9HXX39t/yWgPAkJCXJzc9OyZcv0zjvvaPv27YqOjtaZM2cqdXytW7e2h/Q///nP9tqu9vHvH//4R/3pT39SbGysPvvsM/3Xf/2XkpOT1alTp1LXdObk5Gjw4MF6+umn9dlnn6lXr16aPHmylixZUqk6AZdlALjh/fbbb4abm5sxevRowzAM4+TJk4bFYjGSk5MNwzCMdu3aGZMmTTIMwzCOHDliSDJeeuklwzAMY8uWLYYk46233nLY5tGjRw0fHx/7PMMwjKFDhxoRERH25X/961+GJGPu3LkOr50+fbohyZgyZYp9bMqUKYYkY8aMGQ5zx44da3h7exs2m80+5ufnZwwdOrTCx5+UlGRIMj799FP72J49ewxJxquvvlrma4qLi42ioiJj0aJFhru7u/Hbb7+Ve5wZGRmGJCMpKanUdq48zh49ehiNGjUycnNzHeY999xzhre3t8N+yhIREWE89NBD5a6fO3euIclYuXJluTW0bNnSeOSRR666n2effdYo70eAJMPf37/MWq/cV8l7379/f4d53333nSHJmDZtmsOxldXXrl27Gl27drUvf//99+W+3yX/jkrs37/fkGSMHTvWYd62bdsMScYrr7zisB9JxrZt2xzm3n333UaPHj1K7Qu4EXHGDjCB+vXrKyoqyn7GbsOGDXJ3d1fnzp0lSV27drVfV3fl9XVffPGFLBaLnn76aV26dMn+FRIS4rDNsmzYsEGSNHDgQIfxp556qtzX9OvXz2H53nvv1YULF3TixImKH/AVBg4cqDp16jjcRDF//nxZLBYNHz7cPrZr1y7169dPDRo0kLu7u6xWq4YMGaLi4mL99NNPTu+/xIULF/TNN9+of//+8vX1dXg/e/furQsXLmjr1q3XtQ/DMK45p127dvrqq6/08ssva/369fbr4yrjwQcfVP369Ss8f/DgwQ7LnTp1UkRERKnrO6tayfav/Ii3Xbt2atGihb755huH8ZCQELVr185h7N5779Xhw4ertU6gphDsAJOIiYnRTz/9pGPHjmndunVq06aNbrnlFkmXg92uXbuUm5urdevWycPDQ/fff7+ky9e8GYah4OBgWa1Wh6+tW7de9fEkp06dkoeHhwICAhzGg4ODy31NgwYNHJa9vLwkyanwUcLX11dPPvmkkpOTlZOTo0uXLmnJkiXq2rWrmjRpIkk6cuSIHnjgAWVlZendd9/Vxo0b9f3339uvNbue/Zc4deqULl26pNmzZ5d6L3v37i1JFXrcy9WUBJCwsLBy5/z1r3/Vn/70J61evVoxMTEKCAjQI488ovT09Arv5/cfy1ZESEhImWMlH/9Wl5Ltl1VvWFhYqf1f+e9PuvxvsCr6D7gCj9ouAEDViImJ0axZs7R+/XqtX7/eHiQk2UNcamqq/eL0ktAXGBhovwavJGT9XlljJRo0aKBLly7pt99+cwh3OTk5VXVYFZaQkKCPPvpIixYtUrNmzXTixAm99dZb9vWrV6/W+fPn9emnnyoiIsI+XtYjNa7k7e0tSSosLHQYvzI01K9fX+7u7oqPj9ezzz5b5rYaN25c0UMqxTAMff755/Lz81Pbtm3Lnefn56epU6dq6tSpOn78uP3sXd++ffW///u/FdpXZZ8VV1bPc3JydOedd9qXvb29S72H0uWwGxgYWKn9lSgJatnZ2aXu1j127JjT2wVuVJyxA0yiS5cucnd31yeffKK9e/c63Enq7++v++67TwsXLtShQ4ccHnPSp08fGYahrKwstW3bttRXZGRkufvs2rWrJJV6OPKKFSuu61icOYPSvn17tWzZUklJSUpKSpK/v78effRR+/qSoPL7oGoYhj766KNrbjs4OFje3t7697//7TD+z3/+02HZ19dXMTEx2rVrl+69994y38+yzhhV1NSpU7Vv3z6NGzfOHjYrUvuwYcP01FNP6cCBA8rPz5dUNWdKf2/p0qUOy5s3b9bhw4cd/h3efvvtpd7Dn376SQcOHHAYq0xtDz74oCSVuvnh+++/1/79+9WtW7cKHwNgBpyxA0yibt26at26tVavXi03Nzf79XUlunbtqnfeeUeS4/PrOnfurNGjR2v48OHasWOHunTpIj8/P2VnZ2vTpk2KjIzUH//4xzL32bNnT3Xu3FkTJ05UXl6e2rRpoy1btmjRokWSJDc35353jIyM1Pr16/X5558rNDRUderUUfPmza/5uhEjRmjChAk6cOCAxowZIx8fH/u62NhYeXp66qmnntJLL72kCxcuaO7cuTp9+vQ1t1tyDeL8+fPVpEkTRUVFafv27Vq2bFmpue+++67uv/9+PfDAA/rjH/+o22+/XWfPntXPP/+szz//XN9+++0193fmzBn7tXjnz5/XgQMHtGLFCm3cuFEDBw685t217du3V58+fXTvvfeqfv362r9/vxYvXqyOHTvK19dXkuyB/c0331SvXr3k7u6ue++9V56entesryw7duzQyJEj9fjjj+vo0aN69dVXdeutt2rs2LH2OfHx8Xr66ac1duxYPfroozp8+LBmzJhR6hmDTZo0kY+Pj5YuXaoWLVrolltuUVhYWJkfPzdv3lyjR4/W7Nmz5ebmpl69eunQoUN67bXXFB4e7nDHNXBTqNVbNwBUqZdeesmQZLRt27bUutWrVxuSDE9PT+P8+fOl1s+fP99o37694efnZ/j4+BhNmjQxhgwZYuzYscM+58q7RQ3j8h25w4cPN+rVq2f4+voasbGxxtatWw1JxrvvvmufV3I346+//urw+pK7KjMyMuxju3fvNjp37mz4+voakhzumLyaX3/91fD09DQkGdu3by+1/vPPPzeioqIMb29v49ZbbzX+4z/+w/jqq68MSca6deuuepy5ubnGyJEjjeDgYMPPz8/o27evcejQoVJ3iRrG5btoR4wYYdx6662G1Wo1GjZsaHTq1MnhDtHyREREGJIMSYbFYjFuueUWo3nz5kZ8fLzx9ddfl/maK2t4+eWXjbZt2xr169c3vLy8jDvuuMN48cUXjZMnT9rnFBYWGiNHjjQaNmxoWCwWhx5IMp599tkK7aukf2vWrDHi4+ONevXqGT4+Pkbv3r2N9PR0h9fabDZjxowZxh133GF4e3sbbdu2Nb799ttSd8UahmEsX77cuOuuuwyr1eqwzyvvijWMy3c4v/nmm0azZs0Mq9VqBAYGGk8//bRx9OhRh3ldu3Y17rnnnlLHVFa/gRuVxTAqcIsVAFTCsmXLNHjwYH333Xfq1KlTbZcDADcNgh2A67J8+XJlZWUpMjJSbm5u2rp1q2bOnKlWrVrZH4cCAKgZXGMH4LrUqVNHK1as0LRp03T+/HmFhoZq2LBhmjZtWm2XBgA3Hc7YAQAAmASPOwEAADAJgh0AAIBJEOwAAABMgpsnKshms+nYsWOqU6dOpf/UDgAAgLMMw9DZs2cVFhZ2zQe/E+wq6NixYwoPD6/tMgAAwE3q6NGjpf4m8pUIdhVUp04dSZff1Lp161bLPoqKirRmzRrFxcXJarVWyz5QMfTCddAL10EvXAe9cB010Yu8vDyFh4fbs8jVEOwqqOTj17p161ZrsPP19VXdunX5Rq1l9MJ10AvXQS9cB71wHTXZi4pcCsbNEwAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmIRHbReA0n744Qe5uZWfuQMDA3XbbbfVYEUAAOBGQLBzIZmZmZKkLl26qKCgoNx5Pr6++t/9+wl3AADAAcHOhZw6dUqS1P+1txUQcWeZc05kpOvvf/6jTp48SbADAAAOCHYuqGFEE4W0iKrtMgAAwA2GmycAAABMgmAHAABgErUa7FJTU9W3b1+FhYXJYrFo9erVDustFkuZXzNnzrTPiY6OLrX+ySefdNjO6dOnFR8fL39/f/n7+ys+Pl5nzpypgSMEAACoObUa7M6fP6+oqCjNmTOnzPXZ2dkOX/Pnz5fFYtGjjz7qMG/UqFEO8z788EOH9YMGDdLu3buVnJys5ORk7d69W/Hx8dV2XAAAALWhVm+e6NWrl3r16lXu+pCQEIflf/7zn4qJidEdd9zhMO7r61tqbon9+/crOTlZW7duVfv27SVJH330kTp27KgDBw6oefPm13kUAAAAruGGucbu+PHj+te//qWEhIRS65YuXarAwEDdc889mjRpks6ePWtft2XLFvn7+9tDnSR16NBB/v7+2rx5c43UDgAAUBNumMedLFy4UHXq1NGAAQMcxgcPHqzGjRsrJCREe/bs0eTJk/XDDz8oJSVFkpSTk6OgoKBS2wsKClJOTk65+yssLFRhYaF9OS8vT5JUVFSkoqKiqjikUmw2myTJXYbcbJfKnOMuQz4+PrLZbNVWB2R/b3mPax+9cB30wnXQC9dRE72ozLZvmGA3f/58DR48WN7e3g7jo0aNsv93y5Yt1bRpU7Vt21Y7d+5U69atJV2+CeNKhmGUOV5i+vTpmjp1aqnxNWvWyNfX19nDqJAufvlS5rYy1zX3k2KWL1dWVpaysrKqtQ7I/gsCah+9cB30wnXQC9dRnb3Iz8+v8NwbItht3LhRBw4c0MqVK685t3Xr1rJarUpPT1fr1q0VEhKi48ePl5r366+/Kjg4uNztTJ48WRMmTLAv5+XlKTw8XHFxcapbt65zB3INu3btUnZ2tlLP+yq4eWSZc44d2KO/jeyn1NRURUXxEOPqUlRUpJSUFMXGxspqtdZ2OTc1euE66IXroBeuoyZ6UfKpYUXcEMFu3rx5atOmTYWCzN69e1VUVKTQ0FBJUseOHZWbm6vt27erXbt2kqRt27YpNzdXnTp1Knc7Xl5e8vLyKjVutVqrrXFubpcveSyWRTa3sltTLIsKCgrk5ubGN3MNqM5+o3LoheugF66DXriO6uxFZbZbq8Hu3Llz+vnnn+3LGRkZ2r17twICAux/BzUvL08ff/yx3nrrrVKvP3jwoJYuXarevXsrMDBQ+/bt08SJE9WqVSt17txZktSiRQv17NlTo0aNsj8GZfTo0erTpw93xAIAAFOp1btid+zYoVatWqlVq1aSpAkTJqhVq1b6y1/+Yp+zYsUKGYahp556qtTrPT099c0336hHjx5q3ry5XnjhBcXFxWnt2rVyd3e3z1u6dKkiIyMVFxenuLg43XvvvVq8eHH1HyAAAEANqtUzdtHR0TIM46pzRo8erdGjR5e5Ljw8XBs2bLjmfgICArRkyRKnagQAALhR3DDPsQMAAMDVEewAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJ1GqwS01NVd++fRUWFiaLxaLVq1c7rB82bJgsFovDV4cOHRzmFBYW6vnnn1dgYKD8/PzUr18/ZWZmOsw5ffq04uPj5e/vL39/f8XHx+vMmTPVfHQAAAA1q1aD3fnz5xUVFaU5c+aUO6dnz57Kzs62f3355ZcO68ePH69Vq1ZpxYoV2rRpk86dO6c+ffqouLjYPmfQoEHavXu3kpOTlZycrN27dys+Pr7ajgsAAKA2eNTmznv16qVevXpddY6Xl5dCQkLKXJebm6t58+Zp8eLF6t69uyRpyZIlCg8P19q1a9WjRw/t379fycnJ2rp1q9q3by9J+uijj9SxY0cdOHBAzZs3r9qDAgAAqCW1GuwqYv369QoKClK9evXUtWtX/fd//7eCgoIkSWlpaSoqKlJcXJx9flhYmFq2bKnNmzerR48e2rJli/z9/e2hTpI6dOggf39/bd68udxgV1hYqMLCQvtyXl6eJKmoqEhFRUXVcaiy2WySJHcZcrNdKnOOuwz5+PjIZrNVWx2Q/b3lPa599MJ10AvXQS9cR030ojLbdulg16tXLz3++OOKiIhQRkaGXnvtNT344INKS0uTl5eXcnJy5Onpqfr16zu8Ljg4WDk5OZKknJwcexD8vaCgIPucskyfPl1Tp04tNb5mzRr5+vpe55FdXRe/fClzW5nrmvtJMcuXKysrS1lZWdVaB6SUlJTaLgH/h164DnrhOuiF66jOXuTn51d4rksHuyeeeML+3y1btlTbtm0VERGhf/3rXxowYEC5rzMMQxaLxb78+/8ub86VJk+erAkTJtiX8/LyFB4erri4ONWtW7eyh1Ihu3btUnZ2tlLP+yq4eWSZc44d2KO/jeyn1NRURUVFVUsduPzbUUpKimJjY2W1Wmu7nJsavXAd9MJ10AvXURO9KPnUsCJcOthdKTQ0VBEREUpPT5ckhYSE6OLFizp9+rTDWbsTJ06oU6dO9jnHjx8vta1ff/1VwcHB5e7Ly8tLXl5epcatVmu1Nc7N7fK9LMWyyOZWdmuKZVFBQYHc3Nz4Zq4B1dlvVA69cB30wnXQC9dRnb2ozHZvqOfYnTp1SkePHlVoaKgkqU2bNrJarQ6nP7Ozs7Vnzx57sOvYsaNyc3O1fft2+5xt27YpNzfXPgcAAMAMavWM3blz5/Tzzz/blzMyMrR7924FBAQoICBAiYmJevTRRxUaGqpDhw7plVdeUWBgoPr37y9J8vf3V0JCgiZOnKgGDRooICBAkyZNUmRkpP0u2RYtWqhnz54aNWqUPvzwQ0nS6NGj1adPH+6IBQAAplKrwW7Hjh2KiYmxL5dc0zZ06FDNnTtXP/74oxYtWqQzZ84oNDRUMTExWrlyperUqWN/zdtvvy0PDw8NHDhQBQUF6tatmxYsWCB3d3f7nKVLl+qFF16w3z3br1+/qz47DwAA4EZUq8EuOjpahmGUu/7rr7++5ja8vb01e/ZszZ49u9w5AQEBWrJkiVM1AgAA3ChuqGvsAAAAUD6CHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJlGrwS41NVV9+/ZVWFiYLBaLVq9ebV9XVFSkP/3pT4qMjJSfn5/CwsI0ZMgQHTt2zGEb0dHRslgsDl9PPvmkw5zTp08rPj5e/v7+8vf3V3x8vM6cOVMDRwgAAFBzajXYnT9/XlFRUZozZ06pdfn5+dq5c6dee+017dy5U59++ql++ukn9evXr9TcUaNGKTs72/714YcfOqwfNGiQdu/ereTkZCUnJ2v37t2Kj4+vtuMCAACoDR61ufNevXqpV69eZa7z9/dXSkqKw9js2bPVrl07HTlyRLfddpt93NfXVyEhIWVuZ//+/UpOTtbWrVvVvn17SdJHH32kjh076sCBA2revHkVHQ0AAEDtqtVgV1m5ubmyWCyqV6+ew/jSpUu1ZMkSBQcHq1evXpoyZYrq1KkjSdqyZYv8/f3toU6SOnToIH9/f23evLncYFdYWKjCwkL7cl5enqTLHxEXFRVV8ZFdZrPZJEnuMuRmu1TmHHcZ8vHxkc1mq7Y6IPt7y3tc++iF66AXroNeuI6a6EVltn3DBLsLFy7o5Zdf1qBBg1S3bl37+ODBg9W4cWOFhIRoz549mjx5sn744Qf72b6cnBwFBQWV2l5QUJBycnLK3d/06dM1derUUuNr1qyRr69vFRxR+br45UuZ28pc19xPilm+XFlZWcrKyqrWOqBSZ41Re+iF66AXroNeuI7q7EV+fn6F594Qwa6oqEhPPvmkbDab3n//fYd1o0aNsv93y5Yt1bRpU7Vt21Y7d+5U69atJUkWi6XUNg3DKHO8xOTJkzVhwgT7cl5ensLDwxUXF+cQLKvSrl27lJ2drdTzvgpuHlnmnGMH9uhvI/spNTVVUVFR1VIHLv+bS0lJUWxsrKxWa22Xc1OjF66DXrgOeuE6aqIXJZ8aVoTLB7uioiINHDhQGRkZ+vbbb68Zqlq3bi2r1ar09HS1bt1aISEhOn78eKl5v/76q4KDg8vdjpeXl7y8vEqNW63Wamucm9vle1mKZZHNrezWFMuigoICubm58c1cA6qz36gceuE66IXroBeuozp7UZntuvRz7EpCXXp6utauXasGDRpc8zV79+5VUVGRQkNDJUkdO3ZUbm6utm/fbp+zbds25ebmqlOnTtVWOwAAQE2r1TN2586d088//2xfzsjI0O7duxUQEKCwsDA99thj2rlzp7744gsVFxfbr4kLCAiQp6enDh48qKVLl6p3794KDAzUvn37NHHiRLVq1UqdO3eWJLVo0UI9e/bUqFGj7I9BGT16tPr06cMdsQAAwFRqNdjt2LFDMTEx9uWSa9qGDh2qxMREffbZZ5Kk++67z+F169atU3R0tDw9PfXNN9/o3Xff1blz5xQeHq6HHnpIU6ZMkbu7u33+0qVL9cILLyguLk6S1K9fvzKfnQcAAHAjq9VgFx0dLcMwyl1/tXWSFB4erg0bNlxzPwEBAVqyZEml6wMAALiRuPQ1dgAAAKg4gh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmIRTwS4jI6Oq6wAAAMB1cirY3XnnnYqJidGSJUt04cKFqq4JAAAATnAq2P3www9q1aqVJk6cqJCQEI0ZM0bbt2+v6toAAABQCU4Fu5YtW2rWrFnKyspSUlKScnJydP/99+uee+7RrFmz9Ouvv1Z1nQAAALiG67p5wsPDQ/3799ff//53vfnmmzp48KAmTZqkRo0aaciQIcrOzq6qOgEAAHAN1xXsduzYobFjxyo0NFSzZs3SpEmTdPDgQX377bfKysrSww8/XFV1AgAA4Bo8nHnRrFmzlJSUpAMHDqh3795atGiRevfuLTe3yzmxcePG+vDDD3XXXXdVabEAAAAon1PBbu7cuRoxYoSGDx+ukJCQMufcdtttmjdv3nUVBwAAgIpzKtilp6dfc46np6eGDh3qzOYBAADgBKeusUtKStLHH39cavzjjz/WwoULr7soAAAAVJ5Twe6NN95QYGBgqfGgoCC9/vrr110UAAAAKs+pYHf48GE1bty41HhERISOHDly3UUBAACg8pwKdkFBQfr3v/9davyHH35QgwYNrrsoAAAAVJ5Twe7JJ5/UCy+8oHXr1qm4uFjFxcX69ttvNW7cOD355JNVXSMAAAAqwKm7YqdNm6bDhw+rW7du8vC4vAmbzaYhQ4ZwjR0AAEAtcSrYeXp6auXKlfqv//ov/fDDD/Lx8VFkZKQiIiKquj4AAABUkFPBrkSzZs3UrFmzqqoFAAAA18GpYFdcXKwFCxbom2++0YkTJ2Sz2RzWf/vtt1VSHAAAACrOqZsnxo0bp3Hjxqm4uFgtW7ZUVFSUw1dFpaamqm/fvgoLC5PFYtHq1asd1huGocTERIWFhcnHx0fR0dHau3evw5zCwkI9//zzCgwMlJ+fn/r166fMzEyHOadPn1Z8fLz8/f3l7++v+Ph4nTlzxplDBwAAcFlOnbFbsWKF/v73v6t3797XtfPz588rKipKw4cP16OPPlpq/YwZMzRr1iwtWLBAzZo107Rp0xQbG6sDBw6oTp06kqTx48fr888/14oVK9SgQQNNnDhRffr0UVpamtzd3SVJgwYNUmZmppKTkyVJo0ePVnx8vD7//PPrqh8AAMCVOH3zxJ133nndO+/Vq5d69epV5jrDMPTOO+/o1Vdf1YABAyRJCxcuVHBwsJYtW6YxY8YoNzdX8+bN0+LFi9W9e3dJ0pIlSxQeHq61a9eqR48e2r9/v5KTk7V161a1b99ekvTRRx+pY8eOOnDggJo3b37dxwEAAOAKnAp2EydO1Lvvvqs5c+bIYrFUdU2SpIyMDOXk5CguLs4+5uXlpa5du2rz5s0aM2aM0tLSVFRU5DAnLCxMLVu21ObNm9WjRw9t2bJF/v7+9lAnSR06dJC/v782b95cbrArLCxUYWGhfTkvL0+SVFRUpKKioqo+XEmyX6voLkNutktlznGXIR8fH9lstmqrA7K/t7zHtY9euA564TroheuoiV5UZttOBbtNmzZp3bp1+uqrr3TPPffIarU6rP/000+d2ayDnJwcSVJwcLDDeHBwsA4fPmyf4+npqfr165eaU/L6nJwcBQUFldp+UFCQfU5Zpk+frqlTp5YaX7NmjXx9fSt3MJXUxS9fytxW5rrmflLM8uXKyspSVlZWtdYBKSUlpbZLwP+hF66DXrgOeuE6qrMX+fn5FZ7rVLCrV6+e+vfv78xLK+3KM4KGYVzzLOGVc8qaf63tTJ48WRMmTLAv5+XlKTw8XHFxcapbt25Fy6+UXbt2KTs7W6nnfRXcPLLMOccO7NHfRvZTampqpW5UQeUUFRUpJSVFsbGxpX5xQc2iF66DXrgOeuE6aqIXJZ8aVoRTwS4pKcmZl1VKSEiIpMtn3EJDQ+3jJ06csJ/FCwkJ0cWLF3X69GmHs3YnTpxQp06d7HOOHz9eavu//vprqbOBv+fl5SUvL69S41artdoa5+Z2+SblYllkcyu7NcWyqKCgQG5ubnwz14Dq7Dcqh164DnrhOuiF66jOXlRmu0497kSSLl26pLVr1+rDDz/U2bNnJUnHjh3TuXPnnN2kg8aNGyskJMTh1ObFixe1YcMGe2hr06aNrFarw5zs7Gzt2bPHPqdjx47Kzc3V9u3b7XO2bdum3Nxc+xwAAAAzcOqM3eHDh9WzZ08dOXJEhYWFio2NVZ06dTRjxgxduHBBH3zwQYW2c+7cOf3888/25YyMDO3evVsBAQG67bbbNH78eL3++utq2rSpmjZtqtdff12+vr4aNGiQJMnf318JCQmaOHGiGjRooICAAE2aNEmRkZH2u2RbtGihnj17atSoUfrwww8lXX7cSZ8+fbgjFgAAmIpTwW7cuHFq27atfvjhBzVo0MA+3r9/f40cObLC29mxY4diYmLsyyXXtA0dOlQLFizQSy+9pIKCAo0dO1anT59W+/bttWbNGvsz7CTp7bffloeHhwYOHKiCggJ169ZNCxYssD/DTpKWLl2qF154wX73bL9+/TRnzhxnDh0AAMBlOX1X7HfffSdPT0+H8YiIiErdqRkdHS3DMMpdb7FYlJiYqMTExHLneHt7a/bs2Zo9e3a5cwICArRkyZIK1wUAAHAjcuoaO5vNpuLi4lLjmZmZDmfTAAAAUHOcCnaxsbF655137MsWi0Xnzp3TlClTrvvPjAEAAMA5Tn0U+/bbbysmJkZ33323Lly4oEGDBik9PV2BgYFavnx5VdcIAACACnAq2IWFhWn37t1avny5du7cKZvNpoSEBA0ePFg+Pj5VXSMAAAAqwKlgJ0k+Pj4aMWKERowYUZX1AAAAwElOBbtFixZddf2QIUOcKgYAAADOc/o5dr9XVFSk/Px8eXp6ytfXl2AHAABQC5y6K/b06dMOX+fOndOBAwd0//33c/MEAABALXH6b8VeqWnTpnrjjTdKnc0DAABAzaiyYCdJ7u7uOnbsWFVuEgAAABXk1DV2n332mcOyYRjKzs7WnDlz1Llz5yopDAAAAJXjVLB75JFHHJYtFosaNmyoBx98UG+99VZV1AUAAIBKcirY2Wy2qq4DAAAA16lKr7EDAABA7XHqjN2ECRMqPHfWrFnO7AIAAACV5FSw27Vrl3bu3KlLly6pefPmkqSffvpJ7u7uat26tX2exWKpmioBAABwTU4Fu759+6pOnTpauHCh6tevL+nyQ4uHDx+uBx54QBMnTqzSIgEAAHBtTl1j99Zbb2n69On2UCdJ9evX17Rp07grFgAAoJY4Fezy8vJ0/PjxUuMnTpzQ2bNnr7soAAAAVJ5Twa5///4aPny4PvnkE2VmZiozM1OffPKJEhISNGDAgKquEQAAABXg1DV2H3zwgSZNmqSnn35aRUVFlzfk4aGEhATNnDmzSgsEAABAxTgV7Hx9ffX+++9r5syZOnjwoAzD0J133ik/P7+qrg8AAAAVdF0PKM7OzlZ2draaNWsmPz8/GYZRVXUBAACgkpwKdqdOnVK3bt3UrFkz9e7dW9nZ2ZKkkSNH8qgTAACAWuJUsHvxxRdltVp15MgR+fr62sefeOIJJScnV1lxAAAAqDinrrFbs2aNvv76azVq1MhhvGnTpjp8+HCVFAYAAIDKceqM3fnz5x3O1JU4efKkvLy8rrsoAAAAVJ5Twa5Lly5atGiRfdlischms2nmzJmKiYmpsuIAAABQcU59FDtz5kxFR0drx44dunjxol566SXt3btXv/32m7777ruqrhEAAAAV4NQZu7vvvlv//ve/1a5dO8XGxur8+fMaMGCAdu3apSZNmlR1jQAAAKiASp+xKyoqUlxcnD788ENNnTq1OmoCAACAEyp9xs5qtWrPnj2yWCzVUQ8AAACc5NRHsUOGDNG8efOquhYAAABcB6dunrh48aL+53/+RykpKWrbtm2pvxE7a9asKikOAAAAFVepYPfLL7/o9ttv1549e9S6dWtJ0k8//eQwh49oAQAAakelgl3Tpk2VnZ2tdevWSbr8J8T++te/Kjg4uFqKAwAAQMVV6ho7wzAclr/66iudP3++SgsCAACAc5y6eaLElUEPAAAAtadSwc5isZS6ho5r6gAAAFxDpa6xMwxDw4YNk5eXlyTpwoULeuaZZ0rdFfvpp59WXYUAAACokEqdsRs6dKiCgoLk7+8vf39/Pf300woLC7Mvl3xVpdtvv91+pvD3X88++6wkadiwYaXWdejQwWEbhYWFev755xUYGCg/Pz/169dPmZmZVVonAABAbavUGbukpKTqqqNc33//vYqLi+3Le/bsUWxsrB5//HH7WM+ePR1q8/T0dNjG+PHj9fnnn2vFihVq0KCBJk6cqD59+igtLU3u7u7VfxAAAAA1wKkHFNekhg0bOiy/8cYbatKkibp27Wof8/LyUkhISJmvz83N1bx587R48WJ1795dkrRkyRKFh4dr7dq16tGjR/UVDwAAUINcPtj93sWLF7VkyRJNmDDB4aaN9evXKygoSPXq1VPXrl313//93woKCpIkpaWlqaioSHFxcfb5YWFhatmypTZv3lxusCssLFRhYaF9OS8vT5JUVFSkoqKi6jg82Ww2SZK7DLnZLpU5x12GfHx8ZLPZqq0OyP7e8h7XPnrhOuiF66AXrqMmelGZbVuMG+iZJX//+981aNAgHTlyRGFhYZKklStX6pZbblFERIQyMjL02muv6dKlS0pLS5OXl5eWLVum4cOHO4Q0SYqLi1Pjxo314YcflrmvxMRETZ06tdT4smXL5OvrW/UHBwAAUIb8/HwNGjRIubm5qlu37lXn3lDBrkePHvL09NTnn39e7pzs7GxFRERoxYoVGjBgQLnBLjY2Vk2aNNEHH3xQ5nbKOmMXHh6ukydPXvNNddauXbuUnZ2t1PO+Cm4eWeacYwf26G8j+yk1NVVRUVHVUgcu/3aUkpKi2NhYWa3W2i7npkYvXAe9cB30wnXURC/y8vIUGBhYoWB3w3wUe/jwYa1du/aaj1IJDQ1VRESE0tPTJUkhISG6ePGiTp8+rfr169vnnThxQp06dSp3O15eXvbHuvye1Wqttsa5uV2+SblYFtncym5NsSwqKCiQm5sb38w1oDr7jcqhF66DXrgOeuE6qrMXldnudf3liZqUlJSkoKAgPfTQQ1edd+rUKR09elShoaGSpDZt2shqtSolJcU+Jzs7W3v27LlqsAMAALjR3BBn7Gw2m5KSkjR06FB5ePz/ks+dO6fExEQ9+uijCg0N1aFDh/TKK68oMDBQ/fv3lyT5+/srISFBEydOVIMGDRQQEKBJkyYpMjLSfpcsAACAGdwQwW7t2rU6cuSIRowY4TDu7u6uH3/8UYsWLdKZM2cUGhqqmJgYrVy5UnXq1LHPe/vtt+Xh4aGBAweqoKBA3bp104IFC3iGHQAAMJUbItjFxcWprHs8fHx89PXXX1/z9d7e3po9e7Zmz55dHeUBAAC4hBvmGjsAAABcHcEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTcOlgl5iYKIvF4vAVEhJiX28YhhITExUWFiYfHx9FR0dr7969DtsoLCzU888/r8DAQPn5+alfv37KzMys6UMBAACodi4d7CTpnnvuUXZ2tv3rxx9/tK+bMWOGZs2apTlz5uj7779XSEiIYmNjdfbsWfuc8ePHa9WqVVqxYoU2bdqkc+fOqU+fPiouLq6NwwEAAKg2HrVdwLV4eHg4nKUrYRiG3nnnHb366qsaMGCAJGnhwoUKDg7WsmXLNGbMGOXm5mrevHlavHixunfvLklasmSJwsPDtXbtWvXo0aNGjwUAAKA6ufwZu/T0dIWFhalx48Z68skn9csvv0iSMjIylJOTo7i4OPtcLy8vde3aVZs3b5YkpaWlqaioyGFOWFiYWrZsaZ8DAABgFi59xq59+/ZatGiRmjVrpuPHj2vatGnq1KmT9u7dq5ycHElScHCww2uCg4N1+PBhSVJOTo48PT1Vv379UnNKXl+ewsJCFRYW2pfz8vIkSUVFRSoqKrruYyuLzWaTJLnLkJvtUplz3GXIx8dHNput2uqA7O8t73Htoxeug164DnrhOmqiF5XZtksHu169etn/OzIyUh07dlSTJk20cOFCdejQQZJksVgcXmMYRqmxK1VkzvTp0zV16tRS42vWrJGvr29FD8EpXfzypcxtZa5r7ifFLF+urKwsZWVlVWsdkFJSUmq7BPwfeuE66IXroBeuozp7kZ+fX+G5Lh3sruTn56fIyEilp6frkUcekXT5rFxoaKh9zokTJ+xn8UJCQnTx4kWdPn3a4azdiRMn1KlTp6vua/LkyZowYYJ9OS8vT+Hh4YqLi1PdunWr8Kj+v127dik7O1up530V3DyyzDnHDuzR30b2U2pqqqKioqqlDlz+7SglJUWxsbGyWq21Xc5NjV64DnrhOuiF66iJXpR8algRN1SwKyws1P79+/XAAw+ocePGCgkJUUpKilq1aiVJunjxojZs2KA333xTktSmTRtZrValpKRo4MCBkqTs7Gzt2bNHM2bMuOq+vLy85OXlVWrcarVWW+Pc3C5f8lgsi2xuZbemWBYVFBTIzc2Nb+YaUJ39RuXQC9dBL1wHvXAd1dmLymzXpYPdpEmT1LdvX9122206ceKEpk2bpry8PA0dOlQWi0Xjx4/X66+/rqZNm6pp06Z6/fXX5evrq0GDBkmS/P39lZCQoIkTJ6pBgwYKCAjQpEmTFBkZab9LFgAAwCxcOthlZmbqqaee0smTJ9WwYUN16NBBW7duVUREhCTppZdeUkFBgcaOHavTp0+rffv2WrNmjerUqWPfxttvvy0PDw8NHDhQBQUF6tatmxYsWCB3d/faOiwAAIBq4dLBbsWKFVddb7FYlJiYqMTExHLneHt7a/bs2Zo9e3YVVwcAAOBaXP45dgAAAKgYgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgAAACbh0sFu+vTp+sMf/qA6deooKChIjzzyiA4cOOAwZ9iwYbJYLA5fHTp0cJhTWFio559/XoGBgfLz81O/fv2UmZlZk4cCAABQ7Vw62G3YsEHPPvustm7dqpSUFF26dElxcXE6f/68w7yePXsqOzvb/vXll186rB8/frxWrVqlFStWaNOmTTp37pz69Omj4uLimjwcAACAauVR2wVcTXJyssNyUlKSgoKClJaWpi5dutjHvby8FBISUuY2cnNzNW/ePC1evFjdu3eXJC1ZskTh4eFau3atevToUX0HAAAAUINc+ozdlXJzcyVJAQEBDuPr169XUFCQmjVrplGjRunEiRP2dWlpaSoqKlJcXJx9LCwsTC1bttTmzZtrpnAAAIAa4NJn7H7PMAxNmDBB999/v1q2bGkf79Wrlx5//HFFREQoIyNDr732mh588EGlpaXJy8tLOTk58vT0VP369R22FxwcrJycnHL3V1hYqMLCQvtyXl6eJKmoqEhFRUVVfHSX2Ww2SZK7DLnZLpU5x12GfHx8ZLPZqq0OyP7e8h7XPnrhOuiF66AXrqMmelGZbVsMwzCqrZIq9Oyzz+pf//qXNm3apEaNGpU7Lzs7WxEREVqxYoUGDBigZcuWafjw4Q4hTZJiY2PVpEkTffDBB2VuJzExUVOnTi01vmzZMvn6+l7fwQAAAFRQfn6+Bg0apNzcXNWtW/eqc2+IM3bPP/+8PvvsM6Wmpl411ElSaGioIiIilJ6eLkkKCQnRxYsXdfr0aYezdidOnFCnTp3K3c7kyZM1YcIE+3JeXp7Cw8MVFxd3zTfVWbt27VJ2drZSz/squHlkmXOOHdijv43sp9TUVEVFRVVLHbj821FKSopiY2NltVpru5ybGr1wHfTCddAL11ETvSj51LAiXDrYGYah559/XqtWrdL69evVuHHja77m1KlTOnr0qEJDQyVJbdq0kdVqVUpKigYOHCjp8lm9PXv2aMaMGeVux8vLS15eXqXGrVZrtTXOze3yJY/FssjmVnZrimVRQUGB3Nzc+GauAdXZb1QOvXAd9MJ10AvXUZ29qMx2XTrYPfvss1q2bJn++c9/qk6dOvZr4vz9/eXj46Nz584pMTFRjz76qEJDQ3Xo0CG98sorCgwMVP/+/e1zExISNHHiRDVo0EABAQGaNGmSIiMj7XfJAgAAmIFLB7u5c+dKkqKjox3Gk5KSNGzYMLm7u+vHH3/UokWLdObMGYWGhiomJkYrV65UnTp17PPffvtteXh4aODAgSooKFC3bt20YMECubu71+ThAAAAVCuXDnbXuq/Dx8dHX3/99TW34+3trdmzZ2v27NlVVRoAAIDLuaGeYwcAAIDyEewAAABMgmAHAABgEi59jR0AAEBtOXLkiE6ePHnVOSV/NcpVEOwAAACucOTIEd3VooUK8vOvOs/Hx0fLly9XZmZmhZ63W90IdgAAAFc4efKkCvLzNXDaXAU1blruvN8O/yzp8h9IINgBAAC4sKDGTXVri/L/hKe7DEnna66ga+DmCQAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJO4qYLd+++/r8aNG8vb21tt2rTRxo0ba7skAACAKnPTBLuVK1dq/PjxevXVV7Vr1y498MAD6tWrl44cOVLbpQEAAFSJmybYzZo1SwkJCRo5cqRatGihd955R+Hh4Zo7d25tlwYAAFAlbopgd/HiRaWlpSkuLs5hPC4uTps3b66lqgAAAKqWR20XUBNOnjyp4uJiBQcHO4wHBwcrJyenzNcUFhaqsLDQvpybmytJ+u2331RUVFQtdebl5Sk/P1/H0w+pMP98mXNOHc2Qt7e30tLSlJeXd9Xtubm5yWazXXO/zCvNZrMpPz9fGzdulJvb1X//qcr9uvJ7UlvzaqsXFZ3nyu9dVc9z9V5U9TxXru1m60VF51XlttLT0+Xt7a3jB37Upfxz5c47k3VI+c2ClJeXp1OnTl1z3844e/asJMkwjGvOvSmCXQmLxeKwbBhGqbES06dP19SpU0uNN27cuFpqq6zRo0fXdgkAAJjex//54jXnrKiBOqTLAc/f3/+qc26KYBcYGCh3d/dSZ+dOnDhR6ixeicmTJ2vChAn2ZZvNpt9++00NGjQoNwxer7y8PIWHh+vo0aOqW7dutewDFUMvXAe9cB30wnXQC9dRE70wDENnz55VWFjYNefeFMHO09NTbdq0UUpKivr3728fT0lJ0cMPP1zma7y8vOTl5eUwVq9eveos065u3bp8o7oIeuE66IXroBeug164juruxbXO1JW4KYKdJE2YMEHx8fFq27atOnbsqL/97W86cuSInnnmmdouDQAAoErcNMHuiSee0KlTp/Sf//mfys7OVsuWLfXll18qIiKitksDAACoEjdNsJOksWPHauzYsbVdRrm8vLw0ZcqUUh8Bo+bRC9dBL1wHvXAd9MJ1uFovLEZF7p0FAACAy7spHlAMAABwMyDYAQAAmATBDgAAwCQIdjXo/fffV+PGjeXt7a02bdpo48aNV52/YcMGtWnTRt7e3rrjjjv0wQcf1FClN4fK9OPTTz9VbGysGjZsqLp166pjx476+uuva7Bac6vs90aJ7777Th4eHrrvvvuqt8CbSGV7UVhYqFdffVURERHy8vJSkyZNNH/+/Bqq1twq24ulS5cqKipKvr6+Cg0N1fDhw6vtT1zdTFJTU9W3b1+FhYXJYrFo9erV13xNrf78NlAjVqxYYVitVuOjjz4y9u3bZ4wbN87w8/MzDh8+XOb8X375xfD19TXGjRtn7Nu3z/joo48Mq9VqfPLJJzVcuTlVth/jxo0z3nzzTWP79u3GTz/9ZEyePNmwWq3Gzp07a7hy86lsL0qcOXPGuOOOO4y4uDgjKiqqZoo1OWd60a9fP6N9+/ZGSkqKkZGRYWzbts347rvvarBqc6psLzZu3Gi4ubkZ7777rvHLL78YGzduNO655x7jkUceqeHKzefLL780Xn31VeMf//iHIclYtWrVVefX9s9vgl0NadeunfHMM884jN11113Gyy+/XOb8l156ybjrrrscxsaMGWN06NCh2mq8mVS2H2W5++67jalTp1Z1aTcdZ3vxxBNPGH/+85+NKVOmEOyqSGV78dVXXxn+/v7GqVOnaqK8m0plezFz5kzjjjvucBj761//ajRq1KjaarwZVSTY1fbPbz6KrQEXL15UWlqa4uLiHMbj4uK0efPmMl+zZcuWUvN79OihHTt2qKioqNpqvRk4048r2Ww2nT17VgEBAdVR4k3D2V4kJSXp4MGDmjJlSnWXeNNwphefffaZ2rZtqxkzZujWW29Vs2bNNGnSJBUUFNREyablTC86deqkzMxMffnllzIMQ8ePH9cnn3yihx56qCZKxu/U9s/vm+oBxbXl5MmTKi4uVnBwsMN4cHCwcnJyynxNTk5OmfMvXbqkkydPKjQ0tNrqNTtn+nGlt956S+fPn9fAgQOro8SbhjO9SE9P18svv6yNGzfKw4P/hVUVZ3rxyy+/aNOmTfL29taqVat08uRJjR07Vr/99hvX2V0HZ3rRqVMnLV26VE888YQuXLigS5cuqV+/fpo9e3ZNlIzfqe2f35yxq0EWi8Vh2TCMUmPXml/WOJxT2X6UWL58uRITE7Vy5UoFBQVVV3k3lYr2ori4WIMGDdLUqVPVrFmzmirvplKZ7wubzSaLxaKlS5eqXbt26t27t2bNmqUFCxZw1q4KVKYX+/bt0wsvvKC//OUvSktLU3JysjIyMvh76LWkNn9+8+tuDQgMDJS7u3up37ROnDhRKtWXCAkJKXO+h4eHGjRoUG213gyc6UeJlStXKiEhQR9//LG6d+9enWXeFCrbi7Nnz2rHjh3atWuXnnvuOUmXw4VhGPLw8NCaNWv04IMP1kjtZuPM90VoaKhuvfVW+fv728datGghwzCUmZmppk2bVmvNZuVML6ZPn67OnTvrP/7jPyRJ9957r/z8/PTAAw9o2rRpfMpTg2r75zdn7GqAp6en2rRpo5SUFIfxlJQUderUqczXdOzYsdT8NWvWqG3btrJardVW683AmX5Il8/UDRs2TMuWLeO6lSpS2V7UrVtXP/74o3bv3m3/euaZZ9S8eXPt3r1b7du3r6nSTceZ74vOnTvr2LFjOnfunH3sp59+kpubmxo1alSt9ZqZM73Iz8+Xm5vjj3R3d3dJ//9sEWpGrf/8rpFbNGC/dX3evHnGvn37jPHjxxt+fn7GoUOHDMMwjJdfftmIj4+3zy+5XfrFF1809u3bZ8ybN4/HnVShyvZj2bJlhoeHh/Hee+8Z2dnZ9q8zZ87U1iGYRmV7cSXuiq06le3F2bNnjUaNGhmPPfaYsXfvXmPDhg1G06ZNjZEjR9bWIZhGZXuRlJRkeHh4GO+//75x8OBBY9OmTUbbtm2Ndu3a1dYhmMbZs2eNXbt2Gbt27TIkGbNmzTJ27dplf/SMq/38JtjVoPfee8+IiIgwPD09jdatWxsbNmywrxs6dKjRtWtXh/nr1683WrVqZXh6ehq33367MXfu3Bqu2Nwq04+uXbsakkp9DR06tOYLN6HKfm/8HsGualW2F/v37ze6d+9u+Pj4GI0aNTImTJhg5Ofn13DV5lTZXvz1r3817r77bsPHx8cIDQ01Bg8ebGRmZtZw1eazbt26q/7/39V+flsMg3O0AAAAZsA1dgAAACZBsAMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmATBDgAAwCQIdgBQjaKjozV+/PjaLgPATYJgBwDl6Nu3r7p3717mui1btshisWjnzp01XBUAlI9gBwDlSEhI0LfffqvDhw+XWjd//nzdd999at26dS1UBgBlI9gBQDn69OmjoKAgLViwwGE8Pz9fK1eu1COPPKKnnnpKjRo1kq+vryIjI7V8+fKrbtNisWj16tUOY/Xq1XPYR1ZWlp544gnVr19fDRo00MMPP6xDhw5VzUEBMDWCHQCUw8PDQ0OGDNGCBQtkGIZ9/OOPP9bFixc1cuRItWnTRl988YX27Nmj0aNHKz4+Xtu2bXN6n/n5+YqJidEtt9yi1NRUbdq0Sbfccot69uypixcvVsVhATAxgh0AXMWIESN06NAhrV+/3j42f/58DRgwQLfeeqsmTZqk++67T3fccYeef/559ejRQx9//LHT+1uxYoXc3Nz0P//zP4qMjFSLFi2UlJSkI0eOONQAAGXxqO0CAMCV3XXXXerUqZPmz5+vmJgYHTx4UBs3btSaNWtUXFysN954QytXrlRWVpYKCwtVWFgoPz8/p/eXlpamn3/+WXXq1HEYv3Dhgg4ePHi9hwPA5Ah2AHANCQkJeu655/Tee+8pKSlJERER6tatm2bOnKm3335b77zzjiIjI+Xn56fx48df9SNTi8Xi8LGuJBUVFdn/22azqU2bNlq6dGmp1zZs2LDqDgqAKRHsAOAaBg4cqHHjxmnZsmVauHChRo0aJYvFoo0bN+rhhx/W008/LelyKEtPT1eLFi3K3VbDhg2VnZ1tX05PT1d+fr59uXXr1lq5cqWCgoJUt27d6jsoAKbENXYAcA233HKLnnjiCb3yyis6duyYhg0bJkm68847lZKSos2bN2v//v0aM2aMcnJyrrqtBx98UHPmzNHOnTu1Y8cOPfPMM7Jarfb1gwcPVmBgoB5++GFt3LhRGRkZ2rBhg8aNG6fMzMzqPEwAJkCwA4AKSEhI0OnTp9W9e3fddtttkqTXXntNrVu3Vo8ePRQdHa2QkBA98sgjV93OW2+9pfDwcHXp0kWDBg3SpEmT5Ovra1/v6+ur1NRU3XbbbRowYIBatGihESNGqKCggDN4AK7JYlx5sQcAAABuSJyxAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGAS/w/j9mmKcX+tMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  2.289466/  2.281964, val:  89.16%, val_best:  89.16%, tr:  78.64%, tr_best:  78.64%, epoch time: 261.18 seconds, 4.35 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  2.261396/  2.283510, val:  89.38%, val_best:  89.38%, tr:  82.48%, tr_best:  82.48%, epoch time: 261.93 seconds, 4.37 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  2.261490/  2.164496, val:  68.58%, val_best:  89.38%, tr:  83.67%, tr_best:  83.67%, epoch time: 260.34 seconds, 4.34 minutes\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  2.224973/  2.269370, val:  52.43%, val_best:  89.38%, tr:  86.77%, tr_best:  86.77%, epoch time: 257.77 seconds, 4.30 minutes\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  2.271805/  2.203246, val:  74.12%, val_best:  89.38%, tr:  87.49%, tr_best:  87.49%, epoch time: 260.65 seconds, 4.34 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  2.190523/  2.262972, val:  72.79%, val_best:  89.38%, tr:  88.56%, tr_best:  88.56%, epoch time: 259.55 seconds, 4.33 minutes\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  2.215830/  2.242056, val:  92.70%, val_best:  92.70%, tr:  89.01%, tr_best:  89.01%, epoch time: 259.59 seconds, 4.33 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 217 occurrences\n",
      "test - Value 1: 235 occurrences\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  2.143202/  2.084909, val:  91.37%, val_best:  92.70%, tr:  89.85%, tr_best:  89.85%, epoch time: 258.21 seconds, 4.30 minutes\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  2.202588/  2.198603, val:  91.81%, val_best:  92.70%, tr:  89.50%, tr_best:  89.85%, epoch time: 258.82 seconds, 4.31 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 320 occurrences\n",
      "test - Value 1: 132 occurrences\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  2.142210/  2.023118, val:  78.32%, val_best:  92.70%, tr:  90.62%, tr_best:  90.62%, epoch time: 260.03 seconds, 4.33 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  2.217619/  2.172283, val:  73.23%, val_best:  92.70%, tr:  91.12%, tr_best:  91.12%, epoch time: 260.70 seconds, 4.34 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  2.185319/  2.267011, val:  86.73%, val_best:  92.70%, tr:  90.97%, tr_best:  91.12%, epoch time: 259.70 seconds, 4.33 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  2.315234/  2.356783, val:  89.16%, val_best:  92.70%, tr:  92.31%, tr_best:  92.31%, epoch time: 259.98 seconds, 4.33 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  2.255750/  2.181208, val:  78.98%, val_best:  92.70%, tr:  92.01%, tr_best:  92.31%, epoch time: 261.56 seconds, 4.36 minutes\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  2.266850/  2.303626, val:  69.91%, val_best:  92.70%, tr:  91.54%, tr_best:  92.31%, epoch time: 260.87 seconds, 4.35 minutes\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 283 occurrences\n",
      "test - Value 1: 169 occurrences\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  2.237845/  2.218319, val:  86.06%, val_best:  92.70%, tr:  92.01%, tr_best:  92.31%, epoch time: 260.58 seconds, 4.34 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  2.292361/  2.280288, val:  72.12%, val_best:  92.70%, tr:  92.93%, tr_best:  92.93%, epoch time: 260.83 seconds, 4.35 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  2.329860/  2.338143, val:  93.14%, val_best:  93.14%, tr:  93.37%, tr_best:  93.37%, epoch time: 260.07 seconds, 4.33 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  2.359753/  2.476841, val:  67.70%, val_best:  93.14%, tr:  94.04%, tr_best:  94.04%, epoch time: 260.30 seconds, 4.34 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  2.370664/  2.356580, val:  91.15%, val_best:  93.14%, tr:  94.76%, tr_best:  94.76%, epoch time: 260.74 seconds, 4.35 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  2.382355/  2.305028, val:  89.16%, val_best:  93.14%, tr:  95.58%, tr_best:  95.58%, epoch time: 260.14 seconds, 4.34 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  2.372509/  2.399542, val:  92.70%, val_best:  93.14%, tr:  95.06%, tr_best:  95.58%, epoch time: 258.08 seconds, 4.30 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  2.376579/  2.413960, val:  73.67%, val_best:  93.14%, tr:  95.53%, tr_best:  95.58%, epoch time: 258.67 seconds, 4.31 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  2.392540/  2.292204, val:  88.72%, val_best:  93.14%, tr:  95.09%, tr_best:  95.58%, epoch time: 259.33 seconds, 4.32 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  2.384494/  2.303798, val:  85.84%, val_best:  93.14%, tr:  95.01%, tr_best:  95.58%, epoch time: 260.62 seconds, 4.34 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  2.390863/  2.333437, val:  86.95%, val_best:  93.14%, tr:  95.56%, tr_best:  95.58%, epoch time: 262.45 seconds, 4.37 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  2.436551/  2.422472, val:  80.75%, val_best:  93.14%, tr:  96.38%, tr_best:  96.38%, epoch time: 261.49 seconds, 4.36 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  2.413847/  2.430497, val:  88.94%, val_best:  93.14%, tr:  95.48%, tr_best:  96.38%, epoch time: 260.47 seconds, 4.34 minutes\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 275 occurrences\n",
      "test - Value 1: 177 occurrences\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  2.458904/  2.384640, val:  87.39%, val_best:  93.14%, tr:  96.33%, tr_best:  96.38%, epoch time: 261.43 seconds, 4.36 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  2.400096/  2.464228, val:  54.65%, val_best:  93.14%, tr:  95.36%, tr_best:  96.38%, epoch time: 260.33 seconds, 4.34 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  2.401581/  2.372205, val:  89.82%, val_best:  93.14%, tr:  96.13%, tr_best:  96.38%, epoch time: 262.04 seconds, 4.37 minutes\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  2.450825/  2.522236, val:  88.27%, val_best:  93.14%, tr:  96.18%, tr_best:  96.38%, epoch time: 259.13 seconds, 4.32 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  2.440856/  2.525852, val:  57.30%, val_best:  93.14%, tr:  96.35%, tr_best:  96.38%, epoch time: 261.35 seconds, 4.36 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  2.457328/  2.491165, val:  90.93%, val_best:  93.14%, tr:  96.05%, tr_best:  96.38%, epoch time: 260.96 seconds, 4.35 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  2.479335/  2.422940, val:  90.27%, val_best:  93.14%, tr:  97.02%, tr_best:  97.02%, epoch time: 260.63 seconds, 4.34 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 235 occurrences\n",
      "test - Value 1: 217 occurrences\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  2.412265/  2.382390, val:  93.14%, val_best:  93.14%, tr:  96.55%, tr_best:  97.02%, epoch time: 259.80 seconds, 4.33 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 262 occurrences\n",
      "test - Value 1: 190 occurrences\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  2.427623/  2.375458, val:  89.38%, val_best:  93.14%, tr:  97.10%, tr_best:  97.10%, epoch time: 261.49 seconds, 4.36 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  2.411336/  2.452992, val:  88.27%, val_best:  93.14%, tr:  96.70%, tr_best:  97.10%, epoch time: 260.28 seconds, 4.34 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  2.467322/  2.303230, val:  63.50%, val_best:  93.14%, tr:  97.02%, tr_best:  97.10%, epoch time: 260.45 seconds, 4.34 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  2.441470/  2.499065, val:  92.92%, val_best:  93.14%, tr:  97.52%, tr_best:  97.52%, epoch time: 261.49 seconds, 4.36 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  2.421246/  2.393063, val:  93.14%, val_best:  93.14%, tr:  97.27%, tr_best:  97.52%, epoch time: 260.14 seconds, 4.34 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  2.409626/  2.409813, val:  91.37%, val_best:  93.14%, tr:  97.15%, tr_best:  97.52%, epoch time: 259.76 seconds, 4.33 minutes\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 246 occurrences\n",
      "test - Value 1: 206 occurrences\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  2.430444/  2.355000, val:  91.15%, val_best:  93.14%, tr:  97.67%, tr_best:  97.67%, epoch time: 259.78 seconds, 4.33 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  2.429444/  2.388809, val:  92.48%, val_best:  93.14%, tr:  97.32%, tr_best:  97.67%, epoch time: 260.00 seconds, 4.33 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  2.433523/  2.438339, val:  91.59%, val_best:  93.14%, tr:  97.20%, tr_best:  97.67%, epoch time: 259.13 seconds, 4.32 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  2.424103/  2.393818, val:  77.43%, val_best:  93.14%, tr:  97.89%, tr_best:  97.89%, epoch time: 260.25 seconds, 4.34 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  2.433731/  2.483485, val:  65.71%, val_best:  93.14%, tr:  97.20%, tr_best:  97.89%, epoch time: 259.15 seconds, 4.32 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  2.412548/  2.425743, val:  91.59%, val_best:  93.14%, tr:  97.82%, tr_best:  97.89%, epoch time: 259.80 seconds, 4.33 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  2.407722/  2.525911, val:  83.41%, val_best:  93.14%, tr:  97.54%, tr_best:  97.89%, epoch time: 260.23 seconds, 4.34 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 329 occurrences\n",
      "test - Value 1: 123 occurrences\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  2.426176/  2.300014, val:  75.88%, val_best:  93.14%, tr:  97.54%, tr_best:  97.89%, epoch time: 260.20 seconds, 4.34 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  2.412289/  2.341937, val:  90.71%, val_best:  93.14%, tr:  97.72%, tr_best:  97.89%, epoch time: 260.57 seconds, 4.34 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  2.398674/  2.449826, val:  79.65%, val_best:  93.14%, tr:  97.22%, tr_best:  97.89%, epoch time: 258.26 seconds, 4.30 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  2.361307/  2.380476, val:  89.60%, val_best:  93.14%, tr:  97.07%, tr_best:  97.89%, epoch time: 260.99 seconds, 4.35 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  2.334377/  2.364532, val:  83.19%, val_best:  93.14%, tr:  97.62%, tr_best:  97.89%, epoch time: 259.82 seconds, 4.33 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  2.334793/  2.451084, val:  67.26%, val_best:  93.14%, tr:  97.54%, tr_best:  97.89%, epoch time: 259.82 seconds, 4.33 minutes\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  2.369165/  2.415486, val:  91.37%, val_best:  93.14%, tr:  97.72%, tr_best:  97.89%, epoch time: 259.34 seconds, 4.32 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  2.433214/  2.522142, val:  87.17%, val_best:  93.14%, tr:  98.73%, tr_best:  98.73%, epoch time: 258.12 seconds, 4.30 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  2.391608/  2.333372, val:  76.11%, val_best:  93.14%, tr:  98.11%, tr_best:  98.73%, epoch time: 258.67 seconds, 4.31 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  2.401099/  2.360303, val:  90.27%, val_best:  93.14%, tr:  98.46%, tr_best:  98.73%, epoch time: 260.14 seconds, 4.34 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  2.376868/  2.366325, val:  92.26%, val_best:  93.14%, tr:  98.06%, tr_best:  98.73%, epoch time: 260.28 seconds, 4.34 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  2.285656/  2.209155, val:  90.93%, val_best:  93.14%, tr:  98.11%, tr_best:  98.73%, epoch time: 259.12 seconds, 4.32 minutes\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  2.267850/  2.177175, val:  90.93%, val_best:  93.14%, tr:  97.99%, tr_best:  98.73%, epoch time: 258.79 seconds, 4.31 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  2.326566/  2.421313, val:  82.96%, val_best:  93.14%, tr:  97.79%, tr_best:  98.73%, epoch time: 259.13 seconds, 4.32 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  2.406455/  2.516203, val:  78.76%, val_best:  93.14%, tr:  97.57%, tr_best:  98.73%, epoch time: 261.79 seconds, 4.36 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  2.536782/  2.409561, val:  85.18%, val_best:  93.14%, tr:  98.36%, tr_best:  98.73%, epoch time: 260.58 seconds, 4.34 minutes\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  2.548439/  2.410135, val:  92.48%, val_best:  93.14%, tr:  97.87%, tr_best:  98.73%, epoch time: 259.42 seconds, 4.32 minutes\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  2.472465/  2.414796, val:  92.04%, val_best:  93.14%, tr:  97.74%, tr_best:  98.73%, epoch time: 258.04 seconds, 4.30 minutes\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  2.430110/  2.465039, val:  85.84%, val_best:  93.14%, tr:  97.67%, tr_best:  98.73%, epoch time: 261.15 seconds, 4.35 minutes\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  2.476348/  2.445791, val:  84.07%, val_best:  93.14%, tr:  97.99%, tr_best:  98.73%, epoch time: 258.74 seconds, 4.31 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  2.501680/  2.482775, val:  85.62%, val_best:  93.14%, tr:  98.36%, tr_best:  98.73%, epoch time: 261.14 seconds, 4.35 minutes\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  2.475031/  2.388333, val:  89.38%, val_best:  93.14%, tr:  98.31%, tr_best:  98.73%, epoch time: 259.96 seconds, 4.33 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 231 occurrences\n",
      "test - Value 1: 221 occurrences\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  2.429643/  2.398371, val:  91.37%, val_best:  93.14%, tr:  98.56%, tr_best:  98.73%, epoch time: 261.33 seconds, 4.36 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  2.413661/  2.399128, val:  90.71%, val_best:  93.14%, tr:  98.64%, tr_best:  98.73%, epoch time: 259.94 seconds, 4.33 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  2.412868/  2.397865, val:  92.48%, val_best:  93.14%, tr:  98.51%, tr_best:  98.73%, epoch time: 261.71 seconds, 4.36 minutes\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  2.467157/  2.403140, val:  91.37%, val_best:  93.14%, tr:  98.26%, tr_best:  98.73%, epoch time: 259.69 seconds, 4.33 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  2.442126/  2.568391, val:  54.42%, val_best:  93.14%, tr:  98.11%, tr_best:  98.73%, epoch time: 260.65 seconds, 4.34 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  2.425684/  2.538125, val:  90.93%, val_best:  93.14%, tr:  98.44%, tr_best:  98.73%, epoch time: 260.25 seconds, 4.34 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  2.423864/  2.337544, val:  83.19%, val_best:  93.14%, tr:  98.29%, tr_best:  98.73%, epoch time: 261.13 seconds, 4.35 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  2.423722/  2.399095, val:  92.70%, val_best:  93.14%, tr:  98.06%, tr_best:  98.73%, epoch time: 261.05 seconds, 4.35 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  2.424513/  2.392031, val:  92.04%, val_best:  93.14%, tr:  98.31%, tr_best:  98.73%, epoch time: 260.78 seconds, 4.35 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  2.423876/  2.396992, val:  92.70%, val_best:  93.14%, tr:  98.64%, tr_best:  98.73%, epoch time: 260.93 seconds, 4.35 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  2.427632/  2.520168, val:  62.39%, val_best:  93.14%, tr:  98.61%, tr_best:  98.73%, epoch time: 261.05 seconds, 4.35 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  2.471076/  2.537518, val:  65.04%, val_best:  93.14%, tr:  98.64%, tr_best:  98.73%, epoch time: 261.32 seconds, 4.36 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  2.448423/  2.611137, val:  50.00%, val_best:  93.14%, tr:  98.68%, tr_best:  98.73%, epoch time: 261.92 seconds, 4.37 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  2.515731/  2.452668, val:  88.72%, val_best:  93.14%, tr:  98.64%, tr_best:  98.73%, epoch time: 261.17 seconds, 4.35 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  2.479889/  2.524658, val:  90.71%, val_best:  93.14%, tr:  98.54%, tr_best:  98.73%, epoch time: 260.74 seconds, 4.35 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  2.462905/  2.499676, val:  84.96%, val_best:  93.14%, tr:  98.81%, tr_best:  98.81%, epoch time: 262.69 seconds, 4.38 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  2.443675/  2.471582, val:  87.17%, val_best:  93.14%, tr:  98.86%, tr_best:  98.86%, epoch time: 260.83 seconds, 4.35 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  2.467609/  2.517547, val:  90.93%, val_best:  93.14%, tr:  98.91%, tr_best:  98.91%, epoch time: 260.60 seconds, 4.34 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  2.466182/  2.485645, val:  71.68%, val_best:  93.14%, tr:  98.61%, tr_best:  98.91%, epoch time: 259.83 seconds, 4.33 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  2.509205/  2.454656, val:  92.92%, val_best:  93.14%, tr:  98.73%, tr_best:  98.91%, epoch time: 259.18 seconds, 4.32 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  2.465371/  2.421892, val:  91.37%, val_best:  93.14%, tr:  98.83%, tr_best:  98.91%, epoch time: 259.88 seconds, 4.33 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  2.469605/  2.495911, val:  92.70%, val_best:  93.14%, tr:  98.98%, tr_best:  98.98%, epoch time: 260.75 seconds, 4.35 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  2.461065/  2.485620, val:  80.75%, val_best:  93.14%, tr:  98.91%, tr_best:  98.98%, epoch time: 259.48 seconds, 4.32 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  2.473390/  2.524064, val:  89.38%, val_best:  93.14%, tr:  99.16%, tr_best:  99.16%, epoch time: 261.62 seconds, 4.36 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  2.473820/  2.435709, val:  84.96%, val_best:  93.14%, tr:  99.01%, tr_best:  99.16%, epoch time: 260.78 seconds, 4.35 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  2.440113/  2.455146, val:  93.14%, val_best:  93.14%, tr:  99.16%, tr_best:  99.16%, epoch time: 261.42 seconds, 4.36 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  2.447437/  2.429228, val:  91.15%, val_best:  93.14%, tr:  99.13%, tr_best:  99.16%, epoch time: 260.80 seconds, 4.35 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  2.452064/  2.519850, val:  81.19%, val_best:  93.14%, tr:  98.66%, tr_best:  99.16%, epoch time: 259.63 seconds, 4.33 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  2.497076/  2.526248, val:  70.13%, val_best:  93.14%, tr:  99.11%, tr_best:  99.16%, epoch time: 262.40 seconds, 4.37 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  2.470763/  2.560967, val:  78.32%, val_best:  93.14%, tr:  99.31%, tr_best:  99.31%, epoch time: 261.31 seconds, 4.36 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  2.519140/  2.460079, val:  90.27%, val_best:  93.14%, tr:  99.03%, tr_best:  99.31%, epoch time: 262.34 seconds, 4.37 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  2.482013/  2.493596, val:  60.84%, val_best:  93.14%, tr:  99.11%, tr_best:  99.31%, epoch time: 261.57 seconds, 4.36 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  2.529511/  2.471576, val:  79.20%, val_best:  93.14%, tr:  99.03%, tr_best:  99.31%, epoch time: 261.77 seconds, 4.36 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  2.519334/  2.389721, val:  81.64%, val_best:  93.14%, tr:  98.88%, tr_best:  99.31%, epoch time: 264.15 seconds, 4.40 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  2.489076/  2.493698, val:  86.73%, val_best:  93.14%, tr:  98.81%, tr_best:  99.31%, epoch time: 262.04 seconds, 4.37 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  2.483834/  2.519349, val:  60.40%, val_best:  93.14%, tr:  99.18%, tr_best:  99.31%, epoch time: 262.22 seconds, 4.37 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  2.478155/  2.446864, val:  92.26%, val_best:  93.14%, tr:  99.28%, tr_best:  99.31%, epoch time: 260.30 seconds, 4.34 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  2.497493/  2.478003, val:  91.59%, val_best:  93.14%, tr:  99.03%, tr_best:  99.31%, epoch time: 260.31 seconds, 4.34 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  2.471076/  2.381066, val:  88.27%, val_best:  93.14%, tr:  98.83%, tr_best:  99.31%, epoch time: 260.43 seconds, 4.34 minutes\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  2.456215/  2.448200, val:  90.04%, val_best:  93.14%, tr:  99.13%, tr_best:  99.31%, epoch time: 259.98 seconds, 4.33 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  2.467865/  2.489163, val:  91.15%, val_best:  93.14%, tr:  99.13%, tr_best:  99.31%, epoch time: 260.12 seconds, 4.34 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  2.514581/  2.465735, val:  87.83%, val_best:  93.14%, tr:  99.31%, tr_best:  99.31%, epoch time: 260.77 seconds, 4.35 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  2.516662/  2.597361, val:  83.19%, val_best:  93.14%, tr:  99.31%, tr_best:  99.31%, epoch time: 259.02 seconds, 4.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  2.523419/  2.441228, val:  90.71%, val_best:  93.14%, tr:  99.08%, tr_best:  99.31%, epoch time: 260.25 seconds, 4.34 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  2.448794/  2.364066, val:  91.15%, val_best:  93.14%, tr:  99.08%, tr_best:  99.31%, epoch time: 259.93 seconds, 4.33 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  2.459651/  2.552789, val:  91.59%, val_best:  93.14%, tr:  99.03%, tr_best:  99.31%, epoch time: 260.42 seconds, 4.34 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  2.470287/  2.320050, val:  91.81%, val_best:  93.14%, tr:  99.13%, tr_best:  99.31%, epoch time: 260.16 seconds, 4.34 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  2.307232/  2.480655, val:  92.26%, val_best:  93.14%, tr:  98.73%, tr_best:  99.31%, epoch time: 259.48 seconds, 4.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  2.403717/  2.365871, val:  91.81%, val_best:  93.14%, tr:  98.54%, tr_best:  99.31%, epoch time: 261.72 seconds, 4.36 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  2.414279/  2.352980, val:  91.81%, val_best:  93.14%, tr:  98.78%, tr_best:  99.31%, epoch time: 259.56 seconds, 4.33 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  2.424078/  2.362043, val:  86.95%, val_best:  93.14%, tr:  99.11%, tr_best:  99.31%, epoch time: 258.78 seconds, 4.31 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  2.426317/  2.531769, val:  75.88%, val_best:  93.14%, tr:  98.98%, tr_best:  99.31%, epoch time: 259.19 seconds, 4.32 minutes\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 239 occurrences\n",
      "test - Value 1: 213 occurrences\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  2.525687/  2.388410, val:  90.49%, val_best:  93.14%, tr:  98.71%, tr_best:  99.31%, epoch time: 260.80 seconds, 4.35 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  2.440344/  2.313235, val:  92.26%, val_best:  93.14%, tr:  99.08%, tr_best:  99.31%, epoch time: 260.20 seconds, 4.34 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  2.437537/  2.394377, val:  91.81%, val_best:  93.14%, tr:  98.64%, tr_best:  99.31%, epoch time: 259.20 seconds, 4.32 minutes\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 295 occurrences\n",
      "test - Value 1: 157 occurrences\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  2.499853/  2.315533, val:  81.64%, val_best:  93.14%, tr:  99.01%, tr_best:  99.31%, epoch time: 260.27 seconds, 4.34 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  2.391739/  2.460032, val:  68.58%, val_best:  93.14%, tr:  98.36%, tr_best:  99.31%, epoch time: 258.82 seconds, 4.31 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  2.425025/  2.403205, val:  91.59%, val_best:  93.14%, tr:  98.41%, tr_best:  99.31%, epoch time: 259.63 seconds, 4.33 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  2.433705/  2.452978, val:  87.17%, val_best:  93.14%, tr:  98.78%, tr_best:  99.31%, epoch time: 260.54 seconds, 4.34 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  2.406502/  2.324880, val:  90.27%, val_best:  93.14%, tr:  98.59%, tr_best:  99.31%, epoch time: 260.16 seconds, 4.34 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  2.263223/  2.321161, val:  91.59%, val_best:  93.14%, tr:  98.66%, tr_best:  99.31%, epoch time: 260.06 seconds, 4.33 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  2.345322/  2.335018, val:  90.49%, val_best:  93.14%, tr:  98.91%, tr_best:  99.31%, epoch time: 261.15 seconds, 4.35 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  2.326285/  2.228530, val:  90.93%, val_best:  93.14%, tr:  98.98%, tr_best:  99.31%, epoch time: 259.88 seconds, 4.33 minutes\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 183 occurrences\n",
      "test - Value 1: 269 occurrences\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  2.202482/  2.220715, val:  88.72%, val_best:  93.14%, tr:  98.96%, tr_best:  99.31%, epoch time: 260.75 seconds, 4.35 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  2.210735/  2.248676, val:  91.59%, val_best:  93.14%, tr:  98.76%, tr_best:  99.31%, epoch time: 259.50 seconds, 4.32 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  2.223164/  2.260746, val:  90.27%, val_best:  93.14%, tr:  98.61%, tr_best:  99.31%, epoch time: 260.36 seconds, 4.34 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  2.260466/  2.121233, val:  91.81%, val_best:  93.14%, tr:  98.66%, tr_best:  99.31%, epoch time: 261.50 seconds, 4.36 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  2.239647/  2.162468, val:  92.04%, val_best:  93.14%, tr:  99.08%, tr_best:  99.31%, epoch time: 260.24 seconds, 4.34 minutes\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  2.208687/  2.335159, val:  88.94%, val_best:  93.14%, tr:  98.83%, tr_best:  99.31%, epoch time: 261.36 seconds, 4.36 minutes\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  2.242912/  2.336412, val:  65.93%, val_best:  93.14%, tr:  98.88%, tr_best:  99.31%, epoch time: 260.11 seconds, 4.34 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 258 occurrences\n",
      "test - Value 1: 194 occurrences\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  2.209372/  2.088099, val:  88.05%, val_best:  93.14%, tr:  99.28%, tr_best:  99.31%, epoch time: 257.74 seconds, 4.30 minutes\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  2.194405/  2.155699, val:  90.71%, val_best:  93.14%, tr:  99.13%, tr_best:  99.31%, epoch time: 259.14 seconds, 4.32 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  2.200041/  2.328568, val:  91.37%, val_best:  93.14%, tr:  98.71%, tr_best:  99.31%, epoch time: 257.42 seconds, 4.29 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  2.335795/  2.323947, val:  90.04%, val_best:  93.14%, tr:  98.54%, tr_best:  99.31%, epoch time: 257.87 seconds, 4.30 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  2.329313/  2.325293, val:  90.93%, val_best:  93.14%, tr:  98.91%, tr_best:  99.31%, epoch time: 260.75 seconds, 4.35 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  2.332233/  2.436994, val:  78.54%, val_best:  93.14%, tr:  98.83%, tr_best:  99.31%, epoch time: 257.43 seconds, 4.29 minutes\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  2.243346/  2.251978, val:  86.06%, val_best:  93.14%, tr:  99.26%, tr_best:  99.31%, epoch time: 258.59 seconds, 4.31 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 178 occurrences\n",
      "test - Value 1: 274 occurrences\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  2.165827/  2.293230, val:  88.05%, val_best:  93.14%, tr:  98.78%, tr_best:  99.31%, epoch time: 259.51 seconds, 4.33 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  2.128891/  2.089829, val:  91.15%, val_best:  93.14%, tr:  99.23%, tr_best:  99.31%, epoch time: 255.64 seconds, 4.26 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  2.021370/  2.088240, val:  77.21%, val_best:  93.14%, tr:  99.11%, tr_best:  99.31%, epoch time: 258.02 seconds, 4.30 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  2.130487/  2.199555, val:  82.96%, val_best:  93.14%, tr:  99.11%, tr_best:  99.31%, epoch time: 257.23 seconds, 4.29 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  2.073156/  2.059396, val:  85.84%, val_best:  93.14%, tr:  99.33%, tr_best:  99.33%, epoch time: 259.32 seconds, 4.32 minutes\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  2.039604/  2.198305, val:  90.49%, val_best:  93.14%, tr:  98.98%, tr_best:  99.33%, epoch time: 257.22 seconds, 4.29 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  2.187432/  2.227659, val:  84.73%, val_best:  93.14%, tr:  99.43%, tr_best:  99.43%, epoch time: 258.92 seconds, 4.32 minutes\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  2.272760/  2.194746, val:  76.99%, val_best:  93.14%, tr:  98.91%, tr_best:  99.43%, epoch time: 260.10 seconds, 4.34 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  2.281302/  2.339981, val:  92.48%, val_best:  93.14%, tr:  98.96%, tr_best:  99.43%, epoch time: 260.05 seconds, 4.33 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  2.280527/  2.292562, val:  90.93%, val_best:  93.14%, tr:  99.28%, tr_best:  99.43%, epoch time: 259.07 seconds, 4.32 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  2.195122/  2.128218, val:  90.93%, val_best:  93.14%, tr:  99.26%, tr_best:  99.43%, epoch time: 259.17 seconds, 4.32 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 228 occurrences\n",
      "test - Value 1: 224 occurrences\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  2.103286/  2.134709, val:  90.27%, val_best:  93.14%, tr:  99.38%, tr_best:  99.43%, epoch time: 259.58 seconds, 4.33 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  2.072458/  2.140197, val:  93.36%, val_best:  93.36%, tr:  99.40%, tr_best:  99.43%, epoch time: 260.67 seconds, 4.34 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 31 occurrences\n",
      "test - Value 1: 421 occurrences\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  2.135131/  2.456880, val:  56.86%, val_best:  93.36%, tr:  99.26%, tr_best:  99.43%, epoch time: 259.74 seconds, 4.33 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  2.255883/  2.300076, val:  90.04%, val_best:  93.36%, tr:  98.88%, tr_best:  99.43%, epoch time: 259.69 seconds, 4.33 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  2.259549/  2.314827, val:  90.71%, val_best:  93.36%, tr:  99.03%, tr_best:  99.43%, epoch time: 257.64 seconds, 4.29 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  2.249701/  2.301540, val:  88.72%, val_best:  93.36%, tr:  99.33%, tr_best:  99.43%, epoch time: 259.58 seconds, 4.33 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  2.257904/  2.311703, val:  86.73%, val_best:  93.36%, tr:  99.08%, tr_best:  99.43%, epoch time: 260.49 seconds, 4.34 minutes\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  2.242992/  2.323610, val:  81.42%, val_best:  93.36%, tr:  99.18%, tr_best:  99.43%, epoch time: 261.51 seconds, 4.36 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  2.236095/  2.440399, val:  52.43%, val_best:  93.36%, tr:  99.13%, tr_best:  99.43%, epoch time: 260.28 seconds, 4.34 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  2.245210/  2.228142, val:  88.94%, val_best:  93.36%, tr:  99.23%, tr_best:  99.43%, epoch time: 260.66 seconds, 4.34 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  2.230785/  2.236996, val:  86.73%, val_best:  93.36%, tr:  99.16%, tr_best:  99.43%, epoch time: 259.57 seconds, 4.33 minutes\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  2.230058/  2.254238, val:  91.81%, val_best:  93.36%, tr:  99.16%, tr_best:  99.43%, epoch time: 259.68 seconds, 4.33 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  2.216669/  2.309416, val:  83.41%, val_best:  93.36%, tr:  99.11%, tr_best:  99.43%, epoch time: 256.66 seconds, 4.28 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 226 occurrences\n",
      "test - Value 1: 226 occurrences\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  2.214579/  2.241124, val:  91.59%, val_best:  93.36%, tr:  99.21%, tr_best:  99.43%, epoch time: 259.88 seconds, 4.33 minutes\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  2.222206/  2.230943, val:  91.15%, val_best:  93.36%, tr:  99.21%, tr_best:  99.43%, epoch time: 258.98 seconds, 4.32 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  2.230310/  2.281415, val:  91.15%, val_best:  93.36%, tr:  99.28%, tr_best:  99.43%, epoch time: 261.33 seconds, 4.36 minutes\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  2.243816/  2.283092, val:  80.75%, val_best:  93.36%, tr:  99.23%, tr_best:  99.43%, epoch time: 259.12 seconds, 4.32 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  2.239190/  2.262140, val:  92.70%, val_best:  93.36%, tr:  99.35%, tr_best:  99.43%, epoch time: 258.94 seconds, 4.32 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 200 occurrences\n",
      "test - Value 1: 252 occurrences\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  2.234463/  2.252479, val:  90.71%, val_best:  93.36%, tr:  99.38%, tr_best:  99.43%, epoch time: 257.92 seconds, 4.30 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  2.239277/  2.315551, val:  85.18%, val_best:  93.36%, tr:  99.33%, tr_best:  99.43%, epoch time: 258.24 seconds, 4.30 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  2.237404/  2.327100, val:  87.83%, val_best:  93.36%, tr:  99.60%, tr_best:  99.60%, epoch time: 259.74 seconds, 4.33 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  2.237351/  2.322952, val:  73.23%, val_best:  93.36%, tr:  99.53%, tr_best:  99.60%, epoch time: 254.27 seconds, 4.24 minutes\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  2.231428/  2.288354, val:  88.27%, val_best:  93.36%, tr:  99.38%, tr_best:  99.60%, epoch time: 258.47 seconds, 4.31 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  2.222814/  2.188275, val:  90.93%, val_best:  93.36%, tr:  99.43%, tr_best:  99.60%, epoch time: 259.11 seconds, 4.32 minutes\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  2.227003/  2.221071, val:  91.81%, val_best:  93.36%, tr:  99.40%, tr_best:  99.60%, epoch time: 260.04 seconds, 4.33 minutes\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  2.226153/  2.255466, val:  90.49%, val_best:  93.36%, tr:  99.50%, tr_best:  99.60%, epoch time: 258.77 seconds, 4.31 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-185 lr=['0.0009766'], tr/val_loss:  2.228400/  2.226431, val:  91.81%, val_best:  93.36%, tr:  99.38%, tr_best:  99.60%, epoch time: 259.02 seconds, 4.32 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 191 occurrences\n",
      "test - Value 1: 261 occurrences\n",
      "epoch-186 lr=['0.0009766'], tr/val_loss:  2.225782/  2.277431, val:  90.49%, val_best:  93.36%, tr:  99.50%, tr_best:  99.60%, epoch time: 260.42 seconds, 4.34 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-187 lr=['0.0009766'], tr/val_loss:  2.219675/  2.273452, val:  90.04%, val_best:  93.36%, tr:  99.48%, tr_best:  99.60%, epoch time: 260.17 seconds, 4.34 minutes\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-188 lr=['0.0009766'], tr/val_loss:  2.227137/  2.303910, val:  79.65%, val_best:  93.36%, tr:  99.48%, tr_best:  99.60%, epoch time: 259.46 seconds, 4.32 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-189 lr=['0.0009766'], tr/val_loss:  2.228060/  2.190893, val:  90.04%, val_best:  93.36%, tr:  99.38%, tr_best:  99.60%, epoch time: 260.62 seconds, 4.34 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-190 lr=['0.0009766'], tr/val_loss:  2.219544/  2.257854, val:  91.81%, val_best:  93.36%, tr:  99.50%, tr_best:  99.60%, epoch time: 258.43 seconds, 4.31 minutes\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-191 lr=['0.0009766'], tr/val_loss:  2.230577/  2.266207, val:  91.59%, val_best:  93.36%, tr:  99.53%, tr_best:  99.60%, epoch time: 259.47 seconds, 4.32 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-192 lr=['0.0009766'], tr/val_loss:  2.223817/  2.255913, val:  92.26%, val_best:  93.36%, tr:  99.45%, tr_best:  99.60%, epoch time: 261.82 seconds, 4.36 minutes\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-193 lr=['0.0009766'], tr/val_loss:  2.206283/  2.227185, val:  85.62%, val_best:  93.36%, tr:  99.50%, tr_best:  99.60%, epoch time: 259.44 seconds, 4.32 minutes\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 153 occurrences\n",
      "test - Value 1: 299 occurrences\n",
      "epoch-194 lr=['0.0009766'], tr/val_loss:  2.151627/  2.256307, val:  82.96%, val_best:  93.36%, tr:  99.23%, tr_best:  99.60%, epoch time: 261.78 seconds, 4.36 minutes\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-195 lr=['0.0009766'], tr/val_loss:  2.156121/  2.093494, val:  91.81%, val_best:  93.36%, tr:  99.55%, tr_best:  99.60%, epoch time: 261.45 seconds, 4.36 minutes\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 321 occurrences\n",
      "test - Value 1: 131 occurrences\n",
      "epoch-196 lr=['0.0009766'], tr/val_loss:  2.161013/  2.118356, val:  78.10%, val_best:  93.36%, tr:  99.38%, tr_best:  99.60%, epoch time: 260.21 seconds, 4.34 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-197 lr=['0.0009766'], tr/val_loss:  2.180834/  2.231520, val:  90.93%, val_best:  93.36%, tr:  99.60%, tr_best:  99.60%, epoch time: 259.93 seconds, 4.33 minutes\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-198 lr=['0.0009766'], tr/val_loss:  2.181127/  2.258198, val:  89.82%, val_best:  93.36%, tr:  99.55%, tr_best:  99.60%, epoch time: 261.53 seconds, 4.36 minutes\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test_spike_distribution.mean 10.000000, min 10, max 10\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-199 lr=['0.0009766'], tr/val_loss:  2.166829/  2.179884, val:  91.15%, val_best:  93.36%, tr:  99.50%, tr_best:  99.60%, epoch time: 261.65 seconds, 4.36 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad7252cd49041bdbe8315f3eba00dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà</td></tr><tr><td>val_loss</td><td>‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñá‚ñÜ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99504</td></tr><tr><td>tr_epoch_loss</td><td>2.16683</td></tr><tr><td>val_acc_best</td><td>0.93363</td></tr><tr><td>val_acc_now</td><td>0.9115</td></tr><tr><td>val_loss</td><td>2.17988</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-67</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rfh9ifsm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rfh9ifsm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250725_020417-rfh9ifsm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q985c8bi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001953125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: -14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250725_163154-q985c8bi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q985c8bi' target=\"_blank\">ethereal-sweep-78</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/vb3jbzsk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q985c8bi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q985c8bi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20250725_163203_596', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.125, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 6, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 1, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-14, -14], [-14, -14], [-13, -13]], 'timestep_sums_threshold': 0} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 1\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -14 -14\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 15, v_exp: -14\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -13 -13\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.125, v_reset=10000, sg_width=6, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-14, -14], [-14, -14], [-13, -13]])\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 2124 occurrences\n",
      "train - Value 1: 1906 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  2.305573/  2.340376, val:  50.00%, val_best:  50.00%, tr:  51.14%, tr_best:  51.14%, epoch time: 113.98 seconds, 1.90 minutes\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  2.284146/  2.334430, val:  55.53%, val_best:  55.53%, tr:  51.89%, tr_best:  51.89%, epoch time: 113.24 seconds, 1.89 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  2.298731/  2.321498, val:  50.22%, val_best:  55.53%, tr:  51.32%, tr_best:  51.89%, epoch time: 113.66 seconds, 1.89 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  2.320132/  2.358820, val:  50.00%, val_best:  55.53%, tr:  52.90%, tr_best:  52.90%, epoch time: 113.94 seconds, 1.90 minutes\n",
      "train - Value 0: 2155 occurrences\n",
      "train - Value 1: 1875 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  2.309792/  2.183359, val:  50.00%, val_best:  55.53%, tr:  55.58%, tr_best:  55.58%, epoch time: 112.69 seconds, 1.88 minutes\n",
      "train - Value 0: 2097 occurrences\n",
      "train - Value 1: 1933 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  2.266121/  2.264183, val:  69.47%, val_best:  69.47%, tr:  52.26%, tr_best:  55.58%, epoch time: 110.35 seconds, 1.84 minutes\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  2.233624/  2.291649, val:  50.00%, val_best:  69.47%, tr:  53.67%, tr_best:  55.58%, epoch time: 111.30 seconds, 1.86 minutes\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  2.281854/  2.286538, val:  62.39%, val_best:  69.47%, tr:  54.17%, tr_best:  55.58%, epoch time: 114.59 seconds, 1.91 minutes\n",
      "train - Value 0: 1881 occurrences\n",
      "train - Value 1: 2149 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  2.269351/  2.137402, val:  50.44%, val_best:  69.47%, tr:  53.75%, tr_best:  55.58%, epoch time: 113.03 seconds, 1.88 minutes\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  2.369331/  2.357790, val:  52.21%, val_best:  69.47%, tr:  54.37%, tr_best:  55.58%, epoch time: 111.43 seconds, 1.86 minutes\n",
      "train - Value 0: 2109 occurrences\n",
      "train - Value 1: 1921 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  2.363530/  2.298927, val:  50.00%, val_best:  69.47%, tr:  56.53%, tr_best:  56.53%, epoch time: 113.35 seconds, 1.89 minutes\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1944 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  2.343626/  2.364784, val:  65.04%, val_best:  69.47%, tr:  56.15%, tr_best:  56.53%, epoch time: 112.54 seconds, 1.88 minutes\n",
      "train - Value 0: 1920 occurrences\n",
      "train - Value 1: 2110 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  2.372667/  2.347359, val:  50.88%, val_best:  69.47%, tr:  52.98%, tr_best:  56.53%, epoch time: 113.48 seconds, 1.89 minutes\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2107 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  2.340000/  2.361378, val:  50.00%, val_best:  69.47%, tr:  52.70%, tr_best:  56.53%, epoch time: 111.85 seconds, 1.86 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  2.388005/  2.410787, val:  50.00%, val_best:  69.47%, tr:  52.46%, tr_best:  56.53%, epoch time: 113.56 seconds, 1.89 minutes\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  2.423551/  2.402887, val:  50.00%, val_best:  69.47%, tr:  50.05%, tr_best:  56.53%, epoch time: 111.61 seconds, 1.86 minutes\n",
      "train - Value 0: 2087 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  2.411892/  2.391202, val:  49.78%, val_best:  69.47%, tr:  50.27%, tr_best:  56.53%, epoch time: 112.95 seconds, 1.88 minutes\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  2.302946/  2.339107, val:  51.33%, val_best:  69.47%, tr:  53.35%, tr_best:  56.53%, epoch time: 112.52 seconds, 1.88 minutes\n",
      "train - Value 0: 2244 occurrences\n",
      "train - Value 1: 1786 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  2.324661/  2.317545, val:  52.43%, val_best:  69.47%, tr:  52.48%, tr_best:  56.53%, epoch time: 112.54 seconds, 1.88 minutes\n",
      "train - Value 0: 2237 occurrences\n",
      "train - Value 1: 1793 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  2.337204/  2.347654, val:  53.76%, val_best:  69.47%, tr:  53.15%, tr_best:  56.53%, epoch time: 112.69 seconds, 1.88 minutes\n",
      "train - Value 0: 2130 occurrences\n",
      "train - Value 1: 1900 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  2.325607/  2.325264, val:  50.88%, val_best:  69.47%, tr:  54.27%, tr_best:  56.53%, epoch time: 114.34 seconds, 1.91 minutes\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  2.271939/  2.237953, val:  50.00%, val_best:  69.47%, tr:  51.24%, tr_best:  56.53%, epoch time: 113.42 seconds, 1.89 minutes\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  2.303999/  2.360678, val:  50.00%, val_best:  69.47%, tr:  51.91%, tr_best:  56.53%, epoch time: 113.50 seconds, 1.89 minutes\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  2.424940/  2.400912, val:  50.00%, val_best:  69.47%, tr:  49.75%, tr_best:  56.53%, epoch time: 113.37 seconds, 1.89 minutes\n",
      "train - Value 0: 1696 occurrences\n",
      "train - Value 1: 2334 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  2.412834/  2.399670, val:  50.44%, val_best:  69.47%, tr:  49.65%, tr_best:  56.53%, epoch time: 112.32 seconds, 1.87 minutes\n",
      "train - Value 0: 1693 occurrences\n",
      "train - Value 1: 2337 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  2.413263/  2.401081, val:  50.00%, val_best:  69.47%, tr:  51.86%, tr_best:  56.53%, epoch time: 113.94 seconds, 1.90 minutes\n",
      "train - Value 0: 1730 occurrences\n",
      "train - Value 1: 2300 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  2.404066/  2.392484, val:  50.00%, val_best:  69.47%, tr:  51.04%, tr_best:  56.53%, epoch time: 112.31 seconds, 1.87 minutes\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  2.399439/  2.383496, val:  51.55%, val_best:  69.47%, tr:  50.32%, tr_best:  56.53%, epoch time: 113.19 seconds, 1.89 minutes\n",
      "train - Value 0: 1689 occurrences\n",
      "train - Value 1: 2341 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  2.395199/  2.383852, val:  50.00%, val_best:  69.47%, tr:  50.42%, tr_best:  56.53%, epoch time: 113.34 seconds, 1.89 minutes\n",
      "train - Value 0: 1783 occurrences\n",
      "train - Value 1: 2247 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  2.395168/  2.384439, val:  50.00%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 112.07 seconds, 1.87 minutes\n",
      "train - Value 0: 1707 occurrences\n",
      "train - Value 1: 2323 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  2.394969/  2.383495, val:  51.55%, val_best:  69.47%, tr:  51.32%, tr_best:  56.53%, epoch time: 110.94 seconds, 1.85 minutes\n",
      "train - Value 0: 1688 occurrences\n",
      "train - Value 1: 2342 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  2.395082/  2.383346, val:  50.00%, val_best:  69.47%, tr:  51.04%, tr_best:  56.53%, epoch time: 112.86 seconds, 1.88 minutes\n",
      "train - Value 0: 1709 occurrences\n",
      "train - Value 1: 2321 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  2.397235/  2.387889, val:  50.00%, val_best:  69.47%, tr:  50.12%, tr_best:  56.53%, epoch time: 112.38 seconds, 1.87 minutes\n",
      "train - Value 0: 1659 occurrences\n",
      "train - Value 1: 2371 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  2.396715/  2.386012, val:  50.44%, val_best:  69.47%, tr:  50.67%, tr_best:  56.53%, epoch time: 113.85 seconds, 1.90 minutes\n",
      "train - Value 0: 1834 occurrences\n",
      "train - Value 1: 2196 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  2.399508/  2.387871, val:  50.00%, val_best:  69.47%, tr:  49.26%, tr_best:  56.53%, epoch time: 111.95 seconds, 1.87 minutes\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  2.399848/  2.377875, val:  51.11%, val_best:  69.47%, tr:  51.94%, tr_best:  56.53%, epoch time: 112.77 seconds, 1.88 minutes\n",
      "train - Value 0: 1684 occurrences\n",
      "train - Value 1: 2346 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  2.390442/  2.379607, val:  50.22%, val_best:  69.47%, tr:  50.10%, tr_best:  56.53%, epoch time: 111.26 seconds, 1.85 minutes\n",
      "train - Value 0: 1678 occurrences\n",
      "train - Value 1: 2352 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  2.391035/  2.380876, val:  50.00%, val_best:  69.47%, tr:  52.93%, tr_best:  56.53%, epoch time: 113.10 seconds, 1.89 minutes\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  2.397053/  2.387215, val:  50.00%, val_best:  69.47%, tr:  52.23%, tr_best:  56.53%, epoch time: 114.45 seconds, 1.91 minutes\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  2.402041/  2.388654, val:  53.98%, val_best:  69.47%, tr:  52.58%, tr_best:  56.53%, epoch time: 111.64 seconds, 1.86 minutes\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  2.409946/  2.390318, val:  50.00%, val_best:  69.47%, tr:  53.50%, tr_best:  56.53%, epoch time: 113.72 seconds, 1.90 minutes\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  2.441966/  2.398575, val:  50.00%, val_best:  69.47%, tr:  50.42%, tr_best:  56.53%, epoch time: 113.02 seconds, 1.88 minutes\n",
      "train - Value 0: 1887 occurrences\n",
      "train - Value 1: 2143 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  2.380380/  2.412016, val:  50.00%, val_best:  69.47%, tr:  51.86%, tr_best:  56.53%, epoch time: 113.27 seconds, 1.89 minutes\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  2.419348/  2.395602, val:  51.11%, val_best:  69.47%, tr:  50.89%, tr_best:  56.53%, epoch time: 112.25 seconds, 1.87 minutes\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  2.405599/  2.394848, val:  50.00%, val_best:  69.47%, tr:  53.28%, tr_best:  56.53%, epoch time: 113.36 seconds, 1.89 minutes\n",
      "train - Value 0: 2119 occurrences\n",
      "train - Value 1: 1911 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  2.406307/  2.384069, val:  50.00%, val_best:  69.47%, tr:  50.17%, tr_best:  56.53%, epoch time: 114.67 seconds, 1.91 minutes\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  2.382123/  2.361300, val:  50.00%, val_best:  69.47%, tr:  50.50%, tr_best:  56.53%, epoch time: 113.38 seconds, 1.89 minutes\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  2.359782/  2.403964, val:  50.66%, val_best:  69.47%, tr:  50.99%, tr_best:  56.53%, epoch time: 112.59 seconds, 1.88 minutes\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  2.411361/  2.391572, val:  50.00%, val_best:  69.47%, tr:  50.05%, tr_best:  56.53%, epoch time: 113.26 seconds, 1.89 minutes\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  2.409310/  2.393623, val:  53.76%, val_best:  69.47%, tr:  51.81%, tr_best:  56.53%, epoch time: 112.47 seconds, 1.87 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  2.411463/  2.396695, val:  63.27%, val_best:  69.47%, tr:  53.40%, tr_best:  56.53%, epoch time: 112.39 seconds, 1.87 minutes\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  2.410652/  2.393978, val:  50.00%, val_best:  69.47%, tr:  52.01%, tr_best:  56.53%, epoch time: 113.90 seconds, 1.90 minutes\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  2.413240/  2.395741, val:  61.73%, val_best:  69.47%, tr:  53.85%, tr_best:  56.53%, epoch time: 111.89 seconds, 1.86 minutes\n",
      "train - Value 0: 1755 occurrences\n",
      "train - Value 1: 2275 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  2.415995/  2.395397, val:  58.63%, val_best:  69.47%, tr:  54.59%, tr_best:  56.53%, epoch time: 112.95 seconds, 1.88 minutes\n",
      "train - Value 0: 1788 occurrences\n",
      "train - Value 1: 2242 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  2.413573/  2.397480, val:  50.00%, val_best:  69.47%, tr:  54.52%, tr_best:  56.53%, epoch time: 112.21 seconds, 1.87 minutes\n",
      "train - Value 0: 1852 occurrences\n",
      "train - Value 1: 2178 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  2.410893/  2.404077, val:  50.00%, val_best:  69.47%, tr:  53.97%, tr_best:  56.53%, epoch time: 113.35 seconds, 1.89 minutes\n",
      "train - Value 0: 1896 occurrences\n",
      "train - Value 1: 2134 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  2.405390/  2.386519, val:  50.00%, val_best:  69.47%, tr:  54.67%, tr_best:  56.53%, epoch time: 113.00 seconds, 1.88 minutes\n",
      "train - Value 0: 1787 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  2.401927/  2.391600, val:  50.00%, val_best:  69.47%, tr:  51.51%, tr_best:  56.53%, epoch time: 113.34 seconds, 1.89 minutes\n",
      "train - Value 0: 1689 occurrences\n",
      "train - Value 1: 2341 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  2.400017/  2.389197, val:  50.66%, val_best:  69.47%, tr:  53.70%, tr_best:  56.53%, epoch time: 113.37 seconds, 1.89 minutes\n",
      "train - Value 0: 1754 occurrences\n",
      "train - Value 1: 2276 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  2.400466/  2.389651, val:  51.11%, val_best:  69.47%, tr:  51.49%, tr_best:  56.53%, epoch time: 113.31 seconds, 1.89 minutes\n",
      "train - Value 0: 1807 occurrences\n",
      "train - Value 1: 2223 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  2.405729/  2.408774, val:  50.00%, val_best:  69.47%, tr:  49.08%, tr_best:  56.53%, epoch time: 112.90 seconds, 1.88 minutes\n",
      "train - Value 0: 1909 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  2.415455/  2.396109, val:  47.12%, val_best:  69.47%, tr:  51.22%, tr_best:  56.53%, epoch time: 113.53 seconds, 1.89 minutes\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  2.411935/  2.397297, val:  50.66%, val_best:  69.47%, tr:  50.22%, tr_best:  56.53%, epoch time: 113.71 seconds, 1.90 minutes\n",
      "train - Value 0: 1848 occurrences\n",
      "train - Value 1: 2182 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  2.411342/  2.397941, val:  50.00%, val_best:  69.47%, tr:  50.45%, tr_best:  56.53%, epoch time: 111.19 seconds, 1.85 minutes\n",
      "train - Value 0: 1848 occurrences\n",
      "train - Value 1: 2182 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  2.411615/  2.396377, val:  50.00%, val_best:  69.47%, tr:  50.65%, tr_best:  56.53%, epoch time: 112.85 seconds, 1.88 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  2.411133/  2.399432, val:  61.50%, val_best:  69.47%, tr:  51.09%, tr_best:  56.53%, epoch time: 111.72 seconds, 1.86 minutes\n",
      "train - Value 0: 1796 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  2.417350/  2.401879, val:  50.00%, val_best:  69.47%, tr:  51.84%, tr_best:  56.53%, epoch time: 112.89 seconds, 1.88 minutes\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  2.414936/  2.400832, val:  50.88%, val_best:  69.47%, tr:  51.89%, tr_best:  56.53%, epoch time: 112.51 seconds, 1.88 minutes\n",
      "train - Value 0: 1810 occurrences\n",
      "train - Value 1: 2220 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 415 occurrences\n",
      "test - Value 1: 37 occurrences\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  2.415584/  2.402230, val:  57.74%, val_best:  69.47%, tr:  53.33%, tr_best:  56.53%, epoch time: 112.99 seconds, 1.88 minutes\n",
      "train - Value 0: 1697 occurrences\n",
      "train - Value 1: 2333 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  2.415727/  2.401366, val:  51.55%, val_best:  69.47%, tr:  54.84%, tr_best:  56.53%, epoch time: 113.05 seconds, 1.88 minutes\n",
      "train - Value 0: 1908 occurrences\n",
      "train - Value 1: 2122 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  2.414870/  2.403592, val:  50.66%, val_best:  69.47%, tr:  55.11%, tr_best:  56.53%, epoch time: 113.53 seconds, 1.89 minutes\n",
      "train - Value 0: 1723 occurrences\n",
      "train - Value 1: 2307 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  2.417265/  2.401673, val:  55.53%, val_best:  69.47%, tr:  53.60%, tr_best:  56.53%, epoch time: 111.96 seconds, 1.87 minutes\n",
      "train - Value 0: 2075 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  2.406563/  2.394510, val:  50.00%, val_best:  69.47%, tr:  55.78%, tr_best:  56.53%, epoch time: 112.97 seconds, 1.88 minutes\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  2.404954/  2.392667, val:  50.88%, val_best:  69.47%, tr:  52.95%, tr_best:  56.53%, epoch time: 111.87 seconds, 1.86 minutes\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  2.403838/  2.392717, val:  53.10%, val_best:  69.47%, tr:  51.66%, tr_best:  56.53%, epoch time: 111.19 seconds, 1.85 minutes\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  2.408116/  2.404037, val:  55.97%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 112.50 seconds, 1.87 minutes\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  2.411750/  2.397513, val:  50.00%, val_best:  69.47%, tr:  52.63%, tr_best:  56.53%, epoch time: 112.37 seconds, 1.87 minutes\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  2.343729/  2.311849, val:  50.00%, val_best:  69.47%, tr:  53.35%, tr_best:  56.53%, epoch time: 111.84 seconds, 1.86 minutes\n",
      "train - Value 0: 1833 occurrences\n",
      "train - Value 1: 2197 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  2.247159/  2.204686, val:  51.77%, val_best:  69.47%, tr:  53.55%, tr_best:  56.53%, epoch time: 112.79 seconds, 1.88 minutes\n",
      "train - Value 0: 1860 occurrences\n",
      "train - Value 1: 2170 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  2.308349/  2.320816, val:  50.66%, val_best:  69.47%, tr:  51.24%, tr_best:  56.53%, epoch time: 112.64 seconds, 1.88 minutes\n",
      "train - Value 0: 1780 occurrences\n",
      "train - Value 1: 2250 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  2.321965/  2.341613, val:  50.00%, val_best:  69.47%, tr:  51.89%, tr_best:  56.53%, epoch time: 111.42 seconds, 1.86 minutes\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  2.332141/  2.318856, val:  52.65%, val_best:  69.47%, tr:  51.71%, tr_best:  56.53%, epoch time: 112.10 seconds, 1.87 minutes\n",
      "train - Value 0: 1862 occurrences\n",
      "train - Value 1: 2168 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  2.325257/  2.366937, val:  50.00%, val_best:  69.47%, tr:  52.13%, tr_best:  56.53%, epoch time: 112.41 seconds, 1.87 minutes\n",
      "train - Value 0: 1891 occurrences\n",
      "train - Value 1: 2139 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  2.372625/  2.367155, val:  51.11%, val_best:  69.47%, tr:  52.56%, tr_best:  56.53%, epoch time: 112.50 seconds, 1.88 minutes\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 36 occurrences\n",
      "test - Value 1: 416 occurrences\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  2.377687/  2.367312, val:  57.96%, val_best:  69.47%, tr:  52.21%, tr_best:  56.53%, epoch time: 112.10 seconds, 1.87 minutes\n",
      "train - Value 0: 2139 occurrences\n",
      "train - Value 1: 1891 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  2.377285/  2.367967, val:  51.11%, val_best:  69.47%, tr:  51.66%, tr_best:  56.53%, epoch time: 112.60 seconds, 1.88 minutes\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  2.375506/  2.359025, val:  50.00%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 111.82 seconds, 1.86 minutes\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  2.366782/  2.344120, val:  50.00%, val_best:  69.47%, tr:  52.56%, tr_best:  56.53%, epoch time: 112.78 seconds, 1.88 minutes\n",
      "train - Value 0: 2088 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  2.352550/  2.344244, val:  50.44%, val_best:  69.47%, tr:  50.40%, tr_best:  56.53%, epoch time: 111.95 seconds, 1.87 minutes\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  2.351232/  2.346145, val:  50.00%, val_best:  69.47%, tr:  50.10%, tr_best:  56.53%, epoch time: 113.08 seconds, 1.88 minutes\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  2.349328/  2.333340, val:  50.00%, val_best:  69.47%, tr:  49.13%, tr_best:  56.53%, epoch time: 110.92 seconds, 1.85 minutes\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2119 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  2.353736/  2.361416, val:  51.33%, val_best:  69.47%, tr:  51.96%, tr_best:  56.53%, epoch time: 112.31 seconds, 1.87 minutes\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  2.368854/  2.356131, val:  50.00%, val_best:  69.47%, tr:  53.50%, tr_best:  56.53%, epoch time: 111.73 seconds, 1.86 minutes\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  2.365864/  2.357623, val:  50.00%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 113.30 seconds, 1.89 minutes\n",
      "train - Value 0: 1853 occurrences\n",
      "train - Value 1: 2177 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  2.365510/  2.356948, val:  52.21%, val_best:  69.47%, tr:  49.93%, tr_best:  56.53%, epoch time: 111.40 seconds, 1.86 minutes\n",
      "train - Value 0: 1760 occurrences\n",
      "train - Value 1: 2270 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  2.364235/  2.357866, val:  50.00%, val_best:  69.47%, tr:  52.63%, tr_best:  56.53%, epoch time: 112.86 seconds, 1.88 minutes\n",
      "train - Value 0: 1814 occurrences\n",
      "train - Value 1: 2216 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  2.366196/  2.365011, val:  50.00%, val_best:  69.47%, tr:  51.74%, tr_best:  56.53%, epoch time: 111.75 seconds, 1.86 minutes\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  2.367348/  2.361848, val:  50.00%, val_best:  69.47%, tr:  51.86%, tr_best:  56.53%, epoch time: 112.54 seconds, 1.88 minutes\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  2.368198/  2.360047, val:  50.00%, val_best:  69.47%, tr:  51.61%, tr_best:  56.53%, epoch time: 112.70 seconds, 1.88 minutes\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  2.368710/  2.362865, val:  50.00%, val_best:  69.47%, tr:  50.84%, tr_best:  56.53%, epoch time: 112.69 seconds, 1.88 minutes\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  2.370049/  2.362008, val:  50.00%, val_best:  69.47%, tr:  52.98%, tr_best:  56.53%, epoch time: 111.71 seconds, 1.86 minutes\n",
      "train - Value 0: 1925 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  2.370287/  2.360982, val:  51.11%, val_best:  69.47%, tr:  51.56%, tr_best:  56.53%, epoch time: 112.90 seconds, 1.88 minutes\n",
      "train - Value 0: 2112 occurrences\n",
      "train - Value 1: 1918 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  2.370372/  2.362815, val:  50.00%, val_best:  69.47%, tr:  53.33%, tr_best:  56.53%, epoch time: 112.40 seconds, 1.87 minutes\n",
      "train - Value 0: 2069 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  2.370524/  2.362798, val:  50.00%, val_best:  69.47%, tr:  52.75%, tr_best:  56.53%, epoch time: 113.04 seconds, 1.88 minutes\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2154 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  2.371623/  2.355757, val:  50.22%, val_best:  69.47%, tr:  52.18%, tr_best:  56.53%, epoch time: 111.10 seconds, 1.85 minutes\n",
      "train - Value 0: 1751 occurrences\n",
      "train - Value 1: 2279 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  2.371200/  2.350193, val:  50.00%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 112.09 seconds, 1.87 minutes\n",
      "train - Value 0: 2127 occurrences\n",
      "train - Value 1: 1903 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  2.359221/  2.357345, val:  57.96%, val_best:  69.47%, tr:  51.66%, tr_best:  56.53%, epoch time: 113.06 seconds, 1.88 minutes\n",
      "train - Value 0: 1852 occurrences\n",
      "train - Value 1: 2178 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  2.363511/  2.374313, val:  52.43%, val_best:  69.47%, tr:  51.64%, tr_best:  56.53%, epoch time: 112.77 seconds, 1.88 minutes\n",
      "train - Value 0: 1739 occurrences\n",
      "train - Value 1: 2291 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  2.353740/  2.343560, val:  50.00%, val_best:  69.47%, tr:  52.11%, tr_best:  56.53%, epoch time: 112.13 seconds, 1.87 minutes\n",
      "train - Value 0: 1747 occurrences\n",
      "train - Value 1: 2283 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  2.349967/  2.343213, val:  50.00%, val_best:  69.47%, tr:  52.01%, tr_best:  56.53%, epoch time: 111.86 seconds, 1.86 minutes\n",
      "train - Value 0: 1727 occurrences\n",
      "train - Value 1: 2303 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  2.349828/  2.341143, val:  50.00%, val_best:  69.47%, tr:  51.41%, tr_best:  56.53%, epoch time: 111.90 seconds, 1.87 minutes\n",
      "train - Value 0: 1754 occurrences\n",
      "train - Value 1: 2276 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  2.350131/  2.348617, val:  51.55%, val_best:  69.47%, tr:  53.03%, tr_best:  56.53%, epoch time: 112.59 seconds, 1.88 minutes\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  2.355522/  2.345060, val:  68.58%, val_best:  69.47%, tr:  51.46%, tr_best:  56.53%, epoch time: 113.05 seconds, 1.88 minutes\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  2.354691/  2.366184, val:  44.91%, val_best:  69.47%, tr:  53.23%, tr_best:  56.53%, epoch time: 112.08 seconds, 1.87 minutes\n",
      "train - Value 0: 1909 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  2.363103/  2.348857, val:  50.22%, val_best:  69.47%, tr:  51.86%, tr_best:  56.53%, epoch time: 112.23 seconds, 1.87 minutes\n"
     ]
    }
   ],
   "source": [
    "# sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [4,6,8,10]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [8]},\n",
    "        \"which_data\": {\"values\": ['n_tidigits_tonic']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.03125, 0.0625, 0.125, 0.25, 0.5]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [4.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1/512, 1/1024, 1/2048, 1/4096, 1/8192]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [1]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [0,1,2,3,4,5,6,7,8,9]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [False]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [8]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [-10,-11,-12,-13,-14]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "\n",
    "        # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "\n",
    "        # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"timestep_sums_threshold\": {\"values\": [0]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"2\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w+1,wandb.config.scale_exp_1w+1]],\n",
    "        timestep_sums_threshold  =  wandb.config.timestep_sums_threshold,\n",
    "                        ) \n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling\n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = 'vb3jbzsk'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
