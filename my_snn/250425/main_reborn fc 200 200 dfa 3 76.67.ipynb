{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15498/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on:\n",
    "        assert DFA_on and single_step\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        i = 0\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250425_135425-a5o7fpx8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a5o7fpx8' target=\"_blank\">soft-armadillo-6783</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a5o7fpx8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a5o7fpx8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4.0, surrogate=sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4.0, surrogate=sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (10): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4.0, surrogate=sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.232166/  2.022817, tr:  16.14%, tr_best:  16.14%, val:  39.58%, val_best:  39.58%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.909441/  1.924454, tr:  43.92%, tr_best:  43.92%, val:  46.25%, val_best:  46.25%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.834470/  1.872159, tr:  51.38%, tr_best:  51.38%, val:  50.00%, val_best:  50.00%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.772069/  1.873427, tr:  56.49%, tr_best:  56.49%, val:  40.83%, val_best:  50.00%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.740415/  1.847339, tr:  56.59%, tr_best:  56.59%, val:  47.08%, val_best:  50.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.718398/  1.815231, tr:  57.61%, tr_best:  57.61%, val:  54.58%, val_best:  54.58%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.706232/  1.799120, tr:  63.43%, tr_best:  63.43%, val:  60.00%, val_best:  60.00%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.690966/  1.797130, tr:  66.39%, tr_best:  66.39%, val:  59.17%, val_best:  60.00%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.676954/  1.789703, tr:  68.54%, tr_best:  68.54%, val:  62.08%, val_best:  62.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.668658/  1.788054, tr:  69.56%, tr_best:  69.56%, val:  56.67%, val_best:  62.08%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.661038/  1.786942, tr:  70.58%, tr_best:  70.58%, val:  58.33%, val_best:  62.08%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.655490/  1.784341, tr:  71.09%, tr_best:  71.09%, val:  60.00%, val_best:  62.08%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.654194/  1.785705, tr:  71.50%, tr_best:  71.50%, val:  60.00%, val_best:  62.08%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.644593/  1.780482, tr:  73.14%, tr_best:  73.14%, val:  59.17%, val_best:  62.08%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.634009/  1.783271, tr:  75.08%, tr_best:  75.08%, val:  62.08%, val_best:  62.08%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.636087/  1.778905, tr:  73.65%, tr_best:  75.08%, val:  63.33%, val_best:  63.33%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.628064/  1.778666, tr:  74.67%, tr_best:  75.08%, val:  60.83%, val_best:  63.33%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.626899/  1.787981, tr:  74.06%, tr_best:  75.08%, val:  62.08%, val_best:  63.33%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.622976/  1.782825, tr:  75.69%, tr_best:  75.69%, val:  57.92%, val_best:  63.33%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.615357/  1.776890, tr:  75.79%, tr_best:  75.79%, val:  60.83%, val_best:  63.33%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.614123/  1.775247, tr:  75.69%, tr_best:  75.79%, val:  58.75%, val_best:  63.33%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.611440/  1.773852, tr:  75.59%, tr_best:  75.79%, val:  60.83%, val_best:  63.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.607553/  1.776732, tr:  76.71%, tr_best:  76.71%, val:  61.25%, val_best:  63.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.603120/  1.776742, tr:  76.51%, tr_best:  76.71%, val:  60.42%, val_best:  63.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.602312/  1.773959, tr:  76.92%, tr_best:  76.92%, val:  60.00%, val_best:  63.33%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.597291/  1.772232, tr:  77.53%, tr_best:  77.53%, val:  60.00%, val_best:  63.33%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.594503/  1.778961, tr:  76.81%, tr_best:  77.53%, val:  60.42%, val_best:  63.33%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.593873/  1.786640, tr:  77.32%, tr_best:  77.53%, val:  57.08%, val_best:  63.33%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.595111/  1.776703, tr:  77.22%, tr_best:  77.53%, val:  59.17%, val_best:  63.33%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.589301/  1.780807, tr:  77.43%, tr_best:  77.53%, val:  60.00%, val_best:  63.33%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.586176/  1.775626, tr:  78.35%, tr_best:  78.35%, val:  61.25%, val_best:  63.33%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.583909/  1.782437, tr:  77.22%, tr_best:  78.35%, val:  57.92%, val_best:  63.33%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.584266/  1.778298, tr:  77.73%, tr_best:  78.35%, val:  62.92%, val_best:  63.33%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.581248/  1.790741, tr:  77.83%, tr_best:  78.35%, val:  60.83%, val_best:  63.33%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.579449/  1.781328, tr:  79.16%, tr_best:  79.16%, val:  62.92%, val_best:  63.33%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.578272/  1.790184, tr:  78.35%, tr_best:  79.16%, val:  60.42%, val_best:  63.33%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.574770/  1.785782, tr:  79.67%, tr_best:  79.67%, val:  62.50%, val_best:  63.33%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.573343/  1.786811, tr:  79.16%, tr_best:  79.67%, val:  60.42%, val_best:  63.33%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.573915/  1.784537, tr:  79.06%, tr_best:  79.67%, val:  60.83%, val_best:  63.33%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.572075/  1.781288, tr:  79.37%, tr_best:  79.67%, val:  60.83%, val_best:  63.33%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.569562/  1.783931, tr:  79.37%, tr_best:  79.67%, val:  63.33%, val_best:  63.33%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.571174/  1.786269, tr:  79.78%, tr_best:  79.78%, val:  60.83%, val_best:  63.33%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.565819/  1.791613, tr:  79.88%, tr_best:  79.88%, val:  59.17%, val_best:  63.33%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.565309/  1.796673, tr:  80.69%, tr_best:  80.69%, val:  60.00%, val_best:  63.33%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.564068/  1.790537, tr:  80.18%, tr_best:  80.69%, val:  61.25%, val_best:  63.33%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.561724/  1.789084, tr:  80.39%, tr_best:  80.69%, val:  64.17%, val_best:  64.17%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.559338/  1.796691, tr:  79.67%, tr_best:  80.69%, val:  60.83%, val_best:  64.17%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.552370/  1.797114, tr:  80.80%, tr_best:  80.80%, val:  61.25%, val_best:  64.17%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.549238/  1.794833, tr:  81.10%, tr_best:  81.10%, val:  63.33%, val_best:  64.17%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.547149/  1.797573, tr:  81.21%, tr_best:  81.21%, val:  63.33%, val_best:  64.17%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.546600/  1.792266, tr:  81.51%, tr_best:  81.51%, val:  62.92%, val_best:  64.17%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.543666/  1.803184, tr:  82.12%, tr_best:  82.12%, val:  62.92%, val_best:  64.17%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.542642/  1.798991, tr:  82.43%, tr_best:  82.43%, val:  62.50%, val_best:  64.17%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.542226/  1.796466, tr:  82.33%, tr_best:  82.43%, val:  63.75%, val_best:  64.17%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.542308/  1.796191, tr:  82.64%, tr_best:  82.64%, val:  62.92%, val_best:  64.17%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.540884/  1.799375, tr:  82.64%, tr_best:  82.64%, val:  65.00%, val_best:  65.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.538925/  1.797809, tr:  83.55%, tr_best:  83.55%, val:  65.42%, val_best:  65.42%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.538093/  1.797447, tr:  83.04%, tr_best:  83.55%, val:  65.42%, val_best:  65.42%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.536510/  1.806966, tr:  84.47%, tr_best:  84.47%, val:  66.67%, val_best:  66.67%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.532469/  1.801754, tr:  88.56%, tr_best:  88.56%, val:  70.42%, val_best:  70.42%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.526136/  1.796161, tr:  90.70%, tr_best:  90.70%, val:  69.17%, val_best:  70.42%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.524749/  1.802448, tr:  90.81%, tr_best:  90.81%, val:  69.17%, val_best:  70.42%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.522844/  1.794128, tr:  90.19%, tr_best:  90.81%, val:  70.83%, val_best:  70.83%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.521646/  1.799494, tr:  90.70%, tr_best:  90.81%, val:  69.17%, val_best:  70.83%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.521335/  1.801291, tr:  90.50%, tr_best:  90.81%, val:  70.83%, val_best:  70.83%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.520562/  1.803623, tr:  90.50%, tr_best:  90.81%, val:  70.42%, val_best:  70.83%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.520433/  1.801024, tr:  90.40%, tr_best:  90.81%, val:  72.50%, val_best:  72.50%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.522385/  1.798482, tr:  90.91%, tr_best:  90.91%, val:  72.08%, val_best:  72.50%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.518222/  1.802989, tr:  90.81%, tr_best:  90.91%, val:  69.58%, val_best:  72.50%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.517624/  1.806662, tr:  90.81%, tr_best:  90.91%, val:  68.75%, val_best:  72.50%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.517820/  1.808408, tr:  90.50%, tr_best:  90.91%, val:  68.33%, val_best:  72.50%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.516850/  1.805899, tr:  90.60%, tr_best:  90.91%, val:  68.33%, val_best:  72.50%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.516476/  1.813354, tr:  91.01%, tr_best:  91.01%, val:  66.67%, val_best:  72.50%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.515258/  1.798569, tr:  90.50%, tr_best:  91.01%, val:  72.92%, val_best:  72.92%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.515805/  1.801938, tr:  90.70%, tr_best:  91.01%, val:  69.17%, val_best:  72.92%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.514414/  1.802462, tr:  90.81%, tr_best:  91.01%, val:  70.83%, val_best:  72.92%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.513622/  1.814222, tr:  90.70%, tr_best:  91.01%, val:  68.33%, val_best:  72.92%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.513300/  1.806741, tr:  90.81%, tr_best:  91.01%, val:  68.75%, val_best:  72.92%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.513159/  1.808032, tr:  90.91%, tr_best:  91.01%, val:  67.50%, val_best:  72.92%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.512326/  1.805680, tr:  90.40%, tr_best:  91.01%, val:  71.25%, val_best:  72.92%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.511479/  1.803233, tr:  90.81%, tr_best:  91.01%, val:  69.58%, val_best:  72.92%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.511209/  1.809087, tr:  90.81%, tr_best:  91.01%, val:  69.17%, val_best:  72.92%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.509235/  1.809023, tr:  90.91%, tr_best:  91.01%, val:  69.17%, val_best:  72.92%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.509330/  1.811391, tr:  91.01%, tr_best:  91.01%, val:  68.33%, val_best:  72.92%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.508464/  1.811015, tr:  91.32%, tr_best:  91.32%, val:  69.17%, val_best:  72.92%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.509485/  1.809419, tr:  91.11%, tr_best:  91.32%, val:  68.33%, val_best:  72.92%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.506262/  1.812479, tr:  90.91%, tr_best:  91.32%, val:  67.92%, val_best:  72.92%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.506355/  1.809387, tr:  91.11%, tr_best:  91.32%, val:  70.42%, val_best:  72.92%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.503575/  1.818203, tr:  91.22%, tr_best:  91.32%, val:  69.58%, val_best:  72.92%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.499375/  1.818855, tr:  91.22%, tr_best:  91.32%, val:  69.58%, val_best:  72.92%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.499258/  1.818786, tr:  91.73%, tr_best:  91.73%, val:  70.00%, val_best:  72.92%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.496397/  1.820703, tr:  91.11%, tr_best:  91.73%, val:  70.42%, val_best:  72.92%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.495232/  1.817284, tr:  91.11%, tr_best:  91.73%, val:  69.58%, val_best:  72.92%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.495633/  1.810468, tr:  91.62%, tr_best:  91.73%, val:  72.08%, val_best:  72.92%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.493520/  1.819186, tr:  92.34%, tr_best:  92.34%, val:  70.42%, val_best:  72.92%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.492394/  1.812833, tr:  92.54%, tr_best:  92.54%, val:  72.08%, val_best:  72.92%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.492043/  1.817823, tr:  92.34%, tr_best:  92.54%, val:  71.25%, val_best:  72.92%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.491503/  1.817618, tr:  92.34%, tr_best:  92.54%, val:  71.25%, val_best:  72.92%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.492261/  1.810881, tr:  92.85%, tr_best:  92.85%, val:  74.17%, val_best:  74.17%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.490181/  1.815058, tr:  93.46%, tr_best:  93.46%, val:  70.42%, val_best:  74.17%\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  1.489982/  1.813061, tr:  93.16%, tr_best:  93.46%, val:  71.67%, val_best:  74.17%\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  1.489449/  1.816532, tr:  93.67%, tr_best:  93.67%, val:  71.67%, val_best:  74.17%\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  1.489626/  1.823417, tr:  93.97%, tr_best:  93.97%, val:  70.83%, val_best:  74.17%\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  1.488749/  1.818838, tr:  94.38%, tr_best:  94.38%, val:  72.50%, val_best:  74.17%\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  1.488285/  1.817124, tr:  96.02%, tr_best:  96.02%, val:  74.58%, val_best:  74.58%\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  1.484799/  1.821057, tr:  98.98%, tr_best:  98.98%, val:  75.42%, val_best:  75.42%\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  1.480464/  1.821423, tr:  99.59%, tr_best:  99.59%, val:  75.42%, val_best:  75.42%\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  1.478496/  1.821813, tr:  99.69%, tr_best:  99.69%, val:  75.42%, val_best:  75.42%\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  1.476701/  1.824360, tr:  99.80%, tr_best:  99.80%, val:  75.00%, val_best:  75.42%\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  1.476845/  1.819446, tr:  99.69%, tr_best:  99.80%, val:  74.17%, val_best:  75.42%\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  1.475740/  1.822674, tr:  99.69%, tr_best:  99.80%, val:  75.00%, val_best:  75.42%\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  1.475638/  1.827985, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  75.42%\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  1.474796/  1.822810, tr:  99.80%, tr_best:  99.90%, val:  73.75%, val_best:  75.42%\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  1.474945/  1.830432, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  75.42%\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  1.474670/  1.824807, tr:  99.80%, tr_best:  99.90%, val:  75.42%, val_best:  75.42%\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  1.474476/  1.821707, tr:  99.80%, tr_best:  99.90%, val:  76.67%, val_best:  76.67%\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  1.473649/  1.824815, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  1.473402/  1.824660, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  1.473644/  1.828048, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  1.473958/  1.825676, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  1.472743/  1.827339, tr:  99.90%, tr_best:  99.90%, val:  75.42%, val_best:  76.67%\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  1.472717/  1.826360, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  1.473233/  1.827767, tr:  99.90%, tr_best:  99.90%, val:  75.83%, val_best:  76.67%\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  1.472928/  1.828118, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  1.472563/  1.824030, tr:  99.90%, tr_best:  99.90%, val:  75.42%, val_best:  76.67%\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  1.471745/  1.827124, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  1.472975/  1.831772, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  1.471268/  1.826215, tr:  99.90%, tr_best:  99.90%, val:  75.42%, val_best:  76.67%\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  1.471827/  1.827296, tr:  99.90%, tr_best:  99.90%, val:  75.42%, val_best:  76.67%\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  1.472445/  1.827302, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  1.471686/  1.825322, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  1.471050/  1.832093, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  1.470932/  1.830783, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  1.470722/  1.826130, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  1.470893/  1.829205, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  1.470807/  1.826373, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  1.471590/  1.828618, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  1.470795/  1.827367, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  1.470373/  1.827810, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  1.469738/  1.826651, tr:  99.90%, tr_best:  99.90%, val:  75.42%, val_best:  76.67%\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  1.469827/  1.827247, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  1.469898/  1.827084, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  1.469834/  1.829319, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  1.469721/  1.822516, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  1.469125/  1.823064, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  1.468905/  1.823600, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  1.469116/  1.824509, tr:  99.90%, tr_best:  99.90%, val:  75.00%, val_best:  76.67%\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  1.469639/  1.824738, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  1.468897/  1.825354, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  1.468703/  1.824674, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  1.468709/  1.822104, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  1.468213/  1.825193, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  1.468286/  1.826488, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  1.468478/  1.825094, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  1.468659/  1.826923, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  1.468651/  1.823704, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  1.468408/  1.827559, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  1.468343/  1.825074, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  1.468144/  1.827375, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  1.468361/  1.826790, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  1.467962/  1.826459, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  1.467956/  1.825056, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  1.468004/  1.824434, tr:  99.90%, tr_best:  99.90%, val:  72.50%, val_best:  76.67%\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  1.467802/  1.824892, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  1.468176/  1.831309, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  1.468102/  1.829612, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  1.468105/  1.829889, tr:  99.90%, tr_best:  99.90%, val:  72.50%, val_best:  76.67%\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  1.467996/  1.825791, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  1.467705/  1.825844, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  1.467291/  1.822923, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  1.467518/  1.827126, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  1.467407/  1.824383, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  1.467153/  1.824607, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  1.467062/  1.826591, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  1.467267/  1.830961, tr:  99.90%, tr_best:  99.90%, val:  72.50%, val_best:  76.67%\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  1.467073/  1.823712, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  1.466996/  1.827319, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  1.469602/  1.823957, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  1.466956/  1.821712, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  1.467047/  1.822247, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  1.466701/  1.824643, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  1.466627/  1.828598, tr:  99.90%, tr_best:  99.90%, val:  72.50%, val_best:  76.67%\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  1.466982/  1.826725, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  1.466621/  1.825114, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  1.466611/  1.824284, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  1.466534/  1.828041, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  1.466463/  1.821774, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  1.466536/  1.822550, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  1.466519/  1.824616, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  1.466691/  1.828479, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  1.466118/  1.823524, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  1.467287/  1.825744, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  1.466566/  1.823468, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  1.466125/  1.822114, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  1.466183/  1.822705, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  1.466172/  1.827441, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-196 lr=['0.0010000'], tr/val_loss:  1.465956/  1.826907, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-197 lr=['0.0010000'], tr/val_loss:  1.465940/  1.823864, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-198 lr=['0.0010000'], tr/val_loss:  1.465820/  1.822905, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-199 lr=['0.0010000'], tr/val_loss:  1.466018/  1.822509, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-200 lr=['0.0010000'], tr/val_loss:  1.465877/  1.825613, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-201 lr=['0.0010000'], tr/val_loss:  1.465376/  1.824835, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-202 lr=['0.0010000'], tr/val_loss:  1.465581/  1.823897, tr:  99.90%, tr_best:  99.90%, val:  72.50%, val_best:  76.67%\n",
      "epoch-203 lr=['0.0010000'], tr/val_loss:  1.466571/  1.826599, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-204 lr=['0.0010000'], tr/val_loss:  1.465901/  1.817676, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-205 lr=['0.0010000'], tr/val_loss:  1.465522/  1.821559, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-206 lr=['0.0010000'], tr/val_loss:  1.465520/  1.816734, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-207 lr=['0.0010000'], tr/val_loss:  1.465651/  1.823417, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-208 lr=['0.0010000'], tr/val_loss:  1.465522/  1.823599, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-209 lr=['0.0010000'], tr/val_loss:  1.465602/  1.822065, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-210 lr=['0.0010000'], tr/val_loss:  1.465463/  1.821671, tr:  99.90%, tr_best:  99.90%, val:  74.58%, val_best:  76.67%\n",
      "epoch-211 lr=['0.0010000'], tr/val_loss:  1.465598/  1.822603, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-212 lr=['0.0010000'], tr/val_loss:  1.465764/  1.822596, tr:  99.90%, tr_best:  99.90%, val:  72.92%, val_best:  76.67%\n",
      "epoch-213 lr=['0.0010000'], tr/val_loss:  1.465477/  1.824857, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-214 lr=['0.0010000'], tr/val_loss:  1.465226/  1.821405, tr:  99.90%, tr_best:  99.90%, val:  73.33%, val_best:  76.67%\n",
      "epoch-215 lr=['0.0010000'], tr/val_loss:  1.465358/  1.821868, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-216 lr=['0.0010000'], tr/val_loss:  1.465665/  1.824400, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-217 lr=['0.0010000'], tr/val_loss:  1.465130/  1.822924, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-218 lr=['0.0010000'], tr/val_loss:  1.465242/  1.820338, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-219 lr=['0.0010000'], tr/val_loss:  1.465130/  1.823399, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-220 lr=['0.0010000'], tr/val_loss:  1.464791/  1.825965, tr:  99.90%, tr_best:  99.90%, val:  74.17%, val_best:  76.67%\n",
      "epoch-221 lr=['0.0010000'], tr/val_loss:  1.464825/  1.825744, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-222 lr=['0.0010000'], tr/val_loss:  1.465231/  1.821998, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-223 lr=['0.0010000'], tr/val_loss:  1.464870/  1.824144, tr:  99.90%, tr_best:  99.90%, val:  73.75%, val_best:  76.67%\n",
      "epoch-224 lr=['0.0010000'], tr/val_loss:  1.465131/  1.824709, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-225 lr=['0.0010000'], tr/val_loss:  1.466884/  1.820833, tr:  99.90%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-226 lr=['0.0010000'], tr/val_loss:  1.464787/  1.826113, tr:  99.90%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-227 lr=['0.0010000'], tr/val_loss:  1.464798/  1.823130, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-228 lr=['0.0010000'], tr/val_loss:  1.464499/  1.824402, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-229 lr=['0.0010000'], tr/val_loss:  1.464659/  1.825698, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-230 lr=['0.0010000'], tr/val_loss:  1.464489/  1.827808, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-231 lr=['0.0010000'], tr/val_loss:  1.464933/  1.822907, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-232 lr=['0.0010000'], tr/val_loss:  1.464716/  1.824004, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-233 lr=['0.0010000'], tr/val_loss:  1.464606/  1.823499, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-234 lr=['0.0010000'], tr/val_loss:  1.464520/  1.824449, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-235 lr=['0.0010000'], tr/val_loss:  1.464445/  1.829074, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-236 lr=['0.0010000'], tr/val_loss:  1.464491/  1.827712, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-237 lr=['0.0010000'], tr/val_loss:  1.464513/  1.825020, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-238 lr=['0.0010000'], tr/val_loss:  1.464627/  1.827064, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-239 lr=['0.0010000'], tr/val_loss:  1.464393/  1.823935, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-240 lr=['0.0010000'], tr/val_loss:  1.464360/  1.821767, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-241 lr=['0.0010000'], tr/val_loss:  1.464135/  1.825901, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-242 lr=['0.0010000'], tr/val_loss:  1.464309/  1.825300, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-243 lr=['0.0010000'], tr/val_loss:  1.464376/  1.824764, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-244 lr=['0.0010000'], tr/val_loss:  1.464212/  1.824729, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-245 lr=['0.0010000'], tr/val_loss:  1.464042/  1.823207, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-246 lr=['0.0010000'], tr/val_loss:  1.464312/  1.828162, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-247 lr=['0.0010000'], tr/val_loss:  1.464133/  1.825495, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-248 lr=['0.0010000'], tr/val_loss:  1.464267/  1.826228, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-249 lr=['0.0010000'], tr/val_loss:  1.463971/  1.827571, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-250 lr=['0.0010000'], tr/val_loss:  1.464202/  1.827011, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-251 lr=['0.0010000'], tr/val_loss:  1.463973/  1.827993, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-252 lr=['0.0010000'], tr/val_loss:  1.463989/  1.826057, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-253 lr=['0.0010000'], tr/val_loss:  1.464060/  1.829653, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-254 lr=['0.0010000'], tr/val_loss:  1.464114/  1.826573, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-255 lr=['0.0010000'], tr/val_loss:  1.464042/  1.826994, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-256 lr=['0.0010000'], tr/val_loss:  1.464149/  1.827551, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-257 lr=['0.0010000'], tr/val_loss:  1.463991/  1.827251, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-258 lr=['0.0010000'], tr/val_loss:  1.464107/  1.827284, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-259 lr=['0.0010000'], tr/val_loss:  1.463879/  1.826766, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-260 lr=['0.0010000'], tr/val_loss:  1.464372/  1.825263, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-261 lr=['0.0010000'], tr/val_loss:  1.464441/  1.826530, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-262 lr=['0.0010000'], tr/val_loss:  1.463876/  1.823946, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-263 lr=['0.0010000'], tr/val_loss:  1.463878/  1.822242, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-264 lr=['0.0010000'], tr/val_loss:  1.463945/  1.820563, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-265 lr=['0.0010000'], tr/val_loss:  1.463763/  1.823057, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-266 lr=['0.0010000'], tr/val_loss:  1.463765/  1.821969, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-267 lr=['0.0010000'], tr/val_loss:  1.463860/  1.818771, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-268 lr=['0.0010000'], tr/val_loss:  1.463736/  1.821437, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-269 lr=['0.0010000'], tr/val_loss:  1.463754/  1.820908, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-270 lr=['0.0010000'], tr/val_loss:  1.463797/  1.819465, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-271 lr=['0.0010000'], tr/val_loss:  1.463683/  1.819833, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-272 lr=['0.0010000'], tr/val_loss:  1.463971/  1.823072, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-273 lr=['0.0010000'], tr/val_loss:  1.463881/  1.820792, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-274 lr=['0.0010000'], tr/val_loss:  1.463802/  1.823723, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-275 lr=['0.0010000'], tr/val_loss:  1.463723/  1.819443, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-276 lr=['0.0010000'], tr/val_loss:  1.463790/  1.819033, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-277 lr=['0.0010000'], tr/val_loss:  1.463614/  1.820500, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-278 lr=['0.0010000'], tr/val_loss:  1.463687/  1.822040, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-279 lr=['0.0010000'], tr/val_loss:  1.463602/  1.822882, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-280 lr=['0.0010000'], tr/val_loss:  1.463643/  1.819059, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-281 lr=['0.0010000'], tr/val_loss:  1.463547/  1.815909, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-282 lr=['0.0010000'], tr/val_loss:  1.463808/  1.818432, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-283 lr=['0.0010000'], tr/val_loss:  1.463817/  1.821657, tr: 100.00%, tr_best: 100.00%, val:  76.67%, val_best:  76.67%\n",
      "epoch-284 lr=['0.0010000'], tr/val_loss:  1.463688/  1.822973, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-285 lr=['0.0010000'], tr/val_loss:  1.463702/  1.822550, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-286 lr=['0.0010000'], tr/val_loss:  1.463920/  1.818859, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-287 lr=['0.0010000'], tr/val_loss:  1.463458/  1.822742, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-288 lr=['0.0010000'], tr/val_loss:  1.463776/  1.817146, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-289 lr=['0.0010000'], tr/val_loss:  1.463969/  1.818099, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-290 lr=['0.0010000'], tr/val_loss:  1.464100/  1.819545, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-291 lr=['0.0010000'], tr/val_loss:  1.463558/  1.816082, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-292 lr=['0.0010000'], tr/val_loss:  1.463588/  1.820394, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-293 lr=['0.0010000'], tr/val_loss:  1.463430/  1.815355, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-294 lr=['0.0010000'], tr/val_loss:  1.463629/  1.814069, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-295 lr=['0.0010000'], tr/val_loss:  1.463530/  1.816411, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-296 lr=['0.0010000'], tr/val_loss:  1.463542/  1.817243, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-297 lr=['0.0010000'], tr/val_loss:  1.463601/  1.815183, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-298 lr=['0.0010000'], tr/val_loss:  1.463457/  1.814543, tr: 100.00%, tr_best: 100.00%, val:  76.67%, val_best:  76.67%\n",
      "epoch-299 lr=['0.0010000'], tr/val_loss:  1.463515/  1.815961, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-300 lr=['0.0010000'], tr/val_loss:  1.463398/  1.816418, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-301 lr=['0.0010000'], tr/val_loss:  1.463636/  1.815288, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-302 lr=['0.0010000'], tr/val_loss:  1.463317/  1.816485, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-303 lr=['0.0010000'], tr/val_loss:  1.463203/  1.821016, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-304 lr=['0.0010000'], tr/val_loss:  1.463412/  1.819533, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-305 lr=['0.0010000'], tr/val_loss:  1.463444/  1.819867, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-306 lr=['0.0010000'], tr/val_loss:  1.463430/  1.819062, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-307 lr=['0.0010000'], tr/val_loss:  1.463460/  1.820089, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-308 lr=['0.0010000'], tr/val_loss:  1.463542/  1.818672, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-309 lr=['0.0010000'], tr/val_loss:  1.463285/  1.816978, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-310 lr=['0.0010000'], tr/val_loss:  1.463258/  1.817708, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-311 lr=['0.0010000'], tr/val_loss:  1.463397/  1.819758, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-312 lr=['0.0010000'], tr/val_loss:  1.463357/  1.818769, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-313 lr=['0.0010000'], tr/val_loss:  1.463357/  1.818269, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-314 lr=['0.0010000'], tr/val_loss:  1.463373/  1.816837, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-315 lr=['0.0010000'], tr/val_loss:  1.463130/  1.819224, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-316 lr=['0.0010000'], tr/val_loss:  1.463071/  1.817304, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-317 lr=['0.0010000'], tr/val_loss:  1.463169/  1.817839, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-318 lr=['0.0010000'], tr/val_loss:  1.463133/  1.815515, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-319 lr=['0.0010000'], tr/val_loss:  1.462941/  1.819453, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-320 lr=['0.0010000'], tr/val_loss:  1.462913/  1.818099, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-321 lr=['0.0010000'], tr/val_loss:  1.462995/  1.818760, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-322 lr=['0.0010000'], tr/val_loss:  1.463023/  1.820724, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-323 lr=['0.0010000'], tr/val_loss:  1.463067/  1.817959, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-324 lr=['0.0010000'], tr/val_loss:  1.463023/  1.820876, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-325 lr=['0.0010000'], tr/val_loss:  1.462996/  1.817606, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-326 lr=['0.0010000'], tr/val_loss:  1.463065/  1.823081, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-327 lr=['0.0010000'], tr/val_loss:  1.462925/  1.822606, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-328 lr=['0.0010000'], tr/val_loss:  1.462982/  1.820912, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-329 lr=['0.0010000'], tr/val_loss:  1.463037/  1.820351, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-330 lr=['0.0010000'], tr/val_loss:  1.463080/  1.822185, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-331 lr=['0.0010000'], tr/val_loss:  1.462925/  1.822591, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-332 lr=['0.0010000'], tr/val_loss:  1.463163/  1.823054, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-333 lr=['0.0010000'], tr/val_loss:  1.463014/  1.823653, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-334 lr=['0.0010000'], tr/val_loss:  1.462956/  1.818161, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-335 lr=['0.0010000'], tr/val_loss:  1.462814/  1.823022, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-336 lr=['0.0010000'], tr/val_loss:  1.463786/  1.820822, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-337 lr=['0.0010000'], tr/val_loss:  1.462996/  1.821512, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-338 lr=['0.0010000'], tr/val_loss:  1.462871/  1.821964, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-339 lr=['0.0010000'], tr/val_loss:  1.463039/  1.823315, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-340 lr=['0.0010000'], tr/val_loss:  1.462913/  1.823091, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-341 lr=['0.0010000'], tr/val_loss:  1.462913/  1.826039, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-342 lr=['0.0010000'], tr/val_loss:  1.462858/  1.826545, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-343 lr=['0.0010000'], tr/val_loss:  1.462885/  1.825608, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-344 lr=['0.0010000'], tr/val_loss:  1.463363/  1.827855, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-345 lr=['0.0010000'], tr/val_loss:  1.462926/  1.821362, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-346 lr=['0.0010000'], tr/val_loss:  1.462899/  1.822185, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-347 lr=['0.0010000'], tr/val_loss:  1.462970/  1.827086, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-348 lr=['0.0010000'], tr/val_loss:  1.462899/  1.824257, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-349 lr=['0.0010000'], tr/val_loss:  1.462899/  1.826223, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-350 lr=['0.0010000'], tr/val_loss:  1.462910/  1.826157, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-351 lr=['0.0010000'], tr/val_loss:  1.462697/  1.829444, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-352 lr=['0.0010000'], tr/val_loss:  1.462683/  1.826559, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-353 lr=['0.0010000'], tr/val_loss:  1.462656/  1.824357, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-354 lr=['0.0010000'], tr/val_loss:  1.462814/  1.826868, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-355 lr=['0.0010000'], tr/val_loss:  1.462553/  1.829965, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-356 lr=['0.0010000'], tr/val_loss:  1.462514/  1.826530, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-357 lr=['0.0010000'], tr/val_loss:  1.462583/  1.826786, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-358 lr=['0.0010000'], tr/val_loss:  1.462716/  1.825812, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-359 lr=['0.0010000'], tr/val_loss:  1.462484/  1.825586, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-360 lr=['0.0010000'], tr/val_loss:  1.462569/  1.825542, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-361 lr=['0.0010000'], tr/val_loss:  1.462544/  1.824454, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-362 lr=['0.0010000'], tr/val_loss:  1.462638/  1.823596, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-363 lr=['0.0010000'], tr/val_loss:  1.462583/  1.827514, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-364 lr=['0.0010000'], tr/val_loss:  1.462555/  1.825316, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-365 lr=['0.0010000'], tr/val_loss:  1.462569/  1.826033, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-366 lr=['0.0010000'], tr/val_loss:  1.462553/  1.826425, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-367 lr=['0.0010000'], tr/val_loss:  1.462397/  1.828408, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-368 lr=['0.0010000'], tr/val_loss:  1.462510/  1.826634, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-369 lr=['0.0010000'], tr/val_loss:  1.462367/  1.823646, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-370 lr=['0.0010000'], tr/val_loss:  1.462466/  1.827576, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-371 lr=['0.0010000'], tr/val_loss:  1.462553/  1.827168, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-372 lr=['0.0010000'], tr/val_loss:  1.462326/  1.824438, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-373 lr=['0.0010000'], tr/val_loss:  1.462367/  1.825524, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-374 lr=['0.0010000'], tr/val_loss:  1.462466/  1.826405, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-375 lr=['0.0010000'], tr/val_loss:  1.462507/  1.824544, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-376 lr=['0.0010000'], tr/val_loss:  1.462526/  1.827815, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-377 lr=['0.0010000'], tr/val_loss:  1.462269/  1.826130, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-378 lr=['0.0010000'], tr/val_loss:  1.462425/  1.827091, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-379 lr=['0.0010000'], tr/val_loss:  1.462255/  1.825740, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-380 lr=['0.0010000'], tr/val_loss:  1.462326/  1.824211, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-381 lr=['0.0010000'], tr/val_loss:  1.462241/  1.827378, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-382 lr=['0.0010000'], tr/val_loss:  1.462340/  1.823268, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-383 lr=['0.0010000'], tr/val_loss:  1.462312/  1.828452, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-384 lr=['0.0010000'], tr/val_loss:  1.462386/  1.825049, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-385 lr=['0.0010000'], tr/val_loss:  1.462340/  1.827417, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-386 lr=['0.0010000'], tr/val_loss:  1.462326/  1.824329, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-387 lr=['0.0010000'], tr/val_loss:  1.462340/  1.825413, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-388 lr=['0.0010000'], tr/val_loss:  1.462381/  1.825036, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-389 lr=['0.0010000'], tr/val_loss:  1.462255/  1.825532, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-390 lr=['0.0010000'], tr/val_loss:  1.462241/  1.825030, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-391 lr=['0.0010000'], tr/val_loss:  1.462324/  1.825423, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-392 lr=['0.0010000'], tr/val_loss:  1.462425/  1.824929, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-393 lr=['0.0010000'], tr/val_loss:  1.462269/  1.823371, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-394 lr=['0.0010000'], tr/val_loss:  1.462214/  1.825631, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-395 lr=['0.0010000'], tr/val_loss:  1.462213/  1.823656, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-396 lr=['0.0010000'], tr/val_loss:  1.462328/  1.825228, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-397 lr=['0.0010000'], tr/val_loss:  1.462312/  1.826114, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-398 lr=['0.0010000'], tr/val_loss:  1.462411/  1.827389, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-399 lr=['0.0010000'], tr/val_loss:  1.462186/  1.827858, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-400 lr=['0.0010000'], tr/val_loss:  1.462241/  1.823897, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-401 lr=['0.0010000'], tr/val_loss:  1.462340/  1.826110, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-402 lr=['0.0010000'], tr/val_loss:  1.462255/  1.821424, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-403 lr=['0.0010000'], tr/val_loss:  1.462259/  1.822348, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-404 lr=['0.0010000'], tr/val_loss:  1.462200/  1.824271, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-405 lr=['0.0010000'], tr/val_loss:  1.462292/  1.823778, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-406 lr=['0.0010000'], tr/val_loss:  1.462298/  1.822327, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-407 lr=['0.0010000'], tr/val_loss:  1.462299/  1.826312, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-408 lr=['0.0010000'], tr/val_loss:  1.462209/  1.823886, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-409 lr=['0.0010000'], tr/val_loss:  1.462264/  1.824703, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-410 lr=['0.0010000'], tr/val_loss:  1.462283/  1.826608, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-411 lr=['0.0010000'], tr/val_loss:  1.462225/  1.825348, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-412 lr=['0.0010000'], tr/val_loss:  1.462198/  1.826782, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-413 lr=['0.0010000'], tr/val_loss:  1.462225/  1.825382, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-414 lr=['0.0010000'], tr/val_loss:  1.462253/  1.828387, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-415 lr=['0.0010000'], tr/val_loss:  1.462181/  1.824835, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-416 lr=['0.0010000'], tr/val_loss:  1.462342/  1.825865, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-417 lr=['0.0010000'], tr/val_loss:  1.462253/  1.827937, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-418 lr=['0.0010000'], tr/val_loss:  1.462152/  1.828556, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-419 lr=['0.0010000'], tr/val_loss:  1.462278/  1.825229, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-420 lr=['0.0010000'], tr/val_loss:  1.462225/  1.825576, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-421 lr=['0.0010000'], tr/val_loss:  1.462280/  1.825186, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-422 lr=['0.0010000'], tr/val_loss:  1.462209/  1.829825, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-423 lr=['0.0010000'], tr/val_loss:  1.462225/  1.828748, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-424 lr=['0.0010000'], tr/val_loss:  1.462354/  1.829249, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-425 lr=['0.0010000'], tr/val_loss:  1.462239/  1.830117, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-426 lr=['0.0010000'], tr/val_loss:  1.462209/  1.828717, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-427 lr=['0.0010000'], tr/val_loss:  1.462338/  1.826451, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-428 lr=['0.0010000'], tr/val_loss:  1.462140/  1.826289, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-429 lr=['0.0010000'], tr/val_loss:  1.462180/  1.825005, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-430 lr=['0.0010000'], tr/val_loss:  1.462152/  1.826700, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-431 lr=['0.0010000'], tr/val_loss:  1.462119/  1.826782, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-432 lr=['0.0010000'], tr/val_loss:  1.462106/  1.825255, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-433 lr=['0.0010000'], tr/val_loss:  1.462178/  1.824760, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-434 lr=['0.0010000'], tr/val_loss:  1.462205/  1.824508, tr: 100.00%, tr_best: 100.00%, val:  76.67%, val_best:  76.67%\n",
      "epoch-435 lr=['0.0010000'], tr/val_loss:  1.462178/  1.825529, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-436 lr=['0.0010000'], tr/val_loss:  1.462107/  1.823964, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-437 lr=['0.0010000'], tr/val_loss:  1.462195/  1.825762, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-438 lr=['0.0010000'], tr/val_loss:  1.462168/  1.824383, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-439 lr=['0.0010000'], tr/val_loss:  1.462182/  1.822325, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-440 lr=['0.0010000'], tr/val_loss:  1.462079/  1.823811, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-441 lr=['0.0010000'], tr/val_loss:  1.462166/  1.825955, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-442 lr=['0.0010000'], tr/val_loss:  1.462109/  1.825951, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-443 lr=['0.0010000'], tr/val_loss:  1.462196/  1.825494, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-444 lr=['0.0010000'], tr/val_loss:  1.462192/  1.825457, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-445 lr=['0.0010000'], tr/val_loss:  1.462067/  1.824449, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-446 lr=['0.0010000'], tr/val_loss:  1.462079/  1.828937, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-447 lr=['0.0010000'], tr/val_loss:  1.462077/  1.827206, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-448 lr=['0.0010000'], tr/val_loss:  1.462050/  1.825899, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-449 lr=['0.0010000'], tr/val_loss:  1.462224/  1.824738, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-450 lr=['0.0010000'], tr/val_loss:  1.462091/  1.822490, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-451 lr=['0.0010000'], tr/val_loss:  1.462109/  1.822877, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-452 lr=['0.0010000'], tr/val_loss:  1.462123/  1.828011, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-453 lr=['0.0010000'], tr/val_loss:  1.462164/  1.821330, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-454 lr=['0.0010000'], tr/val_loss:  1.462049/  1.827234, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-455 lr=['0.0010000'], tr/val_loss:  1.462065/  1.826346, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-456 lr=['0.0010000'], tr/val_loss:  1.462037/  1.827403, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-457 lr=['0.0010000'], tr/val_loss:  1.462124/  1.823620, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-458 lr=['0.0010000'], tr/val_loss:  1.462062/  1.828525, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-459 lr=['0.0010000'], tr/val_loss:  1.462169/  1.828905, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-460 lr=['0.0010000'], tr/val_loss:  1.462024/  1.827177, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-461 lr=['0.0010000'], tr/val_loss:  1.462037/  1.827950, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-462 lr=['0.0010000'], tr/val_loss:  1.462065/  1.825153, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-463 lr=['0.0010000'], tr/val_loss:  1.462010/  1.827179, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-464 lr=['0.0010000'], tr/val_loss:  1.462069/  1.827397, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-465 lr=['0.0010000'], tr/val_loss:  1.462022/  1.827063, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-466 lr=['0.0010000'], tr/val_loss:  1.462037/  1.826833, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-467 lr=['0.0010000'], tr/val_loss:  1.461994/  1.828251, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-468 lr=['0.0010000'], tr/val_loss:  1.462124/  1.829658, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-469 lr=['0.0010000'], tr/val_loss:  1.462081/  1.828553, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-470 lr=['0.0010000'], tr/val_loss:  1.461996/  1.827224, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-471 lr=['0.0010000'], tr/val_loss:  1.461980/  1.828606, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-472 lr=['0.0010000'], tr/val_loss:  1.461996/  1.827928, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-473 lr=['0.0010000'], tr/val_loss:  1.462042/  1.829994, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-474 lr=['0.0010000'], tr/val_loss:  1.462143/  1.827012, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-475 lr=['0.0010000'], tr/val_loss:  1.462107/  1.827798, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-476 lr=['0.0010000'], tr/val_loss:  1.462088/  1.830540, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-477 lr=['0.0010000'], tr/val_loss:  1.462028/  1.830766, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-478 lr=['0.0010000'], tr/val_loss:  1.461982/  1.830917, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-479 lr=['0.0010000'], tr/val_loss:  1.461981/  1.828771, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-480 lr=['0.0010000'], tr/val_loss:  1.462028/  1.830415, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-481 lr=['0.0010000'], tr/val_loss:  1.461989/  1.828859, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-482 lr=['0.0010000'], tr/val_loss:  1.461980/  1.829202, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-483 lr=['0.0010000'], tr/val_loss:  1.461854/  1.830029, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-484 lr=['0.0010000'], tr/val_loss:  1.461928/  1.830651, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-485 lr=['0.0010000'], tr/val_loss:  1.461856/  1.831002, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-486 lr=['0.0010000'], tr/val_loss:  1.462040/  1.829578, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-487 lr=['0.0010000'], tr/val_loss:  1.461955/  1.832505, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-488 lr=['0.0010000'], tr/val_loss:  1.462028/  1.828169, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-489 lr=['0.0010000'], tr/val_loss:  1.461969/  1.830470, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-490 lr=['0.0010000'], tr/val_loss:  1.461955/  1.831289, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-491 lr=['0.0010000'], tr/val_loss:  1.461769/  1.833849, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-492 lr=['0.0010000'], tr/val_loss:  1.461783/  1.832549, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-493 lr=['0.0010000'], tr/val_loss:  1.461755/  1.828185, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-494 lr=['0.0010000'], tr/val_loss:  1.461913/  1.829284, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-495 lr=['0.0010000'], tr/val_loss:  1.461755/  1.830349, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-496 lr=['0.0010000'], tr/val_loss:  1.461856/  1.831917, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-497 lr=['0.0010000'], tr/val_loss:  1.461954/  1.830272, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-498 lr=['0.0010000'], tr/val_loss:  1.461842/  1.830930, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-499 lr=['0.0010000'], tr/val_loss:  1.461755/  1.831923, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-500 lr=['0.0010000'], tr/val_loss:  1.461868/  1.832850, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-501 lr=['0.0010000'], tr/val_loss:  1.461755/  1.831033, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-502 lr=['0.0010000'], tr/val_loss:  1.461769/  1.829595, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-503 lr=['0.0010000'], tr/val_loss:  1.461741/  1.832906, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-504 lr=['0.0010000'], tr/val_loss:  1.461801/  1.830812, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-505 lr=['0.0010000'], tr/val_loss:  1.461927/  1.834735, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-506 lr=['0.0010000'], tr/val_loss:  1.461913/  1.831769, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-507 lr=['0.0010000'], tr/val_loss:  1.461854/  1.831497, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-508 lr=['0.0010000'], tr/val_loss:  1.461741/  1.832195, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-509 lr=['0.0010000'], tr/val_loss:  1.461741/  1.832137, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-510 lr=['0.0010000'], tr/val_loss:  1.461728/  1.832505, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-511 lr=['0.0010000'], tr/val_loss:  1.461755/  1.832715, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-512 lr=['0.0010000'], tr/val_loss:  1.461728/  1.832296, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-513 lr=['0.0010000'], tr/val_loss:  1.461700/  1.835486, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-514 lr=['0.0010000'], tr/val_loss:  1.461771/  1.832460, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-515 lr=['0.0010000'], tr/val_loss:  1.461769/  1.832620, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-516 lr=['0.0010000'], tr/val_loss:  1.461700/  1.833096, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-517 lr=['0.0010000'], tr/val_loss:  1.461785/  1.833676, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-518 lr=['0.0010000'], tr/val_loss:  1.461700/  1.831704, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-519 lr=['0.0010000'], tr/val_loss:  1.461728/  1.832027, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-520 lr=['0.0010000'], tr/val_loss:  1.461774/  1.833986, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-521 lr=['0.0010000'], tr/val_loss:  1.461742/  1.835872, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-522 lr=['0.0010000'], tr/val_loss:  1.461838/  1.833272, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-523 lr=['0.0010000'], tr/val_loss:  1.461799/  1.834748, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-524 lr=['0.0010000'], tr/val_loss:  1.461700/  1.835254, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-525 lr=['0.0010000'], tr/val_loss:  1.461686/  1.835455, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-526 lr=['0.0010000'], tr/val_loss:  1.461714/  1.832315, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-527 lr=['0.0010000'], tr/val_loss:  1.461787/  1.833395, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-528 lr=['0.0010000'], tr/val_loss:  1.461714/  1.835198, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-529 lr=['0.0010000'], tr/val_loss:  1.461686/  1.836788, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-530 lr=['0.0010000'], tr/val_loss:  1.461700/  1.834396, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-531 lr=['0.0010000'], tr/val_loss:  1.461700/  1.831874, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-532 lr=['0.0010000'], tr/val_loss:  1.461799/  1.836281, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-533 lr=['0.0010000'], tr/val_loss:  1.461672/  1.834820, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-534 lr=['0.0010000'], tr/val_loss:  1.461727/  1.834409, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-535 lr=['0.0010000'], tr/val_loss:  1.461686/  1.834543, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-536 lr=['0.0010000'], tr/val_loss:  1.461686/  1.834049, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-537 lr=['0.0010000'], tr/val_loss:  1.461659/  1.831586, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-538 lr=['0.0010000'], tr/val_loss:  1.461645/  1.833559, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-539 lr=['0.0010000'], tr/val_loss:  1.461645/  1.832814, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-540 lr=['0.0010000'], tr/val_loss:  1.461659/  1.831079, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-541 lr=['0.0010000'], tr/val_loss:  1.461672/  1.831594, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-542 lr=['0.0010000'], tr/val_loss:  1.461659/  1.833506, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-543 lr=['0.0010000'], tr/val_loss:  1.461673/  1.835057, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-544 lr=['0.0010000'], tr/val_loss:  1.461672/  1.833271, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-545 lr=['0.0010000'], tr/val_loss:  1.461659/  1.834630, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-546 lr=['0.0010000'], tr/val_loss:  1.461659/  1.835618, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-547 lr=['0.0010000'], tr/val_loss:  1.461817/  1.834314, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-548 lr=['0.0010000'], tr/val_loss:  1.462288/  1.833773, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-549 lr=['0.0010000'], tr/val_loss:  1.461645/  1.834938, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-550 lr=['0.0010000'], tr/val_loss:  1.461746/  1.832878, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-551 lr=['0.0010000'], tr/val_loss:  1.461631/  1.835417, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-552 lr=['0.0010000'], tr/val_loss:  1.461672/  1.835317, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-553 lr=['0.0010000'], tr/val_loss:  1.461658/  1.835064, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-554 lr=['0.0010000'], tr/val_loss:  1.461671/  1.835121, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-555 lr=['0.0010000'], tr/val_loss:  1.461659/  1.832399, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-556 lr=['0.0010000'], tr/val_loss:  1.461633/  1.837821, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-557 lr=['0.0010000'], tr/val_loss:  1.461645/  1.836238, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-558 lr=['0.0010000'], tr/val_loss:  1.461647/  1.838380, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-559 lr=['0.0010000'], tr/val_loss:  1.461633/  1.835992, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-560 lr=['0.0010000'], tr/val_loss:  1.461633/  1.835320, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-561 lr=['0.0010000'], tr/val_loss:  1.461633/  1.835317, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-562 lr=['0.0010000'], tr/val_loss:  1.461633/  1.834808, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-563 lr=['0.0010000'], tr/val_loss:  1.461720/  1.838454, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-564 lr=['0.0010000'], tr/val_loss:  1.461633/  1.836595, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-565 lr=['0.0010000'], tr/val_loss:  1.461646/  1.835905, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-566 lr=['0.0010000'], tr/val_loss:  1.461633/  1.837312, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-567 lr=['0.0010000'], tr/val_loss:  1.461633/  1.832581, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-568 lr=['0.0010000'], tr/val_loss:  1.461647/  1.834429, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-569 lr=['0.0010000'], tr/val_loss:  1.461647/  1.836370, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-570 lr=['0.0010000'], tr/val_loss:  1.461633/  1.836326, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-571 lr=['0.0010000'], tr/val_loss:  1.461619/  1.837660, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-572 lr=['0.0010000'], tr/val_loss:  1.462249/  1.834989, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-573 lr=['0.0010000'], tr/val_loss:  1.461619/  1.835659, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-574 lr=['0.0010000'], tr/val_loss:  1.461605/  1.834771, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-575 lr=['0.0010000'], tr/val_loss:  1.461605/  1.836775, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-576 lr=['0.0010000'], tr/val_loss:  1.461633/  1.838079, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-577 lr=['0.0010000'], tr/val_loss:  1.461619/  1.837505, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-578 lr=['0.0010000'], tr/val_loss:  1.461605/  1.839622, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-579 lr=['0.0010000'], tr/val_loss:  1.461690/  1.837504, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-580 lr=['0.0010000'], tr/val_loss:  1.461619/  1.838389, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-581 lr=['0.0010000'], tr/val_loss:  1.461633/  1.838850, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-582 lr=['0.0010000'], tr/val_loss:  1.461679/  1.839827, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-583 lr=['0.0010000'], tr/val_loss:  1.461646/  1.838417, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-584 lr=['0.0010000'], tr/val_loss:  1.461633/  1.836758, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-585 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837085, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-586 lr=['0.0010000'], tr/val_loss:  1.461619/  1.836965, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-587 lr=['0.0010000'], tr/val_loss:  1.461619/  1.838350, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-588 lr=['0.0010000'], tr/val_loss:  1.461633/  1.837415, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-589 lr=['0.0010000'], tr/val_loss:  1.461633/  1.839168, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-590 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837659, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-591 lr=['0.0010000'], tr/val_loss:  1.461633/  1.838218, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-592 lr=['0.0010000'], tr/val_loss:  1.461619/  1.835958, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-593 lr=['0.0010000'], tr/val_loss:  1.461619/  1.837861, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-594 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837205, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-595 lr=['0.0010000'], tr/val_loss:  1.461605/  1.834649, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-596 lr=['0.0010000'], tr/val_loss:  1.461619/  1.838366, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-597 lr=['0.0010000'], tr/val_loss:  1.461619/  1.834695, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-598 lr=['0.0010000'], tr/val_loss:  1.461619/  1.834708, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-599 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837375, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-600 lr=['0.0010000'], tr/val_loss:  1.461605/  1.840687, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-601 lr=['0.0010000'], tr/val_loss:  1.461605/  1.840742, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-602 lr=['0.0010000'], tr/val_loss:  1.461605/  1.839954, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-603 lr=['0.0010000'], tr/val_loss:  1.461619/  1.839445, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-604 lr=['0.0010000'], tr/val_loss:  1.461605/  1.839560, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-605 lr=['0.0010000'], tr/val_loss:  1.461605/  1.836229, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-606 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839311, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-607 lr=['0.0010000'], tr/val_loss:  1.461605/  1.838912, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-608 lr=['0.0010000'], tr/val_loss:  1.461592/  1.834507, tr: 100.00%, tr_best: 100.00%, val:  75.83%, val_best:  76.67%\n",
      "epoch-609 lr=['0.0010000'], tr/val_loss:  1.461605/  1.838665, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-610 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837770, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-611 lr=['0.0010000'], tr/val_loss:  1.461605/  1.840218, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-612 lr=['0.0010000'], tr/val_loss:  1.461605/  1.837032, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-613 lr=['0.0010000'], tr/val_loss:  1.461619/  1.840585, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-614 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839250, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-615 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839166, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-616 lr=['0.0010000'], tr/val_loss:  1.461591/  1.835153, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-617 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839800, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-618 lr=['0.0010000'], tr/val_loss:  1.461591/  1.840108, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-619 lr=['0.0010000'], tr/val_loss:  1.461591/  1.836959, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-620 lr=['0.0010000'], tr/val_loss:  1.461591/  1.840429, tr: 100.00%, tr_best: 100.00%, val:  76.25%, val_best:  76.67%\n",
      "epoch-621 lr=['0.0010000'], tr/val_loss:  1.461591/  1.836859, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-622 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839015, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-623 lr=['0.0010000'], tr/val_loss:  1.461591/  1.838570, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-624 lr=['0.0010000'], tr/val_loss:  1.461591/  1.840329, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-625 lr=['0.0010000'], tr/val_loss:  1.461605/  1.838570, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-626 lr=['0.0010000'], tr/val_loss:  1.461591/  1.841428, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-627 lr=['0.0010000'], tr/val_loss:  1.461591/  1.837824, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-628 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839179, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-629 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839953, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-630 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839921, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-631 lr=['0.0010000'], tr/val_loss:  1.461591/  1.838101, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-632 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839890, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-633 lr=['0.0010000'], tr/val_loss:  1.461591/  1.836550, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-634 lr=['0.0010000'], tr/val_loss:  1.461591/  1.841722, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-635 lr=['0.0010000'], tr/val_loss:  1.461591/  1.838024, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-636 lr=['0.0010000'], tr/val_loss:  1.461651/  1.840304, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-637 lr=['0.0010000'], tr/val_loss:  1.461578/  1.841445, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-638 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839732, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-639 lr=['0.0010000'], tr/val_loss:  1.461591/  1.843734, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-640 lr=['0.0010000'], tr/val_loss:  1.461605/  1.839715, tr: 100.00%, tr_best: 100.00%, val:  75.42%, val_best:  76.67%\n",
      "epoch-641 lr=['0.0010000'], tr/val_loss:  1.461591/  1.837946, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-642 lr=['0.0010000'], tr/val_loss:  1.461605/  1.838766, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-643 lr=['0.0010000'], tr/val_loss:  1.461592/  1.842345, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-644 lr=['0.0010000'], tr/val_loss:  1.461651/  1.841106, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-645 lr=['0.0010000'], tr/val_loss:  1.461605/  1.839069, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-646 lr=['0.0010000'], tr/val_loss:  1.461591/  1.841273, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-647 lr=['0.0010000'], tr/val_loss:  1.461591/  1.839445, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-648 lr=['0.0010000'], tr/val_loss:  1.461591/  1.843703, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-649 lr=['0.0010000'], tr/val_loss:  1.461605/  1.841352, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-650 lr=['0.0010000'], tr/val_loss:  1.461591/  1.840362, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-651 lr=['0.0010000'], tr/val_loss:  1.461651/  1.844034, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-652 lr=['0.0010000'], tr/val_loss:  1.461578/  1.843760, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-653 lr=['0.0010000'], tr/val_loss:  1.461605/  1.844041, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-654 lr=['0.0010000'], tr/val_loss:  1.461578/  1.842951, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-655 lr=['0.0010000'], tr/val_loss:  1.461578/  1.842240, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-656 lr=['0.0010000'], tr/val_loss:  1.461578/  1.842551, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-657 lr=['0.0010000'], tr/val_loss:  1.461591/  1.844514, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-658 lr=['0.0010000'], tr/val_loss:  1.461605/  1.846563, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-659 lr=['0.0010000'], tr/val_loss:  1.461662/  1.842200, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-660 lr=['0.0010000'], tr/val_loss:  1.461637/  1.843469, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-661 lr=['0.0010000'], tr/val_loss:  1.461564/  1.844582, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-662 lr=['0.0010000'], tr/val_loss:  1.461564/  1.844012, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-663 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843765, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-664 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843734, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-665 lr=['0.0010000'], tr/val_loss:  1.461564/  1.846061, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-666 lr=['0.0010000'], tr/val_loss:  1.461670/  1.846628, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-667 lr=['0.0010000'], tr/val_loss:  1.461564/  1.844609, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-668 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844685, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-669 lr=['0.0010000'], tr/val_loss:  1.461564/  1.842745, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-670 lr=['0.0010000'], tr/val_loss:  1.461550/  1.848241, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-671 lr=['0.0010000'], tr/val_loss:  1.461578/  1.842427, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-672 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845315, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-673 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843509, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-674 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845103, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-675 lr=['0.0010000'], tr/val_loss:  1.461987/  1.844728, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-676 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846531, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-677 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844398, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-678 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844027, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-679 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844085, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-680 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846128, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-681 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844237, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-682 lr=['0.0010000'], tr/val_loss:  1.461564/  1.844440, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-683 lr=['0.0010000'], tr/val_loss:  1.461550/  1.842207, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-684 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843746, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-685 lr=['0.0010000'], tr/val_loss:  1.461550/  1.842937, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-686 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843611, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-687 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845355, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-688 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844975, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-689 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846047, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-690 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845010, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-691 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845972, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-692 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844078, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-693 lr=['0.0010000'], tr/val_loss:  1.461550/  1.842886, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-694 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846015, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-695 lr=['0.0010000'], tr/val_loss:  1.461564/  1.846937, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-696 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844430, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-697 lr=['0.0010000'], tr/val_loss:  1.461550/  1.841270, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-698 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843261, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-699 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844543, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-700 lr=['0.0010000'], tr/val_loss:  1.461550/  1.842557, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-701 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843060, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-702 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844797, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-703 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844163, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-704 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845233, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-705 lr=['0.0010000'], tr/val_loss:  1.461610/  1.847467, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-706 lr=['0.0010000'], tr/val_loss:  1.461564/  1.844927, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-707 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845120, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-708 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846307, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-709 lr=['0.0010000'], tr/val_loss:  1.461550/  1.843930, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-710 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846871, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-711 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845833, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-712 lr=['0.0010000'], tr/val_loss:  1.461550/  1.847561, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-713 lr=['0.0010000'], tr/val_loss:  1.461536/  1.847337, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-714 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846238, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-715 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845646, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-716 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846996, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-717 lr=['0.0010000'], tr/val_loss:  1.461550/  1.846675, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-718 lr=['0.0010000'], tr/val_loss:  1.461550/  1.848720, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-719 lr=['0.0010000'], tr/val_loss:  1.461536/  1.847014, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-720 lr=['0.0010000'], tr/val_loss:  1.461564/  1.849252, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-721 lr=['0.0010000'], tr/val_loss:  1.461550/  1.844912, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-722 lr=['0.0010000'], tr/val_loss:  1.461564/  1.846367, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-723 lr=['0.0010000'], tr/val_loss:  1.461550/  1.845586, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-724 lr=['0.0010000'], tr/val_loss:  1.461449/  1.846212, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-725 lr=['0.0010000'], tr/val_loss:  1.461550/  1.848252, tr: 100.00%, tr_best: 100.00%, val:  75.00%, val_best:  76.67%\n",
      "epoch-726 lr=['0.0010000'], tr/val_loss:  1.461536/  1.849153, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-727 lr=['0.0010000'], tr/val_loss:  1.461522/  1.846758, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-728 lr=['0.0010000'], tr/val_loss:  1.461449/  1.846703, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-729 lr=['0.0010000'], tr/val_loss:  1.461463/  1.848570, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-730 lr=['0.0010000'], tr/val_loss:  1.461449/  1.846297, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-731 lr=['0.0010000'], tr/val_loss:  1.461536/  1.846633, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-732 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848283, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-733 lr=['0.0010000'], tr/val_loss:  1.461463/  1.846116, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-734 lr=['0.0010000'], tr/val_loss:  1.461463/  1.848715, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-735 lr=['0.0010000'], tr/val_loss:  1.461449/  1.846132, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-736 lr=['0.0010000'], tr/val_loss:  1.461449/  1.847462, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-737 lr=['0.0010000'], tr/val_loss:  1.461463/  1.846358, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-738 lr=['0.0010000'], tr/val_loss:  1.461463/  1.846735, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-739 lr=['0.0010000'], tr/val_loss:  1.461449/  1.849096, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-740 lr=['0.0010000'], tr/val_loss:  1.461522/  1.846865, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-741 lr=['0.0010000'], tr/val_loss:  1.461449/  1.846657, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-742 lr=['0.0010000'], tr/val_loss:  1.461449/  1.845350, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-743 lr=['0.0010000'], tr/val_loss:  1.461463/  1.847700, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-744 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847628, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-745 lr=['0.0010000'], tr/val_loss:  1.461463/  1.848755, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-746 lr=['0.0010000'], tr/val_loss:  1.461463/  1.846747, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-747 lr=['0.0010000'], tr/val_loss:  1.461449/  1.847313, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-748 lr=['0.0010000'], tr/val_loss:  1.461435/  1.850491, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-749 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848975, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-750 lr=['0.0010000'], tr/val_loss:  1.461449/  1.848563, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-751 lr=['0.0010000'], tr/val_loss:  1.461477/  1.846278, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-752 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849280, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-753 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847744, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-754 lr=['0.0010000'], tr/val_loss:  1.461449/  1.845724, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-755 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847010, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-756 lr=['0.0010000'], tr/val_loss:  1.461449/  1.847668, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-757 lr=['0.0010000'], tr/val_loss:  1.461435/  1.844348, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-758 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846833, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-759 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847126, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-760 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846853, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-761 lr=['0.0010000'], tr/val_loss:  1.461449/  1.848010, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-762 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849179, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-763 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848130, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-764 lr=['0.0010000'], tr/val_loss:  1.461449/  1.850311, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-765 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848106, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-766 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846200, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-767 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846499, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-768 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849711, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-769 lr=['0.0010000'], tr/val_loss:  1.461436/  1.849172, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-770 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848188, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-771 lr=['0.0010000'], tr/val_loss:  1.461495/  1.848896, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-772 lr=['0.0010000'], tr/val_loss:  1.461435/  1.848818, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-773 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849144, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-774 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846094, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-775 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847026, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-776 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849547, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-777 lr=['0.0010000'], tr/val_loss:  1.461435/  1.847972, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-778 lr=['0.0010000'], tr/val_loss:  1.461435/  1.850444, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-779 lr=['0.0010000'], tr/val_loss:  1.461435/  1.846649, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-780 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849112, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-781 lr=['0.0010000'], tr/val_loss:  1.461422/  1.849126, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-782 lr=['0.0010000'], tr/val_loss:  1.461422/  1.849736, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-783 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849281, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-784 lr=['0.0010000'], tr/val_loss:  1.461435/  1.850373, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-785 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849395, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-786 lr=['0.0010000'], tr/val_loss:  1.461422/  1.850437, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-787 lr=['0.0010000'], tr/val_loss:  1.461435/  1.850130, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-788 lr=['0.0010000'], tr/val_loss:  1.461495/  1.851222, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-789 lr=['0.0010000'], tr/val_loss:  1.461422/  1.850270, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-790 lr=['0.0010000'], tr/val_loss:  1.461435/  1.849924, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-791 lr=['0.0010000'], tr/val_loss:  1.461422/  1.849580, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-792 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850108, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-793 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851860, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-794 lr=['0.0010000'], tr/val_loss:  1.461408/  1.849027, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-795 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850068, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-796 lr=['0.0010000'], tr/val_loss:  1.461408/  1.852148, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-797 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851043, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-798 lr=['0.0010000'], tr/val_loss:  1.461408/  1.848502, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-799 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851181, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-800 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850058, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-801 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850637, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-802 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850242, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-803 lr=['0.0010000'], tr/val_loss:  1.461408/  1.852392, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-804 lr=['0.0010000'], tr/val_loss:  1.461408/  1.849607, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-805 lr=['0.0010000'], tr/val_loss:  1.461408/  1.848572, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-806 lr=['0.0010000'], tr/val_loss:  1.461408/  1.852218, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-807 lr=['0.0010000'], tr/val_loss:  1.461408/  1.849981, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-808 lr=['0.0010000'], tr/val_loss:  1.461408/  1.852847, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-809 lr=['0.0010000'], tr/val_loss:  1.461408/  1.850413, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-810 lr=['0.0010000'], tr/val_loss:  1.461421/  1.853509, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-811 lr=['0.0010000'], tr/val_loss:  1.461408/  1.852271, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-812 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853332, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-813 lr=['0.0010000'], tr/val_loss:  1.461380/  1.850273, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-814 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851159, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-815 lr=['0.0010000'], tr/val_loss:  1.461394/  1.850535, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-816 lr=['0.0010000'], tr/val_loss:  1.461394/  1.852342, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-817 lr=['0.0010000'], tr/val_loss:  1.461394/  1.851293, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-818 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851196, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-819 lr=['0.0010000'], tr/val_loss:  1.461394/  1.851239, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-820 lr=['0.0010000'], tr/val_loss:  1.461408/  1.851063, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-821 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853811, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-822 lr=['0.0010000'], tr/val_loss:  1.461394/  1.852635, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-823 lr=['0.0010000'], tr/val_loss:  1.461408/  1.854972, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-824 lr=['0.0010000'], tr/val_loss:  1.461394/  1.854205, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-825 lr=['0.0010000'], tr/val_loss:  1.461394/  1.852983, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-826 lr=['0.0010000'], tr/val_loss:  1.461394/  1.854283, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-827 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852559, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-828 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853550, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-829 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853241, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-830 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853863, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-831 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853181, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-832 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853372, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-833 lr=['0.0010000'], tr/val_loss:  1.461394/  1.853837, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-834 lr=['0.0010000'], tr/val_loss:  1.461394/  1.852842, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-835 lr=['0.0010000'], tr/val_loss:  1.461394/  1.854730, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-836 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852269, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-837 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852054, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-838 lr=['0.0010000'], tr/val_loss:  1.461380/  1.851831, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-839 lr=['0.0010000'], tr/val_loss:  1.461394/  1.855528, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-840 lr=['0.0010000'], tr/val_loss:  1.461380/  1.853602, tr: 100.00%, tr_best: 100.00%, val:  74.17%, val_best:  76.67%\n",
      "epoch-841 lr=['0.0010000'], tr/val_loss:  1.461380/  1.851901, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-842 lr=['0.0010000'], tr/val_loss:  1.461380/  1.853169, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-843 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852493, tr: 100.00%, tr_best: 100.00%, val:  74.58%, val_best:  76.67%\n",
      "epoch-844 lr=['0.0010000'], tr/val_loss:  1.461380/  1.853462, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-845 lr=['0.0010000'], tr/val_loss:  1.461394/  1.851269, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-846 lr=['0.0010000'], tr/val_loss:  1.461380/  1.854281, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-847 lr=['0.0010000'], tr/val_loss:  1.461394/  1.851537, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-848 lr=['0.0010000'], tr/val_loss:  1.461380/  1.850129, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-849 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852689, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-850 lr=['0.0010000'], tr/val_loss:  1.461380/  1.851434, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-851 lr=['0.0010000'], tr/val_loss:  1.461380/  1.851665, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-852 lr=['0.0010000'], tr/val_loss:  1.461380/  1.853435, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-853 lr=['0.0010000'], tr/val_loss:  1.461394/  1.855659, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-854 lr=['0.0010000'], tr/val_loss:  1.461380/  1.850015, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-855 lr=['0.0010000'], tr/val_loss:  1.461380/  1.852322, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-856 lr=['0.0010000'], tr/val_loss:  1.461394/  1.855766, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-857 lr=['0.0010000'], tr/val_loss:  1.461408/  1.853382, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-858 lr=['0.0010000'], tr/val_loss:  1.461408/  1.853032, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-859 lr=['0.0010000'], tr/val_loss:  1.461394/  1.851762, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-860 lr=['0.0010000'], tr/val_loss:  1.461394/  1.850846, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-861 lr=['0.0010000'], tr/val_loss:  1.461394/  1.849762, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-862 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852033, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-863 lr=['0.0010000'], tr/val_loss:  1.461394/  1.850884, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-864 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852735, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-865 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852510, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-866 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853527, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-867 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852454, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-868 lr=['0.0010000'], tr/val_loss:  1.461321/  1.853432, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-869 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853433, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-870 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851965, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-871 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854176, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-872 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851529, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-873 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854341, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-874 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851324, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-875 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852514, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-876 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854342, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-877 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852008, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-878 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853405, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-879 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852455, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-880 lr=['0.0010000'], tr/val_loss:  1.461307/  1.848276, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-881 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851733, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-882 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851447, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-883 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852691, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-884 lr=['0.0010000'], tr/val_loss:  1.461367/  1.852546, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-885 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852095, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-886 lr=['0.0010000'], tr/val_loss:  1.461307/  1.850768, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-887 lr=['0.0010000'], tr/val_loss:  1.461321/  1.854149, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-888 lr=['0.0010000'], tr/val_loss:  1.461307/  1.848951, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-889 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851369, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-890 lr=['0.0010000'], tr/val_loss:  1.461307/  1.848394, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-891 lr=['0.0010000'], tr/val_loss:  1.461321/  1.849840, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-892 lr=['0.0010000'], tr/val_loss:  1.461394/  1.849748, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-893 lr=['0.0010000'], tr/val_loss:  1.461362/  1.849449, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-894 lr=['0.0010000'], tr/val_loss:  1.461321/  1.848600, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-895 lr=['0.0010000'], tr/val_loss:  1.461335/  1.849628, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-896 lr=['0.0010000'], tr/val_loss:  1.461321/  1.848946, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-897 lr=['0.0010000'], tr/val_loss:  1.461307/  1.849673, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-898 lr=['0.0010000'], tr/val_loss:  1.461321/  1.852242, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-899 lr=['0.0010000'], tr/val_loss:  1.461321/  1.849154, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-900 lr=['0.0010000'], tr/val_loss:  1.461348/  1.850325, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-901 lr=['0.0010000'], tr/val_loss:  1.461307/  1.849999, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-902 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851015, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-903 lr=['0.0010000'], tr/val_loss:  1.461335/  1.851158, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-904 lr=['0.0010000'], tr/val_loss:  1.461321/  1.852499, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-905 lr=['0.0010000'], tr/val_loss:  1.461321/  1.849825, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-906 lr=['0.0010000'], tr/val_loss:  1.461307/  1.849359, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-907 lr=['0.0010000'], tr/val_loss:  1.461321/  1.850600, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-908 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851755, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-909 lr=['0.0010000'], tr/val_loss:  1.461334/  1.850901, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-910 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851313, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-911 lr=['0.0010000'], tr/val_loss:  1.461307/  1.848454, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-912 lr=['0.0010000'], tr/val_loss:  1.461307/  1.848558, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-913 lr=['0.0010000'], tr/val_loss:  1.461381/  1.851918, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-914 lr=['0.0010000'], tr/val_loss:  1.461307/  1.849923, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-915 lr=['0.0010000'], tr/val_loss:  1.461307/  1.850561, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-916 lr=['0.0010000'], tr/val_loss:  1.461335/  1.851007, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-917 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852311, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-918 lr=['0.0010000'], tr/val_loss:  1.461307/  1.850782, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-919 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852172, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-920 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851719, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-921 lr=['0.0010000'], tr/val_loss:  1.461307/  1.850412, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-922 lr=['0.0010000'], tr/val_loss:  1.461321/  1.850380, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-923 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851279, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-924 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851667, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-925 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851908, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-926 lr=['0.0010000'], tr/val_loss:  1.461744/  1.853102, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-927 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853014, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-928 lr=['0.0010000'], tr/val_loss:  1.461321/  1.851066, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-929 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851559, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-930 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854669, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-931 lr=['0.0010000'], tr/val_loss:  1.461321/  1.852010, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-932 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852301, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-933 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853262, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-934 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852718, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-935 lr=['0.0010000'], tr/val_loss:  1.461335/  1.853298, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-936 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852308, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-937 lr=['0.0010000'], tr/val_loss:  1.461307/  1.849783, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-938 lr=['0.0010000'], tr/val_loss:  1.461307/  1.850214, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-939 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854367, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-940 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852566, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-941 lr=['0.0010000'], tr/val_loss:  1.461321/  1.852544, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-942 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856112, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-943 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852430, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-944 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852674, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-945 lr=['0.0010000'], tr/val_loss:  1.461307/  1.851443, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-946 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853970, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-947 lr=['0.0010000'], tr/val_loss:  1.461321/  1.854166, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-948 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854844, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-949 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855040, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-950 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853670, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-951 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853772, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-952 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853422, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-953 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854072, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-954 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853584, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-955 lr=['0.0010000'], tr/val_loss:  1.461321/  1.853895, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-956 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854235, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-957 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853072, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-958 lr=['0.0010000'], tr/val_loss:  1.461381/  1.854377, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-959 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852764, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-960 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855834, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-961 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853181, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-962 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854794, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-963 lr=['0.0010000'], tr/val_loss:  1.461307/  1.852826, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-964 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855208, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-965 lr=['0.0010000'], tr/val_loss:  1.461321/  1.855758, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-966 lr=['0.0010000'], tr/val_loss:  1.461321/  1.854875, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-967 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855216, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-968 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854854, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-969 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853969, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-970 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855521, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-971 lr=['0.0010000'], tr/val_loss:  1.461321/  1.856233, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-972 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855886, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-973 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855808, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-974 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855483, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-975 lr=['0.0010000'], tr/val_loss:  1.461744/  1.854560, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-976 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856296, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-977 lr=['0.0010000'], tr/val_loss:  1.461307/  1.858175, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-978 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854162, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-979 lr=['0.0010000'], tr/val_loss:  1.461321/  1.856797, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-980 lr=['0.0010000'], tr/val_loss:  1.461321/  1.856186, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-981 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856869, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-982 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854805, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-983 lr=['0.0010000'], tr/val_loss:  1.461321/  1.856175, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-984 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856894, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-985 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856150, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-986 lr=['0.0010000'], tr/val_loss:  1.461321/  1.857197, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-987 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856086, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-988 lr=['0.0010000'], tr/val_loss:  1.461321/  1.855497, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-989 lr=['0.0010000'], tr/val_loss:  1.461321/  1.858068, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-990 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856052, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-991 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856892, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-992 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856116, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-993 lr=['0.0010000'], tr/val_loss:  1.461321/  1.859018, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-994 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855405, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-995 lr=['0.0010000'], tr/val_loss:  1.461307/  1.854349, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-996 lr=['0.0010000'], tr/val_loss:  1.461307/  1.857516, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-997 lr=['0.0010000'], tr/val_loss:  1.461307/  1.857253, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-998 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856895, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-999 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856272, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1000 lr=['0.0010000'], tr/val_loss:  1.461321/  1.856210, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1001 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855240, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1002 lr=['0.0010000'], tr/val_loss:  1.461307/  1.853402, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1003 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855486, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1004 lr=['0.0010000'], tr/val_loss:  1.461321/  1.854751, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1005 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856220, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1006 lr=['0.0010000'], tr/val_loss:  1.461307/  1.855620, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1007 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856498, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1008 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856869, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1009 lr=['0.0010000'], tr/val_loss:  1.461307/  1.857222, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1010 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856566, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1011 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856714, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1012 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856799, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1013 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856203, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1014 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856086, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1015 lr=['0.0010000'], tr/val_loss:  1.461307/  1.858513, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1016 lr=['0.0010000'], tr/val_loss:  1.461307/  1.856920, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1017 lr=['0.0010000'], tr/val_loss:  1.461307/  1.857399, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1018 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857840, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1019 lr=['0.0010000'], tr/val_loss:  1.461307/  1.858521, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1020 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857835, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1021 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859511, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1022 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858304, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1023 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857605, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1024 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856680, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1025 lr=['0.0010000'], tr/val_loss:  1.461307/  1.859422, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1026 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857498, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1027 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859422, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1028 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858764, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1029 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858146, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1030 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857647, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1031 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859474, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1032 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858709, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1033 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858996, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1034 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860496, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1035 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858527, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1036 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858662, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1037 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858083, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1038 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859219, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1039 lr=['0.0010000'], tr/val_loss:  1.461293/  1.861375, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1040 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860507, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1041 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858650, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1042 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858117, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1043 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858929, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1044 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858917, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1045 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858659, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1046 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860116, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1047 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859424, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1048 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858920, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1049 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858461, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1050 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858598, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1051 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856731, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1052 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857843, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1053 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856682, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1054 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856630, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1055 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857236, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1056 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858001, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1057 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856433, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1058 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858474, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1059 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856173, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1060 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858295, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1061 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855836, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1062 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859055, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1063 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857779, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1064 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857967, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1065 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859521, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1066 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857127, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1067 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857140, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1068 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857875, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1069 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859294, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1070 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859335, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1071 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858452, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1072 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859167, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1073 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859123, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1074 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857785, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1075 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857204, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1076 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858879, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1077 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857930, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1078 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858342, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1079 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858039, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1080 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857697, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1081 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858884, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1082 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857371, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1083 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859148, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1084 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858019, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1085 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858367, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1086 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858240, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1087 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856287, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1088 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859560, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1089 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856969, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1090 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855310, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1091 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859214, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1092 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857582, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1093 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858069, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1094 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857956, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1095 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858477, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1096 lr=['0.0010000'], tr/val_loss:  1.461293/  1.861057, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1097 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859472, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1098 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856862, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1099 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858126, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1100 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858705, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1101 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858046, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1102 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858270, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1103 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859847, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1104 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859482, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1105 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860657, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1106 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859688, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1107 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860295, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1108 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858276, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1109 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860286, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1110 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858041, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1111 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859546, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1112 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859726, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1113 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858861, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1114 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858674, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1115 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859667, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1116 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859775, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1117 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858107, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1118 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860848, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1119 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859250, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1120 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860480, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1121 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858693, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1122 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859976, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1123 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860373, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1124 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858512, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1125 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859168, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1126 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860895, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1127 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859266, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1128 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857638, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1129 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857356, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1130 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858259, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1131 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859336, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1132 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859393, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1133 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860769, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1134 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859536, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1135 lr=['0.0010000'], tr/val_loss:  1.461716/  1.860727, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1136 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859022, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1137 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858785, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1138 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859681, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1139 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859285, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1140 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857904, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1141 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857604, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1142 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859389, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1143 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859001, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1144 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858956, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-1145 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861009, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1146 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859545, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1147 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858334, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1148 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857743, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1149 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858274, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1150 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859203, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1151 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859930, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1152 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858971, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1153 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858896, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1154 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859797, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1155 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861476, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1156 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857477, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1157 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860829, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1158 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860136, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1159 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858367, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1160 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860086, tr: 100.00%, tr_best: 100.00%, val:  73.75%, val_best:  76.67%\n",
      "epoch-1161 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859843, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1162 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860159, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1163 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858132, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1164 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859535, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1165 lr=['0.0010000'], tr/val_loss:  1.461366/  1.858351, tr: 100.00%, tr_best: 100.00%, val:  73.33%, val_best:  76.67%\n",
      "epoch-1166 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861181, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1167 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859946, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1168 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860214, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1169 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859578, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1170 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859523, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1171 lr=['0.0010000'], tr/val_loss:  1.461380/  1.858425, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1172 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859410, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1173 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858536, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1174 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858579, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1175 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858475, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1176 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859247, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1177 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859210, tr: 100.00%, tr_best: 100.00%, val:  72.92%, val_best:  76.67%\n",
      "epoch-1178 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858063, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1179 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860304, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1180 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858023, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1181 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858011, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1182 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855923, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1183 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859769, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1184 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859056, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1185 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857095, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1186 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857378, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1187 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859962, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1188 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857829, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1189 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859298, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1190 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858043, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1191 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859641, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1192 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859086, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1193 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856947, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1194 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859513, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1195 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858605, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1196 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859437, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1197 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859203, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1198 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859283, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1199 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858820, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1200 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857895, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1201 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855733, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1202 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856607, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1203 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856837, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1204 lr=['0.0010000'], tr/val_loss:  1.461279/  1.855944, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1205 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856656, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1206 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857419, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1207 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858063, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1208 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856996, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1209 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855635, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1210 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858977, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1211 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857675, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1212 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858044, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1213 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857868, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1214 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856521, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1215 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857659, tr: 100.00%, tr_best: 100.00%, val:  72.50%, val_best:  76.67%\n",
      "epoch-1216 lr=['0.0010000'], tr/val_loss:  1.461279/  1.855981, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1217 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857516, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1218 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858254, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1219 lr=['0.0010000'], tr/val_loss:  1.461730/  1.857050, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1220 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858694, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1221 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856395, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1222 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856440, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1223 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858452, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1224 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858313, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1225 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857846, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1226 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856062, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1227 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857145, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1228 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857998, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1229 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858128, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1230 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856283, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1231 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856486, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1232 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856581, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1233 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857468, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1234 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855313, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1235 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857885, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1236 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856895, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1237 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857185, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1238 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857417, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1239 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858127, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1240 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856645, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1241 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856533, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1242 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857267, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1243 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858056, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1244 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859928, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1245 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858346, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1246 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858556, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1247 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858894, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1248 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857239, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1249 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858645, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1250 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856566, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1251 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858468, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1252 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857997, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1253 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859514, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1254 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857247, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1255 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859163, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1256 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858424, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1257 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858927, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1258 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856962, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1259 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859878, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1260 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858338, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1261 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859495, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1262 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859753, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1263 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858184, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1264 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858696, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1265 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859179, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1266 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858831, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1267 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858747, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1268 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857997, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1269 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860609, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1270 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860263, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1271 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859334, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1272 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859902, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1273 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858917, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1274 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859409, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1275 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861806, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1276 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860748, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1277 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861608, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1278 lr=['0.0010000'], tr/val_loss:  1.461280/  1.862799, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1279 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859477, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1280 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858705, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1281 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859224, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1282 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860538, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1283 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860190, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1284 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859026, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1285 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856745, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1286 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861788, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1287 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858023, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1288 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860942, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1289 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859289, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1290 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858735, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1291 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859366, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1292 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859034, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1293 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857529, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1294 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857897, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1295 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858958, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1296 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857965, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1297 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858523, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1298 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859430, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1299 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857021, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1300 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857288, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1301 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860090, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1302 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858842, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1303 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859936, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1304 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859421, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1305 lr=['0.0010000'], tr/val_loss:  1.461293/  1.862064, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1306 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860083, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1307 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861334, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1308 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860327, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1309 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859656, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1310 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859228, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1311 lr=['0.0010000'], tr/val_loss:  1.461339/  1.860188, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1312 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860037, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1313 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858736, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1314 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860712, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1315 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858655, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1316 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858764, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1317 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859028, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1318 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860821, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1319 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859512, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1320 lr=['0.0010000'], tr/val_loss:  1.461339/  1.857612, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1321 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860744, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1322 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859818, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1323 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859364, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1324 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859842, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1325 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856937, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1326 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858947, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1327 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857554, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1328 lr=['0.0010000'], tr/val_loss:  1.461280/  1.862113, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1329 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858009, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1330 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860655, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1331 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856132, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1332 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856782, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1333 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860076, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1334 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859494, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1335 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857156, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1336 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860095, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1337 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857832, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1338 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859225, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1339 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857547, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1340 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858428, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1341 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861610, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1342 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859380, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1343 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857506, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1344 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857995, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1345 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860681, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1346 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859068, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1347 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857440, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1348 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858524, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1349 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858925, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1350 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858755, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1351 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859054, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1352 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858335, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1353 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858380, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1354 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858396, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1355 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857948, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1356 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859029, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1357 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857074, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1358 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858415, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1359 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859605, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1360 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860511, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1361 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857078, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1362 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857037, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1363 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858540, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1364 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858476, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1365 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859970, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1366 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860393, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1367 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858176, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1368 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859450, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1369 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861518, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1370 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861051, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1371 lr=['0.0010000'], tr/val_loss:  1.461293/  1.861340, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1372 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859091, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1373 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861452, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1374 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859788, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1375 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858433, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1376 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861427, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1377 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861048, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1378 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860278, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1379 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860671, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1380 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859012, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1381 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859746, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1382 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861586, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1383 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859321, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1384 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860279, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1385 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859217, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1386 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860270, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1387 lr=['0.0010000'], tr/val_loss:  1.461339/  1.859033, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1388 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861057, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1389 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860541, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1390 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860790, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1391 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859503, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1392 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860734, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1393 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861033, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1394 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861438, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1395 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861037, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1396 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861548, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1397 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860882, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1398 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861313, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1399 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861820, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1400 lr=['0.0010000'], tr/val_loss:  1.461279/  1.862098, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1401 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861119, tr: 100.00%, tr_best: 100.00%, val:  69.17%, val_best:  76.67%\n",
      "epoch-1402 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860912, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1403 lr=['0.0010000'], tr/val_loss:  1.461280/  1.861794, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1404 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859623, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1405 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859945, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1406 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858547, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1407 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857770, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1408 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858886, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1409 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857506, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1410 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857226, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1411 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859764, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1412 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857180, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1413 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858701, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1414 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858538, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1415 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859908, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1416 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859761, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1417 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859090, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1418 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860218, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1419 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860791, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1420 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858913, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1421 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858725, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1422 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857561, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1423 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859785, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1424 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859304, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1425 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857770, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1426 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859649, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1427 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858930, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1428 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858412, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1429 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858593, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1430 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859820, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1431 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857915, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1432 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860031, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1433 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860568, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1434 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860612, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1435 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858997, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1436 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857963, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1437 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858954, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1438 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860662, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1439 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858380, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1440 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857932, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1441 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860115, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1442 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859357, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1443 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861044, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1444 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858140, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1445 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858100, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1446 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857505, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1447 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859887, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1448 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858330, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1449 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859937, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1450 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859445, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1451 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860229, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1452 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858570, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1453 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859873, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1454 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858299, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1455 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860192, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1456 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860456, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1457 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860089, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1458 lr=['0.0010000'], tr/val_loss:  1.461293/  1.860677, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1459 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858761, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1460 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858835, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1461 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859474, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1462 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859904, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1463 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858111, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1464 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860486, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1465 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859054, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1466 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859530, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1467 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859304, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1468 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858742, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1469 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858792, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1470 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857205, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1471 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858822, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1472 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859044, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1473 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858927, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1474 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857169, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1475 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858349, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1476 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857784, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1477 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857340, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1478 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857562, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1479 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858860, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1480 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857870, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1481 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857526, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1482 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856891, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1483 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856571, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1484 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858403, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1485 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857474, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1486 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858647, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1487 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859128, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1488 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858037, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1489 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857995, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1490 lr=['0.0010000'], tr/val_loss:  1.461293/  1.858888, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1491 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857884, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1492 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857280, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1493 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857527, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1494 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857229, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1495 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859061, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1496 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858665, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1497 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856529, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1498 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857768, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1499 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857044, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1500 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859322, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1501 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857212, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1502 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857437, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1503 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856721, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1504 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857137, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1505 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859106, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1506 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858173, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1507 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857276, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1508 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856227, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1509 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858858, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1510 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857431, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1511 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858690, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1512 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856409, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1513 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856057, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1514 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857374, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1515 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857192, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1516 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857005, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1517 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858891, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1518 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858275, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1519 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858592, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1520 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856053, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1521 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858968, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1522 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859027, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1523 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857747, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1524 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858327, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1525 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857159, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1526 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857962, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1527 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856586, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1528 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857622, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1529 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859072, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1530 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857639, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1531 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857973, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1532 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859216, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1533 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857713, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1534 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857862, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1535 lr=['0.0010000'], tr/val_loss:  1.461280/  1.855803, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1536 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858388, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1537 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857952, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1538 lr=['0.0010000'], tr/val_loss:  1.461293/  1.857108, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1539 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858781, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1540 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859012, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1541 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856842, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1542 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859360, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1543 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858049, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1544 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858977, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1545 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859794, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1546 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860910, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1547 lr=['0.0010000'], tr/val_loss:  1.461280/  1.860029, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1548 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859162, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1549 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858911, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1550 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858490, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1551 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859781, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1552 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859387, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1553 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856835, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1554 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857743, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1555 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858715, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1556 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858339, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1557 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860254, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1558 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859160, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1559 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861556, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1560 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859419, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1561 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857686, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1562 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859957, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1563 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858811, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1564 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859482, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1565 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859758, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1566 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860507, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1567 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859034, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1568 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860446, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1569 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858361, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1570 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858419, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1571 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858452, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1572 lr=['0.0010000'], tr/val_loss:  1.461280/  1.859183, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1573 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857937, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1574 lr=['0.0010000'], tr/val_loss:  1.461279/  1.860095, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1575 lr=['0.0010000'], tr/val_loss:  1.461279/  1.861015, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1576 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858831, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1577 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859585, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1578 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859295, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1579 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857484, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1580 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859486, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1581 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857439, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1582 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858084, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1583 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858158, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1584 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858568, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1585 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858074, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1586 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858819, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1587 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858376, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1588 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858727, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1589 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858975, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1590 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858234, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1591 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858524, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1592 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859466, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1593 lr=['0.0010000'], tr/val_loss:  1.461279/  1.858469, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1594 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858757, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1595 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856744, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1596 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859084, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1597 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857802, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1598 lr=['0.0010000'], tr/val_loss:  1.461293/  1.859673, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1599 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859861, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1600 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857513, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1601 lr=['0.0010000'], tr/val_loss:  1.461279/  1.859432, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1602 lr=['0.0010000'], tr/val_loss:  1.461280/  1.858221, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1603 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856031, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1604 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856572, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1605 lr=['0.0010000'], tr/val_loss:  1.461279/  1.857789, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1606 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856090, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1607 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856987, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1608 lr=['0.0010000'], tr/val_loss:  1.461280/  1.857065, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1609 lr=['0.0010000'], tr/val_loss:  1.461279/  1.855861, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1610 lr=['0.0010000'], tr/val_loss:  1.461339/  1.856435, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1611 lr=['0.0010000'], tr/val_loss:  1.461279/  1.855519, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1612 lr=['0.0010000'], tr/val_loss:  1.461280/  1.855763, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1613 lr=['0.0010000'], tr/val_loss:  1.461293/  1.855201, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1614 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856385, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1615 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856952, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1616 lr=['0.0010000'], tr/val_loss:  1.461339/  1.855194, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1617 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856362, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1618 lr=['0.0010000'], tr/val_loss:  1.461293/  1.856628, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1619 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856767, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1620 lr=['0.0010000'], tr/val_loss:  1.461279/  1.856008, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1621 lr=['0.0010000'], tr/val_loss:  1.461279/  1.854861, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1622 lr=['0.0010000'], tr/val_loss:  1.461280/  1.856826, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1623 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853020, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1624 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854071, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1625 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856813, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1626 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856828, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1627 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855752, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1628 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852926, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1629 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854126, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1630 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853736, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1631 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853683, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1632 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855365, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1633 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853629, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1634 lr=['0.0010000'], tr/val_loss:  1.461206/  1.852827, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1635 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853725, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1636 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853384, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1637 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854963, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1638 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853558, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1639 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854083, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1640 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854313, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1641 lr=['0.0010000'], tr/val_loss:  1.461206/  1.852377, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1642 lr=['0.0010000'], tr/val_loss:  1.461220/  1.854533, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1643 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856775, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1644 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855999, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1645 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855408, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1646 lr=['0.0010000'], tr/val_loss:  1.461206/  1.857687, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1647 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854282, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1648 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856265, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1649 lr=['0.0010000'], tr/val_loss:  1.461266/  1.854084, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1650 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856749, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1651 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854116, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1652 lr=['0.0010000'], tr/val_loss:  1.461206/  1.857154, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1653 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855975, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1654 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854272, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1655 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857660, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1656 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856469, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1657 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856301, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1658 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855734, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1659 lr=['0.0010000'], tr/val_loss:  1.461206/  1.856676, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1660 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854130, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1661 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854452, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1662 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855645, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1663 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854621, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1664 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854419, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1665 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853517, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1666 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854452, tr: 100.00%, tr_best: 100.00%, val:  69.58%, val_best:  76.67%\n",
      "epoch-1667 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855286, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1668 lr=['0.0010000'], tr/val_loss:  1.461206/  1.857214, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1669 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854758, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1670 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857106, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1671 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855259, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1672 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854637, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1673 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854245, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1674 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855968, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1675 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854694, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1676 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855174, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1677 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856235, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1678 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855158, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1679 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855682, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1680 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855417, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1681 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856435, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1682 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855714, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1683 lr=['0.0010000'], tr/val_loss:  1.461192/  1.851397, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1684 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853613, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1685 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855124, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1686 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855741, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1687 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853519, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1688 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855392, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1689 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854107, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1690 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854112, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1691 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856891, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1692 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853182, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1693 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855087, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1694 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853478, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1695 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854777, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1696 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854004, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1697 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854506, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1698 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852923, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1699 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853424, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1700 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855240, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1701 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853328, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1702 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854286, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1703 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855586, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1704 lr=['0.0010000'], tr/val_loss:  1.461192/  1.851598, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1705 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853510, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1706 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855021, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1707 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853983, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1708 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853628, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1709 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854639, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1710 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855642, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1711 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855234, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1712 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854003, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1713 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854752, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1714 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854637, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1715 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853742, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1716 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854075, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1717 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852590, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1718 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854937, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1719 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852971, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1720 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852685, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1721 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854095, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1722 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853366, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1723 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855490, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1724 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853332, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1725 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853433, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1726 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855110, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1727 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853967, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1728 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852114, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1729 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853106, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1730 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853657, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1731 lr=['0.0010000'], tr/val_loss:  1.461206/  1.852407, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1732 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852751, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1733 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853108, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1734 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854718, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1735 lr=['0.0010000'], tr/val_loss:  1.461206/  1.851975, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1736 lr=['0.0010000'], tr/val_loss:  1.461206/  1.852378, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1737 lr=['0.0010000'], tr/val_loss:  1.461206/  1.849365, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1738 lr=['0.0010000'], tr/val_loss:  1.461206/  1.852774, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1739 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854058, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1740 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854290, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1741 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854730, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1742 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855442, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1743 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854892, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1744 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855356, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1745 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854910, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1746 lr=['0.0010000'], tr/val_loss:  1.461206/  1.851708, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1747 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854238, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1748 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853669, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1749 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853009, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1750 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853346, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1751 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855502, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1752 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854679, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1753 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853691, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1754 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855235, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1755 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853830, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1756 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853040, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1757 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854561, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1758 lr=['0.0010000'], tr/val_loss:  1.461206/  1.853509, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1759 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855019, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1760 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855781, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1761 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852979, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1762 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854834, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1763 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853597, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1764 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853218, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1765 lr=['0.0010000'], tr/val_loss:  1.461192/  1.850091, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1766 lr=['0.0010000'], tr/val_loss:  1.461192/  1.851493, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1767 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854355, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1768 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853546, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1769 lr=['0.0010000'], tr/val_loss:  1.461206/  1.851321, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1770 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852486, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1771 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854605, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1772 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853782, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1773 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853220, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1774 lr=['0.0010000'], tr/val_loss:  1.461192/  1.851726, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1775 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854959, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1776 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853640, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1777 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853868, tr: 100.00%, tr_best: 100.00%, val:  71.67%, val_best:  76.67%\n",
      "epoch-1778 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853335, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1779 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854298, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1780 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856117, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1781 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855947, tr: 100.00%, tr_best: 100.00%, val:  72.08%, val_best:  76.67%\n",
      "epoch-1782 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854689, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1783 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853445, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1784 lr=['0.0010000'], tr/val_loss:  1.461192/  1.852732, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1785 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853725, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1786 lr=['0.0010000'], tr/val_loss:  1.461192/  1.853936, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1787 lr=['0.0010000'], tr/val_loss:  1.461206/  1.854962, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1788 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855134, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1789 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855484, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1790 lr=['0.0010000'], tr/val_loss:  1.461206/  1.855088, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1791 lr=['0.0010000'], tr/val_loss:  1.461192/  1.851713, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1792 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856546, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1793 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855150, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1794 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854756, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1795 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854410, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1796 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855876, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1797 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855718, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1798 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857539, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1799 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856313, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1800 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857718, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1801 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855122, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1802 lr=['0.0010000'], tr/val_loss:  1.461179/  1.856047, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1803 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855854, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1804 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854492, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1805 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856487, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1806 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855867, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1807 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856739, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1808 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856544, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1809 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856316, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1810 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856838, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1811 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855139, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1812 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855526, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1813 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854927, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1814 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856336, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1815 lr=['0.0010000'], tr/val_loss:  1.461192/  1.854753, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1816 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857133, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1817 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857199, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1818 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855517, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1819 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855512, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1820 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856799, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1821 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856270, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1822 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856117, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1823 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855303, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1824 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856414, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1825 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858665, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1826 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856730, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1827 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858549, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1828 lr=['0.0010000'], tr/val_loss:  1.461179/  1.858824, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1829 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857199, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1830 lr=['0.0010000'], tr/val_loss:  1.461179/  1.855999, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1831 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856780, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1832 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857648, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1833 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857246, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1834 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856297, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1835 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857914, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1836 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857306, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1837 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857465, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1838 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856725, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1839 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857296, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1840 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856764, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1841 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857718, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1842 lr=['0.0010000'], tr/val_loss:  1.461179/  1.856290, tr: 100.00%, tr_best: 100.00%, val:  71.25%, val_best:  76.67%\n",
      "epoch-1843 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857661, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1844 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859746, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1845 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859505, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1846 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857820, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1847 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856998, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1848 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857071, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1849 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856568, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1850 lr=['0.0010000'], tr/val_loss:  1.461192/  1.856793, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1851 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857588, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1852 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858919, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1853 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858421, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1854 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857460, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1855 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859138, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1856 lr=['0.0010000'], tr/val_loss:  1.461179/  1.855883, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1857 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857774, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1858 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859259, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1859 lr=['0.0010000'], tr/val_loss:  1.461192/  1.855038, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1860 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858456, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1861 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858733, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1862 lr=['0.0010000'], tr/val_loss:  1.461179/  1.856354, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1863 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858255, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1864 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858740, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1865 lr=['0.0010000'], tr/val_loss:  1.461206/  1.859017, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1866 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859404, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1867 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857417, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1868 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859585, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1869 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859677, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1870 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859203, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1871 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857474, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1872 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857939, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1873 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858353, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1874 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858487, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1875 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857370, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1876 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858185, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1877 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859268, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1878 lr=['0.0010000'], tr/val_loss:  1.461179/  1.858451, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1879 lr=['0.0010000'], tr/val_loss:  1.461192/  1.860725, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1880 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859266, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1881 lr=['0.0010000'], tr/val_loss:  1.461179/  1.858877, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1882 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859427, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1883 lr=['0.0010000'], tr/val_loss:  1.461179/  1.861117, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1884 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857336, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1885 lr=['0.0010000'], tr/val_loss:  1.461192/  1.860087, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1886 lr=['0.0010000'], tr/val_loss:  1.461192/  1.860393, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1887 lr=['0.0010000'], tr/val_loss:  1.461192/  1.859138, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1888 lr=['0.0010000'], tr/val_loss:  1.461192/  1.860160, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1889 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859336, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1890 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857751, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1891 lr=['0.0010000'], tr/val_loss:  1.461179/  1.859234, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1892 lr=['0.0010000'], tr/val_loss:  1.461192/  1.857472, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1893 lr=['0.0010000'], tr/val_loss:  1.461179/  1.856950, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1894 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857171, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1895 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857087, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1896 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857766, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n",
      "epoch-1897 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858608, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1898 lr=['0.0010000'], tr/val_loss:  1.461179/  1.857597, tr: 100.00%, tr_best: 100.00%, val:  70.42%, val_best:  76.67%\n",
      "epoch-1899 lr=['0.0010000'], tr/val_loss:  1.461179/  1.856419, tr: 100.00%, tr_best: 100.00%, val:  70.00%, val_best:  76.67%\n",
      "epoch-1900 lr=['0.0010000'], tr/val_loss:  1.461192/  1.858739, tr: 100.00%, tr_best: 100.00%, val:  70.83%, val_best:  76.67%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = True # trace 할거면 True, 안할거면 False\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "DFA_on_True__BPTT_on_False_single_step_True = True # True # False \n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "my_snn_system(  devices = \"3\",\n",
    "                single_step = DFA_on_True__BPTT_on_False_single_step_True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = ['M', 'M', 200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = not DFA_on_True__BPTT_on_False_single_step_True,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 5, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = DFA_on_True__BPTT_on_False_single_step_True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.001]}, #0.00936191669529645\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"decay\": {\"values\": [0.25]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"epoch_num\": {\"values\": [200]},\n",
    "#         \"dvs_duration\": {\"values\": [25_000,50_000,100_000]},\n",
    "#         \"dvs_clipping\": {\"values\": [1,2,3,4,5]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"const2\": {\"values\": [False]},\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "#         \"DFA_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "#         \"e_transport_swap\": {\"values\": [0]},\n",
    "#         \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "#         \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [3.555718888923306]},\n",
    "#         \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.720291189014991]},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "#         \"denoise_on\": {\"values\": [True,False]}, \n",
    "#         \"I_wanna_sweep_at_this_epoch\": {\"values\": [-1]}, \n",
    "#         \"dvs_duration_domain\": {\"values\": [[]]}, \n",
    "#         \"dvs_relative_timestep\": {\"values\": [[False]]}, \n",
    "#         \"extra_train_dataset\": {\"values\": [0]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num \n",
    "#     dvs_duration  =  wandb.config.dvs_duration\n",
    "#     dvs_clipping  =  wandb.config.dvs_clipping\n",
    "#     which_data  =  wandb.config.which_data\n",
    "#     const2  =  wandb.config.const2\n",
    "#     surrogate  =  wandb.config.surrogate\n",
    "#     DFA_on  =  wandb.config.DFA_on\n",
    "#     OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "#     cfg  =  wandb.config.cfg\n",
    "#     e_transport_swap  =  wandb.config.e_transport_swap\n",
    "#     e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "#     drop_rate  =  wandb.config.drop_rate\n",
    "#     exclude_class  =  wandb.config.exclude_class\n",
    "#     merge_polarities  =  wandb.config.merge_polarities\n",
    "#     lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "#     lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "#     e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "#     lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "#     scheduler_name  =  wandb.config.scheduler_name\n",
    "#     denoise_on  =  wandb.config.denoise_on\n",
    "#     I_wanna_sweep_at_this_epoch  =  wandb.config.I_wanna_sweep_at_this_epoch\n",
    "#     dvs_duration_domain  =  wandb.config.dvs_duration_domain\n",
    "#     dvs_relative_timestep  =  wandb.config.dvs_relative_timestep\n",
    "#     extra_train_dataset  =  wandb.config.extra_train_dataset\n",
    "#     if const2 == True:\n",
    "#         const2 = decay\n",
    "#     else:\n",
    "#         const2 = 0.0\n",
    "\n",
    "#     my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = which_data,\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 cfg = cfg,\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "#                 drop_rate = drop_rate,\n",
    "\n",
    "#                 exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = denoise_on,\n",
    "\n",
    "#                 I_wanna_sweep_at_this_epoch = I_wanna_sweep_at_this_epoch,\n",
    "#                 dvs_duration_domain = dvs_duration_domain,\n",
    "#                 dvs_relative_timestep = dvs_relative_timestep, # True # False \n",
    "\n",
    "#                 extra_train_dataset = extra_train_dataset,\n",
    "\n",
    "#                 num_workers = 2,\n",
    "#                 chaching_on = True,\n",
    "#                 pin_memory = True, # True # False\n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d53c56eaeb842088e9a19c11ceb382b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.446 MB of 0.446 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▆▂▅▅▄▅█▆█▄▆▆▇▇██▇▇▇▇██████████▇██████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██</td></tr><tr><td>tr_acc</td><td>▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>299</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98979</td></tr><tr><td>tr_epoch_loss</td><td>1.50874</td></tr><tr><td>val_acc_best</td><td>0.85417</td></tr><tr><td>val_acc_now</td><td>0.85417</td></tr><tr><td>val_loss</td><td>1.7061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-aardvark-6749</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j3tg799j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j3tg799j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_193044-j3tg799j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
