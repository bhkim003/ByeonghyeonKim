{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12640/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "            # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "            return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                        \n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "            if extra_train_dataset == -1:\n",
    "                # print(inputs.shape)\n",
    "                assert BATCH == 1\n",
    "                now_T = inputs.shape[1]\n",
    "                now_time_steps = temporal_filter*TIME\n",
    "                # start_idx = random.randint(0, now_T - now_time_steps)\n",
    "                start_idx = random.choice(range(0, now_T - now_time_steps + 1, now_time_steps))\n",
    "                # start_idx = random.choice([i for i in range(0, now_T - now_time_steps + 1, now_time_steps)])\n",
    "                inputs = inputs[:, start_idx : start_idx + now_time_steps]\n",
    "                if dvs_clipping != 0:\n",
    "                    inputs[inputs<dvs_clipping] = 0.0\n",
    "                    inputs[inputs>=dvs_clipping] = 1.0\n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # if i % 1000 == 999:\n",
    "            #     # SYNAPSE_FCÏóê ÏûàÎäî sparsity_print_and_reset() Ïã§Ìñâ\n",
    "            #     for name, module in net.module.named_modules():\n",
    "            #         if isinstance(module, SYNAPSE_FC):\n",
    "            #             module.sparsity_print_and_reset()\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = (outputs_one_time.detach()).argmax(dim=1)\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if extra_train_dataset == -1:\n",
    "                            assert BATCH == 1\n",
    "                            now_T = inputs_val.shape[1]\n",
    "                            now_time_steps = temporal_filter*TIME\n",
    "                            start_idx = 0\n",
    "                            inputs_val = inputs_val[:, start_idx : start_idx + now_time_steps]\n",
    "\n",
    "                            if dvs_clipping != 0:\n",
    "                                inputs_val[inputs_val<dvs_clipping] = 0.0\n",
    "                                inputs_val[inputs_val>=dvs_clipping] = 1.0\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.6\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251118_194725-jytwhfhq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jytwhfhq' target=\"_blank\">magic-moon-18906</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jytwhfhq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jytwhfhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20251118_194722_958', 'my_seed': 1, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 999], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  1.915713/  2.099847, val:  28.33%, val_best:  28.33%, tr:  89.38%, tr_best:  89.38%, epoch time: 73.01 seconds, 1.22 minutes\n",
      "layer   1  Sparsity: 91.0905%\n",
      "layer   2  Sparsity: 78.1342%\n",
      "layer   3  Sparsity: 72.4671%\n",
      "total_backward_count 9790 real_backward_count 2993  30.572%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  1.881949/  2.060053, val:  40.83%, val_best:  40.83%, tr:  98.77%, tr_best:  98.77%, epoch time: 71.65 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1014%\n",
      "layer   2  Sparsity: 76.8271%\n",
      "layer   3  Sparsity: 70.1641%\n",
      "total_backward_count 19580 real_backward_count 4866  24.852%\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  1.896136/  2.043099, val:  48.75%, val_best:  48.75%, tr:  99.28%, tr_best:  99.28%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0984%\n",
      "layer   2  Sparsity: 76.9218%\n",
      "layer   3  Sparsity: 70.1257%\n",
      "total_backward_count 29370 real_backward_count 6511  22.169%\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  1.906469/  2.052562, val:  50.42%, val_best:  50.42%, tr:  99.69%, tr_best:  99.69%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0435%\n",
      "layer   2  Sparsity: 76.4736%\n",
      "layer   3  Sparsity: 70.1432%\n",
      "total_backward_count 39160 real_backward_count 8031  20.508%\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  1.903573/  2.055777, val:  57.08%, val_best:  57.08%, tr:  99.39%, tr_best:  99.69%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0944%\n",
      "layer   2  Sparsity: 77.4913%\n",
      "layer   3  Sparsity: 70.3080%\n",
      "total_backward_count 48950 real_backward_count 9533  19.475%\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  1.902743/  2.025969, val:  49.17%, val_best:  57.08%, tr:  99.39%, tr_best:  99.69%, epoch time: 70.71 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0972%\n",
      "layer   2  Sparsity: 77.0613%\n",
      "layer   3  Sparsity: 69.9358%\n",
      "total_backward_count 58740 real_backward_count 10940  18.624%\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  1.873318/  2.033329, val:  52.50%, val_best:  57.08%, tr:  99.80%, tr_best:  99.80%, epoch time: 70.04 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1070%\n",
      "layer   2  Sparsity: 76.6027%\n",
      "layer   3  Sparsity: 69.4819%\n",
      "total_backward_count 68530 real_backward_count 12304  17.954%\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  1.878045/  1.999567, val:  58.33%, val_best:  58.33%, tr:  99.49%, tr_best:  99.80%, epoch time: 69.87 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0768%\n",
      "layer   2  Sparsity: 76.0728%\n",
      "layer   3  Sparsity: 69.4797%\n",
      "total_backward_count 78320 real_backward_count 13662  17.444%\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  1.898329/  2.037509, val:  43.75%, val_best:  58.33%, tr:  99.59%, tr_best:  99.80%, epoch time: 70.18 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 76.0261%\n",
      "layer   3  Sparsity: 70.4597%\n",
      "total_backward_count 88110 real_backward_count 14969  16.989%\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  1.904289/  2.035452, val:  60.83%, val_best:  60.83%, tr:  99.59%, tr_best:  99.80%, epoch time: 70.20 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0770%\n",
      "layer   2  Sparsity: 74.8556%\n",
      "layer   3  Sparsity: 70.6817%\n",
      "total_backward_count 97900 real_backward_count 16257  16.606%\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  1.901780/  2.023862, val:  62.08%, val_best:  62.08%, tr:  99.59%, tr_best:  99.80%, epoch time: 70.44 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1069%\n",
      "layer   2  Sparsity: 75.4635%\n",
      "layer   3  Sparsity: 70.9621%\n",
      "total_backward_count 107690 real_backward_count 17517  16.266%\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  1.885257/  1.993355, val:  55.83%, val_best:  62.08%, tr:  99.69%, tr_best:  99.80%, epoch time: 70.69 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0709%\n",
      "layer   2  Sparsity: 74.6373%\n",
      "layer   3  Sparsity: 70.7550%\n",
      "total_backward_count 117480 real_backward_count 18771  15.978%\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  1.875657/  2.006032, val:  59.17%, val_best:  62.08%, tr:  99.39%, tr_best:  99.80%, epoch time: 70.45 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1177%\n",
      "layer   2  Sparsity: 74.8312%\n",
      "layer   3  Sparsity: 71.6651%\n",
      "total_backward_count 127270 real_backward_count 20024  15.733%\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  1.887070/  2.014276, val:  54.58%, val_best:  62.08%, tr:  99.90%, tr_best:  99.90%, epoch time: 70.37 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0862%\n",
      "layer   2  Sparsity: 75.2502%\n",
      "layer   3  Sparsity: 72.3416%\n",
      "total_backward_count 137060 real_backward_count 21194  15.463%\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  1.884937/  2.022291, val:  47.92%, val_best:  62.08%, tr:  99.69%, tr_best:  99.90%, epoch time: 70.54 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0811%\n",
      "layer   2  Sparsity: 74.6132%\n",
      "layer   3  Sparsity: 71.5930%\n",
      "total_backward_count 146850 real_backward_count 22395  15.250%\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  1.871324/  2.001574, val:  53.33%, val_best:  62.08%, tr:  99.80%, tr_best:  99.90%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0645%\n",
      "layer   2  Sparsity: 74.5763%\n",
      "layer   3  Sparsity: 72.1637%\n",
      "total_backward_count 156640 real_backward_count 23553  15.036%\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  1.873541/  1.993941, val:  69.17%, val_best:  69.17%, tr:  99.90%, tr_best:  99.90%, epoch time: 70.84 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0660%\n",
      "layer   2  Sparsity: 74.4382%\n",
      "layer   3  Sparsity: 72.3442%\n",
      "total_backward_count 166430 real_backward_count 24732  14.860%\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  1.871164/  1.980545, val:  76.67%, val_best:  76.67%, tr:  99.80%, tr_best:  99.90%, epoch time: 71.54 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1012%\n",
      "layer   2  Sparsity: 74.5372%\n",
      "layer   3  Sparsity: 72.9836%\n",
      "total_backward_count 176220 real_backward_count 25922  14.710%\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  1.860827/  1.977795, val:  63.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.36 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0481%\n",
      "layer   2  Sparsity: 73.6657%\n",
      "layer   3  Sparsity: 72.6187%\n",
      "total_backward_count 186010 real_backward_count 27017  14.524%\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  1.862016/  1.982601, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.74 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 73.8381%\n",
      "layer   3  Sparsity: 72.6795%\n",
      "total_backward_count 195800 real_backward_count 28126  14.365%\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  1.857769/  1.979592, val:  69.58%, val_best:  76.67%, tr:  99.80%, tr_best: 100.00%, epoch time: 69.97 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0492%\n",
      "layer   2  Sparsity: 73.6048%\n",
      "layer   3  Sparsity: 72.6984%\n",
      "total_backward_count 205590 real_backward_count 29167  14.187%\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  1.843189/  1.965392, val:  61.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.88 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 73.6623%\n",
      "layer   3  Sparsity: 72.7710%\n",
      "total_backward_count 215380 real_backward_count 30242  14.041%\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  1.841021/  1.976625, val:  64.17%, val_best:  76.67%, tr:  99.69%, tr_best: 100.00%, epoch time: 69.94 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0949%\n",
      "layer   2  Sparsity: 73.1680%\n",
      "layer   3  Sparsity: 72.8021%\n",
      "total_backward_count 225170 real_backward_count 31326  13.912%\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  1.847738/  1.973858, val:  67.08%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.82 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0832%\n",
      "layer   2  Sparsity: 72.8998%\n",
      "layer   3  Sparsity: 73.5350%\n",
      "total_backward_count 234960 real_backward_count 32373  13.778%\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  1.834318/  1.961348, val:  61.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.13 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0753%\n",
      "layer   2  Sparsity: 72.9253%\n",
      "layer   3  Sparsity: 72.2651%\n",
      "total_backward_count 244750 real_backward_count 33400  13.647%\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  1.826035/  1.946978, val:  63.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.64 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.1185%\n",
      "layer   2  Sparsity: 73.0813%\n",
      "layer   3  Sparsity: 72.6872%\n",
      "total_backward_count 254540 real_backward_count 34418  13.522%\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  1.830678/  1.939706, val:  70.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.96 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0432%\n",
      "layer   2  Sparsity: 72.6645%\n",
      "layer   3  Sparsity: 72.5523%\n",
      "total_backward_count 264330 real_backward_count 35364  13.379%\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  1.821058/  1.960249, val:  62.08%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.97 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0946%\n",
      "layer   2  Sparsity: 72.6107%\n",
      "layer   3  Sparsity: 72.3658%\n",
      "total_backward_count 274120 real_backward_count 36288  13.238%\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  1.823587/  1.923124, val:  72.50%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.32 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0771%\n",
      "layer   2  Sparsity: 72.3199%\n",
      "layer   3  Sparsity: 72.3041%\n",
      "total_backward_count 283910 real_backward_count 37194  13.101%\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  1.813154/  1.918976, val:  75.00%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.16 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0541%\n",
      "layer   2  Sparsity: 72.2927%\n",
      "layer   3  Sparsity: 72.2812%\n",
      "total_backward_count 293700 real_backward_count 38111  12.976%\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  1.820273/  1.935835, val:  58.75%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.28 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0603%\n",
      "layer   2  Sparsity: 72.1065%\n",
      "layer   3  Sparsity: 72.4972%\n",
      "total_backward_count 303490 real_backward_count 39026  12.859%\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  1.802469/  1.923905, val:  60.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.03 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0796%\n",
      "layer   2  Sparsity: 71.9052%\n",
      "layer   3  Sparsity: 72.3797%\n",
      "total_backward_count 313280 real_backward_count 39965  12.757%\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  1.792946/  1.905327, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.56 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.1099%\n",
      "layer   2  Sparsity: 71.9738%\n",
      "layer   3  Sparsity: 72.2489%\n",
      "total_backward_count 323070 real_backward_count 40837  12.640%\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  1.780109/  1.920747, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.14 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0769%\n",
      "layer   2  Sparsity: 71.8312%\n",
      "layer   3  Sparsity: 71.3909%\n",
      "total_backward_count 332860 real_backward_count 41730  12.537%\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  1.790163/  1.914736, val:  67.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.14 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0707%\n",
      "layer   2  Sparsity: 71.6790%\n",
      "layer   3  Sparsity: 71.5469%\n",
      "total_backward_count 342650 real_backward_count 42588  12.429%\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  1.786026/  1.909211, val:  60.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.80 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 71.7561%\n",
      "layer   3  Sparsity: 71.7067%\n",
      "total_backward_count 352440 real_backward_count 43426  12.322%\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  1.784820/  1.890475, val:  82.08%, val_best:  82.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.91 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0176%\n",
      "layer   2  Sparsity: 71.5014%\n",
      "layer   3  Sparsity: 72.1101%\n",
      "total_backward_count 362230 real_backward_count 44283  12.225%\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  1.767727/  1.881896, val:  76.67%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.91 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 71.5019%\n",
      "layer   3  Sparsity: 71.7610%\n",
      "total_backward_count 372020 real_backward_count 45091  12.121%\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  1.756988/  1.867685, val:  70.00%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.42 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0875%\n",
      "layer   2  Sparsity: 71.2962%\n",
      "layer   3  Sparsity: 71.6418%\n",
      "total_backward_count 381810 real_backward_count 45934  12.031%\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  1.756785/  1.872816, val:  80.83%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.73 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 71.1939%\n",
      "layer   3  Sparsity: 71.5415%\n",
      "total_backward_count 391600 real_backward_count 46718  11.930%\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  1.751600/  1.863569, val:  77.92%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.31 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0946%\n",
      "layer   2  Sparsity: 70.8691%\n",
      "layer   3  Sparsity: 71.6285%\n",
      "total_backward_count 401390 real_backward_count 47473  11.827%\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  1.735924/  1.864747, val:  79.58%, val_best:  82.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.51 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0892%\n",
      "layer   2  Sparsity: 71.3012%\n",
      "layer   3  Sparsity: 71.2293%\n",
      "total_backward_count 411180 real_backward_count 48272  11.740%\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  1.747048/  1.858715, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.86 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0624%\n",
      "layer   2  Sparsity: 71.3543%\n",
      "layer   3  Sparsity: 70.8302%\n",
      "total_backward_count 420970 real_backward_count 49032  11.647%\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  1.739219/  1.850049, val:  81.25%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.60 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0512%\n",
      "layer   2  Sparsity: 71.1562%\n",
      "layer   3  Sparsity: 70.8600%\n",
      "total_backward_count 430760 real_backward_count 49727  11.544%\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  1.728720/  1.848530, val:  80.83%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.38 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 71.3424%\n",
      "layer   3  Sparsity: 70.3579%\n",
      "total_backward_count 440550 real_backward_count 50446  11.451%\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  1.730451/  1.842287, val:  81.25%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.32 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0494%\n",
      "layer   2  Sparsity: 70.9940%\n",
      "layer   3  Sparsity: 70.4136%\n",
      "total_backward_count 450340 real_backward_count 51174  11.363%\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  1.735310/  1.857809, val:  74.17%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.82 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0672%\n",
      "layer   2  Sparsity: 70.5405%\n",
      "layer   3  Sparsity: 70.4802%\n",
      "total_backward_count 460130 real_backward_count 51836  11.266%\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  1.724659/  1.849020, val:  67.92%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.33 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0531%\n",
      "layer   2  Sparsity: 70.6050%\n",
      "layer   3  Sparsity: 70.2898%\n",
      "total_backward_count 469920 real_backward_count 52588  11.191%\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  1.724599/  1.852505, val:  80.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.12 seconds, 1.15 minutes\n",
      "layer   1  Sparsity: 91.0487%\n",
      "layer   2  Sparsity: 70.5100%\n",
      "layer   3  Sparsity: 70.7406%\n",
      "total_backward_count 479710 real_backward_count 53258  11.102%\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  1.709735/  1.833902, val:  77.08%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.43 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 71.2945%\n",
      "layer   3  Sparsity: 70.8925%\n",
      "total_backward_count 489500 real_backward_count 53877  11.007%\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  1.710976/  1.837551, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.07 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1042%\n",
      "layer   2  Sparsity: 70.9989%\n",
      "layer   3  Sparsity: 70.8139%\n",
      "total_backward_count 499290 real_backward_count 54551  10.926%\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  1.708866/  1.839505, val:  64.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.71 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0874%\n",
      "layer   2  Sparsity: 70.4425%\n",
      "layer   3  Sparsity: 70.6436%\n",
      "total_backward_count 509080 real_backward_count 55253  10.854%\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  1.693227/  1.807097, val:  87.08%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.66 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1006%\n",
      "layer   2  Sparsity: 70.6549%\n",
      "layer   3  Sparsity: 70.8000%\n",
      "total_backward_count 518870 real_backward_count 55895  10.772%\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  1.687317/  1.814474, val:  80.42%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.75 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 70.6200%\n",
      "layer   3  Sparsity: 70.8057%\n",
      "total_backward_count 528660 real_backward_count 56548  10.696%\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  1.692127/  1.807617, val:  76.25%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.82 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.1036%\n",
      "layer   2  Sparsity: 70.5923%\n",
      "layer   3  Sparsity: 70.6166%\n",
      "total_backward_count 538450 real_backward_count 57169  10.617%\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  1.686900/  1.815318, val:  73.33%, val_best:  87.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 69.93 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0806%\n",
      "layer   2  Sparsity: 70.6503%\n",
      "layer   3  Sparsity: 70.5369%\n",
      "total_backward_count 548240 real_backward_count 57773  10.538%\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  1.691279/  1.816111, val:  82.92%, val_best:  87.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.13 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0646%\n",
      "layer   2  Sparsity: 70.3826%\n",
      "layer   3  Sparsity: 70.3361%\n",
      "total_backward_count 558030 real_backward_count 58399  10.465%\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  1.684420/  1.809289, val:  72.50%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.33 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0528%\n",
      "layer   2  Sparsity: 70.3475%\n",
      "layer   3  Sparsity: 70.0062%\n",
      "total_backward_count 567820 real_backward_count 59009  10.392%\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  1.672223/  1.816415, val:  75.83%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.87 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0516%\n",
      "layer   2  Sparsity: 70.4984%\n",
      "layer   3  Sparsity: 69.9470%\n",
      "total_backward_count 577610 real_backward_count 59589  10.316%\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  1.673819/  1.805596, val:  75.00%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.19 seconds, 1.15 minutes\n",
      "layer   1  Sparsity: 91.0993%\n",
      "layer   2  Sparsity: 70.5709%\n",
      "layer   3  Sparsity: 69.5226%\n",
      "total_backward_count 587400 real_backward_count 60206  10.250%\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  1.670981/  1.790894, val:  86.25%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.08 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0897%\n",
      "layer   2  Sparsity: 70.4578%\n",
      "layer   3  Sparsity: 69.7639%\n",
      "total_backward_count 597190 real_backward_count 60762  10.175%\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  1.671829/  1.796955, val:  77.50%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.13 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 70.1117%\n",
      "layer   3  Sparsity: 69.9412%\n",
      "total_backward_count 606980 real_backward_count 61275  10.095%\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  1.668847/  1.793814, val:  82.50%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.28 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1061%\n",
      "layer   2  Sparsity: 70.0404%\n",
      "layer   3  Sparsity: 70.1913%\n",
      "total_backward_count 616770 real_backward_count 61797  10.019%\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  1.663264/  1.802110, val:  82.50%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.27 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0679%\n",
      "layer   2  Sparsity: 70.1274%\n",
      "layer   3  Sparsity: 70.4167%\n",
      "total_backward_count 626560 real_backward_count 62374   9.955%\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  1.655515/  1.795734, val:  80.00%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.94 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1119%\n",
      "layer   2  Sparsity: 70.1359%\n",
      "layer   3  Sparsity: 70.0131%\n",
      "total_backward_count 636350 real_backward_count 62923   9.888%\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  1.655289/  1.795150, val:  82.92%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.75 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0954%\n",
      "layer   2  Sparsity: 70.3653%\n",
      "layer   3  Sparsity: 69.7148%\n",
      "total_backward_count 646140 real_backward_count 63508   9.829%\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  1.654721/  1.774335, val:  84.58%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.35 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0470%\n",
      "layer   2  Sparsity: 70.3654%\n",
      "layer   3  Sparsity: 69.8825%\n",
      "total_backward_count 655930 real_backward_count 64054   9.765%\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  1.656634/  1.780455, val:  85.00%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.73 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 70.0023%\n",
      "layer   3  Sparsity: 70.0686%\n",
      "total_backward_count 665720 real_backward_count 64625   9.708%\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  1.649833/  1.769923, val:  85.42%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.22 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1006%\n",
      "layer   2  Sparsity: 70.2488%\n",
      "layer   3  Sparsity: 70.2945%\n",
      "total_backward_count 675510 real_backward_count 65201   9.652%\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  1.652518/  1.784880, val:  81.25%, val_best:  87.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.43 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1107%\n",
      "layer   2  Sparsity: 70.1478%\n",
      "layer   3  Sparsity: 69.9635%\n",
      "total_backward_count 685300 real_backward_count 65774   9.598%\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  1.654643/  1.779434, val:  80.83%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.72 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0825%\n",
      "layer   2  Sparsity: 69.9252%\n",
      "layer   3  Sparsity: 69.6068%\n",
      "total_backward_count 695090 real_backward_count 66332   9.543%\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  1.651501/  1.777388, val:  85.42%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.75 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0555%\n",
      "layer   2  Sparsity: 69.9267%\n",
      "layer   3  Sparsity: 69.6411%\n",
      "total_backward_count 704880 real_backward_count 66832   9.481%\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  1.644754/  1.772584, val:  87.92%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.70 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0626%\n",
      "layer   2  Sparsity: 69.8483%\n",
      "layer   3  Sparsity: 70.1151%\n",
      "total_backward_count 714670 real_backward_count 67359   9.425%\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  1.641884/  1.765592, val:  84.58%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.89 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0420%\n",
      "layer   2  Sparsity: 69.7358%\n",
      "layer   3  Sparsity: 70.1233%\n",
      "total_backward_count 724460 real_backward_count 67874   9.369%\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  1.630062/  1.754350, val:  77.92%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.30 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0292%\n",
      "layer   2  Sparsity: 70.1676%\n",
      "layer   3  Sparsity: 70.4435%\n",
      "total_backward_count 734250 real_backward_count 68377   9.312%\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  1.633736/  1.770446, val:  80.00%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.51 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0351%\n",
      "layer   2  Sparsity: 69.9226%\n",
      "layer   3  Sparsity: 70.3366%\n",
      "total_backward_count 744040 real_backward_count 68855   9.254%\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  1.625653/  1.748376, val:  89.17%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.78 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0514%\n",
      "layer   2  Sparsity: 70.1289%\n",
      "layer   3  Sparsity: 70.2402%\n",
      "total_backward_count 753830 real_backward_count 69380   9.204%\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  1.610705/  1.738494, val:  88.75%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.27 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0591%\n",
      "layer   2  Sparsity: 70.2724%\n",
      "layer   3  Sparsity: 70.1308%\n",
      "total_backward_count 763620 real_backward_count 69841   9.146%\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  1.601220/  1.750498, val:  69.17%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.58 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0744%\n",
      "layer   2  Sparsity: 69.8424%\n",
      "layer   3  Sparsity: 70.0753%\n",
      "total_backward_count 773410 real_backward_count 70291   9.088%\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  1.589658/  1.735032, val:  81.25%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.25 seconds, 1.15 minutes\n",
      "layer   1  Sparsity: 91.0608%\n",
      "layer   2  Sparsity: 69.8860%\n",
      "layer   3  Sparsity: 70.6084%\n",
      "total_backward_count 783200 real_backward_count 70770   9.036%\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  1.606423/  1.729752, val:  86.25%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.05 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0677%\n",
      "layer   2  Sparsity: 69.4273%\n",
      "layer   3  Sparsity: 70.2781%\n",
      "total_backward_count 792990 real_backward_count 71240   8.984%\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  1.586264/  1.713478, val:  88.75%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.54 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0737%\n",
      "layer   2  Sparsity: 69.4234%\n",
      "layer   3  Sparsity: 70.1251%\n",
      "total_backward_count 802780 real_backward_count 71732   8.935%\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  1.583830/  1.747548, val:  82.08%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.77 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0651%\n",
      "layer   2  Sparsity: 69.7612%\n",
      "layer   3  Sparsity: 70.0664%\n",
      "total_backward_count 812570 real_backward_count 72180   8.883%\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  1.596126/  1.733857, val:  87.08%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.27 seconds, 1.15 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 69.8153%\n",
      "layer   3  Sparsity: 70.0070%\n",
      "total_backward_count 822360 real_backward_count 72627   8.832%\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  1.594663/  1.717844, val:  83.75%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.98 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0383%\n",
      "layer   2  Sparsity: 69.6187%\n",
      "layer   3  Sparsity: 69.5257%\n",
      "total_backward_count 832150 real_backward_count 73088   8.783%\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  1.602060/  1.733336, val:  84.58%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.14 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0620%\n",
      "layer   2  Sparsity: 69.4213%\n",
      "layer   3  Sparsity: 69.6749%\n",
      "total_backward_count 841940 real_backward_count 73532   8.734%\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  1.596404/  1.739183, val:  86.25%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.38 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0462%\n",
      "layer   2  Sparsity: 69.6289%\n",
      "layer   3  Sparsity: 69.9159%\n",
      "total_backward_count 851730 real_backward_count 73945   8.682%\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  1.604018/  1.737286, val:  84.17%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.93 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0462%\n",
      "layer   2  Sparsity: 69.6651%\n",
      "layer   3  Sparsity: 70.3778%\n",
      "total_backward_count 861520 real_backward_count 74334   8.628%\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  1.608142/  1.720567, val:  90.00%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.26 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0665%\n",
      "layer   2  Sparsity: 69.9541%\n",
      "layer   3  Sparsity: 70.5300%\n",
      "total_backward_count 871310 real_backward_count 74760   8.580%\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  1.596908/  1.731930, val:  90.00%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.88 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0805%\n",
      "layer   2  Sparsity: 70.0410%\n",
      "layer   3  Sparsity: 70.5078%\n",
      "total_backward_count 881100 real_backward_count 75132   8.527%\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  1.585225/  1.718865, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.44 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1133%\n",
      "layer   2  Sparsity: 70.0891%\n",
      "layer   3  Sparsity: 70.4524%\n",
      "total_backward_count 890890 real_backward_count 75561   8.482%\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  1.586950/  1.728198, val:  85.00%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.23 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1018%\n",
      "layer   2  Sparsity: 69.8279%\n",
      "layer   3  Sparsity: 70.0644%\n",
      "total_backward_count 900680 real_backward_count 75963   8.434%\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  1.591306/  1.725589, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.71 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0929%\n",
      "layer   2  Sparsity: 69.5658%\n",
      "layer   3  Sparsity: 70.0823%\n",
      "total_backward_count 910470 real_backward_count 76365   8.387%\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  1.587975/  1.720900, val:  89.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.89 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0945%\n",
      "layer   2  Sparsity: 69.7830%\n",
      "layer   3  Sparsity: 70.3089%\n",
      "total_backward_count 920260 real_backward_count 76754   8.340%\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  1.586488/  1.712766, val:  89.58%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.71 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0901%\n",
      "layer   2  Sparsity: 70.0070%\n",
      "layer   3  Sparsity: 70.8308%\n",
      "total_backward_count 930050 real_backward_count 77106   8.291%\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  1.582623/  1.713661, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.61 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0777%\n",
      "layer   2  Sparsity: 69.5307%\n",
      "layer   3  Sparsity: 71.0139%\n",
      "total_backward_count 939840 real_backward_count 77515   8.248%\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  1.574672/  1.717393, val:  83.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.78 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0731%\n",
      "layer   2  Sparsity: 69.5994%\n",
      "layer   3  Sparsity: 70.9694%\n",
      "total_backward_count 949630 real_backward_count 77917   8.205%\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  1.582314/  1.712250, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.81 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0646%\n",
      "layer   2  Sparsity: 69.8489%\n",
      "layer   3  Sparsity: 70.7486%\n",
      "total_backward_count 959420 real_backward_count 78357   8.167%\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  1.567052/  1.703076, val:  86.67%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.86 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0835%\n",
      "layer   2  Sparsity: 69.9618%\n",
      "layer   3  Sparsity: 70.7418%\n",
      "total_backward_count 969210 real_backward_count 78732   8.123%\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  1.566335/  1.678026, val:  88.75%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.81 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0565%\n",
      "layer   2  Sparsity: 69.7596%\n",
      "layer   3  Sparsity: 70.2986%\n",
      "total_backward_count 979000 real_backward_count 79125   8.082%\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  1.555965/  1.683872, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.37 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0739%\n",
      "layer   2  Sparsity: 69.8469%\n",
      "layer   3  Sparsity: 70.7237%\n",
      "total_backward_count 988790 real_backward_count 79515   8.042%\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  1.555044/  1.690064, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.08 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1124%\n",
      "layer   2  Sparsity: 69.7754%\n",
      "layer   3  Sparsity: 70.6024%\n",
      "total_backward_count 998580 real_backward_count 79901   8.001%\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  1.551057/  1.687207, val:  89.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.31 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1052%\n",
      "layer   2  Sparsity: 69.8500%\n",
      "layer   3  Sparsity: 70.3605%\n",
      "total_backward_count 1008370 real_backward_count 80250   7.958%\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  1.549093/  1.680648, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.65 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0784%\n",
      "layer   2  Sparsity: 69.7774%\n",
      "layer   3  Sparsity: 70.3822%\n",
      "total_backward_count 1018160 real_backward_count 80590   7.915%\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  1.547952/  1.685069, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.53 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0926%\n",
      "layer   2  Sparsity: 69.7559%\n",
      "layer   3  Sparsity: 70.4053%\n",
      "total_backward_count 1027950 real_backward_count 80987   7.878%\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  1.547234/  1.669274, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.09 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0732%\n",
      "layer   2  Sparsity: 69.5364%\n",
      "layer   3  Sparsity: 70.6717%\n",
      "total_backward_count 1037740 real_backward_count 81373   7.841%\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  1.538225/  1.677884, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.69 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0808%\n",
      "layer   2  Sparsity: 69.4638%\n",
      "layer   3  Sparsity: 70.4667%\n",
      "total_backward_count 1047530 real_backward_count 81725   7.802%\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  1.531974/  1.677342, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.03 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0785%\n",
      "layer   2  Sparsity: 69.6781%\n",
      "layer   3  Sparsity: 70.1991%\n",
      "total_backward_count 1057320 real_backward_count 82050   7.760%\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  1.532573/  1.668988, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.70 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0201%\n",
      "layer   2  Sparsity: 69.8582%\n",
      "layer   3  Sparsity: 70.5754%\n",
      "total_backward_count 1067110 real_backward_count 82384   7.720%\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  1.527925/  1.669844, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.38 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.1034%\n",
      "layer   2  Sparsity: 69.5975%\n",
      "layer   3  Sparsity: 70.4598%\n",
      "total_backward_count 1076900 real_backward_count 82741   7.683%\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  1.521438/  1.666470, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.49 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0699%\n",
      "layer   2  Sparsity: 69.7625%\n",
      "layer   3  Sparsity: 70.2992%\n",
      "total_backward_count 1086690 real_backward_count 83070   7.644%\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  1.520495/  1.653677, val:  84.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.88 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 69.5798%\n",
      "layer   3  Sparsity: 69.7960%\n",
      "total_backward_count 1096480 real_backward_count 83399   7.606%\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  1.504924/  1.648291, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.25 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0401%\n",
      "layer   2  Sparsity: 69.9212%\n",
      "layer   3  Sparsity: 70.0219%\n",
      "total_backward_count 1106270 real_backward_count 83731   7.569%\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  1.509037/  1.647412, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.84 seconds, 1.16 minutes\n",
      "layer   1  Sparsity: 91.0951%\n",
      "layer   2  Sparsity: 69.9216%\n",
      "layer   3  Sparsity: 70.2570%\n",
      "total_backward_count 1116060 real_backward_count 84045   7.531%\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  1.512035/  1.644648, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.20 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0405%\n",
      "layer   2  Sparsity: 69.6780%\n",
      "layer   3  Sparsity: 70.6881%\n",
      "total_backward_count 1125850 real_backward_count 84353   7.492%\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  1.516138/  1.663975, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 67.25 seconds, 1.12 minutes\n",
      "layer   1  Sparsity: 91.0638%\n",
      "layer   2  Sparsity: 69.6895%\n",
      "layer   3  Sparsity: 70.3459%\n",
      "total_backward_count 1135640 real_backward_count 84659   7.455%\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  1.518809/  1.674206, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.45 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1017%\n",
      "layer   2  Sparsity: 69.7096%\n",
      "layer   3  Sparsity: 70.2596%\n",
      "total_backward_count 1145430 real_backward_count 84953   7.417%\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  1.510809/  1.659737, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.05 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0708%\n",
      "layer   2  Sparsity: 69.7255%\n",
      "layer   3  Sparsity: 70.7327%\n",
      "total_backward_count 1155220 real_backward_count 85257   7.380%\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  1.507135/  1.649748, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.62 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0720%\n",
      "layer   2  Sparsity: 69.7993%\n",
      "layer   3  Sparsity: 70.5551%\n",
      "total_backward_count 1165010 real_backward_count 85565   7.345%\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  1.505668/  1.650391, val:  91.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.05 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0565%\n",
      "layer   2  Sparsity: 69.5998%\n",
      "layer   3  Sparsity: 70.3171%\n",
      "total_backward_count 1174800 real_backward_count 85884   7.311%\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  1.507370/  1.642521, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.53 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0705%\n",
      "layer   2  Sparsity: 69.7556%\n",
      "layer   3  Sparsity: 70.5663%\n",
      "total_backward_count 1184590 real_backward_count 86211   7.278%\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  1.504081/  1.645052, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.60 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0975%\n",
      "layer   2  Sparsity: 70.0223%\n",
      "layer   3  Sparsity: 70.7326%\n",
      "total_backward_count 1194380 real_backward_count 86517   7.244%\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  1.500392/  1.648171, val:  85.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.06 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0453%\n",
      "layer   2  Sparsity: 69.7863%\n",
      "layer   3  Sparsity: 70.2012%\n",
      "total_backward_count 1204170 real_backward_count 86827   7.211%\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  1.494487/  1.642077, val:  91.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.84 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0950%\n",
      "layer   2  Sparsity: 69.7148%\n",
      "layer   3  Sparsity: 70.3372%\n",
      "total_backward_count 1213960 real_backward_count 87144   7.178%\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  1.490405/  1.649660, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.08 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0234%\n",
      "layer   2  Sparsity: 69.7230%\n",
      "layer   3  Sparsity: 70.3326%\n",
      "total_backward_count 1223750 real_backward_count 87413   7.143%\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  1.491750/  1.644245, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.24 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0600%\n",
      "layer   2  Sparsity: 69.7026%\n",
      "layer   3  Sparsity: 70.4497%\n",
      "total_backward_count 1233540 real_backward_count 87718   7.111%\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  1.496949/  1.650247, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.17 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0628%\n",
      "layer   2  Sparsity: 69.4600%\n",
      "layer   3  Sparsity: 70.2056%\n",
      "total_backward_count 1243330 real_backward_count 88021   7.079%\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  1.495427/  1.642080, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.64 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0769%\n",
      "layer   2  Sparsity: 69.3575%\n",
      "layer   3  Sparsity: 70.0126%\n",
      "total_backward_count 1253120 real_backward_count 88311   7.047%\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  1.492193/  1.637607, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.28 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0773%\n",
      "layer   2  Sparsity: 69.2666%\n",
      "layer   3  Sparsity: 69.5549%\n",
      "total_backward_count 1262910 real_backward_count 88594   7.015%\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  1.496598/  1.641185, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.21 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0333%\n",
      "layer   2  Sparsity: 69.3818%\n",
      "layer   3  Sparsity: 69.1601%\n",
      "total_backward_count 1272700 real_backward_count 88874   6.983%\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  1.487199/  1.643031, val:  90.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.54 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0551%\n",
      "layer   2  Sparsity: 69.6002%\n",
      "layer   3  Sparsity: 69.6658%\n",
      "total_backward_count 1282490 real_backward_count 89145   6.951%\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  1.495462/  1.631078, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.84 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0884%\n",
      "layer   2  Sparsity: 69.6770%\n",
      "layer   3  Sparsity: 69.7700%\n",
      "total_backward_count 1292280 real_backward_count 89456   6.922%\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  1.497208/  1.641036, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.07 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0829%\n",
      "layer   2  Sparsity: 69.7904%\n",
      "layer   3  Sparsity: 69.4224%\n",
      "total_backward_count 1302070 real_backward_count 89766   6.894%\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  1.498576/  1.644117, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.91 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1014%\n",
      "layer   2  Sparsity: 70.0201%\n",
      "layer   3  Sparsity: 69.6489%\n",
      "total_backward_count 1311860 real_backward_count 90075   6.866%\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  1.492038/  1.644319, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.92 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1091%\n",
      "layer   2  Sparsity: 69.8677%\n",
      "layer   3  Sparsity: 69.9316%\n",
      "total_backward_count 1321650 real_backward_count 90363   6.837%\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  1.488315/  1.634056, val:  88.33%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 60.85 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0722%\n",
      "layer   2  Sparsity: 69.9304%\n",
      "layer   3  Sparsity: 69.9705%\n",
      "total_backward_count 1331440 real_backward_count 90633   6.807%\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  1.489081/  1.628467, val:  86.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.08 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0703%\n",
      "layer   2  Sparsity: 69.8596%\n",
      "layer   3  Sparsity: 69.6651%\n",
      "total_backward_count 1341230 real_backward_count 90931   6.780%\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  1.490258/  1.629704, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.34 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0550%\n",
      "layer   2  Sparsity: 69.8308%\n",
      "layer   3  Sparsity: 69.4086%\n",
      "total_backward_count 1351020 real_backward_count 91198   6.750%\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  1.489678/  1.646896, val:  91.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.23 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0589%\n",
      "layer   2  Sparsity: 69.8058%\n",
      "layer   3  Sparsity: 69.9868%\n",
      "total_backward_count 1360810 real_backward_count 91436   6.719%\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  1.485778/  1.644064, val:  90.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.25 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0742%\n",
      "layer   2  Sparsity: 69.6397%\n",
      "layer   3  Sparsity: 70.0691%\n",
      "total_backward_count 1370600 real_backward_count 91703   6.691%\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  1.486015/  1.647694, val:  83.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.47 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0350%\n",
      "layer   2  Sparsity: 69.5616%\n",
      "layer   3  Sparsity: 70.0160%\n",
      "total_backward_count 1380390 real_backward_count 91968   6.662%\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  1.487373/  1.635426, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.36 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0760%\n",
      "layer   2  Sparsity: 69.5538%\n",
      "layer   3  Sparsity: 70.0345%\n",
      "total_backward_count 1390180 real_backward_count 92250   6.636%\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  1.484014/  1.630317, val:  90.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.58 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0500%\n",
      "layer   2  Sparsity: 69.5941%\n",
      "layer   3  Sparsity: 69.9922%\n",
      "total_backward_count 1399970 real_backward_count 92465   6.605%\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  1.478382/  1.639043, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.69 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0718%\n",
      "layer   2  Sparsity: 69.4319%\n",
      "layer   3  Sparsity: 69.9999%\n",
      "total_backward_count 1409760 real_backward_count 92709   6.576%\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  1.480338/  1.634135, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.47 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0428%\n",
      "layer   2  Sparsity: 69.3184%\n",
      "layer   3  Sparsity: 69.9818%\n",
      "total_backward_count 1419550 real_backward_count 92964   6.549%\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  1.470289/  1.629229, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.43 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0933%\n",
      "layer   2  Sparsity: 69.3362%\n",
      "layer   3  Sparsity: 69.7698%\n",
      "total_backward_count 1429340 real_backward_count 93252   6.524%\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  1.478263/  1.630143, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.21 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1055%\n",
      "layer   2  Sparsity: 69.5871%\n",
      "layer   3  Sparsity: 70.0721%\n",
      "total_backward_count 1439130 real_backward_count 93516   6.498%\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  1.474108/  1.635710, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.91 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0868%\n",
      "layer   2  Sparsity: 69.5900%\n",
      "layer   3  Sparsity: 70.9603%\n",
      "total_backward_count 1448920 real_backward_count 93748   6.470%\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  1.476969/  1.644158, val:  85.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.09 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0894%\n",
      "layer   2  Sparsity: 69.4272%\n",
      "layer   3  Sparsity: 70.7881%\n",
      "total_backward_count 1458710 real_backward_count 93961   6.441%\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  1.475457/  1.629218, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.46 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1302%\n",
      "layer   2  Sparsity: 69.3567%\n",
      "layer   3  Sparsity: 70.1605%\n",
      "total_backward_count 1468500 real_backward_count 94183   6.414%\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  1.474829/  1.632923, val:  86.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.51 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0570%\n",
      "layer   2  Sparsity: 69.5968%\n",
      "layer   3  Sparsity: 70.2350%\n",
      "total_backward_count 1478290 real_backward_count 94420   6.387%\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  1.479477/  1.639940, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.45 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0716%\n",
      "layer   2  Sparsity: 69.6416%\n",
      "layer   3  Sparsity: 70.4282%\n",
      "total_backward_count 1488080 real_backward_count 94644   6.360%\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  1.473229/  1.633340, val:  88.75%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 61.35 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1291%\n",
      "layer   2  Sparsity: 69.3853%\n",
      "layer   3  Sparsity: 70.2696%\n",
      "total_backward_count 1497870 real_backward_count 94890   6.335%\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  1.471748/  1.631293, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.67 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0883%\n",
      "layer   2  Sparsity: 69.2722%\n",
      "layer   3  Sparsity: 70.2391%\n",
      "total_backward_count 1507660 real_backward_count 95142   6.311%\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  1.469047/  1.621512, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.48 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0623%\n",
      "layer   2  Sparsity: 69.4751%\n",
      "layer   3  Sparsity: 70.6034%\n",
      "total_backward_count 1517450 real_backward_count 95373   6.285%\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  1.458017/  1.617525, val:  84.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.21 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0920%\n",
      "layer   2  Sparsity: 69.3166%\n",
      "layer   3  Sparsity: 70.7707%\n",
      "total_backward_count 1527240 real_backward_count 95586   6.259%\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  1.457543/  1.606501, val:  90.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.35 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0949%\n",
      "layer   2  Sparsity: 69.2788%\n",
      "layer   3  Sparsity: 70.6228%\n",
      "total_backward_count 1537030 real_backward_count 95808   6.233%\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  1.461452/  1.633734, val:  85.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.94 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0800%\n",
      "layer   2  Sparsity: 69.3409%\n",
      "layer   3  Sparsity: 70.7756%\n",
      "total_backward_count 1546820 real_backward_count 96035   6.209%\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  1.458306/  1.620481, val:  83.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.20 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0860%\n",
      "layer   2  Sparsity: 69.4221%\n",
      "layer   3  Sparsity: 70.6844%\n",
      "total_backward_count 1556610 real_backward_count 96251   6.183%\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  1.460257/  1.626801, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.62 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0869%\n",
      "layer   2  Sparsity: 69.4596%\n",
      "layer   3  Sparsity: 70.6329%\n",
      "total_backward_count 1566400 real_backward_count 96463   6.158%\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  1.469878/  1.629846, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 60.85 seconds, 1.01 minutes\n",
      "layer   1  Sparsity: 91.0560%\n",
      "layer   2  Sparsity: 69.1299%\n",
      "layer   3  Sparsity: 70.4624%\n",
      "total_backward_count 1576190 real_backward_count 96672   6.133%\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  1.467149/  1.619663, val:  84.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.01 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0705%\n",
      "layer   2  Sparsity: 69.0785%\n",
      "layer   3  Sparsity: 70.3035%\n",
      "total_backward_count 1585980 real_backward_count 96886   6.109%\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  1.460594/  1.608864, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.78 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.1122%\n",
      "layer   2  Sparsity: 69.2270%\n",
      "layer   3  Sparsity: 70.0400%\n",
      "total_backward_count 1595770 real_backward_count 97121   6.086%\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  1.451621/  1.609593, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.97 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0675%\n",
      "layer   2  Sparsity: 69.2696%\n",
      "layer   3  Sparsity: 69.8785%\n",
      "total_backward_count 1605560 real_backward_count 97338   6.063%\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  1.458519/  1.616304, val:  90.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.22 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0616%\n",
      "layer   2  Sparsity: 68.9973%\n",
      "layer   3  Sparsity: 70.1680%\n",
      "total_backward_count 1615350 real_backward_count 97583   6.041%\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  1.457500/  1.611877, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.46 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0861%\n",
      "layer   2  Sparsity: 69.0897%\n",
      "layer   3  Sparsity: 69.9869%\n",
      "total_backward_count 1625140 real_backward_count 97785   6.017%\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  1.454737/  1.612646, val:  85.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.76 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0913%\n",
      "layer   2  Sparsity: 69.0734%\n",
      "layer   3  Sparsity: 69.6503%\n",
      "total_backward_count 1634930 real_backward_count 98031   5.996%\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  1.448834/  1.604867, val:  85.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.81 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0947%\n",
      "layer   2  Sparsity: 69.1479%\n",
      "layer   3  Sparsity: 69.6653%\n",
      "total_backward_count 1644720 real_backward_count 98229   5.972%\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  1.445594/  1.593294, val:  92.50%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.42 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0805%\n",
      "layer   2  Sparsity: 69.1359%\n",
      "layer   3  Sparsity: 69.6800%\n",
      "total_backward_count 1654510 real_backward_count 98431   5.949%\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  1.437149/  1.596365, val:  88.33%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.32 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0816%\n",
      "layer   2  Sparsity: 69.1983%\n",
      "layer   3  Sparsity: 70.1643%\n",
      "total_backward_count 1664300 real_backward_count 98631   5.926%\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  1.437498/  1.594634, val:  87.08%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.91 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.1152%\n",
      "layer   2  Sparsity: 69.3436%\n",
      "layer   3  Sparsity: 70.4598%\n",
      "total_backward_count 1674090 real_backward_count 98822   5.903%\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  1.444372/  1.600563, val:  90.00%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.32 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0521%\n",
      "layer   2  Sparsity: 69.2426%\n",
      "layer   3  Sparsity: 70.0975%\n",
      "total_backward_count 1683880 real_backward_count 99001   5.879%\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  1.445177/  1.607168, val:  87.92%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.05 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0728%\n",
      "layer   2  Sparsity: 69.2427%\n",
      "layer   3  Sparsity: 70.3244%\n",
      "total_backward_count 1693670 real_backward_count 99195   5.857%\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  1.443526/  1.598683, val:  89.17%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.60 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0670%\n",
      "layer   2  Sparsity: 69.1488%\n",
      "layer   3  Sparsity: 70.0238%\n",
      "total_backward_count 1703460 real_backward_count 99356   5.833%\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  1.435429/  1.596248, val:  90.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.41 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0947%\n",
      "layer   2  Sparsity: 69.1509%\n",
      "layer   3  Sparsity: 70.3753%\n",
      "total_backward_count 1713250 real_backward_count 99536   5.810%\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  1.430940/  1.577744, val:  90.00%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.15 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0549%\n",
      "layer   2  Sparsity: 69.3735%\n",
      "layer   3  Sparsity: 70.6120%\n",
      "total_backward_count 1723040 real_backward_count 99720   5.787%\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  1.427292/  1.587906, val:  87.92%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.88 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0767%\n",
      "layer   2  Sparsity: 69.2543%\n",
      "layer   3  Sparsity: 70.3573%\n",
      "total_backward_count 1732830 real_backward_count 99923   5.766%\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  1.419254/  1.568003, val:  89.17%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.99 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0904%\n",
      "layer   2  Sparsity: 69.1826%\n",
      "layer   3  Sparsity: 70.1226%\n",
      "total_backward_count 1742620 real_backward_count 100114   5.745%\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  1.415877/  1.574981, val:  85.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.63 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0921%\n",
      "layer   2  Sparsity: 69.3542%\n",
      "layer   3  Sparsity: 70.7232%\n",
      "total_backward_count 1752410 real_backward_count 100270   5.722%\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  1.411588/  1.588135, val:  83.33%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.85 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0577%\n",
      "layer   2  Sparsity: 69.3194%\n",
      "layer   3  Sparsity: 70.8479%\n",
      "total_backward_count 1762200 real_backward_count 100451   5.700%\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  1.407580/  1.573449, val:  88.33%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.89 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0680%\n",
      "layer   2  Sparsity: 69.1680%\n",
      "layer   3  Sparsity: 70.8199%\n",
      "total_backward_count 1771990 real_backward_count 100629   5.679%\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  1.411047/  1.570873, val:  88.75%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.39 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0854%\n",
      "layer   2  Sparsity: 69.2902%\n",
      "layer   3  Sparsity: 70.8048%\n",
      "total_backward_count 1781780 real_backward_count 100829   5.659%\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  1.411895/  1.570950, val:  88.33%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.14 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0712%\n",
      "layer   2  Sparsity: 69.2989%\n",
      "layer   3  Sparsity: 70.8005%\n",
      "total_backward_count 1791570 real_backward_count 101002   5.638%\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  1.413331/  1.572809, val:  86.67%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.39 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.1156%\n",
      "layer   2  Sparsity: 69.4731%\n",
      "layer   3  Sparsity: 70.1587%\n",
      "total_backward_count 1801360 real_backward_count 101166   5.616%\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  1.410936/  1.575340, val:  86.25%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.92 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0511%\n",
      "layer   2  Sparsity: 69.2446%\n",
      "layer   3  Sparsity: 69.9519%\n",
      "total_backward_count 1811150 real_backward_count 101342   5.595%\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  1.412359/  1.580372, val:  89.17%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.70 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0655%\n",
      "layer   2  Sparsity: 69.2100%\n",
      "layer   3  Sparsity: 69.9525%\n",
      "total_backward_count 1820940 real_backward_count 101535   5.576%\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  1.408416/  1.574213, val:  90.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.99 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0887%\n",
      "layer   2  Sparsity: 69.1349%\n",
      "layer   3  Sparsity: 70.5893%\n",
      "total_backward_count 1830730 real_backward_count 101712   5.556%\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  1.408519/  1.570123, val:  89.17%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.59 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0782%\n",
      "layer   2  Sparsity: 69.1235%\n",
      "layer   3  Sparsity: 70.6398%\n",
      "total_backward_count 1840520 real_backward_count 101880   5.535%\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  1.408080/  1.570681, val:  90.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.30 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0358%\n",
      "layer   2  Sparsity: 68.9230%\n",
      "layer   3  Sparsity: 70.3270%\n",
      "total_backward_count 1850310 real_backward_count 102054   5.516%\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  1.408119/  1.570319, val:  90.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.20 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0684%\n",
      "layer   2  Sparsity: 68.8171%\n",
      "layer   3  Sparsity: 70.5748%\n",
      "total_backward_count 1860100 real_backward_count 102238   5.496%\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  1.392421/  1.554795, val:  92.08%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.15 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0791%\n",
      "layer   2  Sparsity: 68.8715%\n",
      "layer   3  Sparsity: 70.4657%\n",
      "total_backward_count 1869890 real_backward_count 102458   5.479%\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  1.389171/  1.559109, val:  84.58%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.22 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.1019%\n",
      "layer   2  Sparsity: 69.0557%\n",
      "layer   3  Sparsity: 70.2506%\n",
      "total_backward_count 1879680 real_backward_count 102636   5.460%\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  1.385950/  1.547442, val:  90.83%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.29 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0188%\n",
      "layer   2  Sparsity: 69.1787%\n",
      "layer   3  Sparsity: 70.5566%\n",
      "total_backward_count 1889470 real_backward_count 102803   5.441%\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  1.386554/  1.552479, val:  90.00%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.85 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0603%\n",
      "layer   2  Sparsity: 69.1329%\n",
      "layer   3  Sparsity: 70.7420%\n",
      "total_backward_count 1899260 real_backward_count 102955   5.421%\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  1.380921/  1.539304, val:  88.75%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.17 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0922%\n",
      "layer   2  Sparsity: 69.1101%\n",
      "layer   3  Sparsity: 70.5599%\n",
      "total_backward_count 1909050 real_backward_count 103120   5.402%\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  1.384033/  1.550187, val:  90.00%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.57 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0901%\n",
      "layer   2  Sparsity: 69.3978%\n",
      "layer   3  Sparsity: 70.3011%\n",
      "total_backward_count 1918840 real_backward_count 103308   5.384%\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  1.393555/  1.564667, val:  87.08%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.45 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0457%\n",
      "layer   2  Sparsity: 69.2780%\n",
      "layer   3  Sparsity: 70.3686%\n",
      "total_backward_count 1928630 real_backward_count 103490   5.366%\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  1.385710/  1.553903, val:  88.75%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.53 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0957%\n",
      "layer   2  Sparsity: 69.2674%\n",
      "layer   3  Sparsity: 70.5721%\n",
      "total_backward_count 1938420 real_backward_count 103665   5.348%\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  1.382022/  1.536720, val:  90.42%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.29 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0822%\n",
      "layer   2  Sparsity: 69.0688%\n",
      "layer   3  Sparsity: 70.5418%\n",
      "total_backward_count 1948210 real_backward_count 103839   5.330%\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  1.381568/  1.547060, val:  90.42%, val_best:  92.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.45 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0374%\n",
      "layer   2  Sparsity: 68.9863%\n",
      "layer   3  Sparsity: 70.5792%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b537d65018410b9ea24c2b5624a298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>1.38157</td></tr><tr><td>val_acc_best</td><td>0.925</td></tr><tr><td>val_acc_now</td><td>0.90417</td></tr><tr><td>val_loss</td><td>1.54706</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-moon-18906</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jytwhfhq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jytwhfhq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251118_194725-jytwhfhq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1af305332df4f58849431198207b9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112914522851094, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251118_232938-9j4lw8yu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9j4lw8yu' target=\"_blank\">vibrant-frost-18923</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9j4lw8yu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9j4lw8yu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20251118_232938_401', 'my_seed': 2, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 999], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  1.897917/  2.056978, val:  36.25%, val_best:  36.25%, tr:  91.32%, tr_best:  91.32%, epoch time: 62.18 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.1079%\n",
      "layer   2  Sparsity: 75.9340%\n",
      "layer   3  Sparsity: 69.9948%\n",
      "total_backward_count 9790 real_backward_count 2836  28.968%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  1.845688/  2.037082, val:  37.08%, val_best:  37.08%, tr:  98.37%, tr_best:  98.37%, epoch time: 61.95 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0604%\n",
      "layer   2  Sparsity: 75.8137%\n",
      "layer   3  Sparsity: 66.2114%\n",
      "total_backward_count 19580 real_backward_count 4760  24.311%\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  1.845783/  2.027323, val:  38.75%, val_best:  38.75%, tr:  98.77%, tr_best:  98.77%, epoch time: 61.77 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0829%\n",
      "layer   2  Sparsity: 76.2846%\n",
      "layer   3  Sparsity: 65.4668%\n",
      "total_backward_count 29370 real_backward_count 6460  21.995%\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  1.834501/  1.982377, val:  52.08%, val_best:  52.08%, tr:  99.08%, tr_best:  99.08%, epoch time: 61.70 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 75.7735%\n",
      "layer   3  Sparsity: 64.5422%\n",
      "total_backward_count 39160 real_backward_count 8062  20.587%\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  1.835398/  2.005641, val:  38.33%, val_best:  52.08%, tr:  99.49%, tr_best:  99.49%, epoch time: 62.27 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0720%\n",
      "layer   2  Sparsity: 75.2459%\n",
      "layer   3  Sparsity: 64.1127%\n",
      "total_backward_count 48950 real_backward_count 9532  19.473%\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  1.845012/  2.053928, val:  41.67%, val_best:  52.08%, tr:  99.18%, tr_best:  99.49%, epoch time: 62.10 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0613%\n",
      "layer   2  Sparsity: 76.1514%\n",
      "layer   3  Sparsity: 65.5726%\n",
      "total_backward_count 58740 real_backward_count 10998  18.723%\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  1.854147/  1.972007, val:  54.58%, val_best:  54.58%, tr:  99.39%, tr_best:  99.49%, epoch time: 61.91 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.1054%\n",
      "layer   2  Sparsity: 76.1911%\n",
      "layer   3  Sparsity: 66.8116%\n",
      "total_backward_count 68530 real_backward_count 12439  18.151%\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  1.842102/  2.003374, val:  48.33%, val_best:  54.58%, tr:  99.39%, tr_best:  99.49%, epoch time: 62.25 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0909%\n",
      "layer   2  Sparsity: 75.8525%\n",
      "layer   3  Sparsity: 66.3673%\n",
      "total_backward_count 78320 real_backward_count 13806  17.628%\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  1.846606/  1.995970, val:  45.42%, val_best:  54.58%, tr:  99.80%, tr_best:  99.80%, epoch time: 62.29 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 74.4482%\n",
      "layer   3  Sparsity: 65.7255%\n",
      "total_backward_count 88110 real_backward_count 15150  17.194%\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  1.831274/  1.991959, val:  48.75%, val_best:  54.58%, tr:  99.59%, tr_best:  99.80%, epoch time: 62.07 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0691%\n",
      "layer   2  Sparsity: 74.7457%\n",
      "layer   3  Sparsity: 66.1889%\n",
      "total_backward_count 97900 real_backward_count 16450  16.803%\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  1.823577/  1.955636, val:  55.83%, val_best:  55.83%, tr:  99.59%, tr_best:  99.80%, epoch time: 61.86 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0423%\n",
      "layer   2  Sparsity: 74.5948%\n",
      "layer   3  Sparsity: 66.7343%\n",
      "total_backward_count 107690 real_backward_count 17694  16.430%\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  1.833123/  1.971928, val:  52.50%, val_best:  55.83%, tr:  99.59%, tr_best:  99.80%, epoch time: 61.57 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0555%\n",
      "layer   2  Sparsity: 74.2944%\n",
      "layer   3  Sparsity: 67.8535%\n",
      "total_backward_count 117480 real_backward_count 18948  16.129%\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  1.826395/  1.970664, val:  60.42%, val_best:  60.42%, tr:  99.69%, tr_best:  99.80%, epoch time: 61.62 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0718%\n",
      "layer   2  Sparsity: 73.6969%\n",
      "layer   3  Sparsity: 67.6013%\n",
      "total_backward_count 127270 real_backward_count 20184  15.859%\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  1.816784/  1.951401, val:  67.92%, val_best:  67.92%, tr:  99.69%, tr_best:  99.80%, epoch time: 61.38 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.1031%\n",
      "layer   2  Sparsity: 73.4372%\n",
      "layer   3  Sparsity: 67.1986%\n",
      "total_backward_count 137060 real_backward_count 21351  15.578%\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  1.810367/  1.945228, val:  65.42%, val_best:  67.92%, tr:  99.90%, tr_best:  99.90%, epoch time: 61.74 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0668%\n",
      "layer   2  Sparsity: 72.8917%\n",
      "layer   3  Sparsity: 67.4783%\n",
      "total_backward_count 146850 real_backward_count 22542  15.350%\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  1.805038/  1.942905, val:  57.08%, val_best:  67.92%, tr:  99.80%, tr_best:  99.90%, epoch time: 61.55 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0441%\n",
      "layer   2  Sparsity: 72.5543%\n",
      "layer   3  Sparsity: 67.0425%\n",
      "total_backward_count 156640 real_backward_count 23758  15.167%\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  1.801388/  1.955965, val:  55.42%, val_best:  67.92%, tr:  99.59%, tr_best:  99.90%, epoch time: 62.13 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0648%\n",
      "layer   2  Sparsity: 73.2024%\n",
      "layer   3  Sparsity: 67.6623%\n",
      "total_backward_count 166430 real_backward_count 24863  14.939%\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  1.811329/  1.952257, val:  45.00%, val_best:  67.92%, tr:  99.90%, tr_best:  99.90%, epoch time: 62.23 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0865%\n",
      "layer   2  Sparsity: 72.7738%\n",
      "layer   3  Sparsity: 67.8712%\n",
      "total_backward_count 176220 real_backward_count 25965  14.734%\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  1.798290/  1.949688, val:  54.58%, val_best:  67.92%, tr:  99.80%, tr_best:  99.90%, epoch time: 62.27 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0559%\n",
      "layer   2  Sparsity: 72.5203%\n",
      "layer   3  Sparsity: 67.9901%\n",
      "total_backward_count 186010 real_backward_count 27145  14.593%\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  1.793661/  1.945539, val:  71.25%, val_best:  71.25%, tr:  99.80%, tr_best:  99.90%, epoch time: 61.64 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0829%\n",
      "layer   2  Sparsity: 72.3968%\n",
      "layer   3  Sparsity: 68.2667%\n",
      "total_backward_count 195800 real_backward_count 28232  14.419%\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  1.790926/  1.924776, val:  58.75%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%, epoch time: 61.76 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0844%\n",
      "layer   2  Sparsity: 71.7888%\n",
      "layer   3  Sparsity: 67.5674%\n",
      "total_backward_count 205590 real_backward_count 29272  14.238%\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  1.778644/  1.935177, val:  67.50%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%, epoch time: 62.20 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0870%\n",
      "layer   2  Sparsity: 71.2062%\n",
      "layer   3  Sparsity: 67.3986%\n",
      "total_backward_count 215380 real_backward_count 30296  14.066%\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  1.780190/  1.923320, val:  62.50%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%, epoch time: 62.15 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0798%\n",
      "layer   2  Sparsity: 71.8728%\n",
      "layer   3  Sparsity: 67.8068%\n",
      "total_backward_count 225170 real_backward_count 31385  13.938%\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  1.772415/  1.896900, val:  68.75%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.71 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0473%\n",
      "layer   2  Sparsity: 71.9594%\n",
      "layer   3  Sparsity: 68.5072%\n",
      "total_backward_count 234960 real_backward_count 32385  13.783%\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  1.767569/  1.886295, val:  69.58%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.66 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0754%\n",
      "layer   2  Sparsity: 71.5863%\n",
      "layer   3  Sparsity: 68.4784%\n",
      "total_backward_count 244750 real_backward_count 33360  13.630%\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  1.762233/  1.900356, val:  69.58%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 62.19 seconds, 1.04 minutes\n",
      "layer   1  Sparsity: 91.0726%\n",
      "layer   2  Sparsity: 71.0829%\n",
      "layer   3  Sparsity: 67.9011%\n",
      "total_backward_count 254540 real_backward_count 34309  13.479%\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  1.750662/  1.887216, val:  62.92%, val_best:  71.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.21 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0818%\n",
      "layer   2  Sparsity: 71.7241%\n",
      "layer   3  Sparsity: 68.5111%\n",
      "total_backward_count 264330 real_backward_count 35232  13.329%\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  1.732352/  1.861655, val:  68.75%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%, epoch time: 61.22 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0621%\n",
      "layer   2  Sparsity: 71.6033%\n",
      "layer   3  Sparsity: 67.5950%\n",
      "total_backward_count 274120 real_backward_count 36131  13.181%\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  1.717944/  1.863536, val:  70.00%, val_best:  71.25%, tr:  99.90%, tr_best: 100.00%, epoch time: 61.42 seconds, 1.02 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 71.7017%\n",
      "layer   3  Sparsity: 68.3849%\n",
      "total_backward_count 283910 real_backward_count 37034  13.044%\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  1.726684/  1.869942, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.98 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.1089%\n",
      "layer   2  Sparsity: 70.9931%\n",
      "layer   3  Sparsity: 69.1525%\n",
      "total_backward_count 293700 real_backward_count 37898  12.904%\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  1.725101/  1.850272, val:  74.17%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 61.81 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0882%\n",
      "layer   2  Sparsity: 71.2937%\n",
      "layer   3  Sparsity: 68.4258%\n",
      "total_backward_count 303490 real_backward_count 38775  12.776%\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  1.717109/  1.883314, val:  66.25%, val_best:  75.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 61.99 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.0886%\n",
      "layer   2  Sparsity: 71.1847%\n",
      "layer   3  Sparsity: 68.2592%\n",
      "total_backward_count 313280 real_backward_count 39677  12.665%\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  1.733236/  1.890118, val:  70.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 61.69 seconds, 1.03 minutes\n",
      "layer   1  Sparsity: 91.1071%\n",
      "layer   2  Sparsity: 71.4907%\n",
      "layer   3  Sparsity: 67.7749%\n",
      "total_backward_count 323070 real_backward_count 40576  12.560%\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  1.731996/  1.871234, val:  70.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 65.67 seconds, 1.09 minutes\n",
      "layer   1  Sparsity: 91.0617%\n",
      "layer   2  Sparsity: 70.9215%\n",
      "layer   3  Sparsity: 67.6322%\n",
      "total_backward_count 332860 real_backward_count 41451  12.453%\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  1.725455/  1.849803, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 63.11 seconds, 1.05 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 70.8738%\n",
      "layer   3  Sparsity: 68.3150%\n",
      "total_backward_count 342650 real_backward_count 42342  12.357%\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  1.716280/  1.889717, val:  80.00%, val_best:  80.83%, tr:  99.69%, tr_best: 100.00%, epoch time: 70.67 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0687%\n",
      "layer   2  Sparsity: 70.9247%\n",
      "layer   3  Sparsity: 68.6750%\n",
      "total_backward_count 352440 real_backward_count 43201  12.258%\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  1.713379/  1.862158, val:  65.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.78 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0556%\n",
      "layer   2  Sparsity: 71.2541%\n",
      "layer   3  Sparsity: 68.5219%\n",
      "total_backward_count 362230 real_backward_count 44036  12.157%\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  1.699716/  1.835330, val:  83.33%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.48 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1074%\n",
      "layer   2  Sparsity: 71.2116%\n",
      "layer   3  Sparsity: 68.8464%\n",
      "total_backward_count 372020 real_backward_count 44820  12.048%\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  1.694829/  1.829971, val:  72.92%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.06 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0705%\n",
      "layer   2  Sparsity: 70.7998%\n",
      "layer   3  Sparsity: 67.8647%\n",
      "total_backward_count 381810 real_backward_count 45578  11.937%\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  1.696612/  1.849215, val:  61.25%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.68 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0937%\n",
      "layer   2  Sparsity: 70.7223%\n",
      "layer   3  Sparsity: 67.2680%\n",
      "total_backward_count 391600 real_backward_count 46364  11.840%\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  1.702166/  1.827849, val:  72.92%, val_best:  83.33%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.07 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0601%\n",
      "layer   2  Sparsity: 71.0263%\n",
      "layer   3  Sparsity: 67.7710%\n",
      "total_backward_count 401390 real_backward_count 47117  11.738%\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  1.686127/  1.810812, val:  77.50%, val_best:  83.33%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.58 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1083%\n",
      "layer   2  Sparsity: 70.7850%\n",
      "layer   3  Sparsity: 67.4783%\n",
      "total_backward_count 411180 real_backward_count 47863  11.640%\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  1.676705/  1.809284, val:  82.08%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0586%\n",
      "layer   2  Sparsity: 70.8525%\n",
      "layer   3  Sparsity: 67.6616%\n",
      "total_backward_count 420970 real_backward_count 48637  11.554%\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  1.652740/  1.796400, val:  81.67%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.74 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0942%\n",
      "layer   2  Sparsity: 70.8112%\n",
      "layer   3  Sparsity: 68.4178%\n",
      "total_backward_count 430760 real_backward_count 49377  11.463%\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  1.659765/  1.805350, val:  79.58%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.06 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0681%\n",
      "layer   2  Sparsity: 70.8747%\n",
      "layer   3  Sparsity: 67.6242%\n",
      "total_backward_count 440550 real_backward_count 50083  11.368%\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  1.667175/  1.824351, val:  63.75%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.05 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 70.4652%\n",
      "layer   3  Sparsity: 67.7849%\n",
      "total_backward_count 450340 real_backward_count 50802  11.281%\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  1.666750/  1.818231, val:  76.67%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.48 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0671%\n",
      "layer   2  Sparsity: 70.4223%\n",
      "layer   3  Sparsity: 67.7193%\n",
      "total_backward_count 460130 real_backward_count 51477  11.187%\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  1.661476/  1.809149, val:  72.08%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.50 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1057%\n",
      "layer   2  Sparsity: 70.3093%\n",
      "layer   3  Sparsity: 68.0132%\n",
      "total_backward_count 469920 real_backward_count 52148  11.097%\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  1.666316/  1.806970, val:  85.42%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.87 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0356%\n",
      "layer   2  Sparsity: 70.2678%\n",
      "layer   3  Sparsity: 67.9142%\n",
      "total_backward_count 479710 real_backward_count 52831  11.013%\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  1.670141/  1.807929, val:  79.58%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.07 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1090%\n",
      "layer   2  Sparsity: 70.5296%\n",
      "layer   3  Sparsity: 67.9837%\n",
      "total_backward_count 489500 real_backward_count 53526  10.935%\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  1.645131/  1.790046, val:  81.67%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.02 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1036%\n",
      "layer   2  Sparsity: 70.2760%\n",
      "layer   3  Sparsity: 67.5927%\n",
      "total_backward_count 499290 real_backward_count 54188  10.853%\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  1.643800/  1.774412, val:  81.67%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0777%\n",
      "layer   2  Sparsity: 70.3468%\n",
      "layer   3  Sparsity: 67.3664%\n",
      "total_backward_count 509080 real_backward_count 54842  10.773%\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  1.650503/  1.798152, val:  76.25%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.60 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0801%\n",
      "layer   2  Sparsity: 70.3314%\n",
      "layer   3  Sparsity: 66.9507%\n",
      "total_backward_count 518870 real_backward_count 55477  10.692%\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  1.642288/  1.771825, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0774%\n",
      "layer   2  Sparsity: 69.9925%\n",
      "layer   3  Sparsity: 67.3188%\n",
      "total_backward_count 528660 real_backward_count 56107  10.613%\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  1.626944/  1.757497, val:  87.08%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.06 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1127%\n",
      "layer   2  Sparsity: 70.3870%\n",
      "layer   3  Sparsity: 67.1773%\n",
      "total_backward_count 538450 real_backward_count 56765  10.542%\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  1.620577/  1.764990, val:  78.75%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0960%\n",
      "layer   2  Sparsity: 70.4121%\n",
      "layer   3  Sparsity: 67.2158%\n",
      "total_backward_count 548240 real_backward_count 57389  10.468%\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  1.627010/  1.756727, val:  84.17%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.86 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0843%\n",
      "layer   2  Sparsity: 70.3491%\n",
      "layer   3  Sparsity: 67.3142%\n",
      "total_backward_count 558030 real_backward_count 57996  10.393%\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  1.604715/  1.733616, val:  86.25%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0775%\n",
      "layer   2  Sparsity: 70.3194%\n",
      "layer   3  Sparsity: 67.6018%\n",
      "total_backward_count 567820 real_backward_count 58596  10.319%\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  1.605274/  1.741596, val:  80.00%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.21 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0675%\n",
      "layer   2  Sparsity: 70.9553%\n",
      "layer   3  Sparsity: 67.7324%\n",
      "total_backward_count 577610 real_backward_count 59161  10.242%\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  1.607303/  1.744843, val:  85.00%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1104%\n",
      "layer   2  Sparsity: 70.7342%\n",
      "layer   3  Sparsity: 67.5661%\n",
      "total_backward_count 587400 real_backward_count 59728  10.168%\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  1.604360/  1.737601, val:  83.33%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.34 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 70.2581%\n",
      "layer   3  Sparsity: 66.7096%\n",
      "total_backward_count 597190 real_backward_count 60332  10.103%\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  1.594339/  1.745464, val:  81.67%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.00 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0938%\n",
      "layer   2  Sparsity: 70.0341%\n",
      "layer   3  Sparsity: 67.2585%\n",
      "total_backward_count 606980 real_backward_count 60932  10.039%\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  1.604156/  1.764422, val:  77.92%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.83 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0387%\n",
      "layer   2  Sparsity: 69.7613%\n",
      "layer   3  Sparsity: 67.6234%\n",
      "total_backward_count 616770 real_backward_count 61518   9.974%\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  1.595771/  1.737339, val:  86.67%, val_best:  87.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.53 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0614%\n",
      "layer   2  Sparsity: 69.9021%\n",
      "layer   3  Sparsity: 67.5606%\n",
      "total_backward_count 626560 real_backward_count 62081   9.908%\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  1.589473/  1.753864, val:  78.33%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.75 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0457%\n",
      "layer   2  Sparsity: 70.0296%\n",
      "layer   3  Sparsity: 67.4759%\n",
      "total_backward_count 636350 real_backward_count 62673   9.849%\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  1.593302/  1.743340, val:  82.08%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.44 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0664%\n",
      "layer   2  Sparsity: 69.9184%\n",
      "layer   3  Sparsity: 67.1529%\n",
      "total_backward_count 646140 real_backward_count 63185   9.779%\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  1.587389/  1.720272, val:  90.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0838%\n",
      "layer   2  Sparsity: 69.8466%\n",
      "layer   3  Sparsity: 66.4659%\n",
      "total_backward_count 655930 real_backward_count 63741   9.718%\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  1.584709/  1.738608, val:  81.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.77 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1064%\n",
      "layer   2  Sparsity: 69.5132%\n",
      "layer   3  Sparsity: 66.0868%\n",
      "total_backward_count 665720 real_backward_count 64297   9.658%\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  1.589186/  1.739336, val:  80.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.21 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0892%\n",
      "layer   2  Sparsity: 69.6743%\n",
      "layer   3  Sparsity: 66.3616%\n",
      "total_backward_count 675510 real_backward_count 64826   9.597%\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  1.577657/  1.719756, val:  84.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.65 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0441%\n",
      "layer   2  Sparsity: 69.2830%\n",
      "layer   3  Sparsity: 66.1113%\n",
      "total_backward_count 685300 real_backward_count 65334   9.534%\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  1.574065/  1.717949, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0681%\n",
      "layer   2  Sparsity: 69.0888%\n",
      "layer   3  Sparsity: 66.2067%\n",
      "total_backward_count 695090 real_backward_count 65868   9.476%\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  1.572932/  1.711514, val:  84.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0553%\n",
      "layer   2  Sparsity: 69.3201%\n",
      "layer   3  Sparsity: 66.1829%\n",
      "total_backward_count 704880 real_backward_count 66397   9.420%\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  1.554787/  1.684147, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.57 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0816%\n",
      "layer   2  Sparsity: 69.6918%\n",
      "layer   3  Sparsity: 65.9734%\n",
      "total_backward_count 714670 real_backward_count 66929   9.365%\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  1.549926/  1.710625, val:  73.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.55 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0793%\n",
      "layer   2  Sparsity: 69.5574%\n",
      "layer   3  Sparsity: 65.9675%\n",
      "total_backward_count 724460 real_backward_count 67441   9.309%\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  1.546179/  1.698992, val:  78.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.46 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 69.8208%\n",
      "layer   3  Sparsity: 66.1824%\n",
      "total_backward_count 734250 real_backward_count 67971   9.257%\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  1.545755/  1.699090, val:  82.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.63 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0551%\n",
      "layer   2  Sparsity: 69.7292%\n",
      "layer   3  Sparsity: 66.6049%\n",
      "total_backward_count 744040 real_backward_count 68476   9.203%\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  1.543144/  1.685749, val:  80.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.35 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0760%\n",
      "layer   2  Sparsity: 69.5437%\n",
      "layer   3  Sparsity: 67.1724%\n",
      "total_backward_count 753830 real_backward_count 68926   9.143%\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  1.541019/  1.688738, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0559%\n",
      "layer   2  Sparsity: 69.5977%\n",
      "layer   3  Sparsity: 66.5208%\n",
      "total_backward_count 763620 real_backward_count 69401   9.088%\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  1.538934/  1.709748, val:  85.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.92 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0769%\n",
      "layer   2  Sparsity: 69.7486%\n",
      "layer   3  Sparsity: 66.7018%\n",
      "total_backward_count 773410 real_backward_count 69882   9.036%\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  1.553776/  1.702299, val:  78.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.85 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0655%\n",
      "layer   2  Sparsity: 69.7478%\n",
      "layer   3  Sparsity: 66.8757%\n",
      "total_backward_count 783200 real_backward_count 70317   8.978%\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  1.546409/  1.698195, val:  82.08%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.89 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0159%\n",
      "layer   2  Sparsity: 69.5405%\n",
      "layer   3  Sparsity: 67.1358%\n",
      "total_backward_count 792990 real_backward_count 70803   8.929%\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  1.535341/  1.686979, val:  85.83%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.97 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1078%\n",
      "layer   2  Sparsity: 69.3856%\n",
      "layer   3  Sparsity: 67.2663%\n",
      "total_backward_count 802780 real_backward_count 71250   8.875%\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  1.532358/  1.680956, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.18 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0532%\n",
      "layer   2  Sparsity: 69.4417%\n",
      "layer   3  Sparsity: 67.2783%\n",
      "total_backward_count 812570 real_backward_count 71695   8.823%\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  1.539467/  1.698930, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.24 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0620%\n",
      "layer   2  Sparsity: 69.4369%\n",
      "layer   3  Sparsity: 67.3655%\n",
      "total_backward_count 822360 real_backward_count 72193   8.779%\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  1.540372/  1.690435, val:  81.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.17 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0672%\n",
      "layer   2  Sparsity: 69.3731%\n",
      "layer   3  Sparsity: 67.5890%\n",
      "total_backward_count 832150 real_backward_count 72639   8.729%\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  1.531978/  1.688589, val:  86.25%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.46 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0798%\n",
      "layer   2  Sparsity: 69.2863%\n",
      "layer   3  Sparsity: 67.0529%\n",
      "total_backward_count 841940 real_backward_count 73132   8.686%\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  1.533240/  1.671231, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.80 seconds, 1.20 minutes\n",
      "layer   1  Sparsity: 91.0766%\n",
      "layer   2  Sparsity: 69.2923%\n",
      "layer   3  Sparsity: 66.6874%\n",
      "total_backward_count 851730 real_backward_count 73586   8.640%\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  1.521947/  1.655910, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0601%\n",
      "layer   2  Sparsity: 69.5053%\n",
      "layer   3  Sparsity: 67.3459%\n",
      "total_backward_count 861520 real_backward_count 74006   8.590%\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  1.517384/  1.677333, val:  85.00%, val_best:  90.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.88 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1194%\n",
      "layer   2  Sparsity: 69.4017%\n",
      "layer   3  Sparsity: 67.7351%\n",
      "total_backward_count 871310 real_backward_count 74421   8.541%\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  1.513699/  1.680813, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.07 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1114%\n",
      "layer   2  Sparsity: 69.2804%\n",
      "layer   3  Sparsity: 66.9177%\n",
      "total_backward_count 881100 real_backward_count 74852   8.495%\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  1.518076/  1.684498, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0659%\n",
      "layer   2  Sparsity: 69.1291%\n",
      "layer   3  Sparsity: 66.7809%\n",
      "total_backward_count 890890 real_backward_count 75267   8.449%\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  1.511295/  1.673662, val:  84.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0990%\n",
      "layer   2  Sparsity: 69.3164%\n",
      "layer   3  Sparsity: 66.7300%\n",
      "total_backward_count 900680 real_backward_count 75644   8.399%\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  1.508049/  1.658325, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.24 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0828%\n",
      "layer   2  Sparsity: 69.2454%\n",
      "layer   3  Sparsity: 66.7385%\n",
      "total_backward_count 910470 real_backward_count 76034   8.351%\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  1.503765/  1.653973, val:  85.83%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.91 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1296%\n",
      "layer   2  Sparsity: 69.3551%\n",
      "layer   3  Sparsity: 67.0169%\n",
      "total_backward_count 920260 real_backward_count 76443   8.307%\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  1.511176/  1.657572, val:  79.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0965%\n",
      "layer   2  Sparsity: 69.3580%\n",
      "layer   3  Sparsity: 66.7454%\n",
      "total_backward_count 930050 real_backward_count 76858   8.264%\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  1.501660/  1.675911, val:  77.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.01 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0653%\n",
      "layer   2  Sparsity: 69.1295%\n",
      "layer   3  Sparsity: 66.7048%\n",
      "total_backward_count 939840 real_backward_count 77262   8.221%\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  1.502811/  1.644234, val:  85.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.26 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0582%\n",
      "layer   2  Sparsity: 69.2634%\n",
      "layer   3  Sparsity: 66.5129%\n",
      "total_backward_count 949630 real_backward_count 77651   8.177%\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  1.496257/  1.644954, val:  85.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.22 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0446%\n",
      "layer   2  Sparsity: 69.2733%\n",
      "layer   3  Sparsity: 66.7923%\n",
      "total_backward_count 959420 real_backward_count 78049   8.135%\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  1.502623/  1.648594, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0674%\n",
      "layer   2  Sparsity: 69.3076%\n",
      "layer   3  Sparsity: 66.7237%\n",
      "total_backward_count 969210 real_backward_count 78402   8.089%\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  1.492941/  1.650668, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.52 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1076%\n",
      "layer   2  Sparsity: 69.3732%\n",
      "layer   3  Sparsity: 66.8455%\n",
      "total_backward_count 979000 real_backward_count 78759   8.045%\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  1.492977/  1.655197, val:  85.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.78 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1128%\n",
      "layer   2  Sparsity: 68.8774%\n",
      "layer   3  Sparsity: 66.4599%\n",
      "total_backward_count 988790 real_backward_count 79108   8.000%\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  1.492715/  1.652202, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.58 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0993%\n",
      "layer   2  Sparsity: 68.8947%\n",
      "layer   3  Sparsity: 66.3954%\n",
      "total_backward_count 998580 real_backward_count 79509   7.962%\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  1.489523/  1.642895, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.26 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 69.1062%\n",
      "layer   3  Sparsity: 66.3185%\n",
      "total_backward_count 1008370 real_backward_count 79889   7.923%\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  1.482159/  1.636422, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.61 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0819%\n",
      "layer   2  Sparsity: 69.2944%\n",
      "layer   3  Sparsity: 67.3082%\n",
      "total_backward_count 1018160 real_backward_count 80246   7.881%\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  1.477553/  1.634697, val:  85.83%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.49 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0549%\n",
      "layer   2  Sparsity: 69.4749%\n",
      "layer   3  Sparsity: 67.2894%\n",
      "total_backward_count 1027950 real_backward_count 80609   7.842%\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  1.472149/  1.629786, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.96 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0604%\n",
      "layer   2  Sparsity: 69.2985%\n",
      "layer   3  Sparsity: 67.1282%\n",
      "total_backward_count 1037740 real_backward_count 80980   7.803%\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  1.469794/  1.635579, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.31 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0432%\n",
      "layer   2  Sparsity: 69.3689%\n",
      "layer   3  Sparsity: 67.5082%\n",
      "total_backward_count 1047530 real_backward_count 81359   7.767%\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  1.462539/  1.621769, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.42 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 69.4077%\n",
      "layer   3  Sparsity: 67.8330%\n",
      "total_backward_count 1057320 real_backward_count 81660   7.723%\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  1.453176/  1.618980, val:  83.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.81 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0408%\n",
      "layer   2  Sparsity: 69.0521%\n",
      "layer   3  Sparsity: 66.8796%\n",
      "total_backward_count 1067110 real_backward_count 81971   7.682%\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  1.451811/  1.605291, val:  90.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.84 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1168%\n",
      "layer   2  Sparsity: 68.9997%\n",
      "layer   3  Sparsity: 67.0545%\n",
      "total_backward_count 1076900 real_backward_count 82309   7.643%\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  1.439339/  1.597669, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.08 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0853%\n",
      "layer   2  Sparsity: 68.9920%\n",
      "layer   3  Sparsity: 67.2131%\n",
      "total_backward_count 1086690 real_backward_count 82667   7.607%\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  1.446636/  1.616364, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.43 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0888%\n",
      "layer   2  Sparsity: 68.9560%\n",
      "layer   3  Sparsity: 67.1011%\n",
      "total_backward_count 1096480 real_backward_count 83029   7.572%\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  1.452128/  1.610129, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.00 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0839%\n",
      "layer   2  Sparsity: 68.9037%\n",
      "layer   3  Sparsity: 67.3299%\n",
      "total_backward_count 1106270 real_backward_count 83360   7.535%\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  1.449567/  1.620766, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.86 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0735%\n",
      "layer   2  Sparsity: 69.0222%\n",
      "layer   3  Sparsity: 67.3428%\n",
      "total_backward_count 1116060 real_backward_count 83674   7.497%\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  1.448797/  1.608208, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.64 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0685%\n",
      "layer   2  Sparsity: 68.8210%\n",
      "layer   3  Sparsity: 67.3872%\n",
      "total_backward_count 1125850 real_backward_count 83993   7.460%\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  1.441925/  1.615523, val:  83.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.25 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0878%\n",
      "layer   2  Sparsity: 68.8631%\n",
      "layer   3  Sparsity: 67.3778%\n",
      "total_backward_count 1135640 real_backward_count 84304   7.423%\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  1.426517/  1.606356, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.23 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 68.8478%\n",
      "layer   3  Sparsity: 67.0017%\n",
      "total_backward_count 1145430 real_backward_count 84589   7.385%\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  1.432310/  1.589628, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.25 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0510%\n",
      "layer   2  Sparsity: 68.9228%\n",
      "layer   3  Sparsity: 67.5328%\n",
      "total_backward_count 1155220 real_backward_count 84885   7.348%\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  1.433610/  1.610801, val:  87.08%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0441%\n",
      "layer   2  Sparsity: 68.9096%\n",
      "layer   3  Sparsity: 67.6783%\n",
      "total_backward_count 1165010 real_backward_count 85184   7.312%\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  1.430921/  1.599745, val:  87.50%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.03 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1078%\n",
      "layer   2  Sparsity: 68.8224%\n",
      "layer   3  Sparsity: 67.1651%\n",
      "total_backward_count 1174800 real_backward_count 85519   7.279%\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  1.433182/  1.587881, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.59 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1150%\n",
      "layer   2  Sparsity: 68.5791%\n",
      "layer   3  Sparsity: 66.8046%\n",
      "total_backward_count 1184590 real_backward_count 85844   7.247%\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  1.429803/  1.596600, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.37 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0752%\n",
      "layer   2  Sparsity: 68.8235%\n",
      "layer   3  Sparsity: 67.4032%\n",
      "total_backward_count 1194380 real_backward_count 86137   7.212%\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  1.427879/  1.591381, val:  85.83%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.70 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1032%\n",
      "layer   2  Sparsity: 68.9324%\n",
      "layer   3  Sparsity: 67.1379%\n",
      "total_backward_count 1204170 real_backward_count 86407   7.176%\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  1.428360/  1.596392, val:  85.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0898%\n",
      "layer   2  Sparsity: 68.9658%\n",
      "layer   3  Sparsity: 67.6508%\n",
      "total_backward_count 1213960 real_backward_count 86686   7.141%\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  1.426407/  1.603311, val:  85.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.84 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0465%\n",
      "layer   2  Sparsity: 69.2335%\n",
      "layer   3  Sparsity: 67.6562%\n",
      "total_backward_count 1223750 real_backward_count 86946   7.105%\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  1.433926/  1.600321, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.83 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1007%\n",
      "layer   2  Sparsity: 68.8748%\n",
      "layer   3  Sparsity: 66.8245%\n",
      "total_backward_count 1233540 real_backward_count 87226   7.071%\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  1.434320/  1.606940, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.49 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1101%\n",
      "layer   2  Sparsity: 68.9473%\n",
      "layer   3  Sparsity: 66.7884%\n",
      "total_backward_count 1243330 real_backward_count 87519   7.039%\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  1.427232/  1.595736, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0993%\n",
      "layer   2  Sparsity: 68.7992%\n",
      "layer   3  Sparsity: 66.4644%\n",
      "total_backward_count 1253120 real_backward_count 87837   7.009%\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  1.428086/  1.604954, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.78 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0887%\n",
      "layer   2  Sparsity: 68.7323%\n",
      "layer   3  Sparsity: 66.3468%\n",
      "total_backward_count 1262910 real_backward_count 88129   6.978%\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  1.411933/  1.575017, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.70 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0679%\n",
      "layer   2  Sparsity: 69.0815%\n",
      "layer   3  Sparsity: 66.6621%\n",
      "total_backward_count 1272700 real_backward_count 88428   6.948%\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  1.402234/  1.569792, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.02 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0998%\n",
      "layer   2  Sparsity: 69.0070%\n",
      "layer   3  Sparsity: 66.9363%\n",
      "total_backward_count 1282490 real_backward_count 88693   6.916%\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  1.414735/  1.569127, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0655%\n",
      "layer   2  Sparsity: 69.0447%\n",
      "layer   3  Sparsity: 66.7292%\n",
      "total_backward_count 1292280 real_backward_count 88946   6.883%\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  1.408526/  1.583870, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.01 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0886%\n",
      "layer   2  Sparsity: 68.6707%\n",
      "layer   3  Sparsity: 66.6682%\n",
      "total_backward_count 1302070 real_backward_count 89249   6.854%\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  1.399023/  1.573398, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.38 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1188%\n",
      "layer   2  Sparsity: 68.6299%\n",
      "layer   3  Sparsity: 67.0546%\n",
      "total_backward_count 1311860 real_backward_count 89515   6.824%\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  1.393644/  1.568494, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.81 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0898%\n",
      "layer   2  Sparsity: 68.6441%\n",
      "layer   3  Sparsity: 67.3375%\n",
      "total_backward_count 1321650 real_backward_count 89773   6.792%\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  1.398802/  1.575152, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.33 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0658%\n",
      "layer   2  Sparsity: 68.8480%\n",
      "layer   3  Sparsity: 67.3871%\n",
      "total_backward_count 1331440 real_backward_count 90050   6.763%\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  1.401361/  1.576310, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.38 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0832%\n",
      "layer   2  Sparsity: 68.7476%\n",
      "layer   3  Sparsity: 67.0733%\n",
      "total_backward_count 1341230 real_backward_count 90311   6.733%\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  1.397987/  1.575085, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.22 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0845%\n",
      "layer   2  Sparsity: 68.8981%\n",
      "layer   3  Sparsity: 67.3704%\n",
      "total_backward_count 1351020 real_backward_count 90561   6.703%\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  1.394305/  1.570336, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0391%\n",
      "layer   2  Sparsity: 68.8496%\n",
      "layer   3  Sparsity: 67.3999%\n",
      "total_backward_count 1360810 real_backward_count 90836   6.675%\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  1.392385/  1.581259, val:  81.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.32 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0396%\n",
      "layer   2  Sparsity: 68.6123%\n",
      "layer   3  Sparsity: 67.3609%\n",
      "total_backward_count 1370600 real_backward_count 91097   6.647%\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  1.398345/  1.576699, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1065%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 66.8199%\n",
      "total_backward_count 1380390 real_backward_count 91350   6.618%\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  1.394941/  1.567011, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.93 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0581%\n",
      "layer   2  Sparsity: 68.7384%\n",
      "layer   3  Sparsity: 66.7122%\n",
      "total_backward_count 1390180 real_backward_count 91643   6.592%\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  1.391229/  1.560717, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.92 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0780%\n",
      "layer   2  Sparsity: 68.8947%\n",
      "layer   3  Sparsity: 66.9117%\n",
      "total_backward_count 1399970 real_backward_count 91889   6.564%\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  1.381794/  1.557981, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.96 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0692%\n",
      "layer   2  Sparsity: 68.9765%\n",
      "layer   3  Sparsity: 67.0616%\n",
      "total_backward_count 1409760 real_backward_count 92129   6.535%\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  1.382334/  1.574806, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.58 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0931%\n",
      "layer   2  Sparsity: 68.9054%\n",
      "layer   3  Sparsity: 66.9842%\n",
      "total_backward_count 1419550 real_backward_count 92371   6.507%\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  1.381614/  1.564185, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.35 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0570%\n",
      "layer   2  Sparsity: 68.8322%\n",
      "layer   3  Sparsity: 66.6318%\n",
      "total_backward_count 1429340 real_backward_count 92612   6.479%\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  1.377919/  1.562411, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.37 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 68.6406%\n",
      "layer   3  Sparsity: 67.1004%\n",
      "total_backward_count 1439130 real_backward_count 92901   6.455%\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  1.386819/  1.570237, val:  85.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.65 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0637%\n",
      "layer   2  Sparsity: 68.7053%\n",
      "layer   3  Sparsity: 66.8257%\n",
      "total_backward_count 1448920 real_backward_count 93157   6.429%\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  1.385019/  1.573093, val:  86.25%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.71 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0676%\n",
      "layer   2  Sparsity: 68.7966%\n",
      "layer   3  Sparsity: 66.2773%\n",
      "total_backward_count 1458710 real_backward_count 93403   6.403%\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  1.384970/  1.561992, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.14 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0829%\n",
      "layer   2  Sparsity: 68.8822%\n",
      "layer   3  Sparsity: 66.2027%\n",
      "total_backward_count 1468500 real_backward_count 93655   6.378%\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  1.370165/  1.541029, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0951%\n",
      "layer   2  Sparsity: 69.0468%\n",
      "layer   3  Sparsity: 66.4309%\n",
      "total_backward_count 1478290 real_backward_count 93893   6.351%\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  1.360425/  1.539972, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.02 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0670%\n",
      "layer   2  Sparsity: 69.0375%\n",
      "layer   3  Sparsity: 66.4854%\n",
      "total_backward_count 1488080 real_backward_count 94112   6.324%\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  1.366307/  1.566039, val:  84.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.38 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0916%\n",
      "layer   2  Sparsity: 69.1130%\n",
      "layer   3  Sparsity: 66.1357%\n",
      "total_backward_count 1497870 real_backward_count 94386   6.301%\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  1.369185/  1.525942, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0651%\n",
      "layer   2  Sparsity: 69.0192%\n",
      "layer   3  Sparsity: 66.5649%\n",
      "total_backward_count 1507660 real_backward_count 94640   6.277%\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  1.361971/  1.536312, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1173%\n",
      "layer   2  Sparsity: 68.8658%\n",
      "layer   3  Sparsity: 66.7644%\n",
      "total_backward_count 1517450 real_backward_count 94881   6.253%\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  1.363690/  1.552623, val:  85.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.32 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0384%\n",
      "layer   2  Sparsity: 68.9737%\n",
      "layer   3  Sparsity: 67.1333%\n",
      "total_backward_count 1527240 real_backward_count 95090   6.226%\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  1.355066/  1.560400, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.70 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0946%\n",
      "layer   2  Sparsity: 69.1025%\n",
      "layer   3  Sparsity: 67.2567%\n",
      "total_backward_count 1537030 real_backward_count 95275   6.199%\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  1.363539/  1.546226, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.60 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0810%\n",
      "layer   2  Sparsity: 69.0361%\n",
      "layer   3  Sparsity: 67.2577%\n",
      "total_backward_count 1546820 real_backward_count 95509   6.175%\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  1.358835/  1.543980, val:  85.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.28 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1235%\n",
      "layer   2  Sparsity: 69.1635%\n",
      "layer   3  Sparsity: 67.0495%\n",
      "total_backward_count 1556610 real_backward_count 95718   6.149%\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  1.355194/  1.534428, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.53 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0725%\n",
      "layer   2  Sparsity: 68.9567%\n",
      "layer   3  Sparsity: 66.9574%\n",
      "total_backward_count 1566400 real_backward_count 95910   6.123%\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  1.358409/  1.538041, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.36 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0731%\n",
      "layer   2  Sparsity: 68.7891%\n",
      "layer   3  Sparsity: 66.9182%\n",
      "total_backward_count 1576190 real_backward_count 96128   6.099%\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  1.357147/  1.521464, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.80 seconds, 1.20 minutes\n",
      "layer   1  Sparsity: 91.0870%\n",
      "layer   2  Sparsity: 68.9673%\n",
      "layer   3  Sparsity: 67.1374%\n",
      "total_backward_count 1585980 real_backward_count 96321   6.073%\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  1.352707/  1.541953, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.62 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0856%\n",
      "layer   2  Sparsity: 68.9726%\n",
      "layer   3  Sparsity: 67.1774%\n",
      "total_backward_count 1595770 real_backward_count 96553   6.051%\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  1.360159/  1.527502, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.25 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0725%\n",
      "layer   2  Sparsity: 68.6623%\n",
      "layer   3  Sparsity: 67.0891%\n",
      "total_backward_count 1605560 real_backward_count 96800   6.029%\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  1.350427/  1.531124, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.88 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0697%\n",
      "layer   2  Sparsity: 68.8621%\n",
      "layer   3  Sparsity: 66.9160%\n",
      "total_backward_count 1615350 real_backward_count 96990   6.004%\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  1.356790/  1.537029, val:  90.42%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.78 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0980%\n",
      "layer   2  Sparsity: 68.8127%\n",
      "layer   3  Sparsity: 66.5586%\n",
      "total_backward_count 1625140 real_backward_count 97237   5.983%\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  1.354918/  1.530715, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0600%\n",
      "layer   2  Sparsity: 68.7075%\n",
      "layer   3  Sparsity: 66.6963%\n",
      "total_backward_count 1634930 real_backward_count 97435   5.960%\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  1.360000/  1.535046, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.48 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0991%\n",
      "layer   2  Sparsity: 68.5787%\n",
      "layer   3  Sparsity: 66.6970%\n",
      "total_backward_count 1644720 real_backward_count 97656   5.938%\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  1.353313/  1.533255, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.89 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0507%\n",
      "layer   2  Sparsity: 68.6697%\n",
      "layer   3  Sparsity: 66.9845%\n",
      "total_backward_count 1654510 real_backward_count 97837   5.913%\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  1.347374/  1.520804, val:  90.42%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.86 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0959%\n",
      "layer   2  Sparsity: 68.7429%\n",
      "layer   3  Sparsity: 66.8497%\n",
      "total_backward_count 1664300 real_backward_count 98037   5.891%\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  1.349664/  1.521025, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.10 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0585%\n",
      "layer   2  Sparsity: 68.6573%\n",
      "layer   3  Sparsity: 66.5487%\n",
      "total_backward_count 1674090 real_backward_count 98222   5.867%\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  1.340250/  1.507672, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.23 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0939%\n",
      "layer   2  Sparsity: 68.6579%\n",
      "layer   3  Sparsity: 66.5279%\n",
      "total_backward_count 1683880 real_backward_count 98450   5.847%\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  1.335223/  1.520398, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.37 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0661%\n",
      "layer   2  Sparsity: 68.7491%\n",
      "layer   3  Sparsity: 66.3954%\n",
      "total_backward_count 1693670 real_backward_count 98658   5.825%\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  1.328131/  1.512369, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.42 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1212%\n",
      "layer   2  Sparsity: 68.7648%\n",
      "layer   3  Sparsity: 66.2330%\n",
      "total_backward_count 1703460 real_backward_count 98851   5.803%\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  1.329279/  1.505004, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.74 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 68.9255%\n",
      "layer   3  Sparsity: 66.3687%\n",
      "total_backward_count 1713250 real_backward_count 99031   5.780%\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  1.333053/  1.520593, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.85 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0577%\n",
      "layer   2  Sparsity: 68.9579%\n",
      "layer   3  Sparsity: 66.5839%\n",
      "total_backward_count 1723040 real_backward_count 99234   5.759%\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  1.332387/  1.515324, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.91 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0827%\n",
      "layer   2  Sparsity: 68.7858%\n",
      "layer   3  Sparsity: 66.7551%\n",
      "total_backward_count 1732830 real_backward_count 99430   5.738%\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  1.331761/  1.509577, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.80 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0778%\n",
      "layer   2  Sparsity: 68.5473%\n",
      "layer   3  Sparsity: 66.6893%\n",
      "total_backward_count 1742620 real_backward_count 99649   5.718%\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  1.323215/  1.503657, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.81 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0122%\n",
      "layer   2  Sparsity: 68.6770%\n",
      "layer   3  Sparsity: 67.3912%\n",
      "total_backward_count 1752410 real_backward_count 99853   5.698%\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  1.322566/  1.500416, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.31 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0871%\n",
      "layer   2  Sparsity: 68.9340%\n",
      "layer   3  Sparsity: 67.1625%\n",
      "total_backward_count 1762200 real_backward_count 100025   5.676%\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  1.317669/  1.501996, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0874%\n",
      "layer   2  Sparsity: 68.9171%\n",
      "layer   3  Sparsity: 67.4695%\n",
      "total_backward_count 1771990 real_backward_count 100189   5.654%\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  1.313411/  1.495712, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.49 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0823%\n",
      "layer   2  Sparsity: 68.9172%\n",
      "layer   3  Sparsity: 67.5633%\n",
      "total_backward_count 1781780 real_backward_count 100378   5.634%\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  1.309798/  1.506929, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.54 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0888%\n",
      "layer   2  Sparsity: 68.8930%\n",
      "layer   3  Sparsity: 67.8440%\n",
      "total_backward_count 1791570 real_backward_count 100548   5.612%\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  1.313668/  1.498380, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.42 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0683%\n",
      "layer   2  Sparsity: 68.8719%\n",
      "layer   3  Sparsity: 67.7280%\n",
      "total_backward_count 1801360 real_backward_count 100718   5.591%\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  1.311502/  1.500080, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.37 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0675%\n",
      "layer   2  Sparsity: 68.8037%\n",
      "layer   3  Sparsity: 67.2376%\n",
      "total_backward_count 1811150 real_backward_count 100890   5.570%\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  1.308241/  1.500382, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0990%\n",
      "layer   2  Sparsity: 68.9519%\n",
      "layer   3  Sparsity: 67.2943%\n",
      "total_backward_count 1820940 real_backward_count 101070   5.550%\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  1.311130/  1.499380, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.02 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0948%\n",
      "layer   2  Sparsity: 68.8437%\n",
      "layer   3  Sparsity: 67.3869%\n",
      "total_backward_count 1830730 real_backward_count 101227   5.529%\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  1.310035/  1.500498, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.25 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0721%\n",
      "layer   2  Sparsity: 68.9638%\n",
      "layer   3  Sparsity: 67.6113%\n",
      "total_backward_count 1840520 real_backward_count 101407   5.510%\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  1.301201/  1.483570, val:  91.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.11 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0322%\n",
      "layer   2  Sparsity: 68.6391%\n",
      "layer   3  Sparsity: 67.4829%\n",
      "total_backward_count 1850310 real_backward_count 101560   5.489%\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  1.300690/  1.495103, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0591%\n",
      "layer   2  Sparsity: 68.6278%\n",
      "layer   3  Sparsity: 67.4117%\n",
      "total_backward_count 1860100 real_backward_count 101728   5.469%\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  1.309752/  1.485249, val:  91.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0476%\n",
      "layer   2  Sparsity: 68.7712%\n",
      "layer   3  Sparsity: 67.5570%\n",
      "total_backward_count 1869890 real_backward_count 101890   5.449%\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  1.311500/  1.504578, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.10 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0903%\n",
      "layer   2  Sparsity: 68.8311%\n",
      "layer   3  Sparsity: 67.4747%\n",
      "total_backward_count 1879680 real_backward_count 102030   5.428%\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  1.313342/  1.492209, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.74 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 68.6416%\n",
      "layer   3  Sparsity: 67.1043%\n",
      "total_backward_count 1889470 real_backward_count 102230   5.411%\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  1.307300/  1.484083, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0512%\n",
      "layer   2  Sparsity: 68.7982%\n",
      "layer   3  Sparsity: 67.5426%\n",
      "total_backward_count 1899260 real_backward_count 102389   5.391%\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  1.300881/  1.495778, val:  86.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.32 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0850%\n",
      "layer   2  Sparsity: 68.7957%\n",
      "layer   3  Sparsity: 67.7809%\n",
      "total_backward_count 1909050 real_backward_count 102566   5.373%\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  1.306518/  1.496901, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0762%\n",
      "layer   2  Sparsity: 68.6878%\n",
      "layer   3  Sparsity: 67.8295%\n",
      "total_backward_count 1918840 real_backward_count 102711   5.353%\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  1.304341/  1.483072, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0786%\n",
      "layer   2  Sparsity: 68.6492%\n",
      "layer   3  Sparsity: 67.7412%\n",
      "total_backward_count 1928630 real_backward_count 102862   5.333%\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  1.300467/  1.477852, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0810%\n",
      "layer   2  Sparsity: 68.6581%\n",
      "layer   3  Sparsity: 67.3848%\n",
      "total_backward_count 1938420 real_backward_count 103044   5.316%\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  1.295624/  1.477084, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.81 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0523%\n",
      "layer   2  Sparsity: 68.7088%\n",
      "layer   3  Sparsity: 66.9322%\n",
      "total_backward_count 1948210 real_backward_count 103209   5.298%\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  1.294901/  1.475561, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.25 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0703%\n",
      "layer   2  Sparsity: 68.6731%\n",
      "layer   3  Sparsity: 67.1704%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5f5533f3e74441ad4bd2d3d415b493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>1.2949</td></tr><tr><td>val_acc_best</td><td>0.91667</td></tr><tr><td>val_acc_now</td><td>0.8875</td></tr><tr><td>val_loss</td><td>1.47556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-frost-18923</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9j4lw8yu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9j4lw8yu</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251118_232938-9j4lw8yu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70173a39232145ff8baa558c118e819e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112852878351178, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251119_032140-qze3nq7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qze3nq7j' target=\"_blank\">classic-plasma-18936</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qze3nq7j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qze3nq7j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20251119_032140_895', 'my_seed': 3, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001953125, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 999], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 999], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.001953125\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "epoch-0   lr=['0.0019531'], tr/val_loss:  1.909951/  2.026771, val:  37.92%, val_best:  37.92%, tr:  91.52%, tr_best:  91.52%, epoch time: 71.71 seconds, 1.20 minutes\n",
      "layer   1  Sparsity: 91.0891%\n",
      "layer   2  Sparsity: 77.4899%\n",
      "layer   3  Sparsity: 72.8926%\n",
      "total_backward_count 9790 real_backward_count 2752  28.110%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0019531'], tr/val_loss:  1.863268/  2.012733, val:  52.92%, val_best:  52.92%, tr:  98.57%, tr_best:  98.57%, epoch time: 71.21 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0537%\n",
      "layer   2  Sparsity: 77.9667%\n",
      "layer   3  Sparsity: 69.9195%\n",
      "total_backward_count 19580 real_backward_count 4655  23.774%\n",
      "epoch-2   lr=['0.0019531'], tr/val_loss:  1.888589/  2.014477, val:  47.08%, val_best:  52.92%, tr:  98.88%, tr_best:  98.88%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 77.1294%\n",
      "layer   3  Sparsity: 68.4563%\n",
      "total_backward_count 29370 real_backward_count 6387  21.747%\n",
      "epoch-3   lr=['0.0019531'], tr/val_loss:  1.863481/  2.006480, val:  54.17%, val_best:  54.17%, tr:  99.69%, tr_best:  99.69%, epoch time: 71.39 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 77.1313%\n",
      "layer   3  Sparsity: 67.3731%\n",
      "total_backward_count 39160 real_backward_count 7899  20.171%\n",
      "epoch-4   lr=['0.0019531'], tr/val_loss:  1.872738/  2.003196, val:  52.08%, val_best:  54.17%, tr:  98.88%, tr_best:  99.69%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0789%\n",
      "layer   2  Sparsity: 77.1113%\n",
      "layer   3  Sparsity: 67.4610%\n",
      "total_backward_count 48950 real_backward_count 9390  19.183%\n",
      "epoch-5   lr=['0.0019531'], tr/val_loss:  1.857047/  2.009488, val:  43.33%, val_best:  54.17%, tr:  99.90%, tr_best:  99.90%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0698%\n",
      "layer   2  Sparsity: 77.6653%\n",
      "layer   3  Sparsity: 66.2062%\n",
      "total_backward_count 58740 real_backward_count 10758  18.315%\n",
      "epoch-6   lr=['0.0019531'], tr/val_loss:  1.843573/  2.004390, val:  39.17%, val_best:  54.17%, tr:  99.69%, tr_best:  99.90%, epoch time: 70.35 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0772%\n",
      "layer   2  Sparsity: 77.0551%\n",
      "layer   3  Sparsity: 65.1732%\n",
      "total_backward_count 68530 real_backward_count 12073  17.617%\n",
      "epoch-7   lr=['0.0019531'], tr/val_loss:  1.839386/  1.982113, val:  46.25%, val_best:  54.17%, tr:  99.59%, tr_best:  99.90%, epoch time: 70.30 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0695%\n",
      "layer   2  Sparsity: 77.2602%\n",
      "layer   3  Sparsity: 65.3747%\n",
      "total_backward_count 78320 real_backward_count 13346  17.040%\n",
      "epoch-8   lr=['0.0019531'], tr/val_loss:  1.827948/  1.991929, val:  54.17%, val_best:  54.17%, tr:  99.59%, tr_best:  99.90%, epoch time: 70.38 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1063%\n",
      "layer   2  Sparsity: 76.8233%\n",
      "layer   3  Sparsity: 65.3412%\n",
      "total_backward_count 88110 real_backward_count 14646  16.622%\n",
      "epoch-9   lr=['0.0019531'], tr/val_loss:  1.821805/  1.974538, val:  61.25%, val_best:  61.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 69.95 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0924%\n",
      "layer   2  Sparsity: 76.3306%\n",
      "layer   3  Sparsity: 65.2817%\n",
      "total_backward_count 97900 real_backward_count 15908  16.249%\n",
      "epoch-10  lr=['0.0019531'], tr/val_loss:  1.807129/  1.961599, val:  50.83%, val_best:  61.25%, tr:  99.80%, tr_best: 100.00%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0635%\n",
      "layer   2  Sparsity: 75.6817%\n",
      "layer   3  Sparsity: 65.3801%\n",
      "total_backward_count 107690 real_backward_count 17129  15.906%\n",
      "epoch-11  lr=['0.0019531'], tr/val_loss:  1.789787/  1.944255, val:  58.75%, val_best:  61.25%, tr:  99.59%, tr_best: 100.00%, epoch time: 71.05 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0872%\n",
      "layer   2  Sparsity: 76.3249%\n",
      "layer   3  Sparsity: 65.0388%\n",
      "total_backward_count 117480 real_backward_count 18324  15.598%\n",
      "epoch-12  lr=['0.0019531'], tr/val_loss:  1.805763/  1.983000, val:  49.58%, val_best:  61.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.10 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0832%\n",
      "layer   2  Sparsity: 75.5487%\n",
      "layer   3  Sparsity: 65.3236%\n",
      "total_backward_count 127270 real_backward_count 19569  15.376%\n",
      "epoch-13  lr=['0.0019531'], tr/val_loss:  1.798713/  1.950428, val:  59.17%, val_best:  61.25%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0908%\n",
      "layer   2  Sparsity: 75.3187%\n",
      "layer   3  Sparsity: 65.1461%\n",
      "total_backward_count 137060 real_backward_count 20761  15.147%\n",
      "epoch-14  lr=['0.0019531'], tr/val_loss:  1.803857/  1.983950, val:  57.08%, val_best:  61.25%, tr:  99.49%, tr_best: 100.00%, epoch time: 71.33 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0768%\n",
      "layer   2  Sparsity: 75.3030%\n",
      "layer   3  Sparsity: 65.3532%\n",
      "total_backward_count 146850 real_backward_count 21875  14.896%\n",
      "epoch-15  lr=['0.0019531'], tr/val_loss:  1.802805/  1.965979, val:  53.33%, val_best:  61.25%, tr:  99.59%, tr_best: 100.00%, epoch time: 71.41 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1105%\n",
      "layer   2  Sparsity: 74.9655%\n",
      "layer   3  Sparsity: 65.3149%\n",
      "total_backward_count 156640 real_backward_count 23019  14.695%\n",
      "epoch-16  lr=['0.0019531'], tr/val_loss:  1.791515/  1.957940, val:  50.00%, val_best:  61.25%, tr:  99.69%, tr_best: 100.00%, epoch time: 71.45 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0556%\n",
      "layer   2  Sparsity: 75.3692%\n",
      "layer   3  Sparsity: 65.4099%\n",
      "total_backward_count 166430 real_backward_count 24145  14.508%\n",
      "epoch-17  lr=['0.0019531'], tr/val_loss:  1.791032/  1.956260, val:  57.92%, val_best:  61.25%, tr:  99.80%, tr_best: 100.00%, epoch time: 70.75 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1093%\n",
      "layer   2  Sparsity: 75.2145%\n",
      "layer   3  Sparsity: 65.5012%\n",
      "total_backward_count 176220 real_backward_count 25262  14.335%\n",
      "epoch-18  lr=['0.0019531'], tr/val_loss:  1.786354/  1.936333, val:  60.00%, val_best:  61.25%, tr:  99.59%, tr_best: 100.00%, epoch time: 70.06 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0624%\n",
      "layer   2  Sparsity: 74.8797%\n",
      "layer   3  Sparsity: 65.6069%\n",
      "total_backward_count 186010 real_backward_count 26378  14.181%\n",
      "epoch-19  lr=['0.0019531'], tr/val_loss:  1.778335/  1.931462, val:  53.33%, val_best:  61.25%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.59 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0445%\n",
      "layer   2  Sparsity: 74.8840%\n",
      "layer   3  Sparsity: 66.3537%\n",
      "total_backward_count 195800 real_backward_count 27477  14.033%\n",
      "epoch-20  lr=['0.0019531'], tr/val_loss:  1.767697/  1.957679, val:  51.25%, val_best:  61.25%, tr:  99.80%, tr_best: 100.00%, epoch time: 70.52 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0872%\n",
      "layer   2  Sparsity: 74.5958%\n",
      "layer   3  Sparsity: 66.3426%\n",
      "total_backward_count 205590 real_backward_count 28547  13.885%\n",
      "epoch-21  lr=['0.0019531'], tr/val_loss:  1.771490/  1.912649, val:  60.83%, val_best:  61.25%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.12 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0838%\n",
      "layer   2  Sparsity: 74.0464%\n",
      "layer   3  Sparsity: 65.9950%\n",
      "total_backward_count 215380 real_backward_count 29603  13.745%\n",
      "epoch-22  lr=['0.0019531'], tr/val_loss:  1.754815/  1.905510, val:  65.00%, val_best:  65.00%, tr:  99.59%, tr_best: 100.00%, epoch time: 71.09 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0856%\n",
      "layer   2  Sparsity: 74.2450%\n",
      "layer   3  Sparsity: 66.2341%\n",
      "total_backward_count 225170 real_backward_count 30677  13.624%\n",
      "epoch-23  lr=['0.0019531'], tr/val_loss:  1.745381/  1.894129, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.92 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0640%\n",
      "layer   2  Sparsity: 73.3660%\n",
      "layer   3  Sparsity: 65.9348%\n",
      "total_backward_count 234960 real_backward_count 31679  13.483%\n",
      "epoch-24  lr=['0.0019531'], tr/val_loss:  1.739326/  1.887231, val:  62.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.45 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0853%\n",
      "layer   2  Sparsity: 73.7791%\n",
      "layer   3  Sparsity: 66.2360%\n",
      "total_backward_count 244750 real_backward_count 32706  13.363%\n",
      "epoch-25  lr=['0.0019531'], tr/val_loss:  1.744787/  1.903019, val:  64.58%, val_best:  75.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.35 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0858%\n",
      "layer   2  Sparsity: 73.4455%\n",
      "layer   3  Sparsity: 66.1325%\n",
      "total_backward_count 254540 real_backward_count 33676  13.230%\n",
      "epoch-26  lr=['0.0019531'], tr/val_loss:  1.753760/  1.903186, val:  64.17%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%, epoch time: 71.28 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0885%\n",
      "layer   2  Sparsity: 73.3781%\n",
      "layer   3  Sparsity: 67.0256%\n",
      "total_backward_count 264330 real_backward_count 34691  13.124%\n",
      "epoch-27  lr=['0.0019531'], tr/val_loss:  1.747558/  1.886574, val:  62.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.37 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0528%\n",
      "layer   2  Sparsity: 73.1587%\n",
      "layer   3  Sparsity: 66.1426%\n",
      "total_backward_count 274120 real_backward_count 35693  13.021%\n",
      "epoch-28  lr=['0.0019531'], tr/val_loss:  1.736563/  1.880099, val:  63.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.91 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0896%\n",
      "layer   2  Sparsity: 73.3192%\n",
      "layer   3  Sparsity: 67.2647%\n",
      "total_backward_count 283910 real_backward_count 36581  12.885%\n",
      "epoch-29  lr=['0.0019531'], tr/val_loss:  1.736204/  1.874483, val:  57.50%, val_best:  75.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.41 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0901%\n",
      "layer   2  Sparsity: 73.1372%\n",
      "layer   3  Sparsity: 67.3576%\n",
      "total_backward_count 293700 real_backward_count 37528  12.778%\n",
      "epoch-30  lr=['0.0019531'], tr/val_loss:  1.737090/  1.874574, val:  69.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0634%\n",
      "layer   2  Sparsity: 72.8987%\n",
      "layer   3  Sparsity: 68.2155%\n",
      "total_backward_count 303490 real_backward_count 38410  12.656%\n",
      "epoch-31  lr=['0.0019531'], tr/val_loss:  1.723074/  1.856825, val:  66.25%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.57 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0630%\n",
      "layer   2  Sparsity: 72.7803%\n",
      "layer   3  Sparsity: 67.4933%\n",
      "total_backward_count 313280 real_backward_count 39333  12.555%\n",
      "epoch-32  lr=['0.0019531'], tr/val_loss:  1.729137/  1.861553, val:  72.50%, val_best:  75.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0618%\n",
      "layer   2  Sparsity: 73.1792%\n",
      "layer   3  Sparsity: 67.6620%\n",
      "total_backward_count 323070 real_backward_count 40188  12.439%\n",
      "epoch-33  lr=['0.0019531'], tr/val_loss:  1.723567/  1.860287, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.17 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0635%\n",
      "layer   2  Sparsity: 72.5349%\n",
      "layer   3  Sparsity: 68.1637%\n",
      "total_backward_count 332860 real_backward_count 41085  12.343%\n",
      "epoch-34  lr=['0.0019531'], tr/val_loss:  1.713332/  1.864243, val:  65.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.42 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0617%\n",
      "layer   2  Sparsity: 72.4435%\n",
      "layer   3  Sparsity: 68.4050%\n",
      "total_backward_count 342650 real_backward_count 41936  12.239%\n",
      "epoch-35  lr=['0.0019531'], tr/val_loss:  1.711965/  1.860490, val:  69.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.36 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0950%\n",
      "layer   2  Sparsity: 72.8013%\n",
      "layer   3  Sparsity: 68.1957%\n",
      "total_backward_count 352440 real_backward_count 42810  12.147%\n",
      "epoch-36  lr=['0.0019531'], tr/val_loss:  1.702862/  1.845048, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0582%\n",
      "layer   2  Sparsity: 72.6618%\n",
      "layer   3  Sparsity: 68.2413%\n",
      "total_backward_count 362230 real_backward_count 43598  12.036%\n",
      "epoch-37  lr=['0.0019531'], tr/val_loss:  1.706145/  1.834185, val:  69.58%, val_best:  77.92%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.30 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0546%\n",
      "layer   2  Sparsity: 72.8400%\n",
      "layer   3  Sparsity: 67.8258%\n",
      "total_backward_count 372020 real_backward_count 44441  11.946%\n",
      "epoch-38  lr=['0.0019531'], tr/val_loss:  1.696024/  1.820935, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.24 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0525%\n",
      "layer   2  Sparsity: 72.6999%\n",
      "layer   3  Sparsity: 67.9056%\n",
      "total_backward_count 381810 real_backward_count 45213  11.842%\n",
      "epoch-39  lr=['0.0019531'], tr/val_loss:  1.694614/  1.834249, val:  83.75%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.47 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0794%\n",
      "layer   2  Sparsity: 72.8126%\n",
      "layer   3  Sparsity: 67.5367%\n",
      "total_backward_count 391600 real_backward_count 45997  11.746%\n",
      "epoch-40  lr=['0.0019531'], tr/val_loss:  1.691675/  1.828476, val:  67.92%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.41 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0741%\n",
      "layer   2  Sparsity: 72.7849%\n",
      "layer   3  Sparsity: 66.9531%\n",
      "total_backward_count 401390 real_backward_count 46733  11.643%\n",
      "epoch-41  lr=['0.0019531'], tr/val_loss:  1.689463/  1.847516, val:  59.17%, val_best:  83.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.81 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0794%\n",
      "layer   2  Sparsity: 72.2693%\n",
      "layer   3  Sparsity: 67.1135%\n",
      "total_backward_count 411180 real_backward_count 47505  11.553%\n",
      "epoch-42  lr=['0.0019531'], tr/val_loss:  1.691042/  1.842149, val:  79.17%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0747%\n",
      "layer   2  Sparsity: 72.0692%\n",
      "layer   3  Sparsity: 67.3917%\n",
      "total_backward_count 420970 real_backward_count 48269  11.466%\n",
      "epoch-43  lr=['0.0019531'], tr/val_loss:  1.698068/  1.840945, val:  69.17%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.40 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0931%\n",
      "layer   2  Sparsity: 72.2457%\n",
      "layer   3  Sparsity: 67.0342%\n",
      "total_backward_count 430760 real_backward_count 49001  11.375%\n",
      "epoch-44  lr=['0.0019531'], tr/val_loss:  1.673245/  1.821885, val:  77.50%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.68 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0627%\n",
      "layer   2  Sparsity: 72.7964%\n",
      "layer   3  Sparsity: 67.8286%\n",
      "total_backward_count 440550 real_backward_count 49715  11.285%\n",
      "epoch-45  lr=['0.0019531'], tr/val_loss:  1.677145/  1.819095, val:  76.25%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.43 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 72.6284%\n",
      "layer   3  Sparsity: 67.9740%\n",
      "total_backward_count 450340 real_backward_count 50422  11.196%\n",
      "epoch-46  lr=['0.0019531'], tr/val_loss:  1.681328/  1.811264, val:  82.08%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.13 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0532%\n",
      "layer   2  Sparsity: 72.7936%\n",
      "layer   3  Sparsity: 67.7380%\n",
      "total_backward_count 460130 real_backward_count 51137  11.114%\n",
      "epoch-47  lr=['0.0019531'], tr/val_loss:  1.667782/  1.813070, val:  84.17%, val_best:  84.17%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.03 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0917%\n",
      "layer   2  Sparsity: 72.2169%\n",
      "layer   3  Sparsity: 67.7060%\n",
      "total_backward_count 469920 real_backward_count 51817  11.027%\n",
      "epoch-48  lr=['0.0019531'], tr/val_loss:  1.666513/  1.802103, val:  85.42%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.48 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0708%\n",
      "layer   2  Sparsity: 71.8968%\n",
      "layer   3  Sparsity: 66.9562%\n",
      "total_backward_count 479710 real_backward_count 52539  10.952%\n",
      "epoch-49  lr=['0.0019531'], tr/val_loss:  1.666408/  1.817372, val:  78.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.57 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0691%\n",
      "layer   2  Sparsity: 72.4167%\n",
      "layer   3  Sparsity: 67.3619%\n",
      "total_backward_count 489500 real_backward_count 53178  10.864%\n",
      "epoch-50  lr=['0.0019531'], tr/val_loss:  1.670393/  1.806553, val:  74.58%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.01 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0917%\n",
      "layer   2  Sparsity: 72.5320%\n",
      "layer   3  Sparsity: 67.7861%\n",
      "total_backward_count 499290 real_backward_count 53911  10.798%\n",
      "epoch-51  lr=['0.0019531'], tr/val_loss:  1.659270/  1.794836, val:  83.75%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.14 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0784%\n",
      "layer   2  Sparsity: 72.4119%\n",
      "layer   3  Sparsity: 67.6220%\n",
      "total_backward_count 509080 real_backward_count 54588  10.723%\n",
      "epoch-52  lr=['0.0019531'], tr/val_loss:  1.648253/  1.802808, val:  81.25%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1015%\n",
      "layer   2  Sparsity: 72.1994%\n",
      "layer   3  Sparsity: 67.8435%\n",
      "total_backward_count 518870 real_backward_count 55274  10.653%\n",
      "epoch-53  lr=['0.0019531'], tr/val_loss:  1.661393/  1.802128, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.83 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0833%\n",
      "layer   2  Sparsity: 72.0213%\n",
      "layer   3  Sparsity: 68.2924%\n",
      "total_backward_count 528660 real_backward_count 55948  10.583%\n",
      "epoch-54  lr=['0.0019531'], tr/val_loss:  1.651355/  1.801068, val:  81.25%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.84 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0983%\n",
      "layer   2  Sparsity: 72.0123%\n",
      "layer   3  Sparsity: 68.3885%\n",
      "total_backward_count 538450 real_backward_count 56569  10.506%\n",
      "epoch-55  lr=['0.0019531'], tr/val_loss:  1.658028/  1.779831, val:  83.33%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.53 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 72.2779%\n",
      "layer   3  Sparsity: 68.8751%\n",
      "total_backward_count 548240 real_backward_count 57228  10.438%\n",
      "epoch-56  lr=['0.0019531'], tr/val_loss:  1.658102/  1.782757, val:  85.42%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.72 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0396%\n",
      "layer   2  Sparsity: 72.3521%\n",
      "layer   3  Sparsity: 68.7539%\n",
      "total_backward_count 558030 real_backward_count 57865  10.370%\n",
      "epoch-57  lr=['0.0019531'], tr/val_loss:  1.646718/  1.777299, val:  82.50%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.72 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 71.9013%\n",
      "layer   3  Sparsity: 68.3170%\n",
      "total_backward_count 567820 real_backward_count 58483  10.300%\n",
      "epoch-58  lr=['0.0019531'], tr/val_loss:  1.636836/  1.795899, val:  66.67%, val_best:  85.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0914%\n",
      "layer   2  Sparsity: 71.9540%\n",
      "layer   3  Sparsity: 68.9890%\n",
      "total_backward_count 577610 real_backward_count 59078  10.228%\n",
      "epoch-59  lr=['0.0019531'], tr/val_loss:  1.636913/  1.768716, val:  82.08%, val_best:  85.42%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0576%\n",
      "layer   2  Sparsity: 71.8557%\n",
      "layer   3  Sparsity: 68.5289%\n",
      "total_backward_count 587400 real_backward_count 59683  10.161%\n",
      "epoch-60  lr=['0.0019531'], tr/val_loss:  1.635962/  1.753256, val:  86.25%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.34 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1245%\n",
      "layer   2  Sparsity: 71.4295%\n",
      "layer   3  Sparsity: 67.4689%\n",
      "total_backward_count 597190 real_backward_count 60326  10.102%\n",
      "epoch-61  lr=['0.0019531'], tr/val_loss:  1.632556/  1.770410, val:  75.83%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.03 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1056%\n",
      "layer   2  Sparsity: 71.3647%\n",
      "layer   3  Sparsity: 67.5312%\n",
      "total_backward_count 606980 real_backward_count 60925  10.037%\n",
      "epoch-62  lr=['0.0019531'], tr/val_loss:  1.625608/  1.746227, val:  85.42%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.85 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0639%\n",
      "layer   2  Sparsity: 71.6336%\n",
      "layer   3  Sparsity: 68.0093%\n",
      "total_backward_count 616770 real_backward_count 61496   9.971%\n",
      "epoch-63  lr=['0.0019531'], tr/val_loss:  1.620143/  1.772421, val:  70.00%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.52 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0388%\n",
      "layer   2  Sparsity: 71.7218%\n",
      "layer   3  Sparsity: 68.3676%\n",
      "total_backward_count 626560 real_backward_count 62085   9.909%\n",
      "epoch-64  lr=['0.0019531'], tr/val_loss:  1.620484/  1.746519, val:  86.25%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0516%\n",
      "layer   2  Sparsity: 71.8294%\n",
      "layer   3  Sparsity: 68.9751%\n",
      "total_backward_count 636350 real_backward_count 62688   9.851%\n",
      "epoch-65  lr=['0.0019531'], tr/val_loss:  1.624396/  1.756764, val:  82.50%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0782%\n",
      "layer   2  Sparsity: 71.6920%\n",
      "layer   3  Sparsity: 68.2416%\n",
      "total_backward_count 646140 real_backward_count 63271   9.792%\n",
      "epoch-66  lr=['0.0019531'], tr/val_loss:  1.623214/  1.777858, val:  80.83%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.10 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0817%\n",
      "layer   2  Sparsity: 71.5354%\n",
      "layer   3  Sparsity: 68.6618%\n",
      "total_backward_count 655930 real_backward_count 63827   9.731%\n",
      "epoch-67  lr=['0.0019531'], tr/val_loss:  1.628074/  1.781267, val:  67.92%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.03 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 71.6685%\n",
      "layer   3  Sparsity: 68.6315%\n",
      "total_backward_count 665720 real_backward_count 64358   9.667%\n",
      "epoch-68  lr=['0.0019531'], tr/val_loss:  1.630956/  1.748882, val:  86.25%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.93 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0787%\n",
      "layer   2  Sparsity: 71.3528%\n",
      "layer   3  Sparsity: 68.3602%\n",
      "total_backward_count 675510 real_backward_count 64893   9.607%\n",
      "epoch-69  lr=['0.0019531'], tr/val_loss:  1.619848/  1.768648, val:  82.08%, val_best:  86.25%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.79 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0564%\n",
      "layer   2  Sparsity: 71.6699%\n",
      "layer   3  Sparsity: 68.0541%\n",
      "total_backward_count 685300 real_backward_count 65433   9.548%\n",
      "epoch-70  lr=['0.0019531'], tr/val_loss:  1.608805/  1.733159, val:  87.08%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.36 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1189%\n",
      "layer   2  Sparsity: 71.9873%\n",
      "layer   3  Sparsity: 68.2707%\n",
      "total_backward_count 695090 real_backward_count 65996   9.495%\n",
      "epoch-71  lr=['0.0019531'], tr/val_loss:  1.584719/  1.738866, val:  75.42%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.99 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0837%\n",
      "layer   2  Sparsity: 71.6834%\n",
      "layer   3  Sparsity: 68.3591%\n",
      "total_backward_count 704880 real_backward_count 66510   9.436%\n",
      "epoch-72  lr=['0.0019531'], tr/val_loss:  1.593969/  1.753697, val:  86.25%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0468%\n",
      "layer   2  Sparsity: 71.5253%\n",
      "layer   3  Sparsity: 68.2145%\n",
      "total_backward_count 714670 real_backward_count 67002   9.375%\n",
      "epoch-73  lr=['0.0019531'], tr/val_loss:  1.597977/  1.730024, val:  83.75%, val_best:  87.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.14 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0850%\n",
      "layer   2  Sparsity: 71.0635%\n",
      "layer   3  Sparsity: 67.4869%\n",
      "total_backward_count 724460 real_backward_count 67489   9.316%\n",
      "epoch-74  lr=['0.0019531'], tr/val_loss:  1.586938/  1.720835, val:  89.58%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0611%\n",
      "layer   2  Sparsity: 71.4528%\n",
      "layer   3  Sparsity: 67.4017%\n",
      "total_backward_count 734250 real_backward_count 67995   9.260%\n",
      "epoch-75  lr=['0.0019531'], tr/val_loss:  1.587932/  1.734359, val:  84.58%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.07 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1075%\n",
      "layer   2  Sparsity: 71.4649%\n",
      "layer   3  Sparsity: 67.5972%\n",
      "total_backward_count 744040 real_backward_count 68486   9.205%\n",
      "epoch-76  lr=['0.0019531'], tr/val_loss:  1.582025/  1.718968, val:  88.75%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.67 seconds, 1.14 minutes\n",
      "layer   1  Sparsity: 91.0947%\n",
      "layer   2  Sparsity: 71.2487%\n",
      "layer   3  Sparsity: 67.9461%\n",
      "total_backward_count 753830 real_backward_count 68982   9.151%\n",
      "epoch-77  lr=['0.0019531'], tr/val_loss:  1.582978/  1.723164, val:  88.33%, val_best:  89.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 68.80 seconds, 1.15 minutes\n",
      "layer   1  Sparsity: 91.0785%\n",
      "layer   2  Sparsity: 71.2959%\n",
      "layer   3  Sparsity: 68.3881%\n",
      "total_backward_count 763620 real_backward_count 69465   9.097%\n",
      "epoch-78  lr=['0.0019531'], tr/val_loss:  1.583773/  1.721683, val:  91.67%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0694%\n",
      "layer   2  Sparsity: 71.4652%\n",
      "layer   3  Sparsity: 68.0828%\n",
      "total_backward_count 773410 real_backward_count 69976   9.048%\n",
      "epoch-79  lr=['0.0019531'], tr/val_loss:  1.574025/  1.720857, val:  72.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.50 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0698%\n",
      "layer   2  Sparsity: 71.3982%\n",
      "layer   3  Sparsity: 68.3124%\n",
      "total_backward_count 783200 real_backward_count 70434   8.993%\n",
      "epoch-80  lr=['0.0019531'], tr/val_loss:  1.586623/  1.714587, val:  83.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.05 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0727%\n",
      "layer   2  Sparsity: 70.9484%\n",
      "layer   3  Sparsity: 68.1341%\n",
      "total_backward_count 792990 real_backward_count 70900   8.941%\n",
      "epoch-81  lr=['0.0019531'], tr/val_loss:  1.569525/  1.702068, val:  89.58%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.67 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1220%\n",
      "layer   2  Sparsity: 71.0011%\n",
      "layer   3  Sparsity: 68.2451%\n",
      "total_backward_count 802780 real_backward_count 71353   8.888%\n",
      "epoch-82  lr=['0.0019531'], tr/val_loss:  1.571612/  1.730098, val:  81.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.71 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0586%\n",
      "layer   2  Sparsity: 71.0222%\n",
      "layer   3  Sparsity: 68.2551%\n",
      "total_backward_count 812570 real_backward_count 71805   8.837%\n",
      "epoch-83  lr=['0.0019531'], tr/val_loss:  1.574088/  1.718264, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.88 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1148%\n",
      "layer   2  Sparsity: 71.1548%\n",
      "layer   3  Sparsity: 68.1558%\n",
      "total_backward_count 822360 real_backward_count 72265   8.788%\n",
      "epoch-84  lr=['0.0019531'], tr/val_loss:  1.571070/  1.717871, val:  76.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.14 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0773%\n",
      "layer   2  Sparsity: 71.2465%\n",
      "layer   3  Sparsity: 68.0362%\n",
      "total_backward_count 832150 real_backward_count 72681   8.734%\n",
      "epoch-85  lr=['0.0019531'], tr/val_loss:  1.569196/  1.696224, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.63 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0545%\n",
      "layer   2  Sparsity: 71.0196%\n",
      "layer   3  Sparsity: 68.0553%\n",
      "total_backward_count 841940 real_backward_count 73119   8.685%\n",
      "epoch-86  lr=['0.0019531'], tr/val_loss:  1.561668/  1.707510, val:  88.33%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.93 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0788%\n",
      "layer   2  Sparsity: 70.9324%\n",
      "layer   3  Sparsity: 68.0632%\n",
      "total_backward_count 851730 real_backward_count 73594   8.641%\n",
      "epoch-87  lr=['0.0019531'], tr/val_loss:  1.566667/  1.724268, val:  75.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.72 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0811%\n",
      "layer   2  Sparsity: 71.2106%\n",
      "layer   3  Sparsity: 68.2374%\n",
      "total_backward_count 861520 real_backward_count 74024   8.592%\n",
      "epoch-88  lr=['0.0019531'], tr/val_loss:  1.555625/  1.698845, val:  78.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.86 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0559%\n",
      "layer   2  Sparsity: 71.2143%\n",
      "layer   3  Sparsity: 68.2294%\n",
      "total_backward_count 871310 real_backward_count 74470   8.547%\n",
      "epoch-89  lr=['0.0019531'], tr/val_loss:  1.554625/  1.708771, val:  84.58%, val_best:  91.67%, tr:  99.90%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1069%\n",
      "layer   2  Sparsity: 71.2437%\n",
      "layer   3  Sparsity: 68.2267%\n",
      "total_backward_count 881100 real_backward_count 74901   8.501%\n",
      "epoch-90  lr=['0.0019531'], tr/val_loss:  1.555954/  1.705830, val:  84.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 71.1444%\n",
      "layer   3  Sparsity: 68.3697%\n",
      "total_backward_count 890890 real_backward_count 75305   8.453%\n",
      "epoch-91  lr=['0.0019531'], tr/val_loss:  1.557055/  1.692001, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.11 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0474%\n",
      "layer   2  Sparsity: 71.0194%\n",
      "layer   3  Sparsity: 67.5202%\n",
      "total_backward_count 900680 real_backward_count 75759   8.411%\n",
      "epoch-92  lr=['0.0019531'], tr/val_loss:  1.539954/  1.683599, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.40 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0736%\n",
      "layer   2  Sparsity: 70.8435%\n",
      "layer   3  Sparsity: 67.9395%\n",
      "total_backward_count 910470 real_backward_count 76188   8.368%\n",
      "epoch-93  lr=['0.0019531'], tr/val_loss:  1.539830/  1.704961, val:  78.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.46 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0362%\n",
      "layer   2  Sparsity: 70.7056%\n",
      "layer   3  Sparsity: 68.3165%\n",
      "total_backward_count 920260 real_backward_count 76579   8.321%\n",
      "epoch-94  lr=['0.0019531'], tr/val_loss:  1.540416/  1.699105, val:  77.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.70 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 70.8424%\n",
      "layer   3  Sparsity: 68.1599%\n",
      "total_backward_count 930050 real_backward_count 77011   8.280%\n",
      "epoch-95  lr=['0.0019531'], tr/val_loss:  1.550271/  1.705180, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.01 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1081%\n",
      "layer   2  Sparsity: 70.6609%\n",
      "layer   3  Sparsity: 68.1724%\n",
      "total_backward_count 939840 real_backward_count 77427   8.238%\n",
      "epoch-96  lr=['0.0019531'], tr/val_loss:  1.547464/  1.684690, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0637%\n",
      "layer   2  Sparsity: 70.9736%\n",
      "layer   3  Sparsity: 68.2510%\n",
      "total_backward_count 949630 real_backward_count 77882   8.201%\n",
      "epoch-97  lr=['0.0019531'], tr/val_loss:  1.540860/  1.686532, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.92 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0497%\n",
      "layer   2  Sparsity: 71.0335%\n",
      "layer   3  Sparsity: 67.6858%\n",
      "total_backward_count 959420 real_backward_count 78289   8.160%\n",
      "epoch-98  lr=['0.0019531'], tr/val_loss:  1.532530/  1.681676, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.97 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1352%\n",
      "layer   2  Sparsity: 71.2235%\n",
      "layer   3  Sparsity: 68.2262%\n",
      "total_backward_count 969210 real_backward_count 78676   8.118%\n",
      "epoch-99  lr=['0.0019531'], tr/val_loss:  1.535908/  1.688140, val:  86.67%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0969%\n",
      "layer   2  Sparsity: 71.2366%\n",
      "layer   3  Sparsity: 68.5386%\n",
      "total_backward_count 979000 real_backward_count 79049   8.074%\n",
      "epoch-100 lr=['0.0019531'], tr/val_loss:  1.538566/  1.666781, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1079%\n",
      "layer   2  Sparsity: 71.1700%\n",
      "layer   3  Sparsity: 68.5229%\n",
      "total_backward_count 988790 real_backward_count 79414   8.031%\n",
      "epoch-101 lr=['0.0019531'], tr/val_loss:  1.528702/  1.676349, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.97 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0631%\n",
      "layer   2  Sparsity: 71.1864%\n",
      "layer   3  Sparsity: 68.3481%\n",
      "total_backward_count 998580 real_backward_count 79808   7.992%\n",
      "epoch-102 lr=['0.0019531'], tr/val_loss:  1.539699/  1.682348, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.93 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0893%\n",
      "layer   2  Sparsity: 70.8461%\n",
      "layer   3  Sparsity: 67.9403%\n",
      "total_backward_count 1008370 real_backward_count 80198   7.953%\n",
      "epoch-103 lr=['0.0019531'], tr/val_loss:  1.524363/  1.660076, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.21 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0626%\n",
      "layer   2  Sparsity: 70.9317%\n",
      "layer   3  Sparsity: 68.2769%\n",
      "total_backward_count 1018160 real_backward_count 80590   7.915%\n",
      "epoch-104 lr=['0.0019531'], tr/val_loss:  1.516589/  1.668485, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0667%\n",
      "layer   2  Sparsity: 71.0141%\n",
      "layer   3  Sparsity: 68.4817%\n",
      "total_backward_count 1027950 real_backward_count 80941   7.874%\n",
      "epoch-105 lr=['0.0019531'], tr/val_loss:  1.523537/  1.672474, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.10 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0917%\n",
      "layer   2  Sparsity: 71.0973%\n",
      "layer   3  Sparsity: 68.3219%\n",
      "total_backward_count 1037740 real_backward_count 81311   7.835%\n",
      "epoch-106 lr=['0.0019531'], tr/val_loss:  1.526144/  1.668502, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.87 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0741%\n",
      "layer   2  Sparsity: 71.2245%\n",
      "layer   3  Sparsity: 68.2586%\n",
      "total_backward_count 1047530 real_backward_count 81691   7.798%\n",
      "epoch-107 lr=['0.0019531'], tr/val_loss:  1.519901/  1.676109, val:  84.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.87 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0408%\n",
      "layer   2  Sparsity: 71.1785%\n",
      "layer   3  Sparsity: 68.2667%\n",
      "total_backward_count 1057320 real_backward_count 82046   7.760%\n",
      "epoch-108 lr=['0.0019531'], tr/val_loss:  1.509247/  1.661144, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.99 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0763%\n",
      "layer   2  Sparsity: 71.2053%\n",
      "layer   3  Sparsity: 68.6899%\n",
      "total_backward_count 1067110 real_backward_count 82388   7.721%\n",
      "epoch-109 lr=['0.0019531'], tr/val_loss:  1.512123/  1.666949, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1054%\n",
      "layer   2  Sparsity: 71.2116%\n",
      "layer   3  Sparsity: 68.6374%\n",
      "total_backward_count 1076900 real_backward_count 82735   7.683%\n",
      "epoch-110 lr=['0.0019531'], tr/val_loss:  1.514040/  1.676990, val:  81.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.35 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1124%\n",
      "layer   2  Sparsity: 70.9868%\n",
      "layer   3  Sparsity: 68.5176%\n",
      "total_backward_count 1086690 real_backward_count 83096   7.647%\n",
      "epoch-111 lr=['0.0019531'], tr/val_loss:  1.505659/  1.657292, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.99 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0703%\n",
      "layer   2  Sparsity: 70.8405%\n",
      "layer   3  Sparsity: 68.6007%\n",
      "total_backward_count 1096480 real_backward_count 83447   7.610%\n",
      "epoch-112 lr=['0.0019531'], tr/val_loss:  1.518123/  1.659760, val:  83.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.82 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0706%\n",
      "layer   2  Sparsity: 70.8273%\n",
      "layer   3  Sparsity: 68.4448%\n",
      "total_backward_count 1106270 real_backward_count 83792   7.574%\n",
      "epoch-113 lr=['0.0019531'], tr/val_loss:  1.519623/  1.657040, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.95 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0827%\n",
      "layer   2  Sparsity: 70.5517%\n",
      "layer   3  Sparsity: 68.0399%\n",
      "total_backward_count 1116060 real_backward_count 84124   7.538%\n",
      "epoch-114 lr=['0.0019531'], tr/val_loss:  1.508744/  1.664505, val:  83.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.83 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0752%\n",
      "layer   2  Sparsity: 70.9158%\n",
      "layer   3  Sparsity: 68.3256%\n",
      "total_backward_count 1125850 real_backward_count 84485   7.504%\n",
      "epoch-115 lr=['0.0019531'], tr/val_loss:  1.507755/  1.658532, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.51 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0736%\n",
      "layer   2  Sparsity: 70.7464%\n",
      "layer   3  Sparsity: 67.8522%\n",
      "total_backward_count 1135640 real_backward_count 84816   7.469%\n",
      "epoch-116 lr=['0.0019531'], tr/val_loss:  1.507870/  1.649760, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.42 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0915%\n",
      "layer   2  Sparsity: 70.8079%\n",
      "layer   3  Sparsity: 68.1603%\n",
      "total_backward_count 1145430 real_backward_count 85157   7.435%\n",
      "epoch-117 lr=['0.0019531'], tr/val_loss:  1.504079/  1.651188, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.23 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0414%\n",
      "layer   2  Sparsity: 70.9283%\n",
      "layer   3  Sparsity: 68.2196%\n",
      "total_backward_count 1155220 real_backward_count 85489   7.400%\n",
      "epoch-118 lr=['0.0019531'], tr/val_loss:  1.507655/  1.641364, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.54 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0998%\n",
      "layer   2  Sparsity: 71.1986%\n",
      "layer   3  Sparsity: 68.2742%\n",
      "total_backward_count 1165010 real_backward_count 85823   7.367%\n",
      "epoch-119 lr=['0.0019531'], tr/val_loss:  1.506215/  1.640910, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.06 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0975%\n",
      "layer   2  Sparsity: 70.8644%\n",
      "layer   3  Sparsity: 67.9528%\n",
      "total_backward_count 1174800 real_backward_count 86147   7.333%\n",
      "epoch-120 lr=['0.0019531'], tr/val_loss:  1.500887/  1.639776, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.38 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0482%\n",
      "layer   2  Sparsity: 71.0714%\n",
      "layer   3  Sparsity: 68.3769%\n",
      "total_backward_count 1184590 real_backward_count 86485   7.301%\n",
      "epoch-121 lr=['0.0019531'], tr/val_loss:  1.493221/  1.632130, val:  83.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0846%\n",
      "layer   2  Sparsity: 71.0929%\n",
      "layer   3  Sparsity: 68.8760%\n",
      "total_backward_count 1194380 real_backward_count 86807   7.268%\n",
      "epoch-122 lr=['0.0019531'], tr/val_loss:  1.489105/  1.620583, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.40 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0766%\n",
      "layer   2  Sparsity: 71.1663%\n",
      "layer   3  Sparsity: 68.8618%\n",
      "total_backward_count 1204170 real_backward_count 87076   7.231%\n",
      "epoch-123 lr=['0.0019531'], tr/val_loss:  1.494163/  1.634298, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.27 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0905%\n",
      "layer   2  Sparsity: 70.8445%\n",
      "layer   3  Sparsity: 68.6485%\n",
      "total_backward_count 1213960 real_backward_count 87378   7.198%\n",
      "epoch-124 lr=['0.0019531'], tr/val_loss:  1.485878/  1.632875, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.04 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1148%\n",
      "layer   2  Sparsity: 70.8494%\n",
      "layer   3  Sparsity: 69.0637%\n",
      "total_backward_count 1223750 real_backward_count 87675   7.164%\n",
      "epoch-125 lr=['0.0019531'], tr/val_loss:  1.488475/  1.636140, val:  85.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.13 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0793%\n",
      "layer   2  Sparsity: 70.9383%\n",
      "layer   3  Sparsity: 69.2194%\n",
      "total_backward_count 1233540 real_backward_count 87987   7.133%\n",
      "epoch-126 lr=['0.0019531'], tr/val_loss:  1.482896/  1.629286, val:  87.50%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.68 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1016%\n",
      "layer   2  Sparsity: 70.7929%\n",
      "layer   3  Sparsity: 69.0199%\n",
      "total_backward_count 1243330 real_backward_count 88298   7.102%\n",
      "epoch-127 lr=['0.0019531'], tr/val_loss:  1.481037/  1.621916, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.11 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1078%\n",
      "layer   2  Sparsity: 71.0270%\n",
      "layer   3  Sparsity: 68.8475%\n",
      "total_backward_count 1253120 real_backward_count 88572   7.068%\n",
      "epoch-128 lr=['0.0019531'], tr/val_loss:  1.475244/  1.624994, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.33 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.1113%\n",
      "layer   2  Sparsity: 71.1477%\n",
      "layer   3  Sparsity: 68.5840%\n",
      "total_backward_count 1262910 real_backward_count 88862   7.036%\n",
      "epoch-129 lr=['0.0019531'], tr/val_loss:  1.472077/  1.623096, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.27 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0768%\n",
      "layer   2  Sparsity: 71.2119%\n",
      "layer   3  Sparsity: 68.8270%\n",
      "total_backward_count 1272700 real_backward_count 89139   7.004%\n",
      "epoch-130 lr=['0.0019531'], tr/val_loss:  1.465663/  1.603249, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.45 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0829%\n",
      "layer   2  Sparsity: 71.0450%\n",
      "layer   3  Sparsity: 68.9960%\n",
      "total_backward_count 1282490 real_backward_count 89443   6.974%\n",
      "epoch-131 lr=['0.0019531'], tr/val_loss:  1.460222/  1.607591, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0645%\n",
      "layer   2  Sparsity: 71.1322%\n",
      "layer   3  Sparsity: 68.9285%\n",
      "total_backward_count 1292280 real_backward_count 89717   6.943%\n",
      "epoch-132 lr=['0.0019531'], tr/val_loss:  1.468641/  1.616353, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.57 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0455%\n",
      "layer   2  Sparsity: 71.0521%\n",
      "layer   3  Sparsity: 68.8737%\n",
      "total_backward_count 1302070 real_backward_count 89988   6.911%\n",
      "epoch-133 lr=['0.0019531'], tr/val_loss:  1.470544/  1.614280, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.36 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 70.8377%\n",
      "layer   3  Sparsity: 68.2568%\n",
      "total_backward_count 1311860 real_backward_count 90262   6.880%\n",
      "epoch-134 lr=['0.0019531'], tr/val_loss:  1.463636/  1.613655, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.05 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0767%\n",
      "layer   2  Sparsity: 71.0319%\n",
      "layer   3  Sparsity: 68.3661%\n",
      "total_backward_count 1321650 real_backward_count 90568   6.853%\n",
      "epoch-135 lr=['0.0019531'], tr/val_loss:  1.467228/  1.603746, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.59 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0686%\n",
      "layer   2  Sparsity: 71.0927%\n",
      "layer   3  Sparsity: 68.7601%\n",
      "total_backward_count 1331440 real_backward_count 90845   6.823%\n",
      "epoch-136 lr=['0.0019531'], tr/val_loss:  1.465852/  1.614076, val:  84.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.98 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0964%\n",
      "layer   2  Sparsity: 71.1100%\n",
      "layer   3  Sparsity: 68.7369%\n",
      "total_backward_count 1341230 real_backward_count 91169   6.797%\n",
      "epoch-137 lr=['0.0019531'], tr/val_loss:  1.453759/  1.617376, val:  84.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.37 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0730%\n",
      "layer   2  Sparsity: 71.0668%\n",
      "layer   3  Sparsity: 68.8941%\n",
      "total_backward_count 1351020 real_backward_count 91440   6.768%\n",
      "epoch-138 lr=['0.0019531'], tr/val_loss:  1.457048/  1.609850, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.34 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0844%\n",
      "layer   2  Sparsity: 70.8315%\n",
      "layer   3  Sparsity: 69.1595%\n",
      "total_backward_count 1360810 real_backward_count 91682   6.737%\n",
      "epoch-139 lr=['0.0019531'], tr/val_loss:  1.451346/  1.621049, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.17 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0616%\n",
      "layer   2  Sparsity: 70.8807%\n",
      "layer   3  Sparsity: 68.9838%\n",
      "total_backward_count 1370600 real_backward_count 91931   6.707%\n",
      "epoch-140 lr=['0.0019531'], tr/val_loss:  1.457783/  1.600729, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.24 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1211%\n",
      "layer   2  Sparsity: 70.8601%\n",
      "layer   3  Sparsity: 68.4649%\n",
      "total_backward_count 1380390 real_backward_count 92205   6.680%\n",
      "epoch-141 lr=['0.0019531'], tr/val_loss:  1.454964/  1.609265, val:  86.25%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.08 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0950%\n",
      "layer   2  Sparsity: 71.0329%\n",
      "layer   3  Sparsity: 68.3590%\n",
      "total_backward_count 1390180 real_backward_count 92486   6.653%\n",
      "epoch-142 lr=['0.0019531'], tr/val_loss:  1.454758/  1.603693, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.19 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1008%\n",
      "layer   2  Sparsity: 71.1213%\n",
      "layer   3  Sparsity: 68.6630%\n",
      "total_backward_count 1399970 real_backward_count 92726   6.623%\n",
      "epoch-143 lr=['0.0019531'], tr/val_loss:  1.447566/  1.594458, val:  89.58%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.99 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0883%\n",
      "layer   2  Sparsity: 70.9372%\n",
      "layer   3  Sparsity: 68.5899%\n",
      "total_backward_count 1409760 real_backward_count 92988   6.596%\n",
      "epoch-144 lr=['0.0019531'], tr/val_loss:  1.453390/  1.608972, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.34 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0973%\n",
      "layer   2  Sparsity: 71.0631%\n",
      "layer   3  Sparsity: 68.8186%\n",
      "total_backward_count 1419550 real_backward_count 93261   6.570%\n",
      "epoch-145 lr=['0.0019531'], tr/val_loss:  1.444487/  1.607401, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.45 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0718%\n",
      "layer   2  Sparsity: 70.8835%\n",
      "layer   3  Sparsity: 68.7502%\n",
      "total_backward_count 1429340 real_backward_count 93515   6.543%\n",
      "epoch-146 lr=['0.0019531'], tr/val_loss:  1.447600/  1.593563, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 70.8785%\n",
      "layer   3  Sparsity: 68.7467%\n",
      "total_backward_count 1439130 real_backward_count 93784   6.517%\n",
      "epoch-147 lr=['0.0019531'], tr/val_loss:  1.441343/  1.590626, val:  88.75%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.18 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0316%\n",
      "layer   2  Sparsity: 70.6406%\n",
      "layer   3  Sparsity: 68.9918%\n",
      "total_backward_count 1448920 real_backward_count 94051   6.491%\n",
      "epoch-148 lr=['0.0019531'], tr/val_loss:  1.444400/  1.587843, val:  85.42%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.83 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0821%\n",
      "layer   2  Sparsity: 70.7691%\n",
      "layer   3  Sparsity: 68.8686%\n",
      "total_backward_count 1458710 real_backward_count 94299   6.465%\n",
      "epoch-149 lr=['0.0019531'], tr/val_loss:  1.434806/  1.591127, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.14 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0739%\n",
      "layer   2  Sparsity: 70.9925%\n",
      "layer   3  Sparsity: 68.7517%\n",
      "total_backward_count 1468500 real_backward_count 94528   6.437%\n",
      "epoch-150 lr=['0.0019531'], tr/val_loss:  1.446543/  1.597722, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.86 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0585%\n",
      "layer   2  Sparsity: 71.1167%\n",
      "layer   3  Sparsity: 68.7107%\n",
      "total_backward_count 1478290 real_backward_count 94797   6.413%\n",
      "epoch-151 lr=['0.0019531'], tr/val_loss:  1.434928/  1.585556, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.63 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0738%\n",
      "layer   2  Sparsity: 71.0077%\n",
      "layer   3  Sparsity: 68.7194%\n",
      "total_backward_count 1488080 real_backward_count 95040   6.387%\n",
      "epoch-152 lr=['0.0019531'], tr/val_loss:  1.429925/  1.593535, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.53 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0773%\n",
      "layer   2  Sparsity: 70.8063%\n",
      "layer   3  Sparsity: 68.9117%\n",
      "total_backward_count 1497870 real_backward_count 95274   6.361%\n",
      "epoch-153 lr=['0.0019531'], tr/val_loss:  1.433503/  1.582419, val:  90.83%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.71 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0961%\n",
      "layer   2  Sparsity: 70.7678%\n",
      "layer   3  Sparsity: 68.9796%\n",
      "total_backward_count 1507660 real_backward_count 95546   6.337%\n",
      "epoch-154 lr=['0.0019531'], tr/val_loss:  1.435883/  1.596258, val:  87.92%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.35 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0430%\n",
      "layer   2  Sparsity: 70.9292%\n",
      "layer   3  Sparsity: 69.1306%\n",
      "total_backward_count 1517450 real_backward_count 95762   6.311%\n",
      "epoch-155 lr=['0.0019531'], tr/val_loss:  1.435959/  1.590715, val:  90.00%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.44 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 70.8322%\n",
      "layer   3  Sparsity: 69.1830%\n",
      "total_backward_count 1527240 real_backward_count 96006   6.286%\n",
      "epoch-156 lr=['0.0019531'], tr/val_loss:  1.431154/  1.597220, val:  87.08%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.58 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0855%\n",
      "layer   2  Sparsity: 70.9049%\n",
      "layer   3  Sparsity: 69.3759%\n",
      "total_backward_count 1537030 real_backward_count 96234   6.261%\n",
      "epoch-157 lr=['0.0019531'], tr/val_loss:  1.430122/  1.581286, val:  89.17%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.49 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0953%\n",
      "layer   2  Sparsity: 70.7497%\n",
      "layer   3  Sparsity: 69.6122%\n",
      "total_backward_count 1546820 real_backward_count 96452   6.236%\n",
      "epoch-158 lr=['0.0019531'], tr/val_loss:  1.429103/  1.580940, val:  88.33%, val_best:  91.67%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.05 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0438%\n",
      "layer   2  Sparsity: 70.6184%\n",
      "layer   3  Sparsity: 69.8205%\n",
      "total_backward_count 1556610 real_backward_count 96644   6.209%\n",
      "epoch-159 lr=['0.0019531'], tr/val_loss:  1.424144/  1.560818, val:  92.08%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.27 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0756%\n",
      "layer   2  Sparsity: 70.5458%\n",
      "layer   3  Sparsity: 69.3759%\n",
      "total_backward_count 1566400 real_backward_count 96874   6.184%\n",
      "epoch-160 lr=['0.0019531'], tr/val_loss:  1.424527/  1.575861, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.93 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1078%\n",
      "layer   2  Sparsity: 70.7311%\n",
      "layer   3  Sparsity: 69.0481%\n",
      "total_backward_count 1576190 real_backward_count 97104   6.161%\n",
      "epoch-161 lr=['0.0019531'], tr/val_loss:  1.429852/  1.576823, val:  91.25%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.03 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0707%\n",
      "layer   2  Sparsity: 70.8983%\n",
      "layer   3  Sparsity: 68.2826%\n",
      "total_backward_count 1585980 real_backward_count 97342   6.138%\n",
      "epoch-162 lr=['0.0019531'], tr/val_loss:  1.429278/  1.572761, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.65 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0571%\n",
      "layer   2  Sparsity: 70.7834%\n",
      "layer   3  Sparsity: 68.1514%\n",
      "total_backward_count 1595770 real_backward_count 97559   6.114%\n",
      "epoch-163 lr=['0.0019531'], tr/val_loss:  1.415932/  1.584952, val:  82.92%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.89 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.1158%\n",
      "layer   2  Sparsity: 70.7338%\n",
      "layer   3  Sparsity: 68.4263%\n",
      "total_backward_count 1605560 real_backward_count 97762   6.089%\n",
      "epoch-164 lr=['0.0019531'], tr/val_loss:  1.415194/  1.576302, val:  87.50%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.51 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0615%\n",
      "layer   2  Sparsity: 70.6470%\n",
      "layer   3  Sparsity: 68.5521%\n",
      "total_backward_count 1615350 real_backward_count 97960   6.064%\n",
      "epoch-165 lr=['0.0019531'], tr/val_loss:  1.418829/  1.569396, val:  87.92%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.69 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 70.7647%\n",
      "layer   3  Sparsity: 68.6096%\n",
      "total_backward_count 1625140 real_backward_count 98202   6.043%\n",
      "epoch-166 lr=['0.0019531'], tr/val_loss:  1.414400/  1.588163, val:  89.17%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.35 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0623%\n",
      "layer   2  Sparsity: 70.8056%\n",
      "layer   3  Sparsity: 68.9286%\n",
      "total_backward_count 1634930 real_backward_count 98386   6.018%\n",
      "epoch-167 lr=['0.0019531'], tr/val_loss:  1.421305/  1.573777, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.26 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0631%\n",
      "layer   2  Sparsity: 70.7129%\n",
      "layer   3  Sparsity: 68.7400%\n",
      "total_backward_count 1644720 real_backward_count 98602   5.995%\n",
      "epoch-168 lr=['0.0019531'], tr/val_loss:  1.417011/  1.567376, val:  88.75%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.40 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0938%\n",
      "layer   2  Sparsity: 70.6359%\n",
      "layer   3  Sparsity: 68.5294%\n",
      "total_backward_count 1654510 real_backward_count 98848   5.974%\n",
      "epoch-169 lr=['0.0019531'], tr/val_loss:  1.409670/  1.569146, val:  88.33%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.48 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0660%\n",
      "layer   2  Sparsity: 70.8703%\n",
      "layer   3  Sparsity: 68.9009%\n",
      "total_backward_count 1664300 real_backward_count 99074   5.953%\n",
      "epoch-170 lr=['0.0019531'], tr/val_loss:  1.405608/  1.564072, val:  88.75%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.99 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0653%\n",
      "layer   2  Sparsity: 70.7422%\n",
      "layer   3  Sparsity: 68.9785%\n",
      "total_backward_count 1674090 real_backward_count 99279   5.930%\n",
      "epoch-171 lr=['0.0019531'], tr/val_loss:  1.397987/  1.576805, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.32 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0871%\n",
      "layer   2  Sparsity: 70.5446%\n",
      "layer   3  Sparsity: 68.9082%\n",
      "total_backward_count 1683880 real_backward_count 99515   5.910%\n",
      "epoch-172 lr=['0.0019531'], tr/val_loss:  1.406524/  1.566103, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.97 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0745%\n",
      "layer   2  Sparsity: 70.5591%\n",
      "layer   3  Sparsity: 69.0187%\n",
      "total_backward_count 1693670 real_backward_count 99742   5.889%\n",
      "epoch-173 lr=['0.0019531'], tr/val_loss:  1.393427/  1.543287, val:  86.25%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.30 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0805%\n",
      "layer   2  Sparsity: 70.6930%\n",
      "layer   3  Sparsity: 69.0127%\n",
      "total_backward_count 1703460 real_backward_count 99943   5.867%\n",
      "epoch-174 lr=['0.0019531'], tr/val_loss:  1.395321/  1.560598, val:  89.58%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.35 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0756%\n",
      "layer   2  Sparsity: 70.4395%\n",
      "layer   3  Sparsity: 68.7208%\n",
      "total_backward_count 1713250 real_backward_count 100174   5.847%\n",
      "epoch-175 lr=['0.0019531'], tr/val_loss:  1.401976/  1.553680, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.16 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 70.3463%\n",
      "layer   3  Sparsity: 68.5625%\n",
      "total_backward_count 1723040 real_backward_count 100376   5.826%\n",
      "epoch-176 lr=['0.0019531'], tr/val_loss:  1.396302/  1.555960, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.15 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0814%\n",
      "layer   2  Sparsity: 70.4650%\n",
      "layer   3  Sparsity: 68.9432%\n",
      "total_backward_count 1732830 real_backward_count 100567   5.804%\n",
      "epoch-177 lr=['0.0019531'], tr/val_loss:  1.394868/  1.560052, val:  86.67%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.92 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 70.5683%\n",
      "layer   3  Sparsity: 68.9319%\n",
      "total_backward_count 1742620 real_backward_count 100767   5.782%\n",
      "epoch-178 lr=['0.0019531'], tr/val_loss:  1.387811/  1.537835, val:  86.67%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.18 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.1008%\n",
      "layer   2  Sparsity: 70.5268%\n",
      "layer   3  Sparsity: 68.8733%\n",
      "total_backward_count 1752410 real_backward_count 100978   5.762%\n",
      "epoch-179 lr=['0.0019531'], tr/val_loss:  1.384704/  1.549060, val:  89.17%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.41 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0855%\n",
      "layer   2  Sparsity: 70.5998%\n",
      "layer   3  Sparsity: 69.3289%\n",
      "total_backward_count 1762200 real_backward_count 101156   5.740%\n",
      "epoch-180 lr=['0.0019531'], tr/val_loss:  1.388736/  1.540120, val:  88.75%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.62 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0904%\n",
      "layer   2  Sparsity: 70.7080%\n",
      "layer   3  Sparsity: 69.2932%\n",
      "total_backward_count 1771990 real_backward_count 101359   5.720%\n",
      "epoch-181 lr=['0.0019531'], tr/val_loss:  1.381929/  1.536477, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.94 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0985%\n",
      "layer   2  Sparsity: 70.6162%\n",
      "layer   3  Sparsity: 69.0873%\n",
      "total_backward_count 1781780 real_backward_count 101534   5.698%\n",
      "epoch-182 lr=['0.0019531'], tr/val_loss:  1.384737/  1.558878, val:  87.92%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.20 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0699%\n",
      "layer   2  Sparsity: 70.7726%\n",
      "layer   3  Sparsity: 68.8873%\n",
      "total_backward_count 1791570 real_backward_count 101735   5.679%\n",
      "epoch-183 lr=['0.0019531'], tr/val_loss:  1.396644/  1.559719, val:  88.33%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.40 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 70.8059%\n",
      "layer   3  Sparsity: 69.2810%\n",
      "total_backward_count 1801360 real_backward_count 101912   5.658%\n",
      "epoch-184 lr=['0.0019531'], tr/val_loss:  1.382010/  1.546594, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.56 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0972%\n",
      "layer   2  Sparsity: 70.8286%\n",
      "layer   3  Sparsity: 69.2084%\n",
      "total_backward_count 1811150 real_backward_count 102077   5.636%\n",
      "epoch-185 lr=['0.0019531'], tr/val_loss:  1.387289/  1.548690, val:  88.75%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.27 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0696%\n",
      "layer   2  Sparsity: 70.6458%\n",
      "layer   3  Sparsity: 69.3265%\n",
      "total_backward_count 1820940 real_backward_count 102258   5.616%\n",
      "epoch-186 lr=['0.0019531'], tr/val_loss:  1.383573/  1.545480, val:  87.92%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.32 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0458%\n",
      "layer   2  Sparsity: 70.5792%\n",
      "layer   3  Sparsity: 69.2752%\n",
      "total_backward_count 1830730 real_backward_count 102432   5.595%\n",
      "epoch-187 lr=['0.0019531'], tr/val_loss:  1.377646/  1.537782, val:  90.42%, val_best:  92.08%, tr:  99.90%, tr_best: 100.00%, epoch time: 70.80 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0608%\n",
      "layer   2  Sparsity: 70.4753%\n",
      "layer   3  Sparsity: 69.1471%\n",
      "total_backward_count 1840520 real_backward_count 102600   5.575%\n",
      "epoch-188 lr=['0.0019531'], tr/val_loss:  1.378540/  1.532577, val:  90.00%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.21 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0745%\n",
      "layer   2  Sparsity: 70.5818%\n",
      "layer   3  Sparsity: 68.6962%\n",
      "total_backward_count 1850310 real_backward_count 102796   5.556%\n",
      "epoch-189 lr=['0.0019531'], tr/val_loss:  1.371843/  1.538360, val:  87.50%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.18 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0698%\n",
      "layer   2  Sparsity: 70.5357%\n",
      "layer   3  Sparsity: 68.9779%\n",
      "total_backward_count 1860100 real_backward_count 102945   5.534%\n",
      "epoch-190 lr=['0.0019531'], tr/val_loss:  1.374083/  1.523142, val:  89.58%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 70.50 seconds, 1.17 minutes\n",
      "layer   1  Sparsity: 91.0423%\n",
      "layer   2  Sparsity: 70.5621%\n",
      "layer   3  Sparsity: 69.1534%\n",
      "total_backward_count 1869890 real_backward_count 103131   5.515%\n",
      "epoch-191 lr=['0.0019531'], tr/val_loss:  1.360379/  1.538236, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.39 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0864%\n",
      "layer   2  Sparsity: 70.7039%\n",
      "layer   3  Sparsity: 69.2660%\n",
      "total_backward_count 1879680 real_backward_count 103315   5.496%\n",
      "epoch-192 lr=['0.0019531'], tr/val_loss:  1.370415/  1.533630, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.18 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0610%\n",
      "layer   2  Sparsity: 70.4755%\n",
      "layer   3  Sparsity: 68.9322%\n",
      "total_backward_count 1889470 real_backward_count 103510   5.478%\n",
      "epoch-193 lr=['0.0019531'], tr/val_loss:  1.370219/  1.532603, val:  86.67%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.34 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0854%\n",
      "layer   2  Sparsity: 70.3840%\n",
      "layer   3  Sparsity: 68.9889%\n",
      "total_backward_count 1899260 real_backward_count 103682   5.459%\n",
      "epoch-194 lr=['0.0019531'], tr/val_loss:  1.365998/  1.526221, val:  89.17%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.07 seconds, 1.18 minutes\n",
      "layer   1  Sparsity: 91.0642%\n",
      "layer   2  Sparsity: 70.2538%\n",
      "layer   3  Sparsity: 68.9291%\n",
      "total_backward_count 1909050 real_backward_count 103857   5.440%\n",
      "epoch-195 lr=['0.0019531'], tr/val_loss:  1.366912/  1.533476, val:  89.58%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.23 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0959%\n",
      "layer   2  Sparsity: 70.3269%\n",
      "layer   3  Sparsity: 69.1227%\n",
      "total_backward_count 1918840 real_backward_count 104042   5.422%\n",
      "epoch-196 lr=['0.0019531'], tr/val_loss:  1.360966/  1.532747, val:  90.83%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.60 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 70.5005%\n",
      "layer   3  Sparsity: 69.1080%\n",
      "total_backward_count 1928630 real_backward_count 104206   5.403%\n",
      "epoch-197 lr=['0.0019531'], tr/val_loss:  1.364782/  1.538338, val:  90.42%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.58 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0822%\n",
      "layer   2  Sparsity: 70.4437%\n",
      "layer   3  Sparsity: 69.5299%\n",
      "total_backward_count 1938420 real_backward_count 104364   5.384%\n",
      "epoch-198 lr=['0.0019531'], tr/val_loss:  1.361615/  1.525290, val:  89.58%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.29 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0674%\n",
      "layer   2  Sparsity: 70.6156%\n",
      "layer   3  Sparsity: 69.8440%\n",
      "total_backward_count 1948210 real_backward_count 104527   5.365%\n",
      "epoch-199 lr=['0.0019531'], tr/val_loss:  1.355156/  1.520276, val:  89.17%, val_best:  92.08%, tr: 100.00%, tr_best: 100.00%, epoch time: 71.18 seconds, 1.19 minutes\n",
      "layer   1  Sparsity: 91.0817%\n",
      "layer   2  Sparsity: 70.7727%\n",
      "layer   3  Sparsity: 69.9084%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfbd033e2364513835880c29452ccf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>1.35516</td></tr><tr><td>val_acc_best</td><td>0.92083</td></tr><tr><td>val_acc_now</td><td>0.89167</td></tr><tr><td>val_loss</td><td>1.52028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-plasma-18936</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qze3nq7j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qze3nq7j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251119_032140-qze3nq7j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for high_seed in [1,2,3]:\n",
    "    ### my_snn control board (Gesture) ########################\n",
    "    decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "    # nda 0.25 # ottt 0.5\n",
    "\n",
    "    unique_name = 'main'\n",
    "    run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "\n",
    "    wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                    single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "                    unique_name = run_name,\n",
    "                    my_seed = high_seed,\n",
    "                    TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "                    BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "                    IMAGE_SIZE = 14, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                    # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                    # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "                    which_data = 'DVS_GESTURE_TONIC',\n",
    "    # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "    # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                    rate_coding = False, # True # False\n",
    "\n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = decay,\n",
    "                    lif_layer_v_threshold = 0.25,   #nda 0.5  #ottt 1.0\n",
    "                    lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "                    lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "                    synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False, # True # False\n",
    "                    convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                    # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                    # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "                    # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                    # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                    # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                    cfg = [200, 200], \n",
    "                    # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                    # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                    # cfg = ['M', 'M', 64], \n",
    "                    # cfg = [64, 124, 64, 124],\n",
    "                    # cfg = ['M','M',512], \n",
    "                    # cfg = [512], \n",
    "                    # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                    # cfg = ['M','M',512],\n",
    "                    # cfg = ['M',200],\n",
    "                    # cfg = [200,200],\n",
    "                    # cfg = ['M','M',200,200],\n",
    "                    # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                    # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                    # cfg = ['M',200,200],\n",
    "                    # cfg = ['M','M',1024,512,256,128,64],\n",
    "                    # cfg = [200,200],\n",
    "                    # cfg = [12], #fc\n",
    "                    # cfg = [12, 'M', 48, 'M', 12], \n",
    "                    # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "                    # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                    # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                    # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                    # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                    # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                    # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                    # cfg = [20001,10001], # depthwise, separable\n",
    "                    # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                    # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                    # cfg = [],        \n",
    "                    \n",
    "                    net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                    \n",
    "                    pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                    # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                    learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,  # True # False\n",
    "                    BN_on = False,  # True # False\n",
    "                    \n",
    "                    surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                    \n",
    "                    BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                    \n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 14, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "                    # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                    # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                    dvs_duration = 25_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                    # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                    # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "                    # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "                    # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "                    DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "                    trace_on = False,   # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                    extra_train_dataset = -1, \n",
    "\n",
    "                    num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "                    chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                    pin_memory = True, # True # False \n",
    "\n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = False, # True # False \n",
    "\n",
    "                    last_lif = False, # True # False \n",
    "\n",
    "                    temporal_filter = 5, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[[999,999],[999,999],[999,999]], # [[neuron_quant,feedback weight quant],[],[]]\n",
    "    # 1w -11~-9\n",
    "    # 1b -11~ -7\n",
    "    # 2w -10~-8\n",
    "    # 2b -10~-8\n",
    "    # 3w -10\n",
    "    # 3b -10\n",
    "                    ) \n",
    "\n",
    "    # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "    # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "    # num_workers = batch_size / num_GPU\n",
    "    # num_workers = batch_size / num_CPU\n",
    "\n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling  \n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# # Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"min\": 1, \"max\": 42000},\n",
    "#         # \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [1]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [4.5, 4.0, 3.5, 3.0, 2.5]},\n",
    "#         # \"lif_layer_sg_width\": {\"values\": [3.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "#         \"learning_rate\": {\"values\": [1/512]}, \n",
    "#         \"epoch_num\": {\"values\": [200]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [14]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [25_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [True]},\n",
    "#         \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [False]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [5]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "#         \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "\n",
    "#         \"scale_exp_1w\": {\"values\": [-10]},\n",
    "#         # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "#         \"scale_exp_2w\": {\"values\": [-10]},\n",
    "#         # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "#         \"scale_exp_3w\": {\"values\": [-9]},\n",
    "#         # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"4\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#         quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "#         scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "#                         ) \n",
    "#     # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "#     # average pooling\n",
    "#     # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "#     # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '4wosfk6x'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
