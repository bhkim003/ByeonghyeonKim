{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12494/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "            # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "            return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                        \n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        smallest_now_T = 99999\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "            if extra_train_dataset == -1:\n",
    "                # print(inputs.shape)\n",
    "                assert BATCH == 1\n",
    "                now_T = inputs.shape[1]\n",
    "                if epoch == 0 and now_T < smallest_now_T:\n",
    "                    smallest_now_T = now_T\n",
    "                    print(f'smallest_now_T updated: {smallest_now_T}')\n",
    "                now_time_steps = temporal_filter*TIME\n",
    "                if now_T < now_time_steps:\n",
    "                    # Î∂ÄÏ°±Ìïú timestep Í∞úÏàò\n",
    "                    diff = now_time_steps - now_T\n",
    "\n",
    "                    # ÎßàÏßÄÎßâ timestep Î≥µÏÇ¨ (shape: [B, 1, C, H, W])\n",
    "                    last_frame = inputs[:, -1:, :, :, :]\n",
    "\n",
    "                    # diffÎßåÌÅº repeatÌïòÏó¨ Ìå®Îî© Íµ¨ÏÑ±\n",
    "                    pad_frames = last_frame.repeat(1, diff, 1, 1, 1)\n",
    "\n",
    "                    # ÏõêÎ≥∏ + Ìå®Îî© Í≤∞Ìï©\n",
    "                    inputs = torch.cat([inputs, pad_frames], dim=1)\n",
    "                else:\n",
    "                    # start_idx = random.randint(0, now_T - now_time_steps)\n",
    "                    start_idx = random.choice(range(0, now_T - now_time_steps + 1, now_time_steps))\n",
    "                    # start_idx = random.choice([i for i in range(0, now_T - now_time_steps + 1, now_time_steps)])\n",
    "                    inputs = inputs[:, start_idx : start_idx + now_time_steps]\n",
    "                if dvs_clipping != 0:\n",
    "                    inputs[inputs<dvs_clipping] = 0.0\n",
    "                    inputs[inputs>=dvs_clipping] = 1.0\n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # if i % 1000 == 999:\n",
    "            #     # SYNAPSE_FCÏóê ÏûàÎäî sparsity_print_and_reset() Ïã§Ìñâ\n",
    "            #     for name, module in net.module.named_modules():\n",
    "            #         if isinstance(module, SYNAPSE_FC):\n",
    "            #             module.sparsity_print_and_reset()\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = (outputs_one_time.detach()).argmax(dim=1)\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            smallest_now_T_val = 99999\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if extra_train_dataset == -1:\n",
    "                            assert BATCH == 1\n",
    "                            now_T = inputs_val.shape[1]\n",
    "                            if epoch == 0 and now_T < smallest_now_T_val:\n",
    "                                smallest_now_T_val = now_T\n",
    "                                print(f'smallest_now_T_val updated: {smallest_now_T_val}')\n",
    "                            now_time_steps = temporal_filter*TIME\n",
    "\n",
    "                            if now_T < now_time_steps:\n",
    "                                # Î∂ÄÏ°±Ìïú timestep Í∞úÏàò\n",
    "                                diff = now_time_steps - now_T\n",
    "\n",
    "                                # ÎßàÏßÄÎßâ timestep Î≥µÏÇ¨ (shape: [B, 1, C, H, W])\n",
    "                                last_frame = inputs_val[:, -1:, :, :, :]\n",
    "\n",
    "                                # diffÎßåÌÅº repeatÌïòÏó¨ Ìå®Îî© Íµ¨ÏÑ±\n",
    "                                pad_frames = last_frame.repeat(1, diff, 1, 1, 1)\n",
    "\n",
    "                                # ÏõêÎ≥∏ + Ìå®Îî© Í≤∞Ìï©\n",
    "                                inputs_val = torch.cat([inputs_val, pad_frames], dim=1)\n",
    "                            else:\n",
    "                                pass\n",
    "                            \n",
    "                            start_idx = 0\n",
    "                            inputs_val = inputs_val[:, start_idx : start_idx + now_time_steps]\n",
    "\n",
    "                            if dvs_clipping != 0:\n",
    "                                inputs_val[inputs_val<dvs_clipping] = 0.0\n",
    "                                inputs_val[inputs_val>=dvs_clipping] = 1.0\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "                \n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.8\n",
    "                elif epoch > 150:\n",
    "                    assert val_acc_best > 0.88\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251126_101931-cdbx7y5e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cdbx7y5e' target=\"_blank\">volcanic-galaxy-19370</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cdbx7y5e' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cdbx7y5e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '5', 'single_step': True, 'unique_name': '20251126_101929_059', 'my_seed': 1, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 6.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.0009765625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 30, 'dvs_duration': 50000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[-10, -10], [-10, -10], [-9, -9]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 575149142d3019108310063e0e922290\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -10 -10\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: -10\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp -9 -9\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.25, v_reset=10000.0, sg_width=6.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[-10, -10], [-10, -10], [-9, -9]], ANPI_MODE=False)\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.0009765625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "smallest_now_T updated: 101\n",
      "fc layer 1 self.abs_max_out: 484.0\n",
      "lif layer 1 self.abs_max_v: 484.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 236.0\n",
      "lif layer 2 self.abs_max_v: 236.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 372.0\n",
      "lif layer 2 self.abs_max_v: 439.0\n",
      "fc layer 3 self.abs_max_out: 117.0\n",
      "fc layer 3 self.abs_max_out: 163.0\n",
      "fc layer 2 self.abs_max_out: 377.0\n",
      "lif layer 2 self.abs_max_v: 525.0\n",
      "fc layer 3 self.abs_max_out: 171.0\n",
      "lif layer 2 self.abs_max_v: 538.0\n",
      "fc layer 2 self.abs_max_out: 417.0\n",
      "fc layer 3 self.abs_max_out: 179.0\n",
      "fc layer 1 self.abs_max_out: 514.0\n",
      "lif layer 1 self.abs_max_v: 514.0\n",
      "fc layer 2 self.abs_max_out: 460.0\n",
      "lif layer 2 self.abs_max_v: 589.0\n",
      "lif layer 1 self.abs_max_v: 550.0\n",
      "fc layer 2 self.abs_max_out: 519.0\n",
      "lif layer 2 self.abs_max_v: 803.0\n",
      "fc layer 1 self.abs_max_out: 569.0\n",
      "lif layer 1 self.abs_max_v: 685.0\n",
      "fc layer 3 self.abs_max_out: 182.0\n",
      "fc layer 3 self.abs_max_out: 222.0\n",
      "fc layer 3 self.abs_max_out: 239.0\n",
      "fc layer 2 self.abs_max_out: 597.0\n",
      "fc layer 1 self.abs_max_out: 749.0\n",
      "lif layer 1 self.abs_max_v: 844.0\n",
      "fc layer 2 self.abs_max_out: 760.0\n",
      "lif layer 2 self.abs_max_v: 985.5\n",
      "lif layer 2 self.abs_max_v: 1055.0\n",
      "lif layer 1 self.abs_max_v: 1050.5\n",
      "fc layer 2 self.abs_max_out: 853.0\n",
      "lif layer 2 self.abs_max_v: 1078.0\n",
      "fc layer 3 self.abs_max_out: 241.0\n",
      "fc layer 1 self.abs_max_out: 774.0\n",
      "fc layer 1 self.abs_max_out: 777.0\n",
      "lif layer 2 self.abs_max_v: 1084.5\n",
      "fc layer 1 self.abs_max_out: 841.0\n",
      "lif layer 1 self.abs_max_v: 1066.0\n",
      "lif layer 2 self.abs_max_v: 1241.5\n",
      "fc layer 1 self.abs_max_out: 958.0\n",
      "lif layer 1 self.abs_max_v: 1276.0\n",
      "fc layer 3 self.abs_max_out: 247.0\n",
      "fc layer 2 self.abs_max_out: 1036.0\n",
      "lif layer 2 self.abs_max_v: 1459.5\n",
      "lif layer 2 self.abs_max_v: 1583.0\n",
      "fc layer 3 self.abs_max_out: 277.0\n",
      "fc layer 1 self.abs_max_out: 1165.0\n",
      "lif layer 1 self.abs_max_v: 1278.0\n",
      "fc layer 3 self.abs_max_out: 299.0\n",
      "fc layer 3 self.abs_max_out: 326.0\n",
      "fc layer 2 self.abs_max_out: 1059.0\n",
      "lif layer 1 self.abs_max_v: 1388.0\n",
      "lif layer 1 self.abs_max_v: 1402.0\n",
      "fc layer 1 self.abs_max_out: 1266.0\n",
      "smallest_now_T updated: 85\n",
      "fc layer 3 self.abs_max_out: 329.0\n",
      "lif layer 1 self.abs_max_v: 1418.5\n",
      "fc layer 3 self.abs_max_out: 331.0\n",
      "fc layer 3 self.abs_max_out: 335.0\n",
      "fc layer 3 self.abs_max_out: 362.0\n",
      "fc layer 3 self.abs_max_out: 377.0\n",
      "smallest_now_T updated: 82\n",
      "fc layer 2 self.abs_max_out: 1217.0\n",
      "lif layer 2 self.abs_max_v: 1604.5\n",
      "fc layer 3 self.abs_max_out: 392.0\n",
      "fc layer 1 self.abs_max_out: 1275.0\n",
      "fc layer 1 self.abs_max_out: 1389.0\n",
      "lif layer 2 self.abs_max_v: 1687.5\n",
      "lif layer 1 self.abs_max_v: 1785.5\n",
      "lif layer 2 self.abs_max_v: 1770.5\n",
      "fc layer 3 self.abs_max_out: 409.0\n",
      "fc layer 3 self.abs_max_out: 419.0\n",
      "fc layer 3 self.abs_max_out: 435.0\n",
      "fc layer 1 self.abs_max_out: 1423.0\n",
      "fc layer 3 self.abs_max_out: 461.0\n",
      "fc layer 2 self.abs_max_out: 1233.0\n",
      "lif layer 2 self.abs_max_v: 1956.0\n",
      "fc layer 1 self.abs_max_out: 1543.0\n",
      "smallest_now_T updated: 74\n",
      "fc layer 2 self.abs_max_out: 1274.0\n",
      "fc layer 2 self.abs_max_out: 1324.0\n",
      "lif layer 1 self.abs_max_v: 1838.5\n",
      "fc layer 1 self.abs_max_out: 1616.0\n",
      "fc layer 3 self.abs_max_out: 483.0\n",
      "fc layer 3 self.abs_max_out: 486.0\n",
      "smallest_now_T updated: 72\n",
      "smallest_now_T updated: 56\n",
      "fc layer 1 self.abs_max_out: 1820.0\n",
      "lif layer 2 self.abs_max_v: 2117.0\n",
      "lif layer 1 self.abs_max_v: 1925.0\n",
      "lif layer 1 self.abs_max_v: 1997.0\n",
      "lif layer 1 self.abs_max_v: 2390.0\n",
      "fc layer 3 self.abs_max_out: 498.0\n",
      "lif layer 1 self.abs_max_v: 2492.0\n",
      "lif layer 1 self.abs_max_v: 2510.0\n",
      "lif layer 1 self.abs_max_v: 2521.0\n",
      "fc layer 3 self.abs_max_out: 555.0\n",
      "fc layer 1 self.abs_max_out: 1849.0\n",
      "fc layer 2 self.abs_max_out: 1404.0\n",
      "fc layer 1 self.abs_max_out: 1925.0\n",
      "fc layer 1 self.abs_max_out: 2016.0\n",
      "lif layer 1 self.abs_max_v: 2544.5\n",
      "fc layer 3 self.abs_max_out: 571.0\n",
      "fc layer 2 self.abs_max_out: 1422.0\n",
      "smallest_now_T updated: 50\n",
      "lif layer 2 self.abs_max_v: 2210.0\n",
      "fc layer 3 self.abs_max_out: 572.0\n",
      "fc layer 2 self.abs_max_out: 1448.0\n",
      "fc layer 2 self.abs_max_out: 1470.0\n",
      "fc layer 1 self.abs_max_out: 2139.0\n",
      "fc layer 2 self.abs_max_out: 1486.0\n",
      "lif layer 2 self.abs_max_v: 2237.5\n",
      "fc layer 2 self.abs_max_out: 1492.0\n",
      "fc layer 2 self.abs_max_out: 1515.0\n",
      "fc layer 2 self.abs_max_out: 1601.0\n",
      "fc layer 2 self.abs_max_out: 1724.0\n",
      "fc layer 2 self.abs_max_out: 1780.0\n",
      "lif layer 1 self.abs_max_v: 2571.0\n",
      "lif layer 1 self.abs_max_v: 2763.5\n",
      "fc layer 3 self.abs_max_out: 615.0\n",
      "fc layer 1 self.abs_max_out: 2320.0\n",
      "lif layer 2 self.abs_max_v: 2358.5\n",
      "fc layer 3 self.abs_max_out: 627.0\n",
      "fc layer 1 self.abs_max_out: 2351.0\n",
      "fc layer 1 self.abs_max_out: 2515.0\n",
      "fc layer 1 self.abs_max_out: 2574.0\n",
      "smallest_now_T_val updated: 129\n",
      "smallest_now_T_val updated: 106\n",
      "smallest_now_T_val updated: 104\n",
      "smallest_now_T_val updated: 102\n",
      "smallest_now_T_val updated: 85\n",
      "smallest_now_T_val updated: 50\n",
      "lif layer 2 self.abs_max_v: 2489.0\n",
      "lif layer 1 self.abs_max_v: 2943.0\n",
      "fc layer 1 self.abs_max_out: 2743.0\n",
      "lif layer 1 self.abs_max_v: 2969.0\n",
      "lif layer 1 self.abs_max_v: 3277.5\n",
      "lif layer 2 self.abs_max_v: 2559.0\n",
      "lif layer 2 self.abs_max_v: 2580.5\n",
      "fc layer 1 self.abs_max_out: 2764.0\n",
      "epoch-0   lr=['0.0009766'], tr/val_loss:  1.930213/  2.065180, val:  36.25%, val_best:  36.25%, tr:  86.93%, tr_best:  86.93%, epoch time: 81.28 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7077%\n",
      "layer   2  Sparsity: 81.4337%\n",
      "layer   3  Sparsity: 75.4862%\n",
      "total_backward_count 9790 real_backward_count 3082  31.481%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "fc layer 3 self.abs_max_out: 657.0\n",
      "fc layer 3 self.abs_max_out: 693.0\n",
      "fc layer 1 self.abs_max_out: 3060.0\n",
      "lif layer 1 self.abs_max_v: 3408.5\n",
      "lif layer 1 self.abs_max_v: 3422.0\n",
      "lif layer 1 self.abs_max_v: 3815.0\n",
      "lif layer 1 self.abs_max_v: 4040.5\n",
      "epoch-1   lr=['0.0009766'], tr/val_loss:  1.865556/  2.014090, val:  40.00%, val_best:  40.00%, tr:  98.57%, tr_best:  98.57%, epoch time: 81.81 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7091%\n",
      "layer   2  Sparsity: 80.4722%\n",
      "layer   3  Sparsity: 71.8604%\n",
      "total_backward_count 19580 real_backward_count 4958  25.322%\n",
      "fc layer 2 self.abs_max_out: 1923.0\n",
      "fc layer 1 self.abs_max_out: 3108.0\n",
      "lif layer 2 self.abs_max_v: 2722.0\n",
      "epoch-2   lr=['0.0009766'], tr/val_loss:  1.859330/  1.991408, val:  53.75%, val_best:  53.75%, tr:  99.59%, tr_best:  99.59%, epoch time: 81.51 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7299%\n",
      "layer   2  Sparsity: 80.4139%\n",
      "layer   3  Sparsity: 71.3421%\n",
      "total_backward_count 29370 real_backward_count 6506  22.152%\n",
      "epoch-3   lr=['0.0009766'], tr/val_loss:  1.857545/  1.968206, val:  59.17%, val_best:  59.17%, tr:  99.69%, tr_best:  99.69%, epoch time: 82.45 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7094%\n",
      "layer   2  Sparsity: 80.0241%\n",
      "layer   3  Sparsity: 71.4146%\n",
      "total_backward_count 39160 real_backward_count 7907  20.192%\n",
      "fc layer 2 self.abs_max_out: 2029.0\n",
      "fc layer 1 self.abs_max_out: 3215.0\n",
      "lif layer 1 self.abs_max_v: 4076.5\n",
      "fc layer 1 self.abs_max_out: 3293.0\n",
      "lif layer 1 self.abs_max_v: 4353.5\n",
      "epoch-4   lr=['0.0009766'], tr/val_loss:  1.836071/  1.968663, val:  47.08%, val_best:  59.17%, tr:  99.49%, tr_best:  99.69%, epoch time: 81.92 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7002%\n",
      "layer   2  Sparsity: 79.6366%\n",
      "layer   3  Sparsity: 71.1701%\n",
      "total_backward_count 48950 real_backward_count 9225  18.846%\n",
      "fc layer 1 self.abs_max_out: 3330.0\n",
      "lif layer 1 self.abs_max_v: 4641.0\n",
      "epoch-5   lr=['0.0009766'], tr/val_loss:  1.834975/  1.960445, val:  65.00%, val_best:  65.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.69 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7403%\n",
      "layer   2  Sparsity: 79.6501%\n",
      "layer   3  Sparsity: 71.7952%\n",
      "total_backward_count 58740 real_backward_count 10471  17.826%\n",
      "epoch-6   lr=['0.0009766'], tr/val_loss:  1.830587/  1.988740, val:  59.17%, val_best:  65.00%, tr:  99.69%, tr_best: 100.00%, epoch time: 82.25 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7322%\n",
      "layer   2  Sparsity: 79.0497%\n",
      "layer   3  Sparsity: 71.9785%\n",
      "total_backward_count 68530 real_backward_count 11661  17.016%\n",
      "fc layer 2 self.abs_max_out: 2055.0\n",
      "lif layer 2 self.abs_max_v: 2762.5\n",
      "lif layer 2 self.abs_max_v: 2778.5\n",
      "lif layer 2 self.abs_max_v: 2956.0\n",
      "fc layer 1 self.abs_max_out: 3373.0\n",
      "fc layer 1 self.abs_max_out: 3422.0\n",
      "epoch-7   lr=['0.0009766'], tr/val_loss:  1.827347/  1.937846, val:  69.58%, val_best:  69.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.30 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7164%\n",
      "layer   2  Sparsity: 79.3938%\n",
      "layer   3  Sparsity: 72.4671%\n",
      "total_backward_count 78320 real_backward_count 12810  16.356%\n",
      "lif layer 1 self.abs_max_v: 4750.0\n",
      "lif layer 1 self.abs_max_v: 4791.0\n",
      "epoch-8   lr=['0.0009766'], tr/val_loss:  1.827949/  1.942207, val:  63.33%, val_best:  69.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.91 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7232%\n",
      "layer   2  Sparsity: 79.2105%\n",
      "layer   3  Sparsity: 73.4148%\n",
      "total_backward_count 88110 real_backward_count 13948  15.830%\n",
      "fc layer 2 self.abs_max_out: 2102.0\n",
      "lif layer 2 self.abs_max_v: 3123.5\n",
      "epoch-9   lr=['0.0009766'], tr/val_loss:  1.824839/  1.945242, val:  65.00%, val_best:  69.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.76 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7322%\n",
      "layer   2  Sparsity: 78.8721%\n",
      "layer   3  Sparsity: 73.5765%\n",
      "total_backward_count 97900 real_backward_count 15016  15.338%\n",
      "fc layer 1 self.abs_max_out: 3461.0\n",
      "epoch-10  lr=['0.0009766'], tr/val_loss:  1.825788/  1.939080, val:  75.00%, val_best:  75.00%, tr:  99.69%, tr_best: 100.00%, epoch time: 81.71 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7027%\n",
      "layer   2  Sparsity: 78.6650%\n",
      "layer   3  Sparsity: 73.7943%\n",
      "total_backward_count 107690 real_backward_count 16032  14.887%\n",
      "fc layer 1 self.abs_max_out: 3561.0\n",
      "lif layer 1 self.abs_max_v: 4825.5\n",
      "lif layer 1 self.abs_max_v: 5234.0\n",
      "lif layer 1 self.abs_max_v: 5266.0\n",
      "epoch-11  lr=['0.0009766'], tr/val_loss:  1.822480/  1.931555, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.91 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7046%\n",
      "layer   2  Sparsity: 78.4371%\n",
      "layer   3  Sparsity: 74.1495%\n",
      "total_backward_count 117480 real_backward_count 17009  14.478%\n",
      "lif layer 2 self.abs_max_v: 3137.5\n",
      "lif layer 2 self.abs_max_v: 3149.5\n",
      "epoch-12  lr=['0.0009766'], tr/val_loss:  1.812496/  1.912682, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.93 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7122%\n",
      "layer   2  Sparsity: 78.6518%\n",
      "layer   3  Sparsity: 74.5534%\n",
      "total_backward_count 127270 real_backward_count 17917  14.078%\n",
      "fc layer 2 self.abs_max_out: 2142.0\n",
      "fc layer 2 self.abs_max_out: 2201.0\n",
      "epoch-13  lr=['0.0009766'], tr/val_loss:  1.814458/  1.915556, val:  70.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.03 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7211%\n",
      "layer   2  Sparsity: 78.5784%\n",
      "layer   3  Sparsity: 74.4937%\n",
      "total_backward_count 137060 real_backward_count 18812  13.725%\n",
      "lif layer 2 self.abs_max_v: 3201.0\n",
      "fc layer 2 self.abs_max_out: 2205.0\n",
      "epoch-14  lr=['0.0009766'], tr/val_loss:  1.805527/  1.919974, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.85 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7045%\n",
      "layer   2  Sparsity: 78.6940%\n",
      "layer   3  Sparsity: 74.5175%\n",
      "total_backward_count 146850 real_backward_count 19737  13.440%\n",
      "fc layer 1 self.abs_max_out: 3696.0\n",
      "epoch-15  lr=['0.0009766'], tr/val_loss:  1.797918/  1.894889, val:  85.83%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.16 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7103%\n",
      "layer   2  Sparsity: 78.5686%\n",
      "layer   3  Sparsity: 74.4953%\n",
      "total_backward_count 156640 real_backward_count 20587  13.143%\n",
      "lif layer 1 self.abs_max_v: 5380.5\n",
      "fc layer 1 self.abs_max_out: 3706.0\n",
      "epoch-16  lr=['0.0009766'], tr/val_loss:  1.788284/  1.909988, val:  72.08%, val_best:  85.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.80 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7226%\n",
      "layer   2  Sparsity: 78.4559%\n",
      "layer   3  Sparsity: 74.9987%\n",
      "total_backward_count 166430 real_backward_count 21416  12.868%\n",
      "lif layer 1 self.abs_max_v: 5494.0\n",
      "fc layer 1 self.abs_max_out: 3778.0\n",
      "epoch-17  lr=['0.0009766'], tr/val_loss:  1.796247/  1.911654, val:  75.00%, val_best:  85.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.68 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6997%\n",
      "layer   2  Sparsity: 78.5292%\n",
      "layer   3  Sparsity: 75.2723%\n",
      "total_backward_count 176220 real_backward_count 22225  12.612%\n",
      "fc layer 1 self.abs_max_out: 3830.0\n",
      "epoch-18  lr=['0.0009766'], tr/val_loss:  1.793959/  1.886718, val:  81.25%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.25 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7049%\n",
      "layer   2  Sparsity: 78.3287%\n",
      "layer   3  Sparsity: 75.2859%\n",
      "total_backward_count 186010 real_backward_count 22998  12.364%\n",
      "lif layer 1 self.abs_max_v: 5534.5\n",
      "epoch-19  lr=['0.0009766'], tr/val_loss:  1.794233/  1.893307, val:  80.00%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.90 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7120%\n",
      "layer   2  Sparsity: 78.2754%\n",
      "layer   3  Sparsity: 75.4769%\n",
      "total_backward_count 195800 real_backward_count 23724  12.116%\n",
      "lif layer 1 self.abs_max_v: 5881.5\n",
      "fc layer 1 self.abs_max_out: 3921.0\n",
      "epoch-20  lr=['0.0009766'], tr/val_loss:  1.802395/  1.913149, val:  80.83%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.17 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7050%\n",
      "layer   2  Sparsity: 78.3101%\n",
      "layer   3  Sparsity: 75.3102%\n",
      "total_backward_count 205590 real_backward_count 24418  11.877%\n",
      "fc layer 1 self.abs_max_out: 3943.0\n",
      "lif layer 1 self.abs_max_v: 6164.5\n",
      "epoch-21  lr=['0.0009766'], tr/val_loss:  1.793387/  1.876482, val:  82.92%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.16 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7105%\n",
      "layer   2  Sparsity: 78.4749%\n",
      "layer   3  Sparsity: 75.4448%\n",
      "total_backward_count 215380 real_backward_count 25148  11.676%\n",
      "epoch-22  lr=['0.0009766'], tr/val_loss:  1.777456/  1.884453, val:  77.92%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.87 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7142%\n",
      "layer   2  Sparsity: 78.4417%\n",
      "layer   3  Sparsity: 76.1822%\n",
      "total_backward_count 225170 real_backward_count 25827  11.470%\n",
      "epoch-23  lr=['0.0009766'], tr/val_loss:  1.775328/  1.869179, val:  82.92%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.21 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7109%\n",
      "layer   2  Sparsity: 78.4540%\n",
      "layer   3  Sparsity: 75.8903%\n",
      "total_backward_count 234960 real_backward_count 26467  11.264%\n",
      "epoch-24  lr=['0.0009766'], tr/val_loss:  1.767308/  1.869040, val:  78.75%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.99 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7325%\n",
      "layer   2  Sparsity: 78.4211%\n",
      "layer   3  Sparsity: 76.0906%\n",
      "total_backward_count 244750 real_backward_count 27066  11.059%\n",
      "epoch-25  lr=['0.0009766'], tr/val_loss:  1.758760/  1.855770, val:  76.67%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.08 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7166%\n",
      "layer   2  Sparsity: 78.2927%\n",
      "layer   3  Sparsity: 76.2312%\n",
      "total_backward_count 254540 real_backward_count 27700  10.882%\n",
      "epoch-26  lr=['0.0009766'], tr/val_loss:  1.760463/  1.864945, val:  81.25%, val_best:  85.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 82.49 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7087%\n",
      "layer   2  Sparsity: 78.5113%\n",
      "layer   3  Sparsity: 76.1699%\n",
      "total_backward_count 264330 real_backward_count 28263  10.692%\n",
      "epoch-27  lr=['0.0009766'], tr/val_loss:  1.759022/  1.860207, val:  80.83%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.16 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7072%\n",
      "layer   2  Sparsity: 78.0483%\n",
      "layer   3  Sparsity: 75.7065%\n",
      "total_backward_count 274120 real_backward_count 28861  10.529%\n",
      "fc layer 1 self.abs_max_out: 4021.0\n",
      "epoch-28  lr=['0.0009766'], tr/val_loss:  1.759489/  1.853063, val:  82.50%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.82 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7396%\n",
      "layer   2  Sparsity: 78.0401%\n",
      "layer   3  Sparsity: 75.6689%\n",
      "total_backward_count 283910 real_backward_count 29442  10.370%\n",
      "lif layer 1 self.abs_max_v: 6501.5\n",
      "epoch-29  lr=['0.0009766'], tr/val_loss:  1.749858/  1.837831, val:  80.83%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.26 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7132%\n",
      "layer   2  Sparsity: 78.0848%\n",
      "layer   3  Sparsity: 75.6123%\n",
      "total_backward_count 293700 real_backward_count 29981  10.208%\n",
      "fc layer 1 self.abs_max_out: 4072.0\n",
      "epoch-30  lr=['0.0009766'], tr/val_loss:  1.739941/  1.839814, val:  83.33%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.51 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7226%\n",
      "layer   2  Sparsity: 78.2226%\n",
      "layer   3  Sparsity: 76.0337%\n",
      "total_backward_count 303490 real_backward_count 30517  10.055%\n",
      "fc layer 1 self.abs_max_out: 4139.0\n",
      "lif layer 1 self.abs_max_v: 6547.5\n",
      "epoch-31  lr=['0.0009766'], tr/val_loss:  1.735640/  1.841817, val:  77.92%, val_best:  85.83%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.78 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6988%\n",
      "layer   2  Sparsity: 78.0221%\n",
      "layer   3  Sparsity: 75.7923%\n",
      "total_backward_count 313280 real_backward_count 31054   9.913%\n",
      "lif layer 2 self.abs_max_v: 3264.5\n",
      "epoch-32  lr=['0.0009766'], tr/val_loss:  1.721271/  1.827355, val:  85.83%, val_best:  85.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.18 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7148%\n",
      "layer   2  Sparsity: 77.8958%\n",
      "layer   3  Sparsity: 75.8124%\n",
      "total_backward_count 323070 real_backward_count 31591   9.778%\n",
      "epoch-33  lr=['0.0009766'], tr/val_loss:  1.711155/  1.811832, val:  87.50%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.66 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7338%\n",
      "layer   2  Sparsity: 78.0030%\n",
      "layer   3  Sparsity: 75.7738%\n",
      "total_backward_count 332860 real_backward_count 32108   9.646%\n",
      "epoch-34  lr=['0.0009766'], tr/val_loss:  1.716852/  1.821526, val:  84.17%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.44 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7423%\n",
      "layer   2  Sparsity: 77.8399%\n",
      "layer   3  Sparsity: 75.8155%\n",
      "total_backward_count 342650 real_backward_count 32576   9.507%\n",
      "epoch-35  lr=['0.0009766'], tr/val_loss:  1.709945/  1.816862, val:  83.33%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.85 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7188%\n",
      "layer   2  Sparsity: 77.8968%\n",
      "layer   3  Sparsity: 75.9432%\n",
      "total_backward_count 352440 real_backward_count 33027   9.371%\n",
      "fc layer 2 self.abs_max_out: 2215.0\n",
      "epoch-36  lr=['0.0009766'], tr/val_loss:  1.702049/  1.806710, val:  84.17%, val_best:  87.50%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.55 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7159%\n",
      "layer   2  Sparsity: 77.6364%\n",
      "layer   3  Sparsity: 75.8372%\n",
      "total_backward_count 362230 real_backward_count 33505   9.250%\n",
      "epoch-37  lr=['0.0009766'], tr/val_loss:  1.703309/  1.810310, val:  82.08%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.88 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7619%\n",
      "layer   2  Sparsity: 77.6825%\n",
      "layer   3  Sparsity: 75.9755%\n",
      "total_backward_count 372020 real_backward_count 33948   9.125%\n",
      "lif layer 1 self.abs_max_v: 6586.5\n",
      "epoch-38  lr=['0.0009766'], tr/val_loss:  1.702395/  1.811874, val:  80.00%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.56 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7080%\n",
      "layer   2  Sparsity: 77.7313%\n",
      "layer   3  Sparsity: 75.8357%\n",
      "total_backward_count 381810 real_backward_count 34383   9.005%\n",
      "lif layer 1 self.abs_max_v: 6698.5\n",
      "epoch-39  lr=['0.0009766'], tr/val_loss:  1.702644/  1.809440, val:  83.33%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.32 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7331%\n",
      "layer   2  Sparsity: 77.6241%\n",
      "layer   3  Sparsity: 76.0121%\n",
      "total_backward_count 391600 real_backward_count 34816   8.891%\n",
      "lif layer 1 self.abs_max_v: 6766.5\n",
      "lif layer 2 self.abs_max_v: 3371.5\n",
      "epoch-40  lr=['0.0009766'], tr/val_loss:  1.703622/  1.805544, val:  85.00%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.24 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7110%\n",
      "layer   2  Sparsity: 77.8987%\n",
      "layer   3  Sparsity: 76.6027%\n",
      "total_backward_count 401390 real_backward_count 35238   8.779%\n",
      "epoch-41  lr=['0.0009766'], tr/val_loss:  1.701296/  1.812870, val:  84.58%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.78 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7134%\n",
      "layer   2  Sparsity: 77.9124%\n",
      "layer   3  Sparsity: 76.8310%\n",
      "total_backward_count 411180 real_backward_count 35666   8.674%\n",
      "fc layer 1 self.abs_max_out: 4144.0\n",
      "epoch-42  lr=['0.0009766'], tr/val_loss:  1.701264/  1.805245, val:  85.42%, val_best:  87.50%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.83 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7106%\n",
      "layer   2  Sparsity: 77.9338%\n",
      "layer   3  Sparsity: 76.7080%\n",
      "total_backward_count 420970 real_backward_count 36095   8.574%\n",
      "fc layer 1 self.abs_max_out: 4174.0\n",
      "epoch-43  lr=['0.0009766'], tr/val_loss:  1.703242/  1.806415, val:  87.92%, val_best:  87.92%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.72 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7004%\n",
      "layer   2  Sparsity: 77.8029%\n",
      "layer   3  Sparsity: 77.1386%\n",
      "total_backward_count 430760 real_backward_count 36474   8.467%\n",
      "fc layer 1 self.abs_max_out: 4199.0\n",
      "epoch-44  lr=['0.0009766'], tr/val_loss:  1.701490/  1.807056, val:  81.25%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.60 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7262%\n",
      "layer   2  Sparsity: 77.9116%\n",
      "layer   3  Sparsity: 77.2148%\n",
      "total_backward_count 440550 real_backward_count 36844   8.363%\n",
      "epoch-45  lr=['0.0009766'], tr/val_loss:  1.699349/  1.806226, val:  83.33%, val_best:  87.92%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.29 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6973%\n",
      "layer   2  Sparsity: 77.8057%\n",
      "layer   3  Sparsity: 77.5701%\n",
      "total_backward_count 450340 real_backward_count 37221   8.265%\n",
      "lif layer 1 self.abs_max_v: 6868.5\n",
      "epoch-46  lr=['0.0009766'], tr/val_loss:  1.698095/  1.803870, val:  85.83%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.37 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7243%\n",
      "layer   2  Sparsity: 77.9424%\n",
      "layer   3  Sparsity: 77.6553%\n",
      "total_backward_count 460130 real_backward_count 37569   8.165%\n",
      "fc layer 1 self.abs_max_out: 4252.0\n",
      "epoch-47  lr=['0.0009766'], tr/val_loss:  1.705143/  1.804086, val:  82.92%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.82 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6976%\n",
      "layer   2  Sparsity: 77.9256%\n",
      "layer   3  Sparsity: 77.5546%\n",
      "total_backward_count 469920 real_backward_count 37956   8.077%\n",
      "fc layer 2 self.abs_max_out: 2240.0\n",
      "fc layer 2 self.abs_max_out: 2282.0\n",
      "epoch-48  lr=['0.0009766'], tr/val_loss:  1.697514/  1.804193, val:  85.00%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.56 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7140%\n",
      "layer   2  Sparsity: 77.9800%\n",
      "layer   3  Sparsity: 77.5820%\n",
      "total_backward_count 479710 real_backward_count 38305   7.985%\n",
      "epoch-49  lr=['0.0009766'], tr/val_loss:  1.700475/  1.803932, val:  85.42%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.37 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7206%\n",
      "layer   2  Sparsity: 78.0580%\n",
      "layer   3  Sparsity: 77.6578%\n",
      "total_backward_count 489500 real_backward_count 38631   7.892%\n",
      "epoch-50  lr=['0.0009766'], tr/val_loss:  1.695422/  1.796957, val:  86.67%, val_best:  87.92%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.20 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.6999%\n",
      "layer   2  Sparsity: 78.1009%\n",
      "layer   3  Sparsity: 77.4228%\n",
      "total_backward_count 499290 real_backward_count 38971   7.805%\n",
      "epoch-51  lr=['0.0009766'], tr/val_loss:  1.700243/  1.804422, val:  82.92%, val_best:  87.92%, tr:  99.90%, tr_best: 100.00%, epoch time: 82.27 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7090%\n",
      "layer   2  Sparsity: 77.9398%\n",
      "layer   3  Sparsity: 77.5915%\n",
      "total_backward_count 509080 real_backward_count 39294   7.719%\n",
      "epoch-52  lr=['0.0009766'], tr/val_loss:  1.695169/  1.798130, val:  88.75%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.26 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7159%\n",
      "layer   2  Sparsity: 78.1453%\n",
      "layer   3  Sparsity: 77.8829%\n",
      "total_backward_count 518870 real_backward_count 39638   7.639%\n",
      "lif layer 1 self.abs_max_v: 7102.0\n",
      "epoch-53  lr=['0.0009766'], tr/val_loss:  1.684453/  1.786422, val:  84.58%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.41 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7218%\n",
      "layer   2  Sparsity: 77.9760%\n",
      "layer   3  Sparsity: 77.7351%\n",
      "total_backward_count 528660 real_backward_count 39974   7.561%\n",
      "epoch-54  lr=['0.0009766'], tr/val_loss:  1.680864/  1.787408, val:  84.58%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.92 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7197%\n",
      "layer   2  Sparsity: 77.8329%\n",
      "layer   3  Sparsity: 77.4447%\n",
      "total_backward_count 538450 real_backward_count 40285   7.482%\n",
      "epoch-55  lr=['0.0009766'], tr/val_loss:  1.677858/  1.783986, val:  87.92%, val_best:  88.75%, tr:  99.80%, tr_best: 100.00%, epoch time: 82.44 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7308%\n",
      "layer   2  Sparsity: 77.8333%\n",
      "layer   3  Sparsity: 77.7270%\n",
      "total_backward_count 548240 real_backward_count 40612   7.408%\n",
      "epoch-56  lr=['0.0009766'], tr/val_loss:  1.678911/  1.780353, val:  87.08%, val_best:  88.75%, tr:  99.90%, tr_best: 100.00%, epoch time: 81.76 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7137%\n",
      "layer   2  Sparsity: 77.8561%\n",
      "layer   3  Sparsity: 77.7944%\n",
      "total_backward_count 558030 real_backward_count 40931   7.335%\n",
      "fc layer 1 self.abs_max_out: 4304.0\n",
      "epoch-57  lr=['0.0009766'], tr/val_loss:  1.676213/  1.774839, val:  87.50%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.97 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7240%\n",
      "layer   2  Sparsity: 77.7679%\n",
      "layer   3  Sparsity: 77.6714%\n",
      "total_backward_count 567820 real_backward_count 41266   7.267%\n",
      "epoch-58  lr=['0.0009766'], tr/val_loss:  1.673745/  1.789869, val:  83.33%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.09 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7408%\n",
      "layer   2  Sparsity: 77.8468%\n",
      "layer   3  Sparsity: 78.1243%\n",
      "total_backward_count 577610 real_backward_count 41604   7.203%\n",
      "epoch-59  lr=['0.0009766'], tr/val_loss:  1.670958/  1.782881, val:  85.83%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.83 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7220%\n",
      "layer   2  Sparsity: 77.7514%\n",
      "layer   3  Sparsity: 77.9797%\n",
      "total_backward_count 587400 real_backward_count 41929   7.138%\n",
      "fc layer 2 self.abs_max_out: 2308.0\n",
      "lif layer 1 self.abs_max_v: 7152.0\n",
      "epoch-60  lr=['0.0009766'], tr/val_loss:  1.663679/  1.773637, val:  86.25%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.56 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7421%\n",
      "layer   2  Sparsity: 78.0209%\n",
      "layer   3  Sparsity: 78.0167%\n",
      "total_backward_count 597190 real_backward_count 42244   7.074%\n",
      "fc layer 1 self.abs_max_out: 4331.0\n",
      "epoch-61  lr=['0.0009766'], tr/val_loss:  1.668066/  1.770124, val:  86.67%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.47 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7154%\n",
      "layer   2  Sparsity: 78.1220%\n",
      "layer   3  Sparsity: 77.7905%\n",
      "total_backward_count 606980 real_backward_count 42511   7.004%\n",
      "lif layer 1 self.abs_max_v: 7180.0\n",
      "epoch-62  lr=['0.0009766'], tr/val_loss:  1.667939/  1.772607, val:  85.42%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.68 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7364%\n",
      "layer   2  Sparsity: 78.0901%\n",
      "layer   3  Sparsity: 77.8236%\n",
      "total_backward_count 616770 real_backward_count 42781   6.936%\n",
      "epoch-63  lr=['0.0009766'], tr/val_loss:  1.659401/  1.766927, val:  86.67%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.16 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7147%\n",
      "layer   2  Sparsity: 77.9118%\n",
      "layer   3  Sparsity: 77.7904%\n",
      "total_backward_count 626560 real_backward_count 43059   6.872%\n",
      "epoch-64  lr=['0.0009766'], tr/val_loss:  1.657101/  1.764395, val:  85.83%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.55 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7175%\n",
      "layer   2  Sparsity: 77.8095%\n",
      "layer   3  Sparsity: 77.9083%\n",
      "total_backward_count 636350 real_backward_count 43317   6.807%\n",
      "epoch-65  lr=['0.0009766'], tr/val_loss:  1.653106/  1.770170, val:  86.25%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.67 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7191%\n",
      "layer   2  Sparsity: 77.7903%\n",
      "layer   3  Sparsity: 77.8549%\n",
      "total_backward_count 646140 real_backward_count 43560   6.742%\n",
      "fc layer 2 self.abs_max_out: 2330.0\n",
      "epoch-66  lr=['0.0009766'], tr/val_loss:  1.654690/  1.757459, val:  86.67%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.58 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7119%\n",
      "layer   2  Sparsity: 77.7539%\n",
      "layer   3  Sparsity: 77.8448%\n",
      "total_backward_count 655930 real_backward_count 43837   6.683%\n",
      "epoch-67  lr=['0.0009766'], tr/val_loss:  1.647493/  1.764795, val:  84.58%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.22 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7227%\n",
      "layer   2  Sparsity: 77.7828%\n",
      "layer   3  Sparsity: 78.1717%\n",
      "total_backward_count 665720 real_backward_count 44070   6.620%\n",
      "lif layer 1 self.abs_max_v: 7388.5\n",
      "epoch-68  lr=['0.0009766'], tr/val_loss:  1.650733/  1.759969, val:  85.42%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.41 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7191%\n",
      "layer   2  Sparsity: 77.7889%\n",
      "layer   3  Sparsity: 78.3444%\n",
      "total_backward_count 675510 real_backward_count 44327   6.562%\n",
      "epoch-69  lr=['0.0009766'], tr/val_loss:  1.642761/  1.758071, val:  85.42%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.21 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7132%\n",
      "layer   2  Sparsity: 77.6552%\n",
      "layer   3  Sparsity: 78.1303%\n",
      "total_backward_count 685300 real_backward_count 44556   6.502%\n",
      "epoch-70  lr=['0.0009766'], tr/val_loss:  1.638937/  1.749444, val:  88.75%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.12 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7266%\n",
      "layer   2  Sparsity: 77.6366%\n",
      "layer   3  Sparsity: 78.0452%\n",
      "total_backward_count 695090 real_backward_count 44777   6.442%\n",
      "epoch-71  lr=['0.0009766'], tr/val_loss:  1.632984/  1.739776, val:  87.08%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.37 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6973%\n",
      "layer   2  Sparsity: 77.7238%\n",
      "layer   3  Sparsity: 78.2356%\n",
      "total_backward_count 704880 real_backward_count 45025   6.388%\n",
      "epoch-72  lr=['0.0009766'], tr/val_loss:  1.628559/  1.750300, val:  86.25%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.31 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7257%\n",
      "layer   2  Sparsity: 77.7034%\n",
      "layer   3  Sparsity: 78.0432%\n",
      "total_backward_count 714670 real_backward_count 45283   6.336%\n",
      "epoch-73  lr=['0.0009766'], tr/val_loss:  1.628023/  1.736876, val:  86.25%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.75 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6884%\n",
      "layer   2  Sparsity: 77.7290%\n",
      "layer   3  Sparsity: 78.0658%\n",
      "total_backward_count 724460 real_backward_count 45514   6.282%\n",
      "epoch-74  lr=['0.0009766'], tr/val_loss:  1.619586/  1.727894, val:  86.25%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.37 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7095%\n",
      "layer   2  Sparsity: 77.7715%\n",
      "layer   3  Sparsity: 78.4030%\n",
      "total_backward_count 734250 real_backward_count 45743   6.230%\n",
      "epoch-75  lr=['0.0009766'], tr/val_loss:  1.617617/  1.731984, val:  87.08%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.98 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7161%\n",
      "layer   2  Sparsity: 77.9540%\n",
      "layer   3  Sparsity: 78.2256%\n",
      "total_backward_count 744040 real_backward_count 45947   6.175%\n",
      "epoch-76  lr=['0.0009766'], tr/val_loss:  1.607362/  1.730382, val:  87.92%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.53 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7208%\n",
      "layer   2  Sparsity: 77.9548%\n",
      "layer   3  Sparsity: 78.4607%\n",
      "total_backward_count 753830 real_backward_count 46156   6.123%\n",
      "epoch-77  lr=['0.0009766'], tr/val_loss:  1.608222/  1.732394, val:  87.92%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.32 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7158%\n",
      "layer   2  Sparsity: 77.8273%\n",
      "layer   3  Sparsity: 78.5482%\n",
      "total_backward_count 763620 real_backward_count 46363   6.071%\n",
      "epoch-78  lr=['0.0009766'], tr/val_loss:  1.604533/  1.732254, val:  85.42%, val_best:  88.75%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.00 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6934%\n",
      "layer   2  Sparsity: 77.7186%\n",
      "layer   3  Sparsity: 78.3367%\n",
      "total_backward_count 773410 real_backward_count 46540   6.018%\n",
      "epoch-79  lr=['0.0009766'], tr/val_loss:  1.609651/  1.734277, val:  90.00%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.26 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7353%\n",
      "layer   2  Sparsity: 77.7680%\n",
      "layer   3  Sparsity: 78.2610%\n",
      "total_backward_count 783200 real_backward_count 46749   5.969%\n",
      "epoch-80  lr=['0.0009766'], tr/val_loss:  1.612717/  1.739360, val:  88.75%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.83 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7136%\n",
      "layer   2  Sparsity: 77.8071%\n",
      "layer   3  Sparsity: 78.3838%\n",
      "total_backward_count 792990 real_backward_count 46924   5.917%\n",
      "lif layer 1 self.abs_max_v: 7441.5\n",
      "epoch-81  lr=['0.0009766'], tr/val_loss:  1.615269/  1.739612, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.39 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7397%\n",
      "layer   2  Sparsity: 77.7494%\n",
      "layer   3  Sparsity: 78.5248%\n",
      "total_backward_count 802780 real_backward_count 47111   5.868%\n",
      "epoch-82  lr=['0.0009766'], tr/val_loss:  1.617878/  1.738747, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.66 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7199%\n",
      "layer   2  Sparsity: 77.7466%\n",
      "layer   3  Sparsity: 78.2915%\n",
      "total_backward_count 812570 real_backward_count 47297   5.821%\n",
      "epoch-83  lr=['0.0009766'], tr/val_loss:  1.611319/  1.736486, val:  84.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.03 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7109%\n",
      "layer   2  Sparsity: 77.6889%\n",
      "layer   3  Sparsity: 78.2789%\n",
      "total_backward_count 822360 real_backward_count 47503   5.776%\n",
      "epoch-84  lr=['0.0009766'], tr/val_loss:  1.616594/  1.735605, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.46 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7162%\n",
      "layer   2  Sparsity: 77.8234%\n",
      "layer   3  Sparsity: 78.5327%\n",
      "total_backward_count 832150 real_backward_count 47664   5.728%\n",
      "fc layer 2 self.abs_max_out: 2355.0\n",
      "epoch-85  lr=['0.0009766'], tr/val_loss:  1.615406/  1.734654, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.41 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6909%\n",
      "layer   2  Sparsity: 77.5413%\n",
      "layer   3  Sparsity: 78.3539%\n",
      "total_backward_count 841940 real_backward_count 47860   5.684%\n",
      "fc layer 1 self.abs_max_out: 4361.0\n",
      "epoch-86  lr=['0.0009766'], tr/val_loss:  1.614790/  1.746582, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.68 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7113%\n",
      "layer   2  Sparsity: 77.5130%\n",
      "layer   3  Sparsity: 78.6832%\n",
      "total_backward_count 851730 real_backward_count 48059   5.643%\n",
      "epoch-87  lr=['0.0009766'], tr/val_loss:  1.611686/  1.729119, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.19 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7003%\n",
      "layer   2  Sparsity: 77.6347%\n",
      "layer   3  Sparsity: 78.6792%\n",
      "total_backward_count 861520 real_backward_count 48245   5.600%\n",
      "epoch-88  lr=['0.0009766'], tr/val_loss:  1.604070/  1.718120, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.20 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7222%\n",
      "layer   2  Sparsity: 77.6580%\n",
      "layer   3  Sparsity: 78.5191%\n",
      "total_backward_count 871310 real_backward_count 48439   5.559%\n",
      "epoch-89  lr=['0.0009766'], tr/val_loss:  1.601950/  1.724895, val:  89.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.81 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7309%\n",
      "layer   2  Sparsity: 77.7085%\n",
      "layer   3  Sparsity: 78.5858%\n",
      "total_backward_count 881100 real_backward_count 48612   5.517%\n",
      "epoch-90  lr=['0.0009766'], tr/val_loss:  1.601338/  1.719942, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.07 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7183%\n",
      "layer   2  Sparsity: 77.5107%\n",
      "layer   3  Sparsity: 78.5925%\n",
      "total_backward_count 890890 real_backward_count 48791   5.477%\n",
      "epoch-91  lr=['0.0009766'], tr/val_loss:  1.593769/  1.723003, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.14 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7361%\n",
      "layer   2  Sparsity: 77.8088%\n",
      "layer   3  Sparsity: 78.7116%\n",
      "total_backward_count 900680 real_backward_count 48953   5.435%\n",
      "epoch-92  lr=['0.0009766'], tr/val_loss:  1.591970/  1.717728, val:  88.75%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.09 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7321%\n",
      "layer   2  Sparsity: 77.8779%\n",
      "layer   3  Sparsity: 78.5447%\n",
      "total_backward_count 910470 real_backward_count 49094   5.392%\n",
      "epoch-93  lr=['0.0009766'], tr/val_loss:  1.596884/  1.726325, val:  85.42%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.27 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7021%\n",
      "layer   2  Sparsity: 77.8720%\n",
      "layer   3  Sparsity: 78.4504%\n",
      "total_backward_count 920260 real_backward_count 49229   5.349%\n",
      "epoch-94  lr=['0.0009766'], tr/val_loss:  1.595534/  1.720761, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.47 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7047%\n",
      "layer   2  Sparsity: 77.7082%\n",
      "layer   3  Sparsity: 78.3361%\n",
      "total_backward_count 930050 real_backward_count 49384   5.310%\n",
      "epoch-95  lr=['0.0009766'], tr/val_loss:  1.593735/  1.715206, val:  89.58%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.71 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7089%\n",
      "layer   2  Sparsity: 77.6386%\n",
      "layer   3  Sparsity: 78.3799%\n",
      "total_backward_count 939840 real_backward_count 49554   5.273%\n",
      "epoch-96  lr=['0.0009766'], tr/val_loss:  1.592318/  1.715985, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.45 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7048%\n",
      "layer   2  Sparsity: 77.6072%\n",
      "layer   3  Sparsity: 78.5447%\n",
      "total_backward_count 949630 real_backward_count 49704   5.234%\n",
      "fc layer 1 self.abs_max_out: 4362.0\n",
      "epoch-97  lr=['0.0009766'], tr/val_loss:  1.597991/  1.718351, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.71 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7087%\n",
      "layer   2  Sparsity: 77.6863%\n",
      "layer   3  Sparsity: 78.4921%\n",
      "total_backward_count 959420 real_backward_count 49886   5.200%\n",
      "fc layer 1 self.abs_max_out: 4376.0\n",
      "fc layer 1 self.abs_max_out: 4380.0\n",
      "epoch-98  lr=['0.0009766'], tr/val_loss:  1.590732/  1.717460, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.73 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7014%\n",
      "layer   2  Sparsity: 77.7361%\n",
      "layer   3  Sparsity: 78.3136%\n",
      "total_backward_count 969210 real_backward_count 50046   5.164%\n",
      "fc layer 1 self.abs_max_out: 4427.0\n",
      "epoch-99  lr=['0.0009766'], tr/val_loss:  1.594754/  1.718905, val:  85.83%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.68 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7276%\n",
      "layer   2  Sparsity: 77.8422%\n",
      "layer   3  Sparsity: 78.3150%\n",
      "total_backward_count 979000 real_backward_count 50215   5.129%\n",
      "epoch-100 lr=['0.0009766'], tr/val_loss:  1.590045/  1.711041, val:  90.00%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.15 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7067%\n",
      "layer   2  Sparsity: 77.7820%\n",
      "layer   3  Sparsity: 78.4309%\n",
      "total_backward_count 988790 real_backward_count 50360   5.093%\n",
      "epoch-101 lr=['0.0009766'], tr/val_loss:  1.583895/  1.712405, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.44 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7081%\n",
      "layer   2  Sparsity: 77.6468%\n",
      "layer   3  Sparsity: 78.4667%\n",
      "total_backward_count 998580 real_backward_count 50506   5.058%\n",
      "epoch-102 lr=['0.0009766'], tr/val_loss:  1.585917/  1.720047, val:  88.75%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.81 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7137%\n",
      "layer   2  Sparsity: 77.7060%\n",
      "layer   3  Sparsity: 78.3586%\n",
      "total_backward_count 1008370 real_backward_count 50672   5.025%\n",
      "epoch-103 lr=['0.0009766'], tr/val_loss:  1.588817/  1.711088, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.94 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7251%\n",
      "layer   2  Sparsity: 77.6743%\n",
      "layer   3  Sparsity: 78.3761%\n",
      "total_backward_count 1018160 real_backward_count 50804   4.990%\n",
      "epoch-104 lr=['0.0009766'], tr/val_loss:  1.583181/  1.712048, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.75 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6955%\n",
      "layer   2  Sparsity: 77.5090%\n",
      "layer   3  Sparsity: 78.2047%\n",
      "total_backward_count 1027950 real_backward_count 50952   4.957%\n",
      "fc layer 1 self.abs_max_out: 4484.0\n",
      "epoch-105 lr=['0.0009766'], tr/val_loss:  1.579103/  1.710050, val:  89.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.42 seconds, 1.34 minutes\n",
      "layer   1  Sparsity: 91.7195%\n",
      "layer   2  Sparsity: 77.6748%\n",
      "layer   3  Sparsity: 78.2704%\n",
      "total_backward_count 1037740 real_backward_count 51102   4.924%\n",
      "epoch-106 lr=['0.0009766'], tr/val_loss:  1.581116/  1.718772, val:  85.42%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 80.84 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7193%\n",
      "layer   2  Sparsity: 77.6878%\n",
      "layer   3  Sparsity: 78.1365%\n",
      "total_backward_count 1047530 real_backward_count 51238   4.891%\n",
      "epoch-107 lr=['0.0009766'], tr/val_loss:  1.587121/  1.711868, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.30 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7119%\n",
      "layer   2  Sparsity: 77.6441%\n",
      "layer   3  Sparsity: 78.0318%\n",
      "total_backward_count 1057320 real_backward_count 51371   4.859%\n",
      "fc layer 1 self.abs_max_out: 4490.0\n",
      "epoch-108 lr=['0.0009766'], tr/val_loss:  1.582329/  1.708773, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.31 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.6875%\n",
      "layer   2  Sparsity: 77.5907%\n",
      "layer   3  Sparsity: 78.1143%\n",
      "total_backward_count 1067110 real_backward_count 51500   4.826%\n",
      "epoch-109 lr=['0.0009766'], tr/val_loss:  1.577297/  1.709017, val:  86.67%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.53 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7046%\n",
      "layer   2  Sparsity: 77.6994%\n",
      "layer   3  Sparsity: 78.0470%\n",
      "total_backward_count 1076900 real_backward_count 51626   4.794%\n",
      "fc layer 1 self.abs_max_out: 4574.0\n",
      "epoch-110 lr=['0.0009766'], tr/val_loss:  1.575088/  1.704800, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.42 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7218%\n",
      "layer   2  Sparsity: 77.8209%\n",
      "layer   3  Sparsity: 78.1835%\n",
      "total_backward_count 1086690 real_backward_count 51742   4.761%\n",
      "epoch-111 lr=['0.0009766'], tr/val_loss:  1.577159/  1.701775, val:  86.67%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.18 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7264%\n",
      "layer   2  Sparsity: 77.8860%\n",
      "layer   3  Sparsity: 78.4574%\n",
      "total_backward_count 1096480 real_backward_count 51886   4.732%\n",
      "epoch-112 lr=['0.0009766'], tr/val_loss:  1.574618/  1.700654, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.36 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7281%\n",
      "layer   2  Sparsity: 77.9189%\n",
      "layer   3  Sparsity: 78.2777%\n",
      "total_backward_count 1106270 real_backward_count 52007   4.701%\n",
      "fc layer 1 self.abs_max_out: 4617.0\n",
      "fc layer 3 self.abs_max_out: 702.0\n",
      "epoch-113 lr=['0.0009766'], tr/val_loss:  1.573147/  1.704691, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.38 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7105%\n",
      "layer   2  Sparsity: 77.9270%\n",
      "layer   3  Sparsity: 78.4004%\n",
      "total_backward_count 1116060 real_backward_count 52101   4.668%\n",
      "fc layer 3 self.abs_max_out: 703.0\n",
      "epoch-114 lr=['0.0009766'], tr/val_loss:  1.569564/  1.702697, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.21 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7031%\n",
      "layer   2  Sparsity: 77.9400%\n",
      "layer   3  Sparsity: 78.3083%\n",
      "total_backward_count 1125850 real_backward_count 52228   4.639%\n",
      "epoch-115 lr=['0.0009766'], tr/val_loss:  1.572078/  1.705073, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.07 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7086%\n",
      "layer   2  Sparsity: 77.8502%\n",
      "layer   3  Sparsity: 78.2362%\n",
      "total_backward_count 1135640 real_backward_count 52361   4.611%\n",
      "fc layer 2 self.abs_max_out: 2362.0\n",
      "epoch-116 lr=['0.0009766'], tr/val_loss:  1.573355/  1.703253, val:  89.17%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.48 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7283%\n",
      "layer   2  Sparsity: 77.8676%\n",
      "layer   3  Sparsity: 78.2479%\n",
      "total_backward_count 1145430 real_backward_count 52494   4.583%\n",
      "epoch-117 lr=['0.0009766'], tr/val_loss:  1.572342/  1.700947, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.77 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6880%\n",
      "layer   2  Sparsity: 77.8216%\n",
      "layer   3  Sparsity: 78.1902%\n",
      "total_backward_count 1155220 real_backward_count 52648   4.557%\n",
      "epoch-118 lr=['0.0009766'], tr/val_loss:  1.568361/  1.691859, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.51 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7183%\n",
      "layer   2  Sparsity: 77.9879%\n",
      "layer   3  Sparsity: 78.2745%\n",
      "total_backward_count 1165010 real_backward_count 52783   4.531%\n",
      "fc layer 2 self.abs_max_out: 2368.0\n",
      "epoch-119 lr=['0.0009766'], tr/val_loss:  1.559705/  1.693220, val:  88.33%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.67 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7056%\n",
      "layer   2  Sparsity: 77.8667%\n",
      "layer   3  Sparsity: 78.1854%\n",
      "total_backward_count 1174800 real_backward_count 52884   4.502%\n",
      "epoch-120 lr=['0.0009766'], tr/val_loss:  1.567175/  1.694433, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.18 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.6888%\n",
      "layer   2  Sparsity: 77.7617%\n",
      "layer   3  Sparsity: 78.2095%\n",
      "total_backward_count 1184590 real_backward_count 52990   4.473%\n",
      "epoch-121 lr=['0.0009766'], tr/val_loss:  1.562518/  1.690859, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.15 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7082%\n",
      "layer   2  Sparsity: 77.6919%\n",
      "layer   3  Sparsity: 78.2546%\n",
      "total_backward_count 1194380 real_backward_count 53099   4.446%\n",
      "fc layer 3 self.abs_max_out: 704.0\n",
      "epoch-122 lr=['0.0009766'], tr/val_loss:  1.560131/  1.686988, val:  87.08%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.21 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7169%\n",
      "layer   2  Sparsity: 77.8719%\n",
      "layer   3  Sparsity: 78.4029%\n",
      "total_backward_count 1204170 real_backward_count 53211   4.419%\n",
      "epoch-123 lr=['0.0009766'], tr/val_loss:  1.554262/  1.683042, val:  88.75%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.75 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7288%\n",
      "layer   2  Sparsity: 77.9154%\n",
      "layer   3  Sparsity: 78.2559%\n",
      "total_backward_count 1213960 real_backward_count 53294   4.390%\n",
      "epoch-124 lr=['0.0009766'], tr/val_loss:  1.554694/  1.681795, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.11 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7386%\n",
      "layer   2  Sparsity: 77.9416%\n",
      "layer   3  Sparsity: 78.4286%\n",
      "total_backward_count 1223750 real_backward_count 53372   4.361%\n",
      "epoch-125 lr=['0.0009766'], tr/val_loss:  1.554816/  1.693925, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.19 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7163%\n",
      "layer   2  Sparsity: 77.9513%\n",
      "layer   3  Sparsity: 78.4959%\n",
      "total_backward_count 1233540 real_backward_count 53477   4.335%\n",
      "epoch-126 lr=['0.0009766'], tr/val_loss:  1.565279/  1.696755, val:  87.50%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.16 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7174%\n",
      "layer   2  Sparsity: 77.8269%\n",
      "layer   3  Sparsity: 78.4713%\n",
      "total_backward_count 1243330 real_backward_count 53579   4.309%\n",
      "epoch-127 lr=['0.0009766'], tr/val_loss:  1.565869/  1.698854, val:  85.42%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.24 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6864%\n",
      "layer   2  Sparsity: 77.7816%\n",
      "layer   3  Sparsity: 78.4937%\n",
      "total_backward_count 1253120 real_backward_count 53678   4.284%\n",
      "epoch-128 lr=['0.0009766'], tr/val_loss:  1.561343/  1.691283, val:  85.83%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.57 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7120%\n",
      "layer   2  Sparsity: 77.7728%\n",
      "layer   3  Sparsity: 78.4223%\n",
      "total_backward_count 1262910 real_backward_count 53787   4.259%\n",
      "lif layer 1 self.abs_max_v: 7454.0\n",
      "epoch-129 lr=['0.0009766'], tr/val_loss:  1.560664/  1.682933, val:  89.58%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.78 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7234%\n",
      "layer   2  Sparsity: 77.7393%\n",
      "layer   3  Sparsity: 78.4295%\n",
      "total_backward_count 1272700 real_backward_count 53890   4.234%\n",
      "epoch-130 lr=['0.0009766'], tr/val_loss:  1.555994/  1.679058, val:  86.25%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.81 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7097%\n",
      "layer   2  Sparsity: 77.7091%\n",
      "layer   3  Sparsity: 78.5054%\n",
      "total_backward_count 1282490 real_backward_count 53983   4.209%\n",
      "epoch-131 lr=['0.0009766'], tr/val_loss:  1.552000/  1.679669, val:  89.58%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.49 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7099%\n",
      "layer   2  Sparsity: 77.6051%\n",
      "layer   3  Sparsity: 78.3737%\n",
      "total_backward_count 1292280 real_backward_count 54085   4.185%\n",
      "epoch-132 lr=['0.0009766'], tr/val_loss:  1.551632/  1.684490, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.58 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7198%\n",
      "layer   2  Sparsity: 77.6911%\n",
      "layer   3  Sparsity: 78.5581%\n",
      "total_backward_count 1302070 real_backward_count 54183   4.161%\n",
      "fc layer 3 self.abs_max_out: 707.0\n",
      "epoch-133 lr=['0.0009766'], tr/val_loss:  1.551775/  1.679913, val:  89.58%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.30 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.7168%\n",
      "layer   2  Sparsity: 77.6642%\n",
      "layer   3  Sparsity: 78.3779%\n",
      "total_backward_count 1311860 real_backward_count 54292   4.139%\n",
      "fc layer 2 self.abs_max_out: 2380.0\n",
      "epoch-134 lr=['0.0009766'], tr/val_loss:  1.550744/  1.683233, val:  87.92%, val_best:  90.00%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.30 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7240%\n",
      "layer   2  Sparsity: 77.8367%\n",
      "layer   3  Sparsity: 78.4366%\n",
      "total_backward_count 1321650 real_backward_count 54390   4.115%\n",
      "epoch-135 lr=['0.0009766'], tr/val_loss:  1.551126/  1.678388, val:  90.42%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.40 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7098%\n",
      "layer   2  Sparsity: 77.8626%\n",
      "layer   3  Sparsity: 78.4323%\n",
      "total_backward_count 1331440 real_backward_count 54491   4.093%\n",
      "epoch-136 lr=['0.0009766'], tr/val_loss:  1.550716/  1.679086, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.80 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7036%\n",
      "layer   2  Sparsity: 77.7350%\n",
      "layer   3  Sparsity: 78.3397%\n",
      "total_backward_count 1341230 real_backward_count 54579   4.069%\n",
      "epoch-137 lr=['0.0009766'], tr/val_loss:  1.548199/  1.676764, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.69 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7395%\n",
      "layer   2  Sparsity: 77.7030%\n",
      "layer   3  Sparsity: 78.5180%\n",
      "total_backward_count 1351020 real_backward_count 54694   4.048%\n",
      "epoch-138 lr=['0.0009766'], tr/val_loss:  1.547096/  1.683593, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.40 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7092%\n",
      "layer   2  Sparsity: 77.7240%\n",
      "layer   3  Sparsity: 78.7541%\n",
      "total_backward_count 1360810 real_backward_count 54769   4.025%\n",
      "epoch-139 lr=['0.0009766'], tr/val_loss:  1.556389/  1.685529, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.85 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6958%\n",
      "layer   2  Sparsity: 77.7945%\n",
      "layer   3  Sparsity: 78.7943%\n",
      "total_backward_count 1370600 real_backward_count 54861   4.003%\n",
      "epoch-140 lr=['0.0009766'], tr/val_loss:  1.558719/  1.694072, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.19 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.7032%\n",
      "layer   2  Sparsity: 77.7213%\n",
      "layer   3  Sparsity: 78.6846%\n",
      "total_backward_count 1380390 real_backward_count 54954   3.981%\n",
      "epoch-141 lr=['0.0009766'], tr/val_loss:  1.557734/  1.681308, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.35 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7311%\n",
      "layer   2  Sparsity: 77.7144%\n",
      "layer   3  Sparsity: 78.6347%\n",
      "total_backward_count 1390180 real_backward_count 55038   3.959%\n",
      "fc layer 3 self.abs_max_out: 712.0\n",
      "epoch-142 lr=['0.0009766'], tr/val_loss:  1.550099/  1.675885, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.12 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.7169%\n",
      "layer   2  Sparsity: 77.8415%\n",
      "layer   3  Sparsity: 78.5287%\n",
      "total_backward_count 1399970 real_backward_count 55129   3.938%\n",
      "epoch-143 lr=['0.0009766'], tr/val_loss:  1.551561/  1.675456, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.35 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7034%\n",
      "layer   2  Sparsity: 77.9175%\n",
      "layer   3  Sparsity: 78.6581%\n",
      "total_backward_count 1409760 real_backward_count 55227   3.917%\n",
      "epoch-144 lr=['0.0009766'], tr/val_loss:  1.549610/  1.683316, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.07 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6933%\n",
      "layer   2  Sparsity: 78.0586%\n",
      "layer   3  Sparsity: 78.8304%\n",
      "total_backward_count 1419550 real_backward_count 55294   3.895%\n",
      "epoch-145 lr=['0.0009766'], tr/val_loss:  1.546762/  1.676801, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.71 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7227%\n",
      "layer   2  Sparsity: 77.8778%\n",
      "layer   3  Sparsity: 78.5470%\n",
      "total_backward_count 1429340 real_backward_count 55372   3.874%\n",
      "epoch-146 lr=['0.0009766'], tr/val_loss:  1.547313/  1.681473, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.66 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7258%\n",
      "layer   2  Sparsity: 77.8221%\n",
      "layer   3  Sparsity: 78.4424%\n",
      "total_backward_count 1439130 real_backward_count 55458   3.854%\n",
      "epoch-147 lr=['0.0009766'], tr/val_loss:  1.548914/  1.680543, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.13 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.7377%\n",
      "layer   2  Sparsity: 77.8569%\n",
      "layer   3  Sparsity: 78.5352%\n",
      "total_backward_count 1448920 real_backward_count 55551   3.834%\n",
      "epoch-148 lr=['0.0009766'], tr/val_loss:  1.550721/  1.685821, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.98 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7048%\n",
      "layer   2  Sparsity: 78.0239%\n",
      "layer   3  Sparsity: 78.5945%\n",
      "total_backward_count 1458710 real_backward_count 55624   3.813%\n",
      "epoch-149 lr=['0.0009766'], tr/val_loss:  1.547808/  1.680153, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.72 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6984%\n",
      "layer   2  Sparsity: 77.9795%\n",
      "layer   3  Sparsity: 78.5916%\n",
      "total_backward_count 1468500 real_backward_count 55699   3.793%\n",
      "epoch-150 lr=['0.0009766'], tr/val_loss:  1.544944/  1.678843, val:  87.92%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.02 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.6926%\n",
      "layer   2  Sparsity: 77.9216%\n",
      "layer   3  Sparsity: 78.6644%\n",
      "total_backward_count 1478290 real_backward_count 55757   3.772%\n",
      "epoch-151 lr=['0.0009766'], tr/val_loss:  1.546050/  1.679154, val:  90.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.80 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7041%\n",
      "layer   2  Sparsity: 77.9250%\n",
      "layer   3  Sparsity: 78.6838%\n",
      "total_backward_count 1488080 real_backward_count 55836   3.752%\n",
      "epoch-152 lr=['0.0009766'], tr/val_loss:  1.549273/  1.672526, val:  86.67%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.77 seconds, 1.40 minutes\n",
      "layer   1  Sparsity: 91.7203%\n",
      "layer   2  Sparsity: 77.7749%\n",
      "layer   3  Sparsity: 78.5850%\n",
      "total_backward_count 1497870 real_backward_count 55917   3.733%\n",
      "fc layer 3 self.abs_max_out: 717.0\n",
      "epoch-153 lr=['0.0009766'], tr/val_loss:  1.541204/  1.674029, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.12 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.7280%\n",
      "layer   2  Sparsity: 77.7290%\n",
      "layer   3  Sparsity: 78.4925%\n",
      "total_backward_count 1507660 real_backward_count 55994   3.714%\n",
      "epoch-154 lr=['0.0009766'], tr/val_loss:  1.536365/  1.672410, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.30 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7226%\n",
      "layer   2  Sparsity: 77.8341%\n",
      "layer   3  Sparsity: 78.5813%\n",
      "total_backward_count 1517450 real_backward_count 56072   3.695%\n",
      "epoch-155 lr=['0.0009766'], tr/val_loss:  1.541678/  1.675527, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.67 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7129%\n",
      "layer   2  Sparsity: 77.8146%\n",
      "layer   3  Sparsity: 78.6715%\n",
      "total_backward_count 1527240 real_backward_count 56161   3.677%\n",
      "epoch-156 lr=['0.0009766'], tr/val_loss:  1.541760/  1.673778, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.66 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6897%\n",
      "layer   2  Sparsity: 77.8505%\n",
      "layer   3  Sparsity: 78.5896%\n",
      "total_backward_count 1537030 real_backward_count 56218   3.658%\n",
      "epoch-157 lr=['0.0009766'], tr/val_loss:  1.540401/  1.673648, val:  88.33%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.63 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7084%\n",
      "layer   2  Sparsity: 77.8125%\n",
      "layer   3  Sparsity: 78.5334%\n",
      "total_backward_count 1546820 real_backward_count 56297   3.640%\n",
      "epoch-158 lr=['0.0009766'], tr/val_loss:  1.533569/  1.670904, val:  86.25%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.48 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7365%\n",
      "layer   2  Sparsity: 77.8509%\n",
      "layer   3  Sparsity: 78.5340%\n",
      "total_backward_count 1556610 real_backward_count 56375   3.622%\n",
      "epoch-159 lr=['0.0009766'], tr/val_loss:  1.533747/  1.669615, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.56 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7167%\n",
      "layer   2  Sparsity: 77.8162%\n",
      "layer   3  Sparsity: 78.5641%\n",
      "total_backward_count 1566400 real_backward_count 56445   3.603%\n",
      "epoch-160 lr=['0.0009766'], tr/val_loss:  1.532510/  1.668096, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.91 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7072%\n",
      "layer   2  Sparsity: 77.8975%\n",
      "layer   3  Sparsity: 78.6809%\n",
      "total_backward_count 1576190 real_backward_count 56500   3.585%\n",
      "fc layer 3 self.abs_max_out: 723.0\n",
      "fc layer 3 self.abs_max_out: 729.0\n",
      "epoch-161 lr=['0.0009766'], tr/val_loss:  1.532960/  1.666936, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.37 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.6940%\n",
      "layer   2  Sparsity: 77.8531%\n",
      "layer   3  Sparsity: 78.6734%\n",
      "total_backward_count 1585980 real_backward_count 56565   3.567%\n",
      "epoch-162 lr=['0.0009766'], tr/val_loss:  1.532038/  1.663756, val:  89.58%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.33 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7234%\n",
      "layer   2  Sparsity: 77.8415%\n",
      "layer   3  Sparsity: 78.6265%\n",
      "total_backward_count 1595770 real_backward_count 56619   3.548%\n",
      "epoch-163 lr=['0.0009766'], tr/val_loss:  1.528620/  1.660793, val:  88.75%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.98 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7320%\n",
      "layer   2  Sparsity: 77.8547%\n",
      "layer   3  Sparsity: 78.5205%\n",
      "total_backward_count 1605560 real_backward_count 56684   3.530%\n",
      "epoch-164 lr=['0.0009766'], tr/val_loss:  1.524768/  1.660838, val:  89.17%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.81 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7292%\n",
      "layer   2  Sparsity: 77.7610%\n",
      "layer   3  Sparsity: 78.5621%\n",
      "total_backward_count 1615350 real_backward_count 56731   3.512%\n",
      "fc layer 3 self.abs_max_out: 735.0\n",
      "epoch-165 lr=['0.0009766'], tr/val_loss:  1.527283/  1.661022, val:  90.00%, val_best:  90.42%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.59 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7103%\n",
      "layer   2  Sparsity: 77.6866%\n",
      "layer   3  Sparsity: 78.5571%\n",
      "total_backward_count 1625140 real_backward_count 56798   3.495%\n",
      "fc layer 2 self.abs_max_out: 2388.0\n",
      "fc layer 3 self.abs_max_out: 743.0\n",
      "epoch-166 lr=['0.0009766'], tr/val_loss:  1.522799/  1.664655, val:  90.83%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.00 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7212%\n",
      "layer   2  Sparsity: 77.6859%\n",
      "layer   3  Sparsity: 78.6378%\n",
      "total_backward_count 1634930 real_backward_count 56846   3.477%\n",
      "epoch-167 lr=['0.0009766'], tr/val_loss:  1.522860/  1.663325, val:  90.42%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.52 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.6996%\n",
      "layer   2  Sparsity: 77.7590%\n",
      "layer   3  Sparsity: 78.6778%\n",
      "total_backward_count 1644720 real_backward_count 56903   3.460%\n",
      "epoch-168 lr=['0.0009766'], tr/val_loss:  1.523669/  1.668550, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.29 seconds, 1.35 minutes\n",
      "layer   1  Sparsity: 91.7244%\n",
      "layer   2  Sparsity: 77.7559%\n",
      "layer   3  Sparsity: 78.6841%\n",
      "total_backward_count 1654510 real_backward_count 56974   3.444%\n",
      "epoch-169 lr=['0.0009766'], tr/val_loss:  1.521348/  1.662944, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.99 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7365%\n",
      "layer   2  Sparsity: 77.8892%\n",
      "layer   3  Sparsity: 78.8679%\n",
      "total_backward_count 1664300 real_backward_count 57058   3.428%\n",
      "epoch-170 lr=['0.0009766'], tr/val_loss:  1.522677/  1.661476, val:  89.58%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.46 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7078%\n",
      "layer   2  Sparsity: 77.9646%\n",
      "layer   3  Sparsity: 78.8034%\n",
      "total_backward_count 1674090 real_backward_count 57136   3.413%\n",
      "epoch-171 lr=['0.0009766'], tr/val_loss:  1.516854/  1.655686, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.50 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7131%\n",
      "layer   2  Sparsity: 77.9301%\n",
      "layer   3  Sparsity: 78.7315%\n",
      "total_backward_count 1683880 real_backward_count 57211   3.398%\n",
      "epoch-172 lr=['0.0009766'], tr/val_loss:  1.512077/  1.650692, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.75 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7208%\n",
      "layer   2  Sparsity: 77.9380%\n",
      "layer   3  Sparsity: 78.5510%\n",
      "total_backward_count 1693670 real_backward_count 57283   3.382%\n",
      "epoch-173 lr=['0.0009766'], tr/val_loss:  1.512483/  1.657588, val:  86.67%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.78 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7270%\n",
      "layer   2  Sparsity: 77.8720%\n",
      "layer   3  Sparsity: 78.7130%\n",
      "total_backward_count 1703460 real_backward_count 57363   3.367%\n",
      "epoch-174 lr=['0.0009766'], tr/val_loss:  1.513993/  1.660717, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.47 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7100%\n",
      "layer   2  Sparsity: 77.8151%\n",
      "layer   3  Sparsity: 78.8674%\n",
      "total_backward_count 1713250 real_backward_count 57430   3.352%\n",
      "epoch-175 lr=['0.0009766'], tr/val_loss:  1.512423/  1.666849, val:  87.92%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.91 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7148%\n",
      "layer   2  Sparsity: 77.8311%\n",
      "layer   3  Sparsity: 78.8061%\n",
      "total_backward_count 1723040 real_backward_count 57499   3.337%\n",
      "epoch-176 lr=['0.0009766'], tr/val_loss:  1.515255/  1.659786, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.87 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6992%\n",
      "layer   2  Sparsity: 77.7766%\n",
      "layer   3  Sparsity: 78.8789%\n",
      "total_backward_count 1732830 real_backward_count 57551   3.321%\n",
      "epoch-177 lr=['0.0009766'], tr/val_loss:  1.516097/  1.665948, val:  88.75%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.58 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.7163%\n",
      "layer   2  Sparsity: 77.6634%\n",
      "layer   3  Sparsity: 78.8408%\n",
      "total_backward_count 1742620 real_backward_count 57605   3.306%\n",
      "epoch-178 lr=['0.0009766'], tr/val_loss:  1.519714/  1.655762, val:  90.00%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 83.31 seconds, 1.39 minutes\n",
      "layer   1  Sparsity: 91.6802%\n",
      "layer   2  Sparsity: 77.6294%\n",
      "layer   3  Sparsity: 78.8067%\n",
      "total_backward_count 1752410 real_backward_count 57674   3.291%\n",
      "epoch-179 lr=['0.0009766'], tr/val_loss:  1.514118/  1.658681, val:  89.17%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.85 seconds, 1.38 minutes\n",
      "layer   1  Sparsity: 91.6969%\n",
      "layer   2  Sparsity: 77.5213%\n",
      "layer   3  Sparsity: 78.8120%\n",
      "total_backward_count 1762200 real_backward_count 57733   3.276%\n",
      "fc layer 3 self.abs_max_out: 746.0\n",
      "epoch-180 lr=['0.0009766'], tr/val_loss:  1.513218/  1.663183, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.49 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7228%\n",
      "layer   2  Sparsity: 77.5833%\n",
      "layer   3  Sparsity: 78.8409%\n",
      "total_backward_count 1771990 real_backward_count 57817   3.263%\n",
      "fc layer 1 self.abs_max_out: 4618.0\n",
      "epoch-181 lr=['0.0009766'], tr/val_loss:  1.515730/  1.666770, val:  87.50%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 81.75 seconds, 1.36 minutes\n",
      "layer   1  Sparsity: 91.7407%\n",
      "layer   2  Sparsity: 77.6941%\n",
      "layer   3  Sparsity: 78.8544%\n",
      "total_backward_count 1781780 real_backward_count 57865   3.248%\n",
      "fc layer 1 self.abs_max_out: 4621.0\n",
      "epoch-182 lr=['0.0009766'], tr/val_loss:  1.511299/  1.660689, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.24 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7460%\n",
      "layer   2  Sparsity: 77.7396%\n",
      "layer   3  Sparsity: 78.9353%\n",
      "total_backward_count 1791570 real_backward_count 57934   3.234%\n",
      "epoch-183 lr=['0.0009766'], tr/val_loss:  1.509951/  1.653189, val:  88.33%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.37 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.7112%\n",
      "layer   2  Sparsity: 77.7023%\n",
      "layer   3  Sparsity: 78.8532%\n",
      "total_backward_count 1801360 real_backward_count 57992   3.219%\n",
      "epoch-184 lr=['0.0009766'], tr/val_loss:  1.510937/  1.652739, val:  87.08%, val_best:  90.83%, tr: 100.00%, tr_best: 100.00%, epoch time: 82.45 seconds, 1.37 minutes\n",
      "layer   1  Sparsity: 91.6926%\n",
      "layer   2  Sparsity: 77.6664%\n",
      "layer   3  Sparsity: 78.8239%\n",
      "total_backward_count 1811150 real_backward_count 58051   3.205%\n",
      "fc layer 1 self.abs_max_out: 4627.0\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main'\n",
    "run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "                unique_name = run_name,\n",
    "                my_seed = 1,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "                BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 14, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.25,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "                lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "                synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                learning_rate = 1/1024, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 200,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 30, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 50_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "                # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "                # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "                exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                merge_polarities = True, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = -1, \n",
    "\n",
    "                num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = False, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 5, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "                quantize_bit_list=[8,8,8],\n",
    "                scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "# 1w -11~-9\n",
    "# 1b -11~ -7\n",
    "# 2w -10~-8\n",
    "# 2b -10~-8\n",
    "# 3w -10\n",
    "# 3b -10\n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# average pooling  \n",
    "# Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# # Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         # \"my_seed\": {\"min\": 1, \"max\": 42000},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [5, 10,]},\n",
    "#         \"BATCH\": {\"values\": [1]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.5, 0.25, 0.125, 0.0625]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "#         # \"lif_layer_sg_width\": {\"values\": [4.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [3.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "#         \"learning_rate\": {\"values\": [1/128, 1/256, 1/512, 1/1024]}, \n",
    "#         \"epoch_num\": {\"values\": [200]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5, 10, 15, 20, 25, 30]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [12_000, 25_000, 50_000, 75_000, 100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [True]},\n",
    "#         \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [-1]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [False]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [5]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "#         \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "#         \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "\n",
    "#         \"scale_exp_1w\": {\"values\": [-11,-10,-9]},\n",
    "#         # \"scale_exp_1w\": {\"values\": [-10]},\n",
    "#         # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "#         # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "#         # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "#         # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "#         # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"5\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#         quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "#         scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_1w + 1,wandb.config.scale_exp_1w + 1]],\n",
    "#                         ) \n",
    "#     # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "#     # average pooling\n",
    "#     # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "#     # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = 'pyz704uj'\n",
    "# # sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
