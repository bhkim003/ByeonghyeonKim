{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(device)\n",
    "                data = zero_to_one_normalize_features(data) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                spike_template = zero_to_one_normalize_features(spike_template) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                                \n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250123_143407-4mx75q1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/4mx75q1h' target=\"_blank\">ethereal-sun-790</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/4mx75q1h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/4mx75q1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '3', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 1200, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250123_143405_354', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'coarse_com_config': (1.0, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [1200, 599, 299, 149]\n",
      "Total number of encoder parameters: 81888\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=14304, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (19): SSBH_L2NormLayer()\n",
      "      (20): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (21): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=14304, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250123_143405_354\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.08876\n",
      "ae train 실행 시간: 583.354초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25328637%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5986258230747209]\n",
      "save model\n",
      "kmeans average accuracy best : 79.91%, kmeans average accuracy : 79.90691940%, total [0.9675583380762663, 0.9701873935264055, 0.9651998849582973, 0.9562464018422567, 0.9457478005865103, 0.8985795454545454, 0.7346819114629141, 0.6520136131593874, 0.9453148093408218, 0.714907192575406, 0.5956221198156681, 0.5785002929115407, 0.9033888228299644, 0.7409012131715771, 0.6488372093023256, 0.5674205553965073]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499102 0.97058824 0.96007428 0.93389199 0.96138614 0.90714286\n",
      " 0.73293769 0.6669627  0.92675483 0.68416031 0.60541045 0.43096647\n",
      " 0.88070539 0.673258   0.62596154 0.50777676]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.84%, post_traincycle_acc : 77.71%, total_acc : 77.80301156%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 49.948초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.05094\n",
      "ae train 실행 시간: 582.699초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.91%, kmeans average accuracy : 79.11028631%, total [0.9664200341491178, 0.9699034639409426, 0.9637618636755824, 0.9571099597006333, 0.9463343108504398, 0.899715909090909, 0.723834652594547, 0.6491775382870107, 0.9402896837126811, 0.703016241299304, 0.5936059907834101, 0.5131810193321616, 0.8900118906064209, 0.7357019064124783, 0.6433139534883721, 0.5622673919267106]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96409336 0.9714795  0.96100279 0.93482309 0.96435644 0.92232143\n",
      " 0.81602374 0.64653641 0.91861648 0.6860687  0.59608209 0.4260355\n",
      " 0.87344398 0.66760829 0.63269231 0.50045746]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.23%, post_traincycle_acc : 78.01%, total_acc : 78.15509485%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 49.031초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.04837\n",
      "ae train 실행 시간: 582.412초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034119%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 80.14305192%, total [0.9675583380762663, 0.9701873935264055, 0.9651998849582973, 0.9562464018422567, 0.9448680351906158, 0.8977272727272727, 0.7332160656698915, 0.6534316505955757, 0.9435412355897133, 0.7334686774941995, 0.6057027649769585, 0.5787932044522555, 0.9152794292508918, 0.7411900635470826, 0.6444767441860465, 0.5720011451474377]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96588869 0.97326203 0.9628598  0.94040968 0.96237624 0.90714286\n",
      " 0.84965381 0.65630551 0.90844354 0.67938931 0.59048507 0.42998028\n",
      " 0.76037344 0.67137476 0.59903846 0.52241537]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.66%, post_traincycle_acc : 77.37%, total_acc : 78.26708649%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.072초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.04566\n",
      "ae train 실행 시간: 582.543초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 77.94199597%, total [0.9664200341491178, 0.9681998864281658, 0.9603106125970664, 0.9490500863557858, 0.9425219941348973, 0.8661931818181818, 0.7384931105247728, 0.633862733976177, 0.9261010937038132, 0.6603828306264501, 0.5846774193548387, 0.5102519039250146, 0.843935790725327, 0.730791450028885, 0.641860465116279, 0.5476667620956198]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95960503 0.97237077 0.95821727 0.92085661 0.95940594 0.87232143\n",
      " 0.74085064 0.62166963 0.92472024 0.67366412 0.57649254 0.4122288\n",
      " 0.79045643 0.60828625 0.60192308 0.4547118 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.47%, post_traincycle_acc : 75.30%, total_acc : 75.42405778%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.413초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.03724\n",
      "ae train 실행 시간: 582.272초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 79.52252575%, total [0.9581673306772909, 0.9613855763770585, 0.9594477998274374, 0.9476108232584917, 0.9469208211143695, 0.8977272727272727, 0.7338024039871005, 0.6562677254679523, 0.9370381318356489, 0.7088167053364269, 0.5728686635944701, 0.5005858230814294, 0.9500594530321046, 0.7622761409589832, 0.6526162790697675, 0.5780131691955339]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95691203 0.96078431 0.94893222 0.90502793 0.95742574 0.9125\n",
      " 0.83382789 0.71403197 0.9155646  0.6851145  0.58115672 0.46153846\n",
      " 0.94917012 0.55743879 0.66826923 0.52790485]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.47%, post_traincycle_acc : 78.35%, total_acc : 78.44103765%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.328초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.03683\n",
      "ae train 실행 시간: 582.642초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.24957775%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.65710343%, total [0.9536141149686966, 0.9613855763770585, 0.9597354040839804, 0.9444444444444444, 0.9387096774193548, 0.8309659090909091, 0.7250073292289652, 0.6477595008508225, 0.9394028968371269, 0.6708236658932715, 0.568836405529954, 0.5035149384885764, 0.9473840665873959, 0.7671865973425765, 0.6546511627906977, 0.5717148582880046]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95062837 0.95632799 0.94986072 0.91061453 0.95742574 0.85446429\n",
      " 0.859545   0.64920071 0.91963377 0.65171756 0.57276119 0.40828402\n",
      " 0.94502075 0.73446328 0.67980769 0.52881976]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.20%, post_traincycle_acc : 78.30%, total_acc : 78.23544906%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.417초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.03515\n",
      "ae train 실행 시간: 582.695초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 79.06984456%, total [0.9533295389869095, 0.9596819988642816, 0.9519700891573195, 0.9375359815774323, 0.9460410557184751, 0.8786931818181818, 0.752272060979185, 0.6531480431083381, 0.9391073012119421, 0.6876450116009281, 0.5653801843317973, 0.502929115407147, 0.9420332936979786, 0.7590987868284229, 0.651453488372093, 0.5708559977097051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95062837 0.94741533 0.9266481  0.86219739 0.96039604 0.90892857\n",
      " 0.82690406 0.68294849 0.91861648 0.69179389 0.53824627 0.42800789\n",
      " 0.92842324 0.58851224 0.62115385 0.51692589]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.98%, post_traincycle_acc : 76.86%, total_acc : 76.95215405%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.053초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.03157\n",
      "ae train 실행 시간: 582.680초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 77.62270636%, total [0.9507683551508253, 0.9559909142532652, 0.9407535231521427, 0.9289004029936673, 0.9325513196480938, 0.8423295454545454, 0.7387862796833773, 0.6392512762336926, 0.9305350280815844, 0.6345707656612529, 0.5469470046082949, 0.4956063268892794, 0.9084423305588585, 0.7498555748122473, 0.6534883720930232, 0.5708559977097051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94883303 0.91532977 0.89972145 0.82960894 0.94059406 0.77857143\n",
      " 0.81008902 0.6678508  0.9145473  0.73377863 0.4636194  0.43885602\n",
      " 0.89419087 0.6920904  0.60384615 0.46203111]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.33%, post_traincycle_acc : 74.96%, total_acc : 75.21860846%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.054초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02996\n",
      "ae train 실행 시간: 582.023초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.27615053%, total [0.952191235059761, 0.9571266325951164, 0.9436295657175726, 0.9283246977547496, 0.9401759530791789, 0.8298295454545455, 0.7288185282908238, 0.6361315938740782, 0.9225539462015963, 0.679814385150812, 0.5743087557603687, 0.4991212653778559, 0.9423305588585018, 0.7608318890814558, 0.6581395348837209, 0.5708559977097051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.93672014 0.91457753 0.83612663 0.94158416 0.85625\n",
      " 0.79228487 0.63765542 0.90233978 0.69274809 0.52518657 0.42899408\n",
      " 0.93983402 0.80508475 0.59711538 0.56084172]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.58%, post_traincycle_acc : 77.00%, total_acc : 76.71349569%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.324초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.02946\n",
      "ae train 실행 시간: 582.567초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.26934569%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.50882985%, total [0.9533295389869095, 0.9582623509369677, 0.9424791486914006, 0.9326424870466321, 0.9390029325513196, 0.828125, 0.714160070360598, 0.6409529211571185, 0.9444280224652675, 0.6890951276102089, 0.5783410138248848, 0.502929115407147, 0.9346016646848989, 0.7648757943385326, 0.6601744186046512, 0.5780131691955339]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.94385027 0.92293408 0.86871508 0.96336634 0.82857143\n",
      " 0.8041543  0.65630551 0.91963377 0.77385496 0.5130597  0.45069034\n",
      " 0.93360996 0.76082863 0.63653846 0.50777676]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.60%, post_traincycle_acc : 77.73%, total_acc : 77.63874334%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.313초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.02898\n",
      "ae train 실행 시간: 582.500초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.26400538%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.05366984%, total [0.9516220830961867, 0.956274843838728, 0.9398907103825137, 0.9260218767990789, 0.9416422287390029, 0.8375, 0.7217824684843155, 0.6423709585933068, 0.9432456399645285, 0.6502320185614849, 0.550979262672811, 0.4953134153485647, 0.9354934601664685, 0.7767186597342577, 0.6549418604651163, 0.5645576868021758]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94883303 0.92602496 0.89507892 0.82681564 0.96237624 0.76428571\n",
      " 0.7992087  0.6589698  0.93082401 0.67270992 0.53078358 0.43589744\n",
      " 0.93153527 0.79943503 0.60961538 0.55077768]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.34%, post_traincycle_acc : 76.52%, total_acc : 76.39887637%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.311초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.02810\n",
      "ae train 실행 시간: 582.039초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.23504266%, total [0.9504837791690381, 0.9542873367404884, 0.9355766465343687, 0.9202648244099021, 0.9357771260997068, 0.8235795454545455, 0.7276458516564057, 0.6327283040272264, 0.9305350280815844, 0.6763341067285383, 0.5567396313364056, 0.5002929115407148, 0.9268727705112961, 0.7570768341998845, 0.7154069767441861, 0.5740051531634698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94793537 0.93404635 0.89415042 0.80726257 0.94059406 0.80982143\n",
      " 0.77546983 0.6589698  0.90844354 0.73282443 0.57182836 0.42899408\n",
      " 0.9253112  0.77212806 0.67596154 0.55809698]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.45%, post_traincycle_acc : 77.14%, total_acc : 76.66631974%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.175초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.02733\n",
      "ae train 실행 시간: 582.269초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958367%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 78.21344521%, total [0.9484917472965282, 0.9540034071550255, 0.9361518550474547, 0.9176741508347726, 0.9413489736070382, 0.8414772727272727, 0.7296980357666374, 0.6369824163357912, 0.9296482412060302, 0.6760440835266821, 0.5627880184331797, 0.5313415348564734, 0.9363852556480381, 0.7478336221837089, 0.6494186046511627, 0.5748640137417692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94793537 0.91889483 0.88579387 0.79329609 0.95346535 0.78303571\n",
      " 0.74975272 0.65097691 0.91759919 0.72041985 0.53731343 0.42406312\n",
      " 0.94087137 0.7693032  0.675      0.53979872]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.89%, post_traincycle_acc : 76.30%, total_acc : 76.02144643%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.341초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.02681\n",
      "ae train 실행 시간: 582.805초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.26392268%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6009161179501861]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 76.56893548%, total [0.9490608992601024, 0.944633730834753, 0.9246476847857348, 0.9107656879677605, 0.9378299120234604, 0.7943181818181818, 0.7012606273819995, 0.6298922291548497, 0.919302394324564, 0.6490719257540604, 0.5181451612903226, 0.46690099589923845, 0.9286563614744352, 0.7504332755632582, 0.6566860465116279, 0.5694245634125393]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.92908438 0.90374332 0.87650882 0.77746741 0.95445545 0.83482143\n",
      " 0.75469832 0.64387211 0.90946083 0.71183206 0.48787313 0.40532544\n",
      " 0.93257261 0.74576271 0.70480769 0.55535224]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.51%, post_traincycle_acc : 75.80%, total_acc : 75.60289064%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.725초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.02684\n",
      "ae train 실행 시간: 582.337초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674096%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 77.38542425%, total [0.9487763232783153, 0.9477569562748438, 0.9416163359217716, 0.9153713298791019, 0.9375366568914956, 0.7994318181818182, 0.6992084432717678, 0.6250709018718095, 0.9228495418267809, 0.6438515081206496, 0.5311059907834101, 0.4707088459285296, 0.9313317479191439, 0.7518775274407856, 0.7340116279069767, 0.5811623246492986]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94524237 0.89215686 0.8718663  0.77746741 0.96039604 0.84285714\n",
      " 0.77151335 0.63587922 0.91658189 0.75       0.5        0.42406312\n",
      " 0.91804979 0.72787194 0.71538462 0.56175663]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.52%, post_traincycle_acc : 76.32%, total_acc : 75.77246056%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 49.962초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.02641\n",
      "ae train 실행 시간: 582.660초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.25675770%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 76.60786549%, total [0.9499146272054638, 0.9454855195911414, 0.9309749784296808, 0.9024179620034543, 0.9343108504398827, 0.7724431818181818, 0.683963647024333, 0.6162790697674418, 0.8613656517883536, 0.5922273781902552, 0.5072004608294931, 0.4956063268892794, 0.9236028537455411, 0.7481224725592144, 0.7348837209302326, 0.6584597766962497]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94793537 0.88770053 0.88115135 0.77839851 0.95049505 0.80803571\n",
      " 0.72205737 0.65186501 0.91047813 0.61736641 0.50186567 0.39151874\n",
      " 0.92116183 0.74293785 0.68846154 0.47483989]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.08%, post_traincycle_acc : 74.23%, total_acc : 73.43523447%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.031초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.02652\n",
      "ae train 실행 시간: 582.542초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 76.59768864%, total [0.9493454752418896, 0.9486087450312323, 0.9390278976128846, 0.9101899827288429, 0.9392961876832845, 0.8042613636363637, 0.6915860451480504, 0.6236528644356211, 0.8711203074194502, 0.6218097447795824, 0.5221774193548387, 0.46895137668424136, 0.917063020214031, 0.7481224725592144, 0.6482558139534884, 0.6521614657887203]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94614004 0.90106952 0.86722377 0.77374302 0.95346535 0.80267857\n",
      " 0.72304649 0.63055062 0.90335707 0.61354962 0.50186567 0.39053254\n",
      " 0.89937759 0.74576271 0.7125     0.53064959]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.22%, post_traincycle_acc : 74.35%, total_acc : 73.57192405%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.095초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.02627\n",
      "ae train 실행 시간: 583.217초, 전체 시작 시간 20250123_143405_354\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.24415536%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.14%, kmeans average accuracy : 77.92296258%, total [0.9496300512236767, 0.9503123225440091, 0.9381650848432557, 0.9052964881980426, 0.9363636363636364, 0.7960227272727273, 0.693051890941073, 0.6162790697674418, 0.8841265149275791, 0.6354408352668214, 0.5161290322580645, 0.4789103690685413, 0.9346016646848989, 0.8610629693818602, 0.7241279069767442, 0.6481534497566561]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.93267504 0.89661319 0.86536676 0.76536313 0.93564356 0.78482143\n",
      " 0.73194857 0.63321492 0.88911495 0.61450382 0.49813433 0.3964497\n",
      " 0.89004149 0.74199623 0.68942308 0.57639524]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.84%, post_traincycle_acc : 74.01%, total_acc : 73.21170420%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.01%\n",
      "accuracy_check 실행 시간: 50.101초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '3'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 1200 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = False # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True\n",
    "coarse_com_config = (1.0, -0.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.12.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.23.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on # True False\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "    \n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
