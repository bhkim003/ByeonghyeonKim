{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15443/4213678604.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "\n",
    "                    loser_encourage_mode = False, # True # False\n",
    "                    \n",
    "                    lif_layer_sg_width2 = None,\n",
    "                    lif_layer_v_threshold2 = None,\n",
    "                    learning_rate2 = None,\n",
    "                    init_scaling = None,\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp,\n",
    "                    ANPI_MODE=False,\n",
    "                    lif_layer_sg_width2=lif_layer_sg_width2,\n",
    "                    lif_layer_v_threshold2=lif_layer_v_threshold2,\n",
    "                    init_scaling=init_scaling).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "    #         return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "    \n",
    "\n",
    "    print(\"ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\")\n",
    "    print(\"ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\")\n",
    "    print(\"ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\")\n",
    "    print(\"ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\")\n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    if loser_encourage_mode:\n",
    "                        input_argmin = input_slice.argmin(dim=1)\n",
    "                    else:\n",
    "                        input_argmin = input_slice.argmax(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    if loser_encourage_mode:\n",
    "                        input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                    else:\n",
    "                        input_argmin = input_slice.argmax(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient Î∞©Ìñ•ÏùÑ argmin Ï™ΩÏúºÎ°ú\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                # lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        lr = learning_rate\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        lr = learning_rate2\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        lr = 1.0\n",
    "\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    \n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                            \n",
    "                    \n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    max_activation_accul = 0\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # Í∑∏ÎûòÌîÑ Í∑∏Î¶¨Í∏∞\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # Ï†úÎ™©Ïóê ÌÜµÍ≥ÑÍ∞í Ìè¨Ìï®\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            if i == 1:\n",
    "                # SYNAPSE_FCÏóê ÏûàÎäî sparsity_print_and_reset() Ïã§Ìñâ\n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                        \n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "            #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "            #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 Ï§ë ÌïòÎÇò ÏÑ†ÌÉù\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = ((outputs_one_time.detach()).argmax(dim=1) >= 5).long()\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch ÌÅ¨Í∏∞ ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        ## Îç∞Ïù¥ÌÑ∞ÎßàÎã§ TIMESTEPSÎã§Î•¥Îã§ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeÎ≥ÑÎ°ú sumÍ∞íÏù¥ 10ÎØ∏ÎßåÏùº Ïãú Ï†úÏô∏\n",
    "                        #     # time stepÎ≥Ñ Ìï© Í≥ÑÏÇ∞: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 Ïù¥ÏÉÅÏù∏ ÌÉÄÏûÑÏä§ÌÖùÎßå ÏÑ†ÌÉù\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # Ìï¥Îãπ ÌÉÄÏûÑÏä§ÌÖùÎßå Ï∂îÏ∂ú\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validÌïú time stepÏùò Í∞úÏàò\n",
    "                        #     net.module.change_timesteps(TIME) # netÏóê TIME ÏÑ§Ï†ï\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                            \n",
    "                            if max_activation_accul < outputs.abs().max().item() * TIME * (2**(-scale_exp[2][0])):\n",
    "                                max_activation_accul = outputs.abs().max().item() * TIME * (2**(-scale_exp[2][0]))\n",
    "                                print(f\"max_activation_accul updated: {max_activation_accul:.2f} at epoch {epoch}, iter {i}\")\n",
    "                       \n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.6\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "#                 BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 # n_tidigits_tonic 8\n",
    "\n",
    "#                 # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "#                 which_data = 'n_tidigits_tonic',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.03125,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "#                 lif_layer_sg_width = 6.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "#                 synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                \n",
    "#                 # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 1000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 1, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 0, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "#                 # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "#                 # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 9, \n",
    "\n",
    "#                 num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "#                 chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 8, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[-10,-10],[-10,-10],[-9,-9]], \n",
    "#                 # quantize_bit_list=[],\n",
    "#                 # scale_exp=[], \n",
    "#                 timestep_sums_threshold = 0,\n",
    "\n",
    "#                 loser_encourage_mode = True,\n",
    "                \n",
    "#                 lif_layer_sg_width2 = 4.0,\n",
    "#                 lif_layer_v_threshold2 = 8,\n",
    "#                 learning_rate2 = 8,\n",
    "#                 init_scaling = [1/4,1/4,1/4],\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "# # average pooling  \n",
    "# # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "# # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oalvfjyr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251210_235613-oalvfjyr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/oalvfjyr' target=\"_blank\">sleek-sweep-33</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/oalvfjyr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/oalvfjyr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251210_235622_650', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 128, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 64, 'lif_layer_v_threshold2': 64, 'init_scaling': [0.5, 0.0625, 0.0625], 'learning_rate': 4, 'learning_rate2': 8, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 2, self.v_threshold 128\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 64, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.0625])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=128, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.0625])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.0625])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 4\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 1132.0\n",
      "lif layer 1 self.abs_max_v: 1132.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 121.0\n",
      "lif layer 2 self.abs_max_v: 121.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 20.0\n",
      "fc layer 1 self.abs_max_out: 1739.0\n",
      "lif layer 1 self.abs_max_v: 1980.0\n",
      "fc layer 2 self.abs_max_out: 128.0\n",
      "lif layer 2 self.abs_max_v: 157.0\n",
      "fc layer 3 self.abs_max_out: 41.0\n",
      "lif layer 1 self.abs_max_v: 2041.0\n",
      "fc layer 2 self.abs_max_out: 140.0\n",
      "lif layer 2 self.abs_max_v: 180.0\n",
      "fc layer 2 self.abs_max_out: 351.0\n",
      "lif layer 2 self.abs_max_v: 371.0\n",
      "fc layer 3 self.abs_max_out: 47.0\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 90.0000%\n",
      "fc layer 2 self.abs_max_out: 534.0\n",
      "lif layer 2 self.abs_max_v: 534.0\n",
      "fc layer 3 self.abs_max_out: 49.0\n",
      "fc layer 2 self.abs_max_out: 618.0\n",
      "lif layer 2 self.abs_max_v: 618.0\n",
      "fc layer 3 self.abs_max_out: 76.0\n",
      "fc layer 3 self.abs_max_out: 81.0\n",
      "lif layer 1 self.abs_max_v: 2046.5\n",
      "fc layer 3 self.abs_max_out: 96.0\n",
      "fc layer 2 self.abs_max_out: 642.0\n",
      "lif layer 2 self.abs_max_v: 642.0\n",
      "fc layer 1 self.abs_max_out: 1806.0\n",
      "lif layer 1 self.abs_max_v: 2417.5\n",
      "lif layer 2 self.abs_max_v: 663.5\n",
      "fc layer 1 self.abs_max_out: 1858.0\n",
      "lif layer 1 self.abs_max_v: 2999.0\n",
      "lif layer 2 self.abs_max_v: 763.0\n",
      "lif layer 2 self.abs_max_v: 847.5\n",
      "fc layer 2 self.abs_max_out: 648.0\n",
      "fc layer 1 self.abs_max_out: 1920.0\n",
      "fc layer 1 self.abs_max_out: 2020.0\n",
      "fc layer 1 self.abs_max_out: 2069.0\n",
      "fc layer 2 self.abs_max_out: 666.0\n",
      "fc layer 1 self.abs_max_out: 2120.0\n",
      "fc layer 3 self.abs_max_out: 97.0\n",
      "fc layer 1 self.abs_max_out: 2273.0\n",
      "fc layer 2 self.abs_max_out: 730.0\n",
      "fc layer 3 self.abs_max_out: 98.0\n",
      "fc layer 3 self.abs_max_out: 100.0\n",
      "fc layer 1 self.abs_max_out: 2349.0\n",
      "fc layer 2 self.abs_max_out: 766.0\n",
      "fc layer 1 self.abs_max_out: 2515.0\n",
      "lif layer 1 self.abs_max_v: 3135.5\n",
      "fc layer 3 self.abs_max_out: 103.0\n",
      "fc layer 3 self.abs_max_out: 118.0\n",
      "fc layer 2 self.abs_max_out: 770.0\n",
      "fc layer 1 self.abs_max_out: 2791.0\n",
      "fc layer 2 self.abs_max_out: 860.0\n",
      "lif layer 2 self.abs_max_v: 860.0\n",
      "fc layer 3 self.abs_max_out: 124.0\n",
      "fc layer 2 self.abs_max_out: 895.0\n",
      "lif layer 2 self.abs_max_v: 895.0\n",
      "fc layer 3 self.abs_max_out: 131.0\n",
      "lif layer 1 self.abs_max_v: 3724.5\n",
      "fc layer 3 self.abs_max_out: 133.0\n",
      "fc layer 3 self.abs_max_out: 147.0\n",
      "fc layer 3 self.abs_max_out: 155.0\n",
      "fc layer 3 self.abs_max_out: 158.0\n",
      "fc layer 3 self.abs_max_out: 159.0\n",
      "fc layer 1 self.abs_max_out: 2906.0\n",
      "fc layer 1 self.abs_max_out: 3286.0\n",
      "fc layer 1 self.abs_max_out: 3364.0\n",
      "lif layer 1 self.abs_max_v: 4074.5\n",
      "fc layer 1 self.abs_max_out: 3600.0\n",
      "fc layer 1 self.abs_max_out: 3622.0\n",
      "fc layer 1 self.abs_max_out: 3661.0\n",
      "fc layer 1 self.abs_max_out: 3807.0\n",
      "fc layer 1 self.abs_max_out: 4280.0\n",
      "lif layer 1 self.abs_max_v: 4323.5\n",
      "fc layer 3 self.abs_max_out: 164.0\n",
      "fc layer 1 self.abs_max_out: 4383.0\n",
      "lif layer 1 self.abs_max_v: 4383.0\n",
      "lif layer 2 self.abs_max_v: 911.0\n",
      "lif layer 2 self.abs_max_v: 920.5\n",
      "lif layer 2 self.abs_max_v: 921.5\n",
      "fc layer 3 self.abs_max_out: 170.0\n",
      "fc layer 1 self.abs_max_out: 4496.0\n",
      "lif layer 1 self.abs_max_v: 4496.0\n",
      "lif layer 2 self.abs_max_v: 958.0\n",
      "lif layer 2 self.abs_max_v: 972.5\n",
      "fc layer 1 self.abs_max_out: 4599.0\n",
      "lif layer 1 self.abs_max_v: 4595.0\n",
      "lif layer 1 self.abs_max_v: 4642.0\n",
      "fc layer 2 self.abs_max_out: 907.0\n",
      "fc layer 2 self.abs_max_out: 914.0\n",
      "fc layer 2 self.abs_max_out: 919.0\n",
      "fc layer 2 self.abs_max_out: 928.0\n",
      "fc layer 2 self.abs_max_out: 951.0\n",
      "lif layer 2 self.abs_max_v: 977.0\n",
      "fc layer 3 self.abs_max_out: 184.0\n",
      "fc layer 3 self.abs_max_out: 189.0\n",
      "lif layer 2 self.abs_max_v: 1031.5\n",
      "lif layer 2 self.abs_max_v: 1035.5\n",
      "lif layer 2 self.abs_max_v: 1081.0\n",
      "lif layer 1 self.abs_max_v: 4731.5\n",
      "lif layer 1 self.abs_max_v: 4909.0\n",
      "lif layer 2 self.abs_max_v: 1084.0\n",
      "lif layer 2 self.abs_max_v: 1117.5\n",
      "lif layer 2 self.abs_max_v: 1159.5\n",
      "lif layer 2 self.abs_max_v: 1276.5\n",
      "lif layer 1 self.abs_max_v: 4917.5\n",
      "lif layer 2 self.abs_max_v: 1327.5\n",
      "lif layer 1 self.abs_max_v: 4963.0\n",
      "fc layer 1 self.abs_max_out: 4620.0\n",
      "lif layer 1 self.abs_max_v: 5051.0\n",
      "lif layer 1 self.abs_max_v: 6343.5\n",
      "lif layer 2 self.abs_max_v: 1339.5\n",
      "fc layer 2 self.abs_max_out: 977.0\n",
      "lif layer 2 self.abs_max_v: 1459.0\n",
      "lif layer 2 self.abs_max_v: 1495.0\n",
      "fc layer 2 self.abs_max_out: 1004.0\n",
      "fc layer 2 self.abs_max_out: 1029.0\n",
      "lif layer 2 self.abs_max_v: 1512.5\n",
      "fc layer 2 self.abs_max_out: 1030.0\n",
      "lif layer 2 self.abs_max_v: 1592.0\n",
      "fc layer 1 self.abs_max_out: 4621.0\n",
      "lif layer 2 self.abs_max_v: 1596.0\n",
      "fc layer 1 self.abs_max_out: 4755.0\n",
      "fc layer 1 self.abs_max_out: 5134.0\n",
      "fc layer 1 self.abs_max_out: 5276.0\n",
      "fc layer 1 self.abs_max_out: 5536.0\n",
      "fc layer 1 self.abs_max_out: 5835.0\n",
      "fc layer 3 self.abs_max_out: 190.0\n",
      "fc layer 3 self.abs_max_out: 192.0\n",
      "fc layer 3 self.abs_max_out: 195.0\n",
      "fc layer 3 self.abs_max_out: 196.0\n",
      "fc layer 3 self.abs_max_out: 207.0\n",
      "fc layer 1 self.abs_max_out: 6173.0\n",
      "lif layer 2 self.abs_max_v: 1617.0\n",
      "fc layer 2 self.abs_max_out: 1154.0\n",
      "lif layer 1 self.abs_max_v: 6467.0\n",
      "fc layer 2 self.abs_max_out: 1186.0\n",
      "fc layer 2 self.abs_max_out: 1275.0\n",
      "lif layer 1 self.abs_max_v: 6712.0\n",
      "lif layer 2 self.abs_max_v: 1681.0\n",
      "fc layer 2 self.abs_max_out: 1346.0\n",
      "fc layer 2 self.abs_max_out: 1621.0\n",
      "lif layer 1 self.abs_max_v: 6837.0\n",
      "lif layer 2 self.abs_max_v: 1821.0\n",
      "lif layer 1 self.abs_max_v: 6911.5\n",
      "fc layer 2 self.abs_max_out: 1629.0\n",
      "fc layer 2 self.abs_max_out: 1636.0\n",
      "fc layer 2 self.abs_max_out: 1682.0\n",
      "lif layer 1 self.abs_max_v: 7293.0\n",
      "fc layer 1 self.abs_max_out: 6547.0\n",
      "fc layer 1 self.abs_max_out: 6601.0\n",
      "fc layer 1 self.abs_max_out: 6822.0\n",
      "lif layer 1 self.abs_max_v: 7631.0\n",
      "lif layer 1 self.abs_max_v: 7817.0\n",
      "fc layer 3 self.abs_max_out: 221.0\n",
      "fc layer 3 self.abs_max_out: 228.0\n",
      "lif layer 1 self.abs_max_v: 9430.0\n",
      "fc layer 3 self.abs_max_out: 234.0\n",
      "lif layer 1 self.abs_max_v: 9456.5\n",
      "fc layer 1 self.abs_max_out: 6847.0\n",
      "lif layer 2 self.abs_max_v: 1842.5\n",
      "lif layer 2 self.abs_max_v: 1858.0\n",
      "lif layer 1 self.abs_max_v: 9875.5\n",
      "lif layer 2 self.abs_max_v: 1876.0\n",
      "lif layer 2 self.abs_max_v: 1965.5\n",
      "lif layer 2 self.abs_max_v: 2006.0\n",
      "lif layer 2 self.abs_max_v: 2036.5\n",
      "lif layer 2 self.abs_max_v: 2057.0\n",
      "lif layer 2 self.abs_max_v: 2300.5\n",
      "lif layer 2 self.abs_max_v: 2428.5\n",
      "lif layer 2 self.abs_max_v: 2448.0\n",
      "fc layer 1 self.abs_max_out: 6959.0\n",
      "lif layer 2 self.abs_max_v: 2456.0\n",
      "lif layer 2 self.abs_max_v: 2457.5\n",
      "lif layer 2 self.abs_max_v: 2463.0\n",
      "fc layer 3 self.abs_max_out: 250.0\n",
      "lif layer 2 self.abs_max_v: 2468.0\n",
      "fc layer 2 self.abs_max_out: 1685.0\n",
      "fc layer 1 self.abs_max_out: 7020.0\n",
      "lif layer 1 self.abs_max_v: 10039.5\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 703.00 at epoch 0, iter 4031\n",
      "fc layer 3 self.abs_max_out: 251.0\n",
      "max_activation_accul updated: 909.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 911.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 928.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 936.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 937.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 944.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 945.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 961.00 at epoch 0, iter 4031\n",
      "fc layer 3 self.abs_max_out: 257.0\n",
      "max_activation_accul updated: 964.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['4.0000000'], tr/val_loss: 84.771187/230.455231, val:  50.00%, val_best:  50.00%, tr:  87.90%, tr_best:  87.90%, epoch time: 133.78 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 58.9457%\n",
      "layer   3  Sparsity: 75.1288%\n",
      "total_backward_count 16128 real_backward_count 3486  21.615%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 73.3398%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 71.6250%\n",
      "fc layer 1 self.abs_max_out: 7173.0\n",
      "fc layer 3 self.abs_max_out: 258.0\n",
      "fc layer 1 self.abs_max_out: 7326.0\n",
      "fc layer 1 self.abs_max_out: 7484.0\n",
      "fc layer 1 self.abs_max_out: 8049.0\n",
      "fc layer 3 self.abs_max_out: 266.0\n",
      "fc layer 3 self.abs_max_out: 271.0\n",
      "fc layer 3 self.abs_max_out: 275.0\n",
      "fc layer 3 self.abs_max_out: 276.0\n",
      "fc layer 3 self.abs_max_out: 295.0\n",
      "fc layer 2 self.abs_max_out: 1706.0\n",
      "fc layer 1 self.abs_max_out: 8093.0\n",
      "fc layer 2 self.abs_max_out: 1803.0\n",
      "fc layer 3 self.abs_max_out: 316.0\n",
      "fc layer 2 self.abs_max_out: 1814.0\n",
      "fc layer 2 self.abs_max_out: 1919.0\n",
      "fc layer 2 self.abs_max_out: 1937.0\n",
      "fc layer 2 self.abs_max_out: 1957.0\n",
      "fc layer 2 self.abs_max_out: 2036.0\n",
      "fc layer 3 self.abs_max_out: 323.0\n",
      "fc layer 3 self.abs_max_out: 324.0\n",
      "fc layer 2 self.abs_max_out: 2040.0\n",
      "fc layer 3 self.abs_max_out: 332.0\n",
      "fc layer 1 self.abs_max_out: 8203.0\n",
      "fc layer 3 self.abs_max_out: 340.0\n",
      "fc layer 2 self.abs_max_out: 2116.0\n",
      "fc layer 2 self.abs_max_out: 2136.0\n",
      "fc layer 2 self.abs_max_out: 2159.0\n",
      "fc layer 1 self.abs_max_out: 8332.0\n",
      "fc layer 1 self.abs_max_out: 8374.0\n",
      "fc layer 1 self.abs_max_out: 8751.0\n",
      "fc layer 1 self.abs_max_out: 9273.0\n",
      "fc layer 1 self.abs_max_out: 9390.0\n",
      "lif layer 2 self.abs_max_v: 2675.0\n",
      "fc layer 1 self.abs_max_out: 9717.0\n",
      "lif layer 1 self.abs_max_v: 10297.0\n",
      "fc layer 2 self.abs_max_out: 2218.0\n",
      "fc layer 2 self.abs_max_out: 2255.0\n",
      "fc layer 2 self.abs_max_out: 2688.0\n",
      "lif layer 2 self.abs_max_v: 2688.0\n",
      "fc layer 1 self.abs_max_out: 9842.0\n",
      "fc layer 2 self.abs_max_out: 2770.0\n",
      "lif layer 2 self.abs_max_v: 2770.0\n",
      "fc layer 1 self.abs_max_out: 9971.0\n",
      "lif layer 1 self.abs_max_v: 11023.0\n",
      "fc layer 1 self.abs_max_out: 10540.0\n",
      "lif layer 1 self.abs_max_v: 11491.5\n",
      "fc layer 2 self.abs_max_out: 2789.0\n",
      "lif layer 2 self.abs_max_v: 2789.0\n",
      "fc layer 2 self.abs_max_out: 2883.0\n",
      "lif layer 2 self.abs_max_v: 2883.0\n",
      "lif layer 1 self.abs_max_v: 11552.5\n",
      "fc layer 2 self.abs_max_out: 3008.0\n",
      "lif layer 2 self.abs_max_v: 3008.0\n",
      "fc layer 2 self.abs_max_out: 3013.0\n",
      "lif layer 2 self.abs_max_v: 3013.0\n",
      "fc layer 1 self.abs_max_out: 10706.0\n",
      "fc layer 2 self.abs_max_out: 3016.0\n",
      "lif layer 2 self.abs_max_v: 3016.0\n",
      "fc layer 1 self.abs_max_out: 10719.0\n",
      "fc layer 3 self.abs_max_out: 344.0\n",
      "lif layer 2 self.abs_max_v: 3019.5\n",
      "fc layer 2 self.abs_max_out: 3037.0\n",
      "lif layer 2 self.abs_max_v: 3037.0\n",
      "fc layer 3 self.abs_max_out: 364.0\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 10963.0\n",
      "max_activation_accul updated: 979.00 at epoch 1, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['4.0000000'], tr/val_loss:164.199783/136.877258, val:  50.00%, val_best:  50.00%, tr:  86.11%, tr_best:  87.90%, epoch time: 129.52 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 55.8177%\n",
      "layer   3  Sparsity: 73.5819%\n",
      "total_backward_count 32256 real_backward_count 7046  21.844%\n",
      "layer   1  Sparsity: 81.4453%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "lif layer 2 self.abs_max_v: 3111.0\n",
      "lif layer 1 self.abs_max_v: 11993.0\n",
      "lif layer 2 self.abs_max_v: 3348.5\n",
      "lif layer 2 self.abs_max_v: 3374.0\n",
      "lif layer 2 self.abs_max_v: 3376.5\n",
      "lif layer 1 self.abs_max_v: 12483.0\n",
      "lif layer 2 self.abs_max_v: 3972.5\n",
      "fc layer 2 self.abs_max_out: 3040.0\n",
      "lif layer 1 self.abs_max_v: 12623.0\n",
      "fc layer 1 self.abs_max_out: 10979.0\n",
      "lif layer 1 self.abs_max_v: 13374.0\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 993.00 at epoch 2, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['4.0000000'], tr/val_loss:187.128036/195.415039, val:  50.00%, val_best:  50.00%, tr:  88.39%, tr_best:  88.39%, epoch time: 131.39 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 55.8294%\n",
      "layer   3  Sparsity: 74.8983%\n",
      "total_backward_count 48384 real_backward_count 10492  21.685%\n",
      "layer   1  Sparsity: 72.9980%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "lif layer 1 self.abs_max_v: 13464.5\n",
      "lif layer 1 self.abs_max_v: 13748.0\n",
      "fc layer 2 self.abs_max_out: 3056.0\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1193.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 1200.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 1280.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 1286.00 at epoch 3, iter 4031\n",
      "fc layer 3 self.abs_max_out: 372.0\n",
      "max_activation_accul updated: 1300.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 1385.00 at epoch 3, iter 4031\n",
      "fc layer 3 self.abs_max_out: 382.0\n",
      "max_activation_accul updated: 1387.00 at epoch 3, iter 4031\n",
      "fc layer 3 self.abs_max_out: 383.0\n",
      "max_activation_accul updated: 1412.00 at epoch 3, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['4.0000000'], tr/val_loss:182.881073/284.991882, val:  50.00%, val_best:  50.00%, tr:  87.45%, tr_best:  88.39%, epoch time: 131.32 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 55.4118%\n",
      "layer   3  Sparsity: 75.0986%\n",
      "total_backward_count 64512 real_backward_count 13954  21.630%\n",
      "layer   1  Sparsity: 73.9258%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 74.1250%\n",
      "lif layer 1 self.abs_max_v: 14641.0\n",
      "lif layer 2 self.abs_max_v: 4107.5\n",
      "lif layer 2 self.abs_max_v: 4209.0\n",
      "fc layer 1 self.abs_max_out: 11084.0\n",
      "fc layer 2 self.abs_max_out: 3059.0\n",
      "fc layer 1 self.abs_max_out: 11262.0\n",
      "fc layer 1 self.abs_max_out: 11446.0\n",
      "fc layer 1 self.abs_max_out: 11513.0\n",
      "fc layer 2 self.abs_max_out: 3118.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-4   lr=['4.0000000'], tr/val_loss:221.210022/154.229858, val:  73.89%, val_best:  73.89%, tr:  88.49%, tr_best:  88.49%, epoch time: 132.20 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 55.9570%\n",
      "layer   3  Sparsity: 75.3871%\n",
      "total_backward_count 80640 real_backward_count 17384  21.558%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 65.2500%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "fc layer 2 self.abs_max_out: 3250.0\n",
      "fc layer 2 self.abs_max_out: 3496.0\n",
      "fc layer 2 self.abs_max_out: 3520.0\n",
      "fc layer 2 self.abs_max_out: 3644.0\n",
      "fc layer 2 self.abs_max_out: 3703.0\n",
      "fc layer 2 self.abs_max_out: 3837.0\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['4.0000000'], tr/val_loss:161.270798/256.099091, val:  50.00%, val_best:  73.89%, tr:  88.14%, tr_best:  88.49%, epoch time: 133.34 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 56.0864%\n",
      "layer   3  Sparsity: 75.4754%\n",
      "total_backward_count 96768 real_backward_count 20865  21.562%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 74.3750%\n",
      "lif layer 2 self.abs_max_v: 4299.0\n",
      "lif layer 2 self.abs_max_v: 4665.5\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-6   lr=['4.0000000'], tr/val_loss:236.258804/232.451248, val:  59.51%, val_best:  73.89%, tr:  88.64%, tr_best:  88.64%, epoch time: 132.86 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 55.8925%\n",
      "layer   3  Sparsity: 75.5340%\n",
      "total_backward_count 112896 real_backward_count 24205  21.440%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "fc layer 2 self.abs_max_out: 3869.0\n",
      "lif layer 2 self.abs_max_v: 4755.0\n",
      "lif layer 2 self.abs_max_v: 5005.5\n",
      "lif layer 2 self.abs_max_v: 5623.0\n",
      "fc layer 2 self.abs_max_out: 3955.0\n",
      "fc layer 2 self.abs_max_out: 3970.0\n",
      "fc layer 2 self.abs_max_out: 4022.0\n",
      "fc layer 2 self.abs_max_out: 4504.0\n",
      "lif layer 2 self.abs_max_v: 5987.0\n",
      "lif layer 2 self.abs_max_v: 7119.5\n",
      "lif layer 2 self.abs_max_v: 7503.5\n",
      "fc layer 2 self.abs_max_out: 4756.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 3 self.abs_max_out: 392.0\n",
      "fc layer 3 self.abs_max_out: 394.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['4.0000000'], tr/val_loss:251.566086/278.257324, val:  50.00%, val_best:  73.89%, tr:  88.47%, tr_best:  88.64%, epoch time: 134.19 seconds, 2.24 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 56.2136%\n",
      "layer   3  Sparsity: 74.9525%\n",
      "total_backward_count 129024 real_backward_count 27420  21.252%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 74.6250%\n",
      "lif layer 2 self.abs_max_v: 7824.5\n",
      "fc layer 2 self.abs_max_out: 5187.0\n",
      "fc layer 2 self.abs_max_out: 5196.0\n",
      "fc layer 3 self.abs_max_out: 396.0\n",
      "fc layer 3 self.abs_max_out: 404.0\n",
      "fc layer 3 self.abs_max_out: 407.0\n",
      "fc layer 3 self.abs_max_out: 416.0\n",
      "fc layer 3 self.abs_max_out: 420.0\n",
      "lif layer 2 self.abs_max_v: 8286.0\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-8   lr=['4.0000000'], tr/val_loss:244.514328/217.897385, val:  55.31%, val_best:  73.89%, tr:  87.95%, tr_best:  88.64%, epoch time: 132.40 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 56.0458%\n",
      "layer   3  Sparsity: 75.2486%\n",
      "total_backward_count 145152 real_backward_count 30920  21.302%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 75.7500%\n",
      "lif layer 1 self.abs_max_v: 14853.0\n",
      "lif layer 1 self.abs_max_v: 15380.5\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['4.0000000'], tr/val_loss:174.030273/297.219299, val:  50.00%, val_best:  73.89%, tr:  90.15%, tr_best:  90.15%, epoch time: 133.24 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 56.6894%\n",
      "layer   3  Sparsity: 74.0775%\n",
      "total_backward_count 161280 real_backward_count 34161  21.181%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 67.6250%\n",
      "fc layer 3 self.abs_max_out: 421.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 421 occurrences\n",
      "test - Value 1: 31 occurrences\n",
      "epoch-10  lr=['4.0000000'], tr/val_loss:251.302368/271.761536, val:  56.86%, val_best:  73.89%, tr:  88.22%, tr_best:  90.15%, epoch time: 133.02 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 55.8679%\n",
      "layer   3  Sparsity: 71.0279%\n",
      "total_backward_count 177408 real_backward_count 37245  20.994%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 69.3750%\n",
      "fc layer 3 self.abs_max_out: 423.0\n",
      "fc layer 3 self.abs_max_out: 430.0\n",
      "fc layer 3 self.abs_max_out: 431.0\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-11  lr=['4.0000000'], tr/val_loss:205.812347/204.523819, val:  73.89%, val_best:  73.89%, tr:  90.13%, tr_best:  90.15%, epoch time: 133.71 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 58.0997%\n",
      "layer   3  Sparsity: 71.1441%\n",
      "total_backward_count 193536 real_backward_count 40379  20.864%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 66.6250%\n",
      "layer   3  Sparsity: 76.6250%\n",
      "lif layer 1 self.abs_max_v: 16089.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 245 occurrences\n",
      "test - Value 1: 207 occurrences\n",
      "epoch-12  lr=['4.0000000'], tr/val_loss:241.302399/202.995239, val:  78.10%, val_best:  78.10%, tr:  89.81%, tr_best:  90.15%, epoch time: 132.61 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 58.4370%\n",
      "layer   3  Sparsity: 71.6519%\n",
      "total_backward_count 209664 real_backward_count 43477  20.737%\n",
      "layer   1  Sparsity: 87.1094%\n",
      "layer   2  Sparsity: 65.8750%\n",
      "layer   3  Sparsity: 77.1250%\n",
      "fc layer 3 self.abs_max_out: 433.0\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 269 occurrences\n",
      "test - Value 1: 183 occurrences\n",
      "epoch-13  lr=['4.0000000'], tr/val_loss:185.819748/252.875946, val:  78.98%, val_best:  78.98%, tr:  91.15%, tr_best:  91.15%, epoch time: 133.46 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 56.5265%\n",
      "layer   3  Sparsity: 72.4138%\n",
      "total_backward_count 225792 real_backward_count 46510  20.599%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 63.3750%\n",
      "layer   3  Sparsity: 78.3750%\n",
      "fc layer 3 self.abs_max_out: 437.0\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-14  lr=['4.0000000'], tr/val_loss:260.070435/242.729568, val:  69.69%, val_best:  78.98%, tr:  91.29%, tr_best:  91.29%, epoch time: 133.46 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 55.6682%\n",
      "layer   3  Sparsity: 73.2997%\n",
      "total_backward_count 241920 real_backward_count 49488  20.456%\n",
      "layer   1  Sparsity: 92.3340%\n",
      "layer   2  Sparsity: 75.3750%\n",
      "layer   3  Sparsity: 85.6250%\n",
      "fc layer 3 self.abs_max_out: 442.0\n",
      "fc layer 1 self.abs_max_out: 11550.0\n",
      "lif layer 1 self.abs_max_v: 17027.5\n",
      "fc layer 1 self.abs_max_out: 11593.0\n",
      "fc layer 3 self.abs_max_out: 448.0\n",
      "fc layer 1 self.abs_max_out: 11756.0\n",
      "fc layer 1 self.abs_max_out: 12018.0\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-15  lr=['4.0000000'], tr/val_loss:256.577515/244.023209, val:  75.88%, val_best:  78.98%, tr:  91.39%, tr_best:  91.39%, epoch time: 132.96 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 55.9325%\n",
      "layer   3  Sparsity: 73.5520%\n",
      "total_backward_count 258048 real_backward_count 52526  20.355%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 71.8750%\n",
      "fc layer 1 self.abs_max_out: 12118.0\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-16  lr=['4.0000000'], tr/val_loss:268.336121/264.803131, val:  80.97%, val_best:  80.97%, tr:  92.24%, tr_best:  92.24%, epoch time: 131.88 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 56.1828%\n",
      "layer   3  Sparsity: 73.9448%\n",
      "total_backward_count 274176 real_backward_count 55463  20.229%\n",
      "layer   1  Sparsity: 72.9004%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "fc layer 1 self.abs_max_out: 12666.0\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 84 occurrences\n",
      "test - Value 1: 368 occurrences\n",
      "epoch-17  lr=['4.0000000'], tr/val_loss:276.589966/272.101196, val:  67.26%, val_best:  80.97%, tr:  91.42%, tr_best:  92.24%, epoch time: 132.25 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 55.9769%\n",
      "layer   3  Sparsity: 73.9341%\n",
      "total_backward_count 290304 real_backward_count 58328  20.092%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-18  lr=['4.0000000'], tr/val_loss:277.118927/283.386841, val:  57.74%, val_best:  80.97%, tr:  91.82%, tr_best:  92.24%, epoch time: 132.69 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 55.8809%\n",
      "layer   3  Sparsity: 73.9148%\n",
      "total_backward_count 306432 real_backward_count 61188  19.968%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 79.1250%\n",
      "fc layer 1 self.abs_max_out: 12675.0\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-19  lr=['4.0000000'], tr/val_loss:280.077637/290.771576, val:  52.43%, val_best:  80.97%, tr:  92.46%, tr_best:  92.46%, epoch time: 133.51 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 55.8023%\n",
      "layer   3  Sparsity: 73.8247%\n",
      "total_backward_count 322560 real_backward_count 63968  19.831%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 48.7500%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "fc layer 1 self.abs_max_out: 13520.0\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-20  lr=['4.0000000'], tr/val_loss:275.055115/265.875916, val:  72.12%, val_best:  80.97%, tr:  91.96%, tr_best:  92.46%, epoch time: 133.38 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 55.6970%\n",
      "layer   3  Sparsity: 73.5325%\n",
      "total_backward_count 338688 real_backward_count 66824  19.730%\n",
      "layer   1  Sparsity: 84.8633%\n",
      "layer   2  Sparsity: 62.7500%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 1938 occurrences\n",
      "train - Value 1: 2094 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-21  lr=['4.0000000'], tr/val_loss:267.271271/256.151184, val:  72.79%, val_best:  80.97%, tr:  92.21%, tr_best:  92.46%, epoch time: 132.04 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 55.4611%\n",
      "layer   3  Sparsity: 73.4815%\n",
      "total_backward_count 354816 real_backward_count 69678  19.638%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 71.6250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1428.00 at epoch 22, iter 4031\n",
      "max_activation_accul updated: 1461.00 at epoch 22, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['4.0000000'], tr/val_loss:266.082397/300.631256, val:  50.00%, val_best:  80.97%, tr:  92.09%, tr_best:  92.46%, epoch time: 131.81 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 55.4558%\n",
      "layer   3  Sparsity: 73.4642%\n",
      "total_backward_count 370944 real_backward_count 72615  19.576%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 49.5000%\n",
      "layer   3  Sparsity: 71.6250%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-23  lr=['4.0000000'], tr/val_loss:267.580963/255.286728, val:  81.42%, val_best:  81.42%, tr:  92.21%, tr_best:  92.46%, epoch time: 132.89 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 55.5656%\n",
      "layer   3  Sparsity: 73.4510%\n",
      "total_backward_count 387072 real_backward_count 75521  19.511%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "fc layer 3 self.abs_max_out: 451.0\n",
      "fc layer 3 self.abs_max_out: 458.0\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-24  lr=['4.0000000'], tr/val_loss:274.788300/282.549011, val:  58.19%, val_best:  81.42%, tr:  93.53%, tr_best:  93.53%, epoch time: 132.73 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 55.3100%\n",
      "layer   3  Sparsity: 73.5262%\n",
      "total_backward_count 403200 real_backward_count 78400  19.444%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 47.5000%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "fc layer 3 self.abs_max_out: 475.0\n",
      "fc layer 3 self.abs_max_out: 485.0\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-25  lr=['4.0000000'], tr/val_loss:279.019867/264.832642, val:  79.87%, val_best:  81.42%, tr:  94.79%, tr_best:  94.79%, epoch time: 133.42 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 55.5630%\n",
      "layer   3  Sparsity: 73.6562%\n",
      "total_backward_count 419328 real_backward_count 81061  19.331%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 49.2500%\n",
      "layer   3  Sparsity: 71.6250%\n",
      "fc layer 3 self.abs_max_out: 487.0\n",
      "fc layer 3 self.abs_max_out: 495.0\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-26  lr=['4.0000000'], tr/val_loss:279.794128/266.901855, val:  53.76%, val_best:  81.42%, tr:  94.00%, tr_best:  94.79%, epoch time: 133.02 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 55.4859%\n",
      "layer   3  Sparsity: 73.4300%\n",
      "total_backward_count 435456 real_backward_count 83922  19.272%\n",
      "layer   1  Sparsity: 70.8984%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 71.5000%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-27  lr=['4.0000000'], tr/val_loss:267.647217/255.575424, val:  74.56%, val_best:  81.42%, tr:  93.50%, tr_best:  94.79%, epoch time: 132.37 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 55.5767%\n",
      "layer   3  Sparsity: 73.4440%\n",
      "total_backward_count 451584 real_backward_count 86789  19.219%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 71.5000%\n",
      "lif layer 1 self.abs_max_v: 17362.0\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-28  lr=['4.0000000'], tr/val_loss:258.454498/248.263306, val:  82.08%, val_best:  82.08%, tr:  94.47%, tr_best:  94.79%, epoch time: 131.76 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 55.5302%\n",
      "layer   3  Sparsity: 73.3962%\n",
      "total_backward_count 467712 real_backward_count 89451  19.125%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 53.2500%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1481.00 at epoch 29, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-29  lr=['4.0000000'], tr/val_loss:273.770813/298.821899, val:  53.10%, val_best:  82.08%, tr:  95.24%, tr_best:  95.24%, epoch time: 133.74 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 55.3236%\n",
      "layer   3  Sparsity: 73.3586%\n",
      "total_backward_count 483840 real_backward_count 91969  19.008%\n",
      "layer   1  Sparsity: 88.4766%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "fc layer 1 self.abs_max_out: 13602.0\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-30  lr=['4.0000000'], tr/val_loss:289.923798/268.060638, val:  77.43%, val_best:  82.08%, tr:  96.33%, tr_best:  96.33%, epoch time: 131.76 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 55.2697%\n",
      "layer   3  Sparsity: 73.4259%\n",
      "total_backward_count 499968 real_backward_count 94295  18.860%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 43.3750%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-31  lr=['4.0000000'], tr/val_loss:286.558289/278.255859, val:  68.58%, val_best:  82.08%, tr:  94.62%, tr_best:  96.33%, epoch time: 128.61 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 55.0388%\n",
      "layer   3  Sparsity: 73.4034%\n",
      "total_backward_count 516096 real_backward_count 96795  18.755%\n",
      "layer   1  Sparsity: 71.8750%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 71.5000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-32  lr=['4.0000000'], tr/val_loss:279.091309/271.289612, val:  80.31%, val_best:  82.08%, tr:  95.86%, tr_best:  96.33%, epoch time: 132.30 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 54.8057%\n",
      "layer   3  Sparsity: 73.7700%\n",
      "total_backward_count 532224 real_backward_count 99171  18.633%\n",
      "layer   1  Sparsity: 88.1836%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-33  lr=['4.0000000'], tr/val_loss:279.998505/161.826813, val:  76.11%, val_best:  82.08%, tr:  96.28%, tr_best:  96.33%, epoch time: 131.29 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.5811%\n",
      "layer   3  Sparsity: 74.1528%\n",
      "total_backward_count 548352 real_backward_count 101508  18.511%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-34  lr=['4.0000000'], tr/val_loss:255.085632/252.228867, val:  76.33%, val_best:  82.08%, tr:  95.14%, tr_best:  96.33%, epoch time: 130.44 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.9389%\n",
      "layer   3  Sparsity: 74.1664%\n",
      "total_backward_count 564480 real_backward_count 103893  18.405%\n",
      "layer   1  Sparsity: 86.8164%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 266 occurrences\n",
      "test - Value 1: 186 occurrences\n",
      "epoch-35  lr=['4.0000000'], tr/val_loss:224.515854/182.095383, val:  79.65%, val_best:  82.08%, tr:  95.36%, tr_best:  96.33%, epoch time: 131.84 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 54.9900%\n",
      "layer   3  Sparsity: 74.5988%\n",
      "total_backward_count 580608 real_backward_count 106303  18.309%\n",
      "layer   1  Sparsity: 93.5547%\n",
      "layer   2  Sparsity: 72.6250%\n",
      "layer   3  Sparsity: 80.2500%\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-36  lr=['4.0000000'], tr/val_loss:194.099792/173.241898, val:  82.08%, val_best:  82.08%, tr:  93.77%, tr_best:  96.33%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 54.7551%\n",
      "layer   3  Sparsity: 74.7725%\n",
      "total_backward_count 596736 real_backward_count 108877  18.245%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-37  lr=['4.0000000'], tr/val_loss:199.030701/246.049622, val:  52.88%, val_best:  82.08%, tr:  95.66%, tr_best:  96.33%, epoch time: 131.17 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 54.6292%\n",
      "layer   3  Sparsity: 74.8476%\n",
      "total_backward_count 612864 real_backward_count 111324  18.165%\n",
      "layer   1  Sparsity: 68.7988%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "fc layer 1 self.abs_max_out: 13724.0\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 5579.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-38  lr=['4.0000000'], tr/val_loss:263.030853/271.238708, val:  62.17%, val_best:  82.08%, tr:  93.20%, tr_best:  96.33%, epoch time: 133.14 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4835%\n",
      "layer   2  Sparsity: 54.5884%\n",
      "layer   3  Sparsity: 74.8500%\n",
      "total_backward_count 628992 real_backward_count 113919  18.111%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-39  lr=['4.0000000'], tr/val_loss:258.193481/254.449066, val:  50.88%, val_best:  82.08%, tr:  96.43%, tr_best:  96.43%, epoch time: 132.29 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 55.2557%\n",
      "layer   3  Sparsity: 74.7428%\n",
      "total_backward_count 645120 real_backward_count 116234  18.017%\n",
      "layer   1  Sparsity: 75.8789%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "fc layer 1 self.abs_max_out: 13727.0\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-40  lr=['4.0000000'], tr/val_loss:261.229095/245.045029, val:  79.42%, val_best:  82.08%, tr:  94.72%, tr_best:  96.43%, epoch time: 132.55 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4819%\n",
      "layer   2  Sparsity: 54.8910%\n",
      "layer   3  Sparsity: 74.8328%\n",
      "total_backward_count 661248 real_backward_count 118588  17.934%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-41  lr=['4.0000000'], tr/val_loss:273.240112/260.542694, val:  72.35%, val_best:  82.08%, tr:  95.76%, tr_best:  96.43%, epoch time: 132.29 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 54.4447%\n",
      "layer   3  Sparsity: 74.6291%\n",
      "total_backward_count 677376 real_backward_count 120850  17.841%\n",
      "layer   1  Sparsity: 67.2852%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 73.0000%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-42  lr=['4.0000000'], tr/val_loss:253.591370/244.305374, val:  69.47%, val_best:  82.08%, tr:  96.55%, tr_best:  96.55%, epoch time: 132.43 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 55.0307%\n",
      "layer   3  Sparsity: 74.6844%\n",
      "total_backward_count 693504 real_backward_count 122985  17.734%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-43  lr=['4.0000000'], tr/val_loss:245.304550/241.040039, val:  84.29%, val_best:  84.29%, tr:  95.91%, tr_best:  96.55%, epoch time: 132.68 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 54.5755%\n",
      "layer   3  Sparsity: 74.6017%\n",
      "total_backward_count 709632 real_backward_count 125237  17.648%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 17633.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-44  lr=['4.0000000'], tr/val_loss:257.584412/254.045853, val:  72.35%, val_best:  84.29%, tr:  97.40%, tr_best:  97.40%, epoch time: 132.64 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.8470%\n",
      "layer   3  Sparsity: 74.6328%\n",
      "total_backward_count 725760 real_backward_count 127318  17.543%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 56.5000%\n",
      "layer   3  Sparsity: 73.0000%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-45  lr=['4.0000000'], tr/val_loss:265.485992/250.179962, val:  84.51%, val_best:  84.51%, tr:  96.95%, tr_best:  97.40%, epoch time: 132.88 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 53.8235%\n",
      "layer   3  Sparsity: 74.6462%\n",
      "total_backward_count 741888 real_backward_count 129430  17.446%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 69.5000%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 17743.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-46  lr=['4.0000000'], tr/val_loss:271.255280/258.428894, val:  75.00%, val_best:  84.51%, tr:  97.05%, tr_best:  97.40%, epoch time: 131.46 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 53.8571%\n",
      "layer   3  Sparsity: 74.6629%\n",
      "total_backward_count 758016 real_backward_count 131599  17.361%\n",
      "layer   1  Sparsity: 70.5566%\n",
      "layer   2  Sparsity: 48.2500%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-47  lr=['4.0000000'], tr/val_loss:267.967010/253.197449, val:  66.37%, val_best:  84.51%, tr:  97.22%, tr_best:  97.40%, epoch time: 132.16 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 53.8201%\n",
      "layer   3  Sparsity: 74.6686%\n",
      "total_backward_count 774144 real_backward_count 133689  17.269%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 49.8750%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "lif layer 1 self.abs_max_v: 17761.0\n",
      "train - Value 0: 2122 occurrences\n",
      "train - Value 1: 1910 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 18109.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-48  lr=['4.0000000'], tr/val_loss:268.772491/259.167419, val:  82.74%, val_best:  84.51%, tr:  95.24%, tr_best:  97.40%, epoch time: 131.88 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 53.6979%\n",
      "layer   3  Sparsity: 74.7882%\n",
      "total_backward_count 790272 real_backward_count 135967  17.205%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 79.8750%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-49  lr=['4.0000000'], tr/val_loss:270.547791/266.962341, val:  73.01%, val_best:  84.51%, tr:  97.05%, tr_best:  97.40%, epoch time: 132.12 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.9187%\n",
      "layer   3  Sparsity: 74.7717%\n",
      "total_backward_count 806400 real_backward_count 138004  17.114%\n",
      "layer   1  Sparsity: 80.5664%\n",
      "layer   2  Sparsity: 54.8750%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "lif layer 1 self.abs_max_v: 18206.0\n",
      "lif layer 1 self.abs_max_v: 18446.0\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 18634.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-50  lr=['4.0000000'], tr/val_loss:274.677368/269.616333, val:  84.51%, val_best:  84.51%, tr:  97.02%, tr_best:  97.40%, epoch time: 132.28 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 54.2361%\n",
      "layer   3  Sparsity: 74.6970%\n",
      "total_backward_count 822528 real_backward_count 139979  17.018%\n",
      "layer   1  Sparsity: 73.0957%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "fc layer 3 self.abs_max_out: 500.0\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-51  lr=['4.0000000'], tr/val_loss:276.138763/267.315460, val:  82.96%, val_best:  84.51%, tr:  97.25%, tr_best:  97.40%, epoch time: 132.50 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.4064%\n",
      "layer   3  Sparsity: 74.6930%\n",
      "total_backward_count 838656 real_backward_count 141952  16.926%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 73.3750%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 18699.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-52  lr=['4.0000000'], tr/val_loss:277.975067/270.551697, val:  78.32%, val_best:  84.51%, tr:  97.42%, tr_best:  97.42%, epoch time: 132.37 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 54.5916%\n",
      "layer   3  Sparsity: 74.8175%\n",
      "total_backward_count 854784 real_backward_count 143896  16.834%\n",
      "layer   1  Sparsity: 90.2344%\n",
      "layer   2  Sparsity: 68.1250%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 18818.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-53  lr=['4.0000000'], tr/val_loss:276.194122/282.747803, val:  66.15%, val_best:  84.51%, tr:  97.42%, tr_best:  97.42%, epoch time: 131.59 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 54.7964%\n",
      "layer   3  Sparsity: 74.8077%\n",
      "total_backward_count 870912 real_backward_count 145985  16.762%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2073 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 94 occurrences\n",
      "test - Value 1: 358 occurrences\n",
      "epoch-54  lr=['4.0000000'], tr/val_loss:265.193939/245.529663, val:  69.91%, val_best:  84.51%, tr:  97.05%, tr_best:  97.42%, epoch time: 132.32 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 55.0218%\n",
      "layer   3  Sparsity: 74.6196%\n",
      "total_backward_count 887040 real_backward_count 148074  16.693%\n",
      "layer   1  Sparsity: 79.2480%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 19149.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-55  lr=['4.0000000'], tr/val_loss:254.479660/259.661621, val:  65.27%, val_best:  84.51%, tr:  96.50%, tr_best:  97.42%, epoch time: 133.46 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 54.8684%\n",
      "layer   3  Sparsity: 74.6844%\n",
      "total_backward_count 903168 real_backward_count 150168  16.627%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 52.2500%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 19328.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-56  lr=['4.0000000'], tr/val_loss:255.680908/278.001923, val:  63.05%, val_best:  84.51%, tr:  94.69%, tr_best:  97.42%, epoch time: 132.23 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 55.0611%\n",
      "layer   3  Sparsity: 74.8020%\n",
      "total_backward_count 919296 real_backward_count 152447  16.583%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 64.8750%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-57  lr=['4.0000000'], tr/val_loss:262.720581/253.544769, val:  82.74%, val_best:  84.51%, tr:  95.76%, tr_best:  97.42%, epoch time: 131.63 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4790%\n",
      "layer   2  Sparsity: 55.0655%\n",
      "layer   3  Sparsity: 74.5709%\n",
      "total_backward_count 935424 real_backward_count 154787  16.547%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 74.6250%\n",
      "layer   3  Sparsity: 86.3750%\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-58  lr=['4.0000000'], tr/val_loss:242.911316/206.319244, val:  74.56%, val_best:  84.51%, tr:  95.59%, tr_best:  97.42%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 54.2338%\n",
      "layer   3  Sparsity: 74.9842%\n",
      "total_backward_count 951552 real_backward_count 157023  16.502%\n",
      "layer   1  Sparsity: 77.2949%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-59  lr=['4.0000000'], tr/val_loss:242.083572/258.096191, val:  84.07%, val_best:  84.51%, tr:  95.49%, tr_best:  97.42%, epoch time: 128.87 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 54.5178%\n",
      "layer   3  Sparsity: 74.4727%\n",
      "total_backward_count 967680 real_backward_count 159299  16.462%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-60  lr=['4.0000000'], tr/val_loss:217.372894/176.087708, val:  84.29%, val_best:  84.51%, tr:  97.12%, tr_best:  97.42%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 54.5803%\n",
      "layer   3  Sparsity: 74.9206%\n",
      "total_backward_count 983808 real_backward_count 161342  16.400%\n",
      "layer   1  Sparsity: 72.7539%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 73.5000%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-61  lr=['4.0000000'], tr/val_loss:223.358200/211.881699, val:  66.59%, val_best:  84.51%, tr:  97.62%, tr_best:  97.62%, epoch time: 128.85 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 54.8718%\n",
      "layer   3  Sparsity: 75.0073%\n",
      "total_backward_count 999936 real_backward_count 163355  16.337%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 73.5000%\n",
      "train - Value 0: 1927 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-62  lr=['4.0000000'], tr/val_loss:223.863312/236.012726, val:  81.86%, val_best:  84.51%, tr:  96.16%, tr_best:  97.62%, epoch time: 130.89 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 53.9017%\n",
      "layer   3  Sparsity: 75.2113%\n",
      "total_backward_count 1016064 real_backward_count 165335  16.272%\n",
      "layer   1  Sparsity: 78.7598%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 73.6250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 216 occurrences\n",
      "test - Value 1: 236 occurrences\n",
      "epoch-63  lr=['4.0000000'], tr/val_loss:246.200043/239.840332, val:  84.96%, val_best:  84.96%, tr:  97.45%, tr_best:  97.62%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 53.6031%\n",
      "layer   3  Sparsity: 75.2352%\n",
      "total_backward_count 1032192 real_backward_count 167230  16.201%\n",
      "layer   1  Sparsity: 76.8066%\n",
      "layer   2  Sparsity: 47.6250%\n",
      "layer   3  Sparsity: 73.3750%\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2132 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-64  lr=['4.0000000'], tr/val_loss:256.789581/261.767670, val:  72.12%, val_best:  84.96%, tr:  96.28%, tr_best:  97.62%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 53.4872%\n",
      "layer   3  Sparsity: 75.3362%\n",
      "total_backward_count 1048320 real_backward_count 169209  16.141%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 80.2500%\n",
      "train - Value 0: 1871 occurrences\n",
      "train - Value 1: 2161 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 92 occurrences\n",
      "test - Value 1: 360 occurrences\n",
      "epoch-65  lr=['4.0000000'], tr/val_loss:253.116028/270.774597, val:  70.35%, val_best:  84.96%, tr:  95.51%, tr_best:  97.62%, epoch time: 132.56 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 53.4179%\n",
      "layer   3  Sparsity: 75.2075%\n",
      "total_backward_count 1064448 real_backward_count 171196  16.083%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 63.7500%\n",
      "layer   3  Sparsity: 80.1250%\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2138 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-66  lr=['4.0000000'], tr/val_loss:256.269806/260.292877, val:  83.85%, val_best:  84.96%, tr:  96.13%, tr_best:  97.62%, epoch time: 132.35 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.5792%\n",
      "layer   3  Sparsity: 75.2623%\n",
      "total_backward_count 1080576 real_backward_count 173109  16.020%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 73.5000%\n",
      "train - Value 0: 1884 occurrences\n",
      "train - Value 1: 2148 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-67  lr=['4.0000000'], tr/val_loss:256.961609/273.128815, val:  66.37%, val_best:  84.96%, tr:  95.83%, tr_best:  97.62%, epoch time: 130.54 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 53.7266%\n",
      "layer   3  Sparsity: 75.2554%\n",
      "total_backward_count 1096704 real_backward_count 175005  15.957%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 80.2500%\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2103 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-68  lr=['4.0000000'], tr/val_loss:253.772385/269.777130, val:  56.64%, val_best:  84.96%, tr:  96.85%, tr_best:  97.62%, epoch time: 130.86 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 53.4956%\n",
      "layer   3  Sparsity: 74.9917%\n",
      "total_backward_count 1112832 real_backward_count 176748  15.883%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-69  lr=['4.0000000'], tr/val_loss:255.208771/261.766205, val:  76.33%, val_best:  84.96%, tr:  97.07%, tr_best:  97.62%, epoch time: 131.12 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.6523%\n",
      "layer   3  Sparsity: 74.7585%\n",
      "total_backward_count 1128960 real_backward_count 178550  15.815%\n",
      "layer   1  Sparsity: 65.8691%\n",
      "layer   2  Sparsity: 39.2500%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-70  lr=['4.0000000'], tr/val_loss:268.043030/267.219757, val:  85.40%, val_best:  85.40%, tr:  98.07%, tr_best:  98.07%, epoch time: 130.63 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 53.6968%\n",
      "layer   3  Sparsity: 74.7675%\n",
      "total_backward_count 1145088 real_backward_count 180287  15.744%\n",
      "layer   1  Sparsity: 70.4102%\n",
      "layer   2  Sparsity: 48.7500%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-71  lr=['4.0000000'], tr/val_loss:272.364777/265.986938, val:  82.74%, val_best:  85.40%, tr:  96.68%, tr_best:  98.07%, epoch time: 130.69 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 53.6077%\n",
      "layer   3  Sparsity: 74.8604%\n",
      "total_backward_count 1161216 real_backward_count 182131  15.685%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 73.3750%\n",
      "train - Value 0: 1898 occurrences\n",
      "train - Value 1: 2134 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1488.00 at epoch 72, iter 4031\n",
      "max_activation_accul updated: 1508.00 at epoch 72, iter 4031\n",
      "max_activation_accul updated: 1539.00 at epoch 72, iter 4031\n",
      "max_activation_accul updated: 1566.00 at epoch 72, iter 4031\n",
      "max_activation_accul updated: 1572.00 at epoch 72, iter 4031\n",
      "max_activation_accul updated: 1603.00 at epoch 72, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-72  lr=['4.0000000'], tr/val_loss:266.414612/298.166748, val:  57.08%, val_best:  85.40%, tr:  96.03%, tr_best:  98.07%, epoch time: 131.38 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 53.6502%\n",
      "layer   3  Sparsity: 74.7511%\n",
      "total_backward_count 1177344 real_backward_count 183991  15.628%\n",
      "layer   1  Sparsity: 80.5176%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 1903 occurrences\n",
      "train - Value 1: 2129 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-73  lr=['4.0000000'], tr/val_loss:264.629272/263.985565, val:  81.19%, val_best:  85.40%, tr:  96.70%, tr_best:  98.07%, epoch time: 130.86 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 53.5257%\n",
      "layer   3  Sparsity: 74.7594%\n",
      "total_backward_count 1193472 real_backward_count 185666  15.557%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 63.1250%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-74  lr=['4.0000000'], tr/val_loss:262.213165/278.635437, val:  65.27%, val_best:  85.40%, tr:  97.52%, tr_best:  98.07%, epoch time: 131.19 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 53.7333%\n",
      "layer   3  Sparsity: 74.7938%\n",
      "total_backward_count 1209600 real_backward_count 187370  15.490%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 64.6250%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "train - Value 0: 1913 occurrences\n",
      "train - Value 1: 2119 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-75  lr=['4.0000000'], tr/val_loss:266.605042/276.323151, val:  71.90%, val_best:  85.40%, tr:  96.65%, tr_best:  98.07%, epoch time: 131.27 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 53.6215%\n",
      "layer   3  Sparsity: 74.7665%\n",
      "total_backward_count 1225728 real_backward_count 189017  15.421%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 1929 occurrences\n",
      "train - Value 1: 2103 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-76  lr=['4.0000000'], tr/val_loss:269.079529/274.712433, val:  72.12%, val_best:  85.40%, tr:  97.40%, tr_best:  98.07%, epoch time: 129.87 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 53.6290%\n",
      "layer   3  Sparsity: 74.7625%\n",
      "total_backward_count 1241856 real_backward_count 190745  15.360%\n",
      "layer   1  Sparsity: 75.3418%\n",
      "layer   2  Sparsity: 46.1250%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-77  lr=['4.0000000'], tr/val_loss:261.558441/266.032288, val:  69.69%, val_best:  85.40%, tr:  96.90%, tr_best:  98.07%, epoch time: 130.69 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 53.6683%\n",
      "layer   3  Sparsity: 74.9173%\n",
      "total_backward_count 1257984 real_backward_count 192605  15.311%\n",
      "layer   1  Sparsity: 76.5137%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 73.5000%\n",
      "train - Value 0: 1914 occurrences\n",
      "train - Value 1: 2118 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-78  lr=['4.0000000'], tr/val_loss:249.610214/287.363983, val:  52.88%, val_best:  85.40%, tr:  96.92%, tr_best:  98.07%, epoch time: 132.45 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 53.5508%\n",
      "layer   3  Sparsity: 75.2134%\n",
      "total_backward_count 1274112 real_backward_count 194282  15.248%\n",
      "layer   1  Sparsity: 83.9355%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 73.6250%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-79  lr=['4.0000000'], tr/val_loss:249.048660/263.535095, val:  76.33%, val_best:  85.40%, tr:  97.22%, tr_best:  98.07%, epoch time: 131.87 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 53.3979%\n",
      "layer   3  Sparsity: 75.2603%\n",
      "total_backward_count 1290240 real_backward_count 195952  15.187%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 73.6250%\n",
      "train - Value 0: 1914 occurrences\n",
      "train - Value 1: 2118 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-80  lr=['4.0000000'], tr/val_loss:260.889557/274.242798, val:  73.45%, val_best:  85.40%, tr:  97.02%, tr_best:  98.07%, epoch time: 131.59 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 53.2455%\n",
      "layer   3  Sparsity: 75.2179%\n",
      "total_backward_count 1306368 real_backward_count 197517  15.120%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 79.8750%\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 267 occurrences\n",
      "test - Value 1: 185 occurrences\n",
      "epoch-81  lr=['4.0000000'], tr/val_loss:253.476288/226.114151, val:  82.08%, val_best:  85.40%, tr:  97.82%, tr_best:  98.07%, epoch time: 131.68 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.1142%\n",
      "layer   3  Sparsity: 75.2182%\n",
      "total_backward_count 1322496 real_backward_count 199111  15.056%\n",
      "layer   1  Sparsity: 78.6621%\n",
      "layer   2  Sparsity: 46.7500%\n",
      "layer   3  Sparsity: 73.7500%\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 205 occurrences\n",
      "test - Value 1: 247 occurrences\n",
      "epoch-82  lr=['4.0000000'], tr/val_loss:236.447632/243.384705, val:  83.85%, val_best:  85.40%, tr:  96.68%, tr_best:  98.07%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 52.5316%\n",
      "layer   3  Sparsity: 74.9283%\n",
      "total_backward_count 1338624 real_backward_count 200991  15.015%\n",
      "layer   1  Sparsity: 72.0703%\n",
      "layer   2  Sparsity: 39.6250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-83  lr=['4.0000000'], tr/val_loss:247.731247/314.436462, val:  53.10%, val_best:  85.40%, tr:  97.42%, tr_best:  98.07%, epoch time: 131.86 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4827%\n",
      "layer   2  Sparsity: 53.1570%\n",
      "layer   3  Sparsity: 74.6411%\n",
      "total_backward_count 1354752 real_backward_count 202729  14.964%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 39.3750%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "fc layer 1 self.abs_max_out: 13843.0\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-84  lr=['4.0000000'], tr/val_loss:259.947052/281.387604, val:  63.94%, val_best:  85.40%, tr:  96.80%, tr_best:  98.07%, epoch time: 132.41 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 52.4617%\n",
      "layer   3  Sparsity: 74.3920%\n",
      "total_backward_count 1370880 real_backward_count 204784  14.938%\n",
      "layer   1  Sparsity: 71.7773%\n",
      "layer   2  Sparsity: 43.6250%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-85  lr=['4.0000000'], tr/val_loss:282.941010/289.267822, val:  73.23%, val_best:  85.40%, tr:  96.68%, tr_best:  98.07%, epoch time: 131.77 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 51.6240%\n",
      "layer   3  Sparsity: 74.3550%\n",
      "total_backward_count 1387008 real_backward_count 206856  14.914%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 44.2500%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['4.0000000'], tr/val_loss:281.002228/354.457214, val:  50.00%, val_best:  85.40%, tr:  97.37%, tr_best:  98.07%, epoch time: 131.94 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 50.8594%\n",
      "layer   3  Sparsity: 74.4068%\n",
      "total_backward_count 1403136 real_backward_count 208733  14.876%\n",
      "layer   1  Sparsity: 78.3203%\n",
      "layer   2  Sparsity: 48.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-87  lr=['4.0000000'], tr/val_loss:281.010406/296.726196, val:  83.41%, val_best:  85.40%, tr:  98.29%, tr_best:  98.29%, epoch time: 132.34 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 51.0001%\n",
      "layer   3  Sparsity: 74.4868%\n",
      "total_backward_count 1419264 real_backward_count 210440  14.827%\n",
      "layer   1  Sparsity: 78.3691%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-88  lr=['4.0000000'], tr/val_loss:298.333588/293.172211, val:  78.10%, val_best:  85.40%, tr:  98.14%, tr_best:  98.29%, epoch time: 130.33 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 51.1317%\n",
      "layer   3  Sparsity: 74.4857%\n",
      "total_backward_count 1435392 real_backward_count 212247  14.787%\n",
      "layer   1  Sparsity: 91.2109%\n",
      "layer   2  Sparsity: 68.6250%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-89  lr=['4.0000000'], tr/val_loss:294.851562/301.680359, val:  84.73%, val_best:  85.40%, tr:  98.12%, tr_best:  98.29%, epoch time: 125.82 seconds, 2.10 minutes\n",
      "layer   1  Sparsity: 79.4785%\n",
      "layer   2  Sparsity: 50.7490%\n",
      "layer   3  Sparsity: 74.5074%\n",
      "total_backward_count 1451520 real_backward_count 214137  14.753%\n",
      "layer   1  Sparsity: 83.2031%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 73.0000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-90  lr=['4.0000000'], tr/val_loss:302.430939/301.622772, val:  82.74%, val_best:  85.40%, tr:  97.74%, tr_best:  98.29%, epoch time: 130.88 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 50.7421%\n",
      "layer   3  Sparsity: 74.4879%\n",
      "total_backward_count 1467648 real_backward_count 215927  14.712%\n",
      "layer   1  Sparsity: 81.2012%\n",
      "layer   2  Sparsity: 47.3750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-91  lr=['4.0000000'], tr/val_loss:308.185242/309.211731, val:  72.57%, val_best:  85.40%, tr:  97.72%, tr_best:  98.29%, epoch time: 131.76 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 50.6536%\n",
      "layer   3  Sparsity: 74.4750%\n",
      "total_backward_count 1483776 real_backward_count 217787  14.678%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 46.3750%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-92  lr=['4.0000000'], tr/val_loss:308.844788/315.152466, val:  76.55%, val_best:  85.40%, tr:  97.35%, tr_best:  98.29%, epoch time: 131.08 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 50.6160%\n",
      "layer   3  Sparsity: 74.5186%\n",
      "total_backward_count 1499904 real_backward_count 219555  14.638%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 45.5000%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-93  lr=['4.0000000'], tr/val_loss:311.263275/315.284912, val:  77.65%, val_best:  85.40%, tr:  97.64%, tr_best:  98.29%, epoch time: 131.87 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 50.6874%\n",
      "layer   3  Sparsity: 74.5347%\n",
      "total_backward_count 1516032 real_backward_count 221400  14.604%\n",
      "layer   1  Sparsity: 75.1465%\n",
      "layer   2  Sparsity: 40.7500%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2060 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 156 occurrences\n",
      "test - Value 1: 296 occurrences\n",
      "epoch-94  lr=['4.0000000'], tr/val_loss:306.498199/310.074524, val:  80.53%, val_best:  85.40%, tr:  97.72%, tr_best:  98.29%, epoch time: 131.18 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 50.6124%\n",
      "layer   3  Sparsity: 74.5079%\n",
      "total_backward_count 1532160 real_backward_count 223165  14.565%\n",
      "layer   1  Sparsity: 66.0645%\n",
      "layer   2  Sparsity: 42.1250%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-95  lr=['4.0000000'], tr/val_loss:310.209259/312.186279, val:  84.51%, val_best:  85.40%, tr:  98.07%, tr_best:  98.29%, epoch time: 131.46 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 50.4595%\n",
      "layer   3  Sparsity: 74.5091%\n",
      "total_backward_count 1548288 real_backward_count 224901  14.526%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-96  lr=['4.0000000'], tr/val_loss:310.397095/355.967834, val:  57.08%, val_best:  85.40%, tr:  97.87%, tr_best:  98.29%, epoch time: 132.69 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 50.5241%\n",
      "layer   3  Sparsity: 74.5006%\n",
      "total_backward_count 1564416 real_backward_count 226580  14.483%\n",
      "layer   1  Sparsity: 65.7227%\n",
      "layer   2  Sparsity: 35.2500%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-97  lr=['4.0000000'], tr/val_loss:298.573425/287.899109, val:  82.52%, val_best:  85.40%, tr:  97.82%, tr_best:  98.29%, epoch time: 131.74 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 50.4213%\n",
      "layer   3  Sparsity: 74.7520%\n",
      "total_backward_count 1580544 real_backward_count 228345  14.447%\n",
      "layer   1  Sparsity: 71.1426%\n",
      "layer   2  Sparsity: 38.5000%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-98  lr=['4.0000000'], tr/val_loss:289.649994/305.607208, val:  72.35%, val_best:  85.40%, tr:  98.07%, tr_best:  98.29%, epoch time: 132.03 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 50.5044%\n",
      "layer   3  Sparsity: 74.9204%\n",
      "total_backward_count 1596672 real_backward_count 230096  14.411%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 45.1250%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-99  lr=['4.0000000'], tr/val_loss:293.663025/303.033478, val:  67.70%, val_best:  85.40%, tr:  97.69%, tr_best:  98.29%, epoch time: 132.29 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 50.0951%\n",
      "layer   3  Sparsity: 75.0143%\n",
      "total_backward_count 1612800 real_backward_count 231817  14.374%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 80.5000%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-100 lr=['4.0000000'], tr/val_loss:303.085052/274.242310, val:  75.88%, val_best:  85.40%, tr:  97.05%, tr_best:  98.29%, epoch time: 131.20 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 50.1317%\n",
      "layer   3  Sparsity: 74.9133%\n",
      "total_backward_count 1628928 real_backward_count 233586  14.340%\n",
      "layer   1  Sparsity: 66.2109%\n",
      "layer   2  Sparsity: 35.6250%\n",
      "layer   3  Sparsity: 73.5000%\n",
      "fc layer 2 self.abs_max_out: 5765.0\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-101 lr=['4.0000000'], tr/val_loss:299.819427/342.680634, val:  60.40%, val_best:  85.40%, tr:  97.50%, tr_best:  98.29%, epoch time: 131.98 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 49.9491%\n",
      "layer   3  Sparsity: 74.7279%\n",
      "total_backward_count 1645056 real_backward_count 235375  14.308%\n",
      "layer   1  Sparsity: 84.1309%\n",
      "layer   2  Sparsity: 61.2500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-102 lr=['4.0000000'], tr/val_loss:311.675415/316.389191, val:  76.11%, val_best:  85.40%, tr:  98.09%, tr_best:  98.29%, epoch time: 132.08 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 50.0678%\n",
      "layer   3  Sparsity: 74.5388%\n",
      "total_backward_count 1661184 real_backward_count 237097  14.273%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 35.7500%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "fc layer 2 self.abs_max_out: 6649.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 99 occurrences\n",
      "test - Value 1: 353 occurrences\n",
      "epoch-103 lr=['4.0000000'], tr/val_loss:331.049408/345.669434, val:  71.02%, val_best:  85.40%, tr:  98.19%, tr_best:  98.29%, epoch time: 131.97 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 50.1864%\n",
      "layer   3  Sparsity: 74.5321%\n",
      "total_backward_count 1677312 real_backward_count 238739  14.233%\n",
      "layer   1  Sparsity: 78.1250%\n",
      "layer   2  Sparsity: 53.0000%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-104 lr=['4.0000000'], tr/val_loss:360.804840/372.631775, val:  65.27%, val_best:  85.40%, tr:  96.95%, tr_best:  98.29%, epoch time: 131.44 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 50.8094%\n",
      "layer   3  Sparsity: 74.4872%\n",
      "total_backward_count 1693440 real_backward_count 240485  14.201%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 45.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-105 lr=['4.0000000'], tr/val_loss:345.493347/364.042877, val:  70.13%, val_best:  85.40%, tr:  98.24%, tr_best:  98.29%, epoch time: 130.97 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 50.9031%\n",
      "layer   3  Sparsity: 74.4491%\n",
      "total_backward_count 1709568 real_backward_count 242231  14.169%\n",
      "layer   1  Sparsity: 83.3496%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-106 lr=['4.0000000'], tr/val_loss:354.549194/374.435852, val:  60.18%, val_best:  85.40%, tr:  97.77%, tr_best:  98.29%, epoch time: 132.08 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 50.6624%\n",
      "layer   3  Sparsity: 74.4594%\n",
      "total_backward_count 1725696 real_backward_count 243924  14.135%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 62.7500%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-107 lr=['4.0000000'], tr/val_loss:358.107117/360.995209, val:  83.63%, val_best:  85.40%, tr:  97.92%, tr_best:  98.29%, epoch time: 132.30 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 50.5150%\n",
      "layer   3  Sparsity: 74.4151%\n",
      "total_backward_count 1741824 real_backward_count 245782  14.111%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-108 lr=['4.0000000'], tr/val_loss:362.433044/343.836517, val:  76.55%, val_best:  85.40%, tr:  99.28%, tr_best:  99.28%, epoch time: 131.57 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 51.0259%\n",
      "layer   3  Sparsity: 74.4683%\n",
      "total_backward_count 1757952 real_backward_count 247424  14.075%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 62.7500%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-109 lr=['4.0000000'], tr/val_loss:354.012878/363.935211, val:  66.37%, val_best:  85.40%, tr:  98.46%, tr_best:  99.28%, epoch time: 132.35 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 51.1774%\n",
      "layer   3  Sparsity: 74.5091%\n",
      "total_backward_count 1774080 real_backward_count 249184  14.046%\n",
      "layer   1  Sparsity: 87.3047%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-110 lr=['4.0000000'], tr/val_loss:352.011108/364.399109, val:  67.92%, val_best:  85.40%, tr:  97.84%, tr_best:  99.28%, epoch time: 131.36 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4793%\n",
      "layer   2  Sparsity: 51.3481%\n",
      "layer   3  Sparsity: 74.4741%\n",
      "total_backward_count 1790208 real_backward_count 250966  14.019%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 48.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 142 occurrences\n",
      "test - Value 1: 310 occurrences\n",
      "epoch-111 lr=['4.0000000'], tr/val_loss:347.217163/336.579742, val:  79.20%, val_best:  85.40%, tr:  97.74%, tr_best:  99.28%, epoch time: 131.74 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 51.1421%\n",
      "layer   3  Sparsity: 74.4923%\n",
      "total_backward_count 1806336 real_backward_count 252653  13.987%\n",
      "layer   1  Sparsity: 77.4902%\n",
      "layer   2  Sparsity: 48.7500%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-112 lr=['4.0000000'], tr/val_loss:346.744354/331.058990, val:  82.52%, val_best:  85.40%, tr:  97.99%, tr_best:  99.28%, epoch time: 130.88 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 51.1321%\n",
      "layer   3  Sparsity: 74.2344%\n",
      "total_backward_count 1822464 real_backward_count 254379  13.958%\n",
      "layer   1  Sparsity: 83.7891%\n",
      "layer   2  Sparsity: 50.1250%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 211 occurrences\n",
      "test - Value 1: 241 occurrences\n",
      "epoch-113 lr=['4.0000000'], tr/val_loss:323.524811/287.685883, val:  83.85%, val_best:  85.40%, tr:  97.72%, tr_best:  99.28%, epoch time: 130.79 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 51.1697%\n",
      "layer   3  Sparsity: 74.3418%\n",
      "total_backward_count 1838592 real_backward_count 255998  13.924%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 45.7500%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-114 lr=['4.0000000'], tr/val_loss:285.651581/300.022064, val:  73.01%, val_best:  85.40%, tr:  97.92%, tr_best:  99.28%, epoch time: 131.75 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 51.2922%\n",
      "layer   3  Sparsity: 74.4222%\n",
      "total_backward_count 1854720 real_backward_count 257694  13.894%\n",
      "layer   1  Sparsity: 75.1953%\n",
      "layer   2  Sparsity: 46.1250%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-115 lr=['4.0000000'], tr/val_loss:301.146271/278.380219, val:  65.71%, val_best:  85.40%, tr:  97.20%, tr_best:  99.28%, epoch time: 131.94 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 51.3749%\n",
      "layer   3  Sparsity: 74.3650%\n",
      "total_backward_count 1870848 real_backward_count 259386  13.865%\n",
      "layer   1  Sparsity: 85.5469%\n",
      "layer   2  Sparsity: 62.7500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-116 lr=['4.0000000'], tr/val_loss:300.492371/300.647186, val:  77.21%, val_best:  85.40%, tr:  98.44%, tr_best:  99.28%, epoch time: 132.05 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 51.0622%\n",
      "layer   3  Sparsity: 74.4080%\n",
      "total_backward_count 1886976 real_backward_count 261174  13.841%\n",
      "layer   1  Sparsity: 69.0918%\n",
      "layer   2  Sparsity: 45.6250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-117 lr=['4.0000000'], tr/val_loss:313.434052/314.314575, val:  80.75%, val_best:  85.40%, tr:  99.33%, tr_best:  99.33%, epoch time: 129.29 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4834%\n",
      "layer   2  Sparsity: 51.0116%\n",
      "layer   3  Sparsity: 74.4153%\n",
      "total_backward_count 1903104 real_backward_count 262878  13.813%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-118 lr=['4.0000000'], tr/val_loss:303.133850/307.528259, val:  75.44%, val_best:  85.40%, tr:  98.34%, tr_best:  99.33%, epoch time: 128.68 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 50.8611%\n",
      "layer   3  Sparsity: 74.4100%\n",
      "total_backward_count 1919232 real_backward_count 264484  13.781%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "fc layer 1 self.abs_max_out: 13884.0\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-119 lr=['4.0000000'], tr/val_loss:311.280884/347.727356, val:  73.89%, val_best:  85.40%, tr:  98.07%, tr_best:  99.33%, epoch time: 126.89 seconds, 2.11 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 50.3531%\n",
      "layer   3  Sparsity: 74.2573%\n",
      "total_backward_count 1935360 real_backward_count 266202  13.755%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 46.1250%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "fc layer 1 self.abs_max_out: 13990.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-120 lr=['4.0000000'], tr/val_loss:333.087402/334.654907, val:  85.40%, val_best:  85.40%, tr:  98.44%, tr_best:  99.33%, epoch time: 129.63 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 50.6454%\n",
      "layer   3  Sparsity: 74.2114%\n",
      "total_backward_count 1951488 real_backward_count 267810  13.723%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 46.5000%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-121 lr=['4.0000000'], tr/val_loss:324.000641/291.278137, val:  78.54%, val_best:  85.40%, tr:  98.16%, tr_best:  99.33%, epoch time: 130.20 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 50.7654%\n",
      "layer   3  Sparsity: 74.1451%\n",
      "total_backward_count 1967616 real_backward_count 269522  13.698%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 47.6250%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-122 lr=['4.0000000'], tr/val_loss:283.822906/306.405243, val:  53.76%, val_best:  85.40%, tr:  98.76%, tr_best:  99.33%, epoch time: 130.06 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 50.9730%\n",
      "layer   3  Sparsity: 74.2128%\n",
      "total_backward_count 1983744 real_backward_count 271002  13.661%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 53.1250%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "fc layer 1 self.abs_max_out: 14001.0\n",
      "fc layer 1 self.abs_max_out: 14126.0\n",
      "fc layer 1 self.abs_max_out: 14129.0\n",
      "fc layer 1 self.abs_max_out: 14264.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-123 lr=['4.0000000'], tr/val_loss:284.058380/291.060760, val:  69.03%, val_best:  85.40%, tr:  97.74%, tr_best:  99.33%, epoch time: 130.14 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 51.0356%\n",
      "layer   3  Sparsity: 74.2165%\n",
      "total_backward_count 1999872 real_backward_count 272672  13.634%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 48.2500%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "fc layer 1 self.abs_max_out: 14321.0\n",
      "fc layer 1 self.abs_max_out: 14434.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-124 lr=['4.0000000'], tr/val_loss:288.541199/277.972931, val:  70.13%, val_best:  85.40%, tr:  98.76%, tr_best:  99.33%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 50.8838%\n",
      "layer   3  Sparsity: 74.1992%\n",
      "total_backward_count 2016000 real_backward_count 274266  13.604%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 1 self.abs_max_out: 14516.0\n",
      "fc layer 1 self.abs_max_out: 14528.0\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 44 occurrences\n",
      "test - Value 1: 408 occurrences\n",
      "epoch-125 lr=['4.0000000'], tr/val_loss:269.671265/314.052002, val:  59.73%, val_best:  85.40%, tr:  97.94%, tr_best:  99.33%, epoch time: 129.93 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 50.7432%\n",
      "layer   3  Sparsity: 74.2242%\n",
      "total_backward_count 2032128 real_backward_count 275871  13.575%\n",
      "layer   1  Sparsity: 70.3125%\n",
      "layer   2  Sparsity: 45.0000%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "fc layer 1 self.abs_max_out: 14653.0\n",
      "fc layer 1 self.abs_max_out: 14654.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-126 lr=['4.0000000'], tr/val_loss:284.502808/268.299530, val:  82.96%, val_best:  85.40%, tr:  98.93%, tr_best:  99.33%, epoch time: 130.17 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 50.7365%\n",
      "layer   3  Sparsity: 74.2761%\n",
      "total_backward_count 2048256 real_backward_count 277316  13.539%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 49.2500%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 1 self.abs_max_out: 14717.0\n",
      "lif layer 1 self.abs_max_v: 19575.0\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-127 lr=['4.0000000'], tr/val_loss:308.788605/284.985870, val:  73.45%, val_best:  85.40%, tr:  99.60%, tr_best:  99.60%, epoch time: 130.25 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 50.4179%\n",
      "layer   3  Sparsity: 74.4559%\n",
      "total_backward_count 2064384 real_backward_count 278698  13.500%\n",
      "layer   1  Sparsity: 88.4277%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "lif layer 1 self.abs_max_v: 20800.5\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-128 lr=['4.0000000'], tr/val_loss:289.678131/282.644653, val:  63.94%, val_best:  85.40%, tr:  99.11%, tr_best:  99.60%, epoch time: 130.17 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 50.1270%\n",
      "layer   3  Sparsity: 74.7513%\n",
      "total_backward_count 2080512 real_backward_count 280048  13.461%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-129 lr=['4.0000000'], tr/val_loss:285.553772/291.903870, val:  80.09%, val_best:  85.40%, tr:  98.78%, tr_best:  99.60%, epoch time: 130.46 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 49.8196%\n",
      "layer   3  Sparsity: 74.7330%\n",
      "total_backward_count 2096640 real_backward_count 281614  13.432%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 62.6250%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-130 lr=['4.0000000'], tr/val_loss:296.589691/324.760803, val:  60.40%, val_best:  85.40%, tr:  97.35%, tr_best:  99.60%, epoch time: 129.12 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 49.7869%\n",
      "layer   3  Sparsity: 74.7553%\n",
      "total_backward_count 2112768 real_backward_count 283283  13.408%\n",
      "layer   1  Sparsity: 87.7441%\n",
      "layer   2  Sparsity: 63.1250%\n",
      "layer   3  Sparsity: 79.8750%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-131 lr=['4.0000000'], tr/val_loss:299.983704/298.811218, val:  80.31%, val_best:  85.40%, tr:  98.31%, tr_best:  99.60%, epoch time: 130.35 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 49.7508%\n",
      "layer   3  Sparsity: 74.7283%\n",
      "total_backward_count 2128896 real_backward_count 284974  13.386%\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 44.5000%\n",
      "layer   3  Sparsity: 73.0000%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-132 lr=['4.0000000'], tr/val_loss:304.600952/304.966431, val:  79.42%, val_best:  85.40%, tr:  98.41%, tr_best:  99.60%, epoch time: 130.56 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4821%\n",
      "layer   2  Sparsity: 49.6034%\n",
      "layer   3  Sparsity: 74.6872%\n",
      "total_backward_count 2145024 real_backward_count 286600  13.361%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 49.2500%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-133 lr=['4.0000000'], tr/val_loss:295.779602/292.954559, val:  81.42%, val_best:  85.40%, tr:  97.79%, tr_best:  99.60%, epoch time: 130.13 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 49.3836%\n",
      "layer   3  Sparsity: 74.6772%\n",
      "total_backward_count 2161152 real_backward_count 288210  13.336%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 45.6250%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-134 lr=['4.0000000'], tr/val_loss:296.248413/283.074829, val:  83.19%, val_best:  85.40%, tr:  96.03%, tr_best:  99.60%, epoch time: 131.46 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 50.0889%\n",
      "layer   3  Sparsity: 74.3364%\n",
      "total_backward_count 2177280 real_backward_count 289908  13.315%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 46.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-135 lr=['4.0000000'], tr/val_loss:277.738251/257.578094, val:  73.01%, val_best:  85.40%, tr:  98.26%, tr_best:  99.60%, epoch time: 129.91 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 49.9179%\n",
      "layer   3  Sparsity: 74.5172%\n",
      "total_backward_count 2193408 real_backward_count 291461  13.288%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-136 lr=['4.0000000'], tr/val_loss:258.148193/286.726379, val:  79.42%, val_best:  85.40%, tr:  98.24%, tr_best:  99.60%, epoch time: 130.76 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 50.1030%\n",
      "layer   3  Sparsity: 74.5445%\n",
      "total_backward_count 2209536 real_backward_count 292968  13.259%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 43.5000%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-137 lr=['4.0000000'], tr/val_loss:280.111176/298.554565, val:  86.06%, val_best:  86.06%, tr:  98.19%, tr_best:  99.60%, epoch time: 130.07 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 50.1449%\n",
      "layer   3  Sparsity: 74.5605%\n",
      "total_backward_count 2225664 real_backward_count 294440  13.229%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 79.6250%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-138 lr=['4.0000000'], tr/val_loss:265.569763/258.322815, val:  82.96%, val_best:  86.06%, tr:  98.12%, tr_best:  99.60%, epoch time: 130.33 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 50.3892%\n",
      "layer   3  Sparsity: 74.5402%\n",
      "total_backward_count 2241792 real_backward_count 295890  13.199%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 46.8750%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-139 lr=['4.0000000'], tr/val_loss:258.007263/237.737122, val:  75.44%, val_best:  86.06%, tr:  97.42%, tr_best:  99.60%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 50.3557%\n",
      "layer   3  Sparsity: 74.5373%\n",
      "total_backward_count 2257920 real_backward_count 297477  13.175%\n",
      "layer   1  Sparsity: 93.6035%\n",
      "layer   2  Sparsity: 72.7500%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 134 occurrences\n",
      "test - Value 1: 318 occurrences\n",
      "epoch-140 lr=['4.0000000'], tr/val_loss:271.727509/299.333008, val:  77.43%, val_best:  86.06%, tr:  98.31%, tr_best:  99.60%, epoch time: 129.62 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 50.3139%\n",
      "layer   3  Sparsity: 74.5437%\n",
      "total_backward_count 2274048 real_backward_count 299055  13.151%\n",
      "layer   1  Sparsity: 77.4414%\n",
      "layer   2  Sparsity: 47.1250%\n",
      "layer   3  Sparsity: 72.8750%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-141 lr=['4.0000000'], tr/val_loss:281.949768/275.295532, val:  75.66%, val_best:  86.06%, tr:  98.51%, tr_best:  99.60%, epoch time: 129.51 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 50.3263%\n",
      "layer   3  Sparsity: 74.5480%\n",
      "total_backward_count 2290176 real_backward_count 300620  13.127%\n",
      "layer   1  Sparsity: 69.9707%\n",
      "layer   2  Sparsity: 38.0000%\n",
      "layer   3  Sparsity: 73.1250%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-142 lr=['4.0000000'], tr/val_loss:270.308990/280.844025, val:  81.19%, val_best:  86.06%, tr:  98.16%, tr_best:  99.60%, epoch time: 130.42 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 50.2268%\n",
      "layer   3  Sparsity: 74.5389%\n",
      "total_backward_count 2306304 real_backward_count 302238  13.105%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-143 lr=['4.0000000'], tr/val_loss:290.208679/311.012451, val:  70.13%, val_best:  86.06%, tr:  98.69%, tr_best:  99.60%, epoch time: 130.30 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 50.0206%\n",
      "layer   3  Sparsity: 74.5159%\n",
      "total_backward_count 2322432 real_backward_count 303738  13.078%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 74.0000%\n",
      "layer   3  Sparsity: 86.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-144 lr=['4.0000000'], tr/val_loss:314.206177/292.660126, val:  80.53%, val_best:  86.06%, tr:  97.67%, tr_best:  99.60%, epoch time: 130.50 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 49.9632%\n",
      "layer   3  Sparsity: 74.2818%\n",
      "total_backward_count 2338560 real_backward_count 305377  13.058%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 35.2500%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-145 lr=['4.0000000'], tr/val_loss:328.506744/319.431610, val:  67.04%, val_best:  86.06%, tr:  97.82%, tr_best:  99.60%, epoch time: 130.10 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 50.2783%\n",
      "layer   3  Sparsity: 74.2295%\n",
      "total_backward_count 2354688 real_backward_count 307065  13.041%\n",
      "layer   1  Sparsity: 73.2910%\n",
      "layer   2  Sparsity: 43.8750%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-146 lr=['4.0000000'], tr/val_loss:318.858154/321.713562, val:  69.25%, val_best:  86.06%, tr:  97.15%, tr_best:  99.60%, epoch time: 128.11 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 50.1407%\n",
      "layer   3  Sparsity: 74.2295%\n",
      "total_backward_count 2370816 real_backward_count 308704  13.021%\n",
      "layer   1  Sparsity: 79.8340%\n",
      "layer   2  Sparsity: 49.5000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "fc layer 1 self.abs_max_out: 14838.0\n",
      "fc layer 1 self.abs_max_out: 14927.0\n",
      "fc layer 1 self.abs_max_out: 15265.0\n",
      "fc layer 1 self.abs_max_out: 15284.0\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-147 lr=['4.0000000'], tr/val_loss:323.279236/321.297974, val:  68.81%, val_best:  86.06%, tr:  96.53%, tr_best:  99.60%, epoch time: 130.06 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 50.1996%\n",
      "layer   3  Sparsity: 74.2274%\n",
      "total_backward_count 2386944 real_backward_count 310238  12.997%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 1 self.abs_max_out: 15425.0\n",
      "fc layer 1 self.abs_max_out: 15607.0\n",
      "fc layer 1 self.abs_max_out: 15622.0\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 57 occurrences\n",
      "test - Value 1: 395 occurrences\n",
      "epoch-148 lr=['4.0000000'], tr/val_loss:317.780975/312.957550, val:  62.61%, val_best:  86.06%, tr:  97.15%, tr_best:  99.60%, epoch time: 129.58 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 49.8327%\n",
      "layer   3  Sparsity: 74.1849%\n",
      "total_backward_count 2403072 real_backward_count 311746  12.973%\n",
      "layer   1  Sparsity: 84.0820%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "fc layer 1 self.abs_max_out: 15629.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-149 lr=['4.0000000'], tr/val_loss:315.587250/323.289642, val:  84.96%, val_best:  86.06%, tr:  98.24%, tr_best:  99.60%, epoch time: 130.16 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 49.8001%\n",
      "layer   3  Sparsity: 74.2176%\n",
      "total_backward_count 2419200 real_backward_count 313230  12.948%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 43.2500%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-150 lr=['4.0000000'], tr/val_loss:318.376373/325.196655, val:  84.96%, val_best:  86.06%, tr:  98.24%, tr_best:  99.60%, epoch time: 130.16 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 49.8045%\n",
      "layer   3  Sparsity: 74.2222%\n",
      "total_backward_count 2435328 real_backward_count 314718  12.923%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 34.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 220 occurrences\n",
      "test - Value 1: 232 occurrences\n",
      "epoch-151 lr=['4.0000000'], tr/val_loss:324.199371/328.486908, val:  84.07%, val_best:  86.06%, tr:  98.76%, tr_best:  99.60%, epoch time: 130.68 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 49.9106%\n",
      "layer   3  Sparsity: 74.2108%\n",
      "total_backward_count 2451456 real_backward_count 316199  12.898%\n",
      "layer   1  Sparsity: 83.0566%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 264 occurrences\n",
      "test - Value 1: 188 occurrences\n",
      "epoch-152 lr=['4.0000000'], tr/val_loss:317.295685/321.003052, val:  82.74%, val_best:  86.06%, tr:  98.44%, tr_best:  99.60%, epoch time: 129.72 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 49.9162%\n",
      "layer   3  Sparsity: 74.2160%\n",
      "total_backward_count 2467584 real_backward_count 317722  12.876%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 46.1250%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-153 lr=['4.0000000'], tr/val_loss:320.272797/321.166962, val:  81.64%, val_best:  86.06%, tr:  98.34%, tr_best:  99.60%, epoch time: 130.85 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 50.0819%\n",
      "layer   3  Sparsity: 74.2237%\n",
      "total_backward_count 2483712 real_backward_count 319174  12.851%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 33.3750%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-154 lr=['4.0000000'], tr/val_loss:323.368530/333.747223, val:  69.03%, val_best:  86.06%, tr:  98.19%, tr_best:  99.60%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 50.0364%\n",
      "layer   3  Sparsity: 74.2661%\n",
      "total_backward_count 2499840 real_backward_count 320725  12.830%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-155 lr=['4.0000000'], tr/val_loss:326.416962/332.398499, val:  78.54%, val_best:  86.06%, tr:  98.02%, tr_best:  99.60%, epoch time: 130.74 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 50.0042%\n",
      "layer   3  Sparsity: 74.1998%\n",
      "total_backward_count 2515968 real_backward_count 322294  12.810%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 62.3750%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-156 lr=['4.0000000'], tr/val_loss:319.255066/327.496490, val:  62.39%, val_best:  86.06%, tr:  98.36%, tr_best:  99.60%, epoch time: 129.37 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 50.1858%\n",
      "layer   3  Sparsity: 74.1962%\n",
      "total_backward_count 2532096 real_backward_count 323761  12.786%\n",
      "layer   1  Sparsity: 74.5605%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-157 lr=['4.0000000'], tr/val_loss:321.371948/342.052216, val:  67.04%, val_best:  86.06%, tr:  97.67%, tr_best:  99.60%, epoch time: 130.17 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4822%\n",
      "layer   2  Sparsity: 49.8228%\n",
      "layer   3  Sparsity: 74.2189%\n",
      "total_backward_count 2548224 real_backward_count 325266  12.764%\n",
      "layer   1  Sparsity: 82.5684%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "fc layer 1 self.abs_max_out: 15663.0\n",
      "lif layer 1 self.abs_max_v: 21112.5\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 159 occurrences\n",
      "test - Value 1: 293 occurrences\n",
      "epoch-158 lr=['4.0000000'], tr/val_loss:342.858643/365.747406, val:  79.87%, val_best:  86.06%, tr:  97.52%, tr_best:  99.60%, epoch time: 130.16 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 50.3305%\n",
      "layer   3  Sparsity: 74.1989%\n",
      "total_backward_count 2564352 real_backward_count 327016  12.752%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 50.3750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "lif layer 1 self.abs_max_v: 21262.5\n",
      "fc layer 1 self.abs_max_out: 15665.0\n",
      "fc layer 1 self.abs_max_out: 15667.0\n",
      "fc layer 1 self.abs_max_out: 15733.0\n",
      "train - Value 0: 2087 occurrences\n",
      "train - Value 1: 1945 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-159 lr=['4.0000000'], tr/val_loss:380.511078/389.783051, val:  67.04%, val_best:  86.06%, tr:  95.61%, tr_best:  99.60%, epoch time: 129.31 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 50.5112%\n",
      "layer   3  Sparsity: 74.0699%\n",
      "total_backward_count 2580480 real_backward_count 328919  12.746%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 60.6250%\n",
      "layer   3  Sparsity: 79.2500%\n",
      "fc layer 1 self.abs_max_out: 15876.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-160 lr=['4.0000000'], tr/val_loss:382.960693/371.874237, val:  71.46%, val_best:  86.06%, tr:  96.53%, tr_best:  99.60%, epoch time: 130.69 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 50.4033%\n",
      "layer   3  Sparsity: 74.0624%\n",
      "total_backward_count 2596608 real_backward_count 330687  12.735%\n",
      "layer   1  Sparsity: 62.3535%\n",
      "layer   2  Sparsity: 37.8750%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['4.0000000'], tr/val_loss:380.499664/429.470245, val:  50.00%, val_best:  86.06%, tr:  96.50%, tr_best:  99.60%, epoch time: 130.77 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 50.3613%\n",
      "layer   3  Sparsity: 73.9912%\n",
      "total_backward_count 2612736 real_backward_count 332511  12.727%\n",
      "layer   1  Sparsity: 92.2852%\n",
      "layer   2  Sparsity: 66.6250%\n",
      "layer   3  Sparsity: 79.5000%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-162 lr=['4.0000000'], tr/val_loss:371.319366/367.290863, val:  72.35%, val_best:  86.06%, tr:  96.45%, tr_best:  99.60%, epoch time: 130.63 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 50.4524%\n",
      "layer   3  Sparsity: 74.1870%\n",
      "total_backward_count 2628864 real_backward_count 334250  12.715%\n",
      "layer   1  Sparsity: 73.5840%\n",
      "layer   2  Sparsity: 40.3750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-163 lr=['4.0000000'], tr/val_loss:371.755554/361.660217, val:  85.84%, val_best:  86.06%, tr:  96.06%, tr_best:  99.60%, epoch time: 130.99 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 50.4279%\n",
      "layer   3  Sparsity: 74.1630%\n",
      "total_backward_count 2644992 real_backward_count 335939  12.701%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 42.7500%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 2130 occurrences\n",
      "train - Value 1: 1902 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-164 lr=['4.0000000'], tr/val_loss:363.893188/359.275238, val:  82.96%, val_best:  86.06%, tr:  95.63%, tr_best:  99.60%, epoch time: 130.31 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 50.8472%\n",
      "layer   3  Sparsity: 74.2334%\n",
      "total_backward_count 2661120 real_backward_count 337713  12.691%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 60.6250%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-165 lr=['4.0000000'], tr/val_loss:371.330292/362.006317, val:  80.09%, val_best:  86.06%, tr:  95.61%, tr_best:  99.60%, epoch time: 130.77 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 50.9689%\n",
      "layer   3  Sparsity: 74.0990%\n",
      "total_backward_count 2677248 real_backward_count 339383  12.677%\n",
      "layer   1  Sparsity: 72.4609%\n",
      "layer   2  Sparsity: 44.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-166 lr=['4.0000000'], tr/val_loss:366.440033/350.845337, val:  83.19%, val_best:  86.06%, tr:  97.94%, tr_best:  99.60%, epoch time: 129.62 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 51.1205%\n",
      "layer   3  Sparsity: 74.1786%\n",
      "total_backward_count 2693376 real_backward_count 340975  12.660%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 79.0000%\n",
      "fc layer 1 self.abs_max_out: 15933.0\n",
      "fc layer 1 self.abs_max_out: 16714.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-167 lr=['4.0000000'], tr/val_loss:362.643646/392.109131, val:  65.04%, val_best:  86.06%, tr:  98.24%, tr_best:  99.60%, epoch time: 129.60 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 51.3141%\n",
      "layer   3  Sparsity: 74.1982%\n",
      "total_backward_count 2709504 real_backward_count 342413  12.637%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 50.1250%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 1 self.abs_max_out: 16809.0\n",
      "lif layer 1 self.abs_max_v: 21563.0\n",
      "fc layer 1 self.abs_max_out: 17260.0\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-168 lr=['4.0000000'], tr/val_loss:370.856873/375.842041, val:  70.80%, val_best:  86.06%, tr:  98.36%, tr_best:  99.60%, epoch time: 130.61 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 51.6117%\n",
      "layer   3  Sparsity: 74.1425%\n",
      "total_backward_count 2725632 real_backward_count 343888  12.617%\n",
      "layer   1  Sparsity: 89.4531%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "fc layer 1 self.abs_max_out: 17544.0\n",
      "fc layer 1 self.abs_max_out: 17635.0\n",
      "fc layer 1 self.abs_max_out: 17790.0\n",
      "fc layer 1 self.abs_max_out: 17874.0\n",
      "lif layer 1 self.abs_max_v: 22246.5\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-169 lr=['4.0000000'], tr/val_loss:374.359619/377.449677, val:  75.00%, val_best:  86.06%, tr:  98.66%, tr_best:  99.60%, epoch time: 130.76 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 51.8352%\n",
      "layer   3  Sparsity: 74.1396%\n",
      "total_backward_count 2741760 real_backward_count 345329  12.595%\n",
      "layer   1  Sparsity: 76.3672%\n",
      "layer   2  Sparsity: 46.6250%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "fc layer 1 self.abs_max_out: 17876.0\n",
      "fc layer 1 self.abs_max_out: 17880.0\n",
      "fc layer 1 self.abs_max_out: 17998.0\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-170 lr=['4.0000000'], tr/val_loss:376.668823/380.810516, val:  82.96%, val_best:  86.06%, tr:  98.78%, tr_best:  99.60%, epoch time: 131.13 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4818%\n",
      "layer   2  Sparsity: 51.6693%\n",
      "layer   3  Sparsity: 74.1753%\n",
      "total_backward_count 2757888 real_backward_count 346704  12.571%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 1 self.abs_max_out: 18078.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-171 lr=['4.0000000'], tr/val_loss:372.589417/366.758820, val:  84.96%, val_best:  86.06%, tr:  98.66%, tr_best:  99.60%, epoch time: 130.24 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 51.6624%\n",
      "layer   3  Sparsity: 74.2389%\n",
      "total_backward_count 2774016 real_backward_count 348068  12.547%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 54.8750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "fc layer 1 self.abs_max_out: 18122.0\n",
      "lif layer 1 self.abs_max_v: 22464.5\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-172 lr=['4.0000000'], tr/val_loss:367.501892/371.523651, val:  75.88%, val_best:  86.06%, tr:  98.93%, tr_best:  99.60%, epoch time: 130.05 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 51.6255%\n",
      "layer   3  Sparsity: 74.1606%\n",
      "total_backward_count 2790144 real_backward_count 349425  12.524%\n",
      "layer   1  Sparsity: 85.1562%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 79.3750%\n",
      "fc layer 1 self.abs_max_out: 18201.0\n",
      "fc layer 1 self.abs_max_out: 18401.0\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-173 lr=['4.0000000'], tr/val_loss:370.531342/410.728394, val:  53.10%, val_best:  86.06%, tr:  98.76%, tr_best:  99.60%, epoch time: 130.47 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 51.7700%\n",
      "layer   3  Sparsity: 74.1843%\n",
      "total_backward_count 2806272 real_backward_count 350723  12.498%\n",
      "layer   1  Sparsity: 93.4082%\n",
      "layer   2  Sparsity: 74.7500%\n",
      "layer   3  Sparsity: 86.3750%\n",
      "fc layer 1 self.abs_max_out: 18422.0\n",
      "lif layer 1 self.abs_max_v: 22697.5\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-174 lr=['4.0000000'], tr/val_loss:370.435120/375.479553, val:  78.10%, val_best:  86.06%, tr:  99.01%, tr_best:  99.60%, epoch time: 127.14 seconds, 2.12 minutes\n",
      "layer   1  Sparsity: 79.4780%\n",
      "layer   2  Sparsity: 51.5288%\n",
      "layer   3  Sparsity: 74.1582%\n",
      "total_backward_count 2822400 real_backward_count 352048  12.473%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "lif layer 1 self.abs_max_v: 23114.0\n",
      "fc layer 1 self.abs_max_out: 18487.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-175 lr=['4.0000000'], tr/val_loss:370.695160/368.767578, val:  76.11%, val_best:  86.06%, tr:  98.88%, tr_best:  99.60%, epoch time: 130.69 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 51.5616%\n",
      "layer   3  Sparsity: 74.1558%\n",
      "total_backward_count 2838528 real_backward_count 353391  12.450%\n",
      "layer   1  Sparsity: 73.7793%\n",
      "layer   2  Sparsity: 46.2500%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "fc layer 1 self.abs_max_out: 18492.0\n",
      "fc layer 1 self.abs_max_out: 18550.0\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-176 lr=['4.0000000'], tr/val_loss:371.256134/362.474487, val:  83.85%, val_best:  86.06%, tr:  98.83%, tr_best:  99.60%, epoch time: 130.90 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 51.5440%\n",
      "layer   3  Sparsity: 74.1857%\n",
      "total_backward_count 2854656 real_backward_count 354783  12.428%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 49.1250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "fc layer 1 self.abs_max_out: 18576.0\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-177 lr=['4.0000000'], tr/val_loss:369.206879/377.711487, val:  73.23%, val_best:  86.06%, tr:  98.19%, tr_best:  99.60%, epoch time: 129.46 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 51.4277%\n",
      "layer   3  Sparsity: 74.2098%\n",
      "total_backward_count 2870784 real_backward_count 356137  12.406%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 47.2500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "fc layer 1 self.abs_max_out: 18754.0\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-178 lr=['4.0000000'], tr/val_loss:370.588531/375.291656, val:  74.56%, val_best:  86.06%, tr:  98.49%, tr_best:  99.60%, epoch time: 130.17 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 51.4669%\n",
      "layer   3  Sparsity: 74.1849%\n",
      "total_backward_count 2886912 real_backward_count 357460  12.382%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 47.6250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "lif layer 1 self.abs_max_v: 23115.5\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 206 occurrences\n",
      "test - Value 1: 246 occurrences\n",
      "epoch-179 lr=['4.0000000'], tr/val_loss:361.248016/358.958160, val:  86.73%, val_best:  86.73%, tr:  98.93%, tr_best:  99.60%, epoch time: 130.22 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 51.6769%\n",
      "layer   3  Sparsity: 74.1799%\n",
      "total_backward_count 2903040 real_backward_count 358829  12.360%\n",
      "layer   1  Sparsity: 70.6543%\n",
      "layer   2  Sparsity: 38.6250%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-180 lr=['4.0000000'], tr/val_loss:365.011169/364.235016, val:  81.42%, val_best:  86.73%, tr:  97.87%, tr_best:  99.60%, epoch time: 129.69 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 51.8822%\n",
      "layer   3  Sparsity: 74.1360%\n",
      "total_backward_count 2919168 real_backward_count 360352  12.344%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-181 lr=['4.0000000'], tr/val_loss:364.803986/359.050140, val:  85.84%, val_best:  86.73%, tr:  98.16%, tr_best:  99.60%, epoch time: 130.00 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 51.8279%\n",
      "layer   3  Sparsity: 74.2279%\n",
      "total_backward_count 2935296 real_backward_count 361944  12.331%\n",
      "layer   1  Sparsity: 57.8125%\n",
      "layer   2  Sparsity: 38.6250%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-182 lr=['4.0000000'], tr/val_loss:366.063202/365.843781, val:  86.06%, val_best:  86.73%, tr:  97.84%, tr_best:  99.60%, epoch time: 130.92 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 51.8490%\n",
      "layer   3  Sparsity: 74.2336%\n",
      "total_backward_count 2951424 real_backward_count 363507  12.316%\n",
      "layer   1  Sparsity: 77.8809%\n",
      "layer   2  Sparsity: 51.8750%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "fc layer 3 self.abs_max_out: 528.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-183 lr=['4.0000000'], tr/val_loss:372.764648/366.613007, val:  85.40%, val_best:  86.73%, tr:  97.59%, tr_best:  99.60%, epoch time: 130.43 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 51.8950%\n",
      "layer   3  Sparsity: 74.2025%\n",
      "total_backward_count 2967552 real_backward_count 365120  12.304%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 45.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-184 lr=['4.0000000'], tr/val_loss:370.854034/371.344147, val:  69.91%, val_best:  86.73%, tr:  96.68%, tr_best:  99.60%, epoch time: 130.03 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 51.6702%\n",
      "layer   3  Sparsity: 74.0794%\n",
      "total_backward_count 2983680 real_backward_count 366762  12.292%\n",
      "layer   1  Sparsity: 85.8887%\n",
      "layer   2  Sparsity: 53.5000%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-185 lr=['4.0000000'], tr/val_loss:369.566376/368.351776, val:  78.32%, val_best:  86.73%, tr:  97.52%, tr_best:  99.60%, epoch time: 129.31 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 51.6554%\n",
      "layer   3  Sparsity: 74.1874%\n",
      "total_backward_count 2999808 real_backward_count 368330  12.278%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 47.0000%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-186 lr=['4.0000000'], tr/val_loss:367.927094/365.965729, val:  83.85%, val_best:  86.73%, tr:  98.24%, tr_best:  99.60%, epoch time: 129.70 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 51.4201%\n",
      "layer   3  Sparsity: 74.1282%\n",
      "total_backward_count 3015936 real_backward_count 369796  12.261%\n",
      "layer   1  Sparsity: 80.0781%\n",
      "layer   2  Sparsity: 49.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-187 lr=['4.0000000'], tr/val_loss:367.166199/384.123596, val:  62.83%, val_best:  86.73%, tr:  98.02%, tr_best:  99.60%, epoch time: 131.03 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 51.2336%\n",
      "layer   3  Sparsity: 74.1953%\n",
      "total_backward_count 3032064 real_backward_count 371364  12.248%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 44.0000%\n",
      "layer   3  Sparsity: 71.8750%\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-188 lr=['4.0000000'], tr/val_loss:374.110352/368.772003, val:  83.19%, val_best:  86.73%, tr:  97.54%, tr_best:  99.60%, epoch time: 130.01 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 51.4044%\n",
      "layer   3  Sparsity: 74.1175%\n",
      "total_backward_count 3048192 real_backward_count 373060  12.239%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 36.0000%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-189 lr=['4.0000000'], tr/val_loss:369.606323/402.036926, val:  53.76%, val_best:  86.73%, tr:  97.62%, tr_best:  99.60%, epoch time: 129.76 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 51.5987%\n",
      "layer   3  Sparsity: 74.1321%\n",
      "total_backward_count 3064320 real_backward_count 374651  12.226%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 48.0000%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-190 lr=['4.0000000'], tr/val_loss:364.980072/384.929657, val:  62.39%, val_best:  86.73%, tr:  97.10%, tr_best:  99.60%, epoch time: 131.72 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 51.7085%\n",
      "layer   3  Sparsity: 74.1620%\n",
      "total_backward_count 3080448 real_backward_count 376230  12.213%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 38.3750%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-191 lr=['4.0000000'], tr/val_loss:369.356201/366.199982, val:  66.59%, val_best:  86.73%, tr:  97.22%, tr_best:  99.60%, epoch time: 131.61 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 51.3664%\n",
      "layer   3  Sparsity: 74.1368%\n",
      "total_backward_count 3096576 real_backward_count 377734  12.198%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 48.5000%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-192 lr=['4.0000000'], tr/val_loss:368.840912/365.253296, val:  80.97%, val_best:  86.73%, tr:  97.42%, tr_best:  99.60%, epoch time: 131.49 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 51.0664%\n",
      "layer   3  Sparsity: 74.1186%\n",
      "total_backward_count 3112704 real_backward_count 379229  12.183%\n",
      "layer   1  Sparsity: 57.6660%\n",
      "layer   2  Sparsity: 36.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-193 lr=['4.0000000'], tr/val_loss:371.870117/396.641327, val:  59.51%, val_best:  86.73%, tr:  96.92%, tr_best:  99.60%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 50.9474%\n",
      "layer   3  Sparsity: 73.9892%\n",
      "total_backward_count 3128832 real_backward_count 380810  12.171%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 48.8750%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 238 occurrences\n",
      "test - Value 1: 214 occurrences\n",
      "epoch-194 lr=['4.0000000'], tr/val_loss:369.655487/363.550751, val:  86.28%, val_best:  86.73%, tr:  98.02%, tr_best:  99.60%, epoch time: 131.31 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 51.0289%\n",
      "layer   3  Sparsity: 74.1121%\n",
      "total_backward_count 3144960 real_backward_count 382285  12.155%\n",
      "layer   1  Sparsity: 88.2324%\n",
      "layer   2  Sparsity: 53.5000%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-195 lr=['4.0000000'], tr/val_loss:370.213226/372.173004, val:  70.35%, val_best:  86.73%, tr:  98.54%, tr_best:  99.60%, epoch time: 130.83 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 51.0691%\n",
      "layer   3  Sparsity: 74.1781%\n",
      "total_backward_count 3161088 real_backward_count 383789  12.141%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 52.2500%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-196 lr=['4.0000000'], tr/val_loss:365.457489/357.044067, val:  85.62%, val_best:  86.73%, tr:  98.54%, tr_best:  99.60%, epoch time: 131.02 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 50.9746%\n",
      "layer   3  Sparsity: 74.2155%\n",
      "total_backward_count 3177216 real_backward_count 385267  12.126%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-197 lr=['4.0000000'], tr/val_loss:367.772522/386.771606, val:  67.48%, val_best:  86.73%, tr:  98.56%, tr_best:  99.60%, epoch time: 131.35 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 51.0325%\n",
      "layer   3  Sparsity: 74.1742%\n",
      "total_backward_count 3193344 real_backward_count 386838  12.114%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 45.3750%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-198 lr=['4.0000000'], tr/val_loss:374.308807/370.734802, val:  82.96%, val_best:  86.73%, tr:  98.81%, tr_best:  99.60%, epoch time: 131.73 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 50.6411%\n",
      "layer   3  Sparsity: 73.9709%\n",
      "total_backward_count 3209472 real_backward_count 388319  12.099%\n",
      "layer   1  Sparsity: 69.7754%\n",
      "layer   2  Sparsity: 47.1250%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-199 lr=['4.0000000'], tr/val_loss:375.431824/369.854858, val:  81.42%, val_best:  86.73%, tr:  98.78%, tr_best:  99.60%, epoch time: 131.05 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 50.7541%\n",
      "layer   3  Sparsity: 74.0026%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e501b0cefd4bf395d2325a6997db1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98785</td></tr><tr><td>tr_epoch_loss</td><td>375.43182</td></tr><tr><td>val_acc_best</td><td>0.86726</td></tr><tr><td>val_acc_now</td><td>0.81416</td></tr><tr><td>val_loss</td><td>369.85486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-33</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/oalvfjyr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/oalvfjyr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251210_235613-oalvfjyr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l3ajhmib with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 2048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251211_071421-l3ajhmib</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l3ajhmib' target=\"_blank\">sparkling-sweep-34</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l3ajhmib' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l3ajhmib</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251211_071430_807', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1024, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 0.25, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 0.0625, 'lif_layer_v_threshold2': 2048, 'init_scaling': [0.03125, 0.5, 0.25], 'learning_rate': 4, 'learning_rate2': 8, 'loser_encourage_mode': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 0.25, self.v_threshold 1024\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 0.0625, self.v_threshold 2048\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.5, 0.25])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1024, v_reset=10000, sg_width=0.25, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.5, 0.25])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=2048, v_reset=10000, sg_width=0.0625, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.5, 0.25])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 4\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 73.0\n",
      "lif layer 1 self.abs_max_v: 73.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 1 self.abs_max_out: 106.0\n",
      "lif layer 1 self.abs_max_v: 134.0\n",
      "lif layer 1 self.abs_max_v: 144.0\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "fc layer 1 self.abs_max_out: 118.0\n",
      "fc layer 1 self.abs_max_out: 288.0\n",
      "lif layer 1 self.abs_max_v: 288.0\n",
      "fc layer 1 self.abs_max_out: 674.0\n",
      "lif layer 1 self.abs_max_v: 803.0\n",
      "fc layer 1 self.abs_max_out: 1379.0\n",
      "lif layer 1 self.abs_max_v: 1381.5\n",
      "fc layer 2 self.abs_max_out: 446.0\n",
      "lif layer 2 self.abs_max_v: 446.0\n",
      "lif layer 1 self.abs_max_v: 1404.0\n",
      "fc layer 1 self.abs_max_out: 2175.0\n",
      "lif layer 1 self.abs_max_v: 2198.5\n",
      "fc layer 2 self.abs_max_out: 543.0\n",
      "lif layer 2 self.abs_max_v: 543.0\n",
      "fc layer 1 self.abs_max_out: 3442.0\n",
      "lif layer 1 self.abs_max_v: 3649.5\n",
      "lif layer 2 self.abs_max_v: 814.5\n",
      "fc layer 2 self.abs_max_out: 683.0\n",
      "lif layer 2 self.abs_max_v: 1090.0\n",
      "fc layer 2 self.abs_max_out: 823.0\n",
      "lif layer 2 self.abs_max_v: 1368.0\n",
      "fc layer 1 self.abs_max_out: 4263.0\n",
      "lif layer 1 self.abs_max_v: 4436.0\n",
      "fc layer 2 self.abs_max_out: 1103.0\n",
      "lif layer 2 self.abs_max_v: 1654.5\n",
      "fc layer 2 self.abs_max_out: 1243.0\n",
      "lif layer 2 self.abs_max_v: 2070.0\n",
      "fc layer 3 self.abs_max_out: 27.0\n",
      "fc layer 1 self.abs_max_out: 4574.0\n",
      "lif layer 1 self.abs_max_v: 4574.0\n",
      "fc layer 2 self.abs_max_out: 1383.0\n",
      "fc layer 1 self.abs_max_out: 5395.0\n",
      "lif layer 1 self.abs_max_v: 6741.0\n",
      "lif layer 2 self.abs_max_v: 2074.5\n",
      "fc layer 1 self.abs_max_out: 5692.0\n",
      "lif layer 1 self.abs_max_v: 8372.5\n",
      "fc layer 2 self.abs_max_out: 1523.0\n",
      "lif layer 2 self.abs_max_v: 2520.0\n",
      "fc layer 3 self.abs_max_out: 148.0\n",
      "lif layer 2 self.abs_max_v: 2743.5\n",
      "fc layer 2 self.abs_max_out: 1660.0\n",
      "fc layer 2 self.abs_max_out: 1777.0\n",
      "fc layer 1 self.abs_max_out: 7960.0\n",
      "lif layer 2 self.abs_max_v: 3027.0\n",
      "lif layer 2 self.abs_max_v: 3260.5\n",
      "fc layer 2 self.abs_max_out: 1886.0\n",
      "lif layer 1 self.abs_max_v: 9571.0\n",
      "fc layer 2 self.abs_max_out: 1956.0\n",
      "fc layer 2 self.abs_max_out: 1963.0\n",
      "fc layer 2 self.abs_max_out: 2011.0\n",
      "fc layer 3 self.abs_max_out: 153.0\n",
      "fc layer 2 self.abs_max_out: 2251.0\n",
      "lif layer 2 self.abs_max_v: 3414.0\n",
      "lif layer 2 self.abs_max_v: 3672.0\n",
      "fc layer 1 self.abs_max_out: 8052.0\n",
      "lif layer 2 self.abs_max_v: 3907.5\n",
      "fc layer 1 self.abs_max_out: 8870.0\n",
      "fc layer 2 self.abs_max_out: 2580.0\n",
      "lif layer 2 self.abs_max_v: 3910.0\n",
      "lif layer 2 self.abs_max_v: 4191.0\n",
      "fc layer 1 self.abs_max_out: 9077.0\n",
      "lif layer 1 self.abs_max_v: 9792.5\n",
      "fc layer 2 self.abs_max_out: 2611.0\n",
      "lif layer 1 self.abs_max_v: 10617.5\n",
      "fc layer 1 self.abs_max_out: 9874.0\n",
      "lif layer 2 self.abs_max_v: 4247.5\n",
      "fc layer 1 self.abs_max_out: 10216.0\n",
      "lif layer 1 self.abs_max_v: 12165.5\n",
      "fc layer 2 self.abs_max_out: 2857.0\n",
      "lif layer 2 self.abs_max_v: 4336.0\n",
      "lif layer 2 self.abs_max_v: 4349.5\n",
      "lif layer 2 self.abs_max_v: 4453.5\n",
      "fc layer 1 self.abs_max_out: 10646.0\n",
      "fc layer 2 self.abs_max_out: 3123.0\n",
      "lif layer 2 self.abs_max_v: 4586.0\n",
      "fc layer 2 self.abs_max_out: 3158.0\n",
      "fc layer 2 self.abs_max_out: 3319.0\n",
      "lif layer 2 self.abs_max_v: 4828.0\n",
      "lif layer 2 self.abs_max_v: 4847.0\n",
      "lif layer 2 self.abs_max_v: 5220.5\n",
      "lif layer 2 self.abs_max_v: 5464.5\n",
      "fc layer 2 self.abs_max_out: 3414.0\n",
      "fc layer 2 self.abs_max_out: 3532.0\n",
      "fc layer 1 self.abs_max_out: 10769.0\n",
      "lif layer 1 self.abs_max_v: 13141.0\n",
      "fc layer 2 self.abs_max_out: 3577.0\n",
      "lif layer 1 self.abs_max_v: 13479.0\n",
      "fc layer 2 self.abs_max_out: 3604.0\n",
      "lif layer 2 self.abs_max_v: 5955.5\n",
      "fc layer 1 self.abs_max_out: 11025.0\n",
      "fc layer 1 self.abs_max_out: 11286.0\n",
      "fc layer 2 self.abs_max_out: 3616.0\n",
      "fc layer 2 self.abs_max_out: 3856.0\n",
      "lif layer 1 self.abs_max_v: 14203.0\n",
      "fc layer 3 self.abs_max_out: 183.0\n",
      "fc layer 1 self.abs_max_out: 11927.0\n",
      "fc layer 2 self.abs_max_out: 3931.0\n",
      "fc layer 2 self.abs_max_out: 3936.0\n",
      "lif layer 2 self.abs_max_v: 6053.0\n",
      "fc layer 2 self.abs_max_out: 4896.0\n",
      "lif layer 2 self.abs_max_v: 6348.0\n",
      "lif layer 2 self.abs_max_v: 6731.0\n",
      "fc layer 2 self.abs_max_out: 5176.0\n",
      "fc layer 3 self.abs_max_out: 195.0\n",
      "lif layer 2 self.abs_max_v: 6872.0\n",
      "fc layer 2 self.abs_max_out: 5316.0\n",
      "fc layer 3 self.abs_max_out: 223.0\n",
      "fc layer 1 self.abs_max_out: 12697.0\n",
      "fc layer 2 self.abs_max_out: 5354.0\n",
      "fc layer 1 self.abs_max_out: 13165.0\n",
      "fc layer 2 self.abs_max_out: 5529.0\n",
      "fc layer 2 self.abs_max_out: 5890.0\n",
      "fc layer 2 self.abs_max_out: 6030.0\n",
      "lif layer 2 self.abs_max_v: 6946.0\n",
      "fc layer 1 self.abs_max_out: 13971.0\n",
      "fc layer 2 self.abs_max_out: 6170.0\n",
      "lif layer 2 self.abs_max_v: 7156.0\n",
      "lif layer 1 self.abs_max_v: 14645.0\n",
      "lif layer 1 self.abs_max_v: 17508.5\n",
      "fc layer 3 self.abs_max_out: 248.0\n",
      "lif layer 2 self.abs_max_v: 7301.5\n",
      "lif layer 2 self.abs_max_v: 7641.5\n",
      "lif layer 2 self.abs_max_v: 7830.0\n",
      "lif layer 2 self.abs_max_v: 8083.5\n",
      "fc layer 1 self.abs_max_out: 14225.0\n",
      "fc layer 1 self.abs_max_out: 14506.0\n",
      "fc layer 1 self.abs_max_out: 15018.0\n",
      "fc layer 2 self.abs_max_out: 6432.0\n",
      "fc layer 2 self.abs_max_out: 6484.0\n",
      "fc layer 1 self.abs_max_out: 15020.0\n",
      "fc layer 3 self.abs_max_out: 266.0\n",
      "fc layer 3 self.abs_max_out: 267.0\n",
      "fc layer 1 self.abs_max_out: 15072.0\n",
      "fc layer 3 self.abs_max_out: 270.0\n",
      "fc layer 1 self.abs_max_out: 15790.0\n",
      "lif layer 2 self.abs_max_v: 8148.5\n",
      "fc layer 2 self.abs_max_out: 7130.0\n",
      "lif layer 2 self.abs_max_v: 8366.0\n",
      "fc layer 1 self.abs_max_out: 16266.0\n",
      "lif layer 2 self.abs_max_v: 8710.0\n",
      "lif layer 2 self.abs_max_v: 9332.0\n",
      "lif layer 2 self.abs_max_v: 9480.0\n",
      "lif layer 2 self.abs_max_v: 9718.5\n",
      "lif layer 2 self.abs_max_v: 9774.0\n",
      "lif layer 1 self.abs_max_v: 18109.5\n",
      "lif layer 1 self.abs_max_v: 18953.0\n",
      "lif layer 2 self.abs_max_v: 9943.5\n",
      "lif layer 1 self.abs_max_v: 19289.0\n",
      "lif layer 2 self.abs_max_v: 10100.0\n",
      "fc layer 1 self.abs_max_out: 17572.0\n",
      "lif layer 2 self.abs_max_v: 10318.0\n",
      "lif layer 2 self.abs_max_v: 10714.0\n",
      "lif layer 2 self.abs_max_v: 10748.0\n",
      "lif layer 2 self.abs_max_v: 11717.0\n",
      "lif layer 1 self.abs_max_v: 22639.0\n",
      "fc layer 2 self.abs_max_out: 7133.0\n",
      "fc layer 2 self.abs_max_out: 7220.0\n",
      "fc layer 2 self.abs_max_out: 7236.0\n",
      "fc layer 2 self.abs_max_out: 7492.0\n",
      "fc layer 2 self.abs_max_out: 7507.0\n",
      "fc layer 2 self.abs_max_out: 7669.0\n",
      "fc layer 2 self.abs_max_out: 7986.0\n",
      "fc layer 2 self.abs_max_out: 7993.0\n",
      "fc layer 2 self.abs_max_out: 8012.0\n",
      "fc layer 1 self.abs_max_out: 17802.0\n",
      "fc layer 2 self.abs_max_out: 8136.0\n",
      "fc layer 2 self.abs_max_out: 8196.0\n",
      "fc layer 2 self.abs_max_out: 8222.0\n",
      "lif layer 2 self.abs_max_v: 11921.0\n",
      "lif layer 1 self.abs_max_v: 22951.5\n",
      "lif layer 2 self.abs_max_v: 14177.5\n",
      "lif layer 1 self.abs_max_v: 23541.5\n",
      "lif layer 1 self.abs_max_v: 24788.0\n",
      "fc layer 2 self.abs_max_out: 8353.0\n",
      "fc layer 2 self.abs_max_out: 8583.0\n",
      "fc layer 1 self.abs_max_out: 17831.0\n",
      "fc layer 2 self.abs_max_out: 8966.0\n",
      "lif layer 1 self.abs_max_v: 25317.0\n",
      "lif layer 1 self.abs_max_v: 26673.5\n",
      "fc layer 1 self.abs_max_out: 17872.0\n",
      "fc layer 2 self.abs_max_out: 9347.0\n",
      "fc layer 1 self.abs_max_out: 18152.0\n",
      "lif layer 1 self.abs_max_v: 29520.0\n",
      "fc layer 2 self.abs_max_out: 9422.0\n",
      "fc layer 1 self.abs_max_out: 18163.0\n",
      "fc layer 1 self.abs_max_out: 18428.0\n",
      "fc layer 1 self.abs_max_out: 18694.0\n",
      "lif layer 1 self.abs_max_v: 32126.5\n",
      "fc layer 2 self.abs_max_out: 9544.0\n",
      "fc layer 1 self.abs_max_out: 18805.0\n",
      "fc layer 1 self.abs_max_out: 19732.0\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 177.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 272.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 273.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 278.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 382.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 415.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-0   lr=['4.0000000'], tr/val_loss: 33.150925/ 18.731869, val:  62.61%, val_best:  62.61%, tr:  65.60%, tr_best:  65.60%, epoch time: 131.36 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 71.9851%\n",
      "layer   3  Sparsity: 81.9747%\n",
      "total_backward_count 16128 real_backward_count 6324  39.211%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 73.3398%\n",
      "layer   2  Sparsity: 66.5000%\n",
      "layer   3  Sparsity: 79.7500%\n",
      "lif layer 2 self.abs_max_v: 14386.5\n",
      "fc layer 2 self.abs_max_out: 9663.0\n",
      "lif layer 2 self.abs_max_v: 14615.0\n",
      "fc layer 2 self.abs_max_out: 10132.0\n",
      "fc layer 2 self.abs_max_out: 10144.0\n",
      "fc layer 2 self.abs_max_out: 10330.0\n",
      "fc layer 2 self.abs_max_out: 10410.0\n",
      "fc layer 2 self.abs_max_out: 10709.0\n",
      "fc layer 2 self.abs_max_out: 10746.0\n",
      "fc layer 2 self.abs_max_out: 11008.0\n",
      "fc layer 2 self.abs_max_out: 11168.0\n",
      "lif layer 2 self.abs_max_v: 14749.0\n",
      "lif layer 2 self.abs_max_v: 14750.5\n",
      "lif layer 2 self.abs_max_v: 16450.5\n",
      "fc layer 2 self.abs_max_out: 11480.0\n",
      "fc layer 1 self.abs_max_out: 20433.0\n",
      "fc layer 1 self.abs_max_out: 20442.0\n",
      "fc layer 1 self.abs_max_out: 20626.0\n",
      "fc layer 1 self.abs_max_out: 21203.0\n",
      "fc layer 1 self.abs_max_out: 21497.0\n",
      "fc layer 2 self.abs_max_out: 11783.0\n",
      "fc layer 1 self.abs_max_out: 21707.0\n",
      "fc layer 1 self.abs_max_out: 23302.0\n",
      "lif layer 2 self.abs_max_v: 16733.5\n",
      "lif layer 2 self.abs_max_v: 18742.5\n",
      "fc layer 1 self.abs_max_out: 23510.0\n",
      "lif layer 2 self.abs_max_v: 19070.0\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 437.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 439.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 447.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 456.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 463.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 510.00 at epoch 1, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-1   lr=['4.0000000'], tr/val_loss: 28.922026/ 34.894508, val:  51.77%, val_best:  62.61%, tr:  74.18%, tr_best:  74.18%, epoch time: 132.00 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 67.3016%\n",
      "layer   3  Sparsity: 77.9555%\n",
      "total_backward_count 32256 real_backward_count 11452  35.503%\n",
      "layer   1  Sparsity: 81.4453%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 75.3750%\n",
      "lif layer 1 self.abs_max_v: 33401.0\n",
      "fc layer 2 self.abs_max_out: 12194.0\n",
      "fc layer 1 self.abs_max_out: 24468.0\n",
      "fc layer 1 self.abs_max_out: 24786.0\n",
      "fc layer 1 self.abs_max_out: 24911.0\n",
      "fc layer 2 self.abs_max_out: 12763.0\n",
      "fc layer 1 self.abs_max_out: 25509.0\n",
      "fc layer 1 self.abs_max_out: 25540.0\n",
      "fc layer 1 self.abs_max_out: 25551.0\n",
      "fc layer 1 self.abs_max_out: 26069.0\n",
      "fc layer 2 self.abs_max_out: 12835.0\n",
      "fc layer 1 self.abs_max_out: 26286.0\n",
      "fc layer 1 self.abs_max_out: 28102.0\n",
      "fc layer 2 self.abs_max_out: 13441.0\n",
      "fc layer 2 self.abs_max_out: 13640.0\n",
      "fc layer 2 self.abs_max_out: 13731.0\n",
      "fc layer 2 self.abs_max_out: 13783.0\n",
      "fc layer 2 self.abs_max_out: 14056.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 691.00 at epoch 2, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['4.0000000'], tr/val_loss: 31.913353/ 48.044727, val:  50.00%, val_best:  62.61%, tr:  78.15%, tr_best:  78.15%, epoch time: 128.73 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 65.1785%\n",
      "layer   3  Sparsity: 74.1697%\n",
      "total_backward_count 48384 real_backward_count 16067  33.207%\n",
      "layer   1  Sparsity: 72.9980%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 72.1250%\n",
      "fc layer 1 self.abs_max_out: 28778.0\n",
      "lif layer 1 self.abs_max_v: 36264.0\n",
      "lif layer 2 self.abs_max_v: 21504.0\n",
      "fc layer 1 self.abs_max_out: 28876.0\n",
      "fc layer 1 self.abs_max_out: 29325.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 36570.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['4.0000000'], tr/val_loss: 29.228121/ 32.446625, val:  50.00%, val_best:  62.61%, tr:  80.21%, tr_best:  80.21%, epoch time: 131.99 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 66.3465%\n",
      "layer   3  Sparsity: 76.1316%\n",
      "total_backward_count 64512 real_backward_count 20291  31.453%\n",
      "layer   1  Sparsity: 73.9258%\n",
      "layer   2  Sparsity: 69.0000%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "lif layer 1 self.abs_max_v: 36884.0\n",
      "lif layer 1 self.abs_max_v: 42163.0\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-4   lr=['4.0000000'], tr/val_loss: 30.853558/ 26.395599, val:  58.85%, val_best:  62.61%, tr:  75.55%, tr_best:  80.21%, epoch time: 132.09 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 67.1549%\n",
      "layer   3  Sparsity: 74.4872%\n",
      "total_backward_count 80640 real_backward_count 25199  31.249%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 73.1250%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "fc layer 1 self.abs_max_out: 29364.0\n",
      "fc layer 1 self.abs_max_out: 29544.0\n",
      "fc layer 1 self.abs_max_out: 29551.0\n",
      "fc layer 1 self.abs_max_out: 29850.0\n",
      "fc layer 1 self.abs_max_out: 30152.0\n",
      "fc layer 1 self.abs_max_out: 30402.0\n",
      "fc layer 1 self.abs_max_out: 31721.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-5   lr=['4.0000000'], tr/val_loss: 32.081093/ 43.426998, val:  46.24%, val_best:  62.61%, tr:  76.34%, tr_best:  80.21%, epoch time: 131.80 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 66.7145%\n",
      "layer   3  Sparsity: 73.7106%\n",
      "total_backward_count 96768 real_backward_count 30116  31.122%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 65.2500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "fc layer 2 self.abs_max_out: 14700.0\n",
      "lif layer 2 self.abs_max_v: 23344.0\n",
      "lif layer 2 self.abs_max_v: 23398.5\n",
      "lif layer 2 self.abs_max_v: 24436.5\n",
      "fc layer 2 self.abs_max_out: 14940.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-6   lr=['4.0000000'], tr/val_loss: 35.996143/ 59.936024, val:  50.88%, val_best:  62.61%, tr:  80.01%, tr_best:  80.21%, epoch time: 131.55 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 66.7619%\n",
      "layer   3  Sparsity: 71.2998%\n",
      "total_backward_count 112896 real_backward_count 34433  30.500%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "fc layer 1 self.abs_max_out: 32225.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 420 occurrences\n",
      "test - Value 1: 32 occurrences\n",
      "epoch-7   lr=['4.0000000'], tr/val_loss: 36.465698/  7.792095, val:  57.08%, val_best:  62.61%, tr:  80.53%, tr_best:  80.53%, epoch time: 132.34 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 68.5222%\n",
      "layer   3  Sparsity: 70.5298%\n",
      "total_backward_count 129024 real_backward_count 38719  30.009%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 77.2500%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "fc layer 2 self.abs_max_out: 15623.0\n",
      "fc layer 2 self.abs_max_out: 15856.0\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-8   lr=['4.0000000'], tr/val_loss: 35.671669/ 21.111387, val:  50.00%, val_best:  62.61%, tr:  78.32%, tr_best:  80.53%, epoch time: 131.92 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 67.9539%\n",
      "layer   3  Sparsity: 71.3287%\n",
      "total_backward_count 145152 real_backward_count 43355  29.869%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 76.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "fc layer 1 self.abs_max_out: 33098.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-9   lr=['4.0000000'], tr/val_loss: 35.625149/ 39.977074, val:  63.50%, val_best:  63.50%, tr:  77.36%, tr_best:  80.53%, epoch time: 133.79 seconds, 2.23 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 67.4655%\n",
      "layer   3  Sparsity: 70.9738%\n",
      "total_backward_count 161280 real_backward_count 48030  29.781%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 71.7500%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "fc layer 1 self.abs_max_out: 33438.0\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-10  lr=['4.0000000'], tr/val_loss: 34.169636/ 17.074062, val:  53.98%, val_best:  63.50%, tr:  76.02%, tr_best:  80.53%, epoch time: 132.47 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 72.4297%\n",
      "layer   3  Sparsity: 72.4672%\n",
      "total_backward_count 177408 real_backward_count 53007  29.879%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-11  lr=['4.0000000'], tr/val_loss: 35.086327/ 43.577808, val:  49.78%, val_best:  63.50%, tr:  75.84%, tr_best:  80.53%, epoch time: 132.64 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 69.2373%\n",
      "layer   3  Sparsity: 71.2775%\n",
      "total_backward_count 193536 real_backward_count 57976  29.956%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 73.3750%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 406 occurrences\n",
      "test - Value 1: 46 occurrences\n",
      "epoch-12  lr=['4.0000000'], tr/val_loss: 36.689541/ 18.673784, val:  57.96%, val_best:  63.50%, tr:  74.65%, tr_best:  80.53%, epoch time: 131.32 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 68.7632%\n",
      "layer   3  Sparsity: 69.4022%\n",
      "total_backward_count 209664 real_backward_count 63059  30.076%\n",
      "layer   1  Sparsity: 87.1094%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-13  lr=['4.0000000'], tr/val_loss: 35.206451/ 34.275417, val:  50.66%, val_best:  63.50%, tr:  74.75%, tr_best:  80.53%, epoch time: 131.75 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 68.4998%\n",
      "layer   3  Sparsity: 71.2250%\n",
      "total_backward_count 225792 real_backward_count 68141  30.179%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 81.1250%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 296 occurrences\n",
      "test - Value 1: 156 occurrences\n",
      "epoch-14  lr=['4.0000000'], tr/val_loss: 30.099476/ 27.976488, val:  64.16%, val_best:  64.16%, tr:  76.74%, tr_best:  80.53%, epoch time: 131.73 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 71.2611%\n",
      "layer   3  Sparsity: 74.0891%\n",
      "total_backward_count 241920 real_backward_count 73094  30.214%\n",
      "layer   1  Sparsity: 92.3340%\n",
      "layer   2  Sparsity: 86.7500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 338 occurrences\n",
      "test - Value 1: 114 occurrences\n",
      "epoch-15  lr=['4.0000000'], tr/val_loss: 31.436632/ 22.257200, val:  63.27%, val_best:  64.16%, tr:  77.16%, tr_best:  80.53%, epoch time: 131.74 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 69.8493%\n",
      "layer   3  Sparsity: 72.9660%\n",
      "total_backward_count 258048 real_backward_count 78070  30.254%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 63.0000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "lif layer 1 self.abs_max_v: 42269.0\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-16  lr=['4.0000000'], tr/val_loss: 31.742460/ 44.592846, val:  69.03%, val_best:  69.03%, tr:  77.26%, tr_best:  80.53%, epoch time: 131.72 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 68.4080%\n",
      "layer   3  Sparsity: 73.2979%\n",
      "total_backward_count 274176 real_backward_count 83056  30.293%\n",
      "layer   1  Sparsity: 72.9004%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-17  lr=['4.0000000'], tr/val_loss: 32.857830/ 26.516069, val:  62.83%, val_best:  69.03%, tr:  80.28%, tr_best:  80.53%, epoch time: 132.05 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 66.3107%\n",
      "layer   3  Sparsity: 70.8334%\n",
      "total_backward_count 290304 real_backward_count 87562  30.162%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-18  lr=['4.0000000'], tr/val_loss: 30.043150/ 29.663960, val:  50.44%, val_best:  69.03%, tr:  82.42%, tr_best:  82.42%, epoch time: 131.61 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 66.0918%\n",
      "layer   3  Sparsity: 73.3608%\n",
      "total_backward_count 306432 real_backward_count 91949  30.006%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 75.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "fc layer 1 self.abs_max_out: 34442.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-19  lr=['4.0000000'], tr/val_loss: 29.260033/ 25.445328, val:  50.66%, val_best:  69.03%, tr:  78.82%, tr_best:  82.42%, epoch time: 132.57 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 64.2683%\n",
      "layer   3  Sparsity: 74.4211%\n",
      "total_backward_count 322560 real_backward_count 96519  29.923%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "fc layer 1 self.abs_max_out: 34623.0\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 343 occurrences\n",
      "test - Value 1: 109 occurrences\n",
      "epoch-20  lr=['4.0000000'], tr/val_loss: 31.078037/ 18.681828, val:  66.15%, val_best:  69.03%, tr:  80.83%, tr_best:  82.42%, epoch time: 130.39 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 67.6591%\n",
      "layer   3  Sparsity: 73.8994%\n",
      "total_backward_count 338688 real_backward_count 101095  29.849%\n",
      "layer   1  Sparsity: 84.8633%\n",
      "layer   2  Sparsity: 76.3750%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-21  lr=['4.0000000'], tr/val_loss: 23.058640/ 12.297467, val:  61.95%, val_best:  69.03%, tr:  77.38%, tr_best:  82.42%, epoch time: 131.15 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 69.0766%\n",
      "layer   3  Sparsity: 79.7129%\n",
      "total_backward_count 354816 real_backward_count 105939  29.857%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['4.0000000'], tr/val_loss: 22.709385/ 40.436275, val:  50.00%, val_best:  69.03%, tr:  79.69%, tr_best:  82.42%, epoch time: 131.76 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 66.6230%\n",
      "layer   3  Sparsity: 80.9231%\n",
      "total_backward_count 370944 real_backward_count 110402  29.762%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "lif layer 1 self.abs_max_v: 42370.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 274 occurrences\n",
      "test - Value 1: 178 occurrences\n",
      "epoch-23  lr=['4.0000000'], tr/val_loss: 25.855518/ 29.589918, val:  68.14%, val_best:  69.03%, tr:  77.11%, tr_best:  82.42%, epoch time: 131.99 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 64.0990%\n",
      "layer   3  Sparsity: 78.4123%\n",
      "total_backward_count 387072 real_backward_count 115115  29.740%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 53.2500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1833 occurrences\n",
      "train - Value 1: 2199 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-24  lr=['4.0000000'], tr/val_loss: 29.338692/ 14.371410, val:  55.31%, val_best:  69.03%, tr:  74.53%, tr_best:  82.42%, epoch time: 132.87 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 65.7605%\n",
      "layer   3  Sparsity: 76.4895%\n",
      "total_backward_count 403200 real_backward_count 120071  29.780%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 60.6250%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1898 occurrences\n",
      "train - Value 1: 2134 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-25  lr=['4.0000000'], tr/val_loss: 24.746277/ 22.745909, val:  52.43%, val_best:  69.03%, tr:  77.78%, tr_best:  82.42%, epoch time: 132.80 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 65.0184%\n",
      "layer   3  Sparsity: 80.2145%\n",
      "total_backward_count 419328 real_backward_count 124792  29.760%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 50.8750%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-26  lr=['4.0000000'], tr/val_loss: 27.715572/ 30.545347, val:  50.44%, val_best:  69.03%, tr:  78.03%, tr_best:  82.42%, epoch time: 132.70 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 65.2621%\n",
      "layer   3  Sparsity: 77.2076%\n",
      "total_backward_count 435456 real_backward_count 129524  29.744%\n",
      "layer   1  Sparsity: 70.8984%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "lif layer 1 self.abs_max_v: 42913.0\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['4.0000000'], tr/val_loss: 32.885483/ 46.788822, val:  50.00%, val_best:  69.03%, tr:  80.13%, tr_best:  82.42%, epoch time: 132.47 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 65.1268%\n",
      "layer   3  Sparsity: 73.3589%\n",
      "total_backward_count 451584 real_backward_count 134066  29.688%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 342 occurrences\n",
      "test - Value 1: 110 occurrences\n",
      "epoch-28  lr=['4.0000000'], tr/val_loss: 33.511967/ 17.779570, val:  65.93%, val_best:  69.03%, tr:  81.32%, tr_best:  82.42%, epoch time: 131.65 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 64.1611%\n",
      "layer   3  Sparsity: 71.7017%\n",
      "total_backward_count 467712 real_backward_count 138388  29.588%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 63.6250%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 693.00 at epoch 29, iter 4031\n",
      "max_activation_accul updated: 822.00 at epoch 29, iter 4031\n",
      "max_activation_accul updated: 868.00 at epoch 29, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['4.0000000'], tr/val_loss: 36.559204/ 69.259171, val:  50.00%, val_best:  69.03%, tr:  80.75%, tr_best:  82.42%, epoch time: 131.58 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 62.7850%\n",
      "layer   3  Sparsity: 69.0260%\n",
      "total_backward_count 483840 real_backward_count 142745  29.503%\n",
      "layer   1  Sparsity: 88.4766%\n",
      "layer   2  Sparsity: 83.2500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-30  lr=['4.0000000'], tr/val_loss: 42.284187/ 29.618847, val:  68.58%, val_best:  69.03%, tr:  81.15%, tr_best:  82.42%, epoch time: 128.19 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 64.7146%\n",
      "layer   3  Sparsity: 65.7455%\n",
      "total_backward_count 499968 real_backward_count 147263  29.454%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 47.5000%\n",
      "lif layer 1 self.abs_max_v: 43448.5\n",
      "fc layer 3 self.abs_max_out: 271.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-31  lr=['4.0000000'], tr/val_loss: 48.061680/ 30.868145, val:  71.68%, val_best:  71.68%, tr:  79.89%, tr_best:  82.42%, epoch time: 129.25 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 63.9505%\n",
      "layer   3  Sparsity: 59.6810%\n",
      "total_backward_count 516096 real_backward_count 151667  29.387%\n",
      "layer   1  Sparsity: 71.8750%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "fc layer 1 self.abs_max_out: 34754.0\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 15969.0\n",
      "fc layer 2 self.abs_max_out: 16179.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-32  lr=['4.0000000'], tr/val_loss: 41.864494/ 41.618328, val:  71.24%, val_best:  71.68%, tr:  79.56%, tr_best:  82.42%, epoch time: 132.91 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 64.7442%\n",
      "layer   3  Sparsity: 65.2163%\n",
      "total_backward_count 532224 real_backward_count 156111  29.332%\n",
      "layer   1  Sparsity: 88.1836%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "lif layer 1 self.abs_max_v: 45233.0\n",
      "lif layer 1 self.abs_max_v: 45892.0\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-33  lr=['4.0000000'], tr/val_loss: 43.334354/  7.544128, val:  53.54%, val_best:  71.68%, tr:  81.08%, tr_best:  82.42%, epoch time: 127.43 seconds, 2.12 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 64.3241%\n",
      "layer   3  Sparsity: 65.0770%\n",
      "total_backward_count 548352 real_backward_count 160184  29.212%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-34  lr=['4.0000000'], tr/val_loss: 39.579876/ 21.989233, val:  65.04%, val_best:  71.68%, tr:  79.99%, tr_best:  82.42%, epoch time: 131.44 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 63.7379%\n",
      "layer   3  Sparsity: 68.1174%\n",
      "total_backward_count 564480 real_backward_count 164752  29.187%\n",
      "layer   1  Sparsity: 86.8164%\n",
      "layer   2  Sparsity: 70.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 359 occurrences\n",
      "test - Value 1: 93 occurrences\n",
      "epoch-35  lr=['4.0000000'], tr/val_loss: 38.591766/ 41.350708, val:  64.82%, val_best:  71.68%, tr:  79.49%, tr_best:  82.42%, epoch time: 131.92 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 62.0712%\n",
      "layer   3  Sparsity: 70.1913%\n",
      "total_backward_count 580608 real_backward_count 169392  29.175%\n",
      "layer   1  Sparsity: 93.5547%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-36  lr=['4.0000000'], tr/val_loss: 37.281895/ 22.108128, val:  63.50%, val_best:  71.68%, tr:  75.42%, tr_best:  82.42%, epoch time: 131.68 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 62.9229%\n",
      "layer   3  Sparsity: 70.7557%\n",
      "total_backward_count 596736 real_backward_count 174417  29.229%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 57.6250%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2084 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-37  lr=['4.0000000'], tr/val_loss: 33.857807/ 37.519176, val:  51.77%, val_best:  71.68%, tr:  76.04%, tr_best:  82.42%, epoch time: 131.97 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 64.3503%\n",
      "layer   3  Sparsity: 72.9563%\n",
      "total_backward_count 612864 real_backward_count 179401  29.273%\n",
      "layer   1  Sparsity: 68.7988%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 338 occurrences\n",
      "test - Value 1: 114 occurrences\n",
      "epoch-38  lr=['4.0000000'], tr/val_loss: 33.514812/ 26.925222, val:  70.80%, val_best:  71.68%, tr:  78.32%, tr_best:  82.42%, epoch time: 130.70 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4835%\n",
      "layer   2  Sparsity: 60.7774%\n",
      "layer   3  Sparsity: 72.4077%\n",
      "total_backward_count 628992 real_backward_count 184080  29.266%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['4.0000000'], tr/val_loss: 34.063511/ 47.003456, val:  50.00%, val_best:  71.68%, tr:  78.72%, tr_best:  82.42%, epoch time: 129.54 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 62.6214%\n",
      "layer   3  Sparsity: 71.9090%\n",
      "total_backward_count 645120 real_backward_count 188842  29.272%\n",
      "layer   1  Sparsity: 75.8789%\n",
      "layer   2  Sparsity: 59.2500%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-40  lr=['4.0000000'], tr/val_loss: 37.672810/ 39.186321, val:  62.39%, val_best:  71.68%, tr:  78.84%, tr_best:  82.42%, epoch time: 131.67 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4819%\n",
      "layer   2  Sparsity: 62.4261%\n",
      "layer   3  Sparsity: 69.5727%\n",
      "total_backward_count 661248 real_backward_count 193416  29.250%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['4.0000000'], tr/val_loss: 33.913689/ 45.216431, val:  50.00%, val_best:  71.68%, tr:  80.48%, tr_best:  82.42%, epoch time: 131.44 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 62.1329%\n",
      "layer   3  Sparsity: 71.1783%\n",
      "total_backward_count 677376 real_backward_count 197870  29.211%\n",
      "layer   1  Sparsity: 67.2852%\n",
      "layer   2  Sparsity: 48.3750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-42  lr=['4.0000000'], tr/val_loss: 31.263727/ 33.332153, val:  57.08%, val_best:  71.68%, tr:  79.99%, tr_best:  82.42%, epoch time: 132.18 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 62.0916%\n",
      "layer   3  Sparsity: 73.3609%\n",
      "total_backward_count 693504 real_backward_count 202352  29.178%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-43  lr=['4.0000000'], tr/val_loss: 31.193501/  7.991693, val:  54.87%, val_best:  71.68%, tr:  74.55%, tr_best:  82.42%, epoch time: 131.55 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 60.0272%\n",
      "layer   3  Sparsity: 73.3540%\n",
      "total_backward_count 709632 real_backward_count 207303  29.213%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['4.0000000'], tr/val_loss: 30.054510/ 26.120056, val:  50.00%, val_best:  71.68%, tr:  76.66%, tr_best:  82.42%, epoch time: 131.44 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 60.6381%\n",
      "layer   3  Sparsity: 75.6787%\n",
      "total_backward_count 725760 real_backward_count 212103  29.225%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 63.0000%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['4.0000000'], tr/val_loss: 35.086861/ 22.757500, val:  50.00%, val_best:  71.68%, tr:  78.84%, tr_best:  82.42%, epoch time: 132.36 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 60.8879%\n",
      "layer   3  Sparsity: 72.0981%\n",
      "total_backward_count 741888 real_backward_count 216635  29.200%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 79.1250%\n",
      "layer   3  Sparsity: 87.5000%\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['4.0000000'], tr/val_loss: 38.795685/ 41.363190, val:  50.00%, val_best:  71.68%, tr:  75.82%, tr_best:  82.42%, epoch time: 131.50 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 61.7813%\n",
      "layer   3  Sparsity: 68.0805%\n",
      "total_backward_count 758016 real_backward_count 221440  29.213%\n",
      "layer   1  Sparsity: 70.5566%\n",
      "layer   2  Sparsity: 54.6250%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "lif layer 2 self.abs_max_v: 25334.0\n",
      "lif layer 2 self.abs_max_v: 26180.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-47  lr=['4.0000000'], tr/val_loss: 31.094322/ 20.540567, val:  55.97%, val_best:  71.68%, tr:  78.62%, tr_best:  82.42%, epoch time: 131.16 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 62.8284%\n",
      "layer   3  Sparsity: 75.2197%\n",
      "total_backward_count 774144 real_backward_count 225986  29.192%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 87.5000%\n",
      "lif layer 2 self.abs_max_v: 27568.5\n",
      "train - Value 0: 1839 occurrences\n",
      "train - Value 1: 2193 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-48  lr=['4.0000000'], tr/val_loss: 28.126768/ 20.187267, val:  59.29%, val_best:  71.68%, tr:  79.74%, tr_best:  82.42%, epoch time: 130.11 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 65.2071%\n",
      "layer   3  Sparsity: 78.6947%\n",
      "total_backward_count 790272 real_backward_count 230271  29.138%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 74.8750%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "fc layer 2 self.abs_max_out: 16265.0\n",
      "fc layer 2 self.abs_max_out: 16290.0\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 23 occurrences\n",
      "test - Value 1: 429 occurrences\n",
      "epoch-49  lr=['4.0000000'], tr/val_loss: 34.934299/ 29.838512, val:  53.32%, val_best:  71.68%, tr:  77.38%, tr_best:  82.42%, epoch time: 131.25 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 65.1834%\n",
      "layer   3  Sparsity: 70.2266%\n",
      "total_backward_count 806400 real_backward_count 234890  29.128%\n",
      "layer   1  Sparsity: 80.5664%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['4.0000000'], tr/val_loss: 34.535572/ 44.766010, val:  50.00%, val_best:  71.68%, tr:  78.22%, tr_best:  82.42%, epoch time: 132.04 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 67.2238%\n",
      "layer   3  Sparsity: 70.5849%\n",
      "total_backward_count 822528 real_backward_count 239540  29.122%\n",
      "layer   1  Sparsity: 73.0957%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 242 occurrences\n",
      "test - Value 1: 210 occurrences\n",
      "epoch-51  lr=['4.0000000'], tr/val_loss: 37.913258/ 15.010202, val:  71.24%, val_best:  71.68%, tr:  80.33%, tr_best:  82.42%, epoch time: 132.15 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 65.5754%\n",
      "layer   3  Sparsity: 69.6795%\n",
      "total_backward_count 838656 real_backward_count 243856  29.077%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 74.1250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "fc layer 2 self.abs_max_out: 16543.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-52  lr=['4.0000000'], tr/val_loss: 36.747341/ 24.262760, val:  67.70%, val_best:  71.68%, tr:  80.41%, tr_best:  82.42%, epoch time: 132.07 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 65.0988%\n",
      "layer   3  Sparsity: 70.8559%\n",
      "total_backward_count 854784 real_backward_count 248236  29.041%\n",
      "layer   1  Sparsity: 90.2344%\n",
      "layer   2  Sparsity: 73.2500%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "fc layer 3 self.abs_max_out: 273.0\n",
      "train - Value 0: 1937 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-53  lr=['4.0000000'], tr/val_loss: 37.138741/ 25.745770, val:  68.36%, val_best:  71.68%, tr:  81.27%, tr_best:  82.42%, epoch time: 131.14 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 65.8046%\n",
      "layer   3  Sparsity: 69.9535%\n",
      "total_backward_count 870912 real_backward_count 252547  28.998%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 71.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-54  lr=['4.0000000'], tr/val_loss: 36.270958/ 20.530281, val:  58.63%, val_best:  71.68%, tr:  81.70%, tr_best:  82.42%, epoch time: 131.47 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 67.4175%\n",
      "layer   3  Sparsity: 71.4204%\n",
      "total_backward_count 887040 real_backward_count 256917  28.963%\n",
      "layer   1  Sparsity: 79.2480%\n",
      "layer   2  Sparsity: 68.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-55  lr=['4.0000000'], tr/val_loss: 34.743889/ 20.427332, val:  54.87%, val_best:  71.68%, tr:  78.55%, tr_best:  82.42%, epoch time: 132.26 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 66.7762%\n",
      "layer   3  Sparsity: 71.0579%\n",
      "total_backward_count 903168 real_backward_count 261709  28.977%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 63.5000%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 98 occurrences\n",
      "test - Value 1: 354 occurrences\n",
      "epoch-56  lr=['4.0000000'], tr/val_loss: 39.664177/ 58.182663, val:  64.16%, val_best:  71.68%, tr:  76.14%, tr_best:  82.42%, epoch time: 131.18 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 64.8099%\n",
      "layer   3  Sparsity: 68.0365%\n",
      "total_backward_count 919296 real_backward_count 266573  28.998%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 78.5000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-57  lr=['4.0000000'], tr/val_loss: 42.730270/ 14.130095, val:  50.00%, val_best:  71.68%, tr:  77.50%, tr_best:  82.42%, epoch time: 131.57 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4790%\n",
      "layer   2  Sparsity: 64.8981%\n",
      "layer   3  Sparsity: 65.5610%\n",
      "total_backward_count 935424 real_backward_count 271317  29.005%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 84.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-58  lr=['4.0000000'], tr/val_loss: 42.458267/ 20.300570, val:  69.25%, val_best:  71.68%, tr:  76.59%, tr_best:  82.42%, epoch time: 131.34 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 64.9291%\n",
      "layer   3  Sparsity: 65.2728%\n",
      "total_backward_count 951552 real_backward_count 276111  29.017%\n",
      "layer   1  Sparsity: 77.2949%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 404 occurrences\n",
      "test - Value 1: 48 occurrences\n",
      "epoch-59  lr=['4.0000000'], tr/val_loss: 33.534901/ 17.038734, val:  60.18%, val_best:  71.68%, tr:  78.25%, tr_best:  82.42%, epoch time: 131.96 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 63.1594%\n",
      "layer   3  Sparsity: 72.8406%\n",
      "total_backward_count 967680 real_backward_count 280895  29.028%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-60  lr=['4.0000000'], tr/val_loss: 35.808548/ 17.214718, val:  50.00%, val_best:  71.68%, tr:  78.47%, tr_best:  82.42%, epoch time: 132.15 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 64.7453%\n",
      "layer   3  Sparsity: 70.7400%\n",
      "total_backward_count 983808 real_backward_count 285439  29.014%\n",
      "layer   1  Sparsity: 72.7539%\n",
      "layer   2  Sparsity: 66.1250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-61  lr=['4.0000000'], tr/val_loss: 34.759289/ 41.719582, val:  40.27%, val_best:  71.68%, tr:  79.64%, tr_best:  82.42%, epoch time: 131.33 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 66.1584%\n",
      "layer   3  Sparsity: 72.4080%\n",
      "total_backward_count 999936 real_backward_count 289928  28.995%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 68.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-62  lr=['4.0000000'], tr/val_loss: 34.190758/ 10.625677, val:  60.62%, val_best:  71.68%, tr:  78.99%, tr_best:  82.42%, epoch time: 127.96 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 67.2480%\n",
      "layer   3  Sparsity: 72.5257%\n",
      "total_backward_count 1016064 real_backward_count 294450  28.979%\n",
      "layer   1  Sparsity: 78.7598%\n",
      "layer   2  Sparsity: 63.3750%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-63  lr=['4.0000000'], tr/val_loss: 37.154423/ 20.431507, val:  58.19%, val_best:  71.68%, tr:  78.10%, tr_best:  82.42%, epoch time: 128.79 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 66.9291%\n",
      "layer   3  Sparsity: 68.5311%\n",
      "total_backward_count 1032192 real_backward_count 299216  28.988%\n",
      "layer   1  Sparsity: 76.8066%\n",
      "layer   2  Sparsity: 62.2500%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-64  lr=['4.0000000'], tr/val_loss: 34.591232/ 18.963408, val:  50.44%, val_best:  71.68%, tr:  77.46%, tr_best:  82.42%, epoch time: 131.37 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 66.6353%\n",
      "layer   3  Sparsity: 72.2842%\n",
      "total_backward_count 1048320 real_backward_count 304000  28.999%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 70.7500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-65  lr=['4.0000000'], tr/val_loss: 36.908775/ 29.149080, val:  50.44%, val_best:  71.68%, tr:  76.81%, tr_best:  82.42%, epoch time: 130.94 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 65.2170%\n",
      "layer   3  Sparsity: 70.4679%\n",
      "total_backward_count 1064448 real_backward_count 308865  29.016%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 73.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-66  lr=['4.0000000'], tr/val_loss: 32.902901/ 33.077194, val:  59.51%, val_best:  71.68%, tr:  78.45%, tr_best:  82.42%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 63.3279%\n",
      "layer   3  Sparsity: 72.9946%\n",
      "total_backward_count 1080576 real_backward_count 313481  29.011%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1771 occurrences\n",
      "train - Value 1: 2261 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-67  lr=['4.0000000'], tr/val_loss: 27.838804/ 27.893866, val:  56.19%, val_best:  71.68%, tr:  79.99%, tr_best:  82.42%, epoch time: 131.02 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 63.9576%\n",
      "layer   3  Sparsity: 80.3179%\n",
      "total_backward_count 1096704 real_backward_count 317880  28.985%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 66.7500%\n",
      "layer   3  Sparsity: 92.5000%\n",
      "train - Value 0: 1751 occurrences\n",
      "train - Value 1: 2281 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['4.0000000'], tr/val_loss: 23.946253/ 16.851217, val:  50.00%, val_best:  71.68%, tr:  75.87%, tr_best:  82.42%, epoch time: 131.26 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 64.8554%\n",
      "layer   3  Sparsity: 81.3334%\n",
      "total_backward_count 1112832 real_backward_count 322679  28.996%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2133 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 344 occurrences\n",
      "test - Value 1: 108 occurrences\n",
      "epoch-69  lr=['4.0000000'], tr/val_loss: 22.040951/ 13.475023, val:  59.29%, val_best:  71.68%, tr:  77.60%, tr_best:  82.42%, epoch time: 131.79 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 65.3722%\n",
      "layer   3  Sparsity: 81.1170%\n",
      "total_backward_count 1128960 real_backward_count 327226  28.985%\n",
      "layer   1  Sparsity: 65.8691%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-70  lr=['4.0000000'], tr/val_loss: 26.442320/ 27.967451, val:  57.74%, val_best:  71.68%, tr:  77.23%, tr_best:  82.42%, epoch time: 130.87 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 65.8067%\n",
      "layer   3  Sparsity: 78.4452%\n",
      "total_backward_count 1145088 real_backward_count 331895  28.984%\n",
      "layer   1  Sparsity: 70.4102%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-71  lr=['4.0000000'], tr/val_loss: 26.423775/ 34.685387, val:  56.64%, val_best:  71.68%, tr:  78.32%, tr_best:  82.42%, epoch time: 131.48 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 62.8503%\n",
      "layer   3  Sparsity: 77.5552%\n",
      "total_backward_count 1161216 real_backward_count 336446  28.974%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "fc layer 2 self.abs_max_out: 16611.0\n",
      "fc layer 2 self.abs_max_out: 16967.0\n",
      "fc layer 2 self.abs_max_out: 17198.0\n",
      "fc layer 2 self.abs_max_out: 17982.0\n",
      "fc layer 2 self.abs_max_out: 18275.0\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['4.0000000'], tr/val_loss: 30.417547/ 55.330265, val:  50.00%, val_best:  71.68%, tr:  75.25%, tr_best:  82.42%, epoch time: 131.16 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 61.1145%\n",
      "layer   3  Sparsity: 73.7698%\n",
      "total_backward_count 1177344 real_backward_count 341381  28.996%\n",
      "layer   1  Sparsity: 80.5176%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-73  lr=['4.0000000'], tr/val_loss: 35.925762/ 40.937820, val:  50.22%, val_best:  71.68%, tr:  75.97%, tr_best:  82.42%, epoch time: 132.14 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 61.0495%\n",
      "layer   3  Sparsity: 70.1900%\n",
      "total_backward_count 1193472 real_backward_count 346261  29.013%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-74  lr=['4.0000000'], tr/val_loss: 35.974728/ 61.540215, val:  50.00%, val_best:  71.68%, tr:  78.89%, tr_best:  82.42%, epoch time: 130.15 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 62.2233%\n",
      "layer   3  Sparsity: 69.5192%\n",
      "total_backward_count 1209600 real_backward_count 350822  29.003%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-75  lr=['4.0000000'], tr/val_loss: 32.436913/ 23.598692, val:  50.00%, val_best:  71.68%, tr:  78.62%, tr_best:  82.42%, epoch time: 130.95 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 63.2556%\n",
      "layer   3  Sparsity: 72.9257%\n",
      "total_backward_count 1225728 real_backward_count 355349  28.991%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-76  lr=['4.0000000'], tr/val_loss: 29.262825/ 23.929678, val:  69.03%, val_best:  71.68%, tr:  77.78%, tr_best:  82.42%, epoch time: 131.95 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 63.4928%\n",
      "layer   3  Sparsity: 75.5816%\n",
      "total_backward_count 1241856 real_backward_count 360086  28.996%\n",
      "layer   1  Sparsity: 75.3418%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-77  lr=['4.0000000'], tr/val_loss: 31.924421/ 10.495364, val:  51.33%, val_best:  71.68%, tr:  78.08%, tr_best:  82.42%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 62.1421%\n",
      "layer   3  Sparsity: 73.0801%\n",
      "total_backward_count 1257984 real_backward_count 364857  29.003%\n",
      "layer   1  Sparsity: 76.5137%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['4.0000000'], tr/val_loss: 33.095951/ 60.536297, val:  50.00%, val_best:  71.68%, tr:  77.31%, tr_best:  82.42%, epoch time: 131.33 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 62.8014%\n",
      "layer   3  Sparsity: 72.7627%\n",
      "total_backward_count 1274112 real_backward_count 369784  29.023%\n",
      "layer   1  Sparsity: 83.9355%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-79  lr=['4.0000000'], tr/val_loss: 33.815384/ 29.463291, val:  71.90%, val_best:  71.90%, tr:  79.49%, tr_best:  82.42%, epoch time: 131.81 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 61.8263%\n",
      "layer   3  Sparsity: 72.9824%\n",
      "total_backward_count 1290240 real_backward_count 374255  29.007%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 64.2500%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-80  lr=['4.0000000'], tr/val_loss: 31.152227/ 19.333307, val:  50.66%, val_best:  71.90%, tr:  79.09%, tr_best:  82.42%, epoch time: 131.71 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 62.1138%\n",
      "layer   3  Sparsity: 74.1624%\n",
      "total_backward_count 1306368 real_backward_count 378740  28.992%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 72.6250%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['4.0000000'], tr/val_loss: 30.756374/ 33.503025, val:  50.00%, val_best:  71.90%, tr:  76.61%, tr_best:  82.42%, epoch time: 132.45 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 64.4940%\n",
      "layer   3  Sparsity: 74.5896%\n",
      "total_backward_count 1322496 real_backward_count 383556  29.002%\n",
      "layer   1  Sparsity: 78.6621%\n",
      "layer   2  Sparsity: 55.5000%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 28 occurrences\n",
      "test - Value 1: 424 occurrences\n",
      "epoch-82  lr=['4.0000000'], tr/val_loss: 32.454151/ 35.595844, val:  53.98%, val_best:  71.90%, tr:  75.25%, tr_best:  82.42%, epoch time: 131.57 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 63.4121%\n",
      "layer   3  Sparsity: 71.2082%\n",
      "total_backward_count 1338624 real_backward_count 388421  29.016%\n",
      "layer   1  Sparsity: 72.0703%\n",
      "layer   2  Sparsity: 43.0000%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2081 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['4.0000000'], tr/val_loss: 33.762852/ 53.238480, val:  50.00%, val_best:  71.90%, tr:  79.79%, tr_best:  82.42%, epoch time: 130.59 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4827%\n",
      "layer   2  Sparsity: 62.1780%\n",
      "layer   3  Sparsity: 72.6477%\n",
      "total_backward_count 1354752 real_backward_count 393086  29.015%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-84  lr=['4.0000000'], tr/val_loss: 30.605207/ 52.949329, val:  50.00%, val_best:  71.90%, tr:  78.17%, tr_best:  82.42%, epoch time: 130.79 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 61.6717%\n",
      "layer   3  Sparsity: 73.0974%\n",
      "total_backward_count 1370880 real_backward_count 397674  29.009%\n",
      "layer   1  Sparsity: 71.7773%\n",
      "layer   2  Sparsity: 51.3750%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 145 occurrences\n",
      "test - Value 1: 307 occurrences\n",
      "epoch-85  lr=['4.0000000'], tr/val_loss: 34.629890/ 20.257812, val:  67.04%, val_best:  71.90%, tr:  78.65%, tr_best:  82.42%, epoch time: 132.79 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 59.6973%\n",
      "layer   3  Sparsity: 71.6998%\n",
      "total_backward_count 1387008 real_backward_count 402346  29.008%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 53.5000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['4.0000000'], tr/val_loss: 31.887615/ 53.855240, val:  50.00%, val_best:  71.90%, tr:  78.50%, tr_best:  82.42%, epoch time: 131.01 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 59.1682%\n",
      "layer   3  Sparsity: 73.3181%\n",
      "total_backward_count 1403136 real_backward_count 407110  29.014%\n",
      "layer   1  Sparsity: 78.3203%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-87  lr=['4.0000000'], tr/val_loss: 33.840366/ 29.029743, val:  60.18%, val_best:  71.90%, tr:  78.82%, tr_best:  82.42%, epoch time: 130.95 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.1212%\n",
      "layer   3  Sparsity: 72.7889%\n",
      "total_backward_count 1419264 real_backward_count 411736  29.011%\n",
      "layer   1  Sparsity: 78.3691%\n",
      "layer   2  Sparsity: 64.5000%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['4.0000000'], tr/val_loss: 28.893803/ 31.869308, val:  50.00%, val_best:  71.90%, tr:  79.04%, tr_best:  82.42%, epoch time: 131.87 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.4415%\n",
      "layer   3  Sparsity: 75.5705%\n",
      "total_backward_count 1435392 real_backward_count 416278  29.001%\n",
      "layer   1  Sparsity: 91.2109%\n",
      "layer   2  Sparsity: 81.8750%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-89  lr=['4.0000000'], tr/val_loss: 30.165392/  7.921224, val:  52.21%, val_best:  71.90%, tr:  76.51%, tr_best:  82.42%, epoch time: 131.84 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4785%\n",
      "layer   2  Sparsity: 58.6135%\n",
      "layer   3  Sparsity: 75.7138%\n",
      "total_backward_count 1451520 real_backward_count 421112  29.012%\n",
      "layer   1  Sparsity: 83.2031%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-90  lr=['4.0000000'], tr/val_loss: 29.713949/ 39.637203, val:  49.78%, val_best:  71.90%, tr:  75.32%, tr_best:  82.42%, epoch time: 131.01 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 57.3346%\n",
      "layer   3  Sparsity: 76.0880%\n",
      "total_backward_count 1467648 real_backward_count 426023  29.028%\n",
      "layer   1  Sparsity: 81.2012%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-91  lr=['4.0000000'], tr/val_loss: 31.541515/ 10.687372, val:  59.29%, val_best:  71.90%, tr:  78.05%, tr_best:  82.42%, epoch time: 131.40 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 56.2434%\n",
      "layer   3  Sparsity: 74.1300%\n",
      "total_backward_count 1483776 real_backward_count 430681  29.026%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-92  lr=['4.0000000'], tr/val_loss: 31.844654/ 53.121693, val:  62.61%, val_best:  71.90%, tr:  78.00%, tr_best:  82.42%, epoch time: 127.57 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 56.2632%\n",
      "layer   3  Sparsity: 73.3660%\n",
      "total_backward_count 1499904 real_backward_count 435444  29.031%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-93  lr=['4.0000000'], tr/val_loss: 35.814220/ 41.850800, val:  50.88%, val_best:  71.90%, tr:  76.86%, tr_best:  82.42%, epoch time: 131.01 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 56.4295%\n",
      "layer   3  Sparsity: 69.9175%\n",
      "total_backward_count 1516032 real_backward_count 440257  29.040%\n",
      "layer   1  Sparsity: 75.1465%\n",
      "layer   2  Sparsity: 41.2500%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "lif layer 2 self.abs_max_v: 27659.0\n",
      "lif layer 2 self.abs_max_v: 28842.5\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-94  lr=['4.0000000'], tr/val_loss: 41.376270/ 26.668850, val:  66.37%, val_best:  71.90%, tr:  76.56%, tr_best:  82.42%, epoch time: 131.65 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 55.9506%\n",
      "layer   3  Sparsity: 66.8079%\n",
      "total_backward_count 1532160 real_backward_count 444995  29.044%\n",
      "layer   1  Sparsity: 66.0645%\n",
      "layer   2  Sparsity: 40.2500%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "fc layer 3 self.abs_max_out: 278.0\n",
      "fc layer 3 self.abs_max_out: 284.0\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['4.0000000'], tr/val_loss: 39.772881/ 45.798576, val:  50.00%, val_best:  71.90%, tr:  77.43%, tr_best:  82.42%, epoch time: 132.13 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 57.8136%\n",
      "layer   3  Sparsity: 67.0617%\n",
      "total_backward_count 1548288 real_backward_count 449813  29.052%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 64.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-96  lr=['4.0000000'], tr/val_loss: 40.956608/ 46.729145, val:  50.22%, val_best:  71.90%, tr:  77.41%, tr_best:  82.42%, epoch time: 131.43 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 53.8390%\n",
      "layer   3  Sparsity: 66.2939%\n",
      "total_backward_count 1564416 real_backward_count 454486  29.051%\n",
      "layer   1  Sparsity: 65.7227%\n",
      "layer   2  Sparsity: 39.1250%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 416 occurrences\n",
      "test - Value 1: 36 occurrences\n",
      "epoch-97  lr=['4.0000000'], tr/val_loss: 43.514687/ 18.528399, val:  56.64%, val_best:  71.90%, tr:  76.91%, tr_best:  82.42%, epoch time: 131.98 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 54.0189%\n",
      "layer   3  Sparsity: 64.8577%\n",
      "total_backward_count 1580544 real_backward_count 459258  29.057%\n",
      "layer   1  Sparsity: 71.1426%\n",
      "layer   2  Sparsity: 42.2500%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-98  lr=['4.0000000'], tr/val_loss: 43.096672/ 36.122440, val:  70.13%, val_best:  71.90%, tr:  76.39%, tr_best:  82.42%, epoch time: 131.86 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 55.5635%\n",
      "layer   3  Sparsity: 66.1245%\n",
      "total_backward_count 1596672 real_backward_count 464111  29.067%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "fc layer 3 self.abs_max_out: 297.0\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-99  lr=['4.0000000'], tr/val_loss: 41.870907/ 63.608349, val:  49.12%, val_best:  71.90%, tr:  77.58%, tr_best:  82.42%, epoch time: 132.39 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 56.5823%\n",
      "layer   3  Sparsity: 66.9622%\n",
      "total_backward_count 1612800 real_backward_count 469063  29.084%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 64.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "lif layer 2 self.abs_max_v: 29119.5\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-100 lr=['4.0000000'], tr/val_loss: 32.023804/ 14.504845, val:  55.31%, val_best:  71.90%, tr:  77.13%, tr_best:  82.42%, epoch time: 131.87 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 56.9017%\n",
      "layer   3  Sparsity: 72.9615%\n",
      "total_backward_count 1628928 real_backward_count 473901  29.093%\n",
      "layer   1  Sparsity: 66.2109%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-101 lr=['4.0000000'], tr/val_loss: 34.683044/ 44.011814, val:  50.00%, val_best:  71.90%, tr:  76.66%, tr_best:  82.42%, epoch time: 131.50 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 58.1571%\n",
      "layer   3  Sparsity: 70.2208%\n",
      "total_backward_count 1645056 real_backward_count 478879  29.110%\n",
      "layer   1  Sparsity: 84.1309%\n",
      "layer   2  Sparsity: 63.3750%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-102 lr=['4.0000000'], tr/val_loss: 38.790436/ 28.305885, val:  56.86%, val_best:  71.90%, tr:  76.76%, tr_best:  82.42%, epoch time: 131.14 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 57.9817%\n",
      "layer   3  Sparsity: 67.8278%\n",
      "total_backward_count 1661184 real_backward_count 483698  29.118%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 39.3750%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 257 occurrences\n",
      "test - Value 1: 195 occurrences\n",
      "epoch-103 lr=['4.0000000'], tr/val_loss: 38.294567/ 33.204662, val:  70.58%, val_best:  71.90%, tr:  77.65%, tr_best:  82.42%, epoch time: 131.94 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 55.4309%\n",
      "layer   3  Sparsity: 68.2066%\n",
      "total_backward_count 1677312 real_backward_count 488423  29.119%\n",
      "layer   1  Sparsity: 78.1250%\n",
      "layer   2  Sparsity: 54.2500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['4.0000000'], tr/val_loss: 31.580906/ 39.424267, val:  50.00%, val_best:  71.90%, tr:  75.84%, tr_best:  82.42%, epoch time: 133.36 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 56.7753%\n",
      "layer   3  Sparsity: 73.1567%\n",
      "total_backward_count 1693440 real_backward_count 493323  29.131%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 47.8750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-105 lr=['4.0000000'], tr/val_loss: 28.789509/ 33.628593, val:  54.65%, val_best:  71.90%, tr:  77.16%, tr_best:  82.42%, epoch time: 132.11 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 57.3734%\n",
      "layer   3  Sparsity: 75.5976%\n",
      "total_backward_count 1709568 real_backward_count 498139  29.138%\n",
      "layer   1  Sparsity: 83.3496%\n",
      "layer   2  Sparsity: 62.6250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-106 lr=['4.0000000'], tr/val_loss: 36.410572/ 32.873337, val:  55.31%, val_best:  71.90%, tr:  77.90%, tr_best:  82.42%, epoch time: 131.53 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 57.3767%\n",
      "layer   3  Sparsity: 70.5757%\n",
      "total_backward_count 1725696 real_backward_count 502839  29.138%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 65.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 366 occurrences\n",
      "test - Value 1: 86 occurrences\n",
      "epoch-107 lr=['4.0000000'], tr/val_loss: 36.611332/ 28.411634, val:  65.04%, val_best:  71.90%, tr:  80.01%, tr_best:  82.42%, epoch time: 131.38 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 58.7416%\n",
      "layer   3  Sparsity: 70.7482%\n",
      "total_backward_count 1741824 real_backward_count 507346  29.127%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-108 lr=['4.0000000'], tr/val_loss: 35.819435/ 24.677441, val:  53.54%, val_best:  71.90%, tr:  79.79%, tr_best:  82.42%, epoch time: 131.27 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 59.6565%\n",
      "layer   3  Sparsity: 72.1906%\n",
      "total_backward_count 1757952 real_backward_count 512103  29.131%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 75.3750%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1908 occurrences\n",
      "train - Value 1: 2124 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-109 lr=['4.0000000'], tr/val_loss: 28.618059/ 31.207321, val:  60.18%, val_best:  71.90%, tr:  79.32%, tr_best:  82.42%, epoch time: 132.14 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 63.6631%\n",
      "layer   3  Sparsity: 74.8314%\n",
      "total_backward_count 1774080 real_backward_count 516825  29.132%\n",
      "layer   1  Sparsity: 87.3047%\n",
      "layer   2  Sparsity: 64.6250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-110 lr=['4.0000000'], tr/val_loss: 30.600517/ 37.873421, val:  50.44%, val_best:  71.90%, tr:  78.45%, tr_best:  82.42%, epoch time: 131.40 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4793%\n",
      "layer   2  Sparsity: 63.7197%\n",
      "layer   3  Sparsity: 74.1407%\n",
      "total_backward_count 1790208 real_backward_count 521567  29.134%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-111 lr=['4.0000000'], tr/val_loss: 28.593081/ 16.641737, val:  62.17%, val_best:  71.90%, tr:  76.71%, tr_best:  82.42%, epoch time: 131.57 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 62.0933%\n",
      "layer   3  Sparsity: 76.5815%\n",
      "total_backward_count 1806336 real_backward_count 526516  29.148%\n",
      "layer   1  Sparsity: 77.4902%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-112 lr=['4.0000000'], tr/val_loss: 30.017149/ 16.208246, val:  66.59%, val_best:  71.90%, tr:  77.03%, tr_best:  82.42%, epoch time: 131.93 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 62.5046%\n",
      "layer   3  Sparsity: 74.3974%\n",
      "total_backward_count 1822464 real_backward_count 531440  29.161%\n",
      "layer   1  Sparsity: 83.7891%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-113 lr=['4.0000000'], tr/val_loss: 29.554960/ 23.078289, val:  57.52%, val_best:  71.90%, tr:  76.09%, tr_best:  82.42%, epoch time: 132.15 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 63.8650%\n",
      "layer   3  Sparsity: 73.7455%\n",
      "total_backward_count 1838592 real_backward_count 536408  29.175%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-114 lr=['4.0000000'], tr/val_loss: 32.817173/  9.425635, val:  51.11%, val_best:  71.90%, tr:  78.94%, tr_best:  82.42%, epoch time: 132.29 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 57.6684%\n",
      "layer   3  Sparsity: 73.6411%\n",
      "total_backward_count 1854720 real_backward_count 540963  29.167%\n",
      "layer   1  Sparsity: 75.1953%\n",
      "layer   2  Sparsity: 48.0000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-115 lr=['4.0000000'], tr/val_loss: 32.404572/ 36.236931, val:  53.10%, val_best:  71.90%, tr:  80.90%, tr_best:  82.42%, epoch time: 131.33 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 57.7584%\n",
      "layer   3  Sparsity: 73.8715%\n",
      "total_backward_count 1870848 real_backward_count 545293  29.147%\n",
      "layer   1  Sparsity: 85.5469%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1898 occurrences\n",
      "train - Value 1: 2134 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['4.0000000'], tr/val_loss: 31.158457/ 24.394629, val:  50.00%, val_best:  71.90%, tr:  79.86%, tr_best:  82.42%, epoch time: 131.54 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 59.1356%\n",
      "layer   3  Sparsity: 74.9572%\n",
      "total_backward_count 1886976 real_backward_count 549668  29.130%\n",
      "layer   1  Sparsity: 69.0918%\n",
      "layer   2  Sparsity: 48.2500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 82 occurrences\n",
      "test - Value 1: 370 occurrences\n",
      "epoch-117 lr=['4.0000000'], tr/val_loss: 31.402155/ 24.686888, val:  57.52%, val_best:  71.90%, tr:  77.95%, tr_best:  82.42%, epoch time: 131.59 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4834%\n",
      "layer   2  Sparsity: 60.0425%\n",
      "layer   3  Sparsity: 72.8095%\n",
      "total_backward_count 1903104 real_backward_count 554019  29.111%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 67.1250%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['4.0000000'], tr/val_loss: 35.362843/ 38.472443, val:  50.00%, val_best:  71.90%, tr:  81.62%, tr_best:  82.42%, epoch time: 130.41 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 60.6150%\n",
      "layer   3  Sparsity: 72.1822%\n",
      "total_backward_count 1919232 real_backward_count 558163  29.083%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 69.1250%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['4.0000000'], tr/val_loss: 35.384575/ 49.608547, val:  50.00%, val_best:  71.90%, tr:  82.02%, tr_best:  82.42%, epoch time: 131.17 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 59.8786%\n",
      "layer   3  Sparsity: 69.0284%\n",
      "total_backward_count 1935360 real_backward_count 562303  29.054%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 61.8750%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-120 lr=['4.0000000'], tr/val_loss: 40.273773/ 48.588680, val:  52.43%, val_best:  71.90%, tr:  81.45%, tr_best:  82.42%, epoch time: 131.50 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 59.7800%\n",
      "layer   3  Sparsity: 68.1607%\n",
      "total_backward_count 1951488 real_backward_count 566522  29.030%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-121 lr=['4.0000000'], tr/val_loss: 31.708918/ 46.866776, val:  50.44%, val_best:  71.90%, tr:  80.58%, tr_best:  82.42%, epoch time: 129.15 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 57.9633%\n",
      "layer   3  Sparsity: 72.8896%\n",
      "total_backward_count 1967616 real_backward_count 570937  29.017%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 57.3750%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['4.0000000'], tr/val_loss: 37.445671/ 42.440525, val:  50.00%, val_best:  71.90%, tr:  79.37%, tr_best:  82.42%, epoch time: 132.89 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 60.7445%\n",
      "layer   3  Sparsity: 69.9172%\n",
      "total_backward_count 1983744 real_backward_count 575381  29.005%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-123 lr=['4.0000000'], tr/val_loss: 37.008606/ 10.801400, val:  62.39%, val_best:  71.90%, tr:  80.23%, tr_best:  82.42%, epoch time: 131.75 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 59.7941%\n",
      "layer   3  Sparsity: 69.4991%\n",
      "total_backward_count 1999872 real_backward_count 579917  28.998%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-124 lr=['4.0000000'], tr/val_loss: 30.543190/ 18.276213, val:  59.07%, val_best:  71.90%, tr:  77.88%, tr_best:  82.42%, epoch time: 132.06 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 59.2310%\n",
      "layer   3  Sparsity: 71.9143%\n",
      "total_backward_count 2016000 real_backward_count 584517  28.994%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 62.1250%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1868 occurrences\n",
      "train - Value 1: 2164 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-125 lr=['4.0000000'], tr/val_loss: 28.109533/ 22.299608, val:  75.22%, val_best:  75.22%, tr:  79.51%, tr_best:  82.42%, epoch time: 131.12 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 58.0940%\n",
      "layer   3  Sparsity: 77.1687%\n",
      "total_backward_count 2032128 real_backward_count 588999  28.984%\n",
      "layer   1  Sparsity: 70.3125%\n",
      "layer   2  Sparsity: 48.3750%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1845 occurrences\n",
      "train - Value 1: 2187 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-126 lr=['4.0000000'], tr/val_loss: 28.333540/ 32.368721, val:  61.73%, val_best:  75.22%, tr:  79.34%, tr_best:  82.42%, epoch time: 131.12 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 57.9725%\n",
      "layer   3  Sparsity: 76.9772%\n",
      "total_backward_count 2048256 real_backward_count 593612  28.981%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-127 lr=['4.0000000'], tr/val_loss: 30.921234/ 20.333942, val:  64.16%, val_best:  75.22%, tr:  78.50%, tr_best:  82.42%, epoch time: 131.34 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 57.6245%\n",
      "layer   3  Sparsity: 75.7872%\n",
      "total_backward_count 2064384 real_backward_count 598359  28.985%\n",
      "layer   1  Sparsity: 88.4277%\n",
      "layer   2  Sparsity: 76.0000%\n",
      "layer   3  Sparsity: 87.5000%\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 287 occurrences\n",
      "test - Value 1: 165 occurrences\n",
      "epoch-128 lr=['4.0000000'], tr/val_loss: 27.380026/ 26.772350, val:  71.46%, val_best:  75.22%, tr:  76.84%, tr_best:  82.42%, epoch time: 131.15 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 60.8365%\n",
      "layer   3  Sparsity: 77.0643%\n",
      "total_backward_count 2080512 real_backward_count 603019  28.984%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 67.6250%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-129 lr=['4.0000000'], tr/val_loss: 34.403614/ 26.826389, val:  51.99%, val_best:  75.22%, tr:  77.21%, tr_best:  82.42%, epoch time: 131.39 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 59.5987%\n",
      "layer   3  Sparsity: 72.4967%\n",
      "total_backward_count 2096640 real_backward_count 607793  28.989%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 68.7500%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-130 lr=['4.0000000'], tr/val_loss: 35.538158/ 36.970390, val:  51.77%, val_best:  75.22%, tr:  79.44%, tr_best:  82.42%, epoch time: 131.70 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 58.9181%\n",
      "layer   3  Sparsity: 70.8549%\n",
      "total_backward_count 2112768 real_backward_count 612223  28.977%\n",
      "layer   1  Sparsity: 87.7441%\n",
      "layer   2  Sparsity: 72.1250%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-131 lr=['4.0000000'], tr/val_loss: 38.644821/ 26.356079, val:  66.81%, val_best:  75.22%, tr:  78.00%, tr_best:  82.42%, epoch time: 131.88 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 58.1801%\n",
      "layer   3  Sparsity: 66.9680%\n",
      "total_backward_count 2128896 real_backward_count 616848  28.975%\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-132 lr=['4.0000000'], tr/val_loss: 30.719082/ 10.532271, val:  52.43%, val_best:  75.22%, tr:  77.11%, tr_best:  82.42%, epoch time: 131.49 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4821%\n",
      "layer   2  Sparsity: 58.4789%\n",
      "layer   3  Sparsity: 72.6634%\n",
      "total_backward_count 2145024 real_backward_count 621729  28.985%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 69.6250%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 324 occurrences\n",
      "test - Value 1: 128 occurrences\n",
      "epoch-133 lr=['4.0000000'], tr/val_loss: 29.297743/ 30.493637, val:  67.70%, val_best:  75.22%, tr:  80.78%, tr_best:  82.42%, epoch time: 131.49 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 56.8597%\n",
      "layer   3  Sparsity: 75.1818%\n",
      "total_backward_count 2161152 real_backward_count 626168  28.974%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 49.0000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-134 lr=['4.0000000'], tr/val_loss: 25.650051/ 22.639847, val:  58.63%, val_best:  75.22%, tr:  80.98%, tr_best:  82.42%, epoch time: 131.39 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 57.2796%\n",
      "layer   3  Sparsity: 77.9227%\n",
      "total_backward_count 2177280 real_backward_count 630544  28.960%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 49.2500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-135 lr=['4.0000000'], tr/val_loss: 24.896292/ 11.700444, val:  73.89%, val_best:  75.22%, tr:  79.37%, tr_best:  82.42%, epoch time: 132.09 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 57.5870%\n",
      "layer   3  Sparsity: 78.7999%\n",
      "total_backward_count 2193408 real_backward_count 635076  28.954%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-136 lr=['4.0000000'], tr/val_loss: 26.766729/ 39.424320, val:  72.35%, val_best:  75.22%, tr:  78.62%, tr_best:  82.42%, epoch time: 132.24 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 54.2395%\n",
      "layer   3  Sparsity: 76.3060%\n",
      "total_backward_count 2209536 real_backward_count 639475  28.942%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 306 occurrences\n",
      "test - Value 1: 146 occurrences\n",
      "epoch-137 lr=['4.0000000'], tr/val_loss: 36.586472/ 30.755520, val:  70.35%, val_best:  75.22%, tr:  79.37%, tr_best:  82.42%, epoch time: 131.29 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 55.2545%\n",
      "layer   3  Sparsity: 69.5611%\n",
      "total_backward_count 2225664 real_backward_count 643919  28.932%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-138 lr=['4.0000000'], tr/val_loss: 36.487034/ 38.253674, val:  57.96%, val_best:  75.22%, tr:  78.55%, tr_best:  82.42%, epoch time: 131.82 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 58.9720%\n",
      "layer   3  Sparsity: 69.0966%\n",
      "total_backward_count 2241792 real_backward_count 648399  28.923%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-139 lr=['4.0000000'], tr/val_loss: 37.502583/ 33.518921, val:  50.00%, val_best:  75.22%, tr:  78.52%, tr_best:  82.42%, epoch time: 132.57 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 59.3282%\n",
      "layer   3  Sparsity: 68.6705%\n",
      "total_backward_count 2257920 real_backward_count 653004  28.921%\n",
      "layer   1  Sparsity: 93.6035%\n",
      "layer   2  Sparsity: 79.5000%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-140 lr=['4.0000000'], tr/val_loss: 36.346725/ 42.944794, val:  61.73%, val_best:  75.22%, tr:  75.02%, tr_best:  82.42%, epoch time: 132.35 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 60.6755%\n",
      "layer   3  Sparsity: 69.3704%\n",
      "total_backward_count 2274048 real_backward_count 657958  28.933%\n",
      "layer   1  Sparsity: 77.4414%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-141 lr=['4.0000000'], tr/val_loss: 31.880072/ 29.148663, val:  76.11%, val_best:  76.11%, tr:  78.35%, tr_best:  82.42%, epoch time: 131.20 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 59.6754%\n",
      "layer   3  Sparsity: 74.4931%\n",
      "total_backward_count 2290176 real_backward_count 662708  28.937%\n",
      "layer   1  Sparsity: 69.9707%\n",
      "layer   2  Sparsity: 43.3750%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-142 lr=['4.0000000'], tr/val_loss: 31.688650/ 30.884523, val:  61.06%, val_best:  76.11%, tr:  81.89%, tr_best:  82.42%, epoch time: 131.97 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 59.1217%\n",
      "layer   3  Sparsity: 73.8551%\n",
      "total_backward_count 2306304 real_backward_count 667085  28.924%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-143 lr=['4.0000000'], tr/val_loss: 34.715019/ 28.741272, val:  69.25%, val_best:  76.11%, tr:  81.65%, tr_best:  82.42%, epoch time: 132.96 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 58.5020%\n",
      "layer   3  Sparsity: 71.3495%\n",
      "total_backward_count 2322432 real_backward_count 671410  28.910%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 84.7500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 312 occurrences\n",
      "test - Value 1: 140 occurrences\n",
      "epoch-144 lr=['4.0000000'], tr/val_loss: 31.032064/ 20.626423, val:  73.01%, val_best:  76.11%, tr:  77.43%, tr_best:  82.42%, epoch time: 131.90 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 58.6459%\n",
      "layer   3  Sparsity: 74.0364%\n",
      "total_backward_count 2338560 real_backward_count 676353  28.922%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 43.3750%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 374 occurrences\n",
      "test - Value 1: 78 occurrences\n",
      "epoch-145 lr=['4.0000000'], tr/val_loss: 29.589891/ 19.708033, val:  62.83%, val_best:  76.11%, tr:  80.16%, tr_best:  82.42%, epoch time: 130.60 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 57.6675%\n",
      "layer   3  Sparsity: 74.5260%\n",
      "total_backward_count 2354688 real_backward_count 680839  28.914%\n",
      "layer   1  Sparsity: 73.2910%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 406 occurrences\n",
      "test - Value 1: 46 occurrences\n",
      "epoch-146 lr=['4.0000000'], tr/val_loss: 32.512062/ 27.658873, val:  60.18%, val_best:  76.11%, tr:  78.47%, tr_best:  82.42%, epoch time: 131.05 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 60.9870%\n",
      "layer   3  Sparsity: 72.2942%\n",
      "total_backward_count 2370816 real_backward_count 685592  28.918%\n",
      "layer   1  Sparsity: 79.8340%\n",
      "layer   2  Sparsity: 58.6250%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 347 occurrences\n",
      "test - Value 1: 105 occurrences\n",
      "epoch-147 lr=['4.0000000'], tr/val_loss: 36.164433/ 32.538029, val:  60.84%, val_best:  76.11%, tr:  79.32%, tr_best:  82.42%, epoch time: 131.18 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 60.5914%\n",
      "layer   3  Sparsity: 70.0987%\n",
      "total_backward_count 2386944 real_backward_count 690243  28.917%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-148 lr=['4.0000000'], tr/val_loss: 37.746449/ 52.031876, val:  53.98%, val_best:  76.11%, tr:  77.16%, tr_best:  82.42%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 59.5862%\n",
      "layer   3  Sparsity: 68.6360%\n",
      "total_backward_count 2403072 real_backward_count 695067  28.924%\n",
      "layer   1  Sparsity: 84.0820%\n",
      "layer   2  Sparsity: 68.1250%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 265 occurrences\n",
      "test - Value 1: 187 occurrences\n",
      "epoch-149 lr=['4.0000000'], tr/val_loss: 38.123329/ 29.245594, val:  69.25%, val_best:  76.11%, tr:  78.97%, tr_best:  82.42%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 58.5455%\n",
      "layer   3  Sparsity: 67.9874%\n",
      "total_backward_count 2419200 real_backward_count 699581  28.918%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 323 occurrences\n",
      "test - Value 1: 129 occurrences\n",
      "epoch-150 lr=['4.0000000'], tr/val_loss: 35.559494/ 31.636789, val:  71.46%, val_best:  76.11%, tr:  78.67%, tr_best:  82.42%, epoch time: 127.88 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 58.6711%\n",
      "layer   3  Sparsity: 69.6810%\n",
      "total_backward_count 2435328 real_backward_count 704277  28.919%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 44.7500%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['4.0000000'], tr/val_loss: 40.229206/ 61.032753, val:  50.00%, val_best:  76.11%, tr:  77.58%, tr_best:  82.42%, epoch time: 132.03 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 60.6146%\n",
      "layer   3  Sparsity: 66.4142%\n",
      "total_backward_count 2451456 real_backward_count 709091  28.925%\n",
      "layer   1  Sparsity: 83.0566%\n",
      "layer   2  Sparsity: 67.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2069 occurrences\n",
      "train - Value 1: 1963 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-152 lr=['4.0000000'], tr/val_loss: 39.725609/ 28.895857, val:  50.00%, val_best:  76.11%, tr:  77.46%, tr_best:  82.42%, epoch time: 129.72 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 61.7901%\n",
      "layer   3  Sparsity: 67.0221%\n",
      "total_backward_count 2467584 real_backward_count 713915  28.932%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 61.1250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1912 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-153 lr=['4.0000000'], tr/val_loss: 29.827808/ 27.203644, val:  55.75%, val_best:  76.11%, tr:  78.27%, tr_best:  82.42%, epoch time: 131.88 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 64.0167%\n",
      "layer   3  Sparsity: 74.5589%\n",
      "total_backward_count 2483712 real_backward_count 718650  28.935%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-154 lr=['4.0000000'], tr/val_loss: 27.581423/ 25.971584, val:  68.36%, val_best:  76.11%, tr:  76.79%, tr_best:  82.42%, epoch time: 129.28 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 62.6216%\n",
      "layer   3  Sparsity: 76.4583%\n",
      "total_backward_count 2499840 real_backward_count 723517  28.943%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 55.5000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 340 occurrences\n",
      "test - Value 1: 112 occurrences\n",
      "epoch-155 lr=['4.0000000'], tr/val_loss: 29.160034/ 44.080395, val:  67.26%, val_best:  76.11%, tr:  77.46%, tr_best:  82.42%, epoch time: 130.20 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 65.1704%\n",
      "layer   3  Sparsity: 73.2835%\n",
      "total_backward_count 2515968 real_backward_count 728390  28.951%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 77.0000%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-156 lr=['4.0000000'], tr/val_loss: 30.288877/ 23.413874, val:  50.66%, val_best:  76.11%, tr:  77.41%, tr_best:  82.42%, epoch time: 131.19 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 65.9764%\n",
      "layer   3  Sparsity: 73.4804%\n",
      "total_backward_count 2532096 real_backward_count 733106  28.953%\n",
      "layer   1  Sparsity: 74.5605%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 280 occurrences\n",
      "test - Value 1: 172 occurrences\n",
      "epoch-157 lr=['4.0000000'], tr/val_loss: 23.283857/ 17.297739, val:  69.03%, val_best:  76.11%, tr:  76.71%, tr_best:  82.42%, epoch time: 131.56 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4822%\n",
      "layer   2  Sparsity: 64.9527%\n",
      "layer   3  Sparsity: 78.1263%\n",
      "total_backward_count 2548224 real_backward_count 737861  28.956%\n",
      "layer   1  Sparsity: 82.5684%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 2132 occurrences\n",
      "train - Value 1: 1900 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-158 lr=['4.0000000'], tr/val_loss: 21.870699/ 20.636765, val:  65.04%, val_best:  76.11%, tr:  76.49%, tr_best:  82.42%, epoch time: 130.80 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 65.4068%\n",
      "layer   3  Sparsity: 79.0352%\n",
      "total_backward_count 2564352 real_backward_count 742683  28.962%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 70.8750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-159 lr=['4.0000000'], tr/val_loss: 28.189135/ 28.715012, val:  50.22%, val_best:  76.11%, tr:  77.11%, tr_best:  82.42%, epoch time: 128.69 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 65.6174%\n",
      "layer   3  Sparsity: 76.5308%\n",
      "total_backward_count 2580480 real_backward_count 747663  28.974%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 66.5000%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-160 lr=['4.0000000'], tr/val_loss: 24.285650/ 20.074539, val:  52.65%, val_best:  76.11%, tr:  81.57%, tr_best:  82.42%, epoch time: 130.94 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 61.4710%\n",
      "layer   3  Sparsity: 77.5993%\n",
      "total_backward_count 2596608 real_backward_count 751926  28.958%\n",
      "layer   1  Sparsity: 62.3535%\n",
      "layer   2  Sparsity: 49.2500%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2159 occurrences\n",
      "train - Value 1: 1873 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['4.0000000'], tr/val_loss: 19.008415/ 27.737947, val:  50.00%, val_best:  76.11%, tr:  77.31%, tr_best:  82.42%, epoch time: 130.50 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 61.9914%\n",
      "layer   3  Sparsity: 82.7799%\n",
      "total_backward_count 2612736 real_backward_count 756721  28.963%\n",
      "layer   1  Sparsity: 92.2852%\n",
      "layer   2  Sparsity: 76.8750%\n",
      "layer   3  Sparsity: 92.5000%\n",
      "train - Value 0: 2108 occurrences\n",
      "train - Value 1: 1924 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-162 lr=['4.0000000'], tr/val_loss: 19.966879/ 12.143513, val:  60.40%, val_best:  76.11%, tr:  80.51%, tr_best:  82.42%, epoch time: 130.98 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 60.3524%\n",
      "layer   3  Sparsity: 80.9017%\n",
      "total_backward_count 2628864 real_backward_count 761087  28.951%\n",
      "layer   1  Sparsity: 73.5840%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-163 lr=['4.0000000'], tr/val_loss: 33.988132/ 20.513887, val:  51.99%, val_best:  76.11%, tr:  78.00%, tr_best:  82.42%, epoch time: 131.18 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 59.7683%\n",
      "layer   3  Sparsity: 71.4226%\n",
      "total_backward_count 2644992 real_backward_count 765784  28.952%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 42.5000%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-164 lr=['4.0000000'], tr/val_loss: 29.820366/ 22.187986, val:  65.71%, val_best:  76.11%, tr:  78.87%, tr_best:  82.42%, epoch time: 129.64 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 60.8171%\n",
      "layer   3  Sparsity: 74.1172%\n",
      "total_backward_count 2661120 real_backward_count 770299  28.946%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 66.5000%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 327 occurrences\n",
      "test - Value 1: 125 occurrences\n",
      "epoch-165 lr=['4.0000000'], tr/val_loss: 29.721586/ 18.987383, val:  60.84%, val_best:  76.11%, tr:  76.61%, tr_best:  82.42%, epoch time: 130.70 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 60.2061%\n",
      "layer   3  Sparsity: 73.7185%\n",
      "total_backward_count 2677248 real_backward_count 775110  28.952%\n",
      "layer   1  Sparsity: 72.4609%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['4.0000000'], tr/val_loss: 27.584808/ 34.799400, val:  50.00%, val_best:  76.11%, tr:  80.38%, tr_best:  82.42%, epoch time: 131.13 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 60.7432%\n",
      "layer   3  Sparsity: 76.7845%\n",
      "total_backward_count 2693376 real_backward_count 779505  28.942%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 67.3750%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1925 occurrences\n",
      "train - Value 1: 2107 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-167 lr=['4.0000000'], tr/val_loss: 26.782785/ 10.242794, val:  57.52%, val_best:  76.11%, tr:  81.47%, tr_best:  82.42%, epoch time: 130.54 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 60.6577%\n",
      "layer   3  Sparsity: 77.9316%\n",
      "total_backward_count 2709504 real_backward_count 783699  28.924%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 51.3750%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2117 occurrences\n",
      "train - Value 1: 1915 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['4.0000000'], tr/val_loss: 23.844568/ 47.481094, val:  50.00%, val_best:  76.11%, tr:  81.67%, tr_best:  82.42%, epoch time: 131.22 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 60.6571%\n",
      "layer   3  Sparsity: 78.7810%\n",
      "total_backward_count 2725632 real_backward_count 787818  28.904%\n",
      "layer   1  Sparsity: 89.4531%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 80.0000%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-169 lr=['4.0000000'], tr/val_loss: 24.305508/ 38.185280, val:  64.16%, val_best:  76.11%, tr:  76.31%, tr_best:  82.42%, epoch time: 130.96 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 65.1817%\n",
      "layer   3  Sparsity: 77.8168%\n",
      "total_backward_count 2741760 real_backward_count 792672  28.911%\n",
      "layer   1  Sparsity: 76.3672%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-170 lr=['4.0000000'], tr/val_loss: 30.207632/ 47.735031, val:  51.99%, val_best:  76.11%, tr:  73.31%, tr_best:  82.42%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4818%\n",
      "layer   2  Sparsity: 59.2053%\n",
      "layer   3  Sparsity: 73.2456%\n",
      "total_backward_count 2757888 real_backward_count 797965  28.934%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 59.6250%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-171 lr=['4.0000000'], tr/val_loss: 34.936481/ 24.052084, val:  54.20%, val_best:  76.11%, tr:  76.54%, tr_best:  82.42%, epoch time: 130.99 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 58.6892%\n",
      "layer   3  Sparsity: 70.3803%\n",
      "total_backward_count 2774016 real_backward_count 802868  28.942%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 62.6250%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-172 lr=['4.0000000'], tr/val_loss: 32.512169/ 12.138864, val:  58.63%, val_best:  76.11%, tr:  79.66%, tr_best:  82.42%, epoch time: 131.79 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 57.3970%\n",
      "layer   3  Sparsity: 73.3884%\n",
      "total_backward_count 2790144 real_backward_count 807437  28.939%\n",
      "layer   1  Sparsity: 85.1562%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-173 lr=['4.0000000'], tr/val_loss: 28.515522/ 21.580906, val:  56.64%, val_best:  76.11%, tr:  78.89%, tr_best:  82.42%, epoch time: 131.52 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 57.1515%\n",
      "layer   3  Sparsity: 75.8527%\n",
      "total_backward_count 2806272 real_backward_count 812116  28.939%\n",
      "layer   1  Sparsity: 93.4082%\n",
      "layer   2  Sparsity: 77.8750%\n",
      "layer   3  Sparsity: 87.5000%\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-174 lr=['4.0000000'], tr/val_loss: 28.842857/ 26.648619, val:  53.76%, val_best:  76.11%, tr:  77.36%, tr_best:  82.42%, epoch time: 131.18 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4780%\n",
      "layer   2  Sparsity: 56.3663%\n",
      "layer   3  Sparsity: 74.5416%\n",
      "total_backward_count 2822400 real_backward_count 817054  28.949%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-175 lr=['4.0000000'], tr/val_loss: 32.878422/ 16.607592, val:  55.09%, val_best:  76.11%, tr:  76.81%, tr_best:  82.42%, epoch time: 130.59 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 57.4012%\n",
      "layer   3  Sparsity: 71.7968%\n",
      "total_backward_count 2838528 real_backward_count 821750  28.950%\n",
      "layer   1  Sparsity: 73.7793%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-176 lr=['4.0000000'], tr/val_loss: 31.202812/ 17.851656, val:  51.99%, val_best:  76.11%, tr:  78.92%, tr_best:  82.42%, epoch time: 131.37 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 58.6832%\n",
      "layer   3  Sparsity: 73.8462%\n",
      "total_backward_count 2854656 real_backward_count 826589  28.956%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-177 lr=['4.0000000'], tr/val_loss: 22.549852/ 27.237509, val:  66.81%, val_best:  76.11%, tr:  76.49%, tr_best:  82.42%, epoch time: 131.79 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 57.6759%\n",
      "layer   3  Sparsity: 79.0927%\n",
      "total_backward_count 2870784 real_backward_count 831451  28.963%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-178 lr=['4.0000000'], tr/val_loss: 21.713697/ 14.816009, val:  48.89%, val_best:  76.11%, tr:  76.26%, tr_best:  82.42%, epoch time: 130.80 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 55.9890%\n",
      "layer   3  Sparsity: 79.0927%\n",
      "total_backward_count 2886912 real_backward_count 836255  28.967%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-179 lr=['4.0000000'], tr/val_loss: 27.799204/ 38.494587, val:  49.78%, val_best:  76.11%, tr:  76.09%, tr_best:  82.42%, epoch time: 131.60 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 57.2189%\n",
      "layer   3  Sparsity: 74.8143%\n",
      "total_backward_count 2903040 real_backward_count 841294  28.980%\n",
      "layer   1  Sparsity: 70.6543%\n",
      "layer   2  Sparsity: 44.6250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-180 lr=['4.0000000'], tr/val_loss: 31.495907/ 19.147120, val:  70.58%, val_best:  76.11%, tr:  78.03%, tr_best:  82.42%, epoch time: 130.98 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 56.6265%\n",
      "layer   3  Sparsity: 72.7024%\n",
      "total_backward_count 2919168 real_backward_count 846093  28.984%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 65.8750%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 352 occurrences\n",
      "test - Value 1: 100 occurrences\n",
      "epoch-181 lr=['4.0000000'], tr/val_loss: 29.623173/ 24.666552, val:  65.04%, val_best:  76.11%, tr:  77.08%, tr_best:  82.42%, epoch time: 130.12 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 57.8350%\n",
      "layer   3  Sparsity: 74.6029%\n",
      "total_backward_count 2935296 real_backward_count 850903  28.989%\n",
      "layer   1  Sparsity: 57.8125%\n",
      "layer   2  Sparsity: 41.1250%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-182 lr=['4.0000000'], tr/val_loss: 29.947905/ 18.075005, val:  50.00%, val_best:  76.11%, tr:  77.73%, tr_best:  82.42%, epoch time: 130.62 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 59.6220%\n",
      "layer   3  Sparsity: 74.7725%\n",
      "total_backward_count 2951424 real_backward_count 855624  28.990%\n",
      "layer   1  Sparsity: 77.8809%\n",
      "layer   2  Sparsity: 55.1250%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 406 occurrences\n",
      "test - Value 1: 46 occurrences\n",
      "epoch-183 lr=['4.0000000'], tr/val_loss: 29.612274/ 31.580317, val:  58.41%, val_best:  76.11%, tr:  78.50%, tr_best:  82.42%, epoch time: 127.31 seconds, 2.12 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 57.0998%\n",
      "layer   3  Sparsity: 73.9343%\n",
      "total_backward_count 2967552 real_backward_count 860257  28.989%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 65.0000%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-184 lr=['4.0000000'], tr/val_loss: 29.276073/ 21.115431, val:  53.54%, val_best:  76.11%, tr:  78.12%, tr_best:  82.42%, epoch time: 130.23 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 57.9114%\n",
      "layer   3  Sparsity: 74.1529%\n",
      "total_backward_count 2983680 real_backward_count 865001  28.991%\n",
      "layer   1  Sparsity: 85.8887%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-185 lr=['4.0000000'], tr/val_loss: 33.669071/ 20.839329, val:  50.00%, val_best:  76.11%, tr:  76.61%, tr_best:  82.42%, epoch time: 128.57 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 55.7522%\n",
      "layer   3  Sparsity: 71.8074%\n",
      "total_backward_count 2999808 real_backward_count 869873  28.998%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 61.8750%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['4.0000000'], tr/val_loss: 30.458490/ 35.883430, val:  50.00%, val_best:  76.11%, tr:  75.22%, tr_best:  82.42%, epoch time: 130.31 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 56.8516%\n",
      "layer   3  Sparsity: 72.8602%\n",
      "total_backward_count 3015936 real_backward_count 874909  29.010%\n",
      "layer   1  Sparsity: 80.0781%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-187 lr=['4.0000000'], tr/val_loss: 41.680210/ 59.072483, val:  50.44%, val_best:  76.11%, tr:  76.71%, tr_best:  82.42%, epoch time: 129.92 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 56.6513%\n",
      "layer   3  Sparsity: 63.5177%\n",
      "total_backward_count 3032064 real_backward_count 879675  29.012%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2084 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 338 occurrences\n",
      "test - Value 1: 114 occurrences\n",
      "epoch-188 lr=['4.0000000'], tr/val_loss: 33.048500/ 27.302536, val:  69.03%, val_best:  76.11%, tr:  77.78%, tr_best:  82.42%, epoch time: 131.35 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 57.2900%\n",
      "layer   3  Sparsity: 72.8881%\n",
      "total_backward_count 3048192 real_backward_count 884493  29.017%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 39.7500%\n",
      "layer   3  Sparsity: 70.0000%\n",
      "train - Value 0: 1907 occurrences\n",
      "train - Value 1: 2125 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-189 lr=['4.0000000'], tr/val_loss: 29.034407/ 14.988321, val:  51.99%, val_best:  76.11%, tr:  76.26%, tr_best:  82.42%, epoch time: 130.56 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 56.6856%\n",
      "layer   3  Sparsity: 75.9926%\n",
      "total_backward_count 3064320 real_backward_count 889412  29.025%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 82.5000%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-190 lr=['4.0000000'], tr/val_loss: 28.631155/ 32.834801, val:  47.35%, val_best:  76.11%, tr:  75.97%, tr_best:  82.42%, epoch time: 129.74 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 55.8857%\n",
      "layer   3  Sparsity: 75.1729%\n",
      "total_backward_count 3080448 real_backward_count 894308  29.032%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 43.8750%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-191 lr=['4.0000000'], tr/val_loss: 36.021801/ 32.807503, val:  47.35%, val_best:  76.11%, tr:  77.85%, tr_best:  82.42%, epoch time: 129.17 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 57.6126%\n",
      "layer   3  Sparsity: 69.4117%\n",
      "total_backward_count 3096576 real_backward_count 899057  29.034%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-192 lr=['4.0000000'], tr/val_loss: 40.466347/ 34.848331, val:  73.67%, val_best:  76.11%, tr:  77.68%, tr_best:  82.42%, epoch time: 130.55 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 55.6889%\n",
      "layer   3  Sparsity: 65.8153%\n",
      "total_backward_count 3112704 real_backward_count 903808  29.036%\n",
      "layer   1  Sparsity: 57.6660%\n",
      "layer   2  Sparsity: 36.2500%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-193 lr=['4.0000000'], tr/val_loss: 41.955467/ 30.996572, val:  51.77%, val_best:  76.11%, tr:  78.99%, tr_best:  82.42%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 56.6106%\n",
      "layer   3  Sparsity: 65.3374%\n",
      "total_backward_count 3128832 real_backward_count 908467  29.035%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 44.6250%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['4.0000000'], tr/val_loss: 36.807163/ 24.902830, val:  50.00%, val_best:  76.11%, tr:  77.38%, tr_best:  82.42%, epoch time: 129.80 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.0963%\n",
      "layer   3  Sparsity: 69.1596%\n",
      "total_backward_count 3144960 real_backward_count 913122  29.034%\n",
      "layer   1  Sparsity: 88.2324%\n",
      "layer   2  Sparsity: 69.7500%\n",
      "layer   3  Sparsity: 85.0000%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-195 lr=['4.0000000'], tr/val_loss: 28.316572/ 19.899504, val:  61.28%, val_best:  76.11%, tr:  81.27%, tr_best:  82.42%, epoch time: 129.75 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 57.5446%\n",
      "layer   3  Sparsity: 73.6181%\n",
      "total_backward_count 3161088 real_backward_count 917449  29.023%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-196 lr=['4.0000000'], tr/val_loss: 30.526752/ 25.879345, val:  60.62%, val_best:  76.11%, tr:  80.41%, tr_best:  82.42%, epoch time: 129.76 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 60.2194%\n",
      "layer   3  Sparsity: 72.8792%\n",
      "total_backward_count 3177216 real_backward_count 921863  29.015%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-197 lr=['4.0000000'], tr/val_loss: 31.322361/ 32.966904, val:  70.58%, val_best:  76.11%, tr:  78.50%, tr_best:  82.42%, epoch time: 129.71 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 59.8884%\n",
      "layer   3  Sparsity: 73.3973%\n",
      "total_backward_count 3193344 real_backward_count 926563  29.015%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 45.0000%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-198 lr=['4.0000000'], tr/val_loss: 32.788406/ 39.031151, val:  50.66%, val_best:  76.11%, tr:  81.97%, tr_best:  82.42%, epoch time: 130.09 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 60.8544%\n",
      "layer   3  Sparsity: 72.6907%\n",
      "total_backward_count 3209472 real_backward_count 930926  29.006%\n",
      "layer   1  Sparsity: 69.7754%\n",
      "layer   2  Sparsity: 51.3750%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 331 occurrences\n",
      "test - Value 1: 121 occurrences\n",
      "epoch-199 lr=['4.0000000'], tr/val_loss: 35.665508/ 24.423960, val:  68.81%, val_best:  76.11%, tr:  76.24%, tr_best:  82.42%, epoch time: 129.59 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 57.5956%\n",
      "layer   3  Sparsity: 70.3959%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1408623b904ad2a2e34a19ae51c571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.7624</td></tr><tr><td>tr_epoch_loss</td><td>35.66551</td></tr><tr><td>val_acc_best</td><td>0.76106</td></tr><tr><td>val_acc_now</td><td>0.68805</td></tr><tr><td>val_loss</td><td>24.42396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-34</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l3ajhmib' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l3ajhmib</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251211_071421-l3ajhmib/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqcglfaw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251211_143238-eqcglfaw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eqcglfaw' target=\"_blank\">fast-sweep-35</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eqcglfaw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eqcglfaw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251211_143247_124', 'my_seed': 42, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 32, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 64, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 64, 'lif_layer_v_threshold2': 32, 'init_scaling': [0.03125, 0.03125, 0.125], 'learning_rate': 1, 'learning_rate2': 4, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 64, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 64, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.03125, 0.125])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.03125, 0.125])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.03125, 0.03125, 0.125])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 1\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 28.0\n",
      "lif layer 1 self.abs_max_v: 28.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 1 self.abs_max_out: 75.0\n",
      "lif layer 1 self.abs_max_v: 76.0\n",
      "fc layer 2 self.abs_max_out: 31.0\n",
      "lif layer 2 self.abs_max_v: 31.0\n",
      "fc layer 1 self.abs_max_out: 103.0\n",
      "lif layer 1 self.abs_max_v: 122.0\n",
      "fc layer 2 self.abs_max_out: 60.0\n",
      "lif layer 2 self.abs_max_v: 64.5\n",
      "fc layer 3 self.abs_max_out: 73.0\n",
      "fc layer 1 self.abs_max_out: 107.0\n",
      "lif layer 1 self.abs_max_v: 153.5\n",
      "lif layer 2 self.abs_max_v: 87.5\n",
      "fc layer 3 self.abs_max_out: 88.0\n",
      "fc layer 1 self.abs_max_out: 114.0\n",
      "lif layer 1 self.abs_max_v: 171.5\n",
      "lif layer 2 self.abs_max_v: 103.0\n",
      "fc layer 3 self.abs_max_out: 121.0\n",
      "fc layer 2 self.abs_max_out: 101.0\n",
      "lif layer 2 self.abs_max_v: 116.0\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 86.2500%\n",
      "layer   3  Sparsity: 96.2500%\n",
      "fc layer 1 self.abs_max_out: 138.0\n",
      "fc layer 2 self.abs_max_out: 148.0\n",
      "lif layer 2 self.abs_max_v: 157.5\n",
      "fc layer 1 self.abs_max_out: 304.0\n",
      "lif layer 1 self.abs_max_v: 304.5\n",
      "fc layer 2 self.abs_max_out: 167.0\n",
      "lif layer 2 self.abs_max_v: 167.0\n",
      "lif layer 1 self.abs_max_v: 340.5\n",
      "fc layer 2 self.abs_max_out: 203.0\n",
      "lif layer 2 self.abs_max_v: 203.0\n",
      "fc layer 2 self.abs_max_out: 214.0\n",
      "lif layer 2 self.abs_max_v: 214.0\n",
      "fc layer 2 self.abs_max_out: 227.0\n",
      "lif layer 2 self.abs_max_v: 227.0\n",
      "lif layer 2 self.abs_max_v: 236.5\n",
      "fc layer 2 self.abs_max_out: 234.0\n",
      "fc layer 2 self.abs_max_out: 236.0\n",
      "fc layer 3 self.abs_max_out: 122.0\n",
      "fc layer 3 self.abs_max_out: 132.0\n",
      "fc layer 1 self.abs_max_out: 321.0\n",
      "fc layer 2 self.abs_max_out: 394.0\n",
      "lif layer 2 self.abs_max_v: 394.0\n",
      "fc layer 3 self.abs_max_out: 144.0\n",
      "lif layer 1 self.abs_max_v: 349.0\n",
      "lif layer 1 self.abs_max_v: 378.0\n",
      "fc layer 1 self.abs_max_out: 338.0\n",
      "fc layer 2 self.abs_max_out: 395.0\n",
      "lif layer 2 self.abs_max_v: 395.0\n",
      "fc layer 1 self.abs_max_out: 361.0\n",
      "fc layer 2 self.abs_max_out: 396.0\n",
      "lif layer 2 self.abs_max_v: 396.0\n",
      "fc layer 1 self.abs_max_out: 410.0\n",
      "lif layer 1 self.abs_max_v: 417.0\n",
      "lif layer 1 self.abs_max_v: 518.5\n",
      "fc layer 2 self.abs_max_out: 405.0\n",
      "lif layer 2 self.abs_max_v: 405.0\n",
      "lif layer 1 self.abs_max_v: 543.5\n",
      "fc layer 3 self.abs_max_out: 147.0\n",
      "fc layer 1 self.abs_max_out: 411.0\n",
      "fc layer 3 self.abs_max_out: 152.0\n",
      "fc layer 1 self.abs_max_out: 443.0\n",
      "fc layer 3 self.abs_max_out: 168.0\n",
      "fc layer 1 self.abs_max_out: 468.0\n",
      "fc layer 3 self.abs_max_out: 171.0\n",
      "fc layer 3 self.abs_max_out: 185.0\n",
      "fc layer 3 self.abs_max_out: 192.0\n",
      "fc layer 3 self.abs_max_out: 203.0\n",
      "fc layer 3 self.abs_max_out: 219.0\n",
      "fc layer 2 self.abs_max_out: 442.0\n",
      "lif layer 2 self.abs_max_v: 442.0\n",
      "fc layer 2 self.abs_max_out: 523.0\n",
      "lif layer 2 self.abs_max_v: 523.0\n",
      "fc layer 1 self.abs_max_out: 477.0\n",
      "fc layer 2 self.abs_max_out: 526.0\n",
      "lif layer 2 self.abs_max_v: 526.0\n",
      "fc layer 3 self.abs_max_out: 242.0\n",
      "fc layer 3 self.abs_max_out: 246.0\n",
      "fc layer 3 self.abs_max_out: 258.0\n",
      "fc layer 3 self.abs_max_out: 269.0\n",
      "fc layer 3 self.abs_max_out: 270.0\n",
      "fc layer 3 self.abs_max_out: 273.0\n",
      "fc layer 2 self.abs_max_out: 536.0\n",
      "lif layer 2 self.abs_max_v: 536.0\n",
      "fc layer 3 self.abs_max_out: 276.0\n",
      "lif layer 2 self.abs_max_v: 561.0\n",
      "lif layer 2 self.abs_max_v: 568.0\n",
      "fc layer 3 self.abs_max_out: 287.0\n",
      "lif layer 2 self.abs_max_v: 571.0\n",
      "lif layer 2 self.abs_max_v: 580.0\n",
      "lif layer 2 self.abs_max_v: 580.5\n",
      "fc layer 2 self.abs_max_out: 547.0\n",
      "fc layer 2 self.abs_max_out: 559.0\n",
      "lif layer 2 self.abs_max_v: 583.5\n",
      "lif layer 2 self.abs_max_v: 597.0\n",
      "fc layer 1 self.abs_max_out: 482.0\n",
      "lif layer 2 self.abs_max_v: 599.0\n",
      "fc layer 3 self.abs_max_out: 289.0\n",
      "fc layer 2 self.abs_max_out: 562.0\n",
      "fc layer 1 self.abs_max_out: 487.0\n",
      "lif layer 2 self.abs_max_v: 604.5\n",
      "lif layer 2 self.abs_max_v: 625.5\n",
      "lif layer 1 self.abs_max_v: 555.0\n",
      "lif layer 2 self.abs_max_v: 630.0\n",
      "lif layer 1 self.abs_max_v: 574.0\n",
      "lif layer 1 self.abs_max_v: 589.0\n",
      "lif layer 2 self.abs_max_v: 634.0\n",
      "lif layer 1 self.abs_max_v: 655.0\n",
      "lif layer 1 self.abs_max_v: 664.5\n",
      "fc layer 3 self.abs_max_out: 298.0\n",
      "fc layer 1 self.abs_max_out: 531.0\n",
      "fc layer 1 self.abs_max_out: 532.0\n",
      "lif layer 1 self.abs_max_v: 696.5\n",
      "fc layer 3 self.abs_max_out: 303.0\n",
      "fc layer 3 self.abs_max_out: 317.0\n",
      "fc layer 3 self.abs_max_out: 325.0\n",
      "fc layer 1 self.abs_max_out: 534.0\n",
      "fc layer 3 self.abs_max_out: 327.0\n",
      "lif layer 2 self.abs_max_v: 635.0\n",
      "lif layer 2 self.abs_max_v: 646.0\n",
      "lif layer 2 self.abs_max_v: 646.5\n",
      "fc layer 2 self.abs_max_out: 566.0\n",
      "fc layer 2 self.abs_max_out: 574.0\n",
      "fc layer 2 self.abs_max_out: 580.0\n",
      "fc layer 2 self.abs_max_out: 581.0\n",
      "fc layer 2 self.abs_max_out: 586.0\n",
      "fc layer 2 self.abs_max_out: 601.0\n",
      "fc layer 1 self.abs_max_out: 556.0\n",
      "fc layer 2 self.abs_max_out: 617.0\n",
      "fc layer 2 self.abs_max_out: 618.0\n",
      "fc layer 2 self.abs_max_out: 637.0\n",
      "fc layer 1 self.abs_max_out: 560.0\n",
      "fc layer 2 self.abs_max_out: 654.0\n",
      "lif layer 2 self.abs_max_v: 654.0\n",
      "fc layer 1 self.abs_max_out: 582.0\n",
      "lif layer 1 self.abs_max_v: 722.0\n",
      "lif layer 1 self.abs_max_v: 752.0\n",
      "fc layer 2 self.abs_max_out: 675.0\n",
      "lif layer 2 self.abs_max_v: 675.0\n",
      "fc layer 2 self.abs_max_out: 677.0\n",
      "lif layer 2 self.abs_max_v: 677.0\n",
      "fc layer 2 self.abs_max_out: 683.0\n",
      "lif layer 2 self.abs_max_v: 683.0\n",
      "fc layer 1 self.abs_max_out: 653.0\n",
      "fc layer 1 self.abs_max_out: 663.0\n",
      "fc layer 1 self.abs_max_out: 668.0\n",
      "lif layer 2 self.abs_max_v: 778.0\n",
      "lif layer 2 self.abs_max_v: 823.0\n",
      "lif layer 2 self.abs_max_v: 849.5\n",
      "fc layer 2 self.abs_max_out: 687.0\n",
      "lif layer 2 self.abs_max_v: 891.5\n",
      "fc layer 1 self.abs_max_out: 707.0\n",
      "lif layer 2 self.abs_max_v: 927.0\n",
      "fc layer 2 self.abs_max_out: 696.0\n",
      "lif layer 1 self.abs_max_v: 920.5\n",
      "lif layer 2 self.abs_max_v: 1051.5\n",
      "fc layer 2 self.abs_max_out: 714.0\n",
      "lif layer 1 self.abs_max_v: 946.0\n",
      "fc layer 2 self.abs_max_out: 740.0\n",
      "lif layer 2 self.abs_max_v: 1076.0\n",
      "lif layer 2 self.abs_max_v: 1097.0\n",
      "lif layer 1 self.abs_max_v: 955.5\n",
      "fc layer 2 self.abs_max_out: 763.0\n",
      "fc layer 2 self.abs_max_out: 785.0\n",
      "fc layer 2 self.abs_max_out: 833.0\n",
      "fc layer 2 self.abs_max_out: 834.0\n",
      "fc layer 2 self.abs_max_out: 859.0\n",
      "lif layer 2 self.abs_max_v: 1109.5\n",
      "lif layer 2 self.abs_max_v: 1124.0\n",
      "lif layer 2 self.abs_max_v: 1246.0\n",
      "lif layer 1 self.abs_max_v: 965.0\n",
      "lif layer 1 self.abs_max_v: 1028.5\n",
      "fc layer 2 self.abs_max_out: 905.0\n",
      "fc layer 2 self.abs_max_out: 907.0\n",
      "fc layer 2 self.abs_max_out: 920.0\n",
      "fc layer 2 self.abs_max_out: 969.0\n",
      "fc layer 3 self.abs_max_out: 339.0\n",
      "fc layer 3 self.abs_max_out: 345.0\n",
      "fc layer 3 self.abs_max_out: 350.0\n",
      "fc layer 3 self.abs_max_out: 367.0\n",
      "fc layer 1 self.abs_max_out: 725.0\n",
      "fc layer 1 self.abs_max_out: 746.0\n",
      "lif layer 2 self.abs_max_v: 1266.5\n",
      "lif layer 2 self.abs_max_v: 1312.0\n",
      "lif layer 2 self.abs_max_v: 1312.5\n",
      "lif layer 2 self.abs_max_v: 1404.5\n",
      "lif layer 2 self.abs_max_v: 1420.0\n",
      "lif layer 2 self.abs_max_v: 1499.0\n",
      "fc layer 1 self.abs_max_out: 761.0\n",
      "fc layer 3 self.abs_max_out: 369.0\n",
      "fc layer 1 self.abs_max_out: 766.0\n",
      "fc layer 1 self.abs_max_out: 777.0\n",
      "fc layer 2 self.abs_max_out: 1010.0\n",
      "fc layer 2 self.abs_max_out: 1059.0\n",
      "lif layer 2 self.abs_max_v: 1602.0\n",
      "fc layer 3 self.abs_max_out: 371.0\n",
      "lif layer 1 self.abs_max_v: 1088.0\n",
      "fc layer 3 self.abs_max_out: 382.0\n",
      "fc layer 1 self.abs_max_out: 788.0\n",
      "lif layer 1 self.abs_max_v: 1102.5\n",
      "lif layer 1 self.abs_max_v: 1168.0\n",
      "lif layer 1 self.abs_max_v: 1204.0\n",
      "lif layer 1 self.abs_max_v: 1229.0\n",
      "lif layer 1 self.abs_max_v: 1272.5\n",
      "fc layer 1 self.abs_max_out: 800.0\n",
      "fc layer 3 self.abs_max_out: 387.0\n",
      "fc layer 3 self.abs_max_out: 397.0\n",
      "fc layer 1 self.abs_max_out: 815.0\n",
      "lif layer 2 self.abs_max_v: 1660.0\n",
      "fc layer 1 self.abs_max_out: 817.0\n",
      "lif layer 1 self.abs_max_v: 1280.5\n",
      "lif layer 2 self.abs_max_v: 1667.5\n",
      "lif layer 2 self.abs_max_v: 1747.0\n",
      "fc layer 1 self.abs_max_out: 820.0\n",
      "fc layer 1 self.abs_max_out: 851.0\n",
      "fc layer 1 self.abs_max_out: 880.0\n",
      "lif layer 2 self.abs_max_v: 1760.5\n",
      "fc layer 1 self.abs_max_out: 897.0\n",
      "fc layer 1 self.abs_max_out: 916.0\n",
      "lif layer 1 self.abs_max_v: 1357.5\n",
      "lif layer 2 self.abs_max_v: 1796.0\n",
      "lif layer 2 self.abs_max_v: 1863.0\n",
      "fc layer 2 self.abs_max_out: 1060.0\n",
      "fc layer 2 self.abs_max_out: 1068.0\n",
      "fc layer 3 self.abs_max_out: 402.0\n",
      "lif layer 1 self.abs_max_v: 1417.5\n",
      "fc layer 1 self.abs_max_out: 940.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 1529.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1756.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1838.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1908.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1929.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2209.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2261.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2620.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2628.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2650.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2672.00 at epoch 0, iter 4031\n",
      "lif layer 1 self.abs_max_v: 1458.0\n",
      "max_activation_accul updated: 2684.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['1.0000000'], tr/val_loss:136.980423/128.801682, val:  50.00%, val_best:  50.00%, tr:  94.44%, tr_best:  94.44%, epoch time: 248.62 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 72.9063%\n",
      "layer   3  Sparsity: 67.4584%\n",
      "total_backward_count 32256 real_backward_count 7296  22.619%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 78.1006%\n",
      "layer   2  Sparsity: 64.8750%\n",
      "layer   3  Sparsity: 64.3750%\n",
      "fc layer 1 self.abs_max_out: 999.0\n",
      "lif layer 1 self.abs_max_v: 1520.5\n",
      "fc layer 2 self.abs_max_out: 1070.0\n",
      "fc layer 2 self.abs_max_out: 1072.0\n",
      "fc layer 3 self.abs_max_out: 438.0\n",
      "lif layer 1 self.abs_max_v: 1610.0\n",
      "fc layer 1 self.abs_max_out: 1002.0\n",
      "fc layer 1 self.abs_max_out: 1054.0\n",
      "fc layer 1 self.abs_max_out: 1074.0\n",
      "lif layer 1 self.abs_max_v: 1629.0\n",
      "lif layer 1 self.abs_max_v: 1630.0\n",
      "lif layer 1 self.abs_max_v: 1631.0\n",
      "lif layer 1 self.abs_max_v: 1715.0\n",
      "lif layer 2 self.abs_max_v: 1881.0\n",
      "fc layer 1 self.abs_max_out: 1150.0\n",
      "lif layer 2 self.abs_max_v: 1882.5\n",
      "lif layer 2 self.abs_max_v: 1884.0\n",
      "lif layer 2 self.abs_max_v: 1920.0\n",
      "fc layer 2 self.abs_max_out: 1126.0\n",
      "lif layer 2 self.abs_max_v: 1937.0\n",
      "lif layer 2 self.abs_max_v: 1966.5\n",
      "lif layer 2 self.abs_max_v: 1977.5\n",
      "lif layer 2 self.abs_max_v: 2008.0\n",
      "lif layer 1 self.abs_max_v: 1749.5\n",
      "lif layer 1 self.abs_max_v: 1752.0\n",
      "fc layer 1 self.abs_max_out: 1161.0\n",
      "lif layer 1 self.abs_max_v: 1815.5\n",
      "lif layer 2 self.abs_max_v: 2060.0\n",
      "fc layer 1 self.abs_max_out: 1176.0\n",
      "fc layer 1 self.abs_max_out: 1194.0\n",
      "lif layer 1 self.abs_max_v: 1844.0\n",
      "lif layer 1 self.abs_max_v: 1876.0\n",
      "lif layer 2 self.abs_max_v: 2092.5\n",
      "fc layer 1 self.abs_max_out: 1261.0\n",
      "fc layer 2 self.abs_max_out: 1143.0\n",
      "fc layer 2 self.abs_max_out: 1149.0\n",
      "lif layer 2 self.abs_max_v: 2112.5\n",
      "lif layer 1 self.abs_max_v: 1905.0\n",
      "fc layer 2 self.abs_max_out: 1190.0\n",
      "lif layer 2 self.abs_max_v: 2128.5\n",
      "lif layer 2 self.abs_max_v: 2135.5\n",
      "lif layer 2 self.abs_max_v: 2156.0\n",
      "fc layer 1 self.abs_max_out: 1275.0\n",
      "lif layer 2 self.abs_max_v: 2205.5\n",
      "lif layer 2 self.abs_max_v: 2276.0\n",
      "lif layer 1 self.abs_max_v: 1911.0\n",
      "lif layer 2 self.abs_max_v: 2302.0\n",
      "lif layer 1 self.abs_max_v: 2024.0\n",
      "fc layer 2 self.abs_max_out: 1269.0\n",
      "lif layer 2 self.abs_max_v: 2302.5\n",
      "lif layer 2 self.abs_max_v: 2348.0\n",
      "lif layer 2 self.abs_max_v: 2379.5\n",
      "lif layer 2 self.abs_max_v: 2400.0\n",
      "fc layer 2 self.abs_max_out: 1273.0\n",
      "lif layer 2 self.abs_max_v: 2416.0\n",
      "fc layer 2 self.abs_max_out: 1284.0\n",
      "fc layer 2 self.abs_max_out: 1295.0\n",
      "fc layer 2 self.abs_max_out: 1297.0\n",
      "lif layer 2 self.abs_max_v: 2441.0\n",
      "fc layer 2 self.abs_max_out: 1312.0\n",
      "lif layer 2 self.abs_max_v: 2460.5\n",
      "lif layer 2 self.abs_max_v: 2481.5\n",
      "fc layer 2 self.abs_max_out: 1323.0\n",
      "lif layer 2 self.abs_max_v: 2511.0\n",
      "lif layer 2 self.abs_max_v: 2523.5\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 2 self.abs_max_out: 1335.0\n",
      "lif layer 2 self.abs_max_v: 2528.5\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['1.0000000'], tr/val_loss:152.836319/107.791397, val:  50.00%, val_best:  50.00%, tr:  95.31%, tr_best:  95.31%, epoch time: 249.32 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 72.2274%\n",
      "layer   3  Sparsity: 68.4553%\n",
      "total_backward_count 64512 real_backward_count 14248  22.086%\n",
      "layer   1  Sparsity: 86.3525%\n",
      "layer   2  Sparsity: 72.3750%\n",
      "layer   3  Sparsity: 70.9375%\n",
      "fc layer 1 self.abs_max_out: 1287.0\n",
      "fc layer 3 self.abs_max_out: 444.0\n",
      "lif layer 2 self.abs_max_v: 2541.5\n",
      "fc layer 3 self.abs_max_out: 491.0\n",
      "fc layer 1 self.abs_max_out: 1367.0\n",
      "lif layer 1 self.abs_max_v: 2056.0\n",
      "lif layer 1 self.abs_max_v: 2080.5\n",
      "lif layer 1 self.abs_max_v: 2101.5\n",
      "fc layer 2 self.abs_max_out: 1383.0\n",
      "fc layer 2 self.abs_max_out: 1388.0\n",
      "lif layer 2 self.abs_max_v: 2568.0\n",
      "lif layer 2 self.abs_max_v: 2654.0\n",
      "fc layer 2 self.abs_max_out: 1424.0\n",
      "fc layer 2 self.abs_max_out: 1454.0\n",
      "lif layer 2 self.abs_max_v: 2676.0\n",
      "lif layer 2 self.abs_max_v: 2701.0\n",
      "lif layer 2 self.abs_max_v: 2725.5\n",
      "fc layer 2 self.abs_max_out: 1523.0\n",
      "lif layer 2 self.abs_max_v: 2814.0\n",
      "lif layer 1 self.abs_max_v: 2102.0\n",
      "lif layer 1 self.abs_max_v: 2178.0\n",
      "fc layer 1 self.abs_max_out: 1384.0\n",
      "fc layer 1 self.abs_max_out: 1395.0\n",
      "lif layer 1 self.abs_max_v: 2255.5\n",
      "fc layer 1 self.abs_max_out: 1413.0\n",
      "fc layer 1 self.abs_max_out: 1478.0\n",
      "fc layer 1 self.abs_max_out: 1498.0\n",
      "lif layer 1 self.abs_max_v: 2277.0\n",
      "lif layer 1 self.abs_max_v: 2283.0\n",
      "lif layer 1 self.abs_max_v: 2287.5\n",
      "lif layer 1 self.abs_max_v: 2405.0\n",
      "lif layer 1 self.abs_max_v: 2446.0\n",
      "fc layer 1 self.abs_max_out: 1515.0\n",
      "lif layer 1 self.abs_max_v: 2513.5\n",
      "fc layer 1 self.abs_max_out: 1549.0\n",
      "fc layer 1 self.abs_max_out: 1556.0\n",
      "lif layer 1 self.abs_max_v: 2527.5\n",
      "lif layer 1 self.abs_max_v: 2533.0\n",
      "fc layer 1 self.abs_max_out: 1573.0\n",
      "lif layer 1 self.abs_max_v: 2602.5\n",
      "fc layer 3 self.abs_max_out: 496.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['1.0000000'], tr/val_loss:164.793015/165.191223, val:  50.00%, val_best:  50.00%, tr:  96.90%, tr_best:  96.90%, epoch time: 247.15 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 71.6216%\n",
      "layer   3  Sparsity: 68.8329%\n",
      "total_backward_count 96768 real_backward_count 21134  21.840%\n",
      "layer   1  Sparsity: 75.9277%\n",
      "layer   2  Sparsity: 68.8125%\n",
      "layer   3  Sparsity: 66.5000%\n",
      "fc layer 2 self.abs_max_out: 1726.0\n",
      "fc layer 2 self.abs_max_out: 1755.0\n",
      "fc layer 2 self.abs_max_out: 1761.0\n",
      "fc layer 2 self.abs_max_out: 1845.0\n",
      "fc layer 2 self.abs_max_out: 1858.0\n",
      "fc layer 2 self.abs_max_out: 1899.0\n",
      "fc layer 2 self.abs_max_out: 1915.0\n",
      "fc layer 2 self.abs_max_out: 1966.0\n",
      "fc layer 2 self.abs_max_out: 2080.0\n",
      "fc layer 2 self.abs_max_out: 2096.0\n",
      "fc layer 2 self.abs_max_out: 2106.0\n",
      "fc layer 2 self.abs_max_out: 2108.0\n",
      "fc layer 2 self.abs_max_out: 2198.0\n",
      "fc layer 1 self.abs_max_out: 1603.0\n",
      "fc layer 1 self.abs_max_out: 1606.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 1 self.abs_max_out: 1675.0\n",
      "max_activation_accul updated: 2689.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2703.00 at epoch 3, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['1.0000000'], tr/val_loss:164.304382/189.472504, val:  50.00%, val_best:  50.00%, tr:  96.90%, tr_best:  96.90%, epoch time: 247.87 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 71.5776%\n",
      "layer   3  Sparsity: 68.4100%\n",
      "total_backward_count 129024 real_backward_count 27813  21.556%\n",
      "layer   1  Sparsity: 78.0518%\n",
      "layer   2  Sparsity: 67.8125%\n",
      "layer   3  Sparsity: 65.1250%\n",
      "lif layer 1 self.abs_max_v: 2615.5\n",
      "lif layer 1 self.abs_max_v: 2622.0\n",
      "fc layer 1 self.abs_max_out: 1721.0\n",
      "lif layer 1 self.abs_max_v: 2734.0\n",
      "fc layer 3 self.abs_max_out: 510.0\n",
      "fc layer 3 self.abs_max_out: 531.0\n",
      "fc layer 3 self.abs_max_out: 537.0\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 2822.00 at epoch 4, iter 4031\n",
      "max_activation_accul updated: 2940.00 at epoch 4, iter 4031\n",
      "max_activation_accul updated: 3018.00 at epoch 4, iter 4031\n",
      "max_activation_accul updated: 3022.00 at epoch 4, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-4   lr=['1.0000000'], tr/val_loss:180.915939/135.609680, val:  65.27%, val_best:  65.27%, tr:  97.25%, tr_best:  97.25%, epoch time: 247.81 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 71.6420%\n",
      "layer   3  Sparsity: 68.4660%\n",
      "total_backward_count 161280 real_backward_count 34449  21.360%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 77.9375%\n",
      "layer   3  Sparsity: 72.4375%\n",
      "fc layer 3 self.abs_max_out: 564.0\n",
      "fc layer 1 self.abs_max_out: 1732.0\n",
      "fc layer 1 self.abs_max_out: 1761.0\n",
      "fc layer 1 self.abs_max_out: 1809.0\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['1.0000000'], tr/val_loss:176.942123/176.451935, val:  50.00%, val_best:  65.27%, tr:  97.37%, tr_best:  97.37%, epoch time: 246.65 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 71.8097%\n",
      "layer   3  Sparsity: 68.7728%\n",
      "total_backward_count 193536 real_backward_count 41243  21.310%\n",
      "layer   1  Sparsity: 85.8154%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 68.3750%\n",
      "lif layer 2 self.abs_max_v: 2835.5\n",
      "fc layer 1 self.abs_max_out: 1824.0\n",
      "lif layer 2 self.abs_max_v: 2890.0\n",
      "lif layer 2 self.abs_max_v: 2955.5\n",
      "lif layer 2 self.abs_max_v: 3009.0\n",
      "lif layer 2 self.abs_max_v: 3135.5\n",
      "lif layer 2 self.abs_max_v: 3235.0\n",
      "lif layer 2 self.abs_max_v: 3266.0\n",
      "lif layer 2 self.abs_max_v: 3314.0\n",
      "lif layer 2 self.abs_max_v: 3441.5\n",
      "lif layer 2 self.abs_max_v: 3481.5\n",
      "lif layer 2 self.abs_max_v: 3670.0\n",
      "lif layer 2 self.abs_max_v: 3820.0\n",
      "lif layer 2 self.abs_max_v: 3941.0\n",
      "lif layer 1 self.abs_max_v: 2846.5\n",
      "fc layer 1 self.abs_max_out: 1861.0\n",
      "fc layer 1 self.abs_max_out: 1922.0\n",
      "fc layer 1 self.abs_max_out: 1950.0\n",
      "lif layer 2 self.abs_max_v: 3996.0\n",
      "lif layer 2 self.abs_max_v: 4122.0\n",
      "fc layer 3 self.abs_max_out: 578.0\n",
      "fc layer 2 self.abs_max_out: 2245.0\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3124.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 3214.00 at epoch 6, iter 4031\n",
      "fc layer 2 self.abs_max_out: 2298.0\n",
      "max_activation_accul updated: 3368.00 at epoch 6, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['1.0000000'], tr/val_loss:180.821060/211.921570, val:  50.00%, val_best:  65.27%, tr:  97.37%, tr_best:  97.37%, epoch time: 246.27 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 71.9846%\n",
      "layer   3  Sparsity: 68.7324%\n",
      "total_backward_count 225792 real_backward_count 48071  21.290%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 80.6250%\n",
      "layer   3  Sparsity: 76.5000%\n",
      "lif layer 1 self.abs_max_v: 2894.5\n",
      "fc layer 1 self.abs_max_out: 1981.0\n",
      "fc layer 1 self.abs_max_out: 2007.0\n",
      "fc layer 1 self.abs_max_out: 2020.0\n",
      "fc layer 2 self.abs_max_out: 2309.0\n",
      "lif layer 2 self.abs_max_v: 4328.0\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3386.00 at epoch 7, iter 4031\n",
      "max_activation_accul updated: 3470.00 at epoch 7, iter 4031\n",
      "max_activation_accul updated: 3471.00 at epoch 7, iter 4031\n",
      "max_activation_accul updated: 3492.00 at epoch 7, iter 4031\n",
      "max_activation_accul updated: 3511.00 at epoch 7, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['1.0000000'], tr/val_loss:142.839355/126.829193, val:  50.00%, val_best:  65.27%, tr:  96.70%, tr_best:  97.37%, epoch time: 245.92 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 71.4423%\n",
      "layer   3  Sparsity: 68.6331%\n",
      "total_backward_count 258048 real_backward_count 54866  21.262%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 72.5625%\n",
      "lif layer 1 self.abs_max_v: 2906.0\n",
      "fc layer 1 self.abs_max_out: 2078.0\n",
      "fc layer 3 self.abs_max_out: 579.0\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-8   lr=['1.0000000'], tr/val_loss:134.371506/141.283844, val:  50.22%, val_best:  65.27%, tr:  96.40%, tr_best:  97.37%, epoch time: 245.28 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 70.9118%\n",
      "layer   3  Sparsity: 67.9739%\n",
      "total_backward_count 290304 real_backward_count 61685  21.248%\n",
      "layer   1  Sparsity: 83.5938%\n",
      "layer   2  Sparsity: 77.9375%\n",
      "layer   3  Sparsity: 72.3125%\n",
      "fc layer 3 self.abs_max_out: 580.0\n",
      "lif layer 1 self.abs_max_v: 3002.0\n",
      "lif layer 1 self.abs_max_v: 3007.0\n",
      "lif layer 1 self.abs_max_v: 3179.5\n",
      "fc layer 3 self.abs_max_out: 587.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['1.0000000'], tr/val_loss:190.636627/216.749298, val:  50.00%, val_best:  65.27%, tr:  97.17%, tr_best:  97.37%, epoch time: 241.69 seconds, 4.03 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 70.6245%\n",
      "layer   3  Sparsity: 67.6866%\n",
      "total_backward_count 322560 real_backward_count 68452  21.221%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 69.7500%\n",
      "layer   3  Sparsity: 68.0625%\n",
      "fc layer 1 self.abs_max_out: 2079.0\n",
      "fc layer 2 self.abs_max_out: 2330.0\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['1.0000000'], tr/val_loss:160.557388/ 38.055950, val:  50.00%, val_best:  65.27%, tr:  97.00%, tr_best:  97.37%, epoch time: 245.91 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 70.3509%\n",
      "layer   3  Sparsity: 67.8875%\n",
      "total_backward_count 354816 real_backward_count 75153  21.181%\n",
      "layer   1  Sparsity: 87.9150%\n",
      "layer   2  Sparsity: 73.5625%\n",
      "layer   3  Sparsity: 71.3750%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-11  lr=['1.0000000'], tr/val_loss:124.103996/129.430801, val:  51.99%, val_best:  65.27%, tr:  97.07%, tr_best:  97.37%, epoch time: 246.83 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 68.6047%\n",
      "layer   3  Sparsity: 67.6179%\n",
      "total_backward_count 387072 real_backward_count 81882  21.154%\n",
      "layer   1  Sparsity: 84.6924%\n",
      "layer   2  Sparsity: 71.1250%\n",
      "layer   3  Sparsity: 70.8125%\n",
      "lif layer 1 self.abs_max_v: 3241.0\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-12  lr=['1.0000000'], tr/val_loss:237.851532/236.543671, val:  55.97%, val_best:  65.27%, tr:  96.73%, tr_best:  97.37%, epoch time: 247.29 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 67.8562%\n",
      "layer   3  Sparsity: 66.5740%\n",
      "total_backward_count 419328 real_backward_count 88364  21.073%\n",
      "layer   1  Sparsity: 88.7939%\n",
      "layer   2  Sparsity: 75.1250%\n",
      "layer   3  Sparsity: 69.4375%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['1.0000000'], tr/val_loss:280.203918/287.855133, val:  50.00%, val_best:  65.27%, tr:  97.17%, tr_best:  97.37%, epoch time: 247.78 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 68.5696%\n",
      "layer   3  Sparsity: 65.8806%\n",
      "total_backward_count 451584 real_backward_count 94929  21.021%\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 77.9375%\n",
      "layer   3  Sparsity: 74.5625%\n",
      "fc layer 3 self.abs_max_out: 611.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['1.0000000'], tr/val_loss:282.841064/250.539124, val:  50.00%, val_best:  65.27%, tr:  97.25%, tr_best:  97.37%, epoch time: 247.47 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 68.1132%\n",
      "layer   3  Sparsity: 66.1016%\n",
      "total_backward_count 483840 real_backward_count 101475  20.973%\n",
      "layer   1  Sparsity: 94.1406%\n",
      "layer   2  Sparsity: 83.2500%\n",
      "layer   3  Sparsity: 80.3125%\n",
      "fc layer 1 self.abs_max_out: 2086.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-15  lr=['1.0000000'], tr/val_loss:243.124802/293.499695, val:  50.00%, val_best:  65.27%, tr:  96.70%, tr_best:  97.37%, epoch time: 248.99 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 68.1084%\n",
      "layer   3  Sparsity: 66.1003%\n",
      "total_backward_count 516096 real_backward_count 108020  20.930%\n",
      "layer   1  Sparsity: 86.2793%\n",
      "layer   2  Sparsity: 70.7500%\n",
      "layer   3  Sparsity: 69.0625%\n",
      "fc layer 1 self.abs_max_out: 2092.0\n",
      "fc layer 1 self.abs_max_out: 2095.0\n",
      "fc layer 1 self.abs_max_out: 2096.0\n",
      "fc layer 1 self.abs_max_out: 2118.0\n",
      "fc layer 1 self.abs_max_out: 2125.0\n",
      "fc layer 1 self.abs_max_out: 2126.0\n",
      "fc layer 1 self.abs_max_out: 2140.0\n",
      "fc layer 1 self.abs_max_out: 2143.0\n",
      "fc layer 1 self.abs_max_out: 2144.0\n",
      "fc layer 1 self.abs_max_out: 2160.0\n",
      "fc layer 1 self.abs_max_out: 2169.0\n",
      "fc layer 1 self.abs_max_out: 2170.0\n",
      "fc layer 1 self.abs_max_out: 2189.0\n",
      "lif layer 1 self.abs_max_v: 3252.0\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 290 occurrences\n",
      "test - Value 1: 162 occurrences\n",
      "epoch-16  lr=['1.0000000'], tr/val_loss:288.665680/274.548004, val:  67.70%, val_best:  67.70%, tr:  96.03%, tr_best:  97.37%, epoch time: 248.60 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 67.8706%\n",
      "layer   3  Sparsity: 65.8432%\n",
      "total_backward_count 548352 real_backward_count 114708  20.919%\n",
      "layer   1  Sparsity: 79.7119%\n",
      "layer   2  Sparsity: 54.2500%\n",
      "layer   3  Sparsity: 57.9375%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-17  lr=['1.0000000'], tr/val_loss:315.122498/321.463684, val:  50.00%, val_best:  67.70%, tr:  96.97%, tr_best:  97.37%, epoch time: 248.03 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 67.4035%\n",
      "layer   3  Sparsity: 65.5140%\n",
      "total_backward_count 580608 real_backward_count 121224  20.879%\n",
      "layer   1  Sparsity: 76.7822%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 59.5000%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['1.0000000'], tr/val_loss:325.305786/290.527100, val:  50.00%, val_best:  67.70%, tr:  95.24%, tr_best:  97.37%, epoch time: 248.44 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 68.1439%\n",
      "layer   3  Sparsity: 64.6977%\n",
      "total_backward_count 612864 real_backward_count 128196  20.918%\n",
      "layer   1  Sparsity: 88.8184%\n",
      "layer   2  Sparsity: 80.2500%\n",
      "layer   3  Sparsity: 73.3750%\n",
      "fc layer 1 self.abs_max_out: 2226.0\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['1.0000000'], tr/val_loss:355.994629/352.800262, val:  50.00%, val_best:  67.70%, tr:  95.19%, tr_best:  97.37%, epoch time: 247.24 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 68.3243%\n",
      "layer   3  Sparsity: 63.8079%\n",
      "total_backward_count 645120 real_backward_count 135232  20.962%\n",
      "layer   1  Sparsity: 83.1787%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 55.1250%\n",
      "fc layer 3 self.abs_max_out: 636.0\n",
      "fc layer 1 self.abs_max_out: 2263.0\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-20  lr=['1.0000000'], tr/val_loss:413.265503/395.850769, val:  50.22%, val_best:  67.70%, tr:  96.88%, tr_best:  97.37%, epoch time: 247.29 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 68.1347%\n",
      "layer   3  Sparsity: 63.6059%\n",
      "total_backward_count 677376 real_backward_count 141720  20.922%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 77.0625%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "lif layer 1 self.abs_max_v: 3417.5\n",
      "fc layer 1 self.abs_max_out: 2323.0\n",
      "lif layer 1 self.abs_max_v: 3420.5\n",
      "lif layer 1 self.abs_max_v: 3625.0\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3573.00 at epoch 21, iter 4031\n",
      "max_activation_accul updated: 3581.00 at epoch 21, iter 4031\n",
      "max_activation_accul updated: 3637.00 at epoch 21, iter 4031\n",
      "max_activation_accul updated: 3665.00 at epoch 21, iter 4031\n",
      "max_activation_accul updated: 3690.00 at epoch 21, iter 4031\n",
      "max_activation_accul updated: 3758.00 at epoch 21, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-21  lr=['1.0000000'], tr/val_loss:452.316223/437.058014, val:  50.00%, val_best:  67.70%, tr:  97.12%, tr_best:  97.37%, epoch time: 246.09 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 68.2264%\n",
      "layer   3  Sparsity: 63.4614%\n",
      "total_backward_count 709632 real_backward_count 148076  20.867%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 69.8125%\n",
      "layer   3  Sparsity: 66.4375%\n",
      "lif layer 1 self.abs_max_v: 3688.5\n",
      "lif layer 1 self.abs_max_v: 3832.0\n",
      "fc layer 1 self.abs_max_out: 2387.0\n",
      "fc layer 3 self.abs_max_out: 658.0\n",
      "fc layer 1 self.abs_max_out: 2429.0\n",
      "fc layer 3 self.abs_max_out: 664.0\n",
      "fc layer 3 self.abs_max_out: 678.0\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['1.0000000'], tr/val_loss:436.173523/419.045715, val:  50.00%, val_best:  67.70%, tr:  96.73%, tr_best:  97.37%, epoch time: 246.52 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 68.4936%\n",
      "layer   3  Sparsity: 63.3139%\n",
      "total_backward_count 741888 real_backward_count 154419  20.814%\n",
      "layer   1  Sparsity: 77.0264%\n",
      "layer   2  Sparsity: 64.3125%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "fc layer 3 self.abs_max_out: 703.0\n",
      "fc layer 3 self.abs_max_out: 706.0\n",
      "fc layer 3 self.abs_max_out: 708.0\n",
      "fc layer 3 self.abs_max_out: 714.0\n",
      "fc layer 3 self.abs_max_out: 733.0\n",
      "fc layer 3 self.abs_max_out: 742.0\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 416 occurrences\n",
      "test - Value 1: 36 occurrences\n",
      "epoch-23  lr=['1.0000000'], tr/val_loss:484.061432/416.758240, val:  55.31%, val_best:  67.70%, tr:  96.55%, tr_best:  97.37%, epoch time: 247.26 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 68.4939%\n",
      "layer   3  Sparsity: 63.3336%\n",
      "total_backward_count 774144 real_backward_count 160841  20.777%\n",
      "layer   1  Sparsity: 76.9287%\n",
      "layer   2  Sparsity: 57.9375%\n",
      "layer   3  Sparsity: 54.3750%\n",
      "fc layer 3 self.abs_max_out: 750.0\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3802.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4133.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4168.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4188.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4289.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4309.00 at epoch 24, iter 4031\n",
      "max_activation_accul updated: 4321.00 at epoch 24, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['1.0000000'], tr/val_loss:473.760529/490.456665, val:  50.00%, val_best:  67.70%, tr:  96.92%, tr_best:  97.37%, epoch time: 245.37 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 68.3492%\n",
      "layer   3  Sparsity: 63.2466%\n",
      "total_backward_count 806400 real_backward_count 167182  20.732%\n",
      "layer   1  Sparsity: 74.2432%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 56.2500%\n",
      "fc layer 3 self.abs_max_out: 765.0\n",
      "lif layer 1 self.abs_max_v: 3876.0\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 1 self.abs_max_out: 2441.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-25  lr=['1.0000000'], tr/val_loss:487.468994/456.982025, val:  50.00%, val_best:  67.70%, tr:  97.62%, tr_best:  97.62%, epoch time: 244.65 seconds, 4.08 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 68.3910%\n",
      "layer   3  Sparsity: 63.0613%\n",
      "total_backward_count 838656 real_backward_count 173444  20.681%\n",
      "layer   1  Sparsity: 77.8564%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 60.5625%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-26  lr=['1.0000000'], tr/val_loss:470.521057/391.703583, val:  51.33%, val_best:  67.70%, tr:  97.67%, tr_best:  97.67%, epoch time: 242.27 seconds, 4.04 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 68.3805%\n",
      "layer   3  Sparsity: 63.2867%\n",
      "total_backward_count 870912 real_backward_count 179768  20.641%\n",
      "layer   1  Sparsity: 73.9990%\n",
      "layer   2  Sparsity: 63.7500%\n",
      "layer   3  Sparsity: 60.8125%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['1.0000000'], tr/val_loss:464.476196/455.119659, val:  50.00%, val_best:  67.70%, tr:  96.88%, tr_best:  97.67%, epoch time: 248.01 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6669%\n",
      "layer   2  Sparsity: 68.2246%\n",
      "layer   3  Sparsity: 63.4012%\n",
      "total_backward_count 903168 real_backward_count 186129  20.608%\n",
      "layer   1  Sparsity: 81.9824%\n",
      "layer   2  Sparsity: 66.1875%\n",
      "layer   3  Sparsity: 61.5000%\n",
      "fc layer 3 self.abs_max_out: 775.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4356.00 at epoch 28, iter 4031\n",
      "fc layer 3 self.abs_max_out: 782.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['1.0000000'], tr/val_loss:500.825684/488.416229, val:  50.00%, val_best:  67.70%, tr:  97.05%, tr_best:  97.67%, epoch time: 248.10 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 68.1820%\n",
      "layer   3  Sparsity: 63.4585%\n",
      "total_backward_count 935424 real_backward_count 192529  20.582%\n",
      "layer   1  Sparsity: 82.2998%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 61.1250%\n",
      "fc layer 3 self.abs_max_out: 793.0\n",
      "fc layer 3 self.abs_max_out: 827.0\n",
      "fc layer 3 self.abs_max_out: 833.0\n",
      "fc layer 1 self.abs_max_out: 2503.0\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['1.0000000'], tr/val_loss:505.712433/462.261780, val:  50.00%, val_best:  67.70%, tr:  97.47%, tr_best:  97.67%, epoch time: 248.71 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 68.1326%\n",
      "layer   3  Sparsity: 63.5305%\n",
      "total_backward_count 967680 real_backward_count 198795  20.543%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 74.8125%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['1.0000000'], tr/val_loss:500.835419/480.218079, val:  50.00%, val_best:  67.70%, tr:  97.64%, tr_best:  97.67%, epoch time: 249.34 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 68.3102%\n",
      "layer   3  Sparsity: 63.3712%\n",
      "total_backward_count 999936 real_backward_count 205160  20.517%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 58.5625%\n",
      "layer   3  Sparsity: 54.5000%\n",
      "lif layer 1 self.abs_max_v: 4017.5\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 387 occurrences\n",
      "test - Value 1: 65 occurrences\n",
      "epoch-31  lr=['1.0000000'], tr/val_loss:497.126099/427.619171, val:  61.28%, val_best:  67.70%, tr:  97.32%, tr_best:  97.67%, epoch time: 248.56 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 68.4217%\n",
      "layer   3  Sparsity: 63.2793%\n",
      "total_backward_count 1032192 real_backward_count 211542  20.494%\n",
      "layer   1  Sparsity: 76.0986%\n",
      "layer   2  Sparsity: 62.4375%\n",
      "layer   3  Sparsity: 55.1875%\n",
      "fc layer 1 self.abs_max_out: 2527.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-32  lr=['1.0000000'], tr/val_loss:494.292145/461.787231, val:  50.00%, val_best:  67.70%, tr:  97.50%, tr_best:  97.67%, epoch time: 249.17 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6664%\n",
      "layer   2  Sparsity: 68.4031%\n",
      "layer   3  Sparsity: 63.5387%\n",
      "total_backward_count 1064448 real_backward_count 217873  20.468%\n",
      "layer   1  Sparsity: 91.4795%\n",
      "layer   2  Sparsity: 71.1875%\n",
      "layer   3  Sparsity: 67.5625%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['1.0000000'], tr/val_loss:494.047821/443.873047, val:  50.00%, val_best:  67.70%, tr:  97.50%, tr_best:  97.67%, epoch time: 249.79 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6630%\n",
      "layer   2  Sparsity: 68.1920%\n",
      "layer   3  Sparsity: 63.4589%\n",
      "total_backward_count 1096704 real_backward_count 224274  20.450%\n",
      "layer   1  Sparsity: 76.0742%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 60.3750%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-34  lr=['1.0000000'], tr/val_loss:482.809387/410.999908, val:  67.04%, val_best:  67.70%, tr:  97.22%, tr_best:  97.67%, epoch time: 249.77 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6664%\n",
      "layer   2  Sparsity: 68.3376%\n",
      "layer   3  Sparsity: 63.4012%\n",
      "total_backward_count 1128960 real_backward_count 230694  20.434%\n",
      "layer   1  Sparsity: 88.6230%\n",
      "layer   2  Sparsity: 78.8125%\n",
      "layer   3  Sparsity: 72.6250%\n",
      "lif layer 1 self.abs_max_v: 4040.0\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['1.0000000'], tr/val_loss:458.261810/443.239624, val:  50.00%, val_best:  67.70%, tr:  96.80%, tr_best:  97.67%, epoch time: 249.06 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 68.6717%\n",
      "layer   3  Sparsity: 63.4469%\n",
      "total_backward_count 1161216 real_backward_count 237075  20.416%\n",
      "layer   1  Sparsity: 95.0195%\n",
      "layer   2  Sparsity: 83.1250%\n",
      "layer   3  Sparsity: 69.8750%\n",
      "lif layer 1 self.abs_max_v: 4068.5\n",
      "lif layer 1 self.abs_max_v: 4103.0\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['1.0000000'], tr/val_loss:458.209320/435.857361, val:  50.00%, val_best:  67.70%, tr:  97.37%, tr_best:  97.67%, epoch time: 250.10 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 68.6107%\n",
      "layer   3  Sparsity: 63.1795%\n",
      "total_backward_count 1193472 real_backward_count 243548  20.407%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 65.8125%\n",
      "layer   3  Sparsity: 61.5625%\n",
      "fc layer 1 self.abs_max_out: 2533.0\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['1.0000000'], tr/val_loss:462.914337/463.711060, val:  50.00%, val_best:  67.70%, tr:  97.27%, tr_best:  97.67%, epoch time: 248.25 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 68.3278%\n",
      "layer   3  Sparsity: 63.3077%\n",
      "total_backward_count 1225728 real_backward_count 250120  20.406%\n",
      "layer   1  Sparsity: 71.6797%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 61.6250%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 370 occurrences\n",
      "test - Value 1: 82 occurrences\n",
      "epoch-38  lr=['1.0000000'], tr/val_loss:463.436157/358.078094, val:  63.72%, val_best:  67.70%, tr:  97.12%, tr_best:  97.67%, epoch time: 248.95 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 68.2723%\n",
      "layer   3  Sparsity: 63.0799%\n",
      "total_backward_count 1257984 real_backward_count 256622  20.399%\n",
      "layer   1  Sparsity: 84.0088%\n",
      "layer   2  Sparsity: 69.3750%\n",
      "layer   3  Sparsity: 60.7500%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['1.0000000'], tr/val_loss:415.041382/412.440887, val:  50.00%, val_best:  67.70%, tr:  96.97%, tr_best:  97.67%, epoch time: 247.66 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 68.1267%\n",
      "layer   3  Sparsity: 62.9205%\n",
      "total_backward_count 1290240 real_backward_count 263283  20.406%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 62.5625%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "fc layer 1 self.abs_max_out: 2558.0\n",
      "fc layer 1 self.abs_max_out: 2663.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-40  lr=['1.0000000'], tr/val_loss:401.139954/380.669220, val:  50.00%, val_best:  67.70%, tr:  97.59%, tr_best:  97.67%, epoch time: 248.86 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 67.5871%\n",
      "layer   3  Sparsity: 63.2751%\n",
      "total_backward_count 1322496 real_backward_count 269756  20.397%\n",
      "layer   1  Sparsity: 84.2773%\n",
      "layer   2  Sparsity: 71.2500%\n",
      "layer   3  Sparsity: 66.5625%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-41  lr=['1.0000000'], tr/val_loss:393.831177/387.381409, val:  58.19%, val_best:  67.70%, tr:  96.90%, tr_best:  97.67%, epoch time: 243.12 seconds, 4.05 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 67.3108%\n",
      "layer   3  Sparsity: 63.3100%\n",
      "total_backward_count 1354752 real_backward_count 276505  20.410%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 58.8125%\n",
      "layer   3  Sparsity: 55.2500%\n",
      "fc layer 1 self.abs_max_out: 2728.0\n",
      "train - Value 0: 2088 occurrences\n",
      "train - Value 1: 1944 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['1.0000000'], tr/val_loss:396.100525/415.478699, val:  50.00%, val_best:  67.70%, tr:  96.13%, tr_best:  97.67%, epoch time: 249.39 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 67.3240%\n",
      "layer   3  Sparsity: 63.4992%\n",
      "total_backward_count 1387008 real_backward_count 283274  20.423%\n",
      "layer   1  Sparsity: 80.7861%\n",
      "layer   2  Sparsity: 67.0625%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "fc layer 2 self.abs_max_out: 2373.0\n",
      "fc layer 1 self.abs_max_out: 2832.0\n",
      "fc layer 1 self.abs_max_out: 2877.0\n",
      "train - Value 0: 2090 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-43  lr=['1.0000000'], tr/val_loss:415.570679/404.408447, val:  53.32%, val_best:  67.70%, tr:  95.59%, tr_best:  97.67%, epoch time: 249.17 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 67.6236%\n",
      "layer   3  Sparsity: 63.4475%\n",
      "total_backward_count 1419264 real_backward_count 290131  20.442%\n",
      "layer   1  Sparsity: 89.6240%\n",
      "layer   2  Sparsity: 76.3125%\n",
      "layer   3  Sparsity: 72.4375%\n",
      "fc layer 2 self.abs_max_out: 2380.0\n",
      "fc layer 1 self.abs_max_out: 2887.0\n",
      "fc layer 1 self.abs_max_out: 2942.0\n",
      "fc layer 1 self.abs_max_out: 3062.0\n",
      "fc layer 1 self.abs_max_out: 3141.0\n",
      "fc layer 1 self.abs_max_out: 3257.0\n",
      "train - Value 0: 2108 occurrences\n",
      "train - Value 1: 1924 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['1.0000000'], tr/val_loss:383.144653/389.858032, val:  50.00%, val_best:  67.70%, tr:  95.78%, tr_best:  97.67%, epoch time: 250.69 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 67.5279%\n",
      "layer   3  Sparsity: 62.7333%\n",
      "total_backward_count 1451520 real_backward_count 296685  20.440%\n",
      "layer   1  Sparsity: 83.5449%\n",
      "layer   2  Sparsity: 68.1875%\n",
      "layer   3  Sparsity: 65.5000%\n",
      "fc layer 1 self.abs_max_out: 3342.0\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['1.0000000'], tr/val_loss:400.805359/392.737671, val:  50.00%, val_best:  67.70%, tr:  95.78%, tr_best:  97.67%, epoch time: 250.22 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 67.0390%\n",
      "layer   3  Sparsity: 63.9404%\n",
      "total_backward_count 1483776 real_backward_count 302915  20.415%\n",
      "layer   1  Sparsity: 94.3604%\n",
      "layer   2  Sparsity: 81.3750%\n",
      "layer   3  Sparsity: 73.7500%\n",
      "fc layer 1 self.abs_max_out: 3363.0\n",
      "fc layer 1 self.abs_max_out: 3495.0\n",
      "fc layer 1 self.abs_max_out: 3638.0\n",
      "fc layer 1 self.abs_max_out: 3751.0\n",
      "fc layer 1 self.abs_max_out: 3757.0\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-46  lr=['1.0000000'], tr/val_loss:413.322540/405.880005, val:  51.55%, val_best:  67.70%, tr:  95.49%, tr_best:  97.67%, epoch time: 250.27 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 67.1489%\n",
      "layer   3  Sparsity: 64.8709%\n",
      "total_backward_count 1516032 real_backward_count 309467  20.413%\n",
      "layer   1  Sparsity: 76.4893%\n",
      "layer   2  Sparsity: 57.7500%\n",
      "layer   3  Sparsity: 58.6250%\n",
      "fc layer 2 self.abs_max_out: 2490.0\n",
      "train - Value 0: 2104 occurrences\n",
      "train - Value 1: 1928 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['1.0000000'], tr/val_loss:427.776520/387.568298, val:  50.00%, val_best:  67.70%, tr:  95.34%, tr_best:  97.67%, epoch time: 247.72 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 66.8542%\n",
      "layer   3  Sparsity: 66.4861%\n",
      "total_backward_count 1548288 real_backward_count 315955  20.407%\n",
      "layer   1  Sparsity: 85.2783%\n",
      "layer   2  Sparsity: 71.0000%\n",
      "layer   3  Sparsity: 69.3750%\n",
      "train - Value 0: 2128 occurrences\n",
      "train - Value 1: 1904 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['1.0000000'], tr/val_loss:452.115356/513.721863, val:  50.00%, val_best:  67.70%, tr:  95.24%, tr_best:  97.67%, epoch time: 249.60 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 66.8234%\n",
      "layer   3  Sparsity: 66.3444%\n",
      "total_backward_count 1580544 real_backward_count 322447  20.401%\n",
      "layer   1  Sparsity: 90.0635%\n",
      "layer   2  Sparsity: 75.7500%\n",
      "layer   3  Sparsity: 70.9375%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-49  lr=['1.0000000'], tr/val_loss:549.569458/474.349609, val:  65.04%, val_best:  67.70%, tr:  96.43%, tr_best:  97.67%, epoch time: 251.04 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 66.7798%\n",
      "layer   3  Sparsity: 66.7837%\n",
      "total_backward_count 1612800 real_backward_count 328525  20.370%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 71.5000%\n",
      "layer   3  Sparsity: 70.1875%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['1.0000000'], tr/val_loss:553.569702/486.316071, val:  50.00%, val_best:  67.70%, tr:  96.92%, tr_best:  97.67%, epoch time: 249.69 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 66.6343%\n",
      "layer   3  Sparsity: 66.9354%\n",
      "total_backward_count 1645056 real_backward_count 334763  20.350%\n",
      "layer   1  Sparsity: 77.3926%\n",
      "layer   2  Sparsity: 66.3125%\n",
      "layer   3  Sparsity: 70.0625%\n",
      "fc layer 1 self.abs_max_out: 3844.0\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['1.0000000'], tr/val_loss:516.955872/470.262054, val:  50.00%, val_best:  67.70%, tr:  96.35%, tr_best:  97.67%, epoch time: 249.57 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6661%\n",
      "layer   2  Sparsity: 66.9847%\n",
      "layer   3  Sparsity: 67.5464%\n",
      "total_backward_count 1677312 real_backward_count 341247  20.345%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 72.1875%\n",
      "layer   3  Sparsity: 70.8750%\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-52  lr=['1.0000000'], tr/val_loss:516.973206/454.571564, val:  51.11%, val_best:  67.70%, tr:  96.68%, tr_best:  97.67%, epoch time: 250.32 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6637%\n",
      "layer   2  Sparsity: 67.4733%\n",
      "layer   3  Sparsity: 67.6663%\n",
      "total_backward_count 1709568 real_backward_count 347677  20.337%\n",
      "layer   1  Sparsity: 92.7490%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 70.6250%\n",
      "train - Value 0: 2101 occurrences\n",
      "train - Value 1: 1931 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-53  lr=['1.0000000'], tr/val_loss:527.161255/505.794403, val:  50.00%, val_best:  67.70%, tr:  96.50%, tr_best:  97.67%, epoch time: 249.78 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 67.3019%\n",
      "layer   3  Sparsity: 67.3930%\n",
      "total_backward_count 1741824 real_backward_count 354151  20.332%\n",
      "layer   1  Sparsity: 87.5000%\n",
      "layer   2  Sparsity: 72.6875%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "fc layer 1 self.abs_max_out: 3857.0\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-54  lr=['1.0000000'], tr/val_loss:526.888916/513.879944, val:  50.00%, val_best:  67.70%, tr:  95.93%, tr_best:  97.67%, epoch time: 250.64 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 68.0168%\n",
      "layer   3  Sparsity: 67.4232%\n",
      "total_backward_count 1774080 real_backward_count 360636  20.328%\n",
      "layer   1  Sparsity: 82.2510%\n",
      "layer   2  Sparsity: 66.6250%\n",
      "layer   3  Sparsity: 65.5000%\n",
      "fc layer 1 self.abs_max_out: 3867.0\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['1.0000000'], tr/val_loss:525.554199/521.631531, val:  50.00%, val_best:  67.70%, tr:  96.23%, tr_best:  97.67%, epoch time: 249.08 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 67.7189%\n",
      "layer   3  Sparsity: 67.5533%\n",
      "total_backward_count 1806336 real_backward_count 367275  20.333%\n",
      "layer   1  Sparsity: 82.3242%\n",
      "layer   2  Sparsity: 66.1250%\n",
      "layer   3  Sparsity: 66.0000%\n",
      "fc layer 1 self.abs_max_out: 3889.0\n",
      "fc layer 1 self.abs_max_out: 3911.0\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['1.0000000'], tr/val_loss:547.846436/514.590149, val:  50.00%, val_best:  67.70%, tr:  95.86%, tr_best:  97.67%, epoch time: 248.04 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 67.9273%\n",
      "layer   3  Sparsity: 67.1320%\n",
      "total_backward_count 1838592 real_backward_count 373692  20.325%\n",
      "layer   1  Sparsity: 90.3564%\n",
      "layer   2  Sparsity: 77.4375%\n",
      "layer   3  Sparsity: 74.8125%\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-57  lr=['1.0000000'], tr/val_loss:552.767090/543.129639, val:  50.00%, val_best:  67.70%, tr:  95.59%, tr_best:  97.67%, epoch time: 247.95 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 68.0472%\n",
      "layer   3  Sparsity: 66.9262%\n",
      "total_backward_count 1870848 real_backward_count 380164  20.320%\n",
      "layer   1  Sparsity: 92.8955%\n",
      "layer   2  Sparsity: 83.8750%\n",
      "layer   3  Sparsity: 79.8750%\n",
      "fc layer 1 self.abs_max_out: 3912.0\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-58  lr=['1.0000000'], tr/val_loss:550.644165/529.924622, val:  50.00%, val_best:  67.70%, tr:  96.88%, tr_best:  97.67%, epoch time: 244.98 seconds, 4.08 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 68.0120%\n",
      "layer   3  Sparsity: 66.7677%\n",
      "total_backward_count 1903104 real_backward_count 386678  20.318%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 59.4375%\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-59  lr=['1.0000000'], tr/val_loss:582.149170/539.475403, val:  51.11%, val_best:  67.70%, tr:  95.49%, tr_best:  97.67%, epoch time: 249.20 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 67.8657%\n",
      "layer   3  Sparsity: 66.1451%\n",
      "total_backward_count 1935360 real_backward_count 393247  20.319%\n",
      "layer   1  Sparsity: 84.2773%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 69.0625%\n",
      "fc layer 1 self.abs_max_out: 3931.0\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-60  lr=['1.0000000'], tr/val_loss:589.317932/504.904968, val:  71.24%, val_best:  71.24%, tr:  96.23%, tr_best:  97.67%, epoch time: 250.97 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 68.0068%\n",
      "layer   3  Sparsity: 65.6008%\n",
      "total_backward_count 1967616 real_backward_count 399755  20.317%\n",
      "layer   1  Sparsity: 75.9766%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 58.6250%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4550.00 at epoch 61, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['1.0000000'], tr/val_loss:613.084900/590.941101, val:  50.00%, val_best:  71.24%, tr:  96.11%, tr_best:  97.67%, epoch time: 250.60 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 68.3182%\n",
      "layer   3  Sparsity: 65.1517%\n",
      "total_backward_count 1999872 real_backward_count 406303  20.316%\n",
      "layer   1  Sparsity: 79.2969%\n",
      "layer   2  Sparsity: 66.6250%\n",
      "layer   3  Sparsity: 63.2500%\n",
      "fc layer 3 self.abs_max_out: 853.0\n",
      "fc layer 1 self.abs_max_out: 3932.0\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-62  lr=['1.0000000'], tr/val_loss:634.229370/602.260620, val:  50.22%, val_best:  71.24%, tr:  95.93%, tr_best:  97.67%, epoch time: 251.29 seconds, 4.19 minutes\n",
      "layer   1  Sparsity: 82.6657%\n",
      "layer   2  Sparsity: 68.1642%\n",
      "layer   3  Sparsity: 65.2153%\n",
      "total_backward_count 2032128 real_backward_count 412786  20.313%\n",
      "layer   1  Sparsity: 81.5674%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 62.7500%\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-63  lr=['1.0000000'], tr/val_loss:632.686707/586.550720, val:  50.00%, val_best:  71.24%, tr:  95.73%, tr_best:  97.67%, epoch time: 248.77 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6652%\n",
      "layer   2  Sparsity: 68.1642%\n",
      "layer   3  Sparsity: 64.8822%\n",
      "total_backward_count 2064384 real_backward_count 419367  20.314%\n",
      "layer   1  Sparsity: 80.0049%\n",
      "layer   2  Sparsity: 65.9375%\n",
      "layer   3  Sparsity: 62.1875%\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-64  lr=['1.0000000'], tr/val_loss:629.504028/571.260925, val:  50.22%, val_best:  71.24%, tr:  95.63%, tr_best:  97.67%, epoch time: 249.64 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 68.2590%\n",
      "layer   3  Sparsity: 64.6839%\n",
      "total_backward_count 2096640 real_backward_count 425917  20.314%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 70.5625%\n",
      "layer   3  Sparsity: 67.6250%\n",
      "fc layer 2 self.abs_max_out: 2593.0\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-65  lr=['1.0000000'], tr/val_loss:610.402222/562.511963, val:  50.00%, val_best:  71.24%, tr:  96.06%, tr_best:  97.67%, epoch time: 245.55 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 67.9727%\n",
      "layer   3  Sparsity: 64.4332%\n",
      "total_backward_count 2128896 real_backward_count 432529  20.317%\n",
      "layer   1  Sparsity: 90.0635%\n",
      "layer   2  Sparsity: 75.5000%\n",
      "layer   3  Sparsity: 67.8125%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4577.00 at epoch 66, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-66  lr=['1.0000000'], tr/val_loss:586.076050/579.893738, val:  50.00%, val_best:  71.24%, tr:  96.70%, tr_best:  97.67%, epoch time: 246.53 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 67.7669%\n",
      "layer   3  Sparsity: 64.3972%\n",
      "total_backward_count 2161152 real_backward_count 439152  20.320%\n",
      "layer   1  Sparsity: 79.6875%\n",
      "layer   2  Sparsity: 64.0625%\n",
      "layer   3  Sparsity: 61.8125%\n",
      "fc layer 2 self.abs_max_out: 2802.0\n",
      "fc layer 2 self.abs_max_out: 2886.0\n",
      "fc layer 3 self.abs_max_out: 860.0\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-67  lr=['1.0000000'], tr/val_loss:598.989624/518.566223, val:  51.99%, val_best:  71.24%, tr:  96.38%, tr_best:  97.67%, epoch time: 246.89 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 67.9942%\n",
      "layer   3  Sparsity: 64.2580%\n",
      "total_backward_count 2193408 real_backward_count 445700  20.320%\n",
      "layer   1  Sparsity: 84.0088%\n",
      "layer   2  Sparsity: 67.8750%\n",
      "layer   3  Sparsity: 62.2500%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['1.0000000'], tr/val_loss:584.458740/540.996277, val:  50.00%, val_best:  71.24%, tr:  96.78%, tr_best:  97.67%, epoch time: 246.53 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 68.1927%\n",
      "layer   3  Sparsity: 64.1209%\n",
      "total_backward_count 2225664 real_backward_count 452401  20.327%\n",
      "layer   1  Sparsity: 90.7715%\n",
      "layer   2  Sparsity: 77.7500%\n",
      "layer   3  Sparsity: 73.4375%\n",
      "fc layer 1 self.abs_max_out: 3933.0\n",
      "fc layer 3 self.abs_max_out: 870.0\n",
      "train - Value 0: 2060 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4583.00 at epoch 69, iter 4031\n",
      "max_activation_accul updated: 4587.00 at epoch 69, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-69  lr=['1.0000000'], tr/val_loss:582.721436/573.879028, val:  50.00%, val_best:  71.24%, tr:  96.78%, tr_best:  97.67%, epoch time: 247.67 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 68.1179%\n",
      "layer   3  Sparsity: 64.1076%\n",
      "total_backward_count 2257920 real_backward_count 459103  20.333%\n",
      "layer   1  Sparsity: 78.4668%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 56.5000%\n",
      "fc layer 1 self.abs_max_out: 3934.0\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-70  lr=['1.0000000'], tr/val_loss:577.607849/529.659973, val:  51.11%, val_best:  71.24%, tr:  96.63%, tr_best:  97.67%, epoch time: 244.94 seconds, 4.08 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 68.3383%\n",
      "layer   3  Sparsity: 63.9006%\n",
      "total_backward_count 2290176 real_backward_count 465746  20.337%\n",
      "layer   1  Sparsity: 74.6094%\n",
      "layer   2  Sparsity: 65.5625%\n",
      "layer   3  Sparsity: 61.2500%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4659.00 at epoch 71, iter 4031\n",
      "max_activation_accul updated: 4684.00 at epoch 71, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-71  lr=['1.0000000'], tr/val_loss:582.833496/570.149231, val:  50.44%, val_best:  71.24%, tr:  96.60%, tr_best:  97.67%, epoch time: 247.87 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 68.0199%\n",
      "layer   3  Sparsity: 63.9659%\n",
      "total_backward_count 2322432 real_backward_count 472450  20.343%\n",
      "layer   1  Sparsity: 80.7861%\n",
      "layer   2  Sparsity: 66.8125%\n",
      "layer   3  Sparsity: 61.7500%\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 5026.00 at epoch 72, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['1.0000000'], tr/val_loss:596.897034/591.465759, val:  50.00%, val_best:  71.24%, tr:  96.45%, tr_best:  97.67%, epoch time: 244.25 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 67.6583%\n",
      "layer   3  Sparsity: 64.0794%\n",
      "total_backward_count 2354688 real_backward_count 479037  20.344%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 65.8125%\n",
      "layer   3  Sparsity: 62.0000%\n",
      "fc layer 3 self.abs_max_out: 878.0\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-73  lr=['1.0000000'], tr/val_loss:585.332397/513.601807, val:  60.40%, val_best:  71.24%, tr:  96.68%, tr_best:  97.67%, epoch time: 245.58 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 67.7210%\n",
      "layer   3  Sparsity: 63.6102%\n",
      "total_backward_count 2386944 real_backward_count 485690  20.348%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 77.3750%\n",
      "layer   3  Sparsity: 72.1875%\n",
      "lif layer 1 self.abs_max_v: 4123.5\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-74  lr=['1.0000000'], tr/val_loss:578.901245/573.943909, val:  50.00%, val_best:  71.24%, tr:  97.02%, tr_best:  97.67%, epoch time: 240.87 seconds, 4.01 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 67.9377%\n",
      "layer   3  Sparsity: 63.3969%\n",
      "total_backward_count 2419200 real_backward_count 492254  20.348%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 77.2500%\n",
      "layer   3  Sparsity: 72.1875%\n",
      "fc layer 1 self.abs_max_out: 3935.0\n",
      "lif layer 1 self.abs_max_v: 4140.0\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 326 occurrences\n",
      "test - Value 1: 126 occurrences\n",
      "epoch-75  lr=['1.0000000'], tr/val_loss:581.781677/504.304840, val:  69.47%, val_best:  71.24%, tr:  96.95%, tr_best:  97.67%, epoch time: 245.69 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 68.0191%\n",
      "layer   3  Sparsity: 63.4284%\n",
      "total_backward_count 2451456 real_backward_count 498794  20.347%\n",
      "layer   1  Sparsity: 88.3301%\n",
      "layer   2  Sparsity: 74.5625%\n",
      "layer   3  Sparsity: 67.0000%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-76  lr=['1.0000000'], tr/val_loss:582.537354/517.323730, val:  52.43%, val_best:  71.24%, tr:  96.70%, tr_best:  97.67%, epoch time: 247.57 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6637%\n",
      "layer   2  Sparsity: 68.0168%\n",
      "layer   3  Sparsity: 63.4157%\n",
      "total_backward_count 2483712 real_backward_count 505447  20.350%\n",
      "layer   1  Sparsity: 78.9062%\n",
      "layer   2  Sparsity: 60.1250%\n",
      "layer   3  Sparsity: 55.3125%\n",
      "lif layer 1 self.abs_max_v: 4167.5\n",
      "lif layer 1 self.abs_max_v: 4307.0\n",
      "lif layer 1 self.abs_max_v: 4447.0\n",
      "lif layer 1 self.abs_max_v: 4573.5\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-77  lr=['1.0000000'], tr/val_loss:588.527222/512.997742, val:  51.77%, val_best:  71.24%, tr:  96.38%, tr_best:  97.67%, epoch time: 246.99 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6658%\n",
      "layer   2  Sparsity: 68.3607%\n",
      "layer   3  Sparsity: 63.4134%\n",
      "total_backward_count 2515968 real_backward_count 512121  20.355%\n",
      "layer   1  Sparsity: 79.7363%\n",
      "layer   2  Sparsity: 68.2500%\n",
      "layer   3  Sparsity: 61.5625%\n",
      "fc layer 3 self.abs_max_out: 906.0\n",
      "fc layer 3 self.abs_max_out: 907.0\n",
      "lif layer 1 self.abs_max_v: 4592.5\n",
      "train - Value 0: 2073 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['1.0000000'], tr/val_loss:599.372498/616.103210, val:  50.00%, val_best:  71.24%, tr:  96.35%, tr_best:  97.67%, epoch time: 248.41 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 68.3401%\n",
      "layer   3  Sparsity: 63.2888%\n",
      "total_backward_count 2548224 real_backward_count 518792  20.359%\n",
      "layer   1  Sparsity: 87.4512%\n",
      "layer   2  Sparsity: 65.8125%\n",
      "layer   3  Sparsity: 61.2500%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['1.0000000'], tr/val_loss:602.300537/570.342896, val:  50.00%, val_best:  71.24%, tr:  96.97%, tr_best:  97.67%, epoch time: 246.36 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 68.5196%\n",
      "layer   3  Sparsity: 63.1555%\n",
      "total_backward_count 2580480 real_backward_count 525260  20.355%\n",
      "layer   1  Sparsity: 86.2061%\n",
      "layer   2  Sparsity: 71.2500%\n",
      "layer   3  Sparsity: 66.3125%\n",
      "fc layer 1 self.abs_max_out: 3937.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "lif layer 1 self.abs_max_v: 4619.5\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['1.0000000'], tr/val_loss:628.256104/558.350037, val:  50.00%, val_best:  71.24%, tr:  97.84%, tr_best:  97.84%, epoch time: 245.65 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 68.8764%\n",
      "layer   3  Sparsity: 63.0540%\n",
      "total_backward_count 2612736 real_backward_count 531471  20.342%\n",
      "layer   1  Sparsity: 89.7949%\n",
      "layer   2  Sparsity: 77.8750%\n",
      "layer   3  Sparsity: 72.1875%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-81  lr=['1.0000000'], tr/val_loss:603.650940/522.664795, val:  50.22%, val_best:  71.24%, tr:  96.58%, tr_best:  97.84%, epoch time: 243.93 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 68.7322%\n",
      "layer   3  Sparsity: 62.7980%\n",
      "total_backward_count 2644992 real_backward_count 537708  20.329%\n",
      "layer   1  Sparsity: 82.0801%\n",
      "layer   2  Sparsity: 61.2500%\n",
      "layer   3  Sparsity: 54.4375%\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['1.0000000'], tr/val_loss:568.545105/570.272644, val:  50.00%, val_best:  71.24%, tr:  96.13%, tr_best:  97.84%, epoch time: 243.49 seconds, 4.06 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 68.7049%\n",
      "layer   3  Sparsity: 62.6756%\n",
      "total_backward_count 2677248 real_backward_count 544249  20.329%\n",
      "layer   1  Sparsity: 80.0049%\n",
      "layer   2  Sparsity: 59.3125%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-83  lr=['1.0000000'], tr/val_loss:577.017883/531.328979, val:  50.22%, val_best:  71.24%, tr:  97.10%, tr_best:  97.84%, epoch time: 246.62 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 68.9499%\n",
      "layer   3  Sparsity: 62.7953%\n",
      "total_backward_count 2709504 real_backward_count 550722  20.326%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 58.9375%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 47 occurrences\n",
      "test - Value 1: 405 occurrences\n",
      "epoch-84  lr=['1.0000000'], tr/val_loss:586.671326/520.965698, val:  58.63%, val_best:  71.24%, tr:  96.73%, tr_best:  97.84%, epoch time: 245.78 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6666%\n",
      "layer   2  Sparsity: 68.7353%\n",
      "layer   3  Sparsity: 63.1811%\n",
      "total_backward_count 2741760 real_backward_count 557276  20.325%\n",
      "layer   1  Sparsity: 74.8779%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 60.8125%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-85  lr=['1.0000000'], tr/val_loss:569.598511/507.958832, val:  51.55%, val_best:  71.24%, tr:  97.17%, tr_best:  97.84%, epoch time: 246.23 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 68.7629%\n",
      "layer   3  Sparsity: 62.8783%\n",
      "total_backward_count 2774016 real_backward_count 563850  20.326%\n",
      "layer   1  Sparsity: 74.8047%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 60.5625%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-86  lr=['1.0000000'], tr/val_loss:567.728638/518.139099, val:  50.22%, val_best:  71.24%, tr:  96.63%, tr_best:  97.84%, epoch time: 243.80 seconds, 4.06 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 68.8010%\n",
      "layer   3  Sparsity: 63.2838%\n",
      "total_backward_count 2806272 real_backward_count 570362  20.325%\n",
      "layer   1  Sparsity: 82.7393%\n",
      "layer   2  Sparsity: 67.1250%\n",
      "layer   3  Sparsity: 61.3750%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-87  lr=['1.0000000'], tr/val_loss:554.966553/517.637390, val:  51.99%, val_best:  71.24%, tr:  96.58%, tr_best:  97.84%, epoch time: 243.87 seconds, 4.06 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 68.5728%\n",
      "layer   3  Sparsity: 63.2714%\n",
      "total_backward_count 2838528 real_backward_count 577010  20.328%\n",
      "layer   1  Sparsity: 80.7373%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 66.1875%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['1.0000000'], tr/val_loss:568.490234/530.835510, val:  50.00%, val_best:  71.24%, tr:  97.27%, tr_best:  97.84%, epoch time: 245.90 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 68.6545%\n",
      "layer   3  Sparsity: 63.3261%\n",
      "total_backward_count 2870784 real_backward_count 583465  20.324%\n",
      "layer   1  Sparsity: 92.7246%\n",
      "layer   2  Sparsity: 77.6250%\n",
      "layer   3  Sparsity: 72.3125%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-89  lr=['1.0000000'], tr/val_loss:562.844543/536.090332, val:  50.88%, val_best:  71.24%, tr:  97.57%, tr_best:  97.84%, epoch time: 244.42 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 68.5859%\n",
      "layer   3  Sparsity: 63.2490%\n",
      "total_backward_count 2903040 real_backward_count 589942  20.322%\n",
      "layer   1  Sparsity: 85.4004%\n",
      "layer   2  Sparsity: 73.0625%\n",
      "layer   3  Sparsity: 62.1250%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-90  lr=['1.0000000'], tr/val_loss:590.226990/580.815430, val:  50.44%, val_best:  71.24%, tr:  96.65%, tr_best:  97.84%, epoch time: 239.04 seconds, 3.98 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 68.7950%\n",
      "layer   3  Sparsity: 62.9661%\n",
      "total_backward_count 2935296 real_backward_count 596506  20.322%\n",
      "layer   1  Sparsity: 83.4229%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 61.3125%\n",
      "fc layer 2 self.abs_max_out: 3068.0\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 83 occurrences\n",
      "test - Value 1: 369 occurrences\n",
      "epoch-91  lr=['1.0000000'], tr/val_loss:589.106812/510.255890, val:  66.15%, val_best:  71.24%, tr:  96.95%, tr_best:  97.84%, epoch time: 243.20 seconds, 4.05 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 68.6059%\n",
      "layer   3  Sparsity: 63.1675%\n",
      "total_backward_count 2967552 real_backward_count 602950  20.318%\n",
      "layer   1  Sparsity: 82.1777%\n",
      "layer   2  Sparsity: 66.5625%\n",
      "layer   3  Sparsity: 61.3750%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 5460.00 at epoch 92, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['1.0000000'], tr/val_loss:582.978821/646.959351, val:  50.00%, val_best:  71.24%, tr:  97.02%, tr_best:  97.84%, epoch time: 242.28 seconds, 4.04 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 68.4668%\n",
      "layer   3  Sparsity: 63.3516%\n",
      "total_backward_count 2999808 real_backward_count 609523  20.319%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 61.0000%\n",
      "fc layer 1 self.abs_max_out: 3938.0\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-93  lr=['1.0000000'], tr/val_loss:582.111877/503.167877, val:  64.16%, val_best:  71.24%, tr:  97.35%, tr_best:  97.84%, epoch time: 245.20 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 68.5924%\n",
      "layer   3  Sparsity: 63.2706%\n",
      "total_backward_count 3032064 real_backward_count 616066  20.318%\n",
      "layer   1  Sparsity: 79.3701%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 55.4375%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-94  lr=['1.0000000'], tr/val_loss:578.713562/541.423828, val:  50.22%, val_best:  71.24%, tr:  97.20%, tr_best:  97.84%, epoch time: 244.88 seconds, 4.08 minutes\n",
      "layer   1  Sparsity: 82.6657%\n",
      "layer   2  Sparsity: 68.2453%\n",
      "layer   3  Sparsity: 63.1116%\n",
      "total_backward_count 3064320 real_backward_count 622535  20.316%\n",
      "layer   1  Sparsity: 69.2383%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 55.6250%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-95  lr=['1.0000000'], tr/val_loss:589.012268/531.934570, val:  51.33%, val_best:  71.24%, tr:  96.73%, tr_best:  97.84%, epoch time: 246.17 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6680%\n",
      "layer   2  Sparsity: 68.1685%\n",
      "layer   3  Sparsity: 63.1380%\n",
      "total_backward_count 3096576 real_backward_count 629112  20.316%\n",
      "layer   1  Sparsity: 90.9180%\n",
      "layer   2  Sparsity: 76.5000%\n",
      "layer   3  Sparsity: 72.1875%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['1.0000000'], tr/val_loss:567.402710/555.148926, val:  50.00%, val_best:  71.24%, tr:  97.15%, tr_best:  97.84%, epoch time: 245.06 seconds, 4.08 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 67.9204%\n",
      "layer   3  Sparsity: 63.0367%\n",
      "total_backward_count 3128832 real_backward_count 635650  20.316%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 55.5625%\n",
      "layer   3  Sparsity: 55.2500%\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-97  lr=['1.0000000'], tr/val_loss:569.544983/544.120667, val:  50.22%, val_best:  71.24%, tr:  96.40%, tr_best:  97.84%, epoch time: 245.49 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 68.2452%\n",
      "layer   3  Sparsity: 62.9975%\n",
      "total_backward_count 3161088 real_backward_count 642281  20.318%\n",
      "layer   1  Sparsity: 82.8857%\n",
      "layer   2  Sparsity: 57.6875%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 396 occurrences\n",
      "test - Value 1: 56 occurrences\n",
      "epoch-98  lr=['1.0000000'], tr/val_loss:578.718994/498.958771, val:  61.95%, val_best:  71.24%, tr:  97.00%, tr_best:  97.84%, epoch time: 245.64 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 68.3150%\n",
      "layer   3  Sparsity: 63.4998%\n",
      "total_backward_count 3193344 real_backward_count 648720  20.315%\n",
      "layer   1  Sparsity: 81.2256%\n",
      "layer   2  Sparsity: 63.9375%\n",
      "layer   3  Sparsity: 61.0625%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-99  lr=['1.0000000'], tr/val_loss:568.340637/510.471680, val:  53.10%, val_best:  71.24%, tr:  97.07%, tr_best:  97.84%, epoch time: 247.52 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 68.1119%\n",
      "layer   3  Sparsity: 63.1948%\n",
      "total_backward_count 3225600 real_backward_count 655164  20.311%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 66.9375%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-100 lr=['1.0000000'], tr/val_loss:583.624084/580.141846, val:  50.00%, val_best:  71.24%, tr:  96.60%, tr_best:  97.84%, epoch time: 245.46 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 68.2994%\n",
      "layer   3  Sparsity: 62.9354%\n",
      "total_backward_count 3257856 real_backward_count 661720  20.312%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 64.3125%\n",
      "layer   3  Sparsity: 60.0000%\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-101 lr=['1.0000000'], tr/val_loss:584.774658/510.497925, val:  69.03%, val_best:  71.24%, tr:  97.05%, tr_best:  97.84%, epoch time: 245.77 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6679%\n",
      "layer   2  Sparsity: 68.4730%\n",
      "layer   3  Sparsity: 62.9898%\n",
      "total_backward_count 3290112 real_backward_count 668251  20.311%\n",
      "layer   1  Sparsity: 86.0840%\n",
      "layer   2  Sparsity: 77.8750%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "fc layer 3 self.abs_max_out: 951.0\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-102 lr=['1.0000000'], tr/val_loss:593.862549/541.145386, val:  56.19%, val_best:  71.24%, tr:  96.80%, tr_best:  97.84%, epoch time: 246.17 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 68.4926%\n",
      "layer   3  Sparsity: 63.3238%\n",
      "total_backward_count 3322368 real_backward_count 674813  20.311%\n",
      "layer   1  Sparsity: 71.6309%\n",
      "layer   2  Sparsity: 57.3125%\n",
      "layer   3  Sparsity: 55.8125%\n",
      "train - Value 0: 2073 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-103 lr=['1.0000000'], tr/val_loss:603.369202/556.711487, val:  70.58%, val_best:  71.24%, tr:  97.25%, tr_best:  97.84%, epoch time: 244.34 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 68.3895%\n",
      "layer   3  Sparsity: 63.2785%\n",
      "total_backward_count 3354624 real_backward_count 681258  20.308%\n",
      "layer   1  Sparsity: 80.1270%\n",
      "layer   2  Sparsity: 69.5000%\n",
      "layer   3  Sparsity: 66.6250%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['1.0000000'], tr/val_loss:604.829041/602.820312, val:  50.00%, val_best:  71.24%, tr:  96.80%, tr_best:  97.84%, epoch time: 244.49 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 68.2990%\n",
      "layer   3  Sparsity: 63.5051%\n",
      "total_backward_count 3386880 real_backward_count 687810  20.308%\n",
      "layer   1  Sparsity: 77.0264%\n",
      "layer   2  Sparsity: 63.3125%\n",
      "layer   3  Sparsity: 56.2500%\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-105 lr=['1.0000000'], tr/val_loss:601.795532/563.904541, val:  50.22%, val_best:  71.24%, tr:  96.63%, tr_best:  97.84%, epoch time: 247.00 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 68.1933%\n",
      "layer   3  Sparsity: 63.5469%\n",
      "total_backward_count 3419136 real_backward_count 694384  20.309%\n",
      "layer   1  Sparsity: 85.7666%\n",
      "layer   2  Sparsity: 77.2500%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['1.0000000'], tr/val_loss:596.584351/513.461853, val:  50.00%, val_best:  71.24%, tr:  96.75%, tr_best:  97.84%, epoch time: 247.10 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 67.8782%\n",
      "layer   3  Sparsity: 63.4206%\n",
      "total_backward_count 3451392 real_backward_count 701004  20.311%\n",
      "layer   1  Sparsity: 91.3574%\n",
      "layer   2  Sparsity: 78.0000%\n",
      "layer   3  Sparsity: 72.3125%\n",
      "fc layer 3 self.abs_max_out: 964.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-107 lr=['1.0000000'], tr/val_loss:608.364563/555.660400, val:  51.77%, val_best:  71.24%, tr:  97.35%, tr_best:  97.84%, epoch time: 247.09 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6630%\n",
      "layer   2  Sparsity: 67.9617%\n",
      "layer   3  Sparsity: 63.3330%\n",
      "total_backward_count 3483648 real_backward_count 707330  20.304%\n",
      "layer   1  Sparsity: 87.0850%\n",
      "layer   2  Sparsity: 76.1875%\n",
      "layer   3  Sparsity: 72.4375%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-108 lr=['1.0000000'], tr/val_loss:602.846130/543.066467, val:  52.65%, val_best:  71.24%, tr:  97.05%, tr_best:  97.84%, epoch time: 248.53 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 68.2755%\n",
      "layer   3  Sparsity: 63.3016%\n",
      "total_backward_count 3515904 real_backward_count 713756  20.301%\n",
      "layer   1  Sparsity: 86.3525%\n",
      "layer   2  Sparsity: 72.0000%\n",
      "layer   3  Sparsity: 67.1250%\n",
      "train - Value 0: 2099 occurrences\n",
      "train - Value 1: 1933 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-109 lr=['1.0000000'], tr/val_loss:603.223633/525.004089, val:  65.71%, val_best:  71.24%, tr:  96.30%, tr_best:  97.84%, epoch time: 247.79 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 68.6002%\n",
      "layer   3  Sparsity: 63.2017%\n",
      "total_backward_count 3548160 real_backward_count 720266  20.300%\n",
      "layer   1  Sparsity: 89.0869%\n",
      "layer   2  Sparsity: 71.0625%\n",
      "layer   3  Sparsity: 66.8125%\n",
      "lif layer 1 self.abs_max_v: 4735.0\n",
      "lif layer 1 self.abs_max_v: 4902.5\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-110 lr=['1.0000000'], tr/val_loss:603.888123/622.293945, val:  50.00%, val_best:  71.24%, tr:  96.65%, tr_best:  97.84%, epoch time: 247.17 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 68.5286%\n",
      "layer   3  Sparsity: 63.2385%\n",
      "total_backward_count 3580416 real_backward_count 726729  20.297%\n",
      "layer   1  Sparsity: 81.3232%\n",
      "layer   2  Sparsity: 66.4375%\n",
      "layer   3  Sparsity: 61.5625%\n",
      "train - Value 0: 2056 occurrences\n",
      "train - Value 1: 1976 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-111 lr=['1.0000000'], tr/val_loss:602.249268/525.121521, val:  59.51%, val_best:  71.24%, tr:  96.88%, tr_best:  97.84%, epoch time: 248.84 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 68.6816%\n",
      "layer   3  Sparsity: 63.2161%\n",
      "total_backward_count 3612672 real_backward_count 733154  20.294%\n",
      "layer   1  Sparsity: 80.8594%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 60.0625%\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-112 lr=['1.0000000'], tr/val_loss:607.580750/572.312012, val:  59.96%, val_best:  71.24%, tr:  95.63%, tr_best:  97.84%, epoch time: 249.34 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 68.7766%\n",
      "layer   3  Sparsity: 63.3647%\n",
      "total_backward_count 3644928 real_backward_count 739727  20.295%\n",
      "layer   1  Sparsity: 85.9131%\n",
      "layer   2  Sparsity: 71.1250%\n",
      "layer   3  Sparsity: 66.8750%\n",
      "lif layer 1 self.abs_max_v: 4934.5\n",
      "lif layer 1 self.abs_max_v: 5179.0\n",
      "lif layer 1 self.abs_max_v: 5402.5\n",
      "lif layer 1 self.abs_max_v: 5658.0\n",
      "lif layer 1 self.abs_max_v: 5678.0\n",
      "lif layer 1 self.abs_max_v: 5862.0\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 5631.00 at epoch 113, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-113 lr=['1.0000000'], tr/val_loss:615.291382/646.930359, val:  50.00%, val_best:  71.24%, tr:  96.30%, tr_best:  97.84%, epoch time: 246.54 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 69.0175%\n",
      "layer   3  Sparsity: 63.6419%\n",
      "total_backward_count 3677184 real_backward_count 746263  20.294%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 62.1250%\n",
      "layer   3  Sparsity: 56.3125%\n",
      "fc layer 2 self.abs_max_out: 3354.0\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['1.0000000'], tr/val_loss:612.276917/595.247131, val:  50.00%, val_best:  71.24%, tr:  96.73%, tr_best:  97.84%, epoch time: 247.62 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 68.8305%\n",
      "layer   3  Sparsity: 63.8274%\n",
      "total_backward_count 3709440 real_backward_count 752696  20.291%\n",
      "layer   1  Sparsity: 80.0537%\n",
      "layer   2  Sparsity: 69.3750%\n",
      "layer   3  Sparsity: 66.6875%\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-115 lr=['1.0000000'], tr/val_loss:608.676819/510.958374, val:  65.04%, val_best:  71.24%, tr:  96.03%, tr_best:  97.84%, epoch time: 248.68 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 68.7262%\n",
      "layer   3  Sparsity: 63.7181%\n",
      "total_backward_count 3741696 real_backward_count 759276  20.292%\n",
      "layer   1  Sparsity: 87.3779%\n",
      "layer   2  Sparsity: 77.0625%\n",
      "layer   3  Sparsity: 72.3750%\n",
      "train - Value 0: 2079 occurrences\n",
      "train - Value 1: 1953 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-116 lr=['1.0000000'], tr/val_loss:603.802124/562.401306, val:  52.21%, val_best:  71.24%, tr:  96.60%, tr_best:  97.84%, epoch time: 247.78 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 68.7241%\n",
      "layer   3  Sparsity: 63.5696%\n",
      "total_backward_count 3773952 real_backward_count 765690  20.289%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 64.4375%\n",
      "layer   3  Sparsity: 62.2500%\n",
      "train - Value 0: 2093 occurrences\n",
      "train - Value 1: 1939 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-117 lr=['1.0000000'], tr/val_loss:612.556519/516.740112, val:  61.06%, val_best:  71.24%, tr:  96.60%, tr_best:  97.84%, epoch time: 247.65 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 68.6775%\n",
      "layer   3  Sparsity: 63.7199%\n",
      "total_backward_count 3806208 real_backward_count 772241  20.289%\n",
      "layer   1  Sparsity: 87.9639%\n",
      "layer   2  Sparsity: 72.1875%\n",
      "layer   3  Sparsity: 67.0625%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['1.0000000'], tr/val_loss:602.608948/526.461060, val:  50.00%, val_best:  71.24%, tr:  96.43%, tr_best:  97.84%, epoch time: 245.85 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 68.5368%\n",
      "layer   3  Sparsity: 63.5399%\n",
      "total_backward_count 3838464 real_backward_count 778754  20.288%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 77.9375%\n",
      "layer   3  Sparsity: 67.8750%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-119 lr=['1.0000000'], tr/val_loss:595.691772/537.372314, val:  71.02%, val_best:  71.24%, tr:  96.90%, tr_best:  97.84%, epoch time: 246.59 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 68.4258%\n",
      "layer   3  Sparsity: 63.7352%\n",
      "total_backward_count 3870720 real_backward_count 785163  20.285%\n",
      "layer   1  Sparsity: 87.5977%\n",
      "layer   2  Sparsity: 71.8750%\n",
      "layer   3  Sparsity: 67.3750%\n",
      "fc layer 1 self.abs_max_out: 3939.0\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 76 occurrences\n",
      "test - Value 1: 376 occurrences\n",
      "epoch-120 lr=['1.0000000'], tr/val_loss:588.372681/482.676880, val:  63.72%, val_best:  71.24%, tr:  96.23%, tr_best:  97.84%, epoch time: 247.15 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 68.5583%\n",
      "layer   3  Sparsity: 63.7356%\n",
      "total_backward_count 3902976 real_backward_count 791734  20.285%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 65.3750%\n",
      "layer   3  Sparsity: 61.5000%\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-121 lr=['1.0000000'], tr/val_loss:588.351501/482.715698, val:  55.09%, val_best:  71.24%, tr:  96.06%, tr_best:  97.84%, epoch time: 248.09 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 68.6934%\n",
      "layer   3  Sparsity: 63.7652%\n",
      "total_backward_count 3935232 real_backward_count 798261  20.285%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 70.5625%\n",
      "layer   3  Sparsity: 66.8125%\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['1.0000000'], tr/val_loss:580.769836/605.828064, val:  50.00%, val_best:  71.24%, tr:  96.21%, tr_best:  97.84%, epoch time: 246.72 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 68.6630%\n",
      "layer   3  Sparsity: 63.5722%\n",
      "total_backward_count 3967488 real_backward_count 804770  20.284%\n",
      "layer   1  Sparsity: 88.7207%\n",
      "layer   2  Sparsity: 71.5000%\n",
      "layer   3  Sparsity: 66.9375%\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-123 lr=['1.0000000'], tr/val_loss:573.833008/524.042847, val:  67.92%, val_best:  71.24%, tr:  96.60%, tr_best:  97.84%, epoch time: 246.90 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 68.6170%\n",
      "layer   3  Sparsity: 63.5055%\n",
      "total_backward_count 3999744 real_backward_count 811245  20.282%\n",
      "layer   1  Sparsity: 83.9111%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 61.5625%\n",
      "train - Value 0: 2085 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 358 occurrences\n",
      "test - Value 1: 94 occurrences\n",
      "epoch-124 lr=['1.0000000'], tr/val_loss:560.429199/485.821503, val:  66.37%, val_best:  71.24%, tr:  96.21%, tr_best:  97.84%, epoch time: 247.33 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 68.5620%\n",
      "layer   3  Sparsity: 63.8637%\n",
      "total_backward_count 4032000 real_backward_count 817645  20.279%\n",
      "layer   1  Sparsity: 86.0840%\n",
      "layer   2  Sparsity: 77.0000%\n",
      "layer   3  Sparsity: 72.6875%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-125 lr=['1.0000000'], tr/val_loss:558.425964/518.652039, val:  50.00%, val_best:  71.24%, tr:  96.83%, tr_best:  97.84%, epoch time: 245.45 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 68.6220%\n",
      "layer   3  Sparsity: 63.6322%\n",
      "total_backward_count 4064256 real_backward_count 824119  20.277%\n",
      "layer   1  Sparsity: 73.3154%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 61.1250%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-126 lr=['1.0000000'], tr/val_loss:571.541870/531.999695, val:  50.00%, val_best:  71.24%, tr:  97.17%, tr_best:  97.84%, epoch time: 245.69 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6671%\n",
      "layer   2  Sparsity: 68.3850%\n",
      "layer   3  Sparsity: 63.5989%\n",
      "total_backward_count 4096512 real_backward_count 830526  20.274%\n",
      "layer   1  Sparsity: 77.4170%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 61.6250%\n",
      "fc layer 1 self.abs_max_out: 3988.0\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['1.0000000'], tr/val_loss:570.623840/587.464233, val:  50.00%, val_best:  71.24%, tr:  97.35%, tr_best:  97.84%, epoch time: 246.74 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6661%\n",
      "layer   2  Sparsity: 68.4548%\n",
      "layer   3  Sparsity: 63.8271%\n",
      "total_backward_count 4128768 real_backward_count 837006  20.273%\n",
      "layer   1  Sparsity: 91.1133%\n",
      "layer   2  Sparsity: 73.4375%\n",
      "layer   3  Sparsity: 67.0000%\n",
      "train - Value 0: 2074 occurrences\n",
      "train - Value 1: 1958 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-128 lr=['1.0000000'], tr/val_loss:575.438843/530.984863, val:  50.22%, val_best:  71.24%, tr:  96.53%, tr_best:  97.84%, epoch time: 246.89 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 68.6288%\n",
      "layer   3  Sparsity: 63.7864%\n",
      "total_backward_count 4161024 real_backward_count 843507  20.272%\n",
      "layer   1  Sparsity: 86.2061%\n",
      "layer   2  Sparsity: 77.0625%\n",
      "layer   3  Sparsity: 72.6875%\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-129 lr=['1.0000000'], tr/val_loss:540.974609/490.755707, val:  50.22%, val_best:  71.24%, tr:  97.15%, tr_best:  97.84%, epoch time: 247.78 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 68.4087%\n",
      "layer   3  Sparsity: 63.7231%\n",
      "total_backward_count 4193280 real_backward_count 850028  20.271%\n",
      "layer   1  Sparsity: 90.5029%\n",
      "layer   2  Sparsity: 76.6875%\n",
      "layer   3  Sparsity: 72.5625%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-130 lr=['1.0000000'], tr/val_loss:541.078247/472.437927, val:  75.66%, val_best:  75.66%, tr:  96.83%, tr_best:  97.84%, epoch time: 248.31 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 68.3499%\n",
      "layer   3  Sparsity: 63.7511%\n",
      "total_backward_count 4225536 real_backward_count 856460  20.269%\n",
      "layer   1  Sparsity: 90.0879%\n",
      "layer   2  Sparsity: 74.0000%\n",
      "layer   3  Sparsity: 67.1875%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-131 lr=['1.0000000'], tr/val_loss:551.104797/504.927216, val:  50.22%, val_best:  75.66%, tr:  96.53%, tr_best:  97.84%, epoch time: 248.24 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 68.2480%\n",
      "layer   3  Sparsity: 63.9337%\n",
      "total_backward_count 4257792 real_backward_count 862899  20.266%\n",
      "layer   1  Sparsity: 79.1260%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 62.0625%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-132 lr=['1.0000000'], tr/val_loss:543.766052/519.800537, val:  62.39%, val_best:  75.66%, tr:  97.17%, tr_best:  97.84%, epoch time: 247.78 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6658%\n",
      "layer   2  Sparsity: 68.4359%\n",
      "layer   3  Sparsity: 64.0726%\n",
      "total_backward_count 4290048 real_backward_count 869345  20.264%\n",
      "layer   1  Sparsity: 88.1104%\n",
      "layer   2  Sparsity: 71.3750%\n",
      "layer   3  Sparsity: 62.3125%\n",
      "lif layer 1 self.abs_max_v: 6287.5\n",
      "lif layer 1 self.abs_max_v: 6378.0\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 357 occurrences\n",
      "test - Value 1: 95 occurrences\n",
      "epoch-133 lr=['1.0000000'], tr/val_loss:555.355530/463.268524, val:  67.48%, val_best:  75.66%, tr:  96.63%, tr_best:  97.84%, epoch time: 248.14 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 68.3974%\n",
      "layer   3  Sparsity: 63.8997%\n",
      "total_backward_count 4322304 real_backward_count 875746  20.261%\n",
      "layer   1  Sparsity: 77.1729%\n",
      "layer   2  Sparsity: 63.1250%\n",
      "layer   3  Sparsity: 61.5000%\n",
      "train - Value 0: 2086 occurrences\n",
      "train - Value 1: 1946 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-134 lr=['1.0000000'], tr/val_loss:556.983276/506.671051, val:  50.44%, val_best:  75.66%, tr:  96.38%, tr_best:  97.84%, epoch time: 248.89 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 68.4545%\n",
      "layer   3  Sparsity: 64.0861%\n",
      "total_backward_count 4354560 real_backward_count 882095  20.257%\n",
      "layer   1  Sparsity: 82.8125%\n",
      "layer   2  Sparsity: 63.6875%\n",
      "layer   3  Sparsity: 61.4375%\n",
      "lif layer 1 self.abs_max_v: 6447.5\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-135 lr=['1.0000000'], tr/val_loss:546.196472/537.005310, val:  50.22%, val_best:  75.66%, tr:  97.02%, tr_best:  97.84%, epoch time: 246.71 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 68.4875%\n",
      "layer   3  Sparsity: 63.8361%\n",
      "total_backward_count 4386816 real_backward_count 888460  20.253%\n",
      "layer   1  Sparsity: 83.5938%\n",
      "layer   2  Sparsity: 75.4375%\n",
      "layer   3  Sparsity: 67.6250%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-136 lr=['1.0000000'], tr/val_loss:468.543488/269.314667, val:  50.00%, val_best:  75.66%, tr:  97.00%, tr_best:  97.84%, epoch time: 248.39 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 68.4876%\n",
      "layer   3  Sparsity: 64.0207%\n",
      "total_backward_count 4419072 real_backward_count 894749  20.247%\n",
      "layer   1  Sparsity: 78.1738%\n",
      "layer   2  Sparsity: 61.0625%\n",
      "layer   3  Sparsity: 57.3125%\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 355 occurrences\n",
      "test - Value 1: 97 occurrences\n",
      "epoch-137 lr=['1.0000000'], tr/val_loss:316.046570/265.294617, val:  69.25%, val_best:  75.66%, tr:  96.43%, tr_best:  97.84%, epoch time: 247.68 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 68.6381%\n",
      "layer   3  Sparsity: 63.9521%\n",
      "total_backward_count 4451328 real_backward_count 901152  20.245%\n",
      "layer   1  Sparsity: 85.0098%\n",
      "layer   2  Sparsity: 72.0000%\n",
      "layer   3  Sparsity: 67.3750%\n",
      "lif layer 1 self.abs_max_v: 6630.0\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-138 lr=['1.0000000'], tr/val_loss:327.649597/387.501068, val:  51.11%, val_best:  75.66%, tr:  96.48%, tr_best:  97.84%, epoch time: 245.26 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 68.7323%\n",
      "layer   3  Sparsity: 63.8043%\n",
      "total_backward_count 4483584 real_backward_count 907624  20.243%\n",
      "layer   1  Sparsity: 84.5459%\n",
      "layer   2  Sparsity: 71.5625%\n",
      "layer   3  Sparsity: 67.5625%\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-139 lr=['1.0000000'], tr/val_loss:311.203308/332.494385, val:  54.42%, val_best:  75.66%, tr:  96.65%, tr_best:  97.84%, epoch time: 245.70 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 68.6778%\n",
      "layer   3  Sparsity: 63.3602%\n",
      "total_backward_count 4515840 real_backward_count 914064  20.241%\n",
      "layer   1  Sparsity: 95.0195%\n",
      "layer   2  Sparsity: 82.6250%\n",
      "layer   3  Sparsity: 77.8125%\n",
      "fc layer 2 self.abs_max_out: 3602.0\n",
      "lif layer 1 self.abs_max_v: 6742.5\n",
      "lif layer 1 self.abs_max_v: 6767.5\n",
      "train - Value 0: 2123 occurrences\n",
      "train - Value 1: 1909 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 381 occurrences\n",
      "test - Value 1: 71 occurrences\n",
      "epoch-140 lr=['1.0000000'], tr/val_loss:343.938477/354.146332, val:  63.50%, val_best:  75.66%, tr:  95.71%, tr_best:  97.84%, epoch time: 245.90 seconds, 4.10 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 69.1149%\n",
      "layer   3  Sparsity: 63.3985%\n",
      "total_backward_count 4548096 real_backward_count 920575  20.241%\n",
      "layer   1  Sparsity: 80.5420%\n",
      "layer   2  Sparsity: 67.6875%\n",
      "layer   3  Sparsity: 61.3125%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-141 lr=['1.0000000'], tr/val_loss:387.508240/368.607727, val:  58.19%, val_best:  75.66%, tr:  97.17%, tr_best:  97.84%, epoch time: 243.94 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 69.1829%\n",
      "layer   3  Sparsity: 63.2883%\n",
      "total_backward_count 4580352 real_backward_count 927028  20.239%\n",
      "layer   1  Sparsity: 72.3389%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 56.0000%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-142 lr=['1.0000000'], tr/val_loss:432.082367/347.541504, val:  50.66%, val_best:  75.66%, tr:  98.12%, tr_best:  98.12%, epoch time: 246.57 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6673%\n",
      "layer   2  Sparsity: 69.1280%\n",
      "layer   3  Sparsity: 63.4022%\n",
      "total_backward_count 4612608 real_backward_count 933198  20.231%\n",
      "layer   1  Sparsity: 84.8877%\n",
      "layer   2  Sparsity: 73.3125%\n",
      "layer   3  Sparsity: 67.1250%\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-143 lr=['1.0000000'], tr/val_loss:430.157104/444.136047, val:  50.00%, val_best:  75.66%, tr:  97.27%, tr_best:  98.12%, epoch time: 247.92 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 69.0944%\n",
      "layer   3  Sparsity: 63.3255%\n",
      "total_backward_count 4644864 real_backward_count 939329  20.223%\n",
      "layer   1  Sparsity: 94.0918%\n",
      "layer   2  Sparsity: 83.9375%\n",
      "layer   3  Sparsity: 77.6250%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-144 lr=['1.0000000'], tr/val_loss:442.941406/428.933594, val:  50.00%, val_best:  75.66%, tr:  97.15%, tr_best:  98.12%, epoch time: 246.83 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 69.1094%\n",
      "layer   3  Sparsity: 63.2211%\n",
      "total_backward_count 4677120 real_backward_count 945612  20.218%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 55.8125%\n",
      "lif layer 1 self.abs_max_v: 6824.5\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-145 lr=['1.0000000'], tr/val_loss:450.484222/418.051300, val:  66.15%, val_best:  75.66%, tr:  96.92%, tr_best:  98.12%, epoch time: 247.03 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 69.2677%\n",
      "layer   3  Sparsity: 63.3267%\n",
      "total_backward_count 4709376 real_backward_count 952031  20.216%\n",
      "layer   1  Sparsity: 76.6113%\n",
      "layer   2  Sparsity: 65.6875%\n",
      "layer   3  Sparsity: 61.0625%\n",
      "lif layer 1 self.abs_max_v: 6839.5\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-146 lr=['1.0000000'], tr/val_loss:458.838531/447.263275, val:  51.33%, val_best:  75.66%, tr:  97.05%, tr_best:  98.12%, epoch time: 246.82 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 69.2933%\n",
      "layer   3  Sparsity: 63.0850%\n",
      "total_backward_count 4741632 real_backward_count 958366  20.212%\n",
      "layer   1  Sparsity: 82.8857%\n",
      "layer   2  Sparsity: 62.1875%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['1.0000000'], tr/val_loss:465.303284/444.365448, val:  50.00%, val_best:  75.66%, tr:  97.02%, tr_best:  98.12%, epoch time: 248.69 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 69.3119%\n",
      "layer   3  Sparsity: 63.1712%\n",
      "total_backward_count 4773888 real_backward_count 964690  20.208%\n",
      "layer   1  Sparsity: 86.1084%\n",
      "layer   2  Sparsity: 76.1250%\n",
      "layer   3  Sparsity: 66.6875%\n",
      "lif layer 1 self.abs_max_v: 7018.5\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['1.0000000'], tr/val_loss:471.797729/481.470734, val:  50.00%, val_best:  75.66%, tr:  96.83%, tr_best:  98.12%, epoch time: 248.67 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 69.3649%\n",
      "layer   3  Sparsity: 63.1994%\n",
      "total_backward_count 4806144 real_backward_count 970951  20.202%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 74.2500%\n",
      "layer   3  Sparsity: 66.5625%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 288 occurrences\n",
      "test - Value 1: 164 occurrences\n",
      "epoch-149 lr=['1.0000000'], tr/val_loss:454.942749/414.096466, val:  74.34%, val_best:  75.66%, tr:  97.57%, tr_best:  98.12%, epoch time: 249.55 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 69.4705%\n",
      "layer   3  Sparsity: 63.2624%\n",
      "total_backward_count 4838400 real_backward_count 977343  20.200%\n",
      "layer   1  Sparsity: 74.2432%\n",
      "layer   2  Sparsity: 65.5625%\n",
      "layer   3  Sparsity: 55.6875%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-150 lr=['1.0000000'], tr/val_loss:379.104065/273.224518, val:  69.69%, val_best:  75.66%, tr:  97.17%, tr_best:  98.12%, epoch time: 247.28 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 69.3250%\n",
      "layer   3  Sparsity: 63.1537%\n",
      "total_backward_count 4870656 real_backward_count 983764  20.198%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 55.5625%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['1.0000000'], tr/val_loss:322.407043/432.509796, val:  50.00%, val_best:  75.66%, tr:  97.17%, tr_best:  98.12%, epoch time: 247.67 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 69.3176%\n",
      "layer   3  Sparsity: 63.2081%\n",
      "total_backward_count 4902912 real_backward_count 990132  20.195%\n",
      "layer   1  Sparsity: 85.7910%\n",
      "layer   2  Sparsity: 73.4375%\n",
      "layer   3  Sparsity: 66.5625%\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-152 lr=['1.0000000'], tr/val_loss:361.088348/395.916931, val:  54.87%, val_best:  75.66%, tr:  96.28%, tr_best:  98.12%, epoch time: 248.02 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 69.4278%\n",
      "layer   3  Sparsity: 63.2977%\n",
      "total_backward_count 4935168 real_backward_count 996435  20.190%\n",
      "layer   1  Sparsity: 82.1289%\n",
      "layer   2  Sparsity: 66.2500%\n",
      "layer   3  Sparsity: 60.6875%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-153 lr=['1.0000000'], tr/val_loss:387.599060/397.310516, val:  50.22%, val_best:  75.66%, tr:  97.37%, tr_best:  98.12%, epoch time: 248.11 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 69.5283%\n",
      "layer   3  Sparsity: 63.4161%\n",
      "total_backward_count 4967424 real_backward_count 1002778  20.187%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 60.0625%\n",
      "layer   3  Sparsity: 56.4375%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-154 lr=['1.0000000'], tr/val_loss:380.878601/329.805603, val:  59.07%, val_best:  75.66%, tr:  96.73%, tr_best:  98.12%, epoch time: 248.07 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6666%\n",
      "layer   2  Sparsity: 69.5612%\n",
      "layer   3  Sparsity: 63.4131%\n",
      "total_backward_count 4999680 real_backward_count 1009112  20.184%\n",
      "layer   1  Sparsity: 83.5693%\n",
      "layer   2  Sparsity: 62.7500%\n",
      "layer   3  Sparsity: 55.5625%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 286 occurrences\n",
      "test - Value 1: 166 occurrences\n",
      "epoch-155 lr=['1.0000000'], tr/val_loss:392.928223/313.733826, val:  78.32%, val_best:  78.32%, tr:  96.88%, tr_best:  98.12%, epoch time: 247.28 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 69.7352%\n",
      "layer   3  Sparsity: 63.2798%\n",
      "total_backward_count 5031936 real_backward_count 1015468  20.180%\n",
      "layer   1  Sparsity: 89.7705%\n",
      "layer   2  Sparsity: 82.5625%\n",
      "layer   3  Sparsity: 77.5625%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 1 self.abs_max_out: 4013.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 299 occurrences\n",
      "test - Value 1: 153 occurrences\n",
      "epoch-156 lr=['1.0000000'], tr/val_loss:313.427002/258.443237, val:  78.10%, val_best:  78.32%, tr:  97.40%, tr_best:  98.12%, epoch time: 248.79 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 69.7536%\n",
      "layer   3  Sparsity: 63.1946%\n",
      "total_backward_count 5064192 real_backward_count 1021734  20.176%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 60.1250%\n",
      "layer   3  Sparsity: 54.9375%\n",
      "lif layer 1 self.abs_max_v: 7023.0\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 397 occurrences\n",
      "test - Value 1: 55 occurrences\n",
      "epoch-157 lr=['1.0000000'], tr/val_loss:319.026886/266.236145, val:  61.73%, val_best:  78.32%, tr:  97.15%, tr_best:  98.12%, epoch time: 242.61 seconds, 4.04 minutes\n",
      "layer   1  Sparsity: 82.6652%\n",
      "layer   2  Sparsity: 69.5951%\n",
      "layer   3  Sparsity: 63.3394%\n",
      "total_backward_count 5096448 real_backward_count 1028013  20.171%\n",
      "layer   1  Sparsity: 84.8389%\n",
      "layer   2  Sparsity: 74.6875%\n",
      "layer   3  Sparsity: 67.1875%\n",
      "train - Value 0: 2097 occurrences\n",
      "train - Value 1: 1935 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['1.0000000'], tr/val_loss:328.050232/303.742615, val:  50.00%, val_best:  78.32%, tr:  96.85%, tr_best:  98.12%, epoch time: 249.21 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 69.6497%\n",
      "layer   3  Sparsity: 62.9207%\n",
      "total_backward_count 5128704 real_backward_count 1034337  20.168%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 72.1875%\n",
      "layer   3  Sparsity: 66.3125%\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-159 lr=['1.0000000'], tr/val_loss:327.780518/399.678741, val:  50.00%, val_best:  78.32%, tr:  96.53%, tr_best:  98.12%, epoch time: 248.73 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 69.7400%\n",
      "layer   3  Sparsity: 62.8225%\n",
      "total_backward_count 5160960 real_backward_count 1040531  20.162%\n",
      "layer   1  Sparsity: 86.5967%\n",
      "layer   2  Sparsity: 74.6250%\n",
      "layer   3  Sparsity: 66.3125%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-160 lr=['1.0000000'], tr/val_loss:322.286682/294.937469, val:  62.83%, val_best:  78.32%, tr:  97.07%, tr_best:  98.12%, epoch time: 249.05 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 69.8266%\n",
      "layer   3  Sparsity: 62.9892%\n",
      "total_backward_count 5193216 real_backward_count 1046687  20.155%\n",
      "layer   1  Sparsity: 64.9170%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 55.6875%\n",
      "lif layer 1 self.abs_max_v: 7033.5\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['1.0000000'], tr/val_loss:316.794708/447.274811, val:  50.00%, val_best:  78.32%, tr:  96.65%, tr_best:  98.12%, epoch time: 248.09 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6689%\n",
      "layer   2  Sparsity: 69.8427%\n",
      "layer   3  Sparsity: 62.9978%\n",
      "total_backward_count 5225472 real_backward_count 1053096  20.153%\n",
      "layer   1  Sparsity: 93.9453%\n",
      "layer   2  Sparsity: 82.8125%\n",
      "layer   3  Sparsity: 74.6250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-162 lr=['1.0000000'], tr/val_loss:339.995392/266.149261, val:  50.22%, val_best:  78.32%, tr:  97.10%, tr_best:  98.12%, epoch time: 248.14 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 69.9181%\n",
      "layer   3  Sparsity: 62.7825%\n",
      "total_backward_count 5257728 real_backward_count 1059239  20.146%\n",
      "layer   1  Sparsity: 81.3721%\n",
      "layer   2  Sparsity: 62.5625%\n",
      "layer   3  Sparsity: 54.6250%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 312 occurrences\n",
      "test - Value 1: 140 occurrences\n",
      "epoch-163 lr=['1.0000000'], tr/val_loss:309.529602/254.375259, val:  73.89%, val_best:  78.32%, tr:  97.77%, tr_best:  98.12%, epoch time: 247.87 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 69.9687%\n",
      "layer   3  Sparsity: 63.1643%\n",
      "total_backward_count 5289984 real_backward_count 1065285  20.138%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 56.1875%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-164 lr=['1.0000000'], tr/val_loss:313.405457/291.875610, val:  72.57%, val_best:  78.32%, tr:  97.42%, tr_best:  98.12%, epoch time: 248.95 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 69.9458%\n",
      "layer   3  Sparsity: 63.0920%\n",
      "total_backward_count 5322240 real_backward_count 1071414  20.131%\n",
      "layer   1  Sparsity: 85.8154%\n",
      "layer   2  Sparsity: 74.1875%\n",
      "layer   3  Sparsity: 66.6250%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-165 lr=['1.0000000'], tr/val_loss:305.565918/270.375488, val:  58.85%, val_best:  78.32%, tr:  97.02%, tr_best:  98.12%, epoch time: 248.30 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 69.9377%\n",
      "layer   3  Sparsity: 63.1887%\n",
      "total_backward_count 5354496 real_backward_count 1077638  20.126%\n",
      "layer   1  Sparsity: 75.9521%\n",
      "layer   2  Sparsity: 64.1875%\n",
      "layer   3  Sparsity: 55.5625%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['1.0000000'], tr/val_loss:312.301575/369.842468, val:  50.00%, val_best:  78.32%, tr:  97.10%, tr_best:  98.12%, epoch time: 249.22 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 69.8402%\n",
      "layer   3  Sparsity: 63.0762%\n",
      "total_backward_count 5386752 real_backward_count 1083806  20.120%\n",
      "layer   1  Sparsity: 85.2295%\n",
      "layer   2  Sparsity: 73.8125%\n",
      "layer   3  Sparsity: 66.3750%\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['1.0000000'], tr/val_loss:311.042053/403.517914, val:  50.00%, val_best:  78.32%, tr:  96.63%, tr_best:  98.12%, epoch time: 244.36 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 69.9018%\n",
      "layer   3  Sparsity: 62.8821%\n",
      "total_backward_count 5419008 real_backward_count 1089821  20.111%\n",
      "layer   1  Sparsity: 83.3008%\n",
      "layer   2  Sparsity: 67.8750%\n",
      "layer   3  Sparsity: 60.6250%\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['1.0000000'], tr/val_loss:309.817474/374.521942, val:  50.00%, val_best:  78.32%, tr:  97.02%, tr_best:  98.12%, epoch time: 247.40 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 69.9635%\n",
      "layer   3  Sparsity: 62.9919%\n",
      "total_backward_count 5451264 real_backward_count 1095911  20.104%\n",
      "layer   1  Sparsity: 91.7480%\n",
      "layer   2  Sparsity: 77.4375%\n",
      "layer   3  Sparsity: 71.8125%\n",
      "train - Value 0: 2073 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 317 occurrences\n",
      "test - Value 1: 135 occurrences\n",
      "epoch-169 lr=['1.0000000'], tr/val_loss:311.117126/270.771301, val:  74.56%, val_best:  78.32%, tr:  97.05%, tr_best:  98.12%, epoch time: 247.11 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6629%\n",
      "layer   2  Sparsity: 69.9418%\n",
      "layer   3  Sparsity: 63.0949%\n",
      "total_backward_count 5483520 real_backward_count 1102057  20.098%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 67.8750%\n",
      "layer   3  Sparsity: 60.9375%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['1.0000000'], tr/val_loss:330.038452/368.516968, val:  50.00%, val_best:  78.32%, tr:  97.02%, tr_best:  98.12%, epoch time: 248.27 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 69.9062%\n",
      "layer   3  Sparsity: 63.0831%\n",
      "total_backward_count 5515776 real_backward_count 1107899  20.086%\n",
      "layer   1  Sparsity: 82.9590%\n",
      "layer   2  Sparsity: 66.3750%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-171 lr=['1.0000000'], tr/val_loss:316.480560/260.301727, val:  50.00%, val_best:  78.32%, tr:  97.12%, tr_best:  98.12%, epoch time: 247.42 seconds, 4.12 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 69.9278%\n",
      "layer   3  Sparsity: 62.9416%\n",
      "total_backward_count 5548032 real_backward_count 1113959  20.078%\n",
      "layer   1  Sparsity: 82.1045%\n",
      "layer   2  Sparsity: 71.6875%\n",
      "layer   3  Sparsity: 66.3750%\n",
      "train - Value 0: 2068 occurrences\n",
      "train - Value 1: 1964 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-172 lr=['1.0000000'], tr/val_loss:291.276031/292.278564, val:  61.06%, val_best:  78.32%, tr:  97.27%, tr_best:  98.12%, epoch time: 246.88 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 70.0836%\n",
      "layer   3  Sparsity: 62.9299%\n",
      "total_backward_count 5580288 real_backward_count 1119668  20.065%\n",
      "layer   1  Sparsity: 87.0117%\n",
      "layer   2  Sparsity: 77.9375%\n",
      "layer   3  Sparsity: 71.8750%\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-173 lr=['1.0000000'], tr/val_loss:304.051056/280.880310, val:  50.22%, val_best:  78.32%, tr:  96.88%, tr_best:  98.12%, epoch time: 245.16 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 69.9815%\n",
      "layer   3  Sparsity: 62.9253%\n",
      "total_backward_count 5612544 real_backward_count 1125814  20.059%\n",
      "layer   1  Sparsity: 95.0684%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 77.5625%\n",
      "train - Value 0: 2105 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-174 lr=['1.0000000'], tr/val_loss:311.459229/360.681946, val:  50.88%, val_best:  78.32%, tr:  97.05%, tr_best:  98.12%, epoch time: 248.67 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 69.9682%\n",
      "layer   3  Sparsity: 62.8658%\n",
      "total_backward_count 5644800 real_backward_count 1131893  20.052%\n",
      "layer   1  Sparsity: 93.3350%\n",
      "layer   2  Sparsity: 79.4375%\n",
      "layer   3  Sparsity: 73.6875%\n",
      "train - Value 0: 2161 occurrences\n",
      "train - Value 1: 1871 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-175 lr=['1.0000000'], tr/val_loss:319.070404/281.522827, val:  50.44%, val_best:  78.32%, tr:  95.26%, tr_best:  98.12%, epoch time: 247.54 seconds, 4.13 minutes\n",
      "layer   1  Sparsity: 82.6626%\n",
      "layer   2  Sparsity: 69.8279%\n",
      "layer   3  Sparsity: 62.8499%\n",
      "total_backward_count 5677056 real_backward_count 1137932  20.044%\n",
      "layer   1  Sparsity: 77.2217%\n",
      "layer   2  Sparsity: 66.7500%\n",
      "layer   3  Sparsity: 60.8125%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 277 occurrences\n",
      "test - Value 1: 175 occurrences\n",
      "epoch-176 lr=['1.0000000'], tr/val_loss:319.197021/290.987610, val:  76.33%, val_best:  78.32%, tr:  98.31%, tr_best:  98.31%, epoch time: 249.78 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 69.6781%\n",
      "layer   3  Sparsity: 63.0352%\n",
      "total_backward_count 5709312 real_backward_count 1143727  20.033%\n",
      "layer   1  Sparsity: 85.3027%\n",
      "layer   2  Sparsity: 72.1250%\n",
      "layer   3  Sparsity: 66.3125%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-177 lr=['1.0000000'], tr/val_loss:326.635529/269.685913, val:  54.20%, val_best:  78.32%, tr:  97.35%, tr_best:  98.31%, epoch time: 251.06 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 69.7421%\n",
      "layer   3  Sparsity: 63.0060%\n",
      "total_backward_count 5741568 real_backward_count 1149663  20.024%\n",
      "layer   1  Sparsity: 87.4756%\n",
      "layer   2  Sparsity: 69.5625%\n",
      "layer   3  Sparsity: 60.6875%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 367 occurrences\n",
      "test - Value 1: 85 occurrences\n",
      "epoch-178 lr=['1.0000000'], tr/val_loss:319.043274/280.267273, val:  65.27%, val_best:  78.32%, tr:  97.87%, tr_best:  98.31%, epoch time: 250.60 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 69.8607%\n",
      "layer   3  Sparsity: 63.0244%\n",
      "total_backward_count 5773824 real_backward_count 1155472  20.012%\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 73.6250%\n",
      "layer   3  Sparsity: 66.7500%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['1.0000000'], tr/val_loss:324.795776/385.922913, val:  50.00%, val_best:  78.32%, tr:  98.44%, tr_best:  98.44%, epoch time: 251.79 seconds, 4.20 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 69.9640%\n",
      "layer   3  Sparsity: 63.1146%\n",
      "total_backward_count 5806080 real_backward_count 1161378  20.003%\n",
      "layer   1  Sparsity: 80.6396%\n",
      "layer   2  Sparsity: 60.9375%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 334 occurrences\n",
      "test - Value 1: 118 occurrences\n",
      "epoch-180 lr=['1.0000000'], tr/val_loss:326.696381/272.126831, val:  71.68%, val_best:  78.32%, tr:  97.05%, tr_best:  98.44%, epoch time: 249.83 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 69.9227%\n",
      "layer   3  Sparsity: 63.0764%\n",
      "total_backward_count 5838336 real_backward_count 1167317  19.994%\n",
      "layer   1  Sparsity: 89.4043%\n",
      "layer   2  Sparsity: 73.8125%\n",
      "layer   3  Sparsity: 66.9375%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-181 lr=['1.0000000'], tr/val_loss:324.956177/302.614380, val:  50.00%, val_best:  78.32%, tr:  98.41%, tr_best:  98.44%, epoch time: 250.68 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 69.8063%\n",
      "layer   3  Sparsity: 63.0777%\n",
      "total_backward_count 5870592 real_backward_count 1173101  19.983%\n",
      "layer   1  Sparsity: 61.9385%\n",
      "layer   2  Sparsity: 62.1875%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "train - Value 0: 2126 occurrences\n",
      "train - Value 1: 1906 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-182 lr=['1.0000000'], tr/val_loss:332.924774/298.518005, val:  50.00%, val_best:  78.32%, tr:  96.28%, tr_best:  98.44%, epoch time: 250.12 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6696%\n",
      "layer   2  Sparsity: 69.8249%\n",
      "layer   3  Sparsity: 62.8835%\n",
      "total_backward_count 5902848 real_backward_count 1178991  19.973%\n",
      "layer   1  Sparsity: 80.3955%\n",
      "layer   2  Sparsity: 67.3125%\n",
      "layer   3  Sparsity: 60.9375%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-183 lr=['1.0000000'], tr/val_loss:330.462219/349.129242, val:  50.44%, val_best:  78.32%, tr:  97.37%, tr_best:  98.44%, epoch time: 248.87 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 69.8311%\n",
      "layer   3  Sparsity: 62.9268%\n",
      "total_backward_count 5935104 real_backward_count 1184853  19.963%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 55.3750%\n",
      "fc layer 1 self.abs_max_out: 4037.0\n",
      "train - Value 0: 2128 occurrences\n",
      "train - Value 1: 1904 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['1.0000000'], tr/val_loss:334.234406/452.104980, val:  50.00%, val_best:  78.32%, tr:  95.83%, tr_best:  98.44%, epoch time: 250.88 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 69.7784%\n",
      "layer   3  Sparsity: 62.9663%\n",
      "total_backward_count 5967360 real_backward_count 1190816  19.955%\n",
      "layer   1  Sparsity: 89.0381%\n",
      "layer   2  Sparsity: 72.8750%\n",
      "layer   3  Sparsity: 66.6875%\n",
      "fc layer 1 self.abs_max_out: 4045.0\n",
      "fc layer 1 self.abs_max_out: 4169.0\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['1.0000000'], tr/val_loss:339.772034/304.706879, val:  50.00%, val_best:  78.32%, tr:  96.88%, tr_best:  98.44%, epoch time: 249.99 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 69.8859%\n",
      "layer   3  Sparsity: 63.0998%\n",
      "total_backward_count 5999616 real_backward_count 1196866  19.949%\n",
      "layer   1  Sparsity: 87.4756%\n",
      "layer   2  Sparsity: 69.1250%\n",
      "layer   3  Sparsity: 61.0000%\n",
      "fc layer 1 self.abs_max_out: 4176.0\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-186 lr=['1.0000000'], tr/val_loss:332.453644/292.552368, val:  51.77%, val_best:  78.32%, tr:  96.88%, tr_best:  98.44%, epoch time: 249.44 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 69.8932%\n",
      "layer   3  Sparsity: 62.9862%\n",
      "total_backward_count 6031872 real_backward_count 1202756  19.940%\n",
      "layer   1  Sparsity: 83.4961%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "fc layer 1 self.abs_max_out: 4192.0\n",
      "train - Value 0: 2107 occurrences\n",
      "train - Value 1: 1925 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['1.0000000'], tr/val_loss:337.906525/394.928650, val:  50.00%, val_best:  78.32%, tr:  97.15%, tr_best:  98.44%, epoch time: 250.08 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 69.8900%\n",
      "layer   3  Sparsity: 62.8934%\n",
      "total_backward_count 6064128 real_backward_count 1208663  19.931%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 63.3750%\n",
      "layer   3  Sparsity: 55.3125%\n",
      "train - Value 0: 2112 occurrences\n",
      "train - Value 1: 1920 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-188 lr=['1.0000000'], tr/val_loss:333.715729/323.284363, val:  58.41%, val_best:  78.32%, tr:  96.63%, tr_best:  98.44%, epoch time: 251.03 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 69.8357%\n",
      "layer   3  Sparsity: 62.8583%\n",
      "total_backward_count 6096384 real_backward_count 1214774  19.926%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 62.1250%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "fc layer 1 self.abs_max_out: 4228.0\n",
      "train - Value 0: 2119 occurrences\n",
      "train - Value 1: 1913 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-189 lr=['1.0000000'], tr/val_loss:332.395203/388.795013, val:  50.00%, val_best:  78.32%, tr:  96.50%, tr_best:  98.44%, epoch time: 246.82 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 69.7341%\n",
      "layer   3  Sparsity: 62.9219%\n",
      "total_backward_count 6128640 real_backward_count 1220705  19.918%\n",
      "layer   1  Sparsity: 82.5439%\n",
      "layer   2  Sparsity: 72.6875%\n",
      "layer   3  Sparsity: 66.6250%\n",
      "train - Value 0: 2144 occurrences\n",
      "train - Value 1: 1888 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 65 occurrences\n",
      "test - Value 1: 387 occurrences\n",
      "epoch-190 lr=['1.0000000'], tr/val_loss:328.738190/308.231476, val:  63.50%, val_best:  78.32%, tr:  95.49%, tr_best:  98.44%, epoch time: 245.39 seconds, 4.09 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 69.8067%\n",
      "layer   3  Sparsity: 62.8559%\n",
      "total_backward_count 6160896 real_backward_count 1226547  19.909%\n",
      "layer   1  Sparsity: 71.6309%\n",
      "layer   2  Sparsity: 60.3125%\n",
      "layer   3  Sparsity: 55.3125%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-191 lr=['1.0000000'], tr/val_loss:334.683075/307.864136, val:  50.00%, val_best:  78.32%, tr:  97.97%, tr_best:  98.44%, epoch time: 249.75 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 69.8514%\n",
      "layer   3  Sparsity: 63.0921%\n",
      "total_backward_count 6193152 real_backward_count 1232368  19.899%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 71.6250%\n",
      "layer   3  Sparsity: 66.5625%\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 202 occurrences\n",
      "test - Value 1: 250 occurrences\n",
      "epoch-192 lr=['1.0000000'], tr/val_loss:329.179291/284.512329, val:  80.97%, val_best:  80.97%, tr:  97.45%, tr_best:  98.44%, epoch time: 249.62 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 69.8869%\n",
      "layer   3  Sparsity: 62.9871%\n",
      "total_backward_count 6225408 real_backward_count 1238186  19.889%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 62.6875%\n",
      "layer   3  Sparsity: 55.0625%\n",
      "fc layer 1 self.abs_max_out: 4233.0\n",
      "train - Value 0: 2127 occurrences\n",
      "train - Value 1: 1905 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['1.0000000'], tr/val_loss:320.509918/366.496307, val:  50.00%, val_best:  80.97%, tr:  96.65%, tr_best:  98.44%, epoch time: 249.00 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6679%\n",
      "layer   2  Sparsity: 69.8741%\n",
      "layer   3  Sparsity: 62.9241%\n",
      "total_backward_count 6257664 real_backward_count 1244049  19.880%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 66.1875%\n",
      "fc layer 1 self.abs_max_out: 4267.0\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-194 lr=['1.0000000'], tr/val_loss:321.135590/353.377502, val:  50.44%, val_best:  80.97%, tr:  97.94%, tr_best:  98.44%, epoch time: 250.42 seconds, 4.17 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 69.8591%\n",
      "layer   3  Sparsity: 62.9311%\n",
      "total_backward_count 6289920 real_backward_count 1249833  19.870%\n",
      "layer   1  Sparsity: 90.0391%\n",
      "layer   2  Sparsity: 75.3125%\n",
      "layer   3  Sparsity: 66.2500%\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-195 lr=['1.0000000'], tr/val_loss:322.093750/356.997131, val:  50.44%, val_best:  80.97%, tr:  97.52%, tr_best:  98.44%, epoch time: 248.77 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 69.8514%\n",
      "layer   3  Sparsity: 62.9554%\n",
      "total_backward_count 6322176 real_backward_count 1255677  19.861%\n",
      "layer   1  Sparsity: 84.6924%\n",
      "layer   2  Sparsity: 68.8750%\n",
      "layer   3  Sparsity: 60.6250%\n",
      "train - Value 0: 2095 occurrences\n",
      "train - Value 1: 1937 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 301 occurrences\n",
      "test - Value 1: 151 occurrences\n",
      "epoch-196 lr=['1.0000000'], tr/val_loss:321.161285/280.238800, val:  74.56%, val_best:  80.97%, tr:  97.25%, tr_best:  98.44%, epoch time: 249.57 seconds, 4.16 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 69.8720%\n",
      "layer   3  Sparsity: 63.0601%\n",
      "total_backward_count 6354432 real_backward_count 1261538  19.853%\n",
      "layer   1  Sparsity: 83.5449%\n",
      "layer   2  Sparsity: 71.8750%\n",
      "layer   3  Sparsity: 66.5625%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-197 lr=['1.0000000'], tr/val_loss:326.288818/354.937622, val:  51.55%, val_best:  80.97%, tr:  97.84%, tr_best:  98.44%, epoch time: 249.23 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 69.9038%\n",
      "layer   3  Sparsity: 63.1807%\n",
      "total_backward_count 6386688 real_backward_count 1267297  19.843%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 68.0625%\n",
      "layer   3  Sparsity: 61.5000%\n",
      "train - Value 0: 2134 occurrences\n",
      "train - Value 1: 1898 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['1.0000000'], tr/val_loss:331.678802/368.684753, val:  50.00%, val_best:  80.97%, tr:  96.18%, tr_best:  98.44%, epoch time: 250.53 seconds, 4.18 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 70.0590%\n",
      "layer   3  Sparsity: 62.9707%\n",
      "total_backward_count 6418944 real_backward_count 1273312  19.837%\n",
      "layer   1  Sparsity: 73.3887%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 60.6875%\n",
      "train - Value 0: 2122 occurrences\n",
      "train - Value 1: 1910 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-199 lr=['1.0000000'], tr/val_loss:328.887726/399.327484, val:  50.00%, val_best:  80.97%, tr:  96.48%, tr_best:  98.44%, epoch time: 248.94 seconds, 4.15 minutes\n",
      "layer   1  Sparsity: 82.6670%\n",
      "layer   2  Sparsity: 69.9857%\n",
      "layer   3  Sparsity: 62.9875%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68353396ac34581b96f1bedb844f76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96478</td></tr><tr><td>tr_epoch_loss</td><td>328.88773</td></tr><tr><td>val_acc_best</td><td>0.80973</td></tr><tr><td>val_acc_now</td><td>0.5</td></tr><tr><td>val_loss</td><td>399.32748</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-35</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eqcglfaw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eqcglfaw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251211_143238-eqcglfaw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eaqw792e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251212_041826-eaqw792e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eaqw792e' target=\"_blank\">peachy-sweep-36</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eaqw792e' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eaqw792e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251212_041836_027', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 64, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 32, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 64, 'lif_layer_v_threshold2': 128, 'init_scaling': [0.5, 0.0625, 0.03125], 'learning_rate': 8, 'learning_rate2': 2, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 32, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 64, self.v_threshold 128\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.03125])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=32, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.03125])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=128, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.0625, 0.03125])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 8\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 1132.0\n",
      "lif layer 1 self.abs_max_v: 1132.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 149.0\n",
      "lif layer 2 self.abs_max_v: 149.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 5.0\n",
      "fc layer 1 self.abs_max_out: 1739.0\n",
      "lif layer 1 self.abs_max_v: 1980.0\n",
      "lif layer 2 self.abs_max_v: 170.5\n",
      "fc layer 3 self.abs_max_out: 6.0\n",
      "lif layer 1 self.abs_max_v: 2041.0\n",
      "lif layer 2 self.abs_max_v: 186.5\n",
      "fc layer 3 self.abs_max_out: 9.0\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 98.2500%\n",
      "fc layer 1 self.abs_max_out: 1823.0\n",
      "fc layer 2 self.abs_max_out: 158.0\n",
      "lif layer 2 self.abs_max_v: 189.5\n",
      "lif layer 2 self.abs_max_v: 197.0\n",
      "fc layer 2 self.abs_max_out: 166.0\n",
      "fc layer 3 self.abs_max_out: 12.0\n",
      "fc layer 2 self.abs_max_out: 273.0\n",
      "lif layer 2 self.abs_max_v: 290.5\n",
      "fc layer 3 self.abs_max_out: 16.0\n",
      "lif layer 1 self.abs_max_v: 2046.5\n",
      "fc layer 2 self.abs_max_out: 286.0\n",
      "lif layer 2 self.abs_max_v: 345.5\n",
      "fc layer 3 self.abs_max_out: 20.0\n",
      "fc layer 1 self.abs_max_out: 1986.0\n",
      "fc layer 2 self.abs_max_out: 312.0\n",
      "lif layer 1 self.abs_max_v: 2095.5\n",
      "fc layer 1 self.abs_max_out: 2066.0\n",
      "lif layer 1 self.abs_max_v: 2777.0\n",
      "fc layer 1 self.abs_max_out: 2533.0\n",
      "fc layer 3 self.abs_max_out: 22.0\n",
      "fc layer 2 self.abs_max_out: 317.0\n",
      "fc layer 2 self.abs_max_out: 320.0\n",
      "lif layer 1 self.abs_max_v: 2901.0\n",
      "lif layer 2 self.abs_max_v: 355.5\n",
      "fc layer 2 self.abs_max_out: 337.0\n",
      "fc layer 2 self.abs_max_out: 363.0\n",
      "lif layer 2 self.abs_max_v: 363.0\n",
      "lif layer 2 self.abs_max_v: 365.5\n",
      "fc layer 1 self.abs_max_out: 2551.0\n",
      "lif layer 2 self.abs_max_v: 369.0\n",
      "fc layer 1 self.abs_max_out: 2646.0\n",
      "lif layer 1 self.abs_max_v: 2930.0\n",
      "lif layer 1 self.abs_max_v: 3004.0\n",
      "fc layer 1 self.abs_max_out: 2658.0\n",
      "fc layer 3 self.abs_max_out: 23.0\n",
      "lif layer 2 self.abs_max_v: 401.0\n",
      "fc layer 2 self.abs_max_out: 384.0\n",
      "lif layer 2 self.abs_max_v: 421.5\n",
      "fc layer 2 self.abs_max_out: 424.0\n",
      "lif layer 2 self.abs_max_v: 424.0\n",
      "lif layer 2 self.abs_max_v: 441.5\n",
      "lif layer 2 self.abs_max_v: 442.5\n",
      "fc layer 2 self.abs_max_out: 427.0\n",
      "fc layer 1 self.abs_max_out: 2742.0\n",
      "lif layer 2 self.abs_max_v: 454.5\n",
      "lif layer 2 self.abs_max_v: 456.5\n",
      "fc layer 2 self.abs_max_out: 438.0\n",
      "lif layer 2 self.abs_max_v: 463.0\n",
      "lif layer 2 self.abs_max_v: 480.0\n",
      "fc layer 3 self.abs_max_out: 24.0\n",
      "fc layer 2 self.abs_max_out: 451.0\n",
      "fc layer 1 self.abs_max_out: 2793.0\n",
      "lif layer 2 self.abs_max_v: 484.5\n",
      "fc layer 2 self.abs_max_out: 468.0\n",
      "lif layer 2 self.abs_max_v: 495.5\n",
      "lif layer 1 self.abs_max_v: 3102.5\n",
      "lif layer 1 self.abs_max_v: 3193.0\n",
      "lif layer 1 self.abs_max_v: 3824.5\n",
      "lif layer 2 self.abs_max_v: 499.5\n",
      "lif layer 2 self.abs_max_v: 500.5\n",
      "fc layer 1 self.abs_max_out: 3360.0\n",
      "fc layer 1 self.abs_max_out: 3387.0\n",
      "fc layer 1 self.abs_max_out: 3552.0\n",
      "fc layer 2 self.abs_max_out: 473.0\n",
      "fc layer 1 self.abs_max_out: 3554.0\n",
      "lif layer 1 self.abs_max_v: 3871.5\n",
      "fc layer 2 self.abs_max_out: 474.0\n",
      "fc layer 1 self.abs_max_out: 3569.0\n",
      "fc layer 1 self.abs_max_out: 3612.0\n",
      "fc layer 1 self.abs_max_out: 3872.0\n",
      "lif layer 1 self.abs_max_v: 3872.0\n",
      "lif layer 2 self.abs_max_v: 501.5\n",
      "lif layer 2 self.abs_max_v: 510.5\n",
      "lif layer 1 self.abs_max_v: 3883.5\n",
      "fc layer 1 self.abs_max_out: 3948.0\n",
      "lif layer 1 self.abs_max_v: 3948.0\n",
      "lif layer 1 self.abs_max_v: 4145.5\n",
      "lif layer 1 self.abs_max_v: 4826.0\n",
      "fc layer 1 self.abs_max_out: 3984.0\n",
      "fc layer 1 self.abs_max_out: 4019.0\n",
      "fc layer 1 self.abs_max_out: 4040.0\n",
      "fc layer 3 self.abs_max_out: 25.0\n",
      "fc layer 1 self.abs_max_out: 4279.0\n",
      "fc layer 1 self.abs_max_out: 4288.0\n",
      "fc layer 3 self.abs_max_out: 27.0\n",
      "fc layer 1 self.abs_max_out: 4310.0\n",
      "fc layer 1 self.abs_max_out: 4348.0\n",
      "fc layer 1 self.abs_max_out: 4407.0\n",
      "lif layer 1 self.abs_max_v: 4950.5\n",
      "lif layer 1 self.abs_max_v: 5223.5\n",
      "fc layer 1 self.abs_max_out: 4567.0\n",
      "lif layer 1 self.abs_max_v: 5667.5\n",
      "fc layer 1 self.abs_max_out: 4693.0\n",
      "fc layer 1 self.abs_max_out: 4718.0\n",
      "lif layer 1 self.abs_max_v: 5817.5\n",
      "fc layer 1 self.abs_max_out: 4822.0\n",
      "lif layer 1 self.abs_max_v: 6238.5\n",
      "lif layer 1 self.abs_max_v: 6769.5\n",
      "lif layer 1 self.abs_max_v: 6983.0\n",
      "fc layer 3 self.abs_max_out: 28.0\n",
      "fc layer 2 self.abs_max_out: 481.0\n",
      "fc layer 2 self.abs_max_out: 483.0\n",
      "fc layer 2 self.abs_max_out: 485.0\n",
      "fc layer 2 self.abs_max_out: 494.0\n",
      "fc layer 2 self.abs_max_out: 495.0\n",
      "fc layer 2 self.abs_max_out: 520.0\n",
      "lif layer 2 self.abs_max_v: 520.0\n",
      "fc layer 2 self.abs_max_out: 527.0\n",
      "lif layer 2 self.abs_max_v: 527.0\n",
      "fc layer 2 self.abs_max_out: 528.0\n",
      "lif layer 2 self.abs_max_v: 528.0\n",
      "fc layer 2 self.abs_max_out: 538.0\n",
      "lif layer 2 self.abs_max_v: 538.0\n",
      "fc layer 2 self.abs_max_out: 549.0\n",
      "lif layer 2 self.abs_max_v: 549.0\n",
      "fc layer 2 self.abs_max_out: 568.0\n",
      "lif layer 2 self.abs_max_v: 568.0\n",
      "lif layer 1 self.abs_max_v: 7044.5\n",
      "fc layer 3 self.abs_max_out: 29.0\n",
      "lif layer 1 self.abs_max_v: 7315.5\n",
      "fc layer 2 self.abs_max_out: 569.0\n",
      "lif layer 2 self.abs_max_v: 569.0\n",
      "fc layer 1 self.abs_max_out: 4853.0\n",
      "fc layer 2 self.abs_max_out: 570.0\n",
      "lif layer 2 self.abs_max_v: 609.5\n",
      "fc layer 2 self.abs_max_out: 572.0\n",
      "fc layer 2 self.abs_max_out: 609.0\n",
      "fc layer 2 self.abs_max_out: 646.0\n",
      "lif layer 2 self.abs_max_v: 646.0\n",
      "fc layer 2 self.abs_max_out: 684.0\n",
      "lif layer 2 self.abs_max_v: 684.0\n",
      "fc layer 1 self.abs_max_out: 4949.0\n",
      "fc layer 2 self.abs_max_out: 693.0\n",
      "lif layer 2 self.abs_max_v: 693.0\n",
      "fc layer 2 self.abs_max_out: 704.0\n",
      "lif layer 2 self.abs_max_v: 704.0\n",
      "fc layer 1 self.abs_max_out: 5424.0\n",
      "fc layer 2 self.abs_max_out: 721.0\n",
      "lif layer 2 self.abs_max_v: 721.0\n",
      "fc layer 2 self.abs_max_out: 748.0\n",
      "lif layer 2 self.abs_max_v: 748.0\n",
      "fc layer 3 self.abs_max_out: 31.0\n",
      "lif layer 1 self.abs_max_v: 7339.5\n",
      "lif layer 1 self.abs_max_v: 7982.0\n",
      "lif layer 1 self.abs_max_v: 8002.0\n",
      "fc layer 3 self.abs_max_out: 32.0\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 86.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 91.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 94.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 95.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 96.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 98.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 99.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['8.0000000'], tr/val_loss: 17.597418/ 30.170563, val:  50.00%, val_best:  50.00%, tr:  85.24%, tr_best:  85.24%, epoch time: 130.38 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 59.4552%\n",
      "layer   3  Sparsity: 96.6443%\n",
      "total_backward_count 16128 real_backward_count 3645  22.600%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 73.3398%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 96.6250%\n",
      "fc layer 1 self.abs_max_out: 5546.0\n",
      "lif layer 2 self.abs_max_v: 775.5\n",
      "fc layer 1 self.abs_max_out: 5930.0\n",
      "fc layer 3 self.abs_max_out: 37.0\n",
      "lif layer 2 self.abs_max_v: 846.5\n",
      "lif layer 2 self.abs_max_v: 860.5\n",
      "lif layer 2 self.abs_max_v: 902.0\n",
      "fc layer 1 self.abs_max_out: 5996.0\n",
      "lif layer 2 self.abs_max_v: 903.0\n",
      "fc layer 2 self.abs_max_out: 896.0\n",
      "fc layer 2 self.abs_max_out: 946.0\n",
      "lif layer 2 self.abs_max_v: 946.0\n",
      "fc layer 2 self.abs_max_out: 1027.0\n",
      "lif layer 2 self.abs_max_v: 1027.0\n",
      "fc layer 2 self.abs_max_out: 1042.0\n",
      "lif layer 2 self.abs_max_v: 1042.0\n",
      "fc layer 2 self.abs_max_out: 1110.0\n",
      "lif layer 2 self.abs_max_v: 1110.0\n",
      "fc layer 1 self.abs_max_out: 6291.0\n",
      "fc layer 2 self.abs_max_out: 1118.0\n",
      "lif layer 2 self.abs_max_v: 1118.0\n",
      "fc layer 2 self.abs_max_out: 1176.0\n",
      "lif layer 2 self.abs_max_v: 1176.0\n",
      "fc layer 2 self.abs_max_out: 1181.0\n",
      "lif layer 2 self.abs_max_v: 1181.0\n",
      "fc layer 3 self.abs_max_out: 38.0\n",
      "fc layer 3 self.abs_max_out: 41.0\n",
      "fc layer 3 self.abs_max_out: 44.0\n",
      "fc layer 3 self.abs_max_out: 48.0\n",
      "fc layer 3 self.abs_max_out: 55.0\n",
      "train - Value 0: 1897 occurrences\n",
      "train - Value 1: 2135 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 110.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 116.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 120.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 122.00 at epoch 1, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['8.0000000'], tr/val_loss: 21.294641/ 11.913700, val:  50.00%, val_best:  50.00%, tr:  87.67%, tr_best:  87.67%, epoch time: 129.38 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 59.3808%\n",
      "layer   3  Sparsity: 95.8890%\n",
      "total_backward_count 32256 real_backward_count 6914  21.435%\n",
      "layer   1  Sparsity: 81.4453%\n",
      "layer   2  Sparsity: 64.8750%\n",
      "layer   3  Sparsity: 96.6250%\n",
      "fc layer 2 self.abs_max_out: 1201.0\n",
      "lif layer 2 self.abs_max_v: 1201.0\n",
      "fc layer 1 self.abs_max_out: 6656.0\n",
      "fc layer 3 self.abs_max_out: 59.0\n",
      "fc layer 3 self.abs_max_out: 65.0\n",
      "train - Value 0: 2098 occurrences\n",
      "train - Value 1: 1934 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 123.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 126.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 130.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 133.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 136.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 140.00 at epoch 2, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-2   lr=['8.0000000'], tr/val_loss: 14.604321/ 13.026767, val:  50.88%, val_best:  50.88%, tr:  84.38%, tr_best:  87.67%, epoch time: 130.82 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 57.7739%\n",
      "layer   3  Sparsity: 95.1580%\n",
      "total_backward_count 48384 real_backward_count 10068  20.809%\n",
      "layer   1  Sparsity: 72.9980%\n",
      "layer   2  Sparsity: 56.5000%\n",
      "layer   3  Sparsity: 94.7500%\n",
      "fc layer 1 self.abs_max_out: 6680.0\n",
      "lif layer 1 self.abs_max_v: 8273.5\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 196.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 200.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 205.00 at epoch 3, iter 4031\n",
      "lif layer 1 self.abs_max_v: 8601.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['8.0000000'], tr/val_loss: 18.550591/ 43.115330, val:  50.00%, val_best:  50.88%, tr:  83.46%, tr_best:  87.67%, epoch time: 131.21 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 58.4870%\n",
      "layer   3  Sparsity: 94.8544%\n",
      "total_backward_count 64512 real_backward_count 13181  20.432%\n",
      "layer   1  Sparsity: 73.9258%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 94.6250%\n",
      "fc layer 1 self.abs_max_out: 6764.0\n",
      "lif layer 2 self.abs_max_v: 1202.5\n",
      "lif layer 2 self.abs_max_v: 1218.5\n",
      "lif layer 2 self.abs_max_v: 1358.5\n",
      "lif layer 2 self.abs_max_v: 1366.5\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 2 self.abs_max_v: 1380.0\n",
      "lif layer 2 self.abs_max_v: 1536.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['8.0000000'], tr/val_loss: 21.736929/ 22.719025, val:  50.00%, val_best:  50.88%, tr:  85.52%, tr_best:  87.67%, epoch time: 130.95 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 57.7598%\n",
      "layer   3  Sparsity: 95.3495%\n",
      "total_backward_count 80640 real_backward_count 16076  19.936%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 95.7500%\n",
      "lif layer 1 self.abs_max_v: 8870.0\n",
      "fc layer 1 self.abs_max_out: 6835.0\n",
      "lif layer 1 self.abs_max_v: 9171.5\n",
      "lif layer 2 self.abs_max_v: 1553.5\n",
      "lif layer 1 self.abs_max_v: 9462.0\n",
      "lif layer 2 self.abs_max_v: 1561.5\n",
      "lif layer 1 self.abs_max_v: 10738.5\n",
      "lif layer 1 self.abs_max_v: 10924.5\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-5   lr=['8.0000000'], tr/val_loss: 34.714005/ 39.267262, val:  65.04%, val_best:  65.04%, tr:  85.04%, tr_best:  87.67%, epoch time: 130.49 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 58.0458%\n",
      "layer   3  Sparsity: 95.3195%\n",
      "total_backward_count 96768 real_backward_count 18959  19.592%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 95.5000%\n",
      "fc layer 1 self.abs_max_out: 6870.0\n",
      "train - Value 0: 1751 occurrences\n",
      "train - Value 1: 2281 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['8.0000000'], tr/val_loss: 41.135414/ 44.633659, val:  50.00%, val_best:  65.04%, tr:  83.51%, tr_best:  87.67%, epoch time: 129.92 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 59.2242%\n",
      "layer   3  Sparsity: 95.0983%\n",
      "total_backward_count 112896 real_backward_count 21847  19.351%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 94.7500%\n",
      "fc layer 2 self.abs_max_out: 1220.0\n",
      "fc layer 2 self.abs_max_out: 1239.0\n",
      "fc layer 2 self.abs_max_out: 1362.0\n",
      "fc layer 2 self.abs_max_out: 1379.0\n",
      "fc layer 2 self.abs_max_out: 1446.0\n",
      "fc layer 2 self.abs_max_out: 1520.0\n",
      "fc layer 1 self.abs_max_out: 6947.0\n",
      "fc layer 1 self.abs_max_out: 7025.0\n",
      "fc layer 1 self.abs_max_out: 7371.0\n",
      "fc layer 1 self.abs_max_out: 7434.0\n",
      "fc layer 1 self.abs_max_out: 8319.0\n",
      "fc layer 1 self.abs_max_out: 8429.0\n",
      "fc layer 1 self.abs_max_out: 9093.0\n",
      "fc layer 3 self.abs_max_out: 72.0\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 383 occurrences\n",
      "test - Value 1: 69 occurrences\n",
      "epoch-7   lr=['8.0000000'], tr/val_loss: 41.607475/ 44.624371, val:  59.96%, val_best:  65.04%, tr:  87.13%, tr_best:  87.67%, epoch time: 130.04 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 59.4595%\n",
      "layer   3  Sparsity: 94.3758%\n",
      "total_backward_count 129024 real_backward_count 24711  19.152%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "fc layer 1 self.abs_max_out: 9295.0\n",
      "fc layer 1 self.abs_max_out: 9412.0\n",
      "train - Value 0: 1886 occurrences\n",
      "train - Value 1: 2146 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 9505.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-8   lr=['8.0000000'], tr/val_loss: 47.366737/ 31.145058, val:  50.66%, val_best:  65.04%, tr:  86.66%, tr_best:  87.67%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 59.5038%\n",
      "layer   3  Sparsity: 93.9627%\n",
      "total_backward_count 145152 real_backward_count 27698  19.082%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "fc layer 1 self.abs_max_out: 9663.0\n",
      "fc layer 1 self.abs_max_out: 9871.0\n",
      "fc layer 1 self.abs_max_out: 10017.0\n",
      "fc layer 1 self.abs_max_out: 10081.0\n",
      "train - Value 0: 1832 occurrences\n",
      "train - Value 1: 2200 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 208.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 215.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 223.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 224.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 228.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 232.00 at epoch 9, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['8.0000000'], tr/val_loss: 46.797253/ 57.544746, val:  50.00%, val_best:  65.04%, tr:  87.40%, tr_best:  87.67%, epoch time: 130.82 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 58.4789%\n",
      "layer   3  Sparsity: 93.9077%\n",
      "total_backward_count 161280 real_backward_count 30716  19.045%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "fc layer 3 self.abs_max_out: 73.0\n",
      "fc layer 1 self.abs_max_out: 10301.0\n",
      "lif layer 1 self.abs_max_v: 11309.5\n",
      "lif layer 1 self.abs_max_v: 11360.5\n",
      "lif layer 1 self.abs_max_v: 11435.5\n",
      "lif layer 1 self.abs_max_v: 13334.0\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['8.0000000'], tr/val_loss: 42.886608/ 20.137671, val:  50.00%, val_best:  65.04%, tr:  84.03%, tr_best:  87.67%, epoch time: 130.21 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 58.4961%\n",
      "layer   3  Sparsity: 93.9031%\n",
      "total_backward_count 177408 real_backward_count 33990  19.159%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "fc layer 1 self.abs_max_out: 10413.0\n",
      "fc layer 3 self.abs_max_out: 84.0\n",
      "fc layer 3 self.abs_max_out: 85.0\n",
      "lif layer 1 self.abs_max_v: 13789.0\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 233.00 at epoch 11, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['8.0000000'], tr/val_loss: 28.240177/ 40.448086, val:  50.00%, val_best:  65.04%, tr:  86.21%, tr_best:  87.67%, epoch time: 129.29 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 57.9431%\n",
      "layer   3  Sparsity: 93.6089%\n",
      "total_backward_count 193536 real_backward_count 37157  19.199%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "fc layer 3 self.abs_max_out: 88.0\n",
      "lif layer 2 self.abs_max_v: 1642.0\n",
      "train - Value 0: 1890 occurrences\n",
      "train - Value 1: 2142 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-12  lr=['8.0000000'], tr/val_loss: 29.728251/ 36.905624, val:  50.00%, val_best:  65.04%, tr:  87.25%, tr_best:  87.67%, epoch time: 130.57 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 57.4471%\n",
      "layer   3  Sparsity: 93.5133%\n",
      "total_backward_count 209664 real_backward_count 40096  19.124%\n",
      "layer   1  Sparsity: 87.1094%\n",
      "layer   2  Sparsity: 62.3750%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "fc layer 3 self.abs_max_out: 89.0\n",
      "fc layer 3 self.abs_max_out: 96.0\n",
      "fc layer 3 self.abs_max_out: 99.0\n",
      "train - Value 0: 1867 occurrences\n",
      "train - Value 1: 2165 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-13  lr=['8.0000000'], tr/val_loss: 31.472561/ 23.485666, val:  68.14%, val_best:  68.14%, tr:  85.79%, tr_best:  87.67%, epoch time: 131.50 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 57.2452%\n",
      "layer   3  Sparsity: 93.5996%\n",
      "total_backward_count 225792 real_backward_count 43118  19.096%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1837 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 379 occurrences\n",
      "test - Value 1: 73 occurrences\n",
      "epoch-14  lr=['8.0000000'], tr/val_loss: 30.592381/ 37.491543, val:  54.65%, val_best:  68.14%, tr:  84.95%, tr_best:  87.67%, epoch time: 130.97 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 56.9742%\n",
      "layer   3  Sparsity: 93.8577%\n",
      "total_backward_count 241920 real_backward_count 46284  19.132%\n",
      "layer   1  Sparsity: 92.3340%\n",
      "layer   2  Sparsity: 69.8750%\n",
      "layer   3  Sparsity: 95.7500%\n",
      "train - Value 0: 1828 occurrences\n",
      "train - Value 1: 2204 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-15  lr=['8.0000000'], tr/val_loss: 31.002428/ 26.072676, val:  66.81%, val_best:  68.14%, tr:  85.02%, tr_best:  87.67%, epoch time: 130.01 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 56.4598%\n",
      "layer   3  Sparsity: 94.1284%\n",
      "total_backward_count 258048 real_backward_count 49362  19.129%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1791 occurrences\n",
      "train - Value 1: 2241 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-16  lr=['8.0000000'], tr/val_loss: 30.154449/ 24.662809, val:  67.26%, val_best:  68.14%, tr:  84.20%, tr_best:  87.67%, epoch time: 129.34 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 56.3372%\n",
      "layer   3  Sparsity: 94.1337%\n",
      "total_backward_count 274176 real_backward_count 52562  19.171%\n",
      "layer   1  Sparsity: 72.9004%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "lif layer 1 self.abs_max_v: 13889.0\n",
      "lif layer 2 self.abs_max_v: 1648.5\n",
      "train - Value 0: 1842 occurrences\n",
      "train - Value 1: 2190 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-17  lr=['8.0000000'], tr/val_loss: 33.320564/ 32.897404, val:  52.88%, val_best:  68.14%, tr:  84.28%, tr_best:  87.67%, epoch time: 131.16 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 56.0241%\n",
      "layer   3  Sparsity: 94.1365%\n",
      "total_backward_count 290304 real_backward_count 55695  19.185%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 53.0000%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "lif layer 2 self.abs_max_v: 1669.0\n",
      "train - Value 0: 1676 occurrences\n",
      "train - Value 1: 2356 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 239.00 at epoch 18, iter 4031\n",
      "max_activation_accul updated: 240.00 at epoch 18, iter 4031\n",
      "max_activation_accul updated: 241.00 at epoch 18, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['8.0000000'], tr/val_loss: 32.350300/ 41.443604, val:  50.00%, val_best:  68.14%, tr:  83.18%, tr_best:  87.67%, epoch time: 130.09 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 55.6964%\n",
      "layer   3  Sparsity: 94.1609%\n",
      "total_backward_count 306432 real_backward_count 58974  19.245%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "lif layer 2 self.abs_max_v: 1684.0\n",
      "train - Value 0: 1746 occurrences\n",
      "train - Value 1: 2286 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 248.00 at epoch 19, iter 4031\n",
      "max_activation_accul updated: 250.00 at epoch 19, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-19  lr=['8.0000000'], tr/val_loss: 31.664114/ 28.598385, val:  50.22%, val_best:  68.14%, tr:  81.80%, tr_best:  87.67%, epoch time: 130.71 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 55.2407%\n",
      "layer   3  Sparsity: 94.1717%\n",
      "total_backward_count 322560 real_backward_count 62211  19.287%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1689 occurrences\n",
      "train - Value 1: 2343 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-20  lr=['8.0000000'], tr/val_loss: 30.009586/ 27.153940, val:  50.00%, val_best:  68.14%, tr:  83.36%, tr_best:  87.67%, epoch time: 129.69 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 55.0959%\n",
      "layer   3  Sparsity: 94.1701%\n",
      "total_backward_count 338688 real_backward_count 65450  19.325%\n",
      "layer   1  Sparsity: 84.8633%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-21  lr=['8.0000000'], tr/val_loss: 26.993326/ 24.783247, val:  50.00%, val_best:  68.14%, tr:  83.80%, tr_best:  87.67%, epoch time: 130.46 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 55.0438%\n",
      "layer   3  Sparsity: 94.1789%\n",
      "total_backward_count 354816 real_backward_count 68648  19.347%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "lif layer 2 self.abs_max_v: 1713.5\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['8.0000000'], tr/val_loss: 27.554899/ 44.562557, val:  50.00%, val_best:  68.14%, tr:  81.82%, tr_best:  87.67%, epoch time: 130.49 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.5744%\n",
      "layer   3  Sparsity: 94.1989%\n",
      "total_backward_count 370944 real_backward_count 72094  19.435%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 51.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1816 occurrences\n",
      "train - Value 1: 2216 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 129 occurrences\n",
      "test - Value 1: 323 occurrences\n",
      "epoch-23  lr=['8.0000000'], tr/val_loss: 27.248150/ 43.739151, val:  63.94%, val_best:  68.14%, tr:  84.08%, tr_best:  87.67%, epoch time: 131.40 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 54.8142%\n",
      "layer   3  Sparsity: 94.1986%\n",
      "total_backward_count 387072 real_backward_count 75406  19.481%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 51.7500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "fc layer 1 self.abs_max_out: 10685.0\n",
      "lif layer 1 self.abs_max_v: 14043.0\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 14842.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['8.0000000'], tr/val_loss: 38.223949/ 24.439138, val:  50.00%, val_best:  68.14%, tr:  84.75%, tr_best:  87.67%, epoch time: 130.63 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.7123%\n",
      "layer   3  Sparsity: 94.1848%\n",
      "total_backward_count 403200 real_backward_count 78749  19.531%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "lif layer 1 self.abs_max_v: 15943.5\n",
      "lif layer 1 self.abs_max_v: 16623.0\n",
      "fc layer 1 self.abs_max_out: 10745.0\n",
      "fc layer 1 self.abs_max_out: 10931.0\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 11064.0\n",
      "fc layer 1 self.abs_max_out: 12024.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-25  lr=['8.0000000'], tr/val_loss: 28.206207/ 41.679897, val:  50.00%, val_best:  68.14%, tr:  83.63%, tr_best:  87.67%, epoch time: 131.98 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 55.3132%\n",
      "layer   3  Sparsity: 94.2067%\n",
      "total_backward_count 419328 real_backward_count 82281  19.622%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 52.8750%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "lif layer 1 self.abs_max_v: 17139.0\n",
      "lif layer 1 self.abs_max_v: 17574.5\n",
      "train - Value 0: 1748 occurrences\n",
      "train - Value 1: 2284 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 12158.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['8.0000000'], tr/val_loss: 28.154604/ 37.594639, val:  50.00%, val_best:  68.14%, tr:  83.58%, tr_best:  87.67%, epoch time: 131.07 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 55.5452%\n",
      "layer   3  Sparsity: 94.2274%\n",
      "total_backward_count 435456 real_backward_count 85796  19.703%\n",
      "layer   1  Sparsity: 70.8984%\n",
      "layer   2  Sparsity: 49.8750%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "lif layer 1 self.abs_max_v: 17587.0\n",
      "lif layer 1 self.abs_max_v: 18420.0\n",
      "train - Value 0: 2324 occurrences\n",
      "train - Value 1: 1708 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 12386.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 19 occurrences\n",
      "test - Value 1: 433 occurrences\n",
      "epoch-27  lr=['8.0000000'], tr/val_loss: 29.155752/ 36.174366, val:  54.20%, val_best:  68.14%, tr:  82.09%, tr_best:  87.67%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 54.7224%\n",
      "layer   3  Sparsity: 94.2795%\n",
      "total_backward_count 451584 real_backward_count 89268  19.768%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "lif layer 1 self.abs_max_v: 18428.5\n",
      "train - Value 0: 2347 occurrences\n",
      "train - Value 1: 1685 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 260.00 at epoch 28, iter 4031\n",
      "fc layer 1 self.abs_max_out: 12401.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['8.0000000'], tr/val_loss: 28.435316/ 22.144457, val:  50.00%, val_best:  68.14%, tr:  81.82%, tr_best:  87.67%, epoch time: 130.86 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 54.8653%\n",
      "layer   3  Sparsity: 93.9116%\n",
      "total_backward_count 467712 real_backward_count 92756  19.832%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 52.2500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "lif layer 1 self.abs_max_v: 18673.5\n",
      "train - Value 0: 2280 occurrences\n",
      "train - Value 1: 1752 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 12438.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['8.0000000'], tr/val_loss: 22.722864/ 28.827061, val:  50.00%, val_best:  68.14%, tr:  84.23%, tr_best:  87.67%, epoch time: 131.00 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 54.8655%\n",
      "layer   3  Sparsity: 93.7527%\n",
      "total_backward_count 483840 real_backward_count 96355  19.915%\n",
      "layer   1  Sparsity: 88.4766%\n",
      "layer   2  Sparsity: 57.3750%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "fc layer 3 self.abs_max_out: 104.0\n",
      "lif layer 1 self.abs_max_v: 18675.5\n",
      "train - Value 0: 2157 occurrences\n",
      "train - Value 1: 1875 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 12452.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['8.0000000'], tr/val_loss: 30.319353/ 59.035809, val:  50.00%, val_best:  68.14%, tr:  81.92%, tr_best:  87.67%, epoch time: 129.88 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.8966%\n",
      "layer   3  Sparsity: 93.7816%\n",
      "total_backward_count 499968 real_backward_count 99924  19.986%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 47.5000%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "lif layer 1 self.abs_max_v: 18714.0\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-31  lr=['8.0000000'], tr/val_loss: 54.999050/ 58.085762, val:  50.00%, val_best:  68.14%, tr:  86.76%, tr_best:  87.67%, epoch time: 129.74 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 54.6977%\n",
      "layer   3  Sparsity: 93.6452%\n",
      "total_backward_count 516096 real_backward_count 103159  19.988%\n",
      "layer   1  Sparsity: 71.8750%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "fc layer 3 self.abs_max_out: 107.0\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-32  lr=['8.0000000'], tr/val_loss: 58.251438/ 56.151527, val:  50.00%, val_best:  68.14%, tr:  86.14%, tr_best:  87.67%, epoch time: 131.21 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 54.7135%\n",
      "layer   3  Sparsity: 93.8683%\n",
      "total_backward_count 532224 real_backward_count 106492  20.009%\n",
      "layer   1  Sparsity: 88.1836%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "fc layer 3 self.abs_max_out: 109.0\n",
      "fc layer 3 self.abs_max_out: 120.0\n",
      "fc layer 3 self.abs_max_out: 124.0\n",
      "fc layer 2 self.abs_max_out: 1572.0\n",
      "train - Value 0: 1883 occurrences\n",
      "train - Value 1: 2149 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 1699.0\n",
      "fc layer 2 self.abs_max_out: 1723.0\n",
      "lif layer 2 self.abs_max_v: 1723.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['8.0000000'], tr/val_loss: 58.441555/ 54.897835, val:  50.00%, val_best:  68.14%, tr:  87.52%, tr_best:  87.67%, epoch time: 130.39 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.6339%\n",
      "layer   3  Sparsity: 93.8788%\n",
      "total_backward_count 548352 real_backward_count 109618  19.990%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "lif layer 2 self.abs_max_v: 1784.0\n",
      "lif layer 2 self.abs_max_v: 1943.0\n",
      "train - Value 0: 1723 occurrences\n",
      "train - Value 1: 2309 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 276.00 at epoch 34, iter 4031\n",
      "max_activation_accul updated: 286.00 at epoch 34, iter 4031\n",
      "max_activation_accul updated: 289.00 at epoch 34, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-34  lr=['8.0000000'], tr/val_loss: 62.299686/ 60.955395, val:  53.10%, val_best:  68.14%, tr:  86.93%, tr_best:  87.67%, epoch time: 130.34 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.6998%\n",
      "layer   3  Sparsity: 93.9246%\n",
      "total_backward_count 564480 real_backward_count 112693  19.964%\n",
      "layer   1  Sparsity: 86.8164%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "fc layer 2 self.abs_max_out: 1875.0\n",
      "fc layer 1 self.abs_max_out: 12538.0\n",
      "train - Value 0: 1770 occurrences\n",
      "train - Value 1: 2262 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 55 occurrences\n",
      "test - Value 1: 397 occurrences\n",
      "epoch-35  lr=['8.0000000'], tr/val_loss: 64.548683/ 65.268127, val:  58.19%, val_best:  68.14%, tr:  86.26%, tr_best:  87.67%, epoch time: 130.79 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 55.1534%\n",
      "layer   3  Sparsity: 93.8637%\n",
      "total_backward_count 580608 real_backward_count 115644  19.918%\n",
      "layer   1  Sparsity: 93.5547%\n",
      "layer   2  Sparsity: 62.8750%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "fc layer 1 self.abs_max_out: 12945.0\n",
      "fc layer 1 self.abs_max_out: 13186.0\n",
      "fc layer 2 self.abs_max_out: 1964.0\n",
      "lif layer 2 self.abs_max_v: 1964.0\n",
      "fc layer 2 self.abs_max_out: 2036.0\n",
      "lif layer 2 self.abs_max_v: 2036.0\n",
      "train - Value 0: 1842 occurrences\n",
      "train - Value 1: 2190 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 350 occurrences\n",
      "test - Value 1: 102 occurrences\n",
      "epoch-36  lr=['8.0000000'], tr/val_loss: 62.751305/ 60.095100, val:  60.62%, val_best:  68.14%, tr:  85.96%, tr_best:  87.67%, epoch time: 129.59 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 55.2695%\n",
      "layer   3  Sparsity: 93.7536%\n",
      "total_backward_count 596736 real_backward_count 118523  19.862%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 55.1250%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1861 occurrences\n",
      "train - Value 1: 2171 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 2168.0\n",
      "lif layer 2 self.abs_max_v: 2168.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['8.0000000'], tr/val_loss: 63.424366/ 62.890728, val:  50.00%, val_best:  68.14%, tr:  85.00%, tr_best:  87.67%, epoch time: 129.98 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 55.3783%\n",
      "layer   3  Sparsity: 93.8324%\n",
      "total_backward_count 612864 real_backward_count 121401  19.809%\n",
      "layer   1  Sparsity: 68.7988%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1863 occurrences\n",
      "train - Value 1: 2169 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-38  lr=['8.0000000'], tr/val_loss: 63.419399/ 60.353207, val:  64.60%, val_best:  68.14%, tr:  86.88%, tr_best:  87.67%, epoch time: 130.15 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4835%\n",
      "layer   2  Sparsity: 55.5289%\n",
      "layer   3  Sparsity: 93.8144%\n",
      "total_backward_count 628992 real_backward_count 124292  19.761%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 61.3750%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "lif layer 1 self.abs_max_v: 19341.5\n",
      "train - Value 0: 1846 occurrences\n",
      "train - Value 1: 2186 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 2224.0\n",
      "lif layer 2 self.abs_max_v: 2224.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-39  lr=['8.0000000'], tr/val_loss: 61.212425/ 60.078674, val:  58.41%, val_best:  68.14%, tr:  87.85%, tr_best:  87.85%, epoch time: 129.44 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 55.3955%\n",
      "layer   3  Sparsity: 93.7173%\n",
      "total_backward_count 645120 real_backward_count 127056  19.695%\n",
      "layer   1  Sparsity: 75.8789%\n",
      "layer   2  Sparsity: 53.3750%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "lif layer 1 self.abs_max_v: 19967.0\n",
      "train - Value 0: 1725 occurrences\n",
      "train - Value 1: 2307 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-40  lr=['8.0000000'], tr/val_loss: 65.403473/ 61.449654, val:  60.62%, val_best:  68.14%, tr:  85.59%, tr_best:  87.85%, epoch time: 130.58 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4819%\n",
      "layer   2  Sparsity: 55.0927%\n",
      "layer   3  Sparsity: 93.8214%\n",
      "total_backward_count 661248 real_backward_count 129649  19.607%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1654 occurrences\n",
      "train - Value 1: 2378 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-41  lr=['8.0000000'], tr/val_loss: 66.112129/ 70.033028, val:  55.75%, val_best:  68.14%, tr:  85.66%, tr_best:  87.85%, epoch time: 129.12 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 54.8154%\n",
      "layer   3  Sparsity: 93.8553%\n",
      "total_backward_count 677376 real_backward_count 132355  19.539%\n",
      "layer   1  Sparsity: 67.2852%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "lif layer 1 self.abs_max_v: 20039.0\n",
      "train - Value 0: 1701 occurrences\n",
      "train - Value 1: 2331 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 305.00 at epoch 42, iter 4031\n",
      "max_activation_accul updated: 313.00 at epoch 42, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 361 occurrences\n",
      "test - Value 1: 91 occurrences\n",
      "epoch-42  lr=['8.0000000'], tr/val_loss: 65.621017/ 62.627552, val:  61.73%, val_best:  68.14%, tr:  86.88%, tr_best:  87.85%, epoch time: 128.81 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 54.6159%\n",
      "layer   3  Sparsity: 93.7699%\n",
      "total_backward_count 693504 real_backward_count 135048  19.473%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "lif layer 1 self.abs_max_v: 20045.0\n",
      "train - Value 0: 1848 occurrences\n",
      "train - Value 1: 2184 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-43  lr=['8.0000000'], tr/val_loss: 66.478966/ 62.537228, val:  60.18%, val_best:  68.14%, tr:  87.15%, tr_best:  87.85%, epoch time: 128.25 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 54.7288%\n",
      "layer   3  Sparsity: 93.8056%\n",
      "total_backward_count 709632 real_backward_count 137798  19.418%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 59.8750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1885 occurrences\n",
      "train - Value 1: 2147 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-44  lr=['8.0000000'], tr/val_loss: 66.268692/ 67.339844, val:  50.22%, val_best:  68.14%, tr:  87.38%, tr_best:  87.85%, epoch time: 129.59 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.4113%\n",
      "layer   3  Sparsity: 93.8030%\n",
      "total_backward_count 725760 real_backward_count 140603  19.373%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1837 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['8.0000000'], tr/val_loss: 65.939674/ 65.391182, val:  50.00%, val_best:  68.14%, tr:  88.02%, tr_best:  88.02%, epoch time: 128.64 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 54.2235%\n",
      "layer   3  Sparsity: 93.8087%\n",
      "total_backward_count 741888 real_backward_count 143348  19.322%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 66.3750%\n",
      "layer   3  Sparsity: 95.5000%\n",
      "lif layer 1 self.abs_max_v: 20050.5\n",
      "train - Value 0: 1838 occurrences\n",
      "train - Value 1: 2194 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 359 occurrences\n",
      "test - Value 1: 93 occurrences\n",
      "epoch-46  lr=['8.0000000'], tr/val_loss: 65.572220/ 61.657089, val:  62.17%, val_best:  68.14%, tr:  86.51%, tr_best:  88.02%, epoch time: 128.41 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 54.3100%\n",
      "layer   3  Sparsity: 93.7880%\n",
      "total_backward_count 758016 real_backward_count 146091  19.273%\n",
      "layer   1  Sparsity: 70.5566%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "lif layer 1 self.abs_max_v: 20057.0\n",
      "train - Value 0: 1904 occurrences\n",
      "train - Value 1: 2128 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 329.00 at epoch 47, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['8.0000000'], tr/val_loss: 65.408501/ 68.847847, val:  50.00%, val_best:  68.14%, tr:  87.95%, tr_best:  88.02%, epoch time: 131.11 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 54.4943%\n",
      "layer   3  Sparsity: 93.7310%\n",
      "total_backward_count 774144 real_backward_count 148670  19.204%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 54.8750%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "lif layer 1 self.abs_max_v: 20063.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['8.0000000'], tr/val_loss: 65.582993/ 68.275887, val:  50.00%, val_best:  68.14%, tr:  87.52%, tr_best:  88.02%, epoch time: 130.75 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 54.4289%\n",
      "layer   3  Sparsity: 93.7249%\n",
      "total_backward_count 790272 real_backward_count 151292  19.144%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-49  lr=['8.0000000'], tr/val_loss: 64.913948/ 63.421619, val:  61.50%, val_best:  68.14%, tr:  89.91%, tr_best:  89.91%, epoch time: 130.28 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.3794%\n",
      "layer   3  Sparsity: 93.7342%\n",
      "total_backward_count 806400 real_backward_count 153948  19.091%\n",
      "layer   1  Sparsity: 80.5664%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1869 occurrences\n",
      "train - Value 1: 2163 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['8.0000000'], tr/val_loss: 65.622856/ 68.862061, val:  50.00%, val_best:  68.14%, tr:  87.87%, tr_best:  89.91%, epoch time: 131.15 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 54.0940%\n",
      "layer   3  Sparsity: 93.7578%\n",
      "total_backward_count 822528 real_backward_count 156640  19.044%\n",
      "layer   1  Sparsity: 73.0957%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['8.0000000'], tr/val_loss: 65.947029/ 69.810570, val:  50.00%, val_best:  68.14%, tr:  87.43%, tr_best:  89.91%, epoch time: 130.78 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.0485%\n",
      "layer   3  Sparsity: 93.8013%\n",
      "total_backward_count 838656 real_backward_count 159364  19.002%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "lif layer 1 self.abs_max_v: 20069.5\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-52  lr=['8.0000000'], tr/val_loss: 65.119576/ 66.729881, val:  50.44%, val_best:  68.14%, tr:  88.37%, tr_best:  89.91%, epoch time: 130.46 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 54.0178%\n",
      "layer   3  Sparsity: 93.7546%\n",
      "total_backward_count 854784 real_backward_count 161929  18.944%\n",
      "layer   1  Sparsity: 90.2344%\n",
      "layer   2  Sparsity: 59.2500%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-53  lr=['8.0000000'], tr/val_loss: 65.250877/ 63.838463, val:  60.62%, val_best:  68.14%, tr:  87.60%, tr_best:  89.91%, epoch time: 131.27 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 54.0667%\n",
      "layer   3  Sparsity: 93.7612%\n",
      "total_backward_count 870912 real_backward_count 164604  18.900%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 53.1250%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1828 occurrences\n",
      "train - Value 1: 2204 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 366 occurrences\n",
      "test - Value 1: 86 occurrences\n",
      "epoch-54  lr=['8.0000000'], tr/val_loss: 65.877831/ 62.437962, val:  61.95%, val_best:  68.14%, tr:  87.50%, tr_best:  89.91%, epoch time: 130.04 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 54.1236%\n",
      "layer   3  Sparsity: 93.8388%\n",
      "total_backward_count 887040 real_backward_count 167288  18.859%\n",
      "layer   1  Sparsity: 79.2480%\n",
      "layer   2  Sparsity: 51.7500%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "fc layer 1 self.abs_max_out: 13194.0\n",
      "train - Value 0: 1826 occurrences\n",
      "train - Value 1: 2206 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 338.00 at epoch 55, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['8.0000000'], tr/val_loss: 65.282455/ 70.114174, val:  50.00%, val_best:  68.14%, tr:  86.95%, tr_best:  89.91%, epoch time: 131.49 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 54.0861%\n",
      "layer   3  Sparsity: 93.7762%\n",
      "total_backward_count 903168 real_backward_count 169942  18.816%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "lif layer 1 self.abs_max_v: 20075.5\n",
      "train - Value 0: 1940 occurrences\n",
      "train - Value 1: 2092 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 67 occurrences\n",
      "test - Value 1: 385 occurrences\n",
      "epoch-56  lr=['8.0000000'], tr/val_loss: 65.370995/ 60.388103, val:  60.40%, val_best:  68.14%, tr:  88.64%, tr_best:  89.91%, epoch time: 131.28 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 54.1210%\n",
      "layer   3  Sparsity: 93.7639%\n",
      "total_backward_count 919296 real_backward_count 172529  18.768%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 59.6250%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "lif layer 1 self.abs_max_v: 20082.0\n",
      "train - Value 0: 1938 occurrences\n",
      "train - Value 1: 2094 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-57  lr=['8.0000000'], tr/val_loss: 65.780869/ 63.161266, val:  71.90%, val_best:  71.90%, tr:  87.30%, tr_best:  89.91%, epoch time: 127.72 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4790%\n",
      "layer   2  Sparsity: 54.1869%\n",
      "layer   3  Sparsity: 93.8083%\n",
      "total_backward_count 935424 real_backward_count 175224  18.732%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 70.8750%\n",
      "layer   3  Sparsity: 95.5000%\n",
      "fc layer 1 self.abs_max_out: 13198.0\n",
      "train - Value 0: 1781 occurrences\n",
      "train - Value 1: 2251 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-58  lr=['8.0000000'], tr/val_loss: 65.408684/ 63.737717, val:  54.20%, val_best:  71.90%, tr:  88.42%, tr_best:  89.91%, epoch time: 130.93 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 54.1727%\n",
      "layer   3  Sparsity: 93.8071%\n",
      "total_backward_count 951552 real_backward_count 177817  18.687%\n",
      "layer   1  Sparsity: 77.2949%\n",
      "layer   2  Sparsity: 50.3750%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1869 occurrences\n",
      "train - Value 1: 2163 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-59  lr=['8.0000000'], tr/val_loss: 66.492149/ 61.439903, val:  75.88%, val_best:  75.88%, tr:  88.07%, tr_best:  89.91%, epoch time: 130.97 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 54.0253%\n",
      "layer   3  Sparsity: 93.8185%\n",
      "total_backward_count 967680 real_backward_count 180522  18.655%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 59.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "fc layer 1 self.abs_max_out: 13266.0\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-60  lr=['8.0000000'], tr/val_loss: 65.705727/ 62.519127, val:  64.16%, val_best:  75.88%, tr:  87.95%, tr_best:  89.91%, epoch time: 131.46 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 54.1100%\n",
      "layer   3  Sparsity: 93.7994%\n",
      "total_backward_count 983808 real_backward_count 183106  18.612%\n",
      "layer   1  Sparsity: 72.7539%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "fc layer 1 self.abs_max_out: 13356.0\n",
      "train - Value 0: 1919 occurrences\n",
      "train - Value 1: 2113 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-61  lr=['8.0000000'], tr/val_loss: 65.763931/ 61.998646, val:  70.35%, val_best:  75.88%, tr:  89.61%, tr_best:  89.91%, epoch time: 130.72 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 54.1169%\n",
      "layer   3  Sparsity: 93.7966%\n",
      "total_backward_count 999936 real_backward_count 185686  18.570%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "fc layer 1 self.abs_max_out: 13438.0\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 342.00 at epoch 62, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['8.0000000'], tr/val_loss: 65.274094/ 72.318024, val:  50.00%, val_best:  75.88%, tr:  88.47%, tr_best:  89.91%, epoch time: 130.85 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 54.0890%\n",
      "layer   3  Sparsity: 93.7649%\n",
      "total_backward_count 1016064 real_backward_count 188215  18.524%\n",
      "layer   1  Sparsity: 78.7598%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "fc layer 1 self.abs_max_out: 13537.0\n",
      "train - Value 0: 1809 occurrences\n",
      "train - Value 1: 2223 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-63  lr=['8.0000000'], tr/val_loss: 65.055168/ 64.668266, val:  50.22%, val_best:  75.88%, tr:  87.23%, tr_best:  89.91%, epoch time: 130.55 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 54.1146%\n",
      "layer   3  Sparsity: 93.7791%\n",
      "total_backward_count 1032192 real_backward_count 190780  18.483%\n",
      "layer   1  Sparsity: 76.8066%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1745 occurrences\n",
      "train - Value 1: 2287 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 408 occurrences\n",
      "test - Value 1: 44 occurrences\n",
      "epoch-64  lr=['8.0000000'], tr/val_loss: 64.955254/ 63.457603, val:  57.96%, val_best:  75.88%, tr:  86.58%, tr_best:  89.91%, epoch time: 130.87 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 54.1326%\n",
      "layer   3  Sparsity: 93.7723%\n",
      "total_backward_count 1048320 real_backward_count 193302  18.439%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-65  lr=['8.0000000'], tr/val_loss: 64.947983/ 65.907372, val:  60.18%, val_best:  75.88%, tr:  87.60%, tr_best:  89.91%, epoch time: 131.19 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 54.1720%\n",
      "layer   3  Sparsity: 93.8168%\n",
      "total_backward_count 1064448 real_backward_count 195789  18.393%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "fc layer 1 self.abs_max_out: 13603.0\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 357 occurrences\n",
      "test - Value 1: 95 occurrences\n",
      "epoch-66  lr=['8.0000000'], tr/val_loss: 65.182671/ 62.039669, val:  65.27%, val_best:  75.88%, tr:  86.48%, tr_best:  89.91%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.1641%\n",
      "layer   3  Sparsity: 93.7852%\n",
      "total_backward_count 1080576 real_backward_count 198350  18.356%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "fc layer 1 self.abs_max_out: 13701.0\n",
      "train - Value 0: 2103 occurrences\n",
      "train - Value 1: 1929 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-67  lr=['8.0000000'], tr/val_loss: 64.997971/ 63.520645, val:  57.30%, val_best:  75.88%, tr:  87.87%, tr_best:  89.91%, epoch time: 131.20 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.1145%\n",
      "layer   3  Sparsity: 93.7919%\n",
      "total_backward_count 1096704 real_backward_count 200848  18.314%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "fc layer 1 self.abs_max_out: 14352.0\n",
      "train - Value 0: 1806 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-68  lr=['8.0000000'], tr/val_loss: 65.538879/ 61.674564, val:  68.81%, val_best:  75.88%, tr:  87.90%, tr_best:  89.91%, epoch time: 130.50 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 54.0412%\n",
      "layer   3  Sparsity: 93.8126%\n",
      "total_backward_count 1112832 real_backward_count 203531  18.289%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1951 occurrences\n",
      "train - Value 1: 2081 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-69  lr=['8.0000000'], tr/val_loss: 65.550095/ 62.375008, val:  52.43%, val_best:  75.88%, tr:  87.57%, tr_best:  89.91%, epoch time: 130.73 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.1548%\n",
      "layer   3  Sparsity: 93.8451%\n",
      "total_backward_count 1128960 real_backward_count 206134  18.259%\n",
      "layer   1  Sparsity: 65.8691%\n",
      "layer   2  Sparsity: 49.1250%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2156 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 2274.0\n",
      "lif layer 2 self.abs_max_v: 2274.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-70  lr=['8.0000000'], tr/val_loss: 65.538521/ 71.122978, val:  50.00%, val_best:  75.88%, tr:  88.14%, tr_best:  89.91%, epoch time: 130.09 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 54.1421%\n",
      "layer   3  Sparsity: 93.7965%\n",
      "total_backward_count 1145088 real_backward_count 208705  18.226%\n",
      "layer   1  Sparsity: 70.4102%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 107 occurrences\n",
      "test - Value 1: 345 occurrences\n",
      "epoch-71  lr=['8.0000000'], tr/val_loss: 65.642418/ 63.146011, val:  69.69%, val_best:  75.88%, tr:  88.34%, tr_best:  89.91%, epoch time: 129.78 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 54.1704%\n",
      "layer   3  Sparsity: 93.7798%\n",
      "total_backward_count 1161216 real_backward_count 211242  18.191%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "fc layer 1 self.abs_max_out: 14362.0\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 343.00 at epoch 72, iter 4031\n",
      "fc layer 2 self.abs_max_out: 2420.0\n",
      "lif layer 2 self.abs_max_v: 2420.0\n",
      "max_activation_accul updated: 348.00 at epoch 72, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['8.0000000'], tr/val_loss: 65.716270/ 83.042015, val:  50.00%, val_best:  75.88%, tr:  87.15%, tr_best:  89.91%, epoch time: 129.49 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 54.1266%\n",
      "layer   3  Sparsity: 93.7612%\n",
      "total_backward_count 1177344 real_backward_count 213882  18.166%\n",
      "layer   1  Sparsity: 80.5176%\n",
      "layer   2  Sparsity: 51.8750%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-73  lr=['8.0000000'], tr/val_loss: 65.989532/ 65.235046, val:  55.97%, val_best:  75.88%, tr:  88.72%, tr_best:  89.91%, epoch time: 130.77 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 54.1048%\n",
      "layer   3  Sparsity: 93.7832%\n",
      "total_backward_count 1193472 real_backward_count 216443  18.136%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-74  lr=['8.0000000'], tr/val_loss: 66.053619/ 63.638615, val:  60.62%, val_best:  75.88%, tr:  88.94%, tr_best:  89.91%, epoch time: 129.23 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 54.1456%\n",
      "layer   3  Sparsity: 93.7850%\n",
      "total_backward_count 1209600 real_backward_count 218988  18.104%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1878 occurrences\n",
      "train - Value 1: 2154 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-75  lr=['8.0000000'], tr/val_loss: 65.781853/ 59.284203, val:  74.78%, val_best:  75.88%, tr:  89.19%, tr_best:  89.91%, epoch time: 126.94 seconds, 2.12 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 54.1792%\n",
      "layer   3  Sparsity: 93.7821%\n",
      "total_backward_count 1225728 real_backward_count 221489  18.070%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1927 occurrences\n",
      "train - Value 1: 2105 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-76  lr=['8.0000000'], tr/val_loss: 64.912292/ 64.354683, val:  56.64%, val_best:  75.88%, tr:  87.43%, tr_best:  89.91%, epoch time: 129.33 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 54.1417%\n",
      "layer   3  Sparsity: 93.7545%\n",
      "total_backward_count 1241856 real_backward_count 223960  18.034%\n",
      "layer   1  Sparsity: 75.3418%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1820 occurrences\n",
      "train - Value 1: 2212 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-77  lr=['8.0000000'], tr/val_loss: 65.548950/ 63.733612, val:  51.33%, val_best:  75.88%, tr:  86.95%, tr_best:  89.91%, epoch time: 129.48 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.1004%\n",
      "layer   3  Sparsity: 93.8169%\n",
      "total_backward_count 1257984 real_backward_count 226568  18.010%\n",
      "layer   1  Sparsity: 76.5137%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-78  lr=['8.0000000'], tr/val_loss: 65.227112/ 65.547501, val:  58.63%, val_best:  75.88%, tr:  87.03%, tr_best:  89.91%, epoch time: 129.74 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 54.1325%\n",
      "layer   3  Sparsity: 93.7887%\n",
      "total_backward_count 1274112 real_backward_count 229145  17.985%\n",
      "layer   1  Sparsity: 83.9355%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-79  lr=['8.0000000'], tr/val_loss: 65.346252/ 62.088573, val:  59.07%, val_best:  75.88%, tr:  87.35%, tr_best:  89.91%, epoch time: 130.83 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 54.0953%\n",
      "layer   3  Sparsity: 93.7899%\n",
      "total_backward_count 1290240 real_backward_count 231730  17.960%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 55.5000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 2085 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 386 occurrences\n",
      "test - Value 1: 66 occurrences\n",
      "epoch-80  lr=['8.0000000'], tr/val_loss: 65.507385/ 63.463669, val:  62.39%, val_best:  75.88%, tr:  87.92%, tr_best:  89.91%, epoch time: 129.79 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 53.9415%\n",
      "layer   3  Sparsity: 93.7692%\n",
      "total_backward_count 1306368 real_backward_count 234274  17.933%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 2097 occurrences\n",
      "train - Value 1: 1935 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-81  lr=['8.0000000'], tr/val_loss: 65.609604/ 64.348679, val:  50.66%, val_best:  75.88%, tr:  88.72%, tr_best:  89.91%, epoch time: 130.04 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 53.9081%\n",
      "layer   3  Sparsity: 93.7440%\n",
      "total_backward_count 1322496 real_backward_count 236834  17.908%\n",
      "layer   1  Sparsity: 78.6621%\n",
      "layer   2  Sparsity: 49.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 2057 occurrences\n",
      "train - Value 1: 1975 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['8.0000000'], tr/val_loss: 65.530907/ 69.525139, val:  50.00%, val_best:  75.88%, tr:  90.15%, tr_best:  90.15%, epoch time: 130.86 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 53.8797%\n",
      "layer   3  Sparsity: 93.7590%\n",
      "total_backward_count 1338624 real_backward_count 239405  17.884%\n",
      "layer   1  Sparsity: 72.0703%\n",
      "layer   2  Sparsity: 48.1250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2138 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-83  lr=['8.0000000'], tr/val_loss: 65.589539/ 72.036850, val:  50.22%, val_best:  75.88%, tr:  89.14%, tr_best:  90.15%, epoch time: 129.25 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4827%\n",
      "layer   2  Sparsity: 53.8891%\n",
      "layer   3  Sparsity: 93.7831%\n",
      "total_backward_count 1354752 real_backward_count 241909  17.856%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 48.0000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-84  lr=['8.0000000'], tr/val_loss: 65.064873/ 69.150375, val:  50.44%, val_best:  75.88%, tr:  90.82%, tr_best:  90.82%, epoch time: 130.25 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 53.8835%\n",
      "layer   3  Sparsity: 93.7645%\n",
      "total_backward_count 1370880 real_backward_count 244377  17.826%\n",
      "layer   1  Sparsity: 71.7773%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 93.1250%\n",
      "train - Value 0: 1759 occurrences\n",
      "train - Value 1: 2273 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-85  lr=['8.0000000'], tr/val_loss: 65.337090/ 70.706024, val:  53.10%, val_best:  75.88%, tr:  87.67%, tr_best:  90.82%, epoch time: 130.09 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 53.9100%\n",
      "layer   3  Sparsity: 93.7726%\n",
      "total_backward_count 1387008 real_backward_count 246899  17.801%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 50.3750%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['8.0000000'], tr/val_loss: 65.786949/ 75.412956, val:  50.00%, val_best:  75.88%, tr:  89.76%, tr_best:  90.82%, epoch time: 129.65 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 53.8937%\n",
      "layer   3  Sparsity: 93.7933%\n",
      "total_backward_count 1403136 real_backward_count 249343  17.770%\n",
      "layer   1  Sparsity: 78.3203%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-87  lr=['8.0000000'], tr/val_loss: 65.623070/ 63.093273, val:  71.90%, val_best:  75.88%, tr:  88.17%, tr_best:  90.82%, epoch time: 130.87 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 53.8972%\n",
      "layer   3  Sparsity: 93.7746%\n",
      "total_backward_count 1419264 real_backward_count 251886  17.748%\n",
      "layer   1  Sparsity: 78.3691%\n",
      "layer   2  Sparsity: 55.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1881 occurrences\n",
      "train - Value 1: 2151 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-88  lr=['8.0000000'], tr/val_loss: 65.820641/ 66.198982, val:  61.06%, val_best:  75.88%, tr:  89.11%, tr_best:  90.82%, epoch time: 130.32 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 53.9823%\n",
      "layer   3  Sparsity: 93.8037%\n",
      "total_backward_count 1435392 real_backward_count 254317  17.718%\n",
      "layer   1  Sparsity: 91.2109%\n",
      "layer   2  Sparsity: 62.1250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-89  lr=['8.0000000'], tr/val_loss: 66.255196/ 64.476234, val:  55.53%, val_best:  75.88%, tr:  89.26%, tr_best:  90.82%, epoch time: 130.43 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4785%\n",
      "layer   2  Sparsity: 53.9365%\n",
      "layer   3  Sparsity: 93.7758%\n",
      "total_backward_count 1451520 real_backward_count 256915  17.700%\n",
      "layer   1  Sparsity: 83.2031%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-90  lr=['8.0000000'], tr/val_loss: 65.825180/ 70.641357, val:  50.00%, val_best:  75.88%, tr:  89.53%, tr_best:  90.82%, epoch time: 130.22 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 53.9455%\n",
      "layer   3  Sparsity: 93.7578%\n",
      "total_backward_count 1467648 real_backward_count 259421  17.676%\n",
      "layer   1  Sparsity: 81.2012%\n",
      "layer   2  Sparsity: 52.8750%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-91  lr=['8.0000000'], tr/val_loss: 66.375900/ 63.697464, val:  67.70%, val_best:  75.88%, tr:  88.96%, tr_best:  90.82%, epoch time: 129.98 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 53.9840%\n",
      "layer   3  Sparsity: 93.7975%\n",
      "total_backward_count 1483776 real_backward_count 261942  17.654%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1910 occurrences\n",
      "train - Value 1: 2122 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['8.0000000'], tr/val_loss: 65.011185/ 80.945023, val:  50.00%, val_best:  75.88%, tr:  87.80%, tr_best:  90.82%, epoch time: 129.60 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 53.9317%\n",
      "layer   3  Sparsity: 93.7799%\n",
      "total_backward_count 1499904 real_backward_count 264455  17.631%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 420 occurrences\n",
      "test - Value 1: 32 occurrences\n",
      "epoch-93  lr=['8.0000000'], tr/val_loss: 65.125435/ 64.742996, val:  57.08%, val_best:  75.88%, tr:  87.77%, tr_best:  90.82%, epoch time: 128.95 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 53.9300%\n",
      "layer   3  Sparsity: 93.7660%\n",
      "total_backward_count 1516032 real_backward_count 267015  17.613%\n",
      "layer   1  Sparsity: 75.1465%\n",
      "layer   2  Sparsity: 46.6250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1899 occurrences\n",
      "train - Value 1: 2133 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 398 occurrences\n",
      "test - Value 1: 54 occurrences\n",
      "epoch-94  lr=['8.0000000'], tr/val_loss: 65.571663/ 63.636772, val:  60.62%, val_best:  75.88%, tr:  87.48%, tr_best:  90.82%, epoch time: 130.73 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 53.9027%\n",
      "layer   3  Sparsity: 93.7905%\n",
      "total_backward_count 1532160 real_backward_count 269596  17.596%\n",
      "layer   1  Sparsity: 66.0645%\n",
      "layer   2  Sparsity: 49.8750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "fc layer 1 self.abs_max_out: 14387.0\n",
      "train - Value 0: 1864 occurrences\n",
      "train - Value 1: 2168 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 50 occurrences\n",
      "test - Value 1: 402 occurrences\n",
      "epoch-95  lr=['8.0000000'], tr/val_loss: 65.047302/ 64.443459, val:  60.62%, val_best:  75.88%, tr:  89.04%, tr_best:  90.82%, epoch time: 129.75 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 53.9302%\n",
      "layer   3  Sparsity: 93.7805%\n",
      "total_backward_count 1548288 real_backward_count 272064  17.572%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 95.6250%\n",
      "train - Value 0: 1879 occurrences\n",
      "train - Value 1: 2153 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-96  lr=['8.0000000'], tr/val_loss: 65.352852/ 68.990715, val:  50.22%, val_best:  75.88%, tr:  89.46%, tr_best:  90.82%, epoch time: 130.00 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 53.9180%\n",
      "layer   3  Sparsity: 93.7787%\n",
      "total_backward_count 1564416 real_backward_count 274549  17.550%\n",
      "layer   1  Sparsity: 65.7227%\n",
      "layer   2  Sparsity: 44.7500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "fc layer 1 self.abs_max_out: 14419.0\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 90 occurrences\n",
      "test - Value 1: 362 occurrences\n",
      "epoch-97  lr=['8.0000000'], tr/val_loss: 66.270706/ 63.471169, val:  66.81%, val_best:  75.88%, tr:  88.81%, tr_best:  90.82%, epoch time: 130.22 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 53.9295%\n",
      "layer   3  Sparsity: 93.7943%\n",
      "total_backward_count 1580544 real_backward_count 277153  17.535%\n",
      "layer   1  Sparsity: 71.1426%\n",
      "layer   2  Sparsity: 48.5000%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 363 occurrences\n",
      "test - Value 1: 89 occurrences\n",
      "epoch-98  lr=['8.0000000'], tr/val_loss: 65.685242/ 64.187691, val:  67.92%, val_best:  75.88%, tr:  89.96%, tr_best:  90.82%, epoch time: 129.54 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 53.9151%\n",
      "layer   3  Sparsity: 93.7748%\n",
      "total_backward_count 1596672 real_backward_count 279664  17.515%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1909 occurrences\n",
      "train - Value 1: 2123 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-99  lr=['8.0000000'], tr/val_loss: 65.484039/ 67.683067, val:  50.22%, val_best:  75.88%, tr:  91.00%, tr_best:  91.00%, epoch time: 131.05 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 53.9693%\n",
      "layer   3  Sparsity: 93.7675%\n",
      "total_backward_count 1612800 real_backward_count 282061  17.489%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 351.00 at epoch 100, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-100 lr=['8.0000000'], tr/val_loss: 65.375519/ 72.711472, val:  50.00%, val_best:  75.88%, tr:  88.44%, tr_best:  91.00%, epoch time: 130.39 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 53.9038%\n",
      "layer   3  Sparsity: 93.7929%\n",
      "total_backward_count 1628928 real_backward_count 284550  17.469%\n",
      "layer   1  Sparsity: 66.2109%\n",
      "layer   2  Sparsity: 47.3750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-101 lr=['8.0000000'], tr/val_loss: 65.223259/ 73.101738, val:  50.00%, val_best:  75.88%, tr:  88.34%, tr_best:  91.00%, epoch time: 129.43 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 53.9427%\n",
      "layer   3  Sparsity: 93.7682%\n",
      "total_backward_count 1645056 real_backward_count 287128  17.454%\n",
      "layer   1  Sparsity: 84.1309%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 361 occurrences\n",
      "test - Value 1: 91 occurrences\n",
      "epoch-102 lr=['8.0000000'], tr/val_loss: 65.363716/ 64.652061, val:  67.92%, val_best:  75.88%, tr:  89.78%, tr_best:  91.00%, epoch time: 129.83 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 53.9198%\n",
      "layer   3  Sparsity: 93.7734%\n",
      "total_backward_count 1661184 real_backward_count 289641  17.436%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 46.3750%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-103 lr=['8.0000000'], tr/val_loss: 65.556000/ 62.921276, val:  65.27%, val_best:  75.88%, tr:  89.73%, tr_best:  91.00%, epoch time: 130.00 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 53.9218%\n",
      "layer   3  Sparsity: 93.7769%\n",
      "total_backward_count 1677312 real_backward_count 292111  17.415%\n",
      "layer   1  Sparsity: 78.1250%\n",
      "layer   2  Sparsity: 52.0000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1880 occurrences\n",
      "train - Value 1: 2152 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['8.0000000'], tr/val_loss: 65.741135/ 73.290512, val:  50.00%, val_best:  75.88%, tr:  89.48%, tr_best:  91.00%, epoch time: 129.24 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 53.9632%\n",
      "layer   3  Sparsity: 93.7896%\n",
      "total_backward_count 1693440 real_backward_count 294673  17.401%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1779 occurrences\n",
      "train - Value 1: 2253 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['8.0000000'], tr/val_loss: 65.538658/ 71.634277, val:  50.00%, val_best:  75.88%, tr:  88.27%, tr_best:  91.00%, epoch time: 126.70 seconds, 2.11 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 53.9739%\n",
      "layer   3  Sparsity: 93.7946%\n",
      "total_backward_count 1709568 real_backward_count 297200  17.385%\n",
      "layer   1  Sparsity: 83.3496%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1902 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-106 lr=['8.0000000'], tr/val_loss: 65.710312/ 62.669193, val:  58.63%, val_best:  75.88%, tr:  88.79%, tr_best:  91.00%, epoch time: 129.18 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 53.8658%\n",
      "layer   3  Sparsity: 93.7843%\n",
      "total_backward_count 1725696 real_backward_count 299685  17.366%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "fc layer 3 self.abs_max_out: 128.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-107 lr=['8.0000000'], tr/val_loss: 60.588593/ 59.431126, val:  68.81%, val_best:  75.88%, tr:  91.32%, tr_best:  91.32%, epoch time: 129.71 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 53.8645%\n",
      "layer   3  Sparsity: 94.2556%\n",
      "total_backward_count 1741824 real_backward_count 302134  17.346%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 59.2500%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 3 self.abs_max_out: 129.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-108 lr=['8.0000000'], tr/val_loss: 60.683506/ 66.520828, val:  50.00%, val_best:  75.88%, tr:  91.34%, tr_best:  91.34%, epoch time: 129.46 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 53.8074%\n",
      "layer   3  Sparsity: 94.2282%\n",
      "total_backward_count 1757952 real_backward_count 304599  17.327%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 57.6250%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-109 lr=['8.0000000'], tr/val_loss: 60.622189/ 55.594734, val:  66.15%, val_best:  75.88%, tr:  89.63%, tr_best:  91.34%, epoch time: 130.44 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 53.9254%\n",
      "layer   3  Sparsity: 94.2286%\n",
      "total_backward_count 1774080 real_backward_count 307100  17.310%\n",
      "layer   1  Sparsity: 87.3047%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-110 lr=['8.0000000'], tr/val_loss: 60.349182/ 67.456696, val:  52.21%, val_best:  75.88%, tr:  90.23%, tr_best:  91.34%, epoch time: 129.41 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4793%\n",
      "layer   2  Sparsity: 53.9393%\n",
      "layer   3  Sparsity: 94.2443%\n",
      "total_backward_count 1790208 real_backward_count 309573  17.293%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-111 lr=['8.0000000'], tr/val_loss: 64.689026/ 67.681137, val:  50.00%, val_best:  75.88%, tr:  89.53%, tr_best:  91.34%, epoch time: 129.28 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 54.0092%\n",
      "layer   3  Sparsity: 93.8587%\n",
      "total_backward_count 1806336 real_backward_count 312091  17.278%\n",
      "layer   1  Sparsity: 77.4902%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1945 occurrences\n",
      "train - Value 1: 2087 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-112 lr=['8.0000000'], tr/val_loss: 64.276329/ 66.666611, val:  53.32%, val_best:  75.88%, tr:  90.20%, tr_best:  91.34%, epoch time: 130.29 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 53.9661%\n",
      "layer   3  Sparsity: 93.8718%\n",
      "total_backward_count 1822464 real_backward_count 314638  17.264%\n",
      "layer   1  Sparsity: 83.7891%\n",
      "layer   2  Sparsity: 52.8750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 360 occurrences\n",
      "test - Value 1: 92 occurrences\n",
      "epoch-113 lr=['8.0000000'], tr/val_loss: 62.516766/ 61.325165, val:  64.16%, val_best:  75.88%, tr:  89.53%, tr_best:  91.34%, epoch time: 129.93 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 53.9291%\n",
      "layer   3  Sparsity: 94.0337%\n",
      "total_backward_count 1838592 real_backward_count 317221  17.253%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-114 lr=['8.0000000'], tr/val_loss: 63.069870/ 64.137688, val:  59.96%, val_best:  75.88%, tr:  90.20%, tr_best:  91.34%, epoch time: 129.21 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 53.9715%\n",
      "layer   3  Sparsity: 93.9682%\n",
      "total_backward_count 1854720 real_backward_count 319761  17.240%\n",
      "layer   1  Sparsity: 75.1953%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 247 occurrences\n",
      "test - Value 1: 205 occurrences\n",
      "epoch-115 lr=['8.0000000'], tr/val_loss: 62.907516/ 57.861748, val:  78.98%, val_best:  78.98%, tr:  91.96%, tr_best:  91.96%, epoch time: 130.01 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 53.8152%\n",
      "layer   3  Sparsity: 94.0286%\n",
      "total_backward_count 1870848 real_backward_count 322259  17.225%\n",
      "layer   1  Sparsity: 85.5469%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 96.1250%\n",
      "train - Value 0: 1937 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-116 lr=['8.0000000'], tr/val_loss: 63.383953/ 61.454597, val:  53.54%, val_best:  78.98%, tr:  90.35%, tr_best:  91.96%, epoch time: 129.55 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 53.8745%\n",
      "layer   3  Sparsity: 93.9635%\n",
      "total_backward_count 1886976 real_backward_count 324834  17.215%\n",
      "layer   1  Sparsity: 69.0918%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 212 occurrences\n",
      "test - Value 1: 240 occurrences\n",
      "epoch-117 lr=['8.0000000'], tr/val_loss: 61.522690/ 57.506756, val:  80.53%, val_best:  80.53%, tr:  89.31%, tr_best:  91.96%, epoch time: 129.29 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4834%\n",
      "layer   2  Sparsity: 53.9111%\n",
      "layer   3  Sparsity: 94.0424%\n",
      "total_backward_count 1903104 real_backward_count 327379  17.202%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 54.6250%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 53 occurrences\n",
      "test - Value 1: 399 occurrences\n",
      "epoch-118 lr=['8.0000000'], tr/val_loss: 63.114979/ 60.486473, val:  60.84%, val_best:  80.53%, tr:  91.20%, tr_best:  91.96%, epoch time: 130.34 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 53.8538%\n",
      "layer   3  Sparsity: 93.9778%\n",
      "total_backward_count 1919232 real_backward_count 329876  17.188%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 60.1250%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 2447.0\n",
      "lif layer 2 self.abs_max_v: 2447.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 370 occurrences\n",
      "test - Value 1: 82 occurrences\n",
      "epoch-119 lr=['8.0000000'], tr/val_loss: 60.700409/ 56.767586, val:  62.39%, val_best:  80.53%, tr:  92.63%, tr_best:  92.63%, epoch time: 129.77 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 53.8357%\n",
      "layer   3  Sparsity: 94.1281%\n",
      "total_backward_count 1935360 real_backward_count 332267  17.168%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-120 lr=['8.0000000'], tr/val_loss: 62.127636/ 59.195240, val:  79.65%, val_best:  80.53%, tr:  91.59%, tr_best:  92.63%, epoch time: 130.40 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 53.9704%\n",
      "layer   3  Sparsity: 94.0514%\n",
      "total_backward_count 1951488 real_backward_count 334767  17.154%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['8.0000000'], tr/val_loss: 62.213032/ 69.599289, val:  50.00%, val_best:  80.53%, tr:  90.80%, tr_best:  92.63%, epoch time: 129.17 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 53.9416%\n",
      "layer   3  Sparsity: 94.0206%\n",
      "total_backward_count 1967616 real_backward_count 337372  17.146%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 30 occurrences\n",
      "test - Value 1: 422 occurrences\n",
      "epoch-122 lr=['8.0000000'], tr/val_loss: 63.328056/ 63.107151, val:  56.19%, val_best:  80.53%, tr:  89.88%, tr_best:  92.63%, epoch time: 129.64 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 53.9845%\n",
      "layer   3  Sparsity: 93.9279%\n",
      "total_backward_count 1983744 real_backward_count 339845  17.131%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-123 lr=['8.0000000'], tr/val_loss: 62.747036/ 58.045994, val:  75.22%, val_best:  80.53%, tr:  90.25%, tr_best:  92.63%, epoch time: 129.50 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 54.1476%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "total_backward_count 1999872 real_backward_count 342283  17.115%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 336 occurrences\n",
      "test - Value 1: 116 occurrences\n",
      "epoch-124 lr=['8.0000000'], tr/val_loss: 63.499031/ 61.169662, val:  69.03%, val_best:  80.53%, tr:  91.96%, tr_best:  92.63%, epoch time: 129.73 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 54.0624%\n",
      "layer   3  Sparsity: 93.9853%\n",
      "total_backward_count 2016000 real_backward_count 344780  17.102%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-125 lr=['8.0000000'], tr/val_loss: 63.511074/ 59.011360, val:  69.47%, val_best:  80.53%, tr:  91.07%, tr_best:  92.63%, epoch time: 129.89 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 54.0087%\n",
      "layer   3  Sparsity: 93.9916%\n",
      "total_backward_count 2032128 real_backward_count 347297  17.090%\n",
      "layer   1  Sparsity: 70.3125%\n",
      "layer   2  Sparsity: 49.8750%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1870 occurrences\n",
      "train - Value 1: 2162 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-126 lr=['8.0000000'], tr/val_loss: 62.682240/ 65.711250, val:  53.32%, val_best:  80.53%, tr:  92.56%, tr_best:  92.63%, epoch time: 129.51 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 54.1205%\n",
      "layer   3  Sparsity: 93.9915%\n",
      "total_backward_count 2048256 real_backward_count 349694  17.073%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1850 occurrences\n",
      "train - Value 1: 2182 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 323 occurrences\n",
      "test - Value 1: 129 occurrences\n",
      "epoch-127 lr=['8.0000000'], tr/val_loss: 63.422821/ 64.110535, val:  73.23%, val_best:  80.53%, tr:  89.93%, tr_best:  92.63%, epoch time: 130.14 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 54.3221%\n",
      "layer   3  Sparsity: 93.9775%\n",
      "total_backward_count 2064384 real_backward_count 352300  17.066%\n",
      "layer   1  Sparsity: 88.4277%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 94.7500%\n",
      "train - Value 0: 1917 occurrences\n",
      "train - Value 1: 2115 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 80 occurrences\n",
      "test - Value 1: 372 occurrences\n",
      "epoch-128 lr=['8.0000000'], tr/val_loss: 62.568562/ 60.987221, val:  66.37%, val_best:  80.53%, tr:  89.61%, tr_best:  92.63%, epoch time: 129.70 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.3833%\n",
      "layer   3  Sparsity: 93.9330%\n",
      "total_backward_count 2080512 real_backward_count 354714  17.049%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1891 occurrences\n",
      "train - Value 1: 2141 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 41 occurrences\n",
      "test - Value 1: 411 occurrences\n",
      "epoch-129 lr=['8.0000000'], tr/val_loss: 62.621307/ 59.729889, val:  59.07%, val_best:  80.53%, tr:  89.91%, tr_best:  92.63%, epoch time: 130.00 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 54.1741%\n",
      "layer   3  Sparsity: 93.9670%\n",
      "total_backward_count 2096640 real_backward_count 357153  17.035%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1815 occurrences\n",
      "train - Value 1: 2217 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-130 lr=['8.0000000'], tr/val_loss: 62.706909/ 61.788322, val:  82.96%, val_best:  82.96%, tr:  90.90%, tr_best:  92.63%, epoch time: 129.89 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.3586%\n",
      "layer   3  Sparsity: 94.0095%\n",
      "total_backward_count 2112768 real_backward_count 359655  17.023%\n",
      "layer   1  Sparsity: 87.7441%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 139 occurrences\n",
      "test - Value 1: 313 occurrences\n",
      "epoch-131 lr=['8.0000000'], tr/val_loss: 62.551075/ 60.152912, val:  72.35%, val_best:  82.96%, tr:  91.10%, tr_best:  92.63%, epoch time: 129.68 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 54.5393%\n",
      "layer   3  Sparsity: 94.0099%\n",
      "total_backward_count 2128896 real_backward_count 362033  17.006%\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-132 lr=['8.0000000'], tr/val_loss: 62.822353/ 59.143803, val:  51.55%, val_best:  82.96%, tr:  90.82%, tr_best:  92.63%, epoch time: 129.55 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4821%\n",
      "layer   2  Sparsity: 54.4474%\n",
      "layer   3  Sparsity: 93.9902%\n",
      "total_backward_count 2145024 real_backward_count 364451  16.991%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "fc layer 1 self.abs_max_out: 14505.0\n",
      "fc layer 3 self.abs_max_out: 130.0\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 294 occurrences\n",
      "test - Value 1: 158 occurrences\n",
      "epoch-133 lr=['8.0000000'], tr/val_loss: 63.565758/ 63.268223, val:  76.11%, val_best:  82.96%, tr:  91.12%, tr_best:  92.63%, epoch time: 129.13 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 54.4124%\n",
      "layer   3  Sparsity: 94.0224%\n",
      "total_backward_count 2161152 real_backward_count 366818  16.973%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 50.8750%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-134 lr=['8.0000000'], tr/val_loss: 63.767529/ 62.356728, val:  57.52%, val_best:  82.96%, tr:  91.72%, tr_best:  92.63%, epoch time: 128.86 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 54.3898%\n",
      "layer   3  Sparsity: 94.0269%\n",
      "total_backward_count 2177280 real_backward_count 369222  16.958%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 51.7500%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 170 occurrences\n",
      "test - Value 1: 282 occurrences\n",
      "epoch-135 lr=['8.0000000'], tr/val_loss: 61.482948/ 62.136230, val:  78.32%, val_best:  82.96%, tr:  90.80%, tr_best:  92.63%, epoch time: 127.65 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 54.3603%\n",
      "layer   3  Sparsity: 94.0593%\n",
      "total_backward_count 2193408 real_backward_count 371549  16.939%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 57.7500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1922 occurrences\n",
      "train - Value 1: 2110 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-136 lr=['8.0000000'], tr/val_loss: 62.877636/ 57.238880, val:  77.21%, val_best:  82.96%, tr:  90.43%, tr_best:  92.63%, epoch time: 129.59 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 54.4213%\n",
      "layer   3  Sparsity: 94.0441%\n",
      "total_backward_count 2209536 real_backward_count 373977  16.926%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-137 lr=['8.0000000'], tr/val_loss: 62.758892/ 64.121185, val:  56.42%, val_best:  82.96%, tr:  90.30%, tr_best:  92.63%, epoch time: 126.87 seconds, 2.11 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 54.3776%\n",
      "layer   3  Sparsity: 93.9846%\n",
      "total_backward_count 2225664 real_backward_count 376427  16.913%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1859 occurrences\n",
      "train - Value 1: 2173 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-138 lr=['8.0000000'], tr/val_loss: 62.591911/ 60.076580, val:  59.51%, val_best:  82.96%, tr:  90.95%, tr_best:  92.63%, epoch time: 129.93 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 54.4426%\n",
      "layer   3  Sparsity: 94.0263%\n",
      "total_backward_count 2241792 real_backward_count 378831  16.899%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-139 lr=['8.0000000'], tr/val_loss: 61.813633/ 66.952545, val:  58.63%, val_best:  82.96%, tr:  91.74%, tr_best:  92.63%, epoch time: 130.46 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 54.1952%\n",
      "layer   3  Sparsity: 94.0820%\n",
      "total_backward_count 2257920 real_backward_count 381231  16.884%\n",
      "layer   1  Sparsity: 93.6035%\n",
      "layer   2  Sparsity: 62.3750%\n",
      "layer   3  Sparsity: 94.7500%\n",
      "train - Value 0: 1850 occurrences\n",
      "train - Value 1: 2182 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 237 occurrences\n",
      "test - Value 1: 215 occurrences\n",
      "epoch-140 lr=['8.0000000'], tr/val_loss: 63.213860/ 61.973824, val:  79.42%, val_best:  82.96%, tr:  89.34%, tr_best:  92.63%, epoch time: 130.54 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 54.1914%\n",
      "layer   3  Sparsity: 93.9723%\n",
      "total_backward_count 2274048 real_backward_count 383743  16.875%\n",
      "layer   1  Sparsity: 77.4414%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-141 lr=['8.0000000'], tr/val_loss: 62.641384/ 63.811493, val:  64.60%, val_best:  82.96%, tr:  90.95%, tr_best:  92.63%, epoch time: 130.08 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 54.1500%\n",
      "layer   3  Sparsity: 94.0852%\n",
      "total_backward_count 2290176 real_backward_count 386312  16.868%\n",
      "layer   1  Sparsity: 69.9707%\n",
      "layer   2  Sparsity: 48.5000%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1904 occurrences\n",
      "train - Value 1: 2128 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 358.00 at epoch 142, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-142 lr=['8.0000000'], tr/val_loss: 63.253990/ 62.901093, val:  51.99%, val_best:  82.96%, tr:  91.67%, tr_best:  92.63%, epoch time: 130.27 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 54.1515%\n",
      "layer   3  Sparsity: 94.0599%\n",
      "total_backward_count 2306304 real_backward_count 388796  16.858%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 60.1250%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 70 occurrences\n",
      "test - Value 1: 382 occurrences\n",
      "epoch-143 lr=['8.0000000'], tr/val_loss: 62.648743/ 61.154671, val:  64.60%, val_best:  82.96%, tr:  89.83%, tr_best:  92.63%, epoch time: 130.65 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 53.9339%\n",
      "layer   3  Sparsity: 93.9987%\n",
      "total_backward_count 2322432 real_backward_count 391253  16.847%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 95.3750%\n",
      "train - Value 0: 1912 occurrences\n",
      "train - Value 1: 2120 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-144 lr=['8.0000000'], tr/val_loss: 62.720310/ 67.089325, val:  54.65%, val_best:  82.96%, tr:  90.48%, tr_best:  92.63%, epoch time: 130.32 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 54.2168%\n",
      "layer   3  Sparsity: 94.0177%\n",
      "total_backward_count 2338560 real_backward_count 393742  16.837%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 47.2500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-145 lr=['8.0000000'], tr/val_loss: 61.703991/ 58.081100, val:  71.02%, val_best:  82.96%, tr:  91.62%, tr_best:  92.63%, epoch time: 130.35 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 54.1580%\n",
      "layer   3  Sparsity: 94.0766%\n",
      "total_backward_count 2354688 real_backward_count 396174  16.825%\n",
      "layer   1  Sparsity: 73.2910%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-146 lr=['8.0000000'], tr/val_loss: 63.069580/ 61.606815, val:  55.97%, val_best:  82.96%, tr:  91.52%, tr_best:  92.63%, epoch time: 129.81 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 54.1432%\n",
      "layer   3  Sparsity: 93.9767%\n",
      "total_backward_count 2370816 real_backward_count 398598  16.813%\n",
      "layer   1  Sparsity: 79.8340%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-147 lr=['8.0000000'], tr/val_loss: 63.482616/ 60.465599, val:  66.59%, val_best:  82.96%, tr:  92.31%, tr_best:  92.63%, epoch time: 130.13 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 54.1537%\n",
      "layer   3  Sparsity: 93.9947%\n",
      "total_backward_count 2386944 real_backward_count 401014  16.800%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['8.0000000'], tr/val_loss: 63.421738/ 73.877380, val:  50.00%, val_best:  82.96%, tr:  91.25%, tr_best:  92.63%, epoch time: 130.90 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 54.2497%\n",
      "layer   3  Sparsity: 93.9958%\n",
      "total_backward_count 2403072 real_backward_count 403455  16.789%\n",
      "layer   1  Sparsity: 84.0820%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1937 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-149 lr=['8.0000000'], tr/val_loss: 63.004047/ 61.815491, val:  68.58%, val_best:  82.96%, tr:  91.25%, tr_best:  92.63%, epoch time: 130.58 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 54.3766%\n",
      "layer   3  Sparsity: 93.9827%\n",
      "total_backward_count 2419200 real_backward_count 405922  16.779%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-150 lr=['8.0000000'], tr/val_loss: 62.986557/ 61.088318, val:  59.51%, val_best:  82.96%, tr:  90.92%, tr_best:  92.63%, epoch time: 130.65 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 54.4157%\n",
      "layer   3  Sparsity: 94.0233%\n",
      "total_backward_count 2435328 real_backward_count 408351  16.768%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1898 occurrences\n",
      "train - Value 1: 2134 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['8.0000000'], tr/val_loss: 62.232357/ 68.301537, val:  50.00%, val_best:  82.96%, tr:  89.48%, tr_best:  92.63%, epoch time: 130.63 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 54.4387%\n",
      "layer   3  Sparsity: 93.9498%\n",
      "total_backward_count 2451456 real_backward_count 410738  16.755%\n",
      "layer   1  Sparsity: 83.0566%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1939 occurrences\n",
      "train - Value 1: 2093 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 400 occurrences\n",
      "test - Value 1: 52 occurrences\n",
      "epoch-152 lr=['8.0000000'], tr/val_loss: 63.517239/ 60.804840, val:  60.18%, val_best:  82.96%, tr:  91.64%, tr_best:  92.63%, epoch time: 130.07 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 54.5189%\n",
      "layer   3  Sparsity: 94.0131%\n",
      "total_backward_count 2467584 real_backward_count 413061  16.739%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-153 lr=['8.0000000'], tr/val_loss: 62.879364/ 62.482876, val:  79.65%, val_best:  82.96%, tr:  91.77%, tr_best:  92.63%, epoch time: 129.92 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 54.6704%\n",
      "layer   3  Sparsity: 94.0135%\n",
      "total_backward_count 2483712 real_backward_count 415418  16.726%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 48.7500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2114 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-154 lr=['8.0000000'], tr/val_loss: 62.994572/ 64.763840, val:  53.98%, val_best:  82.96%, tr:  91.67%, tr_best:  92.63%, epoch time: 130.91 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 54.3742%\n",
      "layer   3  Sparsity: 94.0332%\n",
      "total_backward_count 2499840 real_backward_count 417809  16.713%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-155 lr=['8.0000000'], tr/val_loss: 62.641941/ 58.361099, val:  64.60%, val_best:  82.96%, tr:  91.07%, tr_best:  92.63%, epoch time: 130.15 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 54.3527%\n",
      "layer   3  Sparsity: 94.0040%\n",
      "total_backward_count 2515968 real_backward_count 420128  16.698%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 96.0000%\n",
      "train - Value 0: 1905 occurrences\n",
      "train - Value 1: 2127 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-156 lr=['8.0000000'], tr/val_loss: 62.674183/ 61.424618, val:  75.00%, val_best:  82.96%, tr:  91.99%, tr_best:  92.63%, epoch time: 129.85 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 54.3469%\n",
      "layer   3  Sparsity: 94.0006%\n",
      "total_backward_count 2532096 real_backward_count 422502  16.686%\n",
      "layer   1  Sparsity: 74.5605%\n",
      "layer   2  Sparsity: 49.6250%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-157 lr=['8.0000000'], tr/val_loss: 63.583752/ 62.078949, val:  82.30%, val_best:  82.96%, tr:  91.22%, tr_best:  92.63%, epoch time: 129.93 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4822%\n",
      "layer   2  Sparsity: 54.3806%\n",
      "layer   3  Sparsity: 94.0019%\n",
      "total_backward_count 2548224 real_backward_count 424950  16.676%\n",
      "layer   1  Sparsity: 82.5684%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1905 occurrences\n",
      "train - Value 1: 2127 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['8.0000000'], tr/val_loss: 62.290077/ 64.147736, val:  50.00%, val_best:  82.96%, tr:  90.10%, tr_best:  92.63%, epoch time: 129.51 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 54.3887%\n",
      "layer   3  Sparsity: 94.0012%\n",
      "total_backward_count 2564352 real_backward_count 427416  16.668%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-159 lr=['8.0000000'], tr/val_loss: 62.348358/ 69.607460, val:  53.76%, val_best:  82.96%, tr:  91.49%, tr_best:  92.63%, epoch time: 129.73 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 54.4682%\n",
      "layer   3  Sparsity: 94.0233%\n",
      "total_backward_count 2580480 real_backward_count 429765  16.654%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-160 lr=['8.0000000'], tr/val_loss: 64.426689/ 63.267654, val:  59.96%, val_best:  82.96%, tr:  93.20%, tr_best:  93.20%, epoch time: 129.94 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 54.4378%\n",
      "layer   3  Sparsity: 93.9459%\n",
      "total_backward_count 2596608 real_backward_count 432175  16.644%\n",
      "layer   1  Sparsity: 62.3535%\n",
      "layer   2  Sparsity: 49.5000%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-161 lr=['8.0000000'], tr/val_loss: 63.640697/ 72.724503, val:  50.22%, val_best:  82.96%, tr:  90.60%, tr_best:  93.20%, epoch time: 129.83 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 54.3357%\n",
      "layer   3  Sparsity: 94.0172%\n",
      "total_backward_count 2612736 real_backward_count 434682  16.637%\n",
      "layer   1  Sparsity: 92.2852%\n",
      "layer   2  Sparsity: 71.0000%\n",
      "layer   3  Sparsity: 95.7500%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 330 occurrences\n",
      "test - Value 1: 122 occurrences\n",
      "epoch-162 lr=['8.0000000'], tr/val_loss: 63.273762/ 56.644157, val:  71.24%, val_best:  82.96%, tr:  92.41%, tr_best:  93.20%, epoch time: 130.58 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 54.3145%\n",
      "layer   3  Sparsity: 94.0115%\n",
      "total_backward_count 2628864 real_backward_count 437025  16.624%\n",
      "layer   1  Sparsity: 73.5840%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-163 lr=['8.0000000'], tr/val_loss: 64.423050/ 60.524475, val:  80.31%, val_best:  82.96%, tr:  91.64%, tr_best:  93.20%, epoch time: 129.16 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 54.2693%\n",
      "layer   3  Sparsity: 94.0229%\n",
      "total_backward_count 2644992 real_backward_count 439406  16.613%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-164 lr=['8.0000000'], tr/val_loss: 62.763607/ 57.167187, val:  66.59%, val_best:  82.96%, tr:  91.20%, tr_best:  93.20%, epoch time: 128.91 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 54.1927%\n",
      "layer   3  Sparsity: 93.9998%\n",
      "total_backward_count 2661120 real_backward_count 441860  16.604%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 236 occurrences\n",
      "test - Value 1: 216 occurrences\n",
      "epoch-165 lr=['8.0000000'], tr/val_loss: 62.588470/ 57.723759, val:  80.09%, val_best:  82.96%, tr:  91.99%, tr_best:  93.20%, epoch time: 129.78 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 54.2609%\n",
      "layer   3  Sparsity: 94.0076%\n",
      "total_backward_count 2677248 real_backward_count 444258  16.594%\n",
      "layer   1  Sparsity: 72.4609%\n",
      "layer   2  Sparsity: 50.3750%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 56 occurrences\n",
      "test - Value 1: 396 occurrences\n",
      "epoch-166 lr=['8.0000000'], tr/val_loss: 62.337067/ 60.002556, val:  61.95%, val_best:  82.96%, tr:  90.25%, tr_best:  93.20%, epoch time: 129.17 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 54.2786%\n",
      "layer   3  Sparsity: 94.0001%\n",
      "total_backward_count 2693376 real_backward_count 446676  16.584%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 59.6250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1900 occurrences\n",
      "train - Value 1: 2132 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['8.0000000'], tr/val_loss: 62.588535/ 72.734825, val:  50.00%, val_best:  82.96%, tr:  90.48%, tr_best:  93.20%, epoch time: 126.75 seconds, 2.11 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 54.3303%\n",
      "layer   3  Sparsity: 93.9820%\n",
      "total_backward_count 2709504 real_backward_count 449123  16.576%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 53.0000%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-168 lr=['8.0000000'], tr/val_loss: 62.981785/ 65.420944, val:  56.42%, val_best:  82.96%, tr:  92.21%, tr_best:  93.20%, epoch time: 125.72 seconds, 2.10 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 54.4802%\n",
      "layer   3  Sparsity: 94.0430%\n",
      "total_backward_count 2725632 real_backward_count 451549  16.567%\n",
      "layer   1  Sparsity: 89.4531%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 94.6250%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 248 occurrences\n",
      "test - Value 1: 204 occurrences\n",
      "epoch-169 lr=['8.0000000'], tr/val_loss: 63.925926/ 62.279743, val:  79.20%, val_best:  82.96%, tr:  92.09%, tr_best:  93.20%, epoch time: 128.73 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 54.6090%\n",
      "layer   3  Sparsity: 94.0550%\n",
      "total_backward_count 2741760 real_backward_count 454020  16.559%\n",
      "layer   1  Sparsity: 76.3672%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-170 lr=['8.0000000'], tr/val_loss: 63.524982/ 68.329750, val:  56.86%, val_best:  82.96%, tr:  92.14%, tr_best:  93.20%, epoch time: 129.07 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4818%\n",
      "layer   2  Sparsity: 54.6074%\n",
      "layer   3  Sparsity: 94.0122%\n",
      "total_backward_count 2757888 real_backward_count 456447  16.551%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "fc layer 3 self.abs_max_out: 133.0\n",
      "fc layer 1 self.abs_max_out: 14516.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 243 occurrences\n",
      "test - Value 1: 209 occurrences\n",
      "epoch-171 lr=['8.0000000'], tr/val_loss: 61.715446/ 60.598881, val:  81.64%, val_best:  82.96%, tr:  89.88%, tr_best:  93.20%, epoch time: 129.48 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 54.5276%\n",
      "layer   3  Sparsity: 94.0294%\n",
      "total_backward_count 2774016 real_backward_count 458888  16.542%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 234 occurrences\n",
      "test - Value 1: 218 occurrences\n",
      "epoch-172 lr=['8.0000000'], tr/val_loss: 63.055347/ 58.345604, val:  79.65%, val_best:  82.96%, tr:  91.10%, tr_best:  93.20%, epoch time: 130.68 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 54.5180%\n",
      "layer   3  Sparsity: 94.0131%\n",
      "total_backward_count 2790144 real_backward_count 461383  16.536%\n",
      "layer   1  Sparsity: 85.1562%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 254 occurrences\n",
      "test - Value 1: 198 occurrences\n",
      "epoch-173 lr=['8.0000000'], tr/val_loss: 62.133720/ 61.661190, val:  80.97%, val_best:  82.96%, tr:  91.44%, tr_best:  93.20%, epoch time: 130.14 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 54.6310%\n",
      "layer   3  Sparsity: 93.9650%\n",
      "total_backward_count 2806272 real_backward_count 463702  16.524%\n",
      "layer   1  Sparsity: 93.4082%\n",
      "layer   2  Sparsity: 72.7500%\n",
      "layer   3  Sparsity: 95.8750%\n",
      "train - Value 0: 1953 occurrences\n",
      "train - Value 1: 2079 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-174 lr=['8.0000000'], tr/val_loss: 62.662056/ 78.943535, val:  50.00%, val_best:  82.96%, tr:  91.20%, tr_best:  93.20%, epoch time: 129.88 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4780%\n",
      "layer   2  Sparsity: 54.4858%\n",
      "layer   3  Sparsity: 94.0852%\n",
      "total_backward_count 2822400 real_backward_count 466158  16.516%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 94.6250%\n",
      "train - Value 0: 1928 occurrences\n",
      "train - Value 1: 2104 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 365.00 at epoch 175, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['8.0000000'], tr/val_loss: 63.374386/ 69.183563, val:  50.00%, val_best:  82.96%, tr:  91.17%, tr_best:  93.20%, epoch time: 130.13 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 54.3207%\n",
      "layer   3  Sparsity: 94.0115%\n",
      "total_backward_count 2838528 real_backward_count 468550  16.507%\n",
      "layer   1  Sparsity: 73.7793%\n",
      "layer   2  Sparsity: 51.3750%\n",
      "layer   3  Sparsity: 93.7500%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-176 lr=['8.0000000'], tr/val_loss: 62.572758/ 62.375378, val:  51.77%, val_best:  82.96%, tr:  92.24%, tr_best:  93.20%, epoch time: 129.58 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 54.3433%\n",
      "layer   3  Sparsity: 94.0600%\n",
      "total_backward_count 2854656 real_backward_count 470999  16.499%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 312 occurrences\n",
      "test - Value 1: 140 occurrences\n",
      "epoch-177 lr=['8.0000000'], tr/val_loss: 62.096745/ 62.228455, val:  75.22%, val_best:  82.96%, tr:  91.62%, tr_best:  93.20%, epoch time: 128.25 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 54.0271%\n",
      "layer   3  Sparsity: 93.9981%\n",
      "total_backward_count 2870784 real_backward_count 473456  16.492%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 93.1250%\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 380 occurrences\n",
      "test - Value 1: 72 occurrences\n",
      "epoch-178 lr=['8.0000000'], tr/val_loss: 63.803280/ 61.969025, val:  60.18%, val_best:  82.96%, tr:  91.82%, tr_best:  93.20%, epoch time: 129.74 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 54.1326%\n",
      "layer   3  Sparsity: 93.9820%\n",
      "total_backward_count 2886912 real_backward_count 475906  16.485%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 53.5000%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1892 occurrences\n",
      "train - Value 1: 2140 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-179 lr=['8.0000000'], tr/val_loss: 63.469563/ 61.692646, val:  66.81%, val_best:  82.96%, tr:  91.57%, tr_best:  93.20%, epoch time: 129.85 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 54.0188%\n",
      "layer   3  Sparsity: 94.0267%\n",
      "total_backward_count 2903040 real_backward_count 478462  16.481%\n",
      "layer   1  Sparsity: 70.6543%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 94.2500%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-180 lr=['8.0000000'], tr/val_loss: 62.889153/ 62.319435, val:  65.27%, val_best:  82.96%, tr:  90.92%, tr_best:  93.20%, epoch time: 130.20 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 54.1597%\n",
      "layer   3  Sparsity: 93.9707%\n",
      "total_backward_count 2919168 real_backward_count 480859  16.472%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2108 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-181 lr=['8.0000000'], tr/val_loss: 63.246380/ 63.089249, val:  55.31%, val_best:  82.96%, tr:  91.32%, tr_best:  93.20%, epoch time: 129.81 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 54.2475%\n",
      "layer   3  Sparsity: 93.9978%\n",
      "total_backward_count 2935296 real_backward_count 483351  16.467%\n",
      "layer   1  Sparsity: 57.8125%\n",
      "layer   2  Sparsity: 48.2500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 256 occurrences\n",
      "test - Value 1: 196 occurrences\n",
      "epoch-182 lr=['8.0000000'], tr/val_loss: 63.254765/ 60.365128, val:  79.20%, val_best:  82.96%, tr:  92.71%, tr_best:  93.20%, epoch time: 129.77 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 54.3437%\n",
      "layer   3  Sparsity: 94.0028%\n",
      "total_backward_count 2951424 real_backward_count 485752  16.458%\n",
      "layer   1  Sparsity: 77.8809%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 94.6250%\n",
      "train - Value 0: 1937 occurrences\n",
      "train - Value 1: 2095 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-183 lr=['8.0000000'], tr/val_loss: 63.625744/ 59.048691, val:  56.86%, val_best:  82.96%, tr:  91.39%, tr_best:  93.20%, epoch time: 129.95 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 54.4224%\n",
      "layer   3  Sparsity: 94.0115%\n",
      "total_backward_count 2967552 real_backward_count 488194  16.451%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 48.7500%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['8.0000000'], tr/val_loss: 62.207661/ 67.467850, val:  50.00%, val_best:  82.96%, tr:  90.20%, tr_best:  93.20%, epoch time: 129.19 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 54.3194%\n",
      "layer   3  Sparsity: 93.9606%\n",
      "total_backward_count 2983680 real_backward_count 490637  16.444%\n",
      "layer   1  Sparsity: 85.8887%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 94.5000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-185 lr=['8.0000000'], tr/val_loss: 62.831020/ 59.810997, val:  55.97%, val_best:  82.96%, tr:  91.44%, tr_best:  93.20%, epoch time: 129.94 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 54.0977%\n",
      "layer   3  Sparsity: 94.0074%\n",
      "total_backward_count 2999808 real_backward_count 493109  16.438%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 93.1250%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-186 lr=['8.0000000'], tr/val_loss: 62.118935/ 60.276867, val:  75.44%, val_best:  82.96%, tr:  89.48%, tr_best:  93.20%, epoch time: 129.65 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 54.0959%\n",
      "layer   3  Sparsity: 93.9837%\n",
      "total_backward_count 3015936 real_backward_count 495556  16.431%\n",
      "layer   1  Sparsity: 80.0781%\n",
      "layer   2  Sparsity: 52.2500%\n",
      "layer   3  Sparsity: 94.1250%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['8.0000000'], tr/val_loss: 63.387959/ 72.769745, val:  50.00%, val_best:  82.96%, tr:  92.56%, tr_best:  93.20%, epoch time: 129.43 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 54.1771%\n",
      "layer   3  Sparsity: 93.9992%\n",
      "total_backward_count 3032064 real_backward_count 497993  16.424%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 130 occurrences\n",
      "test - Value 1: 322 occurrences\n",
      "epoch-188 lr=['8.0000000'], tr/val_loss: 62.039978/ 58.857204, val:  74.34%, val_best:  82.96%, tr:  91.79%, tr_best:  93.20%, epoch time: 129.84 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 54.1930%\n",
      "layer   3  Sparsity: 94.0306%\n",
      "total_backward_count 3048192 real_backward_count 500231  16.411%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 48.0000%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-189 lr=['8.0000000'], tr/val_loss: 63.228989/ 64.721046, val:  58.41%, val_best:  82.96%, tr:  90.92%, tr_best:  93.20%, epoch time: 130.04 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 54.1377%\n",
      "layer   3  Sparsity: 93.9671%\n",
      "total_backward_count 3064320 real_backward_count 502697  16.405%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 53.3750%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-190 lr=['8.0000000'], tr/val_loss: 62.174133/ 57.255558, val:  71.24%, val_best:  82.96%, tr:  91.52%, tr_best:  93.20%, epoch time: 129.09 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 54.1858%\n",
      "layer   3  Sparsity: 94.0350%\n",
      "total_backward_count 3080448 real_backward_count 505124  16.398%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 46.0000%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-191 lr=['8.0000000'], tr/val_loss: 62.335251/ 60.633839, val:  66.37%, val_best:  82.96%, tr:  91.39%, tr_best:  93.20%, epoch time: 129.03 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 54.2579%\n",
      "layer   3  Sparsity: 94.0140%\n",
      "total_backward_count 3096576 real_backward_count 507487  16.389%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 93.6250%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-192 lr=['8.0000000'], tr/val_loss: 62.648109/ 60.486320, val:  78.32%, val_best:  82.96%, tr:  90.23%, tr_best:  93.20%, epoch time: 127.79 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.1131%\n",
      "layer   3  Sparsity: 94.0161%\n",
      "total_backward_count 3112704 real_backward_count 509880  16.381%\n",
      "layer   1  Sparsity: 57.6660%\n",
      "layer   2  Sparsity: 47.0000%\n",
      "layer   3  Sparsity: 93.3750%\n",
      "fc layer 1 self.abs_max_out: 14532.0\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['8.0000000'], tr/val_loss: 62.367699/ 70.976036, val:  50.00%, val_best:  82.96%, tr:  90.77%, tr_best:  93.20%, epoch time: 128.52 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 54.1696%\n",
      "layer   3  Sparsity: 93.9630%\n",
      "total_backward_count 3128832 real_backward_count 512253  16.372%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 51.0000%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 33 occurrences\n",
      "test - Value 1: 419 occurrences\n",
      "epoch-194 lr=['8.0000000'], tr/val_loss: 61.927235/ 60.940071, val:  56.42%, val_best:  82.96%, tr:  89.09%, tr_best:  93.20%, epoch time: 129.21 seconds, 2.15 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 54.0499%\n",
      "layer   3  Sparsity: 93.9862%\n",
      "total_backward_count 3144960 real_backward_count 514818  16.370%\n",
      "layer   1  Sparsity: 88.2324%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 94.3750%\n",
      "fc layer 3 self.abs_max_out: 135.0\n",
      "train - Value 0: 1917 occurrences\n",
      "train - Value 1: 2115 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 35 occurrences\n",
      "test - Value 1: 417 occurrences\n",
      "epoch-195 lr=['8.0000000'], tr/val_loss: 63.154793/ 62.576813, val:  57.30%, val_best:  82.96%, tr:  90.70%, tr_best:  93.20%, epoch time: 129.51 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 54.1006%\n",
      "layer   3  Sparsity: 94.0088%\n",
      "total_backward_count 3161088 real_backward_count 517385  16.367%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 52.6250%\n",
      "layer   3  Sparsity: 94.0000%\n",
      "train - Value 0: 1944 occurrences\n",
      "train - Value 1: 2088 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 366.00 at epoch 196, iter 4031\n",
      "max_activation_accul updated: 370.00 at epoch 196, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['8.0000000'], tr/val_loss: 62.901100/ 73.233131, val:  50.00%, val_best:  82.96%, tr:  91.12%, tr_best:  93.20%, epoch time: 129.40 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 54.2156%\n",
      "layer   3  Sparsity: 94.0178%\n",
      "total_backward_count 3177216 real_backward_count 519832  16.361%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 93.8750%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-197 lr=['8.0000000'], tr/val_loss: 62.940094/ 62.060036, val:  60.84%, val_best:  82.96%, tr:  90.75%, tr_best:  93.20%, epoch time: 128.55 seconds, 2.14 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 54.2537%\n",
      "layer   3  Sparsity: 94.0209%\n",
      "total_backward_count 3193344 real_backward_count 522310  16.356%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 49.6250%\n",
      "layer   3  Sparsity: 93.2500%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-198 lr=['8.0000000'], tr/val_loss: 62.793285/ 59.014473, val:  78.32%, val_best:  82.96%, tr:  92.09%, tr_best:  93.20%, epoch time: 127.72 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 54.1840%\n",
      "layer   3  Sparsity: 94.0003%\n",
      "total_backward_count 3209472 real_backward_count 524684  16.348%\n",
      "layer   1  Sparsity: 69.7754%\n",
      "layer   2  Sparsity: 51.2500%\n",
      "layer   3  Sparsity: 93.5000%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 231 occurrences\n",
      "test - Value 1: 221 occurrences\n",
      "epoch-199 lr=['8.0000000'], tr/val_loss: 63.379372/ 61.074795, val:  76.33%, val_best:  82.96%, tr:  90.97%, tr_best:  93.20%, epoch time: 130.37 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 54.3190%\n",
      "layer   3  Sparsity: 93.9678%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1236861da847f08872fb9cb38a8598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÅ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.90972</td></tr><tr><td>tr_epoch_loss</td><td>63.37937</td></tr><tr><td>val_acc_best</td><td>0.82965</td></tr><tr><td>val_acc_now</td><td>0.76327</td></tr><tr><td>val_loss</td><td>61.07479</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peachy-sweep-36</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eaqw792e' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/eaqw792e</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251212_041826-eaqw792e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8ktezvip with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251212_113229-8ktezvip</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/8ktezvip' target=\"_blank\">honest-sweep-37</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/8ktezvip' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/8ktezvip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251212_113239_612', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 2048, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 0.125, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 8, 'lif_layer_v_threshold2': 32, 'init_scaling': [0.125, 0.25, 0.0625], 'learning_rate': 8, 'learning_rate2': 2, 'loser_encourage_mode': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 0.125, self.v_threshold 2048\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 8, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.0625])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=2048, v_reset=10000, sg_width=0.125, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.0625])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=8, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.0625])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 8\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 279.0\n",
      "lif layer 1 self.abs_max_v: 279.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 1 self.abs_max_out: 428.0\n",
      "lif layer 1 self.abs_max_v: 514.0\n",
      "lif layer 1 self.abs_max_v: 598.0\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "fc layer 1 self.abs_max_out: 455.0\n",
      "fc layer 1 self.abs_max_out: 644.0\n",
      "lif layer 1 self.abs_max_v: 644.0\n",
      "fc layer 1 self.abs_max_out: 1340.0\n",
      "lif layer 1 self.abs_max_v: 1618.0\n",
      "fc layer 1 self.abs_max_out: 2590.0\n",
      "lif layer 1 self.abs_max_v: 2590.5\n",
      "fc layer 2 self.abs_max_out: 214.0\n",
      "lif layer 2 self.abs_max_v: 214.0\n",
      "fc layer 3 self.abs_max_out: 72.0\n",
      "fc layer 1 self.abs_max_out: 2834.0\n",
      "lif layer 1 self.abs_max_v: 2857.0\n",
      "fc layer 2 self.abs_max_out: 246.0\n",
      "lif layer 2 self.abs_max_v: 246.0\n",
      "fc layer 3 self.abs_max_out: 74.0\n",
      "fc layer 1 self.abs_max_out: 3745.0\n",
      "lif layer 1 self.abs_max_v: 4399.0\n",
      "lif layer 2 self.abs_max_v: 266.5\n",
      "fc layer 1 self.abs_max_out: 4240.0\n",
      "lif layer 1 self.abs_max_v: 4451.5\n",
      "fc layer 3 self.abs_max_out: 90.0\n",
      "fc layer 3 self.abs_max_out: 96.0\n",
      "fc layer 1 self.abs_max_out: 4472.0\n",
      "lif layer 1 self.abs_max_v: 4472.0\n",
      "fc layer 1 self.abs_max_out: 4833.0\n",
      "lif layer 1 self.abs_max_v: 6832.0\n",
      "lif layer 2 self.abs_max_v: 319.5\n",
      "fc layer 1 self.abs_max_out: 5105.0\n",
      "lif layer 1 self.abs_max_v: 8449.0\n",
      "fc layer 2 self.abs_max_out: 247.0\n",
      "lif layer 2 self.abs_max_v: 373.0\n",
      "lif layer 2 self.abs_max_v: 399.5\n",
      "fc layer 1 self.abs_max_out: 6200.0\n",
      "fc layer 3 self.abs_max_out: 99.0\n",
      "fc layer 1 self.abs_max_out: 7100.0\n",
      "lif layer 1 self.abs_max_v: 8879.0\n",
      "lif layer 1 self.abs_max_v: 9125.0\n",
      "lif layer 1 self.abs_max_v: 9877.5\n",
      "fc layer 1 self.abs_max_out: 7425.0\n",
      "fc layer 2 self.abs_max_out: 289.0\n",
      "lif layer 2 self.abs_max_v: 402.0\n",
      "fc layer 3 self.abs_max_out: 104.0\n",
      "lif layer 2 self.abs_max_v: 408.0\n",
      "fc layer 1 self.abs_max_out: 7724.0\n",
      "lif layer 1 self.abs_max_v: 10822.5\n",
      "lif layer 2 self.abs_max_v: 421.5\n",
      "lif layer 2 self.abs_max_v: 426.0\n",
      "lif layer 2 self.abs_max_v: 446.0\n",
      "fc layer 1 self.abs_max_out: 8699.0\n",
      "fc layer 3 self.abs_max_out: 114.0\n",
      "fc layer 2 self.abs_max_out: 303.0\n",
      "lif layer 2 self.abs_max_v: 449.0\n",
      "lif layer 1 self.abs_max_v: 10986.5\n",
      "fc layer 2 self.abs_max_out: 327.0\n",
      "lif layer 1 self.abs_max_v: 12435.5\n",
      "fc layer 2 self.abs_max_out: 413.0\n",
      "lif layer 2 self.abs_max_v: 465.5\n",
      "lif layer 1 self.abs_max_v: 12769.0\n",
      "lif layer 2 self.abs_max_v: 472.5\n",
      "fc layer 2 self.abs_max_out: 449.0\n",
      "lif layer 2 self.abs_max_v: 597.0\n",
      "fc layer 2 self.abs_max_out: 526.0\n",
      "lif layer 2 self.abs_max_v: 646.0\n",
      "fc layer 1 self.abs_max_out: 9015.0\n",
      "fc layer 1 self.abs_max_out: 11133.0\n",
      "lif layer 1 self.abs_max_v: 13369.5\n",
      "lif layer 1 self.abs_max_v: 14071.0\n",
      "lif layer 2 self.abs_max_v: 646.5\n",
      "lif layer 2 self.abs_max_v: 809.0\n",
      "fc layer 1 self.abs_max_out: 11186.0\n",
      "fc layer 2 self.abs_max_out: 559.0\n",
      "fc layer 1 self.abs_max_out: 11338.0\n",
      "fc layer 1 self.abs_max_out: 11644.0\n",
      "lif layer 1 self.abs_max_v: 15813.5\n",
      "lif layer 1 self.abs_max_v: 17538.5\n",
      "fc layer 1 self.abs_max_out: 14150.0\n",
      "fc layer 2 self.abs_max_out: 574.0\n",
      "fc layer 2 self.abs_max_out: 576.0\n",
      "fc layer 2 self.abs_max_out: 578.0\n",
      "fc layer 2 self.abs_max_out: 602.0\n",
      "fc layer 2 self.abs_max_out: 660.0\n",
      "fc layer 2 self.abs_max_out: 671.0\n",
      "fc layer 2 self.abs_max_out: 709.0\n",
      "fc layer 2 self.abs_max_out: 747.0\n",
      "lif layer 2 self.abs_max_v: 842.0\n",
      "fc layer 2 self.abs_max_out: 773.0\n",
      "fc layer 2 self.abs_max_out: 780.0\n",
      "fc layer 3 self.abs_max_out: 124.0\n",
      "fc layer 2 self.abs_max_out: 807.0\n",
      "lif layer 2 self.abs_max_v: 863.0\n",
      "lif layer 2 self.abs_max_v: 904.0\n",
      "fc layer 1 self.abs_max_out: 16207.0\n",
      "lif layer 1 self.abs_max_v: 17588.5\n",
      "fc layer 2 self.abs_max_out: 809.0\n",
      "lif layer 2 self.abs_max_v: 929.0\n",
      "fc layer 1 self.abs_max_out: 16367.0\n",
      "lif layer 1 self.abs_max_v: 18903.5\n",
      "lif layer 1 self.abs_max_v: 22628.0\n",
      "lif layer 2 self.abs_max_v: 1017.5\n",
      "lif layer 2 self.abs_max_v: 1077.0\n",
      "fc layer 1 self.abs_max_out: 16781.0\n",
      "fc layer 1 self.abs_max_out: 16826.0\n",
      "fc layer 3 self.abs_max_out: 125.0\n",
      "fc layer 1 self.abs_max_out: 17118.0\n",
      "fc layer 1 self.abs_max_out: 17179.0\n",
      "fc layer 1 self.abs_max_out: 18278.0\n",
      "fc layer 1 self.abs_max_out: 18917.0\n",
      "fc layer 1 self.abs_max_out: 19027.0\n",
      "fc layer 2 self.abs_max_out: 811.0\n",
      "fc layer 2 self.abs_max_out: 813.0\n",
      "fc layer 2 self.abs_max_out: 843.0\n",
      "lif layer 2 self.abs_max_v: 1124.5\n",
      "fc layer 2 self.abs_max_out: 928.0\n",
      "fc layer 2 self.abs_max_out: 966.0\n",
      "fc layer 2 self.abs_max_out: 972.0\n",
      "fc layer 2 self.abs_max_out: 990.0\n",
      "fc layer 1 self.abs_max_out: 19522.0\n",
      "lif layer 2 self.abs_max_v: 1158.0\n",
      "fc layer 1 self.abs_max_out: 20138.0\n",
      "fc layer 2 self.abs_max_out: 1020.0\n",
      "fc layer 2 self.abs_max_out: 1058.0\n",
      "fc layer 1 self.abs_max_out: 20388.0\n",
      "fc layer 1 self.abs_max_out: 20784.0\n",
      "lif layer 1 self.abs_max_v: 26099.5\n",
      "lif layer 2 self.abs_max_v: 1159.5\n",
      "lif layer 2 self.abs_max_v: 1173.0\n",
      "fc layer 1 self.abs_max_out: 20800.0\n",
      "fc layer 1 self.abs_max_out: 21094.0\n",
      "lif layer 2 self.abs_max_v: 1174.0\n",
      "lif layer 2 self.abs_max_v: 1214.0\n",
      "fc layer 1 self.abs_max_out: 21197.0\n",
      "fc layer 1 self.abs_max_out: 23051.0\n",
      "lif layer 2 self.abs_max_v: 1267.0\n",
      "lif layer 2 self.abs_max_v: 1351.0\n",
      "lif layer 2 self.abs_max_v: 1369.0\n",
      "fc layer 2 self.abs_max_out: 1337.0\n",
      "lif layer 2 self.abs_max_v: 1394.5\n",
      "lif layer 2 self.abs_max_v: 1411.5\n",
      "lif layer 2 self.abs_max_v: 1556.0\n",
      "lif layer 2 self.abs_max_v: 1572.5\n",
      "lif layer 2 self.abs_max_v: 1593.5\n",
      "lif layer 2 self.abs_max_v: 1639.5\n",
      "lif layer 2 self.abs_max_v: 1646.0\n",
      "lif layer 2 self.abs_max_v: 1733.0\n",
      "lif layer 1 self.abs_max_v: 26703.5\n",
      "fc layer 2 self.abs_max_out: 1346.0\n",
      "fc layer 2 self.abs_max_out: 1351.0\n",
      "fc layer 1 self.abs_max_out: 23894.0\n",
      "lif layer 1 self.abs_max_v: 30156.5\n",
      "lif layer 1 self.abs_max_v: 33219.0\n",
      "lif layer 2 self.abs_max_v: 1929.0\n",
      "fc layer 1 self.abs_max_out: 23963.0\n",
      "fc layer 1 self.abs_max_out: 24217.0\n",
      "fc layer 2 self.abs_max_out: 1378.0\n",
      "fc layer 2 self.abs_max_out: 1396.0\n",
      "fc layer 1 self.abs_max_out: 24670.0\n",
      "fc layer 1 self.abs_max_out: 25291.0\n",
      "fc layer 2 self.abs_max_out: 1420.0\n",
      "fc layer 2 self.abs_max_out: 1492.0\n",
      "fc layer 1 self.abs_max_out: 26088.0\n",
      "lif layer 2 self.abs_max_v: 1975.0\n",
      "lif layer 2 self.abs_max_v: 1978.5\n",
      "lif layer 2 self.abs_max_v: 2036.5\n",
      "fc layer 2 self.abs_max_out: 1612.0\n",
      "lif layer 2 self.abs_max_v: 2078.5\n",
      "fc layer 2 self.abs_max_out: 1644.0\n",
      "lif layer 2 self.abs_max_v: 2193.5\n",
      "lif layer 2 self.abs_max_v: 2221.5\n",
      "fc layer 2 self.abs_max_out: 1662.0\n",
      "fc layer 2 self.abs_max_out: 1696.0\n",
      "fc layer 1 self.abs_max_out: 26346.0\n",
      "lif layer 2 self.abs_max_v: 2274.0\n",
      "lif layer 2 self.abs_max_v: 2316.0\n",
      "lif layer 2 self.abs_max_v: 2324.0\n",
      "lif layer 2 self.abs_max_v: 2390.0\n",
      "lif layer 2 self.abs_max_v: 2429.0\n",
      "lif layer 2 self.abs_max_v: 2619.5\n",
      "lif layer 1 self.abs_max_v: 33697.5\n",
      "lif layer 1 self.abs_max_v: 35078.0\n",
      "lif layer 1 self.abs_max_v: 37470.5\n",
      "fc layer 1 self.abs_max_out: 27419.0\n",
      "fc layer 2 self.abs_max_out: 1700.0\n",
      "lif layer 1 self.abs_max_v: 39505.0\n",
      "fc layer 1 self.abs_max_out: 28447.0\n",
      "fc layer 2 self.abs_max_out: 1702.0\n",
      "lif layer 2 self.abs_max_v: 2683.5\n",
      "lif layer 1 self.abs_max_v: 39790.5\n",
      "fc layer 3 self.abs_max_out: 127.0\n",
      "fc layer 3 self.abs_max_out: 138.0\n",
      "fc layer 2 self.abs_max_out: 1716.0\n",
      "fc layer 2 self.abs_max_out: 1717.0\n",
      "fc layer 2 self.abs_max_out: 1736.0\n",
      "fc layer 2 self.abs_max_out: 1755.0\n",
      "lif layer 1 self.abs_max_v: 43181.0\n",
      "fc layer 1 self.abs_max_out: 28486.0\n",
      "fc layer 3 self.abs_max_out: 141.0\n",
      "fc layer 1 self.abs_max_out: 29448.0\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 217.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 308.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 330.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 331.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 438.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 445.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 482.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['8.0000000'], tr/val_loss: 44.608746/ 28.955244, val:  50.00%, val_best:  50.00%, tr:  77.50%, tr_best:  77.50%, epoch time: 127.92 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 76.7292%\n",
      "layer   3  Sparsity: 64.2792%\n",
      "total_backward_count 16128 real_backward_count 4516  28.001%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 73.3398%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 56.6250%\n",
      "fc layer 2 self.abs_max_out: 1809.0\n",
      "fc layer 3 self.abs_max_out: 144.0\n",
      "fc layer 1 self.abs_max_out: 30400.0\n",
      "lif layer 2 self.abs_max_v: 2706.5\n",
      "lif layer 2 self.abs_max_v: 2823.5\n",
      "fc layer 1 self.abs_max_out: 31154.0\n",
      "fc layer 3 self.abs_max_out: 149.0\n",
      "fc layer 2 self.abs_max_out: 1892.0\n",
      "fc layer 3 self.abs_max_out: 165.0\n",
      "lif layer 1 self.abs_max_v: 49066.5\n",
      "lif layer 2 self.abs_max_v: 2948.5\n",
      "fc layer 2 self.abs_max_out: 2012.0\n",
      "lif layer 2 self.abs_max_v: 3041.5\n",
      "fc layer 2 self.abs_max_out: 2038.0\n",
      "fc layer 1 self.abs_max_out: 32610.0\n",
      "fc layer 1 self.abs_max_out: 32719.0\n",
      "fc layer 2 self.abs_max_out: 2092.0\n",
      "fc layer 2 self.abs_max_out: 2118.0\n",
      "fc layer 2 self.abs_max_out: 2167.0\n",
      "fc layer 2 self.abs_max_out: 2423.0\n",
      "train - Value 0: 1901 occurrences\n",
      "train - Value 1: 2131 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 2 self.abs_max_v: 3258.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-1   lr=['8.0000000'], tr/val_loss: 42.311317/ 19.684404, val:  53.76%, val_best:  53.76%, tr:  77.80%, tr_best:  77.80%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 73.1669%\n",
      "layer   3  Sparsity: 61.3143%\n",
      "total_backward_count 32256 real_backward_count 8980  27.840%\n",
      "layer   1  Sparsity: 81.4453%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 64.7500%\n",
      "lif layer 1 self.abs_max_v: 49661.5\n",
      "lif layer 2 self.abs_max_v: 3527.5\n",
      "lif layer 2 self.abs_max_v: 3593.0\n",
      "fc layer 2 self.abs_max_out: 2593.0\n",
      "fc layer 1 self.abs_max_out: 35073.0\n",
      "fc layer 2 self.abs_max_out: 2611.0\n",
      "lif layer 1 self.abs_max_v: 51535.5\n",
      "fc layer 2 self.abs_max_out: 2659.0\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 51551.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['8.0000000'], tr/val_loss: 43.207516/ 82.511215, val:  50.00%, val_best:  53.76%, tr:  76.84%, tr_best:  77.80%, epoch time: 131.76 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 74.1462%\n",
      "layer   3  Sparsity: 62.5379%\n",
      "total_backward_count 48384 real_backward_count 13422  27.741%\n",
      "layer   1  Sparsity: 72.9980%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 56.0000%\n",
      "train - Value 0: 2121 occurrences\n",
      "train - Value 1: 1911 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 52702.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['8.0000000'], tr/val_loss: 47.392834/ 75.545990, val:  50.00%, val_best:  53.76%, tr:  77.41%, tr_best:  77.80%, epoch time: 130.43 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 71.4959%\n",
      "layer   3  Sparsity: 61.4898%\n",
      "total_backward_count 64512 real_backward_count 17654  27.365%\n",
      "layer   1  Sparsity: 73.9258%\n",
      "layer   2  Sparsity: 75.6250%\n",
      "layer   3  Sparsity: 65.5000%\n",
      "fc layer 2 self.abs_max_out: 2724.0\n",
      "fc layer 2 self.abs_max_out: 2782.0\n",
      "lif layer 1 self.abs_max_v: 57611.0\n",
      "fc layer 1 self.abs_max_out: 35290.0\n",
      "fc layer 1 self.abs_max_out: 36994.0\n",
      "train - Value 0: 2159 occurrences\n",
      "train - Value 1: 1873 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-4   lr=['8.0000000'], tr/val_loss: 46.704514/ 21.885511, val:  51.55%, val_best:  53.76%, tr:  78.65%, tr_best:  78.65%, epoch time: 130.20 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 75.1629%\n",
      "layer   3  Sparsity: 59.5266%\n",
      "total_backward_count 80640 real_backward_count 21661  26.861%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 62.6250%\n",
      "train - Value 0: 1858 occurrences\n",
      "train - Value 1: 2174 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['8.0000000'], tr/val_loss: 52.881268/ 58.323788, val:  50.00%, val_best:  53.76%, tr:  80.61%, tr_best:  80.61%, epoch time: 130.57 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 72.9630%\n",
      "layer   3  Sparsity: 57.5649%\n",
      "total_backward_count 96768 real_backward_count 25792  26.653%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 62.8750%\n",
      "lif layer 2 self.abs_max_v: 3887.0\n",
      "lif layer 2 self.abs_max_v: 3918.0\n",
      "lif layer 2 self.abs_max_v: 3939.5\n",
      "lif layer 2 self.abs_max_v: 3981.0\n",
      "lif layer 2 self.abs_max_v: 3986.5\n",
      "lif layer 2 self.abs_max_v: 4009.5\n",
      "lif layer 2 self.abs_max_v: 4284.0\n",
      "fc layer 2 self.abs_max_out: 3037.0\n",
      "train - Value 0: 1747 occurrences\n",
      "train - Value 1: 2285 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-6   lr=['8.0000000'], tr/val_loss: 48.240402/ 44.039440, val:  50.88%, val_best:  53.76%, tr:  74.43%, tr_best:  80.61%, epoch time: 130.88 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 70.0987%\n",
      "layer   3  Sparsity: 56.8280%\n",
      "total_backward_count 112896 real_backward_count 30304  26.842%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 79.6250%\n",
      "layer   3  Sparsity: 63.5000%\n",
      "fc layer 2 self.abs_max_out: 3082.0\n",
      "lif layer 2 self.abs_max_v: 4349.5\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['8.0000000'], tr/val_loss: 54.760735/ 36.464874, val:  50.00%, val_best:  53.76%, tr:  79.81%, tr_best:  80.61%, epoch time: 131.37 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 71.3770%\n",
      "layer   3  Sparsity: 56.3528%\n",
      "total_backward_count 129024 real_backward_count 34558  26.784%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 73.3750%\n",
      "layer   3  Sparsity: 61.5000%\n",
      "lif layer 2 self.abs_max_v: 4440.0\n",
      "fc layer 2 self.abs_max_out: 3193.0\n",
      "fc layer 2 self.abs_max_out: 3245.0\n",
      "fc layer 3 self.abs_max_out: 169.0\n",
      "train - Value 0: 2146 occurrences\n",
      "train - Value 1: 1886 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-8   lr=['8.0000000'], tr/val_loss: 51.423992/ 37.296104, val:  50.00%, val_best:  53.76%, tr:  79.91%, tr_best:  80.61%, epoch time: 131.13 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 70.5644%\n",
      "layer   3  Sparsity: 56.2327%\n",
      "total_backward_count 145152 real_backward_count 38754  26.699%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 79.1250%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "fc layer 3 self.abs_max_out: 173.0\n",
      "fc layer 1 self.abs_max_out: 38057.0\n",
      "lif layer 1 self.abs_max_v: 58116.0\n",
      "fc layer 3 self.abs_max_out: 179.0\n",
      "fc layer 3 self.abs_max_out: 186.0\n",
      "fc layer 3 self.abs_max_out: 188.0\n",
      "fc layer 3 self.abs_max_out: 196.0\n",
      "fc layer 2 self.abs_max_out: 3263.0\n",
      "train - Value 0: 1835 occurrences\n",
      "train - Value 1: 2197 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-9   lr=['8.0000000'], tr/val_loss: 61.890697/ 56.326183, val:  49.56%, val_best:  53.76%, tr:  75.62%, tr_best:  80.61%, epoch time: 130.79 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 69.7023%\n",
      "layer   3  Sparsity: 54.5518%\n",
      "total_backward_count 161280 real_backward_count 43197  26.784%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 59.8750%\n",
      "fc layer 2 self.abs_max_out: 3275.0\n",
      "fc layer 2 self.abs_max_out: 3507.0\n",
      "fc layer 2 self.abs_max_out: 3567.0\n",
      "fc layer 2 self.abs_max_out: 3587.0\n",
      "fc layer 2 self.abs_max_out: 3681.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 483.00 at epoch 10, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['8.0000000'], tr/val_loss: 58.761917/ 62.955761, val:  50.00%, val_best:  53.76%, tr:  78.94%, tr_best:  80.61%, epoch time: 132.13 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 71.5448%\n",
      "layer   3  Sparsity: 54.7240%\n",
      "total_backward_count 177408 real_backward_count 47411  26.724%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 70.1250%\n",
      "layer   3  Sparsity: 46.8750%\n",
      "fc layer 3 self.abs_max_out: 202.0\n",
      "fc layer 3 self.abs_max_out: 215.0\n",
      "fc layer 3 self.abs_max_out: 238.0\n",
      "fc layer 1 self.abs_max_out: 38499.0\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 75 occurrences\n",
      "test - Value 1: 377 occurrences\n",
      "epoch-11  lr=['8.0000000'], tr/val_loss: 45.710052/ 19.444376, val:  56.42%, val_best:  56.42%, tr:  81.85%, tr_best:  81.85%, epoch time: 131.74 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 73.5786%\n",
      "layer   3  Sparsity: 53.0930%\n",
      "total_backward_count 193536 real_backward_count 51509  26.615%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 76.6250%\n",
      "layer   3  Sparsity: 58.5000%\n",
      "lif layer 2 self.abs_max_v: 4455.0\n",
      "lif layer 2 self.abs_max_v: 4867.0\n",
      "fc layer 2 self.abs_max_out: 3745.0\n",
      "fc layer 2 self.abs_max_out: 3768.0\n",
      "fc layer 2 self.abs_max_out: 3785.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 3857.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-12  lr=['8.0000000'], tr/val_loss: 52.877506/ 49.288891, val:  55.53%, val_best:  56.42%, tr:  80.23%, tr_best:  81.85%, epoch time: 130.90 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 74.0370%\n",
      "layer   3  Sparsity: 52.4498%\n",
      "total_backward_count 209664 real_backward_count 55541  26.490%\n",
      "layer   1  Sparsity: 87.1094%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 59.1250%\n",
      "fc layer 2 self.abs_max_out: 3908.0\n",
      "lif layer 2 self.abs_max_v: 5773.0\n",
      "fc layer 2 self.abs_max_out: 3974.0\n",
      "fc layer 2 self.abs_max_out: 4090.0\n",
      "fc layer 2 self.abs_max_out: 4122.0\n",
      "fc layer 2 self.abs_max_out: 4162.0\n",
      "fc layer 2 self.abs_max_out: 4202.0\n",
      "fc layer 2 self.abs_max_out: 4242.0\n",
      "fc layer 2 self.abs_max_out: 4282.0\n",
      "fc layer 2 self.abs_max_out: 4868.0\n",
      "fc layer 2 self.abs_max_out: 4949.0\n",
      "train - Value 0: 2177 occurrences\n",
      "train - Value 1: 1855 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-13  lr=['8.0000000'], tr/val_loss: 54.497467/ 28.736269, val:  50.44%, val_best:  56.42%, tr:  85.00%, tr_best:  85.00%, epoch time: 130.75 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 72.6548%\n",
      "layer   3  Sparsity: 52.6397%\n",
      "total_backward_count 225792 real_backward_count 59487  26.346%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 84.2500%\n",
      "layer   3  Sparsity: 59.1250%\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-14  lr=['8.0000000'], tr/val_loss: 54.547260/ 45.606808, val:  52.21%, val_best:  56.42%, tr:  83.80%, tr_best:  85.00%, epoch time: 130.88 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 74.0506%\n",
      "layer   3  Sparsity: 52.1568%\n",
      "total_backward_count 241920 real_backward_count 63481  26.240%\n",
      "layer   1  Sparsity: 92.3340%\n",
      "layer   2  Sparsity: 88.8750%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "lif layer 2 self.abs_max_v: 6262.5\n",
      "train - Value 0: 1894 occurrences\n",
      "train - Value 1: 2138 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-15  lr=['8.0000000'], tr/val_loss: 59.207596/ 15.889042, val:  53.32%, val_best:  56.42%, tr:  77.58%, tr_best:  85.00%, epoch time: 130.74 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 72.4960%\n",
      "layer   3  Sparsity: 51.5826%\n",
      "total_backward_count 258048 real_backward_count 67676  26.226%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 43.3750%\n",
      "train - Value 0: 2154 occurrences\n",
      "train - Value 1: 1878 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-16  lr=['8.0000000'], tr/val_loss: 51.301888/ 53.479599, val:  53.54%, val_best:  56.42%, tr:  82.44%, tr_best:  85.00%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 72.9752%\n",
      "layer   3  Sparsity: 52.4495%\n",
      "total_backward_count 274176 real_backward_count 71684  26.145%\n",
      "layer   1  Sparsity: 72.9004%\n",
      "layer   2  Sparsity: 64.1250%\n",
      "layer   3  Sparsity: 44.6250%\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-17  lr=['8.0000000'], tr/val_loss: 59.557835/ 74.555786, val:  52.65%, val_best:  56.42%, tr:  80.85%, tr_best:  85.00%, epoch time: 129.93 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 72.3039%\n",
      "layer   3  Sparsity: 53.1834%\n",
      "total_backward_count 290304 real_backward_count 75685  26.071%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 45.0000%\n",
      "lif layer 2 self.abs_max_v: 6297.0\n",
      "lif layer 2 self.abs_max_v: 6341.0\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['8.0000000'], tr/val_loss: 45.539215/103.705803, val:  50.00%, val_best:  56.42%, tr:  76.39%, tr_best:  85.00%, epoch time: 130.58 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 74.9363%\n",
      "layer   3  Sparsity: 52.6647%\n",
      "total_backward_count 306432 real_backward_count 80129  26.149%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 58.6250%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-19  lr=['8.0000000'], tr/val_loss: 50.027271/ 50.724827, val:  66.81%, val_best:  66.81%, tr:  76.71%, tr_best:  85.00%, epoch time: 130.93 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 72.6125%\n",
      "layer   3  Sparsity: 51.5854%\n",
      "total_backward_count 322560 real_backward_count 84557  26.214%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 65.8750%\n",
      "layer   3  Sparsity: 43.3750%\n",
      "lif layer 2 self.abs_max_v: 6469.5\n",
      "fc layer 2 self.abs_max_out: 4985.0\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-20  lr=['8.0000000'], tr/val_loss: 62.654934/ 41.346859, val:  54.65%, val_best:  66.81%, tr:  74.18%, tr_best:  85.00%, epoch time: 130.83 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 66.8058%\n",
      "layer   3  Sparsity: 51.3567%\n",
      "total_backward_count 338688 real_backward_count 89060  26.296%\n",
      "layer   1  Sparsity: 84.8633%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 58.0000%\n",
      "lif layer 2 self.abs_max_v: 6538.0\n",
      "train - Value 0: 1841 occurrences\n",
      "train - Value 1: 2191 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 528.00 at epoch 21, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 420 occurrences\n",
      "test - Value 1: 32 occurrences\n",
      "epoch-21  lr=['8.0000000'], tr/val_loss: 70.214226/ 63.895119, val:  55.75%, val_best:  66.81%, tr:  78.35%, tr_best:  85.00%, epoch time: 130.25 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 71.9882%\n",
      "layer   3  Sparsity: 51.4083%\n",
      "total_backward_count 354816 real_backward_count 93176  26.260%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 74.3750%\n",
      "layer   3  Sparsity: 43.3750%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-22  lr=['8.0000000'], tr/val_loss: 60.345776/ 62.052448, val:  50.00%, val_best:  66.81%, tr:  79.46%, tr_best:  85.00%, epoch time: 130.23 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 73.0260%\n",
      "layer   3  Sparsity: 51.4813%\n",
      "total_backward_count 370944 real_backward_count 97391  26.255%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 42.3750%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-23  lr=['8.0000000'], tr/val_loss: 67.372429/ 31.952274, val:  53.98%, val_best:  66.81%, tr:  78.94%, tr_best:  85.00%, epoch time: 130.21 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 68.7823%\n",
      "layer   3  Sparsity: 51.5138%\n",
      "total_backward_count 387072 real_backward_count 101682  26.270%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 42.8750%\n",
      "train - Value 0: 2144 occurrences\n",
      "train - Value 1: 1888 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-24  lr=['8.0000000'], tr/val_loss: 48.073128/ 27.909628, val:  51.77%, val_best:  66.81%, tr:  77.43%, tr_best:  85.00%, epoch time: 130.84 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 66.9259%\n",
      "layer   3  Sparsity: 50.6617%\n",
      "total_backward_count 403200 real_backward_count 106013  26.293%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 68.3750%\n",
      "layer   3  Sparsity: 43.1250%\n",
      "lif layer 2 self.abs_max_v: 7126.5\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-25  lr=['8.0000000'], tr/val_loss: 42.725956/ 38.471394, val:  50.00%, val_best:  66.81%, tr:  76.49%, tr_best:  85.00%, epoch time: 131.02 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 64.9255%\n",
      "layer   3  Sparsity: 49.7759%\n",
      "total_backward_count 419328 real_backward_count 110392  26.326%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 41.1250%\n",
      "lif layer 2 self.abs_max_v: 7153.5\n",
      "lif layer 2 self.abs_max_v: 7672.0\n",
      "train - Value 0: 2143 occurrences\n",
      "train - Value 1: 1889 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 544.00 at epoch 26, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['8.0000000'], tr/val_loss: 52.935177/ 70.675720, val:  50.00%, val_best:  66.81%, tr:  78.84%, tr_best:  85.00%, epoch time: 131.31 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 67.5972%\n",
      "layer   3  Sparsity: 49.5273%\n",
      "total_backward_count 435456 real_backward_count 114628  26.324%\n",
      "layer   1  Sparsity: 70.8984%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 40.7500%\n",
      "lif layer 2 self.abs_max_v: 7689.5\n",
      "lif layer 2 self.abs_max_v: 7868.5\n",
      "train - Value 0: 1896 occurrences\n",
      "train - Value 1: 2136 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 580.00 at epoch 27, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-27  lr=['8.0000000'], tr/val_loss: 60.750942/ 50.586910, val:  51.77%, val_best:  66.81%, tr:  76.84%, tr_best:  85.00%, epoch time: 129.71 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 68.5278%\n",
      "layer   3  Sparsity: 49.0861%\n",
      "total_backward_count 451584 real_backward_count 118974  26.346%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 75.5000%\n",
      "layer   3  Sparsity: 41.0000%\n",
      "fc layer 2 self.abs_max_out: 5066.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 5100.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-28  lr=['8.0000000'], tr/val_loss: 55.511681/ 36.030758, val:  50.88%, val_best:  66.81%, tr:  77.06%, tr_best:  85.00%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 70.8307%\n",
      "layer   3  Sparsity: 48.3281%\n",
      "total_backward_count 467712 real_backward_count 123295  26.361%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 41.0000%\n",
      "train - Value 0: 2055 occurrences\n",
      "train - Value 1: 1977 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-29  lr=['8.0000000'], tr/val_loss: 55.746296/ 60.055618, val:  51.99%, val_best:  66.81%, tr:  76.76%, tr_best:  85.00%, epoch time: 131.16 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 71.6706%\n",
      "layer   3  Sparsity: 47.2273%\n",
      "total_backward_count 483840 real_backward_count 127671  26.387%\n",
      "layer   1  Sparsity: 88.4766%\n",
      "layer   2  Sparsity: 86.3750%\n",
      "layer   3  Sparsity: 69.7500%\n",
      "train - Value 0: 2105 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-30  lr=['8.0000000'], tr/val_loss: 59.306831/ 34.365196, val:  50.22%, val_best:  66.81%, tr:  81.08%, tr_best:  85.00%, epoch time: 125.08 seconds, 2.08 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 74.1810%\n",
      "layer   3  Sparsity: 46.7657%\n",
      "total_backward_count 499968 real_backward_count 131849  26.371%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 35.7500%\n",
      "train - Value 0: 2163 occurrences\n",
      "train - Value 1: 1869 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-31  lr=['8.0000000'], tr/val_loss: 69.319763/ 24.006224, val:  57.08%, val_best:  66.81%, tr:  83.16%, tr_best:  85.00%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 71.6270%\n",
      "layer   3  Sparsity: 45.8928%\n",
      "total_backward_count 516096 real_backward_count 135827  26.318%\n",
      "layer   1  Sparsity: 71.8750%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 36.1250%\n",
      "fc layer 1 self.abs_max_out: 38543.0\n",
      "fc layer 2 self.abs_max_out: 5185.0\n",
      "lif layer 2 self.abs_max_v: 8265.5\n",
      "lif layer 2 self.abs_max_v: 8544.0\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-32  lr=['8.0000000'], tr/val_loss: 70.657600/ 20.796682, val:  56.64%, val_best:  66.81%, tr:  80.85%, tr_best:  85.00%, epoch time: 131.44 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 69.6591%\n",
      "layer   3  Sparsity: 45.8886%\n",
      "total_backward_count 532224 real_backward_count 139953  26.296%\n",
      "layer   1  Sparsity: 88.1836%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 52.6250%\n",
      "fc layer 1 self.abs_max_out: 38833.0\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 369 occurrences\n",
      "test - Value 1: 83 occurrences\n",
      "epoch-33  lr=['8.0000000'], tr/val_loss: 63.350967/ 25.865362, val:  63.50%, val_best:  66.81%, tr:  79.56%, tr_best:  85.00%, epoch time: 131.24 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 74.4699%\n",
      "layer   3  Sparsity: 45.8400%\n",
      "total_backward_count 548352 real_backward_count 144124  26.283%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 35.3750%\n",
      "fc layer 2 self.abs_max_out: 5317.0\n",
      "fc layer 2 self.abs_max_out: 5397.0\n",
      "fc layer 1 self.abs_max_out: 39866.0\n",
      "lif layer 2 self.abs_max_v: 8559.5\n",
      "train - Value 0: 1675 occurrences\n",
      "train - Value 1: 2357 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 2 self.abs_max_v: 8858.5\n",
      "lif layer 2 self.abs_max_v: 9171.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-34  lr=['8.0000000'], tr/val_loss: 65.288643/ 70.968765, val:  57.08%, val_best:  66.81%, tr:  78.99%, tr_best:  85.00%, epoch time: 130.67 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 68.8650%\n",
      "layer   3  Sparsity: 45.1107%\n",
      "total_backward_count 564480 real_backward_count 148359  26.282%\n",
      "layer   1  Sparsity: 86.8164%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 52.1250%\n",
      "train - Value 0: 1836 occurrences\n",
      "train - Value 1: 2196 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['8.0000000'], tr/val_loss: 52.006641/ 57.842979, val:  50.00%, val_best:  66.81%, tr:  79.27%, tr_best:  85.00%, epoch time: 130.01 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 71.0697%\n",
      "layer   3  Sparsity: 45.4497%\n",
      "total_backward_count 580608 real_backward_count 152475  26.261%\n",
      "layer   1  Sparsity: 93.5547%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 69.5000%\n",
      "fc layer 1 self.abs_max_out: 40200.0\n",
      "fc layer 3 self.abs_max_out: 272.0\n",
      "fc layer 2 self.abs_max_out: 5416.0\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 5462.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-36  lr=['8.0000000'], tr/val_loss: 48.134312/ 18.903906, val:  60.84%, val_best:  66.81%, tr:  83.75%, tr_best:  85.00%, epoch time: 131.16 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 71.7610%\n",
      "layer   3  Sparsity: 45.9688%\n",
      "total_backward_count 596736 real_backward_count 156410  26.211%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 71.2500%\n",
      "layer   3  Sparsity: 36.5000%\n",
      "fc layer 2 self.abs_max_out: 5522.0\n",
      "fc layer 2 self.abs_max_out: 5562.0\n",
      "fc layer 1 self.abs_max_out: 40211.0\n",
      "fc layer 2 self.abs_max_out: 5602.0\n",
      "fc layer 2 self.abs_max_out: 5642.0\n",
      "fc layer 2 self.abs_max_out: 5662.0\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['8.0000000'], tr/val_loss: 55.608330/ 68.073959, val:  50.00%, val_best:  66.81%, tr:  82.51%, tr_best:  85.00%, epoch time: 130.65 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 71.8418%\n",
      "layer   3  Sparsity: 45.5496%\n",
      "total_backward_count 612864 real_backward_count 160543  26.196%\n",
      "layer   1  Sparsity: 68.7988%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 35.6250%\n",
      "fc layer 3 self.abs_max_out: 275.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-38  lr=['8.0000000'], tr/val_loss: 61.326626/ 95.062248, val:  53.10%, val_best:  66.81%, tr:  80.28%, tr_best:  85.00%, epoch time: 130.80 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4835%\n",
      "layer   2  Sparsity: 70.1169%\n",
      "layer   3  Sparsity: 45.3910%\n",
      "total_backward_count 628992 real_backward_count 164870  26.212%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 51.5000%\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 608.00 at epoch 39, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['8.0000000'], tr/val_loss: 58.595634/ 75.348640, val:  50.00%, val_best:  66.81%, tr:  80.83%, tr_best:  85.00%, epoch time: 130.28 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 67.1876%\n",
      "layer   3  Sparsity: 45.4883%\n",
      "total_backward_count 645120 real_backward_count 169057  26.206%\n",
      "layer   1  Sparsity: 75.8789%\n",
      "layer   2  Sparsity: 56.8750%\n",
      "layer   3  Sparsity: 34.8750%\n",
      "fc layer 2 self.abs_max_out: 5682.0\n",
      "train - Value 0: 1923 occurrences\n",
      "train - Value 1: 2109 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-40  lr=['8.0000000'], tr/val_loss: 74.548340/ 36.837105, val:  51.11%, val_best:  66.81%, tr:  81.08%, tr_best:  85.00%, epoch time: 130.92 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4819%\n",
      "layer   2  Sparsity: 70.8912%\n",
      "layer   3  Sparsity: 45.1459%\n",
      "total_backward_count 661248 real_backward_count 173251  26.201%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 52.2500%\n",
      "fc layer 2 self.abs_max_out: 5691.0\n",
      "lif layer 2 self.abs_max_v: 9172.5\n",
      "fc layer 2 self.abs_max_out: 5698.0\n",
      "train - Value 0: 2225 occurrences\n",
      "train - Value 1: 1807 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-41  lr=['8.0000000'], tr/val_loss: 57.303810/ 40.192501, val:  54.65%, val_best:  66.81%, tr:  78.50%, tr_best:  85.00%, epoch time: 131.08 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 68.2516%\n",
      "layer   3  Sparsity: 45.2450%\n",
      "total_backward_count 677376 real_backward_count 177607  26.220%\n",
      "layer   1  Sparsity: 67.2852%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 35.5000%\n",
      "lif layer 2 self.abs_max_v: 9265.5\n",
      "lif layer 2 self.abs_max_v: 9504.5\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-42  lr=['8.0000000'], tr/val_loss: 64.687523/ 66.009392, val:  54.42%, val_best:  66.81%, tr:  78.15%, tr_best:  85.00%, epoch time: 130.77 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 65.8845%\n",
      "layer   3  Sparsity: 44.8327%\n",
      "total_backward_count 693504 real_backward_count 181990  26.242%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 37.0000%\n",
      "fc layer 2 self.abs_max_out: 6361.0\n",
      "fc layer 2 self.abs_max_out: 6382.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-43  lr=['8.0000000'], tr/val_loss: 58.096855/ 22.234545, val:  49.78%, val_best:  66.81%, tr:  83.75%, tr_best:  85.00%, epoch time: 130.30 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 64.3900%\n",
      "layer   3  Sparsity: 45.4693%\n",
      "total_backward_count 709632 real_backward_count 186106  26.226%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 53.7500%\n",
      "lif layer 2 self.abs_max_v: 9574.0\n",
      "train - Value 0: 2164 occurrences\n",
      "train - Value 1: 1868 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 659.00 at epoch 44, iter 4031\n",
      "max_activation_accul updated: 680.00 at epoch 44, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['8.0000000'], tr/val_loss: 59.590668/ 88.719765, val:  50.00%, val_best:  66.81%, tr:  81.99%, tr_best:  85.00%, epoch time: 130.94 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 64.1000%\n",
      "layer   3  Sparsity: 45.8700%\n",
      "total_backward_count 725760 real_backward_count 190255  26.215%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 52.2500%\n",
      "fc layer 3 self.abs_max_out: 289.0\n",
      "train - Value 0: 2099 occurrences\n",
      "train - Value 1: 1933 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-45  lr=['8.0000000'], tr/val_loss: 66.955696/ 75.044563, val:  53.54%, val_best:  66.81%, tr:  81.57%, tr_best:  85.00%, epoch time: 130.95 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 68.0888%\n",
      "layer   3  Sparsity: 45.9039%\n",
      "total_backward_count 741888 real_backward_count 194579  26.228%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 87.5000%\n",
      "layer   3  Sparsity: 69.7500%\n",
      "train - Value 0: 1879 occurrences\n",
      "train - Value 1: 2153 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-46  lr=['8.0000000'], tr/val_loss: 68.066727/ 35.252605, val:  53.54%, val_best:  66.81%, tr:  77.65%, tr_best:  85.00%, epoch time: 130.83 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 73.1303%\n",
      "layer   3  Sparsity: 47.5134%\n",
      "total_backward_count 758016 real_backward_count 198990  26.251%\n",
      "layer   1  Sparsity: 70.5566%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 41.5000%\n",
      "lif layer 1 self.abs_max_v: 59139.5\n",
      "fc layer 1 self.abs_max_out: 40681.0\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['8.0000000'], tr/val_loss: 58.812561/  9.835470, val:  50.00%, val_best:  66.81%, tr:  81.47%, tr_best:  85.00%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 71.2910%\n",
      "layer   3  Sparsity: 47.8381%\n",
      "total_backward_count 774144 real_backward_count 203158  26.243%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 83.0000%\n",
      "layer   3  Sparsity: 55.3750%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-48  lr=['8.0000000'], tr/val_loss: 66.033638/ 42.512665, val:  52.21%, val_best:  66.81%, tr:  80.61%, tr_best:  85.00%, epoch time: 131.31 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 69.7156%\n",
      "layer   3  Sparsity: 48.3834%\n",
      "total_backward_count 790272 real_backward_count 207346  26.237%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 77.3750%\n",
      "layer   3  Sparsity: 54.5000%\n",
      "fc layer 1 self.abs_max_out: 41880.0\n",
      "lif layer 1 self.abs_max_v: 59734.5\n",
      "lif layer 1 self.abs_max_v: 62158.5\n",
      "train - Value 0: 2077 occurrences\n",
      "train - Value 1: 1955 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['8.0000000'], tr/val_loss: 71.179878/ 77.341759, val:  50.00%, val_best:  66.81%, tr:  77.26%, tr_best:  85.00%, epoch time: 131.12 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 67.6717%\n",
      "layer   3  Sparsity: 48.3057%\n",
      "total_backward_count 806400 real_backward_count 211612  26.242%\n",
      "layer   1  Sparsity: 80.5664%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 55.2500%\n",
      "fc layer 1 self.abs_max_out: 43362.0\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 6847.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-50  lr=['8.0000000'], tr/val_loss: 71.897758/ 77.077065, val:  50.44%, val_best:  66.81%, tr:  77.73%, tr_best:  85.00%, epoch time: 129.73 seconds, 2.16 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 69.6468%\n",
      "layer   3  Sparsity: 47.6182%\n",
      "total_backward_count 822528 real_backward_count 215939  26.253%\n",
      "layer   1  Sparsity: 73.0957%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 35.7500%\n",
      "fc layer 2 self.abs_max_out: 6887.0\n",
      "fc layer 2 self.abs_max_out: 6889.0\n",
      "lif layer 1 self.abs_max_v: 62399.5\n",
      "train - Value 0: 1837 occurrences\n",
      "train - Value 1: 2195 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-51  lr=['8.0000000'], tr/val_loss: 71.085281/ 43.288738, val:  50.22%, val_best:  66.81%, tr:  80.58%, tr_best:  85.00%, epoch time: 126.53 seconds, 2.11 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 66.9699%\n",
      "layer   3  Sparsity: 47.4503%\n",
      "total_backward_count 838656 real_backward_count 220148  26.250%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 54.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-52  lr=['8.0000000'], tr/val_loss: 59.053543/ 53.200085, val:  54.20%, val_best:  66.81%, tr:  78.47%, tr_best:  85.00%, epoch time: 114.38 seconds, 1.91 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 68.0187%\n",
      "layer   3  Sparsity: 46.7865%\n",
      "total_backward_count 854784 real_backward_count 224476  26.261%\n",
      "layer   1  Sparsity: 90.2344%\n",
      "layer   2  Sparsity: 82.5000%\n",
      "layer   3  Sparsity: 56.0000%\n",
      "train - Value 0: 1931 occurrences\n",
      "train - Value 1: 2101 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-53  lr=['8.0000000'], tr/val_loss: 67.674538/ 37.930042, val:  56.86%, val_best:  66.81%, tr:  83.01%, tr_best:  85.00%, epoch time: 113.09 seconds, 1.88 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 65.9438%\n",
      "layer   3  Sparsity: 45.5993%\n",
      "total_backward_count 870912 real_backward_count 228521  26.239%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 77.2500%\n",
      "layer   3  Sparsity: 53.6250%\n",
      "fc layer 3 self.abs_max_out: 298.0\n",
      "fc layer 3 self.abs_max_out: 301.0\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-54  lr=['8.0000000'], tr/val_loss: 60.282822/ 71.564110, val:  53.98%, val_best:  66.81%, tr:  80.28%, tr_best:  85.00%, epoch time: 113.59 seconds, 1.89 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 68.6716%\n",
      "layer   3  Sparsity: 44.6983%\n",
      "total_backward_count 887040 real_backward_count 232666  26.229%\n",
      "layer   1  Sparsity: 79.2480%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 51.2500%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-55  lr=['8.0000000'], tr/val_loss: 58.744095/ 52.724468, val:  51.55%, val_best:  66.81%, tr:  79.07%, tr_best:  85.00%, epoch time: 114.14 seconds, 1.90 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 70.2886%\n",
      "layer   3  Sparsity: 46.4427%\n",
      "total_backward_count 903168 real_backward_count 236904  26.230%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 54.0000%\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['8.0000000'], tr/val_loss: 67.326302/ 57.818718, val:  50.00%, val_best:  66.81%, tr:  77.11%, tr_best:  85.00%, epoch time: 113.69 seconds, 1.89 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 72.0075%\n",
      "layer   3  Sparsity: 46.8245%\n",
      "total_backward_count 919296 real_backward_count 241187  26.236%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 81.2500%\n",
      "layer   3  Sparsity: 53.2500%\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-57  lr=['8.0000000'], tr/val_loss: 70.270088/ 38.109917, val:  50.44%, val_best:  66.81%, tr:  79.69%, tr_best:  85.00%, epoch time: 114.39 seconds, 1.91 minutes\n",
      "layer   1  Sparsity: 79.4790%\n",
      "layer   2  Sparsity: 70.1892%\n",
      "layer   3  Sparsity: 46.2066%\n",
      "total_backward_count 935424 real_backward_count 245380  26.232%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 79.8750%\n",
      "layer   3  Sparsity: 68.3750%\n",
      "train - Value 0: 2184 occurrences\n",
      "train - Value 1: 1848 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 681.00 at epoch 58, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-58  lr=['8.0000000'], tr/val_loss: 66.115753/ 90.563744, val:  50.22%, val_best:  66.81%, tr:  78.42%, tr_best:  85.00%, epoch time: 119.17 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 68.1278%\n",
      "layer   3  Sparsity: 45.6903%\n",
      "total_backward_count 951552 real_backward_count 249755  26.247%\n",
      "layer   1  Sparsity: 77.2949%\n",
      "layer   2  Sparsity: 66.2500%\n",
      "layer   3  Sparsity: 38.0000%\n",
      "train - Value 0: 2174 occurrences\n",
      "train - Value 1: 1858 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-59  lr=['8.0000000'], tr/val_loss: 66.829788/ 88.781670, val:  50.00%, val_best:  66.81%, tr:  80.61%, tr_best:  85.00%, epoch time: 129.97 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 68.4060%\n",
      "layer   3  Sparsity: 46.0308%\n",
      "total_backward_count 967680 real_backward_count 253904  26.238%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 75.7500%\n",
      "layer   3  Sparsity: 54.3750%\n",
      "train - Value 0: 1876 occurrences\n",
      "train - Value 1: 2156 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-60  lr=['8.0000000'], tr/val_loss: 80.749916/ 36.282417, val:  52.88%, val_best:  66.81%, tr:  81.75%, tr_best:  85.00%, epoch time: 131.64 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 69.3086%\n",
      "layer   3  Sparsity: 45.8534%\n",
      "total_backward_count 983808 real_backward_count 257912  26.216%\n",
      "layer   1  Sparsity: 72.7539%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 37.6250%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-61  lr=['8.0000000'], tr/val_loss: 60.026360/ 31.444424, val:  49.78%, val_best:  66.81%, tr:  80.56%, tr_best:  85.00%, epoch time: 132.13 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 71.6737%\n",
      "layer   3  Sparsity: 45.9143%\n",
      "total_backward_count 999936 real_backward_count 261983  26.200%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 37.8750%\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-62  lr=['8.0000000'], tr/val_loss: 67.860191/ 56.020363, val:  53.32%, val_best:  66.81%, tr:  77.98%, tr_best:  85.00%, epoch time: 131.06 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 72.0714%\n",
      "layer   3  Sparsity: 45.2640%\n",
      "total_backward_count 1016064 real_backward_count 266289  26.208%\n",
      "layer   1  Sparsity: 78.7598%\n",
      "layer   2  Sparsity: 71.1250%\n",
      "layer   3  Sparsity: 36.1250%\n",
      "train - Value 0: 1831 occurrences\n",
      "train - Value 1: 2201 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-63  lr=['8.0000000'], tr/val_loss: 63.244076/ 68.171394, val:  50.00%, val_best:  66.81%, tr:  77.46%, tr_best:  85.00%, epoch time: 132.29 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 73.6140%\n",
      "layer   3  Sparsity: 45.6219%\n",
      "total_backward_count 1032192 real_backward_count 270498  26.206%\n",
      "layer   1  Sparsity: 76.8066%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 38.1250%\n",
      "lif layer 2 self.abs_max_v: 9579.5\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-64  lr=['8.0000000'], tr/val_loss: 71.484627/ 18.907679, val:  53.54%, val_best:  66.81%, tr:  81.50%, tr_best:  85.00%, epoch time: 132.42 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 71.1447%\n",
      "layer   3  Sparsity: 46.5388%\n",
      "total_backward_count 1048320 real_backward_count 274662  26.200%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 67.3750%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-65  lr=['8.0000000'], tr/val_loss: 74.129036/ 99.900444, val:  50.00%, val_best:  66.81%, tr:  83.51%, tr_best:  85.00%, epoch time: 131.12 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 73.6339%\n",
      "layer   3  Sparsity: 45.2651%\n",
      "total_backward_count 1064448 real_backward_count 278725  26.185%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 75.1250%\n",
      "layer   3  Sparsity: 52.2500%\n",
      "train - Value 0: 2211 occurrences\n",
      "train - Value 1: 1821 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-66  lr=['8.0000000'], tr/val_loss: 63.456150/ 52.012272, val:  52.21%, val_best:  66.81%, tr:  79.24%, tr_best:  85.00%, epoch time: 132.03 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 66.8215%\n",
      "layer   3  Sparsity: 44.8229%\n",
      "total_backward_count 1080576 real_backward_count 282933  26.184%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 60.1250%\n",
      "layer   3  Sparsity: 34.6250%\n",
      "train - Value 0: 1852 occurrences\n",
      "train - Value 1: 2180 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-67  lr=['8.0000000'], tr/val_loss: 71.141617/ 85.881882, val:  50.00%, val_best:  66.81%, tr:  81.20%, tr_best:  85.00%, epoch time: 132.27 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 69.6841%\n",
      "layer   3  Sparsity: 44.9986%\n",
      "total_backward_count 1096704 real_backward_count 287113  26.180%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 50.7500%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 682.00 at epoch 68, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['8.0000000'], tr/val_loss: 71.380112/132.368439, val:  50.00%, val_best:  66.81%, tr:  81.25%, tr_best:  85.00%, epoch time: 132.50 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 68.5008%\n",
      "layer   3  Sparsity: 44.0754%\n",
      "total_backward_count 1112832 real_backward_count 291379  26.184%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 52.7500%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-69  lr=['8.0000000'], tr/val_loss: 71.651848/ 43.799549, val:  50.00%, val_best:  66.81%, tr:  82.02%, tr_best:  85.00%, epoch time: 133.04 seconds, 2.22 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 69.4272%\n",
      "layer   3  Sparsity: 43.2262%\n",
      "total_backward_count 1128960 real_backward_count 295524  26.177%\n",
      "layer   1  Sparsity: 65.8691%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 32.1250%\n",
      "train - Value 0: 2175 occurrences\n",
      "train - Value 1: 1857 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-70  lr=['8.0000000'], tr/val_loss: 75.013184/ 53.943153, val:  50.00%, val_best:  66.81%, tr:  82.76%, tr_best:  85.00%, epoch time: 131.90 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 68.9151%\n",
      "layer   3  Sparsity: 43.8821%\n",
      "total_backward_count 1145088 real_backward_count 299584  26.163%\n",
      "layer   1  Sparsity: 70.4102%\n",
      "layer   2  Sparsity: 54.3750%\n",
      "layer   3  Sparsity: 33.6250%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 382 occurrences\n",
      "test - Value 1: 70 occurrences\n",
      "epoch-71  lr=['8.0000000'], tr/val_loss: 71.408043/ 41.934002, val:  58.41%, val_best:  66.81%, tr:  81.92%, tr_best:  85.00%, epoch time: 131.46 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 67.1922%\n",
      "layer   3  Sparsity: 43.9697%\n",
      "total_backward_count 1161216 real_backward_count 303681  26.152%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 70.3750%\n",
      "layer   3  Sparsity: 37.0000%\n",
      "train - Value 0: 2130 occurrences\n",
      "train - Value 1: 1902 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['8.0000000'], tr/val_loss: 68.452049/135.625702, val:  50.00%, val_best:  66.81%, tr:  83.78%, tr_best:  85.00%, epoch time: 131.05 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 67.5608%\n",
      "layer   3  Sparsity: 44.2860%\n",
      "total_backward_count 1177344 real_backward_count 307582  26.125%\n",
      "layer   1  Sparsity: 80.5176%\n",
      "layer   2  Sparsity: 71.3750%\n",
      "layer   3  Sparsity: 51.3750%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-73  lr=['8.0000000'], tr/val_loss: 68.927917/ 47.041050, val:  50.66%, val_best:  66.81%, tr:  81.94%, tr_best:  85.00%, epoch time: 132.06 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 65.8983%\n",
      "layer   3  Sparsity: 44.1806%\n",
      "total_backward_count 1193472 real_backward_count 311658  26.114%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 52.7500%\n",
      "train - Value 0: 1840 occurrences\n",
      "train - Value 1: 2192 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-74  lr=['8.0000000'], tr/val_loss: 64.883858/ 60.584316, val:  50.44%, val_best:  66.81%, tr:  80.46%, tr_best:  85.00%, epoch time: 130.76 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 68.5281%\n",
      "layer   3  Sparsity: 44.8269%\n",
      "total_backward_count 1209600 real_backward_count 315905  26.116%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 79.1250%\n",
      "layer   3  Sparsity: 52.3750%\n",
      "train - Value 0: 1890 occurrences\n",
      "train - Value 1: 2142 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 327 occurrences\n",
      "test - Value 1: 125 occurrences\n",
      "epoch-75  lr=['8.0000000'], tr/val_loss: 60.954834/ 46.209419, val:  64.38%, val_best:  66.81%, tr:  78.17%, tr_best:  85.00%, epoch time: 130.31 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 67.3253%\n",
      "layer   3  Sparsity: 44.9132%\n",
      "total_backward_count 1225728 real_backward_count 320102  26.115%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 53.6250%\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-76  lr=['8.0000000'], tr/val_loss: 67.452271/ 44.426647, val:  54.65%, val_best:  66.81%, tr:  79.94%, tr_best:  85.00%, epoch time: 131.45 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 68.7768%\n",
      "layer   3  Sparsity: 45.5066%\n",
      "total_backward_count 1241856 real_backward_count 324130  26.100%\n",
      "layer   1  Sparsity: 75.3418%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 34.7500%\n",
      "train - Value 0: 1866 occurrences\n",
      "train - Value 1: 2166 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-77  lr=['8.0000000'], tr/val_loss: 69.320702/ 56.677948, val:  53.10%, val_best:  66.81%, tr:  81.40%, tr_best:  85.00%, epoch time: 130.66 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 69.6648%\n",
      "layer   3  Sparsity: 45.2213%\n",
      "total_backward_count 1257984 real_backward_count 328210  26.090%\n",
      "layer   1  Sparsity: 76.5137%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 35.5000%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-78  lr=['8.0000000'], tr/val_loss: 70.361183/ 22.230696, val:  51.55%, val_best:  66.81%, tr:  81.67%, tr_best:  85.00%, epoch time: 132.22 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 67.8113%\n",
      "layer   3  Sparsity: 45.5777%\n",
      "total_backward_count 1274112 real_backward_count 332253  26.077%\n",
      "layer   1  Sparsity: 83.9355%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 52.2500%\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['8.0000000'], tr/val_loss: 56.856125/ 62.513851, val:  50.00%, val_best:  66.81%, tr:  77.33%, tr_best:  85.00%, epoch time: 131.13 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 68.6634%\n",
      "layer   3  Sparsity: 45.4404%\n",
      "total_backward_count 1290240 real_backward_count 336559  26.085%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 72.3750%\n",
      "layer   3  Sparsity: 52.0000%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 384 occurrences\n",
      "test - Value 1: 68 occurrences\n",
      "epoch-80  lr=['8.0000000'], tr/val_loss: 67.815727/ 37.148594, val:  57.96%, val_best:  66.81%, tr:  80.83%, tr_best:  85.00%, epoch time: 130.77 seconds, 2.18 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 70.9369%\n",
      "layer   3  Sparsity: 45.8039%\n",
      "total_backward_count 1306368 real_backward_count 340812  26.089%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 77.7500%\n",
      "layer   3  Sparsity: 53.7500%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['8.0000000'], tr/val_loss: 70.980087/ 68.561203, val:  50.00%, val_best:  66.81%, tr:  83.28%, tr_best:  85.00%, epoch time: 128.02 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 75.5424%\n",
      "layer   3  Sparsity: 46.9484%\n",
      "total_backward_count 1322496 real_backward_count 344804  26.072%\n",
      "layer   1  Sparsity: 78.6621%\n",
      "layer   2  Sparsity: 75.7500%\n",
      "layer   3  Sparsity: 37.6250%\n",
      "train - Value 0: 1910 occurrences\n",
      "train - Value 1: 2122 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-82  lr=['8.0000000'], tr/val_loss: 63.436886/ 66.877884, val:  51.11%, val_best:  66.81%, tr:  84.52%, tr_best:  85.00%, epoch time: 120.15 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 77.1256%\n",
      "layer   3  Sparsity: 47.3280%\n",
      "total_backward_count 1338624 real_backward_count 348771  26.054%\n",
      "layer   1  Sparsity: 72.0703%\n",
      "layer   2  Sparsity: 65.6250%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "train - Value 0: 1806 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-83  lr=['8.0000000'], tr/val_loss: 70.243088/ 52.701366, val:  49.78%, val_best:  66.81%, tr:  80.41%, tr_best:  85.00%, epoch time: 132.04 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4827%\n",
      "layer   2  Sparsity: 72.5120%\n",
      "layer   3  Sparsity: 46.9310%\n",
      "total_backward_count 1354752 real_backward_count 352796  26.041%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 46.6250%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "fc layer 2 self.abs_max_out: 7038.0\n",
      "train - Value 0: 1806 occurrences\n",
      "train - Value 1: 2226 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-84  lr=['8.0000000'], tr/val_loss: 76.065933/ 23.503485, val:  57.52%, val_best:  66.81%, tr:  79.71%, tr_best:  85.00%, epoch time: 132.35 seconds, 2.21 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 67.4965%\n",
      "layer   3  Sparsity: 45.7609%\n",
      "total_backward_count 1370880 real_backward_count 356982  26.040%\n",
      "layer   1  Sparsity: 71.7773%\n",
      "layer   2  Sparsity: 57.6250%\n",
      "layer   3  Sparsity: 35.5000%\n",
      "fc layer 2 self.abs_max_out: 7081.0\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-85  lr=['8.0000000'], tr/val_loss: 70.922630/ 42.410263, val:  50.00%, val_best:  66.81%, tr:  78.55%, tr_best:  85.00%, epoch time: 131.78 seconds, 2.20 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 67.8255%\n",
      "layer   3  Sparsity: 45.8782%\n",
      "total_backward_count 1387008 real_backward_count 361257  26.046%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "fc layer 2 self.abs_max_out: 7093.0\n",
      "fc layer 2 self.abs_max_out: 7113.0\n",
      "train - Value 0: 1798 occurrences\n",
      "train - Value 1: 2234 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['8.0000000'], tr/val_loss: 76.451523/110.868279, val:  50.00%, val_best:  66.81%, tr:  80.16%, tr_best:  85.00%, epoch time: 130.17 seconds, 2.17 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 72.9710%\n",
      "layer   3  Sparsity: 46.1276%\n",
      "total_backward_count 1403136 real_backward_count 365335  26.037%\n",
      "layer   1  Sparsity: 78.3203%\n",
      "layer   2  Sparsity: 72.8750%\n",
      "layer   3  Sparsity: 51.5000%\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2108 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-87  lr=['8.0000000'], tr/val_loss: 66.488335/ 62.565250, val:  50.00%, val_best:  66.81%, tr:  79.96%, tr_best:  85.00%, epoch time: 131.70 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 73.1841%\n",
      "layer   3  Sparsity: 45.8358%\n",
      "total_backward_count 1419264 real_backward_count 369581  26.040%\n",
      "layer   1  Sparsity: 78.3691%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 52.6250%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-88  lr=['8.0000000'], tr/val_loss: 53.234207/ 66.833229, val:  50.88%, val_best:  66.81%, tr:  78.05%, tr_best:  85.00%, epoch time: 131.49 seconds, 2.19 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 74.4660%\n",
      "layer   3  Sparsity: 45.8878%\n",
      "total_backward_count 1435392 real_backward_count 373860  26.046%\n",
      "layer   1  Sparsity: 91.2109%\n",
      "layer   2  Sparsity: 92.5000%\n",
      "layer   3  Sparsity: 83.8750%\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-89  lr=['8.0000000'], tr/val_loss: 63.633953/ 14.252827, val:  58.19%, val_best:  66.81%, tr:  77.60%, tr_best:  85.00%, epoch time: 127.50 seconds, 2.13 minutes\n",
      "layer   1  Sparsity: 79.4785%\n",
      "layer   2  Sparsity: 75.8475%\n",
      "layer   3  Sparsity: 45.9873%\n",
      "total_backward_count 1451520 real_backward_count 378294  26.062%\n",
      "layer   1  Sparsity: 83.2031%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 52.8750%\n",
      "train - Value 0: 1708 occurrences\n",
      "train - Value 1: 2324 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-90  lr=['8.0000000'], tr/val_loss: 65.095612/133.619919, val:  50.00%, val_best:  66.81%, tr:  77.43%, tr_best:  85.00%, epoch time: 118.19 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 77.6324%\n",
      "layer   3  Sparsity: 45.6567%\n",
      "total_backward_count 1467648 real_backward_count 382485  26.061%\n",
      "layer   1  Sparsity: 81.2012%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 52.7500%\n",
      "train - Value 0: 1948 occurrences\n",
      "train - Value 1: 2084 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 271 occurrences\n",
      "test - Value 1: 181 occurrences\n",
      "epoch-91  lr=['8.0000000'], tr/val_loss: 49.846252/ 15.366302, val:  62.61%, val_best:  66.81%, tr:  76.93%, tr_best:  85.00%, epoch time: 117.53 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 76.7286%\n",
      "layer   3  Sparsity: 46.4862%\n",
      "total_backward_count 1483776 real_backward_count 386774  26.067%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 73.1250%\n",
      "layer   3  Sparsity: 36.6250%\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['8.0000000'], tr/val_loss: 48.645329/ 71.454247, val:  50.00%, val_best:  66.81%, tr:  79.51%, tr_best:  85.00%, epoch time: 117.79 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 76.2374%\n",
      "layer   3  Sparsity: 46.0266%\n",
      "total_backward_count 1499904 real_backward_count 391056  26.072%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 35.6250%\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['8.0000000'], tr/val_loss: 53.559803/ 88.025398, val:  50.00%, val_best:  66.81%, tr:  76.66%, tr_best:  85.00%, epoch time: 115.68 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 73.7967%\n",
      "layer   3  Sparsity: 45.5165%\n",
      "total_backward_count 1516032 real_backward_count 395359  26.079%\n",
      "layer   1  Sparsity: 75.1465%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 51.5000%\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-94  lr=['8.0000000'], tr/val_loss: 63.784508/  7.070418, val:  50.22%, val_best:  66.81%, tr:  82.27%, tr_best:  85.00%, epoch time: 116.27 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 74.7696%\n",
      "layer   3  Sparsity: 45.7767%\n",
      "total_backward_count 1532160 real_backward_count 399384  26.067%\n",
      "layer   1  Sparsity: 66.0645%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 35.5000%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['8.0000000'], tr/val_loss: 62.019115/117.757210, val:  50.00%, val_best:  66.81%, tr:  79.37%, tr_best:  85.00%, epoch time: 117.96 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 74.2987%\n",
      "layer   3  Sparsity: 46.0952%\n",
      "total_backward_count 1548288 real_backward_count 403563  26.065%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['8.0000000'], tr/val_loss: 61.484169/ 55.542149, val:  50.00%, val_best:  66.81%, tr:  78.52%, tr_best:  85.00%, epoch time: 117.93 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 72.7041%\n",
      "layer   3  Sparsity: 46.8797%\n",
      "total_backward_count 1564416 real_backward_count 407800  26.067%\n",
      "layer   1  Sparsity: 65.7227%\n",
      "layer   2  Sparsity: 57.3750%\n",
      "layer   3  Sparsity: 37.2500%\n",
      "fc layer 2 self.abs_max_out: 7260.0\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-97  lr=['8.0000000'], tr/val_loss: 59.166855/ 89.026344, val:  53.76%, val_best:  66.81%, tr:  80.21%, tr_best:  85.00%, epoch time: 117.47 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 72.3960%\n",
      "layer   3  Sparsity: 46.4141%\n",
      "total_backward_count 1580544 real_backward_count 411987  26.066%\n",
      "layer   1  Sparsity: 71.1426%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 35.7500%\n",
      "fc layer 2 self.abs_max_out: 7316.0\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-98  lr=['8.0000000'], tr/val_loss: 72.745140/ 31.799837, val:  50.00%, val_best:  66.81%, tr:  80.08%, tr_best:  85.00%, epoch time: 117.14 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 73.7219%\n",
      "layer   3  Sparsity: 45.8879%\n",
      "total_backward_count 1596672 real_backward_count 416150  26.064%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 37.5000%\n",
      "train - Value 0: 2112 occurrences\n",
      "train - Value 1: 1920 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-99  lr=['8.0000000'], tr/val_loss: 76.636238/ 57.508953, val:  52.88%, val_best:  66.81%, tr:  80.36%, tr_best:  85.00%, epoch time: 117.57 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 70.1515%\n",
      "layer   3  Sparsity: 45.8294%\n",
      "total_backward_count 1612800 real_backward_count 420237  26.056%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 68.2500%\n",
      "fc layer 2 self.abs_max_out: 7356.0\n",
      "train - Value 0: 2158 occurrences\n",
      "train - Value 1: 1874 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-100 lr=['8.0000000'], tr/val_loss: 58.006245/ 29.250458, val:  50.66%, val_best:  66.81%, tr:  78.08%, tr_best:  85.00%, epoch time: 117.86 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 69.8933%\n",
      "layer   3  Sparsity: 46.6758%\n",
      "total_backward_count 1628928 real_backward_count 424540  26.063%\n",
      "layer   1  Sparsity: 66.2109%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 1915 occurrences\n",
      "train - Value 1: 2117 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-101 lr=['8.0000000'], tr/val_loss: 58.135014/ 53.016460, val:  53.98%, val_best:  66.81%, tr:  82.51%, tr_best:  85.00%, epoch time: 118.73 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 71.1311%\n",
      "layer   3  Sparsity: 46.7785%\n",
      "total_backward_count 1645056 real_backward_count 428632  26.056%\n",
      "layer   1  Sparsity: 84.1309%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 54.3750%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-102 lr=['8.0000000'], tr/val_loss: 53.160664/ 39.544769, val:  55.75%, val_best:  66.81%, tr:  82.12%, tr_best:  85.00%, epoch time: 117.54 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 71.8164%\n",
      "layer   3  Sparsity: 46.4196%\n",
      "total_backward_count 1661184 real_backward_count 432741  26.050%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 35.1250%\n",
      "train - Value 0: 2298 occurrences\n",
      "train - Value 1: 1734 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-103 lr=['8.0000000'], tr/val_loss: 63.819286/ 38.807255, val:  50.00%, val_best:  66.81%, tr:  81.25%, tr_best:  85.00%, epoch time: 116.37 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 71.0849%\n",
      "layer   3  Sparsity: 46.4780%\n",
      "total_backward_count 1677312 real_backward_count 436807  26.042%\n",
      "layer   1  Sparsity: 78.1250%\n",
      "layer   2  Sparsity: 72.6250%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 2249 occurrences\n",
      "train - Value 1: 1783 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['8.0000000'], tr/val_loss: 55.910442/114.848045, val:  50.00%, val_best:  66.81%, tr:  77.11%, tr_best:  85.00%, epoch time: 117.90 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 75.9961%\n",
      "layer   3  Sparsity: 46.6908%\n",
      "total_backward_count 1693440 real_backward_count 441102  26.048%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 37.5000%\n",
      "fc layer 2 self.abs_max_out: 7581.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['8.0000000'], tr/val_loss: 69.855042/ 89.658440, val:  50.00%, val_best:  66.81%, tr:  76.12%, tr_best:  85.00%, epoch time: 117.92 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 71.1693%\n",
      "layer   3  Sparsity: 46.6336%\n",
      "total_backward_count 1709568 real_backward_count 445508  26.060%\n",
      "layer   1  Sparsity: 83.3496%\n",
      "layer   2  Sparsity: 79.8750%\n",
      "layer   3  Sparsity: 54.2500%\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['8.0000000'], tr/val_loss: 66.310669/ 70.143517, val:  50.00%, val_best:  66.81%, tr:  73.71%, tr_best:  85.00%, epoch time: 117.42 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 75.6366%\n",
      "layer   3  Sparsity: 47.0150%\n",
      "total_backward_count 1725696 real_backward_count 449829  26.067%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 54.7500%\n",
      "fc layer 2 self.abs_max_out: 8295.0\n",
      "lif layer 2 self.abs_max_v: 9789.0\n",
      "lif layer 2 self.abs_max_v: 10172.5\n",
      "train - Value 0: 1850 occurrences\n",
      "train - Value 1: 2182 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-107 lr=['8.0000000'], tr/val_loss: 74.196342/ 26.632994, val:  50.44%, val_best:  66.81%, tr:  82.84%, tr_best:  85.00%, epoch time: 115.77 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 71.7017%\n",
      "layer   3  Sparsity: 46.4377%\n",
      "total_backward_count 1741824 real_backward_count 453707  26.048%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 52.7500%\n",
      "train - Value 0: 2116 occurrences\n",
      "train - Value 1: 1916 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-108 lr=['8.0000000'], tr/val_loss: 70.922882/ 68.482079, val:  51.11%, val_best:  66.81%, tr:  83.98%, tr_best:  85.00%, epoch time: 114.07 seconds, 1.90 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 68.8491%\n",
      "layer   3  Sparsity: 46.6325%\n",
      "total_backward_count 1757952 real_backward_count 457560  26.028%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 68.2500%\n",
      "train - Value 0: 1952 occurrences\n",
      "train - Value 1: 2080 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-109 lr=['8.0000000'], tr/val_loss: 77.000572/ 57.160973, val:  50.00%, val_best:  66.81%, tr:  82.79%, tr_best:  85.00%, epoch time: 117.12 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 69.8220%\n",
      "layer   3  Sparsity: 46.7428%\n",
      "total_backward_count 1774080 real_backward_count 461554  26.017%\n",
      "layer   1  Sparsity: 87.3047%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-110 lr=['8.0000000'], tr/val_loss: 77.634911/ 60.862766, val:  50.00%, val_best:  66.81%, tr:  84.55%, tr_best:  85.00%, epoch time: 117.58 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4793%\n",
      "layer   2  Sparsity: 69.5930%\n",
      "layer   3  Sparsity: 46.7607%\n",
      "total_backward_count 1790208 real_backward_count 465460  26.000%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 400 occurrences\n",
      "test - Value 1: 52 occurrences\n",
      "epoch-111 lr=['8.0000000'], tr/val_loss: 65.953835/ 30.647144, val:  55.75%, val_best:  66.81%, tr:  81.82%, tr_best:  85.00%, epoch time: 116.08 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 68.9133%\n",
      "layer   3  Sparsity: 46.9440%\n",
      "total_backward_count 1806336 real_backward_count 469582  25.996%\n",
      "layer   1  Sparsity: 77.4902%\n",
      "layer   2  Sparsity: 58.1250%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-112 lr=['8.0000000'], tr/val_loss: 48.822254/ 40.822563, val:  53.32%, val_best:  66.81%, tr:  79.29%, tr_best:  85.00%, epoch time: 116.07 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 65.9022%\n",
      "layer   3  Sparsity: 46.5407%\n",
      "total_backward_count 1822464 real_backward_count 473894  26.003%\n",
      "layer   1  Sparsity: 83.7891%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 38.7500%\n",
      "lif layer 2 self.abs_max_v: 10537.5\n",
      "train - Value 0: 2133 occurrences\n",
      "train - Value 1: 1899 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-113 lr=['8.0000000'], tr/val_loss: 60.748604/ 70.132751, val:  50.44%, val_best:  66.81%, tr:  80.78%, tr_best:  85.00%, epoch time: 118.40 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 63.3142%\n",
      "layer   3  Sparsity: 46.3588%\n",
      "total_backward_count 1838592 real_backward_count 478037  26.000%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 37.2500%\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-114 lr=['8.0000000'], tr/val_loss: 51.458309/ 30.232330, val:  63.27%, val_best:  66.81%, tr:  78.94%, tr_best:  85.00%, epoch time: 117.08 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 64.9156%\n",
      "layer   3  Sparsity: 46.8368%\n",
      "total_backward_count 1854720 real_backward_count 482192  25.998%\n",
      "layer   1  Sparsity: 75.1953%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 1888 occurrences\n",
      "train - Value 1: 2144 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-115 lr=['8.0000000'], tr/val_loss: 59.876610/ 79.328918, val:  50.00%, val_best:  66.81%, tr:  79.07%, tr_best:  85.00%, epoch time: 112.17 seconds, 1.87 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 69.3380%\n",
      "layer   3  Sparsity: 47.3570%\n",
      "total_backward_count 1870848 real_backward_count 486436  26.001%\n",
      "layer   1  Sparsity: 85.5469%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 56.8750%\n",
      "train - Value 0: 2218 occurrences\n",
      "train - Value 1: 1814 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['8.0000000'], tr/val_loss: 58.916653/ 39.510399, val:  50.00%, val_best:  66.81%, tr:  81.80%, tr_best:  85.00%, epoch time: 117.81 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 69.9843%\n",
      "layer   3  Sparsity: 47.5729%\n",
      "total_backward_count 1886976 real_backward_count 490559  25.997%\n",
      "layer   1  Sparsity: 69.0918%\n",
      "layer   2  Sparsity: 62.8750%\n",
      "layer   3  Sparsity: 37.8750%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-117 lr=['8.0000000'], tr/val_loss: 70.110222/ 42.161304, val:  50.00%, val_best:  66.81%, tr:  85.32%, tr_best:  85.32%, epoch time: 118.02 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4834%\n",
      "layer   2  Sparsity: 69.4103%\n",
      "layer   3  Sparsity: 47.8256%\n",
      "total_backward_count 1903104 real_backward_count 494501  25.984%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 56.1250%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['8.0000000'], tr/val_loss: 65.432396/ 62.377098, val:  50.00%, val_best:  66.81%, tr:  82.89%, tr_best:  85.32%, epoch time: 118.54 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 70.5539%\n",
      "layer   3  Sparsity: 48.0544%\n",
      "total_backward_count 1919232 real_backward_count 498590  25.979%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 86.6250%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "train - Value 0: 2197 occurrences\n",
      "train - Value 1: 1835 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['8.0000000'], tr/val_loss: 59.754543/ 92.877739, val:  50.00%, val_best:  66.81%, tr:  82.96%, tr_best:  85.32%, epoch time: 115.86 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 74.2990%\n",
      "layer   3  Sparsity: 47.9512%\n",
      "total_backward_count 1935360 real_backward_count 502563  25.967%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 39.7500%\n",
      "fc layer 3 self.abs_max_out: 310.0\n",
      "fc layer 3 self.abs_max_out: 320.0\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 22 occurrences\n",
      "test - Value 1: 430 occurrences\n",
      "epoch-120 lr=['8.0000000'], tr/val_loss: 72.253731/ 51.705162, val:  51.77%, val_best:  66.81%, tr:  84.65%, tr_best:  85.32%, epoch time: 113.70 seconds, 1.90 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 72.3577%\n",
      "layer   3  Sparsity: 47.6036%\n",
      "total_backward_count 1951488 real_backward_count 506528  25.956%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 38.7500%\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['8.0000000'], tr/val_loss: 75.115402/103.585907, val:  50.00%, val_best:  66.81%, tr:  77.65%, tr_best:  85.32%, epoch time: 88.56 seconds, 1.48 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 71.8662%\n",
      "layer   3  Sparsity: 48.0209%\n",
      "total_backward_count 1967616 real_backward_count 510748  25.958%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 39.6250%\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['8.0000000'], tr/val_loss: 71.320969/ 43.148354, val:  50.00%, val_best:  66.81%, tr:  80.43%, tr_best:  85.32%, epoch time: 88.82 seconds, 1.48 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 72.1261%\n",
      "layer   3  Sparsity: 48.2749%\n",
      "total_backward_count 1983744 real_backward_count 514665  25.944%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "train - Value 0: 1946 occurrences\n",
      "train - Value 1: 2086 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-123 lr=['8.0000000'], tr/val_loss: 69.982925/ 17.302374, val:  57.30%, val_best:  66.81%, tr:  80.51%, tr_best:  85.32%, epoch time: 92.27 seconds, 1.54 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 72.7413%\n",
      "layer   3  Sparsity: 48.5224%\n",
      "total_backward_count 1999872 real_backward_count 518919  25.948%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 39.1250%\n",
      "train - Value 0: 2089 occurrences\n",
      "train - Value 1: 1943 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-124 lr=['8.0000000'], tr/val_loss: 59.292252/ 84.637543, val:  50.00%, val_best:  66.81%, tr:  83.56%, tr_best:  85.32%, epoch time: 88.10 seconds, 1.47 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 74.2601%\n",
      "layer   3  Sparsity: 48.4022%\n",
      "total_backward_count 2016000 real_backward_count 522845  25.935%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 54.6250%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-125 lr=['8.0000000'], tr/val_loss: 66.144897/ 19.297726, val:  59.51%, val_best:  66.81%, tr:  80.41%, tr_best:  85.32%, epoch time: 91.87 seconds, 1.53 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 76.5969%\n",
      "layer   3  Sparsity: 48.5250%\n",
      "total_backward_count 2032128 real_backward_count 526980  25.932%\n",
      "layer   1  Sparsity: 70.3125%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 42 occurrences\n",
      "test - Value 1: 410 occurrences\n",
      "epoch-126 lr=['8.0000000'], tr/val_loss: 68.146828/ 50.351818, val:  51.33%, val_best:  66.81%, tr:  82.04%, tr_best:  85.32%, epoch time: 92.52 seconds, 1.54 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 76.8824%\n",
      "layer   3  Sparsity: 48.2047%\n",
      "total_backward_count 2048256 real_backward_count 531059  25.927%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 53.8750%\n",
      "train - Value 0: 2150 occurrences\n",
      "train - Value 1: 1882 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 405 occurrences\n",
      "test - Value 1: 47 occurrences\n",
      "epoch-127 lr=['8.0000000'], tr/val_loss: 60.971252/  8.664695, val:  57.30%, val_best:  66.81%, tr:  80.65%, tr_best:  85.32%, epoch time: 91.07 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 76.9224%\n",
      "layer   3  Sparsity: 48.5091%\n",
      "total_backward_count 2064384 real_backward_count 535187  25.925%\n",
      "layer   1  Sparsity: 88.4277%\n",
      "layer   2  Sparsity: 90.0000%\n",
      "layer   3  Sparsity: 70.2500%\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-128 lr=['8.0000000'], tr/val_loss: 62.549942/ 32.094418, val:  51.77%, val_best:  66.81%, tr:  81.87%, tr_best:  85.32%, epoch time: 87.81 seconds, 1.46 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 74.2106%\n",
      "layer   3  Sparsity: 48.7306%\n",
      "total_backward_count 2080512 real_backward_count 539247  25.919%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 55.7500%\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-129 lr=['8.0000000'], tr/val_loss: 66.998917/ 21.016886, val:  53.76%, val_best:  66.81%, tr:  79.96%, tr_best:  85.32%, epoch time: 89.43 seconds, 1.49 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 72.5382%\n",
      "layer   3  Sparsity: 48.8823%\n",
      "total_backward_count 2096640 real_backward_count 543286  25.912%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 82.2500%\n",
      "layer   3  Sparsity: 55.3750%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-130 lr=['8.0000000'], tr/val_loss: 64.143166/  9.816394, val:  50.66%, val_best:  66.81%, tr:  78.45%, tr_best:  85.32%, epoch time: 91.10 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 73.6459%\n",
      "layer   3  Sparsity: 48.9875%\n",
      "total_backward_count 2112768 real_backward_count 547521  25.915%\n",
      "layer   1  Sparsity: 87.7441%\n",
      "layer   2  Sparsity: 78.7500%\n",
      "layer   3  Sparsity: 55.7500%\n",
      "train - Value 0: 2073 occurrences\n",
      "train - Value 1: 1959 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-131 lr=['8.0000000'], tr/val_loss: 59.239063/ 52.957787, val:  61.73%, val_best:  66.81%, tr:  82.81%, tr_best:  85.32%, epoch time: 90.51 seconds, 1.51 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 71.4058%\n",
      "layer   3  Sparsity: 48.2315%\n",
      "total_backward_count 2128896 real_backward_count 551472  25.904%\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 40.6250%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-132 lr=['8.0000000'], tr/val_loss: 48.673351/ 27.470516, val:  50.00%, val_best:  66.81%, tr:  81.13%, tr_best:  85.32%, epoch time: 89.73 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4821%\n",
      "layer   2  Sparsity: 76.9964%\n",
      "layer   3  Sparsity: 48.7281%\n",
      "total_backward_count 2145024 real_backward_count 555556  25.900%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 87.5000%\n",
      "layer   3  Sparsity: 69.3750%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-133 lr=['8.0000000'], tr/val_loss: 59.063900/ 75.438972, val:  53.32%, val_best:  66.81%, tr:  83.98%, tr_best:  85.32%, epoch time: 89.03 seconds, 1.48 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 76.2139%\n",
      "layer   3  Sparsity: 49.1294%\n",
      "total_backward_count 2161152 real_backward_count 559528  25.890%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 69.8750%\n",
      "layer   3  Sparsity: 39.6250%\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['8.0000000'], tr/val_loss: 51.929981/ 65.826828, val:  50.00%, val_best:  66.81%, tr:  83.56%, tr_best:  85.32%, epoch time: 90.96 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 74.6675%\n",
      "layer   3  Sparsity: 48.4274%\n",
      "total_backward_count 2177280 real_backward_count 563444  25.878%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 71.6250%\n",
      "layer   3  Sparsity: 41.6250%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-135 lr=['8.0000000'], tr/val_loss: 45.277515/ 23.188242, val:  51.55%, val_best:  66.81%, tr:  78.57%, tr_best:  85.32%, epoch time: 89.82 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 76.1326%\n",
      "layer   3  Sparsity: 48.9419%\n",
      "total_backward_count 2193408 real_backward_count 567634  25.879%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 80.5000%\n",
      "layer   3  Sparsity: 56.5000%\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 37 occurrences\n",
      "test - Value 1: 415 occurrences\n",
      "epoch-136 lr=['8.0000000'], tr/val_loss: 50.244011/ 25.939789, val:  53.32%, val_best:  66.81%, tr:  78.77%, tr_best:  85.32%, epoch time: 89.62 seconds, 1.49 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 71.7218%\n",
      "layer   3  Sparsity: 48.3421%\n",
      "total_backward_count 2209536 real_backward_count 571730  25.876%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 39.0000%\n",
      "lif layer 2 self.abs_max_v: 10544.5\n",
      "lif layer 2 self.abs_max_v: 10700.0\n",
      "lif layer 2 self.abs_max_v: 10722.0\n",
      "lif layer 2 self.abs_max_v: 10843.0\n",
      "lif layer 2 self.abs_max_v: 10855.5\n",
      "lif layer 2 self.abs_max_v: 11797.0\n",
      "train - Value 0: 1906 occurrences\n",
      "train - Value 1: 2126 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-137 lr=['8.0000000'], tr/val_loss: 53.996895/ 42.748264, val:  50.66%, val_best:  66.81%, tr:  82.04%, tr_best:  85.32%, epoch time: 91.25 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 69.3951%\n",
      "layer   3  Sparsity: 48.1374%\n",
      "total_backward_count 2225664 real_backward_count 575751  25.869%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "lif layer 2 self.abs_max_v: 11980.5\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-138 lr=['8.0000000'], tr/val_loss: 52.987404/ 59.472443, val:  50.00%, val_best:  66.81%, tr:  83.43%, tr_best:  85.32%, epoch time: 90.14 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 66.4155%\n",
      "layer   3  Sparsity: 48.0745%\n",
      "total_backward_count 2241792 real_backward_count 579790  25.863%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 40.6250%\n",
      "train - Value 0: 2146 occurrences\n",
      "train - Value 1: 1886 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-139 lr=['8.0000000'], tr/val_loss: 52.407814/ 98.681648, val:  50.00%, val_best:  66.81%, tr:  82.04%, tr_best:  85.32%, epoch time: 89.27 seconds, 1.49 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 65.0807%\n",
      "layer   3  Sparsity: 47.8497%\n",
      "total_backward_count 2257920 real_backward_count 583812  25.856%\n",
      "layer   1  Sparsity: 93.6035%\n",
      "layer   2  Sparsity: 90.0000%\n",
      "layer   3  Sparsity: 71.1250%\n",
      "train - Value 0: 2154 occurrences\n",
      "train - Value 1: 1878 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-140 lr=['8.0000000'], tr/val_loss: 56.908115/ 80.431625, val:  50.00%, val_best:  66.81%, tr:  81.85%, tr_best:  85.32%, epoch time: 88.82 seconds, 1.48 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 69.1060%\n",
      "layer   3  Sparsity: 47.5551%\n",
      "total_backward_count 2274048 real_backward_count 587747  25.846%\n",
      "layer   1  Sparsity: 77.4414%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 41.2500%\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-141 lr=['8.0000000'], tr/val_loss: 68.958107/ 62.494511, val:  63.72%, val_best:  66.81%, tr:  83.46%, tr_best:  85.32%, epoch time: 91.13 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 72.7547%\n",
      "layer   3  Sparsity: 48.3379%\n",
      "total_backward_count 2290176 real_backward_count 591869  25.844%\n",
      "layer   1  Sparsity: 69.9707%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 39.0000%\n",
      "train - Value 0: 1846 occurrences\n",
      "train - Value 1: 2186 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-142 lr=['8.0000000'], tr/val_loss: 49.625820/ 19.648884, val:  54.42%, val_best:  66.81%, tr:  81.15%, tr_best:  85.32%, epoch time: 91.00 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 71.6725%\n",
      "layer   3  Sparsity: 48.8068%\n",
      "total_backward_count 2306304 real_backward_count 595984  25.842%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 79.7500%\n",
      "layer   3  Sparsity: 55.2500%\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 410 occurrences\n",
      "test - Value 1: 42 occurrences\n",
      "epoch-143 lr=['8.0000000'], tr/val_loss: 49.419998/ 20.267096, val:  51.77%, val_best:  66.81%, tr:  79.29%, tr_best:  85.32%, epoch time: 90.46 seconds, 1.51 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 73.8833%\n",
      "layer   3  Sparsity: 48.2527%\n",
      "total_backward_count 2322432 real_backward_count 600263  25.846%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 91.0000%\n",
      "layer   3  Sparsity: 84.3750%\n",
      "train - Value 0: 1893 occurrences\n",
      "train - Value 1: 2139 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-144 lr=['8.0000000'], tr/val_loss: 72.341850/ 88.100357, val:  50.22%, val_best:  66.81%, tr:  83.85%, tr_best:  85.32%, epoch time: 91.08 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 75.2618%\n",
      "layer   3  Sparsity: 47.9902%\n",
      "total_backward_count 2338560 real_backward_count 604272  25.839%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 37.0000%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-145 lr=['8.0000000'], tr/val_loss: 72.963737/ 54.387867, val:  53.10%, val_best:  66.81%, tr:  81.60%, tr_best:  85.32%, epoch time: 92.87 seconds, 1.55 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 71.7372%\n",
      "layer   3  Sparsity: 47.5676%\n",
      "total_backward_count 2354688 real_backward_count 608370  25.837%\n",
      "layer   1  Sparsity: 73.2910%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 38.0000%\n",
      "fc layer 2 self.abs_max_out: 8536.0\n",
      "train - Value 0: 1892 occurrences\n",
      "train - Value 1: 2140 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-146 lr=['8.0000000'], tr/val_loss: 71.400688/ 70.793770, val:  55.31%, val_best:  66.81%, tr:  82.34%, tr_best:  85.32%, epoch time: 89.99 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 70.8195%\n",
      "layer   3  Sparsity: 48.2729%\n",
      "total_backward_count 2370816 real_backward_count 612662  25.842%\n",
      "layer   1  Sparsity: 79.8340%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 41.3750%\n",
      "train - Value 0: 1917 occurrences\n",
      "train - Value 1: 2115 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['8.0000000'], tr/val_loss: 78.805420/ 89.304710, val:  50.00%, val_best:  66.81%, tr:  82.71%, tr_best:  85.32%, epoch time: 89.85 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 71.9367%\n",
      "layer   3  Sparsity: 48.4108%\n",
      "total_backward_count 2386944 real_backward_count 616797  25.840%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 53.8750%\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 46 occurrences\n",
      "test - Value 1: 406 occurrences\n",
      "epoch-148 lr=['8.0000000'], tr/val_loss: 77.530724/ 29.022339, val:  53.10%, val_best:  66.81%, tr:  86.19%, tr_best:  86.19%, epoch time: 92.57 seconds, 1.54 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 70.0846%\n",
      "layer   3  Sparsity: 47.9183%\n",
      "total_backward_count 2403072 real_backward_count 620668  25.828%\n",
      "layer   1  Sparsity: 84.0820%\n",
      "layer   2  Sparsity: 71.0000%\n",
      "layer   3  Sparsity: 54.5000%\n",
      "train - Value 0: 1964 occurrences\n",
      "train - Value 1: 2068 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-149 lr=['8.0000000'], tr/val_loss: 70.553993/ 31.738392, val:  54.87%, val_best:  66.81%, tr:  81.20%, tr_best:  86.19%, epoch time: 89.28 seconds, 1.49 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 69.8767%\n",
      "layer   3  Sparsity: 47.5879%\n",
      "total_backward_count 2419200 real_backward_count 624823  25.828%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 39.7500%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 348 occurrences\n",
      "test - Value 1: 104 occurrences\n",
      "epoch-150 lr=['8.0000000'], tr/val_loss: 67.196693/ 58.549335, val:  64.16%, val_best:  66.81%, tr:  83.38%, tr_best:  86.19%, epoch time: 89.63 seconds, 1.49 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 70.3779%\n",
      "layer   3  Sparsity: 47.8158%\n",
      "total_backward_count 2435328 real_backward_count 628936  25.826%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 45.0000%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 1858 occurrences\n",
      "train - Value 1: 2174 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['8.0000000'], tr/val_loss: 67.333946/ 64.522026, val:  50.00%, val_best:  66.81%, tr:  78.77%, tr_best:  86.19%, epoch time: 90.40 seconds, 1.51 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 68.2316%\n",
      "layer   3  Sparsity: 47.3628%\n",
      "total_backward_count 2451456 real_backward_count 633119  25.826%\n",
      "layer   1  Sparsity: 83.0566%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 53.8750%\n",
      "train - Value 0: 2235 occurrences\n",
      "train - Value 1: 1797 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-152 lr=['8.0000000'], tr/val_loss: 59.156651/ 16.531382, val:  50.00%, val_best:  66.81%, tr:  77.16%, tr_best:  86.19%, epoch time: 90.11 seconds, 1.50 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 71.9788%\n",
      "layer   3  Sparsity: 47.3869%\n",
      "total_backward_count 2467584 real_backward_count 637506  25.835%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 39.0000%\n",
      "train - Value 0: 2178 occurrences\n",
      "train - Value 1: 1854 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-153 lr=['8.0000000'], tr/val_loss: 65.104332/ 64.905579, val:  49.78%, val_best:  66.81%, tr:  79.86%, tr_best:  86.19%, epoch time: 91.39 seconds, 1.52 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 74.5417%\n",
      "layer   3  Sparsity: 47.6756%\n",
      "total_backward_count 2483712 real_backward_count 641652  25.834%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 37.2500%\n",
      "train - Value 0: 1862 occurrences\n",
      "train - Value 1: 2170 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-154 lr=['8.0000000'], tr/val_loss: 69.967155/ 27.311586, val:  53.76%, val_best:  66.81%, tr:  84.33%, tr_best:  86.19%, epoch time: 110.10 seconds, 1.84 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 73.5782%\n",
      "layer   3  Sparsity: 47.3967%\n",
      "total_backward_count 2499840 real_backward_count 645522  25.823%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 38.8750%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-155 lr=['8.0000000'], tr/val_loss: 72.444366/ 70.309578, val:  51.11%, val_best:  66.81%, tr:  83.83%, tr_best:  86.19%, epoch time: 120.20 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 72.8318%\n",
      "layer   3  Sparsity: 47.7636%\n",
      "total_backward_count 2515968 real_backward_count 649504  25.815%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 54.0000%\n",
      "train - Value 0: 2145 occurrences\n",
      "train - Value 1: 1887 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-156 lr=['8.0000000'], tr/val_loss: 73.895935/ 70.154465, val:  52.21%, val_best:  66.81%, tr:  82.42%, tr_best:  86.19%, epoch time: 118.93 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 71.8925%\n",
      "layer   3  Sparsity: 47.7794%\n",
      "total_backward_count 2532096 real_backward_count 653506  25.809%\n",
      "layer   1  Sparsity: 74.5605%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 39.6250%\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-157 lr=['8.0000000'], tr/val_loss: 69.078835/ 22.411306, val:  51.55%, val_best:  66.81%, tr:  81.40%, tr_best:  86.19%, epoch time: 120.51 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4822%\n",
      "layer   2  Sparsity: 70.4787%\n",
      "layer   3  Sparsity: 47.7043%\n",
      "total_backward_count 2548224 real_backward_count 657530  25.803%\n",
      "layer   1  Sparsity: 82.5684%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "lif layer 2 self.abs_max_v: 12079.0\n",
      "train - Value 0: 2174 occurrences\n",
      "train - Value 1: 1858 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 390 occurrences\n",
      "test - Value 1: 62 occurrences\n",
      "epoch-158 lr=['8.0000000'], tr/val_loss: 58.805424/ 54.726662, val:  60.62%, val_best:  66.81%, tr:  83.38%, tr_best:  86.19%, epoch time: 119.57 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 68.4881%\n",
      "layer   3  Sparsity: 48.3332%\n",
      "total_backward_count 2564352 real_backward_count 661511  25.796%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 39.7500%\n",
      "train - Value 0: 1904 occurrences\n",
      "train - Value 1: 2128 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-159 lr=['8.0000000'], tr/val_loss: 68.420433/ 91.859375, val:  50.00%, val_best:  66.81%, tr:  82.34%, tr_best:  86.19%, epoch time: 120.01 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 67.6275%\n",
      "layer   3  Sparsity: 49.3269%\n",
      "total_backward_count 2580480 real_backward_count 665616  25.794%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 76.5000%\n",
      "layer   3  Sparsity: 56.2500%\n",
      "lif layer 2 self.abs_max_v: 12105.0\n",
      "lif layer 2 self.abs_max_v: 12155.5\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-160 lr=['8.0000000'], tr/val_loss: 61.022453/ 80.001602, val:  50.00%, val_best:  66.81%, tr:  79.37%, tr_best:  86.19%, epoch time: 120.52 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 72.4855%\n",
      "layer   3  Sparsity: 49.3101%\n",
      "total_backward_count 2596608 real_backward_count 669838  25.797%\n",
      "layer   1  Sparsity: 62.3535%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 39.3750%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['8.0000000'], tr/val_loss: 65.803963/ 79.898979, val:  50.00%, val_best:  66.81%, tr:  76.81%, tr_best:  86.19%, epoch time: 119.27 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 75.4690%\n",
      "layer   3  Sparsity: 48.8585%\n",
      "total_backward_count 2612736 real_backward_count 673921  25.794%\n",
      "layer   1  Sparsity: 92.2852%\n",
      "layer   2  Sparsity: 87.5000%\n",
      "layer   3  Sparsity: 70.5000%\n",
      "train - Value 0: 1721 occurrences\n",
      "train - Value 1: 2311 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 431 occurrences\n",
      "test - Value 1: 21 occurrences\n",
      "epoch-162 lr=['8.0000000'], tr/val_loss: 76.597740/ 43.787212, val:  54.20%, val_best:  66.81%, tr:  79.59%, tr_best:  86.19%, epoch time: 120.45 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 74.8137%\n",
      "layer   3  Sparsity: 48.4636%\n",
      "total_backward_count 2628864 real_backward_count 677914  25.787%\n",
      "layer   1  Sparsity: 73.5840%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 39.3750%\n",
      "train - Value 0: 1751 occurrences\n",
      "train - Value 1: 2281 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 2 self.abs_max_v: 12156.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-163 lr=['8.0000000'], tr/val_loss: 68.608429/ 39.393250, val:  50.44%, val_best:  66.81%, tr:  80.08%, tr_best:  86.19%, epoch time: 119.04 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 76.3396%\n",
      "layer   3  Sparsity: 48.6144%\n",
      "total_backward_count 2644992 real_backward_count 681962  25.783%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 40.1250%\n",
      "train - Value 0: 1777 occurrences\n",
      "train - Value 1: 2255 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-164 lr=['8.0000000'], tr/val_loss: 66.711662/ 66.830940, val:  53.98%, val_best:  66.81%, tr:  79.94%, tr_best:  86.19%, epoch time: 119.96 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 72.3118%\n",
      "layer   3  Sparsity: 48.6478%\n",
      "total_backward_count 2661120 real_backward_count 686098  25.782%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 55.6250%\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-165 lr=['8.0000000'], tr/val_loss: 60.860275/ 57.111794, val:  54.42%, val_best:  66.81%, tr:  78.97%, tr_best:  86.19%, epoch time: 120.59 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 70.4977%\n",
      "layer   3  Sparsity: 48.5056%\n",
      "total_backward_count 2677248 real_backward_count 690293  25.784%\n",
      "layer   1  Sparsity: 72.4609%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 38.8750%\n",
      "train - Value 0: 1820 occurrences\n",
      "train - Value 1: 2212 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 13 occurrences\n",
      "test - Value 1: 439 occurrences\n",
      "epoch-166 lr=['8.0000000'], tr/val_loss: 53.445812/ 73.974152, val:  51.55%, val_best:  66.81%, tr:  75.15%, tr_best:  86.19%, epoch time: 120.66 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 68.8712%\n",
      "layer   3  Sparsity: 48.5297%\n",
      "total_backward_count 2693376 real_backward_count 694551  25.787%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "lif layer 2 self.abs_max_v: 12185.5\n",
      "train - Value 0: 2165 occurrences\n",
      "train - Value 1: 1867 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-167 lr=['8.0000000'], tr/val_loss: 54.214787/ 64.819809, val:  50.22%, val_best:  66.81%, tr:  78.79%, tr_best:  86.19%, epoch time: 117.10 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 70.9614%\n",
      "layer   3  Sparsity: 48.9949%\n",
      "total_backward_count 2709504 real_backward_count 698684  25.786%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 54.7500%\n",
      "fc layer 2 self.abs_max_out: 8715.0\n",
      "train - Value 0: 2144 occurrences\n",
      "train - Value 1: 1888 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['8.0000000'], tr/val_loss: 58.017441/ 82.595306, val:  50.00%, val_best:  66.81%, tr:  78.97%, tr_best:  86.19%, epoch time: 117.16 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 73.0879%\n",
      "layer   3  Sparsity: 49.6944%\n",
      "total_backward_count 2725632 real_backward_count 702941  25.790%\n",
      "layer   1  Sparsity: 89.4531%\n",
      "layer   2  Sparsity: 87.5000%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-169 lr=['8.0000000'], tr/val_loss: 45.007378/ 27.735718, val:  50.00%, val_best:  66.81%, tr:  78.97%, tr_best:  86.19%, epoch time: 120.73 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 74.6273%\n",
      "layer   3  Sparsity: 49.6652%\n",
      "total_backward_count 2741760 real_backward_count 707110  25.790%\n",
      "layer   1  Sparsity: 76.3672%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "fc layer 2 self.abs_max_out: 9037.0\n",
      "train - Value 0: 2334 occurrences\n",
      "train - Value 1: 1698 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 2 self.abs_max_v: 12385.5\n",
      "lif layer 2 self.abs_max_v: 12464.5\n",
      "fc layer 2 self.abs_max_out: 9398.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['8.0000000'], tr/val_loss: 44.496769/ 82.464081, val:  50.00%, val_best:  66.81%, tr:  77.33%, tr_best:  86.19%, epoch time: 118.44 seconds, 1.97 minutes\n",
      "layer   1  Sparsity: 79.4818%\n",
      "layer   2  Sparsity: 66.7133%\n",
      "layer   3  Sparsity: 49.4793%\n",
      "total_backward_count 2757888 real_backward_count 711342  25.793%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 42.3750%\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-171 lr=['8.0000000'], tr/val_loss: 49.253765/ 41.330284, val:  50.00%, val_best:  66.81%, tr:  80.33%, tr_best:  86.19%, epoch time: 117.08 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 66.9002%\n",
      "layer   3  Sparsity: 49.8314%\n",
      "total_backward_count 2774016 real_backward_count 715484  25.792%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 70.1250%\n",
      "layer   3  Sparsity: 55.7500%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-172 lr=['8.0000000'], tr/val_loss: 62.921307/ 37.862633, val:  57.74%, val_best:  66.81%, tr:  80.85%, tr_best:  86.19%, epoch time: 120.56 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 69.4347%\n",
      "layer   3  Sparsity: 49.8162%\n",
      "total_backward_count 2790144 real_backward_count 719553  25.789%\n",
      "layer   1  Sparsity: 85.1562%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 56.6250%\n",
      "train - Value 0: 2340 occurrences\n",
      "train - Value 1: 1692 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-173 lr=['8.0000000'], tr/val_loss: 54.819653/ 16.769451, val:  50.44%, val_best:  66.81%, tr:  74.06%, tr_best:  86.19%, epoch time: 120.40 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 74.4083%\n",
      "layer   3  Sparsity: 50.0869%\n",
      "total_backward_count 2806272 real_backward_count 723897  25.796%\n",
      "layer   1  Sparsity: 93.4082%\n",
      "layer   2  Sparsity: 82.5000%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "train - Value 0: 2184 occurrences\n",
      "train - Value 1: 1848 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-174 lr=['8.0000000'], tr/val_loss: 53.793922/ 15.908519, val:  51.11%, val_best:  66.81%, tr:  75.15%, tr_best:  86.19%, epoch time: 120.20 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4780%\n",
      "layer   2  Sparsity: 73.4013%\n",
      "layer   3  Sparsity: 49.4523%\n",
      "total_backward_count 2822400 real_backward_count 728177  25.800%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 56.6250%\n",
      "lif layer 2 self.abs_max_v: 12527.0\n",
      "train - Value 0: 2463 occurrences\n",
      "train - Value 1: 1569 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['8.0000000'], tr/val_loss: 52.062580/ 75.051102, val:  50.00%, val_best:  66.81%, tr:  81.47%, tr_best:  86.19%, epoch time: 120.01 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 70.7161%\n",
      "layer   3  Sparsity: 49.5814%\n",
      "total_backward_count 2838528 real_backward_count 732049  25.790%\n",
      "layer   1  Sparsity: 73.7793%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 41.3750%\n",
      "train - Value 0: 2314 occurrences\n",
      "train - Value 1: 1718 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-176 lr=['8.0000000'], tr/val_loss: 57.401463/ 34.561157, val:  60.84%, val_best:  66.81%, tr:  82.29%, tr_best:  86.19%, epoch time: 120.10 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 69.2250%\n",
      "layer   3  Sparsity: 49.6773%\n",
      "total_backward_count 2854656 real_backward_count 736060  25.785%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 56.8750%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-177 lr=['8.0000000'], tr/val_loss: 59.514572/ 45.189793, val:  53.10%, val_best:  66.81%, tr:  77.50%, tr_best:  86.19%, epoch time: 120.06 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 67.8563%\n",
      "layer   3  Sparsity: 50.0999%\n",
      "total_backward_count 2870784 real_backward_count 740230  25.785%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 56.5000%\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-178 lr=['8.0000000'], tr/val_loss: 53.535259/ 56.927162, val:  50.00%, val_best:  66.81%, tr:  83.31%, tr_best:  86.19%, epoch time: 119.67 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 69.9472%\n",
      "layer   3  Sparsity: 50.2260%\n",
      "total_backward_count 2886912 real_backward_count 744144  25.776%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 56.6250%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['8.0000000'], tr/val_loss: 56.968803/118.324455, val:  50.00%, val_best:  66.81%, tr:  83.31%, tr_best:  86.19%, epoch time: 120.16 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 71.1145%\n",
      "layer   3  Sparsity: 49.7270%\n",
      "total_backward_count 2903040 real_backward_count 748216  25.774%\n",
      "layer   1  Sparsity: 70.6543%\n",
      "layer   2  Sparsity: 53.3750%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 2154 occurrences\n",
      "train - Value 1: 1878 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-180 lr=['8.0000000'], tr/val_loss: 49.332207/ 19.420101, val:  50.00%, val_best:  66.81%, tr:  81.30%, tr_best:  86.19%, epoch time: 119.71 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 69.6466%\n",
      "layer   3  Sparsity: 49.6748%\n",
      "total_backward_count 2919168 real_backward_count 752223  25.768%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 71.6250%\n",
      "fc layer 2 self.abs_max_out: 9447.0\n",
      "fc layer 2 self.abs_max_out: 9467.0\n",
      "train - Value 0: 2140 occurrences\n",
      "train - Value 1: 1892 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-181 lr=['8.0000000'], tr/val_loss: 54.679924/ 33.975250, val:  50.66%, val_best:  66.81%, tr:  78.72%, tr_best:  86.19%, epoch time: 121.25 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 69.5115%\n",
      "layer   3  Sparsity: 50.0407%\n",
      "total_backward_count 2935296 real_backward_count 756361  25.768%\n",
      "layer   1  Sparsity: 57.8125%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 2186 occurrences\n",
      "train - Value 1: 1846 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-182 lr=['8.0000000'], tr/val_loss: 61.449032/ 54.943405, val:  53.54%, val_best:  66.81%, tr:  77.28%, tr_best:  86.19%, epoch time: 120.24 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 70.5522%\n",
      "layer   3  Sparsity: 50.4327%\n",
      "total_backward_count 2951424 real_backward_count 760585  25.770%\n",
      "layer   1  Sparsity: 77.8809%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 41.7500%\n",
      "train - Value 0: 1911 occurrences\n",
      "train - Value 1: 2121 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-183 lr=['8.0000000'], tr/val_loss: 67.258179/ 44.295391, val:  50.00%, val_best:  66.81%, tr:  80.08%, tr_best:  86.19%, epoch time: 119.61 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 73.9903%\n",
      "layer   3  Sparsity: 51.1616%\n",
      "total_backward_count 2967552 real_backward_count 764643  25.767%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 80.0000%\n",
      "layer   3  Sparsity: 56.3750%\n",
      "train - Value 0: 1914 occurrences\n",
      "train - Value 1: 2118 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 760.00 at epoch 184, iter 4031\n",
      "max_activation_accul updated: 825.00 at epoch 184, iter 4031\n",
      "max_activation_accul updated: 870.00 at epoch 184, iter 4031\n",
      "max_activation_accul updated: 874.00 at epoch 184, iter 4031\n",
      "max_activation_accul updated: 884.00 at epoch 184, iter 4031\n",
      "max_activation_accul updated: 952.00 at epoch 184, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['8.0000000'], tr/val_loss: 74.457283/157.898453, val:  50.00%, val_best:  66.81%, tr:  85.32%, tr_best:  86.19%, epoch time: 119.63 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 75.2090%\n",
      "layer   3  Sparsity: 51.1229%\n",
      "total_backward_count 2983680 real_backward_count 768611  25.761%\n",
      "layer   1  Sparsity: 85.8887%\n",
      "layer   2  Sparsity: 77.5000%\n",
      "layer   3  Sparsity: 56.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 372 occurrences\n",
      "test - Value 1: 80 occurrences\n",
      "epoch-185 lr=['8.0000000'], tr/val_loss: 69.810242/ 43.966923, val:  61.06%, val_best:  66.81%, tr:  83.09%, tr_best:  86.19%, epoch time: 119.15 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 75.1448%\n",
      "layer   3  Sparsity: 50.6914%\n",
      "total_backward_count 2999808 real_backward_count 772704  25.758%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 82.5000%\n",
      "layer   3  Sparsity: 57.3750%\n",
      "train - Value 0: 1872 occurrences\n",
      "train - Value 1: 2160 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['8.0000000'], tr/val_loss: 69.030434/ 38.371311, val:  50.00%, val_best:  66.81%, tr:  79.27%, tr_best:  86.19%, epoch time: 117.15 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 76.4756%\n",
      "layer   3  Sparsity: 51.0796%\n",
      "total_backward_count 3015936 real_backward_count 776948  25.761%\n",
      "layer   1  Sparsity: 80.0781%\n",
      "layer   2  Sparsity: 75.0000%\n",
      "layer   3  Sparsity: 42.1250%\n",
      "train - Value 0: 1926 occurrences\n",
      "train - Value 1: 2106 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['8.0000000'], tr/val_loss: 64.086662/ 48.163166, val:  50.00%, val_best:  66.81%, tr:  82.19%, tr_best:  86.19%, epoch time: 114.90 seconds, 1.91 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 74.6004%\n",
      "layer   3  Sparsity: 50.9655%\n",
      "total_backward_count 3032064 real_backward_count 781236  25.766%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 64.6250%\n",
      "layer   3  Sparsity: 41.1250%\n",
      "train - Value 0: 1918 occurrences\n",
      "train - Value 1: 2114 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-188 lr=['8.0000000'], tr/val_loss: 67.082352/ 59.517071, val:  50.00%, val_best:  66.81%, tr:  82.59%, tr_best:  86.19%, epoch time: 113.16 seconds, 1.89 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 68.1015%\n",
      "layer   3  Sparsity: 50.0018%\n",
      "total_backward_count 3048192 real_backward_count 785237  25.761%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "train - Value 0: 2222 occurrences\n",
      "train - Value 1: 1810 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-189 lr=['8.0000000'], tr/val_loss: 58.208450/ 54.954700, val:  50.00%, val_best:  66.81%, tr:  77.58%, tr_best:  86.19%, epoch time: 116.55 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 66.5992%\n",
      "layer   3  Sparsity: 49.5874%\n",
      "total_backward_count 3064320 real_backward_count 789356  25.760%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 73.3750%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "lif layer 2 self.abs_max_v: 12879.0\n",
      "train - Value 0: 2145 occurrences\n",
      "train - Value 1: 1887 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-190 lr=['8.0000000'], tr/val_loss: 68.428474/ 81.898811, val:  50.00%, val_best:  66.81%, tr:  78.35%, tr_best:  86.19%, epoch time: 117.39 seconds, 1.96 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 64.1215%\n",
      "layer   3  Sparsity: 49.5252%\n",
      "total_backward_count 3080448 real_backward_count 793623  25.763%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 47.5000%\n",
      "layer   3  Sparsity: 40.7500%\n",
      "train - Value 0: 2177 occurrences\n",
      "train - Value 1: 1855 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-191 lr=['8.0000000'], tr/val_loss: 48.320072/ 79.825417, val:  50.88%, val_best:  66.81%, tr:  78.20%, tr_best:  86.19%, epoch time: 120.41 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 66.2066%\n",
      "layer   3  Sparsity: 49.6964%\n",
      "total_backward_count 3096576 real_backward_count 797650  25.759%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 1924 occurrences\n",
      "train - Value 1: 2108 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-192 lr=['8.0000000'], tr/val_loss: 48.401726/ 83.665222, val:  50.66%, val_best:  66.81%, tr:  81.99%, tr_best:  86.19%, epoch time: 121.01 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 71.2602%\n",
      "layer   3  Sparsity: 50.5937%\n",
      "total_backward_count 3112704 real_backward_count 801611  25.753%\n",
      "layer   1  Sparsity: 57.6660%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 40.3750%\n",
      "train - Value 0: 2206 occurrences\n",
      "train - Value 1: 1826 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['8.0000000'], tr/val_loss: 49.735023/ 76.309631, val:  50.00%, val_best:  66.81%, tr:  83.98%, tr_best:  86.19%, epoch time: 119.22 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 69.9581%\n",
      "layer   3  Sparsity: 50.8161%\n",
      "total_backward_count 3128832 real_backward_count 805458  25.743%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 41.3750%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['8.0000000'], tr/val_loss: 51.550777/ 40.218929, val:  50.00%, val_best:  66.81%, tr:  82.49%, tr_best:  86.19%, epoch time: 120.39 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 69.7720%\n",
      "layer   3  Sparsity: 50.5488%\n",
      "total_backward_count 3144960 real_backward_count 809407  25.737%\n",
      "layer   1  Sparsity: 88.2324%\n",
      "layer   2  Sparsity: 85.0000%\n",
      "layer   3  Sparsity: 71.5000%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 78 occurrences\n",
      "test - Value 1: 374 occurrences\n",
      "epoch-195 lr=['8.0000000'], tr/val_loss: 57.794357/ 25.764559, val:  55.31%, val_best:  66.81%, tr:  83.18%, tr_best:  86.19%, epoch time: 120.41 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 71.9839%\n",
      "layer   3  Sparsity: 50.5883%\n",
      "total_backward_count 3161088 real_backward_count 813401  25.732%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 70.0000%\n",
      "layer   3  Sparsity: 42.7500%\n",
      "train - Value 0: 1887 occurrences\n",
      "train - Value 1: 2145 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['8.0000000'], tr/val_loss: 72.068909/ 58.763222, val:  50.00%, val_best:  66.81%, tr:  81.27%, tr_best:  86.19%, epoch time: 119.68 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 69.3768%\n",
      "layer   3  Sparsity: 50.0101%\n",
      "total_backward_count 3177216 real_backward_count 817349  25.725%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 56.3750%\n",
      "fc layer 2 self.abs_max_out: 9518.0\n",
      "lif layer 2 self.abs_max_v: 13050.0\n",
      "train - Value 0: 1724 occurrences\n",
      "train - Value 1: 2308 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-197 lr=['8.0000000'], tr/val_loss: 87.397560/ 55.433235, val:  50.66%, val_best:  66.81%, tr:  83.93%, tr_best:  86.19%, epoch time: 120.13 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 65.1240%\n",
      "layer   3  Sparsity: 50.1014%\n",
      "total_backward_count 3193344 real_backward_count 821332  25.720%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 45.0000%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['8.0000000'], tr/val_loss: 71.338150/ 96.094162, val:  50.00%, val_best:  66.81%, tr:  77.80%, tr_best:  86.19%, epoch time: 120.44 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 62.5134%\n",
      "layer   3  Sparsity: 50.2323%\n",
      "total_backward_count 3209472 real_backward_count 825441  25.719%\n",
      "layer   1  Sparsity: 69.7754%\n",
      "layer   2  Sparsity: 52.3750%\n",
      "layer   3  Sparsity: 41.0000%\n",
      "train - Value 0: 2296 occurrences\n",
      "train - Value 1: 1736 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-199 lr=['8.0000000'], tr/val_loss: 54.908318/ 38.790920, val:  50.00%, val_best:  66.81%, tr:  81.10%, tr_best:  86.19%, epoch time: 119.60 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 71.1624%\n",
      "layer   3  Sparsity: 50.8463%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dff58a8433849739a253b1398f3b22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÖ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÉ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.81101</td></tr><tr><td>tr_epoch_loss</td><td>54.90832</td></tr><tr><td>val_acc_best</td><td>0.66814</td></tr><tr><td>val_acc_now</td><td>0.5</td></tr><tr><td>val_loss</td><td>38.79092</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-37</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/8ktezvip' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/8ktezvip</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251212_113229-8ktezvip/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 19c3cv8c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 4096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251212_180857-19c3cv8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/19c3cv8c' target=\"_blank\">vocal-sweep-38</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/19c3cv8c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/19c3cv8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251212_180906_298', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 4096, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 64, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 0.5, 'lif_layer_v_threshold2': 64, 'init_scaling': [0.0625, 0.0625, 0.03125], 'learning_rate': 2, 'learning_rate2': 4, 'loser_encourage_mode': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 64, self.v_threshold 4096\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 0.5, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.0625, 0.0625, 0.03125])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=4096, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.0625, 0.0625, 0.03125])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=0.5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.0625, 0.0625, 0.03125])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 2\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 84.0\n",
      "lif layer 1 self.abs_max_v: 84.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 1 self.abs_max_out: 205.0\n",
      "lif layer 1 self.abs_max_v: 214.0\n",
      "fc layer 1 self.abs_max_out: 219.0\n",
      "lif layer 1 self.abs_max_v: 317.5\n",
      "lif layer 1 self.abs_max_v: 325.0\n",
      "layer   1  Sparsity: 74.1211%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "fc layer 1 self.abs_max_out: 311.0\n",
      "lif layer 1 self.abs_max_v: 341.5\n",
      "lif layer 1 self.abs_max_v: 385.0\n",
      "lif layer 1 self.abs_max_v: 418.5\n",
      "lif layer 1 self.abs_max_v: 446.0\n",
      "lif layer 1 self.abs_max_v: 503.0\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 1 self.abs_max_out: 313.0\n",
      "lif layer 1 self.abs_max_v: 535.5\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.81 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4672%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 24192 real_backward_count 12096  50.000%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 75.7161%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.15 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 48384 real_backward_count 24192  50.000%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-2   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.09 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 72576 real_backward_count 36288  50.000%\n",
      "layer   1  Sparsity: 74.7721%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-3   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.03 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 96768 real_backward_count 48384  50.000%\n",
      "layer   1  Sparsity: 76.6602%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.22 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 120960 real_backward_count 60480  50.000%\n",
      "layer   1  Sparsity: 83.4310%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-5   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.59 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 145152 real_backward_count 72576  50.000%\n",
      "layer   1  Sparsity: 84.4401%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-6   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.07 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 169344 real_backward_count 84672  50.000%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.34 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 193536 real_backward_count 96768  50.000%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-8   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.56 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 217728 real_backward_count 108864  50.000%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-9   lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.97 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 241920 real_backward_count 120960  50.000%\n",
      "layer   1  Sparsity: 79.0690%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.82 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 266112 real_backward_count 133056  50.000%\n",
      "layer   1  Sparsity: 86.7188%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-11  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.19 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 290304 real_backward_count 145152  50.000%\n",
      "layer   1  Sparsity: 83.8542%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-12  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.03 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 314496 real_backward_count 157248  50.000%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-13  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.87 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 338688 real_backward_count 169344  50.000%\n",
      "layer   1  Sparsity: 90.3971%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.74 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 362880 real_backward_count 181440  50.000%\n",
      "layer   1  Sparsity: 93.8151%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-15  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.27 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 387072 real_backward_count 193536  50.000%\n",
      "layer   1  Sparsity: 84.9935%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-16  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.57 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 411264 real_backward_count 205632  50.000%\n",
      "layer   1  Sparsity: 75.6510%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-17  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.42 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 435456 real_backward_count 217728  50.000%\n",
      "layer   1  Sparsity: 75.2930%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-18  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.62 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 459648 real_backward_count 229824  50.000%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.20 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 483840 real_backward_count 241920  50.000%\n",
      "layer   1  Sparsity: 81.2826%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-20  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.93 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 508032 real_backward_count 254016  50.000%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-21  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.21 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 532224 real_backward_count 266112  50.000%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-22  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.71 seconds, 2.96 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 556416 real_backward_count 278208  50.000%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.90 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 580608 real_backward_count 290304  50.000%\n",
      "layer   1  Sparsity: 75.5208%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.99 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 604800 real_backward_count 302400  50.000%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-25  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.60 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 628992 real_backward_count 314496  50.000%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-26  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.46 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 653184 real_backward_count 326592  50.000%\n",
      "layer   1  Sparsity: 72.9818%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-27  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.24 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 677376 real_backward_count 338688  50.000%\n",
      "layer   1  Sparsity: 80.7617%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.94 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 701568 real_backward_count 350784  50.000%\n",
      "layer   1  Sparsity: 80.3385%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-29  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.70 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 725760 real_backward_count 362880  50.000%\n",
      "layer   1  Sparsity: 89.8763%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.31 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 749952 real_backward_count 374976  50.000%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-31  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.40 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 774144 real_backward_count 387072  50.000%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-32  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.97 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 798336 real_backward_count 399168  50.000%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-33  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.01 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 822528 real_backward_count 411264  50.000%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-34  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.21 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 846720 real_backward_count 423360  50.000%\n",
      "layer   1  Sparsity: 87.9232%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-35  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.83 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 870912 real_backward_count 435456  50.000%\n",
      "layer   1  Sparsity: 93.9779%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.39 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 895104 real_backward_count 447552  50.000%\n",
      "layer   1  Sparsity: 80.7292%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-37  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.58 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 919296 real_backward_count 459648  50.000%\n",
      "layer   1  Sparsity: 70.4753%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-38  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.89 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4681%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 943488 real_backward_count 471744  50.000%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-39  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 171.10 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 967680 real_backward_count 483840  50.000%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-40  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.44 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 991872 real_backward_count 495936  50.000%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-41  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.83 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1016064 real_backward_count 508032  50.000%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.18 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4683%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1040256 real_backward_count 520128  50.000%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-43  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.89 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1064448 real_backward_count 532224  50.000%\n",
      "layer   1  Sparsity: 89.1276%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-44  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.11 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1088640 real_backward_count 544320  50.000%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.86 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1112832 real_backward_count 556416  50.000%\n",
      "layer   1  Sparsity: 93.5872%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.69 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1137024 real_backward_count 568512  50.000%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.05 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1161216 real_backward_count 580608  50.000%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.80 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1185408 real_backward_count 592704  50.000%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-49  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.39 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1209600 real_backward_count 604800  50.000%\n",
      "layer   1  Sparsity: 81.9336%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-50  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.90 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1233792 real_backward_count 616896  50.000%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-51  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.24 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1257984 real_backward_count 628992  50.000%\n",
      "layer   1  Sparsity: 87.6953%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-52  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.41 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1282176 real_backward_count 641088  50.000%\n",
      "layer   1  Sparsity: 91.9922%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-53  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.80 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1306368 real_backward_count 653184  50.000%\n",
      "layer   1  Sparsity: 86.3281%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-54  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.70 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1330560 real_backward_count 665280  50.000%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-55  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.33 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1354752 real_backward_count 677376  50.000%\n",
      "layer   1  Sparsity: 81.0872%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-56  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.74 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1378944 real_backward_count 689472  50.000%\n",
      "layer   1  Sparsity: 89.7135%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-57  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.97 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1403136 real_backward_count 701568  50.000%\n",
      "layer   1  Sparsity: 92.0898%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-58  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 172.97 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1427328 real_backward_count 713664  50.000%\n",
      "layer   1  Sparsity: 78.4831%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-59  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.76 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1451520 real_backward_count 725760  50.000%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-60  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.28 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1475712 real_backward_count 737856  50.000%\n",
      "layer   1  Sparsity: 75.0000%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-61  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.26 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1499904 real_backward_count 749952  50.000%\n",
      "layer   1  Sparsity: 78.5807%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.56 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1524096 real_backward_count 762048  50.000%\n",
      "layer   1  Sparsity: 80.9896%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-63  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 172.25 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1548288 real_backward_count 774144  50.000%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-64  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.21 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1572480 real_backward_count 786240  50.000%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-65  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.47 seconds, 2.96 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1596672 real_backward_count 798336  50.000%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-66  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.60 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1620864 real_backward_count 810432  50.000%\n",
      "layer   1  Sparsity: 79.1341%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-67  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.73 seconds, 2.96 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1645056 real_backward_count 822528  50.000%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-68  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.78 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1669248 real_backward_count 834624  50.000%\n",
      "layer   1  Sparsity: 89.8112%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-69  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.54 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1693440 real_backward_count 846720  50.000%\n",
      "layer   1  Sparsity: 73.4701%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-70  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.69 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1717632 real_backward_count 858816  50.000%\n",
      "layer   1  Sparsity: 73.0143%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-71  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.35 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1741824 real_backward_count 870912  50.000%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-72  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.51 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1766016 real_backward_count 883008  50.000%\n",
      "layer   1  Sparsity: 81.8685%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-73  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.81 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1790208 real_backward_count 895104  50.000%\n",
      "layer   1  Sparsity: 87.5000%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-74  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.54 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1814400 real_backward_count 907200  50.000%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-75  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.47 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1838592 real_backward_count 919296  50.000%\n",
      "layer   1  Sparsity: 87.1419%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-76  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.40 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1862784 real_backward_count 931392  50.000%\n",
      "layer   1  Sparsity: 77.6367%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-77  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.74 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1886976 real_backward_count 943488  50.000%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-78  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.52 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1911168 real_backward_count 955584  50.000%\n",
      "layer   1  Sparsity: 86.5560%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-79  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.94 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1935360 real_backward_count 967680  50.000%\n",
      "layer   1  Sparsity: 84.8307%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.82 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1959552 real_backward_count 979776  50.000%\n",
      "layer   1  Sparsity: 89.2253%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-81  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.12 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 1983744 real_backward_count 991872  50.000%\n",
      "layer   1  Sparsity: 80.7943%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-82  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.37 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2007936 real_backward_count 1003968  50.000%\n",
      "layer   1  Sparsity: 77.1159%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-83  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.48 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2032128 real_backward_count 1016064  50.000%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-84  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.86 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2056320 real_backward_count 1028160  50.000%\n",
      "layer   1  Sparsity: 73.8281%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-85  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.60 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2080512 real_backward_count 1040256  50.000%\n",
      "layer   1  Sparsity: 73.6328%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-86  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.60 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2104704 real_backward_count 1052352  50.000%\n",
      "layer   1  Sparsity: 81.3477%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-87  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 172.45 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2128896 real_backward_count 1064448  50.000%\n",
      "layer   1  Sparsity: 79.4596%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-88  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.61 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2153088 real_backward_count 1076544  50.000%\n",
      "layer   1  Sparsity: 91.8945%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-89  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 171.72 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2177280 real_backward_count 1088640  50.000%\n",
      "layer   1  Sparsity: 84.6029%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-90  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.14 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2201472 real_backward_count 1100736  50.000%\n",
      "layer   1  Sparsity: 82.7474%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-91  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.29 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2225664 real_backward_count 1112832  50.000%\n",
      "layer   1  Sparsity: 81.3151%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-92  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.15 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2249856 real_backward_count 1124928  50.000%\n",
      "layer   1  Sparsity: 80.9570%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-93  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.98 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2274048 real_backward_count 1137024  50.000%\n",
      "layer   1  Sparsity: 77.0182%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-94  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.27 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2298240 real_backward_count 1149120  50.000%\n",
      "layer   1  Sparsity: 68.0013%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-95  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.38 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4686%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2322432 real_backward_count 1161216  50.000%\n",
      "layer   1  Sparsity: 90.1693%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-96  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.09 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2346624 real_backward_count 1173312  50.000%\n",
      "layer   1  Sparsity: 72.0378%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-97  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.37 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2370816 real_backward_count 1185408  50.000%\n",
      "layer   1  Sparsity: 78.7435%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-98  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.07 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2395008 real_backward_count 1197504  50.000%\n",
      "layer   1  Sparsity: 79.8503%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-99  lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.44 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2419200 real_backward_count 1209600  50.000%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-100 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.65 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2443392 real_backward_count 1221696  50.000%\n",
      "layer   1  Sparsity: 68.5221%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-101 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.84 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4685%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2467584 real_backward_count 1233792  50.000%\n",
      "layer   1  Sparsity: 85.3516%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-102 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.75 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2491776 real_backward_count 1245888  50.000%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-103 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.56 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2515968 real_backward_count 1257984  50.000%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-104 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.74 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2540160 real_backward_count 1270080  50.000%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-105 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.37 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2564352 real_backward_count 1282176  50.000%\n",
      "layer   1  Sparsity: 84.8958%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-106 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.06 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2588544 real_backward_count 1294272  50.000%\n",
      "layer   1  Sparsity: 90.8203%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-107 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.13 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4635%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2612736 real_backward_count 1306368  50.000%\n",
      "layer   1  Sparsity: 86.2305%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-108 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.45 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2636928 real_backward_count 1318464  50.000%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-109 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.72 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2661120 real_backward_count 1330560  50.000%\n",
      "layer   1  Sparsity: 88.2161%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-110 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.98 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2685312 real_backward_count 1342656  50.000%\n",
      "layer   1  Sparsity: 80.5013%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-111 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.07 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2709504 real_backward_count 1354752  50.000%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-112 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.20 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2733696 real_backward_count 1366848  50.000%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-113 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 171.02 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2757888 real_backward_count 1378944  50.000%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.29 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2782080 real_backward_count 1391040  50.000%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-115 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.13 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4664%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2806272 real_backward_count 1403136  50.000%\n",
      "layer   1  Sparsity: 86.7513%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.82 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2830464 real_backward_count 1415232  50.000%\n",
      "layer   1  Sparsity: 70.9635%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-117 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.25 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2854656 real_backward_count 1427328  50.000%\n",
      "layer   1  Sparsity: 87.2721%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-118 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.04 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2878848 real_backward_count 1439424  50.000%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.61 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2903040 real_backward_count 1451520  50.000%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-120 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.68 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2927232 real_backward_count 1463616  50.000%\n",
      "layer   1  Sparsity: 81.5104%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-121 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.36 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2951424 real_backward_count 1475712  50.000%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-122 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.37 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2975616 real_backward_count 1487808  50.000%\n",
      "layer   1  Sparsity: 88.1510%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-123 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.65 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 2999808 real_backward_count 1499904  50.000%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-124 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.41 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3024000 real_backward_count 1512000  50.000%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-125 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.16 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3048192 real_backward_count 1524096  50.000%\n",
      "layer   1  Sparsity: 72.4284%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-126 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.93 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4676%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3072384 real_backward_count 1536192  50.000%\n",
      "layer   1  Sparsity: 75.6185%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.34 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3096576 real_backward_count 1548288  50.000%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.52 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3120768 real_backward_count 1560384  50.000%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.02 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3144960 real_backward_count 1572480  50.000%\n",
      "layer   1  Sparsity: 89.6159%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-130 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.16 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3169152 real_backward_count 1584576  50.000%\n",
      "layer   1  Sparsity: 88.8997%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-131 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.80 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3193344 real_backward_count 1596672  50.000%\n",
      "layer   1  Sparsity: 77.5065%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-132 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.21 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3217536 real_backward_count 1608768  50.000%\n",
      "layer   1  Sparsity: 87.4349%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-133 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.04 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3241728 real_backward_count 1620864  50.000%\n",
      "layer   1  Sparsity: 75.8464%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-134 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.47 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3265920 real_backward_count 1632960  50.000%\n",
      "layer   1  Sparsity: 81.8359%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-135 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 177.32 seconds, 2.96 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3290112 real_backward_count 1645056  50.000%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-136 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.24 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3314304 real_backward_count 1657152  50.000%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-137 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.43 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3338496 real_backward_count 1669248  50.000%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-138 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 171.44 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3362688 real_backward_count 1681344  50.000%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-139 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.32 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3386880 real_backward_count 1693440  50.000%\n",
      "layer   1  Sparsity: 94.2057%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-140 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.20 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3411072 real_backward_count 1705536  50.000%\n",
      "layer   1  Sparsity: 79.6875%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-141 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.18 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3435264 real_backward_count 1717632  50.000%\n",
      "layer   1  Sparsity: 71.0938%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-142 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.65 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3459456 real_backward_count 1729728  50.000%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-143 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.10 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3483648 real_backward_count 1741824  50.000%\n",
      "layer   1  Sparsity: 93.3594%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-144 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.53 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4630%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3507840 real_backward_count 1753920  50.000%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-145 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.54 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3532032 real_backward_count 1766016  50.000%\n",
      "layer   1  Sparsity: 75.9766%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-146 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.20 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3556224 real_backward_count 1778112  50.000%\n",
      "layer   1  Sparsity: 81.7057%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.56 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3580416 real_backward_count 1790208  50.000%\n",
      "layer   1  Sparsity: 85.2539%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-148 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.94 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3604608 real_backward_count 1802304  50.000%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-149 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.92 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3628800 real_backward_count 1814400  50.000%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-150 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.39 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3652992 real_backward_count 1826496  50.000%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-151 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.90 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3677184 real_backward_count 1838592  50.000%\n",
      "layer   1  Sparsity: 84.7331%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-152 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.51 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3701376 real_backward_count 1850688  50.000%\n",
      "layer   1  Sparsity: 81.2500%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-153 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.56 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3725568 real_backward_count 1862784  50.000%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-154 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.69 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3749760 real_backward_count 1874880  50.000%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-155 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.47 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3773952 real_backward_count 1886976  50.000%\n",
      "layer   1  Sparsity: 88.9974%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-156 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.03 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3798144 real_backward_count 1899072  50.000%\n",
      "layer   1  Sparsity: 78.7109%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-157 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.68 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3822336 real_backward_count 1911168  50.000%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.09 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3846528 real_backward_count 1923264  50.000%\n",
      "layer   1  Sparsity: 85.7422%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-159 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.89 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3870720 real_backward_count 1935360  50.000%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-160 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.50 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3894912 real_backward_count 1947456  50.000%\n",
      "layer   1  Sparsity: 63.6068%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-161 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.46 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4696%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3919104 real_backward_count 1959552  50.000%\n",
      "layer   1  Sparsity: 93.6523%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-162 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 172.25 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3943296 real_backward_count 1971648  50.000%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-163 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.79 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3967488 real_backward_count 1983744  50.000%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-164 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.18 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 3991680 real_backward_count 1995840  50.000%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-165 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.94 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4015872 real_backward_count 2007936  50.000%\n",
      "layer   1  Sparsity: 73.9909%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-166 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.38 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4040064 real_backward_count 2020032  50.000%\n",
      "layer   1  Sparsity: 84.5378%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-167 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.81 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4064256 real_backward_count 2032128  50.000%\n",
      "layer   1  Sparsity: 82.7799%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-168 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.72 seconds, 2.95 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4088448 real_backward_count 2044224  50.000%\n",
      "layer   1  Sparsity: 91.1784%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-169 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 179.40 seconds, 2.99 minutes\n",
      "layer   1  Sparsity: 81.4634%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4112640 real_backward_count 2056320  50.000%\n",
      "layer   1  Sparsity: 79.0365%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-170 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 183.09 seconds, 3.05 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4136832 real_backward_count 2068416  50.000%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-171 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.76 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4161024 real_backward_count 2080512  50.000%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-172 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.38 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4185216 real_backward_count 2092608  50.000%\n",
      "layer   1  Sparsity: 86.4909%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-173 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.00 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4209408 real_backward_count 2104704  50.000%\n",
      "layer   1  Sparsity: 94.4010%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-174 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.95 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4627%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4233600 real_backward_count 2116800  50.000%\n",
      "layer   1  Sparsity: 92.1875%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.25 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4257792 real_backward_count 2128896  50.000%\n",
      "layer   1  Sparsity: 76.1068%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-176 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.20 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4281984 real_backward_count 2140992  50.000%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-177 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.89 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4306176 real_backward_count 2153088  50.000%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-178 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.42 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4330368 real_backward_count 2165184  50.000%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-179 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.68 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4354560 real_backward_count 2177280  50.000%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-180 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.28 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4378752 real_backward_count 2189376  50.000%\n",
      "layer   1  Sparsity: 88.6393%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-181 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.34 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4640%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4402944 real_backward_count 2201472  50.000%\n",
      "layer   1  Sparsity: 59.0495%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-182 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.19 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4706%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4427136 real_backward_count 2213568  50.000%\n",
      "layer   1  Sparsity: 79.7201%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-183 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.06 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4451328 real_backward_count 2225664  50.000%\n",
      "layer   1  Sparsity: 76.4323%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-184 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.28 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4475520 real_backward_count 2237760  50.000%\n",
      "layer   1  Sparsity: 88.1185%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.63 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4499712 real_backward_count 2249856  50.000%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 172.58 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4523904 real_backward_count 2261952  50.000%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-187 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.34 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4548096 real_backward_count 2274048  50.000%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-188 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.13 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4572288 real_backward_count 2286144  50.000%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-189 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.72 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4596480 real_backward_count 2298240  50.000%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-190 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.49 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4620672 real_backward_count 2310336  50.000%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-191 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.17 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4644864 real_backward_count 2322432  50.000%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-192 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.62 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4669056 real_backward_count 2334528  50.000%\n",
      "layer   1  Sparsity: 64.3555%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-193 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 173.48 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4694%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4693248 real_backward_count 2346624  50.000%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-194 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.85 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4717440 real_backward_count 2358720  50.000%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-195 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.56 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4741632 real_backward_count 2370816  50.000%\n",
      "layer   1  Sparsity: 83.9193%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.94 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4765824 real_backward_count 2382912  50.000%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-197 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 174.74 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4790016 real_backward_count 2395008  50.000%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-198 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 175.77 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "total_backward_count 4814208 real_backward_count 2407104  50.000%\n",
      "layer   1  Sparsity: 71.8424%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "train - Value 0: 4032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-199 lr=['2.0000000'], tr/val_loss:  2.302637/  2.302529, val:  50.00%, val_best:  50.00%, tr:  50.00%, tr_best:  50.00%, epoch time: 176.46 seconds, 2.94 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   3  Sparsity: 100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d71baaa2774c3f87486b5e62645283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.5</td></tr><tr><td>tr_epoch_loss</td><td>2.30264</td></tr><tr><td>val_acc_best</td><td>0.5</td></tr><tr><td>val_acc_now</td><td>0.5</td></tr><tr><td>val_loss</td><td>2.30253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-sweep-38</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/19c3cv8c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/19c3cv8c</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251212_180857-19c3cv8c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvhdl5he with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251213_035420-uvhdl5he</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uvhdl5he' target=\"_blank\">dandy-sweep-39</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uvhdl5he' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uvhdl5he</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251213_035430_041', 'my_seed': 42, 'TIME': 4, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 64, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 2, 'lif_layer_v_threshold2': 64, 'init_scaling': [0.5, 0.25, 0.0625], 'learning_rate': 1, 'learning_rate2': 1, 'loser_encourage_mode': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 4, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 2, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=4, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=4, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 1\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 1132.0\n",
      "lif layer 1 self.abs_max_v: 1132.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 607.0\n",
      "lif layer 2 self.abs_max_v: 607.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 50.0\n",
      "fc layer 1 self.abs_max_out: 1739.0\n",
      "lif layer 1 self.abs_max_v: 1980.0\n",
      "lif layer 2 self.abs_max_v: 679.0\n",
      "fc layer 3 self.abs_max_out: 84.0\n",
      "lif layer 1 self.abs_max_v: 2041.0\n",
      "lif layer 2 self.abs_max_v: 728.5\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 66.2500%\n",
      "fc layer 3 self.abs_max_out: 92.0\n",
      "fc layer 1 self.abs_max_out: 1823.0\n",
      "fc layer 2 self.abs_max_out: 693.0\n",
      "lif layer 2 self.abs_max_v: 845.0\n",
      "fc layer 3 self.abs_max_out: 98.0\n",
      "lif layer 1 self.abs_max_v: 2046.5\n",
      "lif layer 2 self.abs_max_v: 987.0\n",
      "fc layer 1 self.abs_max_out: 1982.0\n",
      "lif layer 1 self.abs_max_v: 2095.5\n",
      "fc layer 2 self.abs_max_out: 739.0\n",
      "fc layer 1 self.abs_max_out: 2060.0\n",
      "lif layer 1 self.abs_max_v: 2779.0\n",
      "lif layer 2 self.abs_max_v: 1038.5\n",
      "lif layer 2 self.abs_max_v: 1057.0\n",
      "fc layer 3 self.abs_max_out: 100.0\n",
      "fc layer 1 self.abs_max_out: 2077.0\n",
      "lif layer 1 self.abs_max_v: 2801.0\n",
      "fc layer 2 self.abs_max_out: 781.0\n",
      "lif layer 1 self.abs_max_v: 2897.5\n",
      "fc layer 3 self.abs_max_out: 126.0\n",
      "fc layer 1 self.abs_max_out: 2100.0\n",
      "fc layer 1 self.abs_max_out: 2210.0\n",
      "fc layer 1 self.abs_max_out: 2287.0\n",
      "lif layer 2 self.abs_max_v: 1070.0\n",
      "fc layer 1 self.abs_max_out: 2290.0\n",
      "lif layer 2 self.abs_max_v: 1158.0\n",
      "lif layer 1 self.abs_max_v: 2991.5\n",
      "fc layer 2 self.abs_max_out: 783.0\n",
      "lif layer 2 self.abs_max_v: 1234.5\n",
      "fc layer 2 self.abs_max_out: 792.0\n",
      "lif layer 2 self.abs_max_v: 1288.0\n",
      "fc layer 2 self.abs_max_out: 852.0\n",
      "fc layer 1 self.abs_max_out: 2295.0\n",
      "lif layer 2 self.abs_max_v: 1320.5\n",
      "fc layer 2 self.abs_max_out: 868.0\n",
      "fc layer 1 self.abs_max_out: 2346.0\n",
      "fc layer 1 self.abs_max_out: 2376.0\n",
      "lif layer 1 self.abs_max_v: 3439.5\n",
      "fc layer 2 self.abs_max_out: 881.0\n",
      "fc layer 2 self.abs_max_out: 904.0\n",
      "fc layer 2 self.abs_max_out: 922.0\n",
      "fc layer 2 self.abs_max_out: 980.0\n",
      "fc layer 2 self.abs_max_out: 994.0\n",
      "fc layer 2 self.abs_max_out: 999.0\n",
      "lif layer 2 self.abs_max_v: 1337.5\n",
      "lif layer 2 self.abs_max_v: 1375.0\n",
      "lif layer 2 self.abs_max_v: 1388.0\n",
      "lif layer 2 self.abs_max_v: 1501.5\n",
      "fc layer 1 self.abs_max_out: 2416.0\n",
      "fc layer 2 self.abs_max_out: 1051.0\n",
      "lif layer 2 self.abs_max_v: 1519.0\n",
      "fc layer 1 self.abs_max_out: 2583.0\n",
      "lif layer 2 self.abs_max_v: 1548.0\n",
      "fc layer 1 self.abs_max_out: 2586.0\n",
      "lif layer 1 self.abs_max_v: 3749.0\n",
      "lif layer 2 self.abs_max_v: 1578.0\n",
      "lif layer 2 self.abs_max_v: 1623.0\n",
      "lif layer 2 self.abs_max_v: 1692.5\n",
      "lif layer 2 self.abs_max_v: 1731.0\n",
      "fc layer 1 self.abs_max_out: 2607.0\n",
      "fc layer 2 self.abs_max_out: 1078.0\n",
      "lif layer 2 self.abs_max_v: 1791.0\n",
      "fc layer 2 self.abs_max_out: 1096.0\n",
      "fc layer 1 self.abs_max_out: 2722.0\n",
      "lif layer 2 self.abs_max_v: 1839.0\n",
      "fc layer 2 self.abs_max_out: 1145.0\n",
      "lif layer 2 self.abs_max_v: 1845.5\n",
      "fc layer 2 self.abs_max_out: 1167.0\n",
      "lif layer 2 self.abs_max_v: 1862.5\n",
      "lif layer 2 self.abs_max_v: 1968.5\n",
      "fc layer 2 self.abs_max_out: 1195.0\n",
      "lif layer 2 self.abs_max_v: 2011.0\n",
      "fc layer 2 self.abs_max_out: 1223.0\n",
      "fc layer 1 self.abs_max_out: 2753.0\n",
      "fc layer 1 self.abs_max_out: 2815.0\n",
      "fc layer 1 self.abs_max_out: 2907.0\n",
      "fc layer 1 self.abs_max_out: 2923.0\n",
      "fc layer 3 self.abs_max_out: 134.0\n",
      "fc layer 3 self.abs_max_out: 141.0\n",
      "fc layer 2 self.abs_max_out: 1236.0\n",
      "fc layer 2 self.abs_max_out: 1269.0\n",
      "fc layer 2 self.abs_max_out: 1281.0\n",
      "fc layer 2 self.abs_max_out: 1283.0\n",
      "fc layer 2 self.abs_max_out: 1295.0\n",
      "fc layer 2 self.abs_max_out: 1298.0\n",
      "fc layer 2 self.abs_max_out: 1390.0\n",
      "fc layer 2 self.abs_max_out: 1400.0\n",
      "fc layer 2 self.abs_max_out: 1444.0\n",
      "fc layer 2 self.abs_max_out: 1451.0\n",
      "fc layer 2 self.abs_max_out: 1479.0\n",
      "fc layer 2 self.abs_max_out: 1491.0\n",
      "lif layer 2 self.abs_max_v: 2014.0\n",
      "lif layer 2 self.abs_max_v: 2041.0\n",
      "fc layer 1 self.abs_max_out: 2924.0\n",
      "fc layer 2 self.abs_max_out: 1536.0\n",
      "fc layer 2 self.abs_max_out: 1554.0\n",
      "lif layer 2 self.abs_max_v: 2058.5\n",
      "fc layer 2 self.abs_max_out: 1562.0\n",
      "fc layer 2 self.abs_max_out: 1587.0\n",
      "fc layer 2 self.abs_max_out: 1621.0\n",
      "fc layer 1 self.abs_max_out: 2938.0\n",
      "fc layer 1 self.abs_max_out: 2954.0\n",
      "fc layer 2 self.abs_max_out: 1636.0\n",
      "fc layer 2 self.abs_max_out: 1663.0\n",
      "lif layer 2 self.abs_max_v: 2076.5\n",
      "fc layer 2 self.abs_max_out: 1683.0\n",
      "fc layer 1 self.abs_max_out: 2977.0\n",
      "fc layer 1 self.abs_max_out: 3047.0\n",
      "fc layer 1 self.abs_max_out: 3130.0\n",
      "fc layer 1 self.abs_max_out: 3151.0\n",
      "lif layer 2 self.abs_max_v: 2130.0\n",
      "fc layer 2 self.abs_max_out: 1707.0\n",
      "fc layer 3 self.abs_max_out: 142.0\n",
      "fc layer 1 self.abs_max_out: 3193.0\n",
      "fc layer 3 self.abs_max_out: 144.0\n",
      "lif layer 1 self.abs_max_v: 3802.0\n",
      "lif layer 2 self.abs_max_v: 2139.0\n",
      "lif layer 1 self.abs_max_v: 4012.5\n",
      "lif layer 1 self.abs_max_v: 4174.5\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 209.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 255.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 266.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 303.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 322.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 338.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 357.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 386.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-0   lr=['1.0000000'], tr/val_loss: 48.335468/ 57.525311, val:  58.19%, val_best:  58.19%, tr:  77.65%, tr_best:  77.65%, epoch time: 120.23 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 63.0919%\n",
      "layer   3  Sparsity: 60.4007%\n",
      "total_backward_count 16128 real_backward_count 4558  28.261%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 73.3398%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 52.8750%\n",
      "fc layer 3 self.abs_max_out: 184.0\n",
      "fc layer 1 self.abs_max_out: 3239.0\n",
      "fc layer 1 self.abs_max_out: 3242.0\n",
      "lif layer 1 self.abs_max_v: 4249.5\n",
      "fc layer 3 self.abs_max_out: 210.0\n",
      "fc layer 2 self.abs_max_out: 1723.0\n",
      "fc layer 2 self.abs_max_out: 1742.0\n",
      "fc layer 2 self.abs_max_out: 1766.0\n",
      "fc layer 2 self.abs_max_out: 1806.0\n",
      "fc layer 2 self.abs_max_out: 1809.0\n",
      "fc layer 2 self.abs_max_out: 1821.0\n",
      "fc layer 2 self.abs_max_out: 1937.0\n",
      "fc layer 1 self.abs_max_out: 3304.0\n",
      "fc layer 2 self.abs_max_out: 1963.0\n",
      "fc layer 2 self.abs_max_out: 2044.0\n",
      "fc layer 2 self.abs_max_out: 2061.0\n",
      "fc layer 2 self.abs_max_out: 2089.0\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 1 self.abs_max_out: 3421.0\n",
      "max_activation_accul updated: 428.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 444.00 at epoch 1, iter 4031\n",
      "fc layer 1 self.abs_max_out: 3435.0\n",
      "max_activation_accul updated: 481.00 at epoch 1, iter 4031\n",
      "fc layer 1 self.abs_max_out: 3441.0\n",
      "fc layer 1 self.abs_max_out: 3560.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-1   lr=['1.0000000'], tr/val_loss: 59.448986/ 56.630543, val:  52.65%, val_best:  58.19%, tr:  87.33%, tr_best:  87.33%, epoch time: 119.76 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 61.7961%\n",
      "layer   3  Sparsity: 54.8633%\n",
      "total_backward_count 32256 real_backward_count 8196  25.409%\n",
      "layer   1  Sparsity: 81.4453%\n",
      "layer   2  Sparsity: 66.8750%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "fc layer 2 self.abs_max_out: 2127.0\n",
      "fc layer 2 self.abs_max_out: 2130.0\n",
      "fc layer 2 self.abs_max_out: 2165.0\n",
      "lif layer 2 self.abs_max_v: 2165.0\n",
      "fc layer 2 self.abs_max_out: 2206.0\n",
      "lif layer 2 self.abs_max_v: 2206.0\n",
      "fc layer 2 self.abs_max_out: 2230.0\n",
      "lif layer 2 self.abs_max_v: 2230.0\n",
      "fc layer 2 self.abs_max_out: 2291.0\n",
      "lif layer 2 self.abs_max_v: 2291.0\n",
      "lif layer 1 self.abs_max_v: 4398.5\n",
      "fc layer 1 self.abs_max_out: 3581.0\n",
      "fc layer 2 self.abs_max_out: 2294.0\n",
      "lif layer 2 self.abs_max_v: 2294.0\n",
      "lif layer 1 self.abs_max_v: 4415.5\n",
      "fc layer 3 self.abs_max_out: 230.0\n",
      "lif layer 1 self.abs_max_v: 4459.0\n",
      "lif layer 2 self.abs_max_v: 2346.0\n",
      "lif layer 2 self.abs_max_v: 2354.0\n",
      "fc layer 2 self.abs_max_out: 2310.0\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 2312.0\n",
      "fc layer 2 self.abs_max_out: 2355.0\n",
      "lif layer 2 self.abs_max_v: 2355.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-2   lr=['1.0000000'], tr/val_loss: 63.446388/ 82.156776, val:  51.55%, val_best:  58.19%, tr:  87.50%, tr_best:  87.50%, epoch time: 120.31 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 60.8667%\n",
      "layer   3  Sparsity: 52.6297%\n",
      "total_backward_count 48384 real_backward_count 11758  24.301%\n",
      "layer   1  Sparsity: 72.9980%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 53.8750%\n",
      "fc layer 2 self.abs_max_out: 2357.0\n",
      "lif layer 2 self.abs_max_v: 2357.0\n",
      "fc layer 2 self.abs_max_out: 2387.0\n",
      "lif layer 2 self.abs_max_v: 2387.0\n",
      "lif layer 2 self.abs_max_v: 2545.5\n",
      "fc layer 2 self.abs_max_out: 2458.0\n",
      "fc layer 1 self.abs_max_out: 3602.0\n",
      "fc layer 1 self.abs_max_out: 3650.0\n",
      "fc layer 1 self.abs_max_out: 3861.0\n",
      "fc layer 2 self.abs_max_out: 2482.0\n",
      "lif layer 1 self.abs_max_v: 4537.5\n",
      "lif layer 1 self.abs_max_v: 4867.0\n",
      "fc layer 2 self.abs_max_out: 2526.0\n",
      "fc layer 2 self.abs_max_out: 2557.0\n",
      "lif layer 2 self.abs_max_v: 2557.0\n",
      "fc layer 3 self.abs_max_out: 263.0\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 548.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 595.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 649.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 720.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 722.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 746.00 at epoch 3, iter 4031\n",
      "fc layer 1 self.abs_max_out: 3894.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['1.0000000'], tr/val_loss: 76.216072/141.434738, val:  50.00%, val_best:  58.19%, tr:  90.70%, tr_best:  90.70%, epoch time: 120.55 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 60.1872%\n",
      "layer   3  Sparsity: 45.1181%\n",
      "total_backward_count 64512 real_backward_count 14939  23.157%\n",
      "layer   1  Sparsity: 73.9258%\n",
      "layer   2  Sparsity: 57.8750%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "fc layer 1 self.abs_max_out: 4287.0\n",
      "lif layer 1 self.abs_max_v: 4898.0\n",
      "lif layer 1 self.abs_max_v: 5256.0\n",
      "lif layer 1 self.abs_max_v: 5264.5\n",
      "fc layer 3 self.abs_max_out: 279.0\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 224 occurrences\n",
      "test - Value 1: 228 occurrences\n",
      "epoch-4   lr=['1.0000000'], tr/val_loss: 84.324326/123.376274, val:  82.74%, val_best:  82.74%, tr:  91.69%, tr_best:  91.69%, epoch time: 121.11 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 60.6579%\n",
      "layer   3  Sparsity: 41.9723%\n",
      "total_backward_count 80640 real_backward_count 18104  22.450%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 66.1250%\n",
      "layer   3  Sparsity: 41.5000%\n",
      "fc layer 1 self.abs_max_out: 4451.0\n",
      "fc layer 2 self.abs_max_out: 2616.0\n",
      "lif layer 2 self.abs_max_v: 2616.0\n",
      "lif layer 1 self.abs_max_v: 5551.0\n",
      "fc layer 3 self.abs_max_out: 295.0\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 73 occurrences\n",
      "test - Value 1: 379 occurrences\n",
      "epoch-5   lr=['1.0000000'], tr/val_loss: 82.572121/118.839432, val:  65.71%, val_best:  82.74%, tr:  91.37%, tr_best:  91.69%, epoch time: 121.46 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 61.1039%\n",
      "layer   3  Sparsity: 42.3468%\n",
      "total_backward_count 96768 real_backward_count 21138  21.844%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 36.5000%\n",
      "lif layer 1 self.abs_max_v: 5736.0\n",
      "fc layer 2 self.abs_max_out: 2703.0\n",
      "lif layer 2 self.abs_max_v: 2703.0\n",
      "lif layer 1 self.abs_max_v: 5890.0\n",
      "lif layer 1 self.abs_max_v: 6223.5\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 751.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 833.00 at epoch 6, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-6   lr=['1.0000000'], tr/val_loss: 88.004128/131.700928, val:  71.24%, val_best:  82.74%, tr:  92.86%, tr_best:  92.86%, epoch time: 120.14 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 61.0044%\n",
      "layer   3  Sparsity: 41.0865%\n",
      "total_backward_count 112896 real_backward_count 24096  21.344%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 64.6250%\n",
      "layer   3  Sparsity: 42.7500%\n",
      "fc layer 1 self.abs_max_out: 4455.0\n",
      "fc layer 1 self.abs_max_out: 4533.0\n",
      "fc layer 1 self.abs_max_out: 4707.0\n",
      "lif layer 1 self.abs_max_v: 7087.5\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 300 occurrences\n",
      "test - Value 1: 152 occurrences\n",
      "epoch-7   lr=['1.0000000'], tr/val_loss: 90.223061/ 84.445343, val:  80.09%, val_best:  82.74%, tr:  92.86%, tr_best:  92.86%, epoch time: 121.48 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 61.0535%\n",
      "layer   3  Sparsity: 40.3721%\n",
      "total_backward_count 129024 real_backward_count 27025  20.946%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 61.8750%\n",
      "layer   3  Sparsity: 42.5000%\n",
      "fc layer 2 self.abs_max_out: 2778.0\n",
      "lif layer 2 self.abs_max_v: 2778.0\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-8   lr=['1.0000000'], tr/val_loss: 95.801926/ 90.273453, val:  81.86%, val_best:  82.74%, tr:  94.35%, tr_best:  94.35%, epoch time: 120.91 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 58.8461%\n",
      "layer   3  Sparsity: 38.8788%\n",
      "total_backward_count 145152 real_backward_count 29786  20.521%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 44.8750%\n",
      "fc layer 3 self.abs_max_out: 300.0\n",
      "fc layer 3 self.abs_max_out: 308.0\n",
      "lif layer 2 self.abs_max_v: 2879.5\n",
      "lif layer 2 self.abs_max_v: 3037.5\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-9   lr=['1.0000000'], tr/val_loss: 94.301514/128.296234, val:  59.07%, val_best:  82.74%, tr:  93.38%, tr_best:  94.35%, epoch time: 119.27 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 58.7975%\n",
      "layer   3  Sparsity: 40.7194%\n",
      "total_backward_count 161280 real_backward_count 32485  20.142%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 42.2500%\n",
      "fc layer 2 self.abs_max_out: 2811.0\n",
      "fc layer 2 self.abs_max_out: 2993.0\n",
      "fc layer 2 self.abs_max_out: 3063.0\n",
      "lif layer 2 self.abs_max_v: 3063.0\n",
      "fc layer 2 self.abs_max_out: 3131.0\n",
      "lif layer 2 self.abs_max_v: 3131.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 188 occurrences\n",
      "test - Value 1: 264 occurrences\n",
      "epoch-10  lr=['1.0000000'], tr/val_loss: 94.684105/ 93.611717, val:  85.84%, val_best:  85.84%, tr:  95.09%, tr_best:  95.09%, epoch time: 119.09 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 58.6438%\n",
      "layer   3  Sparsity: 38.5955%\n",
      "total_backward_count 177408 real_backward_count 35076  19.771%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 40.0000%\n",
      "fc layer 3 self.abs_max_out: 322.0\n",
      "fc layer 2 self.abs_max_out: 3215.0\n",
      "lif layer 2 self.abs_max_v: 3215.0\n",
      "fc layer 1 self.abs_max_out: 4934.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-11  lr=['1.0000000'], tr/val_loss: 94.876335/ 91.728714, val:  85.40%, val_best:  85.84%, tr:  94.69%, tr_best:  95.09%, epoch time: 120.95 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 58.4704%\n",
      "layer   3  Sparsity: 44.2751%\n",
      "total_backward_count 193536 real_backward_count 37594  19.425%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 46.8750%\n",
      "fc layer 1 self.abs_max_out: 5076.0\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-12  lr=['1.0000000'], tr/val_loss: 94.381439/ 80.782333, val:  81.64%, val_best:  85.84%, tr:  95.66%, tr_best:  95.66%, epoch time: 121.89 seconds, 2.03 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 58.7314%\n",
      "layer   3  Sparsity: 44.5151%\n",
      "total_backward_count 209664 real_backward_count 39961  19.060%\n",
      "layer   1  Sparsity: 87.1094%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 44.2500%\n",
      "fc layer 1 self.abs_max_out: 5109.0\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 834.00 at epoch 13, iter 4031\n",
      "fc layer 1 self.abs_max_out: 5160.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 119 occurrences\n",
      "test - Value 1: 333 occurrences\n",
      "epoch-13  lr=['1.0000000'], tr/val_loss: 96.343811/136.739944, val:  73.67%, val_best:  85.84%, tr:  96.53%, tr_best:  96.53%, epoch time: 120.97 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 59.1967%\n",
      "layer   3  Sparsity: 42.4552%\n",
      "total_backward_count 225792 real_backward_count 42230  18.703%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 62.8750%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "fc layer 1 self.abs_max_out: 5266.0\n",
      "fc layer 1 self.abs_max_out: 5316.0\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-14  lr=['1.0000000'], tr/val_loss: 97.408600/ 96.612251, val:  71.24%, val_best:  85.84%, tr:  96.75%, tr_best:  96.75%, epoch time: 116.83 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 58.8952%\n",
      "layer   3  Sparsity: 44.4179%\n",
      "total_backward_count 241920 real_backward_count 44448  18.373%\n",
      "layer   1  Sparsity: 92.3340%\n",
      "layer   2  Sparsity: 72.8750%\n",
      "layer   3  Sparsity: 59.8750%\n",
      "fc layer 1 self.abs_max_out: 5389.0\n",
      "fc layer 1 self.abs_max_out: 5594.0\n",
      "fc layer 3 self.abs_max_out: 326.0\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-15  lr=['1.0000000'], tr/val_loss: 95.311028/ 63.463459, val:  86.06%, val_best:  86.06%, tr:  97.05%, tr_best:  97.05%, epoch time: 119.47 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 58.6334%\n",
      "layer   3  Sparsity: 44.4085%\n",
      "total_backward_count 258048 real_backward_count 46542  18.036%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "fc layer 1 self.abs_max_out: 5646.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 885.00 at epoch 16, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-16  lr=['1.0000000'], tr/val_loss:103.684738/101.716347, val:  76.77%, val_best:  86.06%, tr:  97.35%, tr_best:  97.35%, epoch time: 119.70 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 58.2742%\n",
      "layer   3  Sparsity: 41.0528%\n",
      "total_backward_count 274176 real_backward_count 48587  17.721%\n",
      "layer   1  Sparsity: 72.9004%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 29.3750%\n",
      "fc layer 3 self.abs_max_out: 337.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 975.00 at epoch 17, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-17  lr=['1.0000000'], tr/val_loss:102.497299/158.806778, val:  51.55%, val_best:  86.06%, tr:  97.02%, tr_best:  97.35%, epoch time: 120.86 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 58.8514%\n",
      "layer   3  Sparsity: 41.2074%\n",
      "total_backward_count 290304 real_backward_count 50678  17.457%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 57.8750%\n",
      "layer   3  Sparsity: 43.0000%\n",
      "fc layer 2 self.abs_max_out: 3338.0\n",
      "lif layer 2 self.abs_max_v: 3338.0\n",
      "fc layer 1 self.abs_max_out: 5769.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 60 occurrences\n",
      "test - Value 1: 392 occurrences\n",
      "epoch-18  lr=['1.0000000'], tr/val_loss:116.864685/134.010452, val:  62.83%, val_best:  86.06%, tr:  98.14%, tr_best:  98.14%, epoch time: 120.56 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 59.2662%\n",
      "layer   3  Sparsity: 41.3040%\n",
      "total_backward_count 306432 real_backward_count 52650  17.182%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 36.7500%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 305 occurrences\n",
      "test - Value 1: 147 occurrences\n",
      "epoch-19  lr=['1.0000000'], tr/val_loss:104.021858/ 56.871284, val:  79.87%, val_best:  86.06%, tr:  97.99%, tr_best:  98.14%, epoch time: 120.79 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 59.2568%\n",
      "layer   3  Sparsity: 43.4556%\n",
      "total_backward_count 322560 real_backward_count 54577  16.920%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 45.8750%\n",
      "fc layer 1 self.abs_max_out: 5788.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-20  lr=['1.0000000'], tr/val_loss:102.747231/ 75.119667, val:  87.39%, val_best:  87.39%, tr:  97.99%, tr_best:  98.14%, epoch time: 120.46 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.3048%\n",
      "layer   3  Sparsity: 43.4102%\n",
      "total_backward_count 338688 real_backward_count 56584  16.707%\n",
      "layer   1  Sparsity: 84.8633%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 42.5000%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-21  lr=['1.0000000'], tr/val_loss:107.833160/ 86.814171, val:  86.50%, val_best:  87.39%, tr:  98.19%, tr_best:  98.19%, epoch time: 119.49 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 59.3578%\n",
      "layer   3  Sparsity: 43.8021%\n",
      "total_backward_count 354816 real_backward_count 58491  16.485%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 43.8750%\n",
      "fc layer 3 self.abs_max_out: 341.0\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 3379.0\n",
      "lif layer 2 self.abs_max_v: 3379.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-22  lr=['1.0000000'], tr/val_loss:116.701454/126.673698, val:  61.50%, val_best:  87.39%, tr:  97.97%, tr_best:  98.19%, epoch time: 120.21 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 58.4054%\n",
      "layer   3  Sparsity: 42.1757%\n",
      "total_backward_count 370944 real_backward_count 60485  16.306%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 42.6250%\n",
      "fc layer 3 self.abs_max_out: 363.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-23  lr=['1.0000000'], tr/val_loss:111.556564/105.205658, val:  82.74%, val_best:  87.39%, tr:  97.82%, tr_best:  98.19%, epoch time: 120.26 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 58.0087%\n",
      "layer   3  Sparsity: 41.0540%\n",
      "total_backward_count 387072 real_backward_count 62494  16.145%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "fc layer 2 self.abs_max_out: 3421.0\n",
      "lif layer 2 self.abs_max_v: 3421.0\n",
      "fc layer 2 self.abs_max_out: 3442.0\n",
      "lif layer 2 self.abs_max_v: 3442.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 219 occurrences\n",
      "test - Value 1: 233 occurrences\n",
      "epoch-24  lr=['1.0000000'], tr/val_loss:116.107948/ 76.865479, val:  87.39%, val_best:  87.39%, tr:  98.09%, tr_best:  98.19%, epoch time: 120.72 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 57.4551%\n",
      "layer   3  Sparsity: 36.4386%\n",
      "total_backward_count 403200 real_backward_count 64499  15.997%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 51.7500%\n",
      "layer   3  Sparsity: 31.0000%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-25  lr=['1.0000000'], tr/val_loss:111.916626/ 90.094719, val:  84.07%, val_best:  87.39%, tr:  98.16%, tr_best:  98.19%, epoch time: 120.02 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 58.1006%\n",
      "layer   3  Sparsity: 39.1234%\n",
      "total_backward_count 419328 real_backward_count 66374  15.829%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 41.6250%\n",
      "fc layer 1 self.abs_max_out: 5797.0\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 229 occurrences\n",
      "test - Value 1: 223 occurrences\n",
      "epoch-26  lr=['1.0000000'], tr/val_loss:113.601479/104.746887, val:  86.95%, val_best:  87.39%, tr:  98.39%, tr_best:  98.39%, epoch time: 121.05 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 59.1007%\n",
      "layer   3  Sparsity: 41.7197%\n",
      "total_backward_count 435456 real_backward_count 68259  15.675%\n",
      "layer   1  Sparsity: 70.8984%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 40.1250%\n",
      "fc layer 1 self.abs_max_out: 5806.0\n",
      "fc layer 1 self.abs_max_out: 5930.0\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-27  lr=['1.0000000'], tr/val_loss:109.628471/104.857735, val:  73.67%, val_best:  87.39%, tr:  98.12%, tr_best:  98.39%, epoch time: 119.91 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 59.3804%\n",
      "layer   3  Sparsity: 42.7604%\n",
      "total_backward_count 451584 real_backward_count 70085  15.520%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 42.6250%\n",
      "fc layer 1 self.abs_max_out: 5995.0\n",
      "fc layer 1 self.abs_max_out: 6029.0\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-28  lr=['1.0000000'], tr/val_loss:121.820389/ 87.258759, val:  78.98%, val_best:  87.39%, tr:  98.41%, tr_best:  98.41%, epoch time: 121.18 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 59.5021%\n",
      "layer   3  Sparsity: 39.7546%\n",
      "total_backward_count 467712 real_backward_count 71908  15.374%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 33.0000%\n",
      "fc layer 1 self.abs_max_out: 6047.0\n",
      "fc layer 1 self.abs_max_out: 6113.0\n",
      "fc layer 2 self.abs_max_out: 3508.0\n",
      "lif layer 2 self.abs_max_v: 3508.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-29  lr=['1.0000000'], tr/val_loss:127.749329/130.602921, val:  75.66%, val_best:  87.39%, tr:  98.78%, tr_best:  98.78%, epoch time: 119.58 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 59.7092%\n",
      "layer   3  Sparsity: 40.0581%\n",
      "total_backward_count 483840 real_backward_count 73572  15.206%\n",
      "layer   1  Sparsity: 88.4766%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 42.5000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-30  lr=['1.0000000'], tr/val_loss:119.963722/105.508965, val:  85.40%, val_best:  87.39%, tr:  98.36%, tr_best:  98.78%, epoch time: 119.36 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 59.5627%\n",
      "layer   3  Sparsity: 39.7325%\n",
      "total_backward_count 499968 real_backward_count 75247  15.050%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 51.6250%\n",
      "layer   3  Sparsity: 32.2500%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1010.00 at epoch 31, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-31  lr=['1.0000000'], tr/val_loss:115.110413/173.996414, val:  61.50%, val_best:  87.39%, tr:  98.49%, tr_best:  98.78%, epoch time: 119.42 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 59.1084%\n",
      "layer   3  Sparsity: 40.8151%\n",
      "total_backward_count 516096 real_backward_count 76882  14.897%\n",
      "layer   1  Sparsity: 71.8750%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 38.5000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 233 occurrences\n",
      "test - Value 1: 219 occurrences\n",
      "epoch-32  lr=['1.0000000'], tr/val_loss:121.893997/ 84.153671, val:  87.83%, val_best:  87.83%, tr:  98.78%, tr_best:  98.78%, epoch time: 120.55 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 59.2992%\n",
      "layer   3  Sparsity: 41.4931%\n",
      "total_backward_count 532224 real_backward_count 78536  14.756%\n",
      "layer   1  Sparsity: 88.1836%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 39.0000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1081.00 at epoch 33, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-33  lr=['1.0000000'], tr/val_loss:128.099579/132.116028, val:  84.07%, val_best:  87.83%, tr:  98.78%, tr_best:  98.78%, epoch time: 120.44 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 59.1520%\n",
      "layer   3  Sparsity: 38.1951%\n",
      "total_backward_count 548352 real_backward_count 80304  14.645%\n",
      "layer   1  Sparsity: 72.9492%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 25.7500%\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-34  lr=['1.0000000'], tr/val_loss:129.037857/135.117630, val:  86.50%, val_best:  87.83%, tr:  98.54%, tr_best:  98.78%, epoch time: 120.23 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 59.3601%\n",
      "layer   3  Sparsity: 36.2488%\n",
      "total_backward_count 564480 real_backward_count 82063  14.538%\n",
      "layer   1  Sparsity: 86.8164%\n",
      "layer   2  Sparsity: 66.1250%\n",
      "layer   3  Sparsity: 41.6250%\n",
      "lif layer 2 self.abs_max_v: 3526.0\n",
      "lif layer 1 self.abs_max_v: 7166.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-35  lr=['1.0000000'], tr/val_loss:130.364136/132.373428, val:  75.00%, val_best:  87.83%, tr:  98.86%, tr_best:  98.86%, epoch time: 119.90 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 59.7412%\n",
      "layer   3  Sparsity: 37.1640%\n",
      "total_backward_count 580608 real_backward_count 83694  14.415%\n",
      "layer   1  Sparsity: 93.5547%\n",
      "layer   2  Sparsity: 71.0000%\n",
      "layer   3  Sparsity: 43.5000%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 284 occurrences\n",
      "test - Value 1: 168 occurrences\n",
      "epoch-36  lr=['1.0000000'], tr/val_loss:125.691071/ 97.486816, val:  83.63%, val_best:  87.83%, tr:  98.81%, tr_best:  98.86%, epoch time: 120.31 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 59.6481%\n",
      "layer   3  Sparsity: 38.4316%\n",
      "total_backward_count 596736 real_backward_count 85299  14.294%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 34.7500%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1194.00 at epoch 37, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-37  lr=['1.0000000'], tr/val_loss:124.956299/212.828598, val:  61.95%, val_best:  87.83%, tr:  98.96%, tr_best:  98.96%, epoch time: 121.15 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 59.7399%\n",
      "layer   3  Sparsity: 38.0461%\n",
      "total_backward_count 612864 real_backward_count 86973  14.191%\n",
      "layer   1  Sparsity: 68.7988%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 30.1250%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 7273.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-38  lr=['1.0000000'], tr/val_loss:124.261574/106.283287, val:  72.12%, val_best:  87.83%, tr:  99.03%, tr_best:  99.03%, epoch time: 120.58 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4835%\n",
      "layer   2  Sparsity: 59.6244%\n",
      "layer   3  Sparsity: 37.4136%\n",
      "total_backward_count 628992 real_backward_count 88601  14.086%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 64.2500%\n",
      "layer   3  Sparsity: 38.3750%\n",
      "lif layer 1 self.abs_max_v: 7365.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 7518.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-39  lr=['1.0000000'], tr/val_loss:129.732376/109.165993, val:  83.85%, val_best:  87.83%, tr:  98.96%, tr_best:  99.03%, epoch time: 120.64 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 59.8853%\n",
      "layer   3  Sparsity: 40.2583%\n",
      "total_backward_count 645120 real_backward_count 90197  13.981%\n",
      "layer   1  Sparsity: 75.8789%\n",
      "layer   2  Sparsity: 56.8750%\n",
      "layer   3  Sparsity: 39.5000%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 179 occurrences\n",
      "test - Value 1: 273 occurrences\n",
      "epoch-40  lr=['1.0000000'], tr/val_loss:122.026390/136.551590, val:  85.18%, val_best:  87.83%, tr:  98.81%, tr_best:  99.03%, epoch time: 119.28 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4819%\n",
      "layer   2  Sparsity: 59.6948%\n",
      "layer   3  Sparsity: 40.6959%\n",
      "total_backward_count 661248 real_backward_count 91820  13.886%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 65.3750%\n",
      "layer   3  Sparsity: 40.5000%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-41  lr=['1.0000000'], tr/val_loss:122.611130/121.999168, val:  80.31%, val_best:  87.83%, tr:  99.18%, tr_best:  99.18%, epoch time: 120.73 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 59.5289%\n",
      "layer   3  Sparsity: 42.3041%\n",
      "total_backward_count 677376 real_backward_count 93367  13.784%\n",
      "layer   1  Sparsity: 67.2852%\n",
      "layer   2  Sparsity: 55.6250%\n",
      "layer   3  Sparsity: 30.5000%\n",
      "fc layer 3 self.abs_max_out: 376.0\n",
      "lif layer 2 self.abs_max_v: 3555.5\n",
      "lif layer 2 self.abs_max_v: 3616.0\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-42  lr=['1.0000000'], tr/val_loss:130.113312/132.166611, val:  82.08%, val_best:  87.83%, tr:  99.31%, tr_best:  99.31%, epoch time: 120.12 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 59.3800%\n",
      "layer   3  Sparsity: 39.5601%\n",
      "total_backward_count 693504 real_backward_count 94902  13.684%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 44.7500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 180 occurrences\n",
      "test - Value 1: 272 occurrences\n",
      "epoch-43  lr=['1.0000000'], tr/val_loss:126.177773/112.881081, val:  82.30%, val_best:  87.83%, tr:  99.08%, tr_best:  99.31%, epoch time: 120.66 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 60.0517%\n",
      "layer   3  Sparsity: 42.4812%\n",
      "total_backward_count 709632 real_backward_count 96434  13.589%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 66.7500%\n",
      "layer   3  Sparsity: 39.5000%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-44  lr=['1.0000000'], tr/val_loss:129.793716/171.570175, val:  72.35%, val_best:  87.83%, tr:  99.06%, tr_best:  99.31%, epoch time: 120.12 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 60.2166%\n",
      "layer   3  Sparsity: 39.9071%\n",
      "total_backward_count 725760 real_backward_count 97954  13.497%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "fc layer 2 self.abs_max_out: 3530.0\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-45  lr=['1.0000000'], tr/val_loss:128.513016/183.393219, val:  72.12%, val_best:  87.83%, tr:  99.45%, tr_best:  99.45%, epoch time: 120.20 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 60.4766%\n",
      "layer   3  Sparsity: 40.8753%\n",
      "total_backward_count 741888 real_backward_count 99397  13.398%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 69.6250%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "fc layer 2 self.abs_max_out: 3551.0\n",
      "fc layer 2 self.abs_max_out: 3577.0\n",
      "lif layer 2 self.abs_max_v: 3670.0\n",
      "lif layer 2 self.abs_max_v: 3783.0\n",
      "fc layer 1 self.abs_max_out: 6129.0\n",
      "fc layer 1 self.abs_max_out: 6228.0\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-46  lr=['1.0000000'], tr/val_loss:123.413673/ 70.352005, val:  85.62%, val_best:  87.83%, tr:  99.11%, tr_best:  99.45%, epoch time: 120.32 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 60.5755%\n",
      "layer   3  Sparsity: 40.8036%\n",
      "total_backward_count 758016 real_backward_count 100856  13.305%\n",
      "layer   1  Sparsity: 70.5566%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 34.7500%\n",
      "fc layer 2 self.abs_max_out: 3604.0\n",
      "fc layer 2 self.abs_max_out: 3640.0\n",
      "fc layer 2 self.abs_max_out: 3647.0\n",
      "fc layer 2 self.abs_max_out: 3676.0\n",
      "fc layer 2 self.abs_max_out: 3698.0\n",
      "fc layer 2 self.abs_max_out: 3734.0\n",
      "fc layer 1 self.abs_max_out: 6291.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-47  lr=['1.0000000'], tr/val_loss:131.233444/149.560074, val:  83.63%, val_best:  87.83%, tr:  99.36%, tr_best:  99.45%, epoch time: 120.92 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 60.5613%\n",
      "layer   3  Sparsity: 41.7946%\n",
      "total_backward_count 774144 real_backward_count 102271  13.211%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 59.6250%\n",
      "layer   3  Sparsity: 42.7500%\n",
      "fc layer 1 self.abs_max_out: 6511.0\n",
      "fc layer 2 self.abs_max_out: 3795.0\n",
      "lif layer 2 self.abs_max_v: 3795.0\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-48  lr=['1.0000000'], tr/val_loss:133.350800/162.790833, val:  76.11%, val_best:  87.83%, tr:  99.40%, tr_best:  99.45%, epoch time: 119.07 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 60.5699%\n",
      "layer   3  Sparsity: 44.7528%\n",
      "total_backward_count 790272 real_backward_count 103562  13.105%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 46.1250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-49  lr=['1.0000000'], tr/val_loss:126.521385/126.912346, val:  74.56%, val_best:  87.83%, tr:  99.53%, tr_best:  99.53%, epoch time: 119.14 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 60.3843%\n",
      "layer   3  Sparsity: 42.8886%\n",
      "total_backward_count 806400 real_backward_count 104914  13.010%\n",
      "layer   1  Sparsity: 80.5664%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 46.2500%\n",
      "fc layer 2 self.abs_max_out: 3852.0\n",
      "lif layer 2 self.abs_max_v: 3852.0\n",
      "fc layer 2 self.abs_max_out: 3946.0\n",
      "lif layer 2 self.abs_max_v: 3946.0\n",
      "fc layer 3 self.abs_max_out: 381.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-50  lr=['1.0000000'], tr/val_loss:125.946800/ 95.901680, val:  83.41%, val_best:  87.83%, tr:  99.40%, tr_best:  99.53%, epoch time: 115.56 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 60.1808%\n",
      "layer   3  Sparsity: 42.7501%\n",
      "total_backward_count 822528 real_backward_count 106290  12.922%\n",
      "layer   1  Sparsity: 73.0957%\n",
      "layer   2  Sparsity: 57.6250%\n",
      "layer   3  Sparsity: 37.6250%\n",
      "fc layer 2 self.abs_max_out: 3979.0\n",
      "lif layer 2 self.abs_max_v: 3979.0\n",
      "lif layer 2 self.abs_max_v: 3994.5\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1247.00 at epoch 51, iter 4031\n",
      "fc layer 3 self.abs_max_out: 390.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-51  lr=['1.0000000'], tr/val_loss:134.466888/135.154526, val:  80.09%, val_best:  87.83%, tr:  99.36%, tr_best:  99.53%, epoch time: 120.29 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 60.3323%\n",
      "layer   3  Sparsity: 41.9567%\n",
      "total_backward_count 838656 real_backward_count 107621  12.833%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 62.3750%\n",
      "layer   3  Sparsity: 47.5000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-52  lr=['1.0000000'], tr/val_loss:133.041000/198.842545, val:  73.45%, val_best:  87.83%, tr:  99.50%, tr_best:  99.53%, epoch time: 120.18 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 60.4721%\n",
      "layer   3  Sparsity: 38.7711%\n",
      "total_backward_count 854784 real_backward_count 109006  12.752%\n",
      "layer   1  Sparsity: 90.2344%\n",
      "layer   2  Sparsity: 68.3750%\n",
      "layer   3  Sparsity: 35.3750%\n",
      "fc layer 2 self.abs_max_out: 3982.0\n",
      "fc layer 2 self.abs_max_out: 3994.0\n",
      "fc layer 2 self.abs_max_out: 4024.0\n",
      "lif layer 2 self.abs_max_v: 4024.0\n",
      "fc layer 3 self.abs_max_out: 413.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 227 occurrences\n",
      "test - Value 1: 225 occurrences\n",
      "epoch-53  lr=['1.0000000'], tr/val_loss:134.721786/135.835037, val:  86.50%, val_best:  87.83%, tr:  99.36%, tr_best:  99.53%, epoch time: 119.74 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 60.4036%\n",
      "layer   3  Sparsity: 37.3933%\n",
      "total_backward_count 870912 real_backward_count 110403  12.677%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 60.6250%\n",
      "layer   3  Sparsity: 40.1250%\n",
      "fc layer 2 self.abs_max_out: 4041.0\n",
      "lif layer 2 self.abs_max_v: 4041.0\n",
      "fc layer 2 self.abs_max_out: 4056.0\n",
      "lif layer 2 self.abs_max_v: 4056.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-54  lr=['1.0000000'], tr/val_loss:142.391998/155.730515, val:  81.64%, val_best:  87.83%, tr:  99.31%, tr_best:  99.53%, epoch time: 119.99 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 60.1168%\n",
      "layer   3  Sparsity: 39.1628%\n",
      "total_backward_count 887040 real_backward_count 111803  12.604%\n",
      "layer   1  Sparsity: 79.2480%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 161 occurrences\n",
      "test - Value 1: 291 occurrences\n",
      "epoch-55  lr=['1.0000000'], tr/val_loss:140.398407/118.549065, val:  81.64%, val_best:  87.83%, tr:  99.50%, tr_best:  99.53%, epoch time: 118.54 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 60.2551%\n",
      "layer   3  Sparsity: 39.7476%\n",
      "total_backward_count 903168 real_backward_count 113215  12.535%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 36.2500%\n",
      "lif layer 2 self.abs_max_v: 4064.5\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-56  lr=['1.0000000'], tr/val_loss:136.287109/147.325256, val:  66.37%, val_best:  87.83%, tr:  99.58%, tr_best:  99.58%, epoch time: 119.99 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 60.1261%\n",
      "layer   3  Sparsity: 40.8149%\n",
      "total_backward_count 919296 real_backward_count 114595  12.466%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-57  lr=['1.0000000'], tr/val_loss:127.090874/113.778465, val:  85.84%, val_best:  87.83%, tr:  99.36%, tr_best:  99.58%, epoch time: 119.55 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4790%\n",
      "layer   2  Sparsity: 59.8731%\n",
      "layer   3  Sparsity: 39.4445%\n",
      "total_backward_count 935424 real_backward_count 115999  12.401%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 74.5000%\n",
      "layer   3  Sparsity: 54.1250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 7540.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 118 occurrences\n",
      "test - Value 1: 334 occurrences\n",
      "epoch-58  lr=['1.0000000'], tr/val_loss:138.858368/117.063988, val:  75.66%, val_best:  87.83%, tr:  99.53%, tr_best:  99.58%, epoch time: 119.27 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 60.0765%\n",
      "layer   3  Sparsity: 40.2475%\n",
      "total_backward_count 951552 real_backward_count 117315  12.329%\n",
      "layer   1  Sparsity: 77.2949%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 39.3750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-59  lr=['1.0000000'], tr/val_loss:137.951691/187.859009, val:  79.20%, val_best:  87.83%, tr:  99.38%, tr_best:  99.58%, epoch time: 120.09 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 59.9340%\n",
      "layer   3  Sparsity: 39.1535%\n",
      "total_backward_count 967680 real_backward_count 118602  12.256%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 38.3750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 122 occurrences\n",
      "test - Value 1: 330 occurrences\n",
      "epoch-60  lr=['1.0000000'], tr/val_loss:137.843536/148.419266, val:  75.66%, val_best:  87.83%, tr:  99.53%, tr_best:  99.58%, epoch time: 119.60 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 59.5189%\n",
      "layer   3  Sparsity: 39.1034%\n",
      "total_backward_count 983808 real_backward_count 119901  12.187%\n",
      "layer   1  Sparsity: 72.7539%\n",
      "layer   2  Sparsity: 55.6250%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-61  lr=['1.0000000'], tr/val_loss:134.356186/157.725662, val:  71.02%, val_best:  87.83%, tr:  99.63%, tr_best:  99.63%, epoch time: 120.63 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 59.5831%\n",
      "layer   3  Sparsity: 39.0319%\n",
      "total_backward_count 999936 real_backward_count 121193  12.120%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 34.5000%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 204 occurrences\n",
      "test - Value 1: 248 occurrences\n",
      "epoch-62  lr=['1.0000000'], tr/val_loss:143.860916/119.611069, val:  87.17%, val_best:  87.83%, tr:  99.73%, tr_best:  99.73%, epoch time: 119.32 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 59.5613%\n",
      "layer   3  Sparsity: 39.7974%\n",
      "total_backward_count 1016064 real_backward_count 122400  12.046%\n",
      "layer   1  Sparsity: 78.7598%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 34.1250%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 165 occurrences\n",
      "test - Value 1: 287 occurrences\n",
      "epoch-63  lr=['1.0000000'], tr/val_loss:146.524155/106.570778, val:  83.41%, val_best:  87.83%, tr:  99.58%, tr_best:  99.73%, epoch time: 120.28 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4812%\n",
      "layer   2  Sparsity: 59.4675%\n",
      "layer   3  Sparsity: 40.1929%\n",
      "total_backward_count 1032192 real_backward_count 123724  11.987%\n",
      "layer   1  Sparsity: 76.8066%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 35.0000%\n",
      "lif layer 1 self.abs_max_v: 7558.5\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-64  lr=['1.0000000'], tr/val_loss:136.890366/147.829330, val:  70.13%, val_best:  87.83%, tr:  99.36%, tr_best:  99.73%, epoch time: 119.17 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 59.2955%\n",
      "layer   3  Sparsity: 37.8871%\n",
      "total_backward_count 1048320 real_backward_count 125022  11.926%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "fc layer 1 self.abs_max_out: 6529.0\n",
      "lif layer 1 self.abs_max_v: 7579.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-65  lr=['1.0000000'], tr/val_loss:157.959137/229.282227, val:  73.89%, val_best:  87.83%, tr:  99.43%, tr_best:  99.73%, epoch time: 119.47 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 59.6301%\n",
      "layer   3  Sparsity: 38.1156%\n",
      "total_backward_count 1064448 real_backward_count 126348  11.870%\n",
      "layer   1  Sparsity: 88.2812%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 41.7500%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-66  lr=['1.0000000'], tr/val_loss:150.460739/156.577698, val:  71.02%, val_best:  87.83%, tr:  99.80%, tr_best:  99.80%, epoch time: 120.06 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 59.8645%\n",
      "layer   3  Sparsity: 39.1157%\n",
      "total_backward_count 1080576 real_backward_count 127617  11.810%\n",
      "layer   1  Sparsity: 75.4395%\n",
      "layer   2  Sparsity: 57.8750%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "fc layer 3 self.abs_max_out: 415.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-67  lr=['1.0000000'], tr/val_loss:154.861694/167.112244, val:  84.51%, val_best:  87.83%, tr:  99.73%, tr_best:  99.80%, epoch time: 120.26 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 59.9605%\n",
      "layer   3  Sparsity: 38.9182%\n",
      "total_backward_count 1096704 real_backward_count 128915  11.755%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 38.8750%\n",
      "fc layer 3 self.abs_max_out: 430.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-68  lr=['1.0000000'], tr/val_loss:152.268433/171.472824, val:  79.42%, val_best:  87.83%, tr:  99.58%, tr_best:  99.80%, epoch time: 119.43 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 59.8639%\n",
      "layer   3  Sparsity: 38.6484%\n",
      "total_backward_count 1112832 real_backward_count 130252  11.705%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 66.3750%\n",
      "layer   3  Sparsity: 40.6250%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 187 occurrences\n",
      "test - Value 1: 265 occurrences\n",
      "epoch-69  lr=['1.0000000'], tr/val_loss:152.382721/164.061905, val:  85.18%, val_best:  87.83%, tr:  99.70%, tr_best:  99.80%, epoch time: 118.78 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 59.9428%\n",
      "layer   3  Sparsity: 39.9416%\n",
      "total_backward_count 1128960 real_backward_count 131510  11.649%\n",
      "layer   1  Sparsity: 65.8691%\n",
      "layer   2  Sparsity: 52.1250%\n",
      "layer   3  Sparsity: 28.6250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 209 occurrences\n",
      "test - Value 1: 243 occurrences\n",
      "epoch-70  lr=['1.0000000'], tr/val_loss:161.320969/150.948074, val:  86.50%, val_best:  87.83%, tr:  99.80%, tr_best:  99.80%, epoch time: 118.65 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 60.2457%\n",
      "layer   3  Sparsity: 39.4735%\n",
      "total_backward_count 1145088 real_backward_count 132745  11.593%\n",
      "layer   1  Sparsity: 70.4102%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 33.2500%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 150 occurrences\n",
      "test - Value 1: 302 occurrences\n",
      "epoch-71  lr=['1.0000000'], tr/val_loss:164.303070/155.771271, val:  79.20%, val_best:  87.83%, tr:  99.78%, tr_best:  99.80%, epoch time: 119.10 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 59.9894%\n",
      "layer   3  Sparsity: 41.0080%\n",
      "total_backward_count 1161216 real_backward_count 133917  11.532%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 46.8750%\n",
      "fc layer 3 self.abs_max_out: 453.0\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 198 occurrences\n",
      "test - Value 1: 254 occurrences\n",
      "epoch-72  lr=['1.0000000'], tr/val_loss:167.146301/182.250412, val:  88.05%, val_best:  88.05%, tr:  99.73%, tr_best:  99.80%, epoch time: 120.00 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.7820%\n",
      "layer   3  Sparsity: 39.0062%\n",
      "total_backward_count 1177344 real_backward_count 135108  11.476%\n",
      "layer   1  Sparsity: 80.5176%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-73  lr=['1.0000000'], tr/val_loss:166.025360/179.708694, val:  80.09%, val_best:  88.05%, tr:  99.73%, tr_best:  99.80%, epoch time: 120.03 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 59.7948%\n",
      "layer   3  Sparsity: 37.9941%\n",
      "total_backward_count 1193472 real_backward_count 136301  11.421%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 42.6250%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-74  lr=['1.0000000'], tr/val_loss:154.648758/193.305740, val:  72.35%, val_best:  88.05%, tr:  99.60%, tr_best:  99.80%, epoch time: 119.01 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 59.7050%\n",
      "layer   3  Sparsity: 39.5083%\n",
      "total_backward_count 1209600 real_backward_count 137485  11.366%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 43.8750%\n",
      "lif layer 1 self.abs_max_v: 7654.5\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-75  lr=['1.0000000'], tr/val_loss:158.754364/164.208618, val:  83.19%, val_best:  88.05%, tr:  99.85%, tr_best:  99.85%, epoch time: 119.17 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 60.0657%\n",
      "layer   3  Sparsity: 40.2293%\n",
      "total_backward_count 1225728 real_backward_count 138634  11.310%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 61.2500%\n",
      "layer   3  Sparsity: 48.6250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-76  lr=['1.0000000'], tr/val_loss:156.701996/151.887558, val:  81.42%, val_best:  88.05%, tr:  99.78%, tr_best:  99.85%, epoch time: 119.62 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 60.2080%\n",
      "layer   3  Sparsity: 41.9563%\n",
      "total_backward_count 1241856 real_backward_count 139698  11.249%\n",
      "layer   1  Sparsity: 75.3418%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 42.1250%\n",
      "lif layer 1 self.abs_max_v: 7660.5\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 189 occurrences\n",
      "test - Value 1: 263 occurrences\n",
      "epoch-77  lr=['1.0000000'], tr/val_loss:152.865601/156.578445, val:  86.50%, val_best:  88.05%, tr:  99.73%, tr_best:  99.85%, epoch time: 119.77 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 60.1098%\n",
      "layer   3  Sparsity: 39.2165%\n",
      "total_backward_count 1257984 real_backward_count 140845  11.196%\n",
      "layer   1  Sparsity: 76.5137%\n",
      "layer   2  Sparsity: 57.3750%\n",
      "layer   3  Sparsity: 38.5000%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1311.00 at epoch 78, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 126 occurrences\n",
      "test - Value 1: 326 occurrences\n",
      "epoch-78  lr=['1.0000000'], tr/val_loss:162.448608/170.640182, val:  77.43%, val_best:  88.05%, tr:  99.63%, tr_best:  99.85%, epoch time: 119.24 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4817%\n",
      "layer   2  Sparsity: 59.9882%\n",
      "layer   3  Sparsity: 37.8902%\n",
      "total_backward_count 1274112 real_backward_count 142016  11.146%\n",
      "layer   1  Sparsity: 83.9355%\n",
      "layer   2  Sparsity: 58.6250%\n",
      "layer   3  Sparsity: 41.1250%\n",
      "lif layer 1 self.abs_max_v: 7697.5\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-79  lr=['1.0000000'], tr/val_loss:159.225937/139.471527, val:  69.47%, val_best:  88.05%, tr:  99.93%, tr_best:  99.93%, epoch time: 118.98 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 60.1140%\n",
      "layer   3  Sparsity: 40.3621%\n",
      "total_backward_count 1290240 real_backward_count 143101  11.091%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 60.3750%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "lif layer 1 self.abs_max_v: 7769.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 4071.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-80  lr=['1.0000000'], tr/val_loss:159.838425/141.300156, val:  76.77%, val_best:  88.05%, tr:  99.73%, tr_best:  99.93%, epoch time: 119.00 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4805%\n",
      "layer   2  Sparsity: 60.0238%\n",
      "layer   3  Sparsity: 41.0137%\n",
      "total_backward_count 1306368 real_backward_count 144241  11.041%\n",
      "layer   1  Sparsity: 88.1348%\n",
      "layer   2  Sparsity: 66.1250%\n",
      "layer   3  Sparsity: 38.3750%\n",
      "lif layer 2 self.abs_max_v: 4164.5\n",
      "fc layer 2 self.abs_max_out: 4088.0\n",
      "lif layer 1 self.abs_max_v: 7810.5\n",
      "fc layer 2 self.abs_max_out: 4164.0\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 199 occurrences\n",
      "test - Value 1: 253 occurrences\n",
      "epoch-81  lr=['1.0000000'], tr/val_loss:150.623962/151.006058, val:  89.60%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 119.27 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 59.9980%\n",
      "layer   3  Sparsity: 39.3588%\n",
      "total_backward_count 1322496 real_backward_count 145411  10.995%\n",
      "layer   1  Sparsity: 78.6621%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "lif layer 1 self.abs_max_v: 7844.5\n",
      "fc layer 3 self.abs_max_out: 475.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-82  lr=['1.0000000'], tr/val_loss:156.260498/171.805374, val:  73.45%, val_best:  89.60%, tr:  99.83%, tr_best:  99.93%, epoch time: 119.29 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.6525%\n",
      "layer   3  Sparsity: 37.8577%\n",
      "total_backward_count 1338624 real_backward_count 146667  10.957%\n",
      "layer   1  Sparsity: 72.0703%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 35.7500%\n",
      "lif layer 1 self.abs_max_v: 7873.5\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1348.00 at epoch 83, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-83  lr=['1.0000000'], tr/val_loss:161.788452/174.666565, val:  73.45%, val_best:  89.60%, tr:  99.78%, tr_best:  99.93%, epoch time: 119.78 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4827%\n",
      "layer   2  Sparsity: 59.4897%\n",
      "layer   3  Sparsity: 38.8602%\n",
      "total_backward_count 1354752 real_backward_count 147845  10.913%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 52.2500%\n",
      "layer   3  Sparsity: 34.6250%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-84  lr=['1.0000000'], tr/val_loss:172.598267/187.840271, val:  85.18%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 120.05 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 59.5518%\n",
      "layer   3  Sparsity: 39.2288%\n",
      "total_backward_count 1370880 real_backward_count 149009  10.870%\n",
      "layer   1  Sparsity: 71.7773%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 45.6250%\n",
      "lif layer 1 self.abs_max_v: 7884.5\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-85  lr=['1.0000000'], tr/val_loss:158.337265/173.719849, val:  83.19%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 118.72 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4828%\n",
      "layer   2  Sparsity: 59.7276%\n",
      "layer   3  Sparsity: 41.1087%\n",
      "total_backward_count 1387008 real_backward_count 150117  10.823%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 40.5000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1380.00 at epoch 86, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-86  lr=['1.0000000'], tr/val_loss:172.396057/190.309158, val:  74.56%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 116.40 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 59.8102%\n",
      "layer   3  Sparsity: 39.1019%\n",
      "total_backward_count 1403136 real_backward_count 151213  10.777%\n",
      "layer   1  Sparsity: 78.3203%\n",
      "layer   2  Sparsity: 58.6250%\n",
      "layer   3  Sparsity: 31.8750%\n",
      "fc layer 3 self.abs_max_out: 479.0\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-87  lr=['1.0000000'], tr/val_loss:168.883987/161.443771, val:  69.47%, val_best:  89.60%, tr:  99.70%, tr_best:  99.93%, epoch time: 119.35 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.6715%\n",
      "layer   3  Sparsity: 38.1836%\n",
      "total_backward_count 1419264 real_backward_count 152376  10.736%\n",
      "layer   1  Sparsity: 78.3691%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 41.6250%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 207 occurrences\n",
      "test - Value 1: 245 occurrences\n",
      "epoch-88  lr=['1.0000000'], tr/val_loss:171.722443/158.261368, val:  86.95%, val_best:  89.60%, tr:  99.88%, tr_best:  99.93%, epoch time: 119.59 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 59.9623%\n",
      "layer   3  Sparsity: 38.3890%\n",
      "total_backward_count 1435392 real_backward_count 153472  10.692%\n",
      "layer   1  Sparsity: 91.2109%\n",
      "layer   2  Sparsity: 69.8750%\n",
      "layer   3  Sparsity: 45.2500%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-89  lr=['1.0000000'], tr/val_loss:172.400833/178.457626, val:  77.65%, val_best:  89.60%, tr:  99.78%, tr_best:  99.93%, epoch time: 118.56 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4785%\n",
      "layer   2  Sparsity: 59.9121%\n",
      "layer   3  Sparsity: 37.5093%\n",
      "total_backward_count 1451520 real_backward_count 154607  10.651%\n",
      "layer   1  Sparsity: 83.2031%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 41.8750%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 69 occurrences\n",
      "test - Value 1: 383 occurrences\n",
      "epoch-90  lr=['1.0000000'], tr/val_loss:171.076813/218.978729, val:  65.27%, val_best:  89.60%, tr:  99.83%, tr_best:  99.93%, epoch time: 119.81 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 59.9888%\n",
      "layer   3  Sparsity: 38.4307%\n",
      "total_backward_count 1467648 real_backward_count 155676  10.607%\n",
      "layer   1  Sparsity: 81.2012%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 36.6250%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-91  lr=['1.0000000'], tr/val_loss:160.709396/175.879379, val:  83.85%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 119.06 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 59.9709%\n",
      "layer   3  Sparsity: 37.8210%\n",
      "total_backward_count 1483776 real_backward_count 156755  10.565%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 36.1250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-92  lr=['1.0000000'], tr/val_loss:161.387512/175.812988, val:  74.12%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 120.25 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 59.7307%\n",
      "layer   3  Sparsity: 39.1642%\n",
      "total_backward_count 1499904 real_backward_count 157860  10.525%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 34.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 7910.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 154 occurrences\n",
      "test - Value 1: 298 occurrences\n",
      "epoch-93  lr=['1.0000000'], tr/val_loss:164.749832/181.288986, val:  81.86%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 119.91 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 59.6851%\n",
      "layer   3  Sparsity: 40.3476%\n",
      "total_backward_count 1516032 real_backward_count 158941  10.484%\n",
      "layer   1  Sparsity: 75.1465%\n",
      "layer   2  Sparsity: 53.5000%\n",
      "layer   3  Sparsity: 38.5000%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-94  lr=['1.0000000'], tr/val_loss:155.136978/140.121796, val:  84.29%, val_best:  89.60%, tr:  99.88%, tr_best:  99.93%, epoch time: 118.60 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 59.3517%\n",
      "layer   3  Sparsity: 39.1806%\n",
      "total_backward_count 1532160 real_backward_count 160047  10.446%\n",
      "layer   1  Sparsity: 66.0645%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 33.0000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-95  lr=['1.0000000'], tr/val_loss:163.519928/156.967667, val:  81.42%, val_best:  89.60%, tr:  99.93%, tr_best:  99.93%, epoch time: 119.38 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 59.1374%\n",
      "layer   3  Sparsity: 39.1402%\n",
      "total_backward_count 1548288 real_backward_count 161157  10.409%\n",
      "layer   1  Sparsity: 89.1602%\n",
      "layer   2  Sparsity: 70.3750%\n",
      "layer   3  Sparsity: 54.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-96  lr=['1.0000000'], tr/val_loss:166.603806/160.475891, val:  83.41%, val_best:  89.60%, tr:  99.65%, tr_best:  99.93%, epoch time: 120.40 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 58.7870%\n",
      "layer   3  Sparsity: 39.8489%\n",
      "total_backward_count 1564416 real_backward_count 162249  10.371%\n",
      "layer   1  Sparsity: 65.7227%\n",
      "layer   2  Sparsity: 49.6250%\n",
      "layer   3  Sparsity: 35.6250%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 121 occurrences\n",
      "test - Value 1: 331 occurrences\n",
      "epoch-97  lr=['1.0000000'], tr/val_loss:173.293640/160.234192, val:  75.44%, val_best:  89.60%, tr:  99.90%, tr_best:  99.93%, epoch time: 120.73 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4841%\n",
      "layer   2  Sparsity: 58.9659%\n",
      "layer   3  Sparsity: 38.7367%\n",
      "total_backward_count 1580544 real_backward_count 163338  10.334%\n",
      "layer   1  Sparsity: 71.1426%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 27.0000%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 7942.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-98  lr=['1.0000000'], tr/val_loss:161.754974/185.393494, val:  72.57%, val_best:  89.60%, tr:  99.73%, tr_best:  99.93%, epoch time: 120.51 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 59.1243%\n",
      "layer   3  Sparsity: 37.4552%\n",
      "total_backward_count 1596672 real_backward_count 164529  10.304%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-99  lr=['1.0000000'], tr/val_loss:154.563309/197.919281, val:  72.35%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 120.36 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4816%\n",
      "layer   2  Sparsity: 59.4315%\n",
      "layer   3  Sparsity: 37.0891%\n",
      "total_backward_count 1612800 real_backward_count 165719  10.275%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 38.8750%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8036.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-100 lr=['1.0000000'], tr/val_loss:163.137115/161.149429, val:  80.09%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 120.74 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 59.1101%\n",
      "layer   3  Sparsity: 37.2095%\n",
      "total_backward_count 1628928 real_backward_count 166877  10.245%\n",
      "layer   1  Sparsity: 66.2109%\n",
      "layer   2  Sparsity: 49.7500%\n",
      "layer   3  Sparsity: 33.7500%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8289.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-101 lr=['1.0000000'], tr/val_loss:168.151001/167.383163, val:  78.10%, val_best:  89.60%, tr:  99.90%, tr_best:  99.93%, epoch time: 120.59 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 58.8720%\n",
      "layer   3  Sparsity: 39.1328%\n",
      "total_backward_count 1645056 real_backward_count 168042  10.215%\n",
      "layer   1  Sparsity: 84.1309%\n",
      "layer   2  Sparsity: 63.7500%\n",
      "layer   3  Sparsity: 45.1250%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8373.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 125 occurrences\n",
      "test - Value 1: 327 occurrences\n",
      "epoch-102 lr=['1.0000000'], tr/val_loss:170.118225/141.618958, val:  75.88%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 119.36 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 58.7486%\n",
      "layer   3  Sparsity: 38.4082%\n",
      "total_backward_count 1661184 real_backward_count 169135  10.182%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 51.1250%\n",
      "layer   3  Sparsity: 42.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8429.5\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-103 lr=['1.0000000'], tr/val_loss:164.239105/153.737259, val:  75.22%, val_best:  89.60%, tr:  99.80%, tr_best:  99.93%, epoch time: 120.51 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 58.7109%\n",
      "layer   3  Sparsity: 39.5747%\n",
      "total_backward_count 1677312 real_backward_count 170223  10.149%\n",
      "layer   1  Sparsity: 78.1250%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 4245.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-104 lr=['1.0000000'], tr/val_loss:170.562378/242.086365, val:  69.25%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 119.84 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 58.7915%\n",
      "layer   3  Sparsity: 38.4192%\n",
      "total_backward_count 1693440 real_backward_count 171359  10.119%\n",
      "layer   1  Sparsity: 74.2188%\n",
      "layer   2  Sparsity: 56.6250%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "lif layer 2 self.abs_max_v: 4208.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "fc layer 2 self.abs_max_out: 4472.0\n",
      "lif layer 2 self.abs_max_v: 4362.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 169 occurrences\n",
      "test - Value 1: 283 occurrences\n",
      "epoch-105 lr=['1.0000000'], tr/val_loss:182.339447/204.072754, val:  82.08%, val_best:  89.60%, tr:  99.88%, tr_best:  99.93%, epoch time: 120.98 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 58.4905%\n",
      "layer   3  Sparsity: 38.3750%\n",
      "total_backward_count 1709568 real_backward_count 172474  10.089%\n",
      "layer   1  Sparsity: 83.3496%\n",
      "layer   2  Sparsity: 62.2500%\n",
      "layer   3  Sparsity: 42.0000%\n",
      "fc layer 3 self.abs_max_out: 480.0\n",
      "fc layer 3 self.abs_max_out: 487.0\n",
      "fc layer 3 self.abs_max_out: 510.0\n",
      "fc layer 3 self.abs_max_out: 518.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 166 occurrences\n",
      "test - Value 1: 286 occurrences\n",
      "epoch-106 lr=['1.0000000'], tr/val_loss:182.486786/223.049240, val:  83.63%, val_best:  89.60%, tr:  99.83%, tr_best:  99.93%, epoch time: 120.10 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 58.3202%\n",
      "layer   3  Sparsity: 37.3221%\n",
      "total_backward_count 1725696 real_backward_count 173554  10.057%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 62.6250%\n",
      "layer   3  Sparsity: 34.6250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-107 lr=['1.0000000'], tr/val_loss:175.671448/198.745041, val:  81.19%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 119.64 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4787%\n",
      "layer   2  Sparsity: 58.6988%\n",
      "layer   3  Sparsity: 38.1080%\n",
      "total_backward_count 1741824 real_backward_count 174676  10.028%\n",
      "layer   1  Sparsity: 84.5215%\n",
      "layer   2  Sparsity: 64.1250%\n",
      "layer   3  Sparsity: 38.8750%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 221 occurrences\n",
      "test - Value 1: 231 occurrences\n",
      "epoch-108 lr=['1.0000000'], tr/val_loss:165.712479/109.200226, val:  86.50%, val_best:  89.60%, tr:  99.85%, tr_best:  99.93%, epoch time: 119.30 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 58.7579%\n",
      "layer   3  Sparsity: 38.2305%\n",
      "total_backward_count 1757952 real_backward_count 175875  10.005%\n",
      "layer   1  Sparsity: 85.2051%\n",
      "layer   2  Sparsity: 63.6250%\n",
      "layer   3  Sparsity: 38.0000%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1440.00 at epoch 109, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-109 lr=['1.0000000'], tr/val_loss:190.709244/191.623032, val:  79.65%, val_best:  89.60%, tr:  99.93%, tr_best:  99.93%, epoch time: 119.80 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 58.5987%\n",
      "layer   3  Sparsity: 36.2485%\n",
      "total_backward_count 1774080 real_backward_count 177054   9.980%\n",
      "layer   1  Sparsity: 87.3047%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 32.3750%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-110 lr=['1.0000000'], tr/val_loss:186.028763/169.340988, val:  74.78%, val_best:  89.60%, tr:  99.95%, tr_best:  99.95%, epoch time: 119.37 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4793%\n",
      "layer   2  Sparsity: 58.6191%\n",
      "layer   3  Sparsity: 37.4415%\n",
      "total_backward_count 1790208 real_backward_count 178171   9.953%\n",
      "layer   1  Sparsity: 78.5645%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 32.3750%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-111 lr=['1.0000000'], tr/val_loss:180.700653/157.129730, val:  79.87%, val_best:  89.60%, tr:  99.88%, tr_best:  99.95%, epoch time: 118.54 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4813%\n",
      "layer   2  Sparsity: 58.6507%\n",
      "layer   3  Sparsity: 37.7559%\n",
      "total_backward_count 1806336 real_backward_count 179229   9.922%\n",
      "layer   1  Sparsity: 77.4902%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 33.8750%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-112 lr=['1.0000000'], tr/val_loss:174.811295/151.579514, val:  86.28%, val_best:  89.60%, tr:  99.95%, tr_best:  99.95%, epoch time: 119.84 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 58.6895%\n",
      "layer   3  Sparsity: 38.4198%\n",
      "total_backward_count 1822464 real_backward_count 180302   9.893%\n",
      "layer   1  Sparsity: 83.7891%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 42.5000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 230 occurrences\n",
      "test - Value 1: 222 occurrences\n",
      "epoch-113 lr=['1.0000000'], tr/val_loss:190.652100/172.950577, val:  87.61%, val_best:  89.60%, tr:  99.88%, tr_best:  99.95%, epoch time: 119.89 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 58.7976%\n",
      "layer   3  Sparsity: 38.0320%\n",
      "total_backward_count 1838592 real_backward_count 181421   9.867%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 54.8750%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 133 occurrences\n",
      "test - Value 1: 319 occurrences\n",
      "epoch-114 lr=['1.0000000'], tr/val_loss:172.465683/161.119354, val:  77.21%, val_best:  89.60%, tr:  99.93%, tr_best:  99.95%, epoch time: 119.74 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 58.6094%\n",
      "layer   3  Sparsity: 38.3907%\n",
      "total_backward_count 1854720 real_backward_count 182477   9.839%\n",
      "layer   1  Sparsity: 75.1953%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 34.2500%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 218 occurrences\n",
      "test - Value 1: 234 occurrences\n",
      "epoch-115 lr=['1.0000000'], tr/val_loss:175.654160/148.854080, val:  87.61%, val_best:  89.60%, tr:  99.85%, tr_best:  99.95%, epoch time: 119.97 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 58.6859%\n",
      "layer   3  Sparsity: 38.1986%\n",
      "total_backward_count 1870848 real_backward_count 183519   9.809%\n",
      "layer   1  Sparsity: 85.5469%\n",
      "layer   2  Sparsity: 68.1250%\n",
      "layer   3  Sparsity: 53.3750%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1495.00 at epoch 116, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-116 lr=['1.0000000'], tr/val_loss:182.628128/226.349380, val:  69.69%, val_best:  89.60%, tr:  99.88%, tr_best:  99.95%, epoch time: 121.51 seconds, 2.03 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 58.7759%\n",
      "layer   3  Sparsity: 38.7515%\n",
      "total_backward_count 1886976 real_backward_count 184610   9.783%\n",
      "layer   1  Sparsity: 69.0918%\n",
      "layer   2  Sparsity: 55.1250%\n",
      "layer   3  Sparsity: 31.3750%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "max_activation_accul updated: 1782.00 at epoch 117, iter 4031\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 96 occurrences\n",
      "test - Value 1: 356 occurrences\n",
      "epoch-117 lr=['1.0000000'], tr/val_loss:193.150482/235.123703, val:  71.24%, val_best:  89.60%, tr:  99.93%, tr_best:  99.95%, epoch time: 120.97 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4834%\n",
      "layer   2  Sparsity: 58.9230%\n",
      "layer   3  Sparsity: 40.2589%\n",
      "total_backward_count 1903104 real_backward_count 185625   9.754%\n",
      "layer   1  Sparsity: 85.9375%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 32.7500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-118 lr=['1.0000000'], tr/val_loss:181.962723/170.964676, val:  71.90%, val_best:  89.60%, tr:  99.93%, tr_best:  99.95%, epoch time: 120.59 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 58.5576%\n",
      "layer   3  Sparsity: 40.2126%\n",
      "total_backward_count 1919232 real_backward_count 186707   9.728%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 39.1250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 158 occurrences\n",
      "test - Value 1: 294 occurrences\n",
      "epoch-119 lr=['1.0000000'], tr/val_loss:176.885513/149.557922, val:  83.19%, val_best:  89.60%, tr:  99.88%, tr_best:  99.95%, epoch time: 120.69 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 58.8575%\n",
      "layer   3  Sparsity: 40.7039%\n",
      "total_backward_count 1935360 real_backward_count 187763   9.702%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 32.5000%\n",
      "fc layer 2 self.abs_max_out: 4488.0\n",
      "lif layer 2 self.abs_max_v: 4488.0\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 124 occurrences\n",
      "test - Value 1: 328 occurrences\n",
      "epoch-120 lr=['1.0000000'], tr/val_loss:165.774734/191.395874, val:  76.11%, val_best:  89.60%, tr:  99.83%, tr_best:  99.95%, epoch time: 120.14 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4796%\n",
      "layer   2  Sparsity: 58.5775%\n",
      "layer   3  Sparsity: 39.4771%\n",
      "total_backward_count 1951488 real_backward_count 188848   9.677%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 39.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-121 lr=['1.0000000'], tr/val_loss:185.780151/222.536758, val:  74.12%, val_best:  89.60%, tr:  99.93%, tr_best:  99.95%, epoch time: 117.11 seconds, 1.95 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 58.4274%\n",
      "layer   3  Sparsity: 38.8084%\n",
      "total_backward_count 1967616 real_backward_count 189902   9.651%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 36.2500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-122 lr=['1.0000000'], tr/val_loss:187.895920/189.592758, val:  74.34%, val_best:  89.60%, tr:  99.93%, tr_best:  99.95%, epoch time: 119.93 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 58.4446%\n",
      "layer   3  Sparsity: 39.2782%\n",
      "total_backward_count 1983744 real_backward_count 191012   9.629%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 36.1250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8486.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-123 lr=['1.0000000'], tr/val_loss:174.149399/166.657211, val:  86.06%, val_best:  89.60%, tr:  99.88%, tr_best:  99.95%, epoch time: 115.96 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 58.8920%\n",
      "layer   3  Sparsity: 40.3104%\n",
      "total_backward_count 1999872 real_backward_count 192120   9.607%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 34.2500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8533.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-124 lr=['1.0000000'], tr/val_loss:176.731094/176.908325, val:  84.51%, val_best:  89.60%, tr:  99.85%, tr_best:  99.95%, epoch time: 119.57 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 58.8676%\n",
      "layer   3  Sparsity: 40.5897%\n",
      "total_backward_count 2016000 real_backward_count 193188   9.583%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 59.3750%\n",
      "layer   3  Sparsity: 39.1250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "lif layer 1 self.abs_max_v: 8538.0\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 117 occurrences\n",
      "test - Value 1: 335 occurrences\n",
      "epoch-125 lr=['1.0000000'], tr/val_loss:176.598816/201.203506, val:  75.44%, val_best:  89.60%, tr:  99.83%, tr_best:  99.95%, epoch time: 119.99 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4800%\n",
      "layer   2  Sparsity: 58.5003%\n",
      "layer   3  Sparsity: 39.3520%\n",
      "total_backward_count 2032128 real_backward_count 194278   9.560%\n",
      "layer   1  Sparsity: 70.3125%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 77 occurrences\n",
      "test - Value 1: 375 occurrences\n",
      "epoch-126 lr=['1.0000000'], tr/val_loss:178.613312/200.326065, val:  67.04%, val_best:  89.60%, tr:  99.80%, tr_best:  99.95%, epoch time: 116.22 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 58.7537%\n",
      "layer   3  Sparsity: 39.4752%\n",
      "total_backward_count 2048256 real_backward_count 195412   9.540%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 39.3750%\n",
      "fc layer 3 self.abs_max_out: 525.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-127 lr=['1.0000000'], tr/val_loss:174.349899/129.992096, val:  81.19%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.48 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4823%\n",
      "layer   2  Sparsity: 58.7228%\n",
      "layer   3  Sparsity: 40.9637%\n",
      "total_backward_count 2064384 real_backward_count 196520   9.520%\n",
      "layer   1  Sparsity: 88.4277%\n",
      "layer   2  Sparsity: 63.7500%\n",
      "layer   3  Sparsity: 43.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-128 lr=['1.0000000'], tr/val_loss:177.361053/167.645752, val:  84.96%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.31 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 58.5146%\n",
      "layer   3  Sparsity: 39.7210%\n",
      "total_backward_count 2080512 real_backward_count 197631   9.499%\n",
      "layer   1  Sparsity: 84.5703%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 35.3750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-129 lr=['1.0000000'], tr/val_loss:177.902740/198.121323, val:  74.78%, val_best:  89.60%, tr:  99.83%, tr_best: 100.00%, epoch time: 119.31 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 58.5809%\n",
      "layer   3  Sparsity: 40.1764%\n",
      "total_backward_count 2096640 real_backward_count 198769   9.480%\n",
      "layer   1  Sparsity: 88.5254%\n",
      "layer   2  Sparsity: 63.3750%\n",
      "layer   3  Sparsity: 37.6250%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-130 lr=['1.0000000'], tr/val_loss:176.063812/160.691422, val:  78.98%, val_best:  89.60%, tr:  99.85%, tr_best: 100.00%, epoch time: 119.69 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 58.8495%\n",
      "layer   3  Sparsity: 39.1471%\n",
      "total_backward_count 2112768 real_backward_count 199922   9.463%\n",
      "layer   1  Sparsity: 87.7441%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-131 lr=['1.0000000'], tr/val_loss:170.976532/212.149887, val:  81.64%, val_best:  89.60%, tr:  99.70%, tr_best: 100.00%, epoch time: 119.46 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 58.7080%\n",
      "layer   3  Sparsity: 38.3960%\n",
      "total_backward_count 2128896 real_backward_count 201086   9.446%\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 43.3750%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-132 lr=['1.0000000'], tr/val_loss:176.389526/141.518875, val:  84.96%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 118.70 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4821%\n",
      "layer   2  Sparsity: 58.6584%\n",
      "layer   3  Sparsity: 40.8937%\n",
      "total_backward_count 2145024 real_backward_count 202142   9.424%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 42.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 86 occurrences\n",
      "test - Value 1: 366 occurrences\n",
      "epoch-133 lr=['1.0000000'], tr/val_loss:170.915482/202.183350, val:  69.03%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 119.58 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4795%\n",
      "layer   2  Sparsity: 58.9540%\n",
      "layer   3  Sparsity: 41.8485%\n",
      "total_backward_count 2161152 real_backward_count 203183   9.402%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 40.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 162 occurrences\n",
      "test - Value 1: 290 occurrences\n",
      "epoch-134 lr=['1.0000000'], tr/val_loss:177.747345/200.975281, val:  82.74%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 118.63 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 58.7952%\n",
      "layer   3  Sparsity: 42.8909%\n",
      "total_backward_count 2177280 real_backward_count 204185   9.378%\n",
      "layer   1  Sparsity: 79.1992%\n",
      "layer   2  Sparsity: 56.6250%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-135 lr=['1.0000000'], tr/val_loss:177.946671/159.578339, val:  84.96%, val_best:  89.60%, tr:  99.85%, tr_best: 100.00%, epoch time: 120.03 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 59.0889%\n",
      "layer   3  Sparsity: 42.2701%\n",
      "total_backward_count 2193408 real_backward_count 205252   9.358%\n",
      "layer   1  Sparsity: 81.1523%\n",
      "layer   2  Sparsity: 60.8750%\n",
      "layer   3  Sparsity: 43.7500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 141 occurrences\n",
      "test - Value 1: 311 occurrences\n",
      "epoch-136 lr=['1.0000000'], tr/val_loss:180.557617/159.096390, val:  80.75%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.13 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 59.1698%\n",
      "layer   3  Sparsity: 42.4919%\n",
      "total_backward_count 2209536 real_backward_count 206223   9.333%\n",
      "layer   1  Sparsity: 72.6562%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 40.6250%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 168 occurrences\n",
      "test - Value 1: 284 occurrences\n",
      "epoch-137 lr=['1.0000000'], tr/val_loss:186.655380/187.004333, val:  83.63%, val_best:  89.60%, tr:  99.78%, tr_best: 100.00%, epoch time: 120.21 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 59.1368%\n",
      "layer   3  Sparsity: 41.4520%\n",
      "total_backward_count 2225664 real_backward_count 207197   9.309%\n",
      "layer   1  Sparsity: 82.7148%\n",
      "layer   2  Sparsity: 64.8750%\n",
      "layer   3  Sparsity: 45.3750%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-138 lr=['1.0000000'], tr/val_loss:178.207291/229.878830, val:  65.71%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 119.22 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 59.3143%\n",
      "layer   3  Sparsity: 43.3041%\n",
      "total_backward_count 2241792 real_backward_count 208184   9.286%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 40.0000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 74 occurrences\n",
      "test - Value 1: 378 occurrences\n",
      "epoch-139 lr=['1.0000000'], tr/val_loss:178.852264/208.760345, val:  66.37%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.77 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 59.1033%\n",
      "layer   3  Sparsity: 44.2852%\n",
      "total_backward_count 2257920 real_backward_count 209114   9.261%\n",
      "layer   1  Sparsity: 93.6035%\n",
      "layer   2  Sparsity: 69.2500%\n",
      "layer   3  Sparsity: 46.0000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 137 occurrences\n",
      "test - Value 1: 315 occurrences\n",
      "epoch-140 lr=['1.0000000'], tr/val_loss:178.100052/158.700531, val:  77.65%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.06 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4779%\n",
      "layer   2  Sparsity: 59.0168%\n",
      "layer   3  Sparsity: 43.4769%\n",
      "total_backward_count 2274048 real_backward_count 210108   9.239%\n",
      "layer   1  Sparsity: 77.4414%\n",
      "layer   2  Sparsity: 56.5000%\n",
      "layer   3  Sparsity: 46.3750%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-141 lr=['1.0000000'], tr/val_loss:175.194290/135.314224, val:  82.74%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 119.54 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4815%\n",
      "layer   2  Sparsity: 58.9629%\n",
      "layer   3  Sparsity: 43.4582%\n",
      "total_backward_count 2290176 real_backward_count 211056   9.216%\n",
      "layer   1  Sparsity: 69.9707%\n",
      "layer   2  Sparsity: 53.8750%\n",
      "layer   3  Sparsity: 33.6250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 194 occurrences\n",
      "test - Value 1: 258 occurrences\n",
      "epoch-142 lr=['1.0000000'], tr/val_loss:184.627533/144.435471, val:  84.96%, val_best:  89.60%, tr:  99.80%, tr_best: 100.00%, epoch time: 119.74 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 59.0021%\n",
      "layer   3  Sparsity: 41.7224%\n",
      "total_backward_count 2306304 real_backward_count 212041   9.194%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 65.1250%\n",
      "layer   3  Sparsity: 41.2500%\n",
      "lif layer 2 self.abs_max_v: 4516.0\n",
      "lif layer 2 self.abs_max_v: 4700.0\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 197 occurrences\n",
      "test - Value 1: 255 occurrences\n",
      "epoch-143 lr=['1.0000000'], tr/val_loss:180.669495/187.166077, val:  86.95%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.87 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 58.9756%\n",
      "layer   3  Sparsity: 41.8535%\n",
      "total_backward_count 2322432 real_backward_count 212992   9.171%\n",
      "layer   1  Sparsity: 92.6270%\n",
      "layer   2  Sparsity: 73.7500%\n",
      "layer   3  Sparsity: 58.3750%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 167 occurrences\n",
      "test - Value 1: 285 occurrences\n",
      "epoch-144 lr=['1.0000000'], tr/val_loss:183.880859/170.856430, val:  84.29%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.68 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4781%\n",
      "layer   2  Sparsity: 58.7153%\n",
      "layer   3  Sparsity: 41.6198%\n",
      "total_backward_count 2338560 real_backward_count 213973   9.150%\n",
      "layer   1  Sparsity: 67.7734%\n",
      "layer   2  Sparsity: 50.3750%\n",
      "layer   3  Sparsity: 32.1250%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-145 lr=['1.0000000'], tr/val_loss:190.156448/160.956833, val:  75.88%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 120.31 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4837%\n",
      "layer   2  Sparsity: 58.8076%\n",
      "layer   3  Sparsity: 39.9138%\n",
      "total_backward_count 2354688 real_backward_count 214922   9.127%\n",
      "layer   1  Sparsity: 73.2910%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "lif layer 2 self.abs_max_v: 4795.5\n",
      "lif layer 2 self.abs_max_v: 4959.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 244 occurrences\n",
      "test - Value 1: 208 occurrences\n",
      "epoch-146 lr=['1.0000000'], tr/val_loss:171.087097/138.753983, val:  84.96%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 120.27 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4825%\n",
      "layer   2  Sparsity: 59.0267%\n",
      "layer   3  Sparsity: 39.4101%\n",
      "total_backward_count 2370816 real_backward_count 215942   9.108%\n",
      "layer   1  Sparsity: 79.8340%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 33.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-147 lr=['1.0000000'], tr/val_loss:196.217209/205.285080, val:  74.56%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 118.94 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 58.8374%\n",
      "layer   3  Sparsity: 40.7279%\n",
      "total_backward_count 2386944 real_backward_count 216902   9.087%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 62.1250%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-148 lr=['1.0000000'], tr/val_loss:197.699875/214.613892, val:  79.65%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 118.84 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 58.9067%\n",
      "layer   3  Sparsity: 40.5151%\n",
      "total_backward_count 2403072 real_backward_count 217823   9.064%\n",
      "layer   1  Sparsity: 84.0820%\n",
      "layer   2  Sparsity: 63.7500%\n",
      "layer   3  Sparsity: 35.8750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-149 lr=['1.0000000'], tr/val_loss:186.780350/131.921280, val:  84.07%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 120.35 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 58.8284%\n",
      "layer   3  Sparsity: 40.3338%\n",
      "total_backward_count 2419200 real_backward_count 218802   9.044%\n",
      "layer   1  Sparsity: 70.5078%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 40.2500%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 116 occurrences\n",
      "test - Value 1: 336 occurrences\n",
      "epoch-150 lr=['1.0000000'], tr/val_loss:187.521683/173.592712, val:  75.22%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 120.78 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4831%\n",
      "layer   2  Sparsity: 58.6777%\n",
      "layer   3  Sparsity: 39.9953%\n",
      "total_backward_count 2435328 real_backward_count 219750   9.023%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 47.5000%\n",
      "layer   3  Sparsity: 34.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-151 lr=['1.0000000'], tr/val_loss:172.772476/181.951843, val:  77.43%, val_best:  89.60%, tr:  99.85%, tr_best: 100.00%, epoch time: 119.45 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 58.7506%\n",
      "layer   3  Sparsity: 39.6850%\n",
      "total_backward_count 2451456 real_backward_count 220769   9.006%\n",
      "layer   1  Sparsity: 83.0566%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 43.7500%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 157 occurrences\n",
      "test - Value 1: 295 occurrences\n",
      "epoch-152 lr=['1.0000000'], tr/val_loss:170.940033/164.347626, val:  82.08%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 119.45 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 58.6651%\n",
      "layer   3  Sparsity: 38.9303%\n",
      "total_backward_count 2467584 real_backward_count 221753   8.987%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 54.8750%\n",
      "layer   3  Sparsity: 45.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 177 occurrences\n",
      "test - Value 1: 275 occurrences\n",
      "epoch-153 lr=['1.0000000'], tr/val_loss:183.612549/124.574249, val:  83.85%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.08 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 58.6539%\n",
      "layer   3  Sparsity: 40.9671%\n",
      "total_backward_count 2483712 real_backward_count 222759   8.969%\n",
      "layer   1  Sparsity: 66.5039%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 37.7500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 54 occurrences\n",
      "test - Value 1: 398 occurrences\n",
      "epoch-154 lr=['1.0000000'], tr/val_loss:179.940399/250.784103, val:  61.95%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.71 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4840%\n",
      "layer   2  Sparsity: 58.9701%\n",
      "layer   3  Sparsity: 42.0584%\n",
      "total_backward_count 2499840 real_backward_count 223739   8.950%\n",
      "layer   1  Sparsity: 80.3223%\n",
      "layer   2  Sparsity: 58.3750%\n",
      "layer   3  Sparsity: 44.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 114 occurrences\n",
      "test - Value 1: 338 occurrences\n",
      "epoch-155 lr=['1.0000000'], tr/val_loss:185.249252/172.231400, val:  75.22%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 119.34 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 59.3336%\n",
      "layer   3  Sparsity: 41.0440%\n",
      "total_backward_count 2515968 real_backward_count 224745   8.933%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 70.3750%\n",
      "layer   3  Sparsity: 52.0000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 143 occurrences\n",
      "test - Value 1: 309 occurrences\n",
      "epoch-156 lr=['1.0000000'], tr/val_loss:189.518723/174.524124, val:  79.87%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.93 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4792%\n",
      "layer   2  Sparsity: 59.2135%\n",
      "layer   3  Sparsity: 38.7133%\n",
      "total_backward_count 2532096 real_backward_count 225825   8.919%\n",
      "layer   1  Sparsity: 74.5605%\n",
      "layer   2  Sparsity: 56.3750%\n",
      "layer   3  Sparsity: 30.2500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 131 occurrences\n",
      "test - Value 1: 321 occurrences\n",
      "epoch-157 lr=['1.0000000'], tr/val_loss:188.751785/190.438599, val:  78.10%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 120.27 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4822%\n",
      "layer   2  Sparsity: 59.1512%\n",
      "layer   3  Sparsity: 38.9260%\n",
      "total_backward_count 2548224 real_backward_count 226782   8.900%\n",
      "layer   1  Sparsity: 82.5684%\n",
      "layer   2  Sparsity: 64.1250%\n",
      "layer   3  Sparsity: 45.6250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 164 occurrences\n",
      "test - Value 1: 288 occurrences\n",
      "epoch-158 lr=['1.0000000'], tr/val_loss:189.087448/170.064728, val:  82.74%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 119.35 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4804%\n",
      "layer   2  Sparsity: 58.9096%\n",
      "layer   3  Sparsity: 39.7760%\n",
      "total_backward_count 2564352 real_backward_count 227745   8.881%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 38.5000%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-159 lr=['1.0000000'], tr/val_loss:196.781189/230.955292, val:  71.90%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.68 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 58.8844%\n",
      "layer   3  Sparsity: 40.3651%\n",
      "total_backward_count 2580480 real_backward_count 228709   8.863%\n",
      "layer   1  Sparsity: 84.8145%\n",
      "layer   2  Sparsity: 65.3750%\n",
      "layer   3  Sparsity: 47.0000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-160 lr=['1.0000000'], tr/val_loss:206.875580/188.665344, val:  76.33%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.57 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4799%\n",
      "layer   2  Sparsity: 58.7417%\n",
      "layer   3  Sparsity: 41.1379%\n",
      "total_backward_count 2596608 real_backward_count 229635   8.844%\n",
      "layer   1  Sparsity: 62.3535%\n",
      "layer   2  Sparsity: 54.1250%\n",
      "layer   3  Sparsity: 31.6250%\n",
      "fc layer 3 self.abs_max_out: 544.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-161 lr=['1.0000000'], tr/val_loss:202.417923/236.882843, val:  74.34%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 115.58 seconds, 1.93 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 58.6484%\n",
      "layer   3  Sparsity: 40.9163%\n",
      "total_backward_count 2612736 real_backward_count 230564   8.825%\n",
      "layer   1  Sparsity: 92.2852%\n",
      "layer   2  Sparsity: 70.1250%\n",
      "layer   3  Sparsity: 53.6250%\n",
      "fc layer 1 self.abs_max_out: 6568.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-162 lr=['1.0000000'], tr/val_loss:187.421066/228.328125, val:  70.13%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.80 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4782%\n",
      "layer   2  Sparsity: 58.5216%\n",
      "layer   3  Sparsity: 41.5888%\n",
      "total_backward_count 2628864 real_backward_count 231508   8.806%\n",
      "layer   1  Sparsity: 73.5840%\n",
      "layer   2  Sparsity: 55.8750%\n",
      "layer   3  Sparsity: 36.6250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 151 occurrences\n",
      "test - Value 1: 301 occurrences\n",
      "epoch-163 lr=['1.0000000'], tr/val_loss:199.975128/161.306442, val:  82.08%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.12 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 58.5406%\n",
      "layer   3  Sparsity: 39.4455%\n",
      "total_backward_count 2644992 real_backward_count 232475   8.789%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 37.1250%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 128 occurrences\n",
      "test - Value 1: 324 occurrences\n",
      "epoch-164 lr=['1.0000000'], tr/val_loss:180.828110/170.502609, val:  77.88%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 119.76 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 58.5184%\n",
      "layer   3  Sparsity: 39.3056%\n",
      "total_backward_count 2661120 real_backward_count 233464   8.773%\n",
      "layer   1  Sparsity: 83.7402%\n",
      "layer   2  Sparsity: 63.6250%\n",
      "layer   3  Sparsity: 48.2500%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-165 lr=['1.0000000'], tr/val_loss:171.704330/210.995193, val:  72.12%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.71 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4801%\n",
      "layer   2  Sparsity: 58.2795%\n",
      "layer   3  Sparsity: 40.7656%\n",
      "total_backward_count 2677248 real_backward_count 234443   8.757%\n",
      "layer   1  Sparsity: 72.4609%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 40.6250%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 85 occurrences\n",
      "test - Value 1: 367 occurrences\n",
      "epoch-166 lr=['1.0000000'], tr/val_loss:200.844986/206.284073, val:  68.81%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 119.11 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4826%\n",
      "layer   2  Sparsity: 58.4229%\n",
      "layer   3  Sparsity: 39.6801%\n",
      "total_backward_count 2693376 real_backward_count 235408   8.740%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 120 occurrences\n",
      "test - Value 1: 332 occurrences\n",
      "epoch-167 lr=['1.0000000'], tr/val_loss:192.438828/251.342728, val:  76.11%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.63 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4803%\n",
      "layer   2  Sparsity: 58.7264%\n",
      "layer   3  Sparsity: 41.0235%\n",
      "total_backward_count 2709504 real_backward_count 236352   8.723%\n",
      "layer   1  Sparsity: 81.5430%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 34.6250%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-168 lr=['1.0000000'], tr/val_loss:189.818069/173.394287, val:  73.89%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.47 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4806%\n",
      "layer   2  Sparsity: 58.7562%\n",
      "layer   3  Sparsity: 42.4953%\n",
      "total_backward_count 2725632 real_backward_count 237350   8.708%\n",
      "layer   1  Sparsity: 89.4531%\n",
      "layer   2  Sparsity: 66.2500%\n",
      "layer   3  Sparsity: 44.0000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-169 lr=['1.0000000'], tr/val_loss:190.571152/215.809906, val:  74.56%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.98 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4789%\n",
      "layer   2  Sparsity: 58.5318%\n",
      "layer   3  Sparsity: 42.3887%\n",
      "total_backward_count 2741760 real_backward_count 238325   8.692%\n",
      "layer   1  Sparsity: 76.3672%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 34.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-170 lr=['1.0000000'], tr/val_loss:186.962830/180.264816, val:  79.65%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.37 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4818%\n",
      "layer   2  Sparsity: 58.5033%\n",
      "layer   3  Sparsity: 40.8520%\n",
      "total_backward_count 2757888 real_backward_count 239404   8.681%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 56.5000%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "fc layer 1 self.abs_max_out: 6620.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 144 occurrences\n",
      "test - Value 1: 308 occurrences\n",
      "epoch-171 lr=['1.0000000'], tr/val_loss:182.053696/162.917007, val:  80.97%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 120.21 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4811%\n",
      "layer   2  Sparsity: 58.7734%\n",
      "layer   3  Sparsity: 42.5182%\n",
      "total_backward_count 2774016 real_backward_count 240442   8.668%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 59.1250%\n",
      "layer   3  Sparsity: 40.3750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 182 occurrences\n",
      "test - Value 1: 270 occurrences\n",
      "epoch-172 lr=['1.0000000'], tr/val_loss:170.572800/141.948135, val:  85.84%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.24 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4810%\n",
      "layer   2  Sparsity: 58.6451%\n",
      "layer   3  Sparsity: 42.5403%\n",
      "total_backward_count 2790144 real_backward_count 241459   8.654%\n",
      "layer   1  Sparsity: 85.1562%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 45.3750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-173 lr=['1.0000000'], tr/val_loss:170.523346/185.687866, val:  77.65%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 120.13 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4798%\n",
      "layer   2  Sparsity: 58.5753%\n",
      "layer   3  Sparsity: 42.9433%\n",
      "total_backward_count 2806272 real_backward_count 242486   8.641%\n",
      "layer   1  Sparsity: 93.4082%\n",
      "layer   2  Sparsity: 72.6250%\n",
      "layer   3  Sparsity: 55.2500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-174 lr=['1.0000000'], tr/val_loss:175.890717/137.793930, val:  84.51%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 119.01 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4780%\n",
      "layer   2  Sparsity: 58.7734%\n",
      "layer   3  Sparsity: 42.3247%\n",
      "total_backward_count 2822400 real_backward_count 243519   8.628%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 39.3750%\n",
      "fc layer 1 self.abs_max_out: 6635.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-175 lr=['1.0000000'], tr/val_loss:177.514648/155.747864, val:  82.08%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 120.55 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4786%\n",
      "layer   2  Sparsity: 58.6874%\n",
      "layer   3  Sparsity: 40.0358%\n",
      "total_backward_count 2838528 real_backward_count 244534   8.615%\n",
      "layer   1  Sparsity: 73.7793%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 155 occurrences\n",
      "test - Value 1: 297 occurrences\n",
      "epoch-176 lr=['1.0000000'], tr/val_loss:185.000000/187.197968, val:  82.08%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 120.68 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 58.7189%\n",
      "layer   3  Sparsity: 39.4715%\n",
      "total_backward_count 2854656 real_backward_count 245535   8.601%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 37.8750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 174 occurrences\n",
      "test - Value 1: 278 occurrences\n",
      "epoch-177 lr=['1.0000000'], tr/val_loss:191.023254/144.486938, val:  84.96%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 120.95 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4802%\n",
      "layer   2  Sparsity: 58.7775%\n",
      "layer   3  Sparsity: 40.6701%\n",
      "total_backward_count 2870784 real_backward_count 246552   8.588%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 58.1250%\n",
      "layer   3  Sparsity: 41.0000%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-178 lr=['1.0000000'], tr/val_loss:192.366013/172.276550, val:  73.01%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 120.58 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 58.6670%\n",
      "layer   3  Sparsity: 40.7904%\n",
      "total_backward_count 2886912 real_backward_count 247490   8.573%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 35.8750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-179 lr=['1.0000000'], tr/val_loss:181.154251/234.018036, val:  67.04%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 120.75 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 58.6900%\n",
      "layer   3  Sparsity: 40.1058%\n",
      "total_backward_count 2903040 real_backward_count 248488   8.560%\n",
      "layer   1  Sparsity: 70.6543%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 38.0000%\n",
      "fc layer 1 self.abs_max_out: 6644.0\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-180 lr=['1.0000000'], tr/val_loss:170.767975/189.476471, val:  74.12%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 120.83 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4830%\n",
      "layer   2  Sparsity: 58.7906%\n",
      "layer   3  Sparsity: 40.1155%\n",
      "total_backward_count 2919168 real_backward_count 249528   8.548%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 37.3750%\n",
      "fc layer 1 self.abs_max_out: 6757.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 181 occurrences\n",
      "test - Value 1: 271 occurrences\n",
      "epoch-181 lr=['1.0000000'], tr/val_loss:168.311508/176.933853, val:  85.62%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 121.21 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4794%\n",
      "layer   2  Sparsity: 58.8541%\n",
      "layer   3  Sparsity: 41.4266%\n",
      "total_backward_count 2935296 real_backward_count 250558   8.536%\n",
      "layer   1  Sparsity: 57.8125%\n",
      "layer   2  Sparsity: 49.6250%\n",
      "layer   3  Sparsity: 28.0000%\n",
      "fc layer 1 self.abs_max_out: 6831.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 210 occurrences\n",
      "test - Value 1: 242 occurrences\n",
      "epoch-182 lr=['1.0000000'], tr/val_loss:167.862885/138.388443, val:  84.96%, val_best:  89.60%, tr:  99.88%, tr_best: 100.00%, epoch time: 120.26 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 59.0892%\n",
      "layer   3  Sparsity: 41.7990%\n",
      "total_backward_count 2951424 real_backward_count 251532   8.522%\n",
      "layer   1  Sparsity: 77.8809%\n",
      "layer   2  Sparsity: 57.8750%\n",
      "layer   3  Sparsity: 39.2500%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 175 occurrences\n",
      "test - Value 1: 277 occurrences\n",
      "epoch-183 lr=['1.0000000'], tr/val_loss:170.806366/170.265335, val:  85.18%, val_best:  89.60%, tr:  99.80%, tr_best: 100.00%, epoch time: 121.32 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4814%\n",
      "layer   2  Sparsity: 59.0610%\n",
      "layer   3  Sparsity: 42.0911%\n",
      "total_backward_count 2967552 real_backward_count 252549   8.510%\n",
      "layer   1  Sparsity: 71.2891%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 39.1250%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 111 occurrences\n",
      "test - Value 1: 341 occurrences\n",
      "epoch-184 lr=['1.0000000'], tr/val_loss:173.108414/241.969971, val:  74.12%, val_best:  89.60%, tr:  99.85%, tr_best: 100.00%, epoch time: 120.28 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4829%\n",
      "layer   2  Sparsity: 58.6359%\n",
      "layer   3  Sparsity: 41.3413%\n",
      "total_backward_count 2983680 real_backward_count 253570   8.499%\n",
      "layer   1  Sparsity: 85.8887%\n",
      "layer   2  Sparsity: 54.6250%\n",
      "layer   3  Sparsity: 44.3750%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 147 occurrences\n",
      "test - Value 1: 305 occurrences\n",
      "epoch-185 lr=['1.0000000'], tr/val_loss:176.812164/150.035233, val:  78.98%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 120.12 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 58.6369%\n",
      "layer   3  Sparsity: 43.4768%\n",
      "total_backward_count 2999808 real_backward_count 254564   8.486%\n",
      "layer   1  Sparsity: 85.6445%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 49.3750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 140 occurrences\n",
      "test - Value 1: 312 occurrences\n",
      "epoch-186 lr=['1.0000000'], tr/val_loss:160.895355/140.233627, val:  77.43%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 120.02 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4797%\n",
      "layer   2  Sparsity: 58.5584%\n",
      "layer   3  Sparsity: 42.7357%\n",
      "total_backward_count 3015936 real_backward_count 255500   8.472%\n",
      "layer   1  Sparsity: 80.0781%\n",
      "layer   2  Sparsity: 55.3750%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-187 lr=['1.0000000'], tr/val_loss:152.506653/200.553421, val:  79.65%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 120.11 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 58.5652%\n",
      "layer   3  Sparsity: 41.7510%\n",
      "total_backward_count 3032064 real_backward_count 256558   8.461%\n",
      "layer   1  Sparsity: 68.0664%\n",
      "layer   2  Sparsity: 55.6250%\n",
      "layer   3  Sparsity: 40.0000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 192 occurrences\n",
      "test - Value 1: 260 occurrences\n",
      "epoch-188 lr=['1.0000000'], tr/val_loss:169.520584/159.507401, val:  84.96%, val_best:  89.60%, tr:  99.85%, tr_best: 100.00%, epoch time: 119.44 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4836%\n",
      "layer   2  Sparsity: 58.8578%\n",
      "layer   3  Sparsity: 40.9967%\n",
      "total_backward_count 3048192 real_backward_count 257581   8.450%\n",
      "layer   1  Sparsity: 62.4512%\n",
      "layer   2  Sparsity: 49.8750%\n",
      "layer   3  Sparsity: 32.5000%\n",
      "fc layer 1 self.abs_max_out: 6882.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-189 lr=['1.0000000'], tr/val_loss:175.339142/164.334061, val:  76.33%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 120.30 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4849%\n",
      "layer   2  Sparsity: 58.7827%\n",
      "layer   3  Sparsity: 39.9629%\n",
      "total_backward_count 3064320 real_backward_count 258620   8.440%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 35.6250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-190 lr=['1.0000000'], tr/val_loss:170.386414/191.912308, val:  73.23%, val_best:  89.60%, tr:  99.90%, tr_best: 100.00%, epoch time: 119.63 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4808%\n",
      "layer   2  Sparsity: 58.4328%\n",
      "layer   3  Sparsity: 39.6725%\n",
      "total_backward_count 3080448 real_backward_count 259674   8.430%\n",
      "layer   1  Sparsity: 67.3828%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 44.7500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 186 occurrences\n",
      "test - Value 1: 266 occurrences\n",
      "epoch-191 lr=['1.0000000'], tr/val_loss:173.635773/139.097763, val:  86.73%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 120.92 seconds, 2.02 minutes\n",
      "layer   1  Sparsity: 79.4838%\n",
      "layer   2  Sparsity: 58.2187%\n",
      "layer   3  Sparsity: 41.0077%\n",
      "total_backward_count 3096576 real_backward_count 260659   8.418%\n",
      "layer   1  Sparsity: 75.5371%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 35.1250%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 171 occurrences\n",
      "test - Value 1: 281 occurrences\n",
      "epoch-192 lr=['1.0000000'], tr/val_loss:175.270432/163.241653, val:  84.73%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.07 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 58.0496%\n",
      "layer   3  Sparsity: 41.5701%\n",
      "total_backward_count 3112704 real_backward_count 261580   8.404%\n",
      "layer   1  Sparsity: 57.6660%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 33.2500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 109 occurrences\n",
      "test - Value 1: 343 occurrences\n",
      "epoch-193 lr=['1.0000000'], tr/val_loss:173.512497/194.335938, val:  73.67%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.06 seconds, 1.98 minutes\n",
      "layer   1  Sparsity: 79.4859%\n",
      "layer   2  Sparsity: 57.9939%\n",
      "layer   3  Sparsity: 40.6654%\n",
      "total_backward_count 3128832 real_backward_count 262485   8.389%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 57.8750%\n",
      "layer   3  Sparsity: 40.8750%\n",
      "lif layer 2 self.abs_max_v: 4966.0\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 106 occurrences\n",
      "test - Value 1: 346 occurrences\n",
      "epoch-194 lr=['1.0000000'], tr/val_loss:168.545761/195.682816, val:  72.57%, val_best:  89.60%, tr:  99.95%, tr_best: 100.00%, epoch time: 119.69 seconds, 1.99 minutes\n",
      "layer   1  Sparsity: 79.4820%\n",
      "layer   2  Sparsity: 58.1554%\n",
      "layer   3  Sparsity: 42.1085%\n",
      "total_backward_count 3144960 real_backward_count 263423   8.376%\n",
      "layer   1  Sparsity: 88.2324%\n",
      "layer   2  Sparsity: 61.0000%\n",
      "layer   3  Sparsity: 34.2500%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 152 occurrences\n",
      "test - Value 1: 300 occurrences\n",
      "epoch-195 lr=['1.0000000'], tr/val_loss:176.725494/172.120346, val:  82.74%, val_best:  89.60%, tr:  99.98%, tr_best: 100.00%, epoch time: 120.53 seconds, 2.01 minutes\n",
      "layer   1  Sparsity: 79.4791%\n",
      "layer   2  Sparsity: 58.1321%\n",
      "layer   3  Sparsity: 42.8498%\n",
      "total_backward_count 3161088 real_backward_count 264343   8.362%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 42.7500%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 148 occurrences\n",
      "test - Value 1: 304 occurrences\n",
      "epoch-196 lr=['1.0000000'], tr/val_loss:183.662369/211.512726, val:  80.53%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 120.04 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4807%\n",
      "layer   2  Sparsity: 58.0593%\n",
      "layer   3  Sparsity: 42.9855%\n",
      "total_backward_count 3177216 real_backward_count 265336   8.351%\n",
      "layer   1  Sparsity: 80.2734%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 46.8750%\n",
      "fc layer 1 self.abs_max_out: 6902.0\n",
      "lif layer 2 self.abs_max_v: 5045.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 123 occurrences\n",
      "test - Value 1: 329 occurrences\n",
      "epoch-197 lr=['1.0000000'], tr/val_loss:189.414337/170.726974, val:  76.33%, val_best:  89.60%, tr:  99.93%, tr_best: 100.00%, epoch time: 116.62 seconds, 1.94 minutes\n",
      "layer   1  Sparsity: 79.4809%\n",
      "layer   2  Sparsity: 58.0012%\n",
      "layer   3  Sparsity: 43.4227%\n",
      "total_backward_count 3193344 real_backward_count 266260   8.338%\n",
      "layer   1  Sparsity: 73.4863%\n",
      "layer   2  Sparsity: 55.6250%\n",
      "layer   3  Sparsity: 40.0000%\n",
      "fc layer 1 self.abs_max_out: 6922.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 113 occurrences\n",
      "test - Value 1: 339 occurrences\n",
      "epoch-198 lr=['1.0000000'], tr/val_loss:187.953430/207.993362, val:  74.12%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.85 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4824%\n",
      "layer   2  Sparsity: 57.9418%\n",
      "layer   3  Sparsity: 44.0028%\n",
      "total_backward_count 3209472 real_backward_count 267180   8.325%\n",
      "layer   1  Sparsity: 69.7754%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 35.8750%\n",
      "fc layer 1 self.abs_max_out: 6939.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test_spike_distribution.mean 4.000000, min 4, max 4\n",
      "test - Value 0: 91 occurrences\n",
      "test - Value 1: 361 occurrences\n",
      "epoch-199 lr=['1.0000000'], tr/val_loss:191.531158/204.062805, val:  69.69%, val_best:  89.60%, tr: 100.00%, tr_best: 100.00%, epoch time: 119.94 seconds, 2.00 minutes\n",
      "layer   1  Sparsity: 79.4832%\n",
      "layer   2  Sparsity: 58.0043%\n",
      "layer   3  Sparsity: 43.5096%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d98a6d980b45809248f66e8b311b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>191.53116</td></tr><tr><td>val_acc_best</td><td>0.89602</td></tr><tr><td>val_acc_now</td><td>0.6969</td></tr><tr><td>val_loss</td><td>204.06281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-sweep-39</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uvhdl5he' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uvhdl5he</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251213_035420-uvhdl5he/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pztfajjm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251213_103424-pztfajjm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/pztfajjm' target=\"_blank\">fine-sweep-40</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/pztfajjm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/pztfajjm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251213_103433_800', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 32, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 0.015625, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 4, 'lif_layer_v_threshold2': 32, 'init_scaling': [1, 0.125, 0.03125], 'learning_rate': 4, 'learning_rate2': 1, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 0.015625, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 4, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.125, 0.03125])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=0.015625, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.125, 0.03125])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.125, 0.03125])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 4\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 1357.0\n",
      "lif layer 1 self.abs_max_v: 1357.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 268.0\n",
      "lif layer 2 self.abs_max_v: 268.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 30.0\n",
      "fc layer 1 self.abs_max_out: 3281.0\n",
      "lif layer 1 self.abs_max_v: 3384.5\n",
      "lif layer 2 self.abs_max_v: 354.5\n",
      "fc layer 3 self.abs_max_out: 48.0\n",
      "fc layer 1 self.abs_max_out: 3429.0\n",
      "lif layer 1 self.abs_max_v: 4987.5\n",
      "lif layer 2 self.abs_max_v: 407.5\n",
      "fc layer 3 self.abs_max_out: 62.0\n",
      "lif layer 1 self.abs_max_v: 5010.0\n",
      "fc layer 2 self.abs_max_out: 340.0\n",
      "lif layer 2 self.abs_max_v: 544.0\n",
      "lif layer 2 self.abs_max_v: 550.0\n",
      "layer   1  Sparsity: 74.1211%\n",
      "layer   2  Sparsity: 53.1667%\n",
      "layer   3  Sparsity: 65.6667%\n",
      "fc layer 2 self.abs_max_out: 349.0\n",
      "fc layer 3 self.abs_max_out: 64.0\n",
      "fc layer 3 self.abs_max_out: 75.0\n",
      "fc layer 1 self.abs_max_out: 4810.0\n",
      "fc layer 3 self.abs_max_out: 98.0\n",
      "lif layer 1 self.abs_max_v: 5316.5\n",
      "fc layer 3 self.abs_max_out: 100.0\n",
      "fc layer 3 self.abs_max_out: 106.0\n",
      "fc layer 3 self.abs_max_out: 126.0\n",
      "fc layer 2 self.abs_max_out: 375.0\n",
      "fc layer 2 self.abs_max_out: 437.0\n",
      "fc layer 2 self.abs_max_out: 460.0\n",
      "lif layer 2 self.abs_max_v: 566.0\n",
      "fc layer 2 self.abs_max_out: 492.0\n",
      "lif layer 1 self.abs_max_v: 5350.5\n",
      "lif layer 2 self.abs_max_v: 572.0\n",
      "lif layer 2 self.abs_max_v: 589.0\n",
      "fc layer 3 self.abs_max_out: 141.0\n",
      "lif layer 2 self.abs_max_v: 601.5\n",
      "lif layer 2 self.abs_max_v: 603.5\n",
      "lif layer 2 self.abs_max_v: 609.5\n",
      "lif layer 2 self.abs_max_v: 637.5\n",
      "lif layer 2 self.abs_max_v: 639.0\n",
      "lif layer 1 self.abs_max_v: 6156.5\n",
      "lif layer 2 self.abs_max_v: 670.0\n",
      "lif layer 1 self.abs_max_v: 6271.5\n",
      "lif layer 2 self.abs_max_v: 689.0\n",
      "fc layer 1 self.abs_max_out: 5038.0\n",
      "fc layer 1 self.abs_max_out: 5403.0\n",
      "lif layer 1 self.abs_max_v: 6401.0\n",
      "lif layer 1 self.abs_max_v: 7847.5\n",
      "fc layer 1 self.abs_max_out: 6153.0\n",
      "lif layer 1 self.abs_max_v: 8053.5\n",
      "fc layer 1 self.abs_max_out: 6350.0\n",
      "fc layer 3 self.abs_max_out: 153.0\n",
      "fc layer 3 self.abs_max_out: 155.0\n",
      "fc layer 2 self.abs_max_out: 504.0\n",
      "fc layer 3 self.abs_max_out: 179.0\n",
      "fc layer 2 self.abs_max_out: 535.0\n",
      "fc layer 2 self.abs_max_out: 580.0\n",
      "fc layer 2 self.abs_max_out: 595.0\n",
      "fc layer 2 self.abs_max_out: 645.0\n",
      "fc layer 1 self.abs_max_out: 6428.0\n",
      "fc layer 2 self.abs_max_out: 646.0\n",
      "fc layer 3 self.abs_max_out: 193.0\n",
      "fc layer 2 self.abs_max_out: 700.0\n",
      "lif layer 2 self.abs_max_v: 700.0\n",
      "fc layer 2 self.abs_max_out: 725.0\n",
      "lif layer 2 self.abs_max_v: 725.0\n",
      "lif layer 2 self.abs_max_v: 731.0\n",
      "lif layer 2 self.abs_max_v: 765.0\n",
      "lif layer 2 self.abs_max_v: 820.5\n",
      "fc layer 2 self.abs_max_out: 760.0\n",
      "fc layer 2 self.abs_max_out: 791.0\n",
      "fc layer 2 self.abs_max_out: 821.0\n",
      "lif layer 2 self.abs_max_v: 821.0\n",
      "fc layer 2 self.abs_max_out: 831.0\n",
      "lif layer 2 self.abs_max_v: 831.0\n",
      "fc layer 2 self.abs_max_out: 855.0\n",
      "lif layer 2 self.abs_max_v: 855.0\n",
      "fc layer 2 self.abs_max_out: 881.0\n",
      "lif layer 2 self.abs_max_v: 881.0\n",
      "fc layer 1 self.abs_max_out: 6723.0\n",
      "fc layer 2 self.abs_max_out: 928.0\n",
      "lif layer 2 self.abs_max_v: 928.0\n",
      "lif layer 2 self.abs_max_v: 931.5\n",
      "lif layer 2 self.abs_max_v: 940.0\n",
      "lif layer 2 self.abs_max_v: 949.5\n",
      "lif layer 2 self.abs_max_v: 1024.5\n",
      "lif layer 2 self.abs_max_v: 1031.5\n",
      "lif layer 2 self.abs_max_v: 1055.0\n",
      "fc layer 3 self.abs_max_out: 196.0\n",
      "lif layer 2 self.abs_max_v: 1065.5\n",
      "lif layer 2 self.abs_max_v: 1125.0\n",
      "lif layer 2 self.abs_max_v: 1163.0\n",
      "lif layer 2 self.abs_max_v: 1194.0\n",
      "lif layer 2 self.abs_max_v: 1259.0\n",
      "lif layer 1 self.abs_max_v: 8288.0\n",
      "lif layer 2 self.abs_max_v: 1289.0\n",
      "lif layer 2 self.abs_max_v: 1339.5\n",
      "lif layer 2 self.abs_max_v: 1409.0\n",
      "lif layer 2 self.abs_max_v: 1414.0\n",
      "fc layer 2 self.abs_max_out: 941.0\n",
      "lif layer 2 self.abs_max_v: 1428.0\n",
      "lif layer 2 self.abs_max_v: 1505.0\n",
      "fc layer 2 self.abs_max_out: 960.0\n",
      "lif layer 2 self.abs_max_v: 1508.0\n",
      "lif layer 2 self.abs_max_v: 1569.0\n",
      "lif layer 2 self.abs_max_v: 1595.5\n",
      "lif layer 2 self.abs_max_v: 1640.0\n",
      "fc layer 2 self.abs_max_out: 1043.0\n",
      "lif layer 1 self.abs_max_v: 8860.5\n",
      "fc layer 1 self.abs_max_out: 6750.0\n",
      "lif layer 2 self.abs_max_v: 1648.5\n",
      "fc layer 2 self.abs_max_out: 1064.0\n",
      "fc layer 3 self.abs_max_out: 220.0\n",
      "lif layer 1 self.abs_max_v: 8885.0\n",
      "fc layer 3 self.abs_max_out: 237.0\n",
      "lif layer 2 self.abs_max_v: 1668.5\n",
      "lif layer 2 self.abs_max_v: 1689.5\n",
      "fc layer 2 self.abs_max_out: 1070.0\n",
      "lif layer 2 self.abs_max_v: 1768.5\n",
      "fc layer 2 self.abs_max_out: 1072.0\n",
      "fc layer 2 self.abs_max_out: 1111.0\n",
      "lif layer 2 self.abs_max_v: 1777.5\n",
      "lif layer 1 self.abs_max_v: 8912.0\n",
      "lif layer 2 self.abs_max_v: 1799.0\n",
      "lif layer 2 self.abs_max_v: 1808.5\n",
      "fc layer 1 self.abs_max_out: 7019.0\n",
      "lif layer 1 self.abs_max_v: 9670.5\n",
      "fc layer 2 self.abs_max_out: 1130.0\n",
      "fc layer 1 self.abs_max_out: 7116.0\n",
      "lif layer 1 self.abs_max_v: 9816.0\n",
      "fc layer 1 self.abs_max_out: 7544.0\n",
      "lif layer 1 self.abs_max_v: 10058.5\n",
      "lif layer 1 self.abs_max_v: 10844.5\n",
      "lif layer 1 self.abs_max_v: 12145.0\n",
      "lif layer 2 self.abs_max_v: 1811.5\n",
      "lif layer 2 self.abs_max_v: 1872.5\n",
      "fc layer 2 self.abs_max_out: 1134.0\n",
      "fc layer 1 self.abs_max_out: 7634.0\n",
      "fc layer 3 self.abs_max_out: 248.0\n",
      "fc layer 1 self.abs_max_out: 7658.0\n",
      "fc layer 1 self.abs_max_out: 7662.0\n",
      "lif layer 1 self.abs_max_v: 12416.0\n",
      "fc layer 1 self.abs_max_out: 8927.0\n",
      "lif layer 1 self.abs_max_v: 14349.0\n",
      "fc layer 3 self.abs_max_out: 269.0\n",
      "fc layer 3 self.abs_max_out: 303.0\n",
      "lif layer 2 self.abs_max_v: 1932.5\n",
      "fc layer 1 self.abs_max_out: 8947.0\n",
      "fc layer 1 self.abs_max_out: 9395.0\n",
      "lif layer 1 self.abs_max_v: 14612.0\n",
      "fc layer 1 self.abs_max_out: 9565.0\n",
      "fc layer 1 self.abs_max_out: 10033.0\n",
      "fc layer 1 self.abs_max_out: 10304.0\n",
      "lif layer 2 self.abs_max_v: 1966.5\n",
      "lif layer 2 self.abs_max_v: 1977.5\n",
      "lif layer 1 self.abs_max_v: 15009.5\n",
      "lif layer 1 self.abs_max_v: 15130.5\n",
      "fc layer 1 self.abs_max_out: 10327.0\n",
      "lif layer 1 self.abs_max_v: 15851.0\n",
      "fc layer 3 self.abs_max_out: 306.0\n",
      "fc layer 1 self.abs_max_out: 10911.0\n",
      "lif layer 1 self.abs_max_v: 15912.0\n",
      "lif layer 1 self.abs_max_v: 18457.0\n",
      "lif layer 2 self.abs_max_v: 1990.5\n",
      "fc layer 3 self.abs_max_out: 336.0\n",
      "fc layer 1 self.abs_max_out: 11167.0\n",
      "fc layer 1 self.abs_max_out: 11260.0\n",
      "fc layer 1 self.abs_max_out: 11809.0\n",
      "fc layer 2 self.abs_max_out: 1165.0\n",
      "fc layer 3 self.abs_max_out: 345.0\n",
      "fc layer 3 self.abs_max_out: 350.0\n",
      "fc layer 3 self.abs_max_out: 375.0\n",
      "fc layer 3 self.abs_max_out: 406.0\n",
      "lif layer 1 self.abs_max_v: 19159.5\n",
      "fc layer 1 self.abs_max_out: 12101.0\n",
      "fc layer 2 self.abs_max_out: 1179.0\n",
      "fc layer 2 self.abs_max_out: 1299.0\n",
      "fc layer 2 self.abs_max_out: 1318.0\n",
      "fc layer 1 self.abs_max_out: 12539.0\n",
      "fc layer 2 self.abs_max_out: 1335.0\n",
      "fc layer 3 self.abs_max_out: 428.0\n",
      "fc layer 3 self.abs_max_out: 444.0\n",
      "fc layer 3 self.abs_max_out: 477.0\n",
      "fc layer 1 self.abs_max_out: 12876.0\n",
      "fc layer 1 self.abs_max_out: 13361.0\n",
      "fc layer 1 self.abs_max_out: 13533.0\n",
      "fc layer 1 self.abs_max_out: 13977.0\n",
      "fc layer 1 self.abs_max_out: 13989.0\n",
      "fc layer 3 self.abs_max_out: 512.0\n",
      "fc layer 3 self.abs_max_out: 581.0\n",
      "fc layer 2 self.abs_max_out: 1363.0\n",
      "fc layer 2 self.abs_max_out: 1376.0\n",
      "fc layer 2 self.abs_max_out: 1410.0\n",
      "fc layer 2 self.abs_max_out: 1461.0\n",
      "lif layer 1 self.abs_max_v: 20345.0\n",
      "fc layer 2 self.abs_max_out: 1473.0\n",
      "fc layer 2 self.abs_max_out: 1476.0\n",
      "fc layer 2 self.abs_max_out: 1492.0\n",
      "fc layer 2 self.abs_max_out: 1598.0\n",
      "fc layer 1 self.abs_max_out: 15004.0\n",
      "lif layer 1 self.abs_max_v: 20466.0\n",
      "lif layer 1 self.abs_max_v: 21008.5\n",
      "lif layer 1 self.abs_max_v: 21178.5\n",
      "fc layer 2 self.abs_max_out: 1601.0\n",
      "fc layer 1 self.abs_max_out: 16199.0\n",
      "lif layer 1 self.abs_max_v: 22082.0\n",
      "lif layer 1 self.abs_max_v: 22485.5\n",
      "lif layer 1 self.abs_max_v: 23737.0\n",
      "lif layer 1 self.abs_max_v: 24923.0\n",
      "fc layer 1 self.abs_max_out: 16518.0\n",
      "fc layer 2 self.abs_max_out: 1656.0\n",
      "fc layer 1 self.abs_max_out: 17104.0\n",
      "lif layer 1 self.abs_max_v: 25068.5\n",
      "lif layer 1 self.abs_max_v: 25267.0\n",
      "fc layer 1 self.abs_max_out: 17156.0\n",
      "lif layer 1 self.abs_max_v: 26379.5\n",
      "fc layer 2 self.abs_max_out: 1666.0\n",
      "fc layer 2 self.abs_max_out: 1696.0\n",
      "fc layer 1 self.abs_max_out: 17300.0\n",
      "lif layer 1 self.abs_max_v: 28420.0\n",
      "fc layer 1 self.abs_max_out: 17425.0\n",
      "fc layer 1 self.abs_max_out: 17601.0\n",
      "fc layer 1 self.abs_max_out: 17627.0\n",
      "lif layer 1 self.abs_max_v: 29524.5\n",
      "fc layer 2 self.abs_max_out: 1718.0\n",
      "fc layer 1 self.abs_max_out: 17843.0\n",
      "fc layer 1 self.abs_max_out: 18437.0\n",
      "fc layer 2 self.abs_max_out: 1756.0\n",
      "fc layer 1 self.abs_max_out: 18907.0\n",
      "lif layer 1 self.abs_max_v: 30491.0\n",
      "fc layer 1 self.abs_max_out: 19148.0\n",
      "fc layer 1 self.abs_max_out: 19744.0\n",
      "fc layer 1 self.abs_max_out: 20007.0\n",
      "fc layer 1 self.abs_max_out: 20157.0\n",
      "fc layer 1 self.abs_max_out: 20558.0\n",
      "fc layer 2 self.abs_max_out: 1819.0\n",
      "lif layer 1 self.abs_max_v: 30887.5\n",
      "fc layer 3 self.abs_max_out: 583.0\n",
      "lif layer 1 self.abs_max_v: 31218.5\n",
      "lif layer 1 self.abs_max_v: 31695.0\n",
      "lif layer 1 self.abs_max_v: 32033.5\n",
      "lif layer 1 self.abs_max_v: 33303.0\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 1243.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1340.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1535.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1569.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1584.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1612.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1642.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1691.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1799.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 1841.00 at epoch 0, iter 4031\n",
      "lif layer 1 self.abs_max_v: 34043.5\n",
      "max_activation_accul updated: 2093.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['4.0000000'], tr/val_loss:136.802048/186.769333, val:  50.00%, val_best:  50.00%, tr:  91.62%, tr_best:  91.62%, epoch time: 175.14 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4672%\n",
      "layer   2  Sparsity: 58.8733%\n",
      "layer   3  Sparsity: 57.3519%\n",
      "total_backward_count 24192 real_backward_count 5294  21.883%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 75.7161%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 48.1667%\n",
      "fc layer 3 self.abs_max_out: 601.0\n",
      "fc layer 2 self.abs_max_out: 1868.0\n",
      "fc layer 2 self.abs_max_out: 1953.0\n",
      "fc layer 2 self.abs_max_out: 2041.0\n",
      "lif layer 2 self.abs_max_v: 2041.0\n",
      "fc layer 3 self.abs_max_out: 619.0\n",
      "fc layer 1 self.abs_max_out: 21287.0\n",
      "fc layer 1 self.abs_max_out: 21362.0\n",
      "fc layer 1 self.abs_max_out: 22042.0\n",
      "lif layer 1 self.abs_max_v: 36052.0\n",
      "fc layer 1 self.abs_max_out: 22461.0\n",
      "fc layer 1 self.abs_max_out: 22710.0\n",
      "fc layer 1 self.abs_max_out: 23779.0\n",
      "fc layer 3 self.abs_max_out: 660.0\n",
      "lif layer 2 self.abs_max_v: 2087.5\n",
      "lif layer 2 self.abs_max_v: 2142.5\n",
      "lif layer 2 self.abs_max_v: 2183.0\n",
      "lif layer 2 self.abs_max_v: 2247.5\n",
      "lif layer 2 self.abs_max_v: 2374.5\n",
      "lif layer 2 self.abs_max_v: 2390.5\n",
      "fc layer 1 self.abs_max_out: 23904.0\n",
      "fc layer 1 self.abs_max_out: 24120.0\n",
      "fc layer 1 self.abs_max_out: 25088.0\n",
      "fc layer 1 self.abs_max_out: 25205.0\n",
      "lif layer 2 self.abs_max_v: 2445.0\n",
      "fc layer 1 self.abs_max_out: 26432.0\n",
      "fc layer 1 self.abs_max_out: 26473.0\n",
      "fc layer 1 self.abs_max_out: 26742.0\n",
      "fc layer 1 self.abs_max_out: 26845.0\n",
      "fc layer 1 self.abs_max_out: 28338.0\n",
      "fc layer 2 self.abs_max_out: 2089.0\n",
      "fc layer 3 self.abs_max_out: 724.0\n",
      "lif layer 2 self.abs_max_v: 2472.0\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 2259.00 at epoch 1, iter 4031\n",
      "fc layer 2 self.abs_max_out: 2095.0\n",
      "fc layer 2 self.abs_max_out: 2187.0\n",
      "max_activation_accul updated: 2372.00 at epoch 1, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['4.0000000'], tr/val_loss:217.274277/266.183594, val:  50.00%, val_best:  50.00%, tr:  89.76%, tr_best:  91.62%, epoch time: 175.39 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 67.0912%\n",
      "layer   3  Sparsity: 54.1199%\n",
      "total_backward_count 48384 real_backward_count 10568  21.842%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 73.4167%\n",
      "layer   3  Sparsity: 62.5833%\n",
      "lif layer 2 self.abs_max_v: 2630.5\n",
      "lif layer 2 self.abs_max_v: 2651.0\n",
      "fc layer 2 self.abs_max_out: 2191.0\n",
      "fc layer 2 self.abs_max_out: 2199.0\n",
      "fc layer 2 self.abs_max_out: 2207.0\n",
      "fc layer 2 self.abs_max_out: 2219.0\n",
      "fc layer 2 self.abs_max_out: 2239.0\n",
      "fc layer 2 self.abs_max_out: 2246.0\n",
      "fc layer 2 self.abs_max_out: 2293.0\n",
      "fc layer 2 self.abs_max_out: 2339.0\n",
      "fc layer 3 self.abs_max_out: 761.0\n",
      "fc layer 3 self.abs_max_out: 764.0\n",
      "fc layer 2 self.abs_max_out: 2344.0\n",
      "fc layer 2 self.abs_max_out: 2367.0\n",
      "fc layer 2 self.abs_max_out: 2439.0\n",
      "fc layer 2 self.abs_max_out: 2465.0\n",
      "fc layer 2 self.abs_max_out: 2484.0\n",
      "fc layer 2 self.abs_max_out: 2485.0\n",
      "fc layer 2 self.abs_max_out: 2507.0\n",
      "fc layer 2 self.abs_max_out: 2512.0\n",
      "fc layer 2 self.abs_max_out: 2636.0\n",
      "lif layer 2 self.abs_max_v: 2709.0\n",
      "lif layer 2 self.abs_max_v: 2924.0\n",
      "lif layer 2 self.abs_max_v: 3132.0\n",
      "fc layer 2 self.abs_max_out: 2643.0\n",
      "lif layer 2 self.abs_max_v: 3311.0\n",
      "fc layer 2 self.abs_max_out: 2665.0\n",
      "fc layer 2 self.abs_max_out: 2682.0\n",
      "fc layer 2 self.abs_max_out: 2740.0\n",
      "fc layer 2 self.abs_max_out: 2788.0\n",
      "fc layer 2 self.abs_max_out: 2823.0\n",
      "fc layer 2 self.abs_max_out: 2855.0\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 2898.0\n",
      "fc layer 2 self.abs_max_out: 2913.0\n",
      "fc layer 2 self.abs_max_out: 3088.0\n",
      "lif layer 2 self.abs_max_v: 3355.5\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 103 occurrences\n",
      "test - Value 1: 349 occurrences\n",
      "epoch-2   lr=['4.0000000'], tr/val_loss:277.483032/154.085159, val:  59.96%, val_best:  59.96%, tr:  90.38%, tr_best:  91.62%, epoch time: 175.50 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 69.6176%\n",
      "layer   3  Sparsity: 53.4898%\n",
      "total_backward_count 72576 real_backward_count 15490  21.343%\n",
      "layer   1  Sparsity: 74.7721%\n",
      "layer   2  Sparsity: 72.7500%\n",
      "layer   3  Sparsity: 56.0833%\n",
      "lif layer 2 self.abs_max_v: 3603.5\n",
      "lif layer 2 self.abs_max_v: 3655.0\n",
      "lif layer 2 self.abs_max_v: 3658.5\n",
      "fc layer 1 self.abs_max_out: 29964.0\n",
      "fc layer 3 self.abs_max_out: 780.0\n",
      "lif layer 2 self.abs_max_v: 3704.0\n",
      "fc layer 3 self.abs_max_out: 838.0\n",
      "fc layer 3 self.abs_max_out: 851.0\n",
      "fc layer 3 self.abs_max_out: 862.0\n",
      "fc layer 3 self.abs_max_out: 895.0\n",
      "lif layer 2 self.abs_max_v: 3779.5\n",
      "lif layer 2 self.abs_max_v: 3781.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 2397.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2484.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2565.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2710.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2773.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 2958.00 at epoch 3, iter 4031\n",
      "max_activation_accul updated: 3006.00 at epoch 3, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['4.0000000'], tr/val_loss:265.420288/247.289139, val:  50.00%, val_best:  59.96%, tr:  92.24%, tr_best:  92.24%, epoch time: 175.17 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 66.5883%\n",
      "layer   3  Sparsity: 49.8228%\n",
      "total_backward_count 96768 real_backward_count 20135  20.807%\n",
      "layer   1  Sparsity: 76.6602%\n",
      "layer   2  Sparsity: 70.7500%\n",
      "layer   3  Sparsity: 51.3333%\n",
      "fc layer 1 self.abs_max_out: 30288.0\n",
      "lif layer 2 self.abs_max_v: 3798.5\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-4   lr=['4.0000000'], tr/val_loss:276.599823/198.092880, val:  50.44%, val_best:  59.96%, tr:  93.33%, tr_best:  93.33%, epoch time: 173.82 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 64.7193%\n",
      "layer   3  Sparsity: 47.0961%\n",
      "total_backward_count 120960 real_backward_count 24719  20.436%\n",
      "layer   1  Sparsity: 83.4310%\n",
      "layer   2  Sparsity: 64.9167%\n",
      "layer   3  Sparsity: 50.1667%\n",
      "lif layer 2 self.abs_max_v: 3853.5\n",
      "lif layer 2 self.abs_max_v: 3892.0\n",
      "lif layer 2 self.abs_max_v: 3893.5\n",
      "lif layer 2 self.abs_max_v: 3913.0\n",
      "fc layer 3 self.abs_max_out: 904.0\n",
      "lif layer 2 self.abs_max_v: 3957.5\n",
      "lif layer 2 self.abs_max_v: 4021.0\n",
      "lif layer 2 self.abs_max_v: 4030.5\n",
      "lif layer 2 self.abs_max_v: 4031.0\n",
      "lif layer 2 self.abs_max_v: 4076.0\n",
      "lif layer 2 self.abs_max_v: 4121.5\n",
      "fc layer 3 self.abs_max_out: 922.0\n",
      "lif layer 2 self.abs_max_v: 4161.0\n",
      "lif layer 2 self.abs_max_v: 4174.0\n",
      "lif layer 2 self.abs_max_v: 4202.0\n",
      "lif layer 2 self.abs_max_v: 4222.0\n",
      "lif layer 2 self.abs_max_v: 4254.0\n",
      "lif layer 2 self.abs_max_v: 4278.0\n",
      "lif layer 2 self.abs_max_v: 4279.5\n",
      "lif layer 2 self.abs_max_v: 4285.0\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 3024.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 3093.00 at epoch 5, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['4.0000000'], tr/val_loss:271.344849/262.729340, val:  50.00%, val_best:  59.96%, tr:  94.49%, tr_best:  94.49%, epoch time: 174.07 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 63.3228%\n",
      "layer   3  Sparsity: 45.5312%\n",
      "total_backward_count 145152 real_backward_count 29409  20.261%\n",
      "layer   1  Sparsity: 84.4401%\n",
      "layer   2  Sparsity: 60.1667%\n",
      "layer   3  Sparsity: 42.9167%\n",
      "lif layer 1 self.abs_max_v: 37454.5\n",
      "lif layer 1 self.abs_max_v: 38252.5\n",
      "lif layer 2 self.abs_max_v: 4364.5\n",
      "lif layer 2 self.abs_max_v: 4376.5\n",
      "lif layer 2 self.abs_max_v: 4377.5\n",
      "lif layer 2 self.abs_max_v: 4391.5\n",
      "lif layer 2 self.abs_max_v: 4413.0\n",
      "lif layer 2 self.abs_max_v: 4447.0\n",
      "fc layer 2 self.abs_max_out: 3143.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 3285.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 3656.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 3751.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 3841.00 at epoch 6, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['4.0000000'], tr/val_loss:267.264557/340.374725, val:  50.00%, val_best:  59.96%, tr:  95.11%, tr_best:  95.11%, epoch time: 174.83 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.2436%\n",
      "layer   3  Sparsity: 45.5275%\n",
      "total_backward_count 169344 real_backward_count 33900  20.018%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 65.4167%\n",
      "layer   3  Sparsity: 48.7500%\n",
      "lif layer 1 self.abs_max_v: 38428.5\n",
      "lif layer 1 self.abs_max_v: 40264.5\n",
      "fc layer 1 self.abs_max_out: 30496.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-7   lr=['4.0000000'], tr/val_loss:246.172791/138.903061, val:  50.22%, val_best:  59.96%, tr:  94.84%, tr_best:  95.11%, epoch time: 174.87 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.2522%\n",
      "layer   3  Sparsity: 45.8657%\n",
      "total_backward_count 193536 real_backward_count 38532  19.909%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 58.9167%\n",
      "layer   3  Sparsity: 41.2500%\n",
      "fc layer 2 self.abs_max_out: 3168.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-8   lr=['4.0000000'], tr/val_loss:235.390610/323.936554, val:  50.00%, val_best:  59.96%, tr:  94.22%, tr_best:  95.11%, epoch time: 173.90 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.3616%\n",
      "layer   3  Sparsity: 45.8285%\n",
      "total_backward_count 217728 real_backward_count 43248  19.863%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 67.0833%\n",
      "layer   3  Sparsity: 48.8333%\n",
      "lif layer 2 self.abs_max_v: 4450.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 3895.00 at epoch 9, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['4.0000000'], tr/val_loss:403.058075/484.054138, val:  50.00%, val_best:  59.96%, tr:  94.02%, tr_best:  95.11%, epoch time: 173.53 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.2343%\n",
      "layer   3  Sparsity: 44.2511%\n",
      "total_backward_count 241920 real_backward_count 47888  19.795%\n",
      "layer   1  Sparsity: 79.0690%\n",
      "layer   2  Sparsity: 61.8333%\n",
      "layer   3  Sparsity: 36.5833%\n",
      "fc layer 3 self.abs_max_out: 928.0\n",
      "lif layer 2 self.abs_max_v: 4499.0\n",
      "lif layer 2 self.abs_max_v: 4968.0\n",
      "fc layer 3 self.abs_max_out: 948.0\n",
      "fc layer 3 self.abs_max_out: 962.0\n",
      "fc layer 3 self.abs_max_out: 988.0\n",
      "fc layer 2 self.abs_max_out: 3291.0\n",
      "lif layer 2 self.abs_max_v: 5235.5\n",
      "fc layer 2 self.abs_max_out: 3340.0\n",
      "fc layer 2 self.abs_max_out: 3417.0\n",
      "fc layer 2 self.abs_max_out: 3421.0\n",
      "train - Value 0: 2072 occurrences\n",
      "train - Value 1: 1960 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "lif layer 2 self.abs_max_v: 5431.5\n",
      "fc layer 2 self.abs_max_out: 3481.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-10  lr=['4.0000000'], tr/val_loss:483.023926/466.479675, val:  59.51%, val_best:  59.96%, tr:  94.49%, tr_best:  95.11%, epoch time: 174.34 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 64.1182%\n",
      "layer   3  Sparsity: 42.3794%\n",
      "total_backward_count 266112 real_backward_count 52513  19.733%\n",
      "layer   1  Sparsity: 86.7188%\n",
      "layer   2  Sparsity: 61.9167%\n",
      "layer   3  Sparsity: 36.6667%\n",
      "fc layer 2 self.abs_max_out: 3653.0\n",
      "lif layer 2 self.abs_max_v: 5656.5\n",
      "fc layer 3 self.abs_max_out: 1006.0\n",
      "fc layer 3 self.abs_max_out: 1050.0\n",
      "fc layer 3 self.abs_max_out: 1091.0\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 3946.00 at epoch 11, iter 4031\n",
      "max_activation_accul updated: 4421.00 at epoch 11, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['4.0000000'], tr/val_loss:516.409302/589.972534, val:  50.00%, val_best:  59.96%, tr:  93.48%, tr_best:  95.11%, epoch time: 174.09 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 64.2375%\n",
      "layer   3  Sparsity: 41.9169%\n",
      "total_backward_count 290304 real_backward_count 57233  19.715%\n",
      "layer   1  Sparsity: 83.8542%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 36.0833%\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 241 occurrences\n",
      "test - Value 1: 211 occurrences\n",
      "epoch-12  lr=['4.0000000'], tr/val_loss:574.964783/524.418091, val:  66.15%, val_best:  66.15%, tr:  93.73%, tr_best:  95.11%, epoch time: 174.78 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 64.0351%\n",
      "layer   3  Sparsity: 41.6254%\n",
      "total_backward_count 314496 real_backward_count 61948  19.698%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 72.0833%\n",
      "layer   3  Sparsity: 47.0000%\n",
      "fc layer 3 self.abs_max_out: 1099.0\n",
      "fc layer 3 self.abs_max_out: 1124.0\n",
      "lif layer 2 self.abs_max_v: 5765.0\n",
      "lif layer 1 self.abs_max_v: 41378.5\n",
      "lif layer 2 self.abs_max_v: 5803.5\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 4577.00 at epoch 13, iter 4031\n",
      "lif layer 1 self.abs_max_v: 42099.0\n",
      "lif layer 1 self.abs_max_v: 42532.5\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['4.0000000'], tr/val_loss:619.222717/652.879822, val:  50.00%, val_best:  66.15%, tr:  93.85%, tr_best:  95.11%, epoch time: 174.53 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 63.6860%\n",
      "layer   3  Sparsity: 41.7909%\n",
      "total_backward_count 338688 real_backward_count 66679  19.687%\n",
      "layer   1  Sparsity: 90.3971%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 45.4167%\n",
      "lif layer 2 self.abs_max_v: 5815.5\n",
      "lif layer 2 self.abs_max_v: 5817.5\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-14  lr=['4.0000000'], tr/val_loss:684.805420/631.604675, val:  57.74%, val_best:  66.15%, tr:  94.82%, tr_best:  95.11%, epoch time: 173.72 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 63.8182%\n",
      "layer   3  Sparsity: 42.7166%\n",
      "total_backward_count 362880 real_backward_count 71165  19.611%\n",
      "layer   1  Sparsity: 93.8151%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "lif layer 2 self.abs_max_v: 6072.0\n",
      "fc layer 2 self.abs_max_out: 3715.0\n",
      "lif layer 2 self.abs_max_v: 6142.5\n",
      "lif layer 2 self.abs_max_v: 6344.5\n",
      "fc layer 2 self.abs_max_out: 3806.0\n",
      "fc layer 2 self.abs_max_out: 3819.0\n",
      "lif layer 2 self.abs_max_v: 6401.0\n",
      "fc layer 2 self.abs_max_out: 3858.0\n",
      "fc layer 2 self.abs_max_out: 3859.0\n",
      "fc layer 2 self.abs_max_out: 3900.0\n",
      "lif layer 2 self.abs_max_v: 6796.0\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 368 occurrences\n",
      "test - Value 1: 84 occurrences\n",
      "epoch-15  lr=['4.0000000'], tr/val_loss:719.470337/655.471680, val:  63.27%, val_best:  66.15%, tr:  95.56%, tr_best:  95.56%, epoch time: 174.79 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 63.7075%\n",
      "layer   3  Sparsity: 43.2626%\n",
      "total_backward_count 387072 real_backward_count 75560  19.521%\n",
      "layer   1  Sparsity: 84.9935%\n",
      "layer   2  Sparsity: 59.9167%\n",
      "layer   3  Sparsity: 51.0000%\n",
      "fc layer 2 self.abs_max_out: 3974.0\n",
      "lif layer 2 self.abs_max_v: 6965.0\n",
      "lif layer 2 self.abs_max_v: 7066.5\n",
      "fc layer 2 self.abs_max_out: 3980.0\n",
      "fc layer 2 self.abs_max_out: 4047.0\n",
      "lif layer 2 self.abs_max_v: 7311.0\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-16  lr=['4.0000000'], tr/val_loss:714.321899/684.925781, val:  50.22%, val_best:  66.15%, tr:  94.84%, tr_best:  95.56%, epoch time: 174.27 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 63.7418%\n",
      "layer   3  Sparsity: 44.4124%\n",
      "total_backward_count 411264 real_backward_count 80340  19.535%\n",
      "layer   1  Sparsity: 75.6510%\n",
      "layer   2  Sparsity: 55.0833%\n",
      "layer   3  Sparsity: 37.7500%\n",
      "fc layer 2 self.abs_max_out: 4056.0\n",
      "fc layer 2 self.abs_max_out: 4089.0\n",
      "fc layer 3 self.abs_max_out: 1137.0\n",
      "fc layer 2 self.abs_max_out: 4129.0\n",
      "fc layer 2 self.abs_max_out: 4163.0\n",
      "fc layer 2 self.abs_max_out: 4223.0\n",
      "fc layer 2 self.abs_max_out: 4323.0\n",
      "fc layer 2 self.abs_max_out: 4358.0\n",
      "fc layer 2 self.abs_max_out: 4376.0\n",
      "lif layer 2 self.abs_max_v: 7744.5\n",
      "fc layer 2 self.abs_max_out: 4431.0\n",
      "fc layer 2 self.abs_max_out: 4437.0\n",
      "fc layer 3 self.abs_max_out: 1187.0\n",
      "lif layer 2 self.abs_max_v: 7755.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-17  lr=['4.0000000'], tr/val_loss:698.871643/620.317444, val:  50.66%, val_best:  66.15%, tr:  94.82%, tr_best:  95.56%, epoch time: 174.51 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.8750%\n",
      "layer   3  Sparsity: 44.2656%\n",
      "total_backward_count 435456 real_backward_count 85081  19.538%\n",
      "layer   1  Sparsity: 75.2930%\n",
      "layer   2  Sparsity: 64.0833%\n",
      "layer   3  Sparsity: 37.8333%\n",
      "fc layer 2 self.abs_max_out: 4455.0\n",
      "fc layer 2 self.abs_max_out: 4587.0\n",
      "fc layer 2 self.abs_max_out: 4688.0\n",
      "fc layer 2 self.abs_max_out: 4868.0\n",
      "lif layer 1 self.abs_max_v: 44596.5\n",
      "lif layer 2 self.abs_max_v: 8212.0\n",
      "lif layer 2 self.abs_max_v: 8251.0\n",
      "lif layer 2 self.abs_max_v: 8624.5\n",
      "lif layer 1 self.abs_max_v: 47084.5\n",
      "lif layer 1 self.abs_max_v: 47865.5\n",
      "lif layer 1 self.abs_max_v: 50090.0\n",
      "fc layer 1 self.abs_max_out: 30572.0\n",
      "fc layer 1 self.abs_max_out: 30771.0\n",
      "fc layer 1 self.abs_max_out: 30862.0\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 1 self.abs_max_out: 31168.0\n",
      "lif layer 1 self.abs_max_v: 50114.5\n",
      "max_activation_accul updated: 4650.00 at epoch 18, iter 4031\n",
      "lif layer 1 self.abs_max_v: 50135.5\n",
      "lif layer 1 self.abs_max_v: 50434.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['4.0000000'], tr/val_loss:651.335510/688.525940, val:  50.00%, val_best:  66.15%, tr:  94.10%, tr_best:  95.56%, epoch time: 172.77 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 62.2320%\n",
      "layer   3  Sparsity: 43.6081%\n",
      "total_backward_count 459648 real_backward_count 89879  19.554%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 73.2500%\n",
      "layer   3  Sparsity: 57.0833%\n",
      "fc layer 1 self.abs_max_out: 31179.0\n",
      "fc layer 2 self.abs_max_out: 4945.0\n",
      "lif layer 2 self.abs_max_v: 8853.5\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 5061.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['4.0000000'], tr/val_loss:669.534607/707.016113, val:  50.00%, val_best:  66.15%, tr:  94.12%, tr_best:  95.56%, epoch time: 173.01 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 62.3060%\n",
      "layer   3  Sparsity: 43.2539%\n",
      "total_backward_count 483840 real_backward_count 94487  19.529%\n",
      "layer   1  Sparsity: 81.2826%\n",
      "layer   2  Sparsity: 57.8333%\n",
      "layer   3  Sparsity: 48.6667%\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-20  lr=['4.0000000'], tr/val_loss:704.020508/662.852844, val:  53.54%, val_best:  66.15%, tr:  95.11%, tr_best:  95.56%, epoch time: 174.02 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 62.5729%\n",
      "layer   3  Sparsity: 43.4287%\n",
      "total_backward_count 508032 real_backward_count 99024  19.492%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 66.7500%\n",
      "layer   3  Sparsity: 47.7500%\n",
      "lif layer 2 self.abs_max_v: 8986.5\n",
      "lif layer 2 self.abs_max_v: 9013.5\n",
      "fc layer 2 self.abs_max_out: 5079.0\n",
      "lif layer 2 self.abs_max_v: 9147.0\n",
      "fc layer 2 self.abs_max_out: 5104.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 5266.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 428 occurrences\n",
      "test - Value 1: 24 occurrences\n",
      "epoch-21  lr=['4.0000000'], tr/val_loss:655.317322/635.513672, val:  54.87%, val_best:  66.15%, tr:  94.87%, tr_best:  95.56%, epoch time: 173.49 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 62.3438%\n",
      "layer   3  Sparsity: 42.8916%\n",
      "total_backward_count 532224 real_backward_count 103682  19.481%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 48.5833%\n",
      "lif layer 2 self.abs_max_v: 9376.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['4.0000000'], tr/val_loss:646.179443/584.470886, val:  50.00%, val_best:  66.15%, tr:  94.02%, tr_best:  95.56%, epoch time: 168.52 seconds, 2.81 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 62.3665%\n",
      "layer   3  Sparsity: 42.6851%\n",
      "total_backward_count 556416 real_backward_count 108464  19.493%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 36.7500%\n",
      "lif layer 2 self.abs_max_v: 9457.0\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-23  lr=['4.0000000'], tr/val_loss:636.339966/624.163330, val:  51.55%, val_best:  66.15%, tr:  94.59%, tr_best:  95.56%, epoch time: 173.34 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 62.5496%\n",
      "layer   3  Sparsity: 42.3337%\n",
      "total_backward_count 580608 real_backward_count 113158  19.490%\n",
      "layer   1  Sparsity: 75.5208%\n",
      "layer   2  Sparsity: 57.3333%\n",
      "layer   3  Sparsity: 33.5000%\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 5337.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-24  lr=['4.0000000'], tr/val_loss:648.920471/660.572754, val:  50.44%, val_best:  66.15%, tr:  94.10%, tr_best:  95.56%, epoch time: 174.75 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 62.8576%\n",
      "layer   3  Sparsity: 42.1368%\n",
      "total_backward_count 604800 real_backward_count 118013  19.513%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 55.0833%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "lif layer 2 self.abs_max_v: 9561.5\n",
      "fc layer 2 self.abs_max_out: 5359.0\n",
      "lif layer 2 self.abs_max_v: 9619.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-25  lr=['4.0000000'], tr/val_loss:721.569824/636.944885, val:  60.18%, val_best:  66.15%, tr:  94.67%, tr_best:  95.56%, epoch time: 173.98 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 62.4585%\n",
      "layer   3  Sparsity: 42.0312%\n",
      "total_backward_count 628992 real_backward_count 122627  19.496%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 63.6667%\n",
      "layer   3  Sparsity: 37.5833%\n",
      "fc layer 3 self.abs_max_out: 1207.0\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['4.0000000'], tr/val_loss:689.481628/663.166565, val:  50.00%, val_best:  66.15%, tr:  93.80%, tr_best:  95.56%, epoch time: 174.03 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 62.1119%\n",
      "layer   3  Sparsity: 42.2014%\n",
      "total_backward_count 653184 real_backward_count 127585  19.533%\n",
      "layer   1  Sparsity: 72.9818%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 35.7500%\n",
      "fc layer 3 self.abs_max_out: 1227.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['4.0000000'], tr/val_loss:725.670471/763.455322, val:  50.00%, val_best:  66.15%, tr:  94.07%, tr_best:  95.56%, epoch time: 174.58 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 62.6453%\n",
      "layer   3  Sparsity: 42.4507%\n",
      "total_backward_count 677376 real_backward_count 132323  19.535%\n",
      "layer   1  Sparsity: 80.7617%\n",
      "layer   2  Sparsity: 61.4167%\n",
      "layer   3  Sparsity: 48.0833%\n",
      "fc layer 2 self.abs_max_out: 5367.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 5378.0\n",
      "fc layer 2 self.abs_max_out: 5515.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 427 occurrences\n",
      "test - Value 1: 25 occurrences\n",
      "epoch-28  lr=['4.0000000'], tr/val_loss:802.410645/783.337402, val:  55.09%, val_best:  66.15%, tr:  95.14%, tr_best:  95.56%, epoch time: 173.38 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 63.0015%\n",
      "layer   3  Sparsity: 39.1292%\n",
      "total_backward_count 701568 real_backward_count 136919  19.516%\n",
      "layer   1  Sparsity: 80.3385%\n",
      "layer   2  Sparsity: 55.5000%\n",
      "layer   3  Sparsity: 33.1667%\n",
      "fc layer 2 self.abs_max_out: 5725.0\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 4669.00 at epoch 29, iter 4031\n",
      "max_activation_accul updated: 4982.00 at epoch 29, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['4.0000000'], tr/val_loss:912.503906/890.317993, val:  50.00%, val_best:  66.15%, tr:  94.79%, tr_best:  95.56%, epoch time: 173.38 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 63.3795%\n",
      "layer   3  Sparsity: 37.6898%\n",
      "total_backward_count 725760 real_backward_count 141643  19.517%\n",
      "layer   1  Sparsity: 89.8763%\n",
      "layer   2  Sparsity: 69.5833%\n",
      "layer   3  Sparsity: 45.0000%\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5140.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5156.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5160.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5187.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5214.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5336.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5383.00 at epoch 30, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['4.0000000'], tr/val_loss:927.070801/919.429871, val:  50.00%, val_best:  66.15%, tr:  95.51%, tr_best:  95.56%, epoch time: 174.27 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.4383%\n",
      "layer   3  Sparsity: 38.0038%\n",
      "total_backward_count 749952 real_backward_count 146190  19.493%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 30.5833%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 345 occurrences\n",
      "test - Value 1: 107 occurrences\n",
      "epoch-31  lr=['4.0000000'], tr/val_loss:937.031006/854.874634, val:  64.38%, val_best:  66.15%, tr:  95.21%, tr_best:  95.56%, epoch time: 173.67 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 63.3051%\n",
      "layer   3  Sparsity: 38.1770%\n",
      "total_backward_count 774144 real_backward_count 150799  19.479%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 58.0000%\n",
      "layer   3  Sparsity: 34.1667%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 43 occurrences\n",
      "test - Value 1: 409 occurrences\n",
      "epoch-32  lr=['4.0000000'], tr/val_loss:944.917358/852.830933, val:  57.30%, val_best:  66.15%, tr:  94.79%, tr_best:  95.56%, epoch time: 172.76 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 63.3887%\n",
      "layer   3  Sparsity: 37.5900%\n",
      "total_backward_count 798336 real_backward_count 155319  19.455%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 71.0000%\n",
      "layer   3  Sparsity: 44.3333%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-33  lr=['4.0000000'], tr/val_loss:949.407227/871.375610, val:  56.86%, val_best:  66.15%, tr:  94.49%, tr_best:  95.56%, epoch time: 174.24 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 63.3105%\n",
      "layer   3  Sparsity: 37.9443%\n",
      "total_backward_count 822528 real_backward_count 160099  19.464%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 64.2500%\n",
      "layer   3  Sparsity: 33.1667%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 398 occurrences\n",
      "test - Value 1: 54 occurrences\n",
      "epoch-34  lr=['4.0000000'], tr/val_loss:958.535278/869.892822, val:  60.18%, val_best:  66.15%, tr:  94.92%, tr_best:  95.56%, epoch time: 174.16 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 63.2933%\n",
      "layer   3  Sparsity: 38.4299%\n",
      "total_backward_count 846720 real_backward_count 164772  19.460%\n",
      "layer   1  Sparsity: 87.9232%\n",
      "layer   2  Sparsity: 67.5833%\n",
      "layer   3  Sparsity: 45.1667%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5478.00 at epoch 35, iter 4031\n",
      "max_activation_accul updated: 5536.00 at epoch 35, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['4.0000000'], tr/val_loss:969.901123/961.787781, val:  50.00%, val_best:  66.15%, tr:  94.84%, tr_best:  95.56%, epoch time: 173.01 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 63.3942%\n",
      "layer   3  Sparsity: 38.0394%\n",
      "total_backward_count 870912 real_backward_count 169278  19.437%\n",
      "layer   1  Sparsity: 93.9779%\n",
      "layer   2  Sparsity: 71.6667%\n",
      "layer   3  Sparsity: 54.9167%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-36  lr=['4.0000000'], tr/val_loss:978.127991/940.143555, val:  50.66%, val_best:  66.15%, tr:  94.82%, tr_best:  95.56%, epoch time: 171.13 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 63.3717%\n",
      "layer   3  Sparsity: 37.5349%\n",
      "total_backward_count 895104 real_backward_count 173923  19.430%\n",
      "layer   1  Sparsity: 80.7292%\n",
      "layer   2  Sparsity: 61.3333%\n",
      "layer   3  Sparsity: 31.5833%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['4.0000000'], tr/val_loss:989.893982/908.032471, val:  50.00%, val_best:  66.15%, tr:  95.16%, tr_best:  95.56%, epoch time: 173.48 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 63.3793%\n",
      "layer   3  Sparsity: 37.7456%\n",
      "total_backward_count 919296 real_backward_count 178597  19.428%\n",
      "layer   1  Sparsity: 70.4753%\n",
      "layer   2  Sparsity: 58.2500%\n",
      "layer   3  Sparsity: 29.9167%\n",
      "fc layer 3 self.abs_max_out: 1238.0\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5545.00 at epoch 38, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-38  lr=['4.0000000'], tr/val_loss:1002.050110/969.072693, val:  50.22%, val_best:  66.15%, tr:  94.54%, tr_best:  95.56%, epoch time: 174.08 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4681%\n",
      "layer   2  Sparsity: 63.3541%\n",
      "layer   3  Sparsity: 38.0839%\n",
      "total_backward_count 943488 real_backward_count 183361  19.434%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 62.0833%\n",
      "layer   3  Sparsity: 33.2500%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5633.00 at epoch 39, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['4.0000000'], tr/val_loss:993.754456/932.723450, val:  50.00%, val_best:  66.15%, tr:  95.51%, tr_best:  95.56%, epoch time: 174.12 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.3661%\n",
      "layer   3  Sparsity: 38.2745%\n",
      "total_backward_count 967680 real_backward_count 187992  19.427%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 42.8333%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5789.00 at epoch 40, iter 4031\n",
      "max_activation_accul updated: 5866.00 at epoch 40, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-40  lr=['4.0000000'], tr/val_loss:997.648682/992.575317, val:  50.00%, val_best:  66.15%, tr:  95.71%, tr_best:  95.71%, epoch time: 174.56 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.3462%\n",
      "layer   3  Sparsity: 37.9554%\n",
      "total_backward_count 991872 real_backward_count 192397  19.397%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 60.9167%\n",
      "layer   3  Sparsity: 34.8333%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-41  lr=['4.0000000'], tr/val_loss:1006.006226/920.812744, val:  50.22%, val_best:  66.15%, tr:  95.31%, tr_best:  95.71%, epoch time: 174.30 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 63.3791%\n",
      "layer   3  Sparsity: 37.6356%\n",
      "total_backward_count 1016064 real_backward_count 197066  19.395%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 30.0000%\n",
      "fc layer 3 self.abs_max_out: 1293.0\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5901.00 at epoch 42, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-42  lr=['4.0000000'], tr/val_loss:1007.606323/969.789673, val:  50.88%, val_best:  66.15%, tr:  95.14%, tr_best:  95.71%, epoch time: 174.69 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4683%\n",
      "layer   2  Sparsity: 63.4207%\n",
      "layer   3  Sparsity: 37.5092%\n",
      "total_backward_count 1040256 real_backward_count 201670  19.387%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 66.0833%\n",
      "layer   3  Sparsity: 43.3333%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-43  lr=['4.0000000'], tr/val_loss:994.097473/955.012695, val:  50.22%, val_best:  66.15%, tr:  94.47%, tr_best:  95.71%, epoch time: 174.04 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 63.3607%\n",
      "layer   3  Sparsity: 38.1591%\n",
      "total_backward_count 1064448 real_backward_count 206501  19.400%\n",
      "layer   1  Sparsity: 89.1276%\n",
      "layer   2  Sparsity: 69.4167%\n",
      "layer   3  Sparsity: 45.4167%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['4.0000000'], tr/val_loss:995.069641/978.784119, val:  50.00%, val_best:  66.15%, tr:  94.77%, tr_best:  95.71%, epoch time: 174.46 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 63.3363%\n",
      "layer   3  Sparsity: 38.4764%\n",
      "total_backward_count 1088640 real_backward_count 211137  19.395%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 34.2500%\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 430 occurrences\n",
      "test - Value 1: 22 occurrences\n",
      "epoch-45  lr=['4.0000000'], tr/val_loss:987.684814/884.571167, val:  54.87%, val_best:  66.15%, tr:  95.01%, tr_best:  95.71%, epoch time: 174.05 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 63.2588%\n",
      "layer   3  Sparsity: 38.9982%\n",
      "total_backward_count 1112832 real_backward_count 215811  19.393%\n",
      "layer   1  Sparsity: 93.5872%\n",
      "layer   2  Sparsity: 71.5833%\n",
      "layer   3  Sparsity: 54.5833%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5981.00 at epoch 46, iter 4031\n",
      "max_activation_accul updated: 6139.00 at epoch 46, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['4.0000000'], tr/val_loss:983.981689/1016.761780, val:  50.00%, val_best:  66.15%, tr:  94.20%, tr_best:  95.71%, epoch time: 169.78 seconds, 2.83 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 63.3821%\n",
      "layer   3  Sparsity: 38.0480%\n",
      "total_backward_count 1137024 real_backward_count 220533  19.396%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 57.3333%\n",
      "layer   3  Sparsity: 33.0833%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-47  lr=['4.0000000'], tr/val_loss:990.821838/912.368896, val:  50.44%, val_best:  66.15%, tr:  95.39%, tr_best:  95.71%, epoch time: 174.01 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 63.4368%\n",
      "layer   3  Sparsity: 38.6001%\n",
      "total_backward_count 1161216 real_backward_count 225179  19.392%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 71.6667%\n",
      "layer   3  Sparsity: 44.0000%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-48  lr=['4.0000000'], tr/val_loss:981.721008/947.798950, val:  50.88%, val_best:  66.15%, tr:  94.94%, tr_best:  95.71%, epoch time: 174.62 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.4336%\n",
      "layer   3  Sparsity: 38.1237%\n",
      "total_backward_count 1185408 real_backward_count 229910  19.395%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 43.3333%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 127 occurrences\n",
      "test - Value 1: 325 occurrences\n",
      "epoch-49  lr=['4.0000000'], tr/val_loss:979.919189/886.312439, val:  62.61%, val_best:  66.15%, tr:  95.16%, tr_best:  95.71%, epoch time: 171.93 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.4458%\n",
      "layer   3  Sparsity: 38.0422%\n",
      "total_backward_count 1209600 real_backward_count 234590  19.394%\n",
      "layer   1  Sparsity: 81.9336%\n",
      "layer   2  Sparsity: 64.4167%\n",
      "layer   3  Sparsity: 42.1667%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['4.0000000'], tr/val_loss:992.827881/957.306885, val:  50.00%, val_best:  66.15%, tr:  95.14%, tr_best:  95.71%, epoch time: 173.71 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.3366%\n",
      "layer   3  Sparsity: 38.1085%\n",
      "total_backward_count 1233792 real_backward_count 239300  19.395%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 67.2500%\n",
      "layer   3  Sparsity: 45.0833%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['4.0000000'], tr/val_loss:984.149963/909.079712, val:  50.00%, val_best:  66.15%, tr:  94.82%, tr_best:  95.71%, epoch time: 174.40 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.3252%\n",
      "layer   3  Sparsity: 38.7503%\n",
      "total_backward_count 1257984 real_backward_count 243895  19.388%\n",
      "layer   1  Sparsity: 87.6953%\n",
      "layer   2  Sparsity: 71.0833%\n",
      "layer   3  Sparsity: 44.2500%\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-52  lr=['4.0000000'], tr/val_loss:983.826294/929.573730, val:  50.00%, val_best:  66.15%, tr:  95.31%, tr_best:  95.71%, epoch time: 174.85 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 63.3145%\n",
      "layer   3  Sparsity: 38.4763%\n",
      "total_backward_count 1282176 real_backward_count 248539  19.384%\n",
      "layer   1  Sparsity: 91.9922%\n",
      "layer   2  Sparsity: 64.2500%\n",
      "layer   3  Sparsity: 43.4167%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-53  lr=['4.0000000'], tr/val_loss:981.199219/921.664368, val:  53.32%, val_best:  66.15%, tr:  94.82%, tr_best:  95.71%, epoch time: 174.68 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 63.3841%\n",
      "layer   3  Sparsity: 37.8529%\n",
      "total_backward_count 1306368 real_backward_count 253081  19.373%\n",
      "layer   1  Sparsity: 86.3281%\n",
      "layer   2  Sparsity: 65.4167%\n",
      "layer   3  Sparsity: 44.2500%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 365 occurrences\n",
      "test - Value 1: 87 occurrences\n",
      "epoch-54  lr=['4.0000000'], tr/val_loss:980.926941/885.148315, val:  64.38%, val_best:  66.15%, tr:  95.49%, tr_best:  95.71%, epoch time: 174.96 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 63.4224%\n",
      "layer   3  Sparsity: 37.8180%\n",
      "total_backward_count 1330560 real_backward_count 257520  19.354%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 63.6667%\n",
      "layer   3  Sparsity: 36.5000%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-55  lr=['4.0000000'], tr/val_loss:982.419983/950.757019, val:  50.22%, val_best:  66.15%, tr:  94.12%, tr_best:  95.71%, epoch time: 174.42 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.3726%\n",
      "layer   3  Sparsity: 38.4567%\n",
      "total_backward_count 1354752 real_backward_count 262403  19.369%\n",
      "layer   1  Sparsity: 81.0872%\n",
      "layer   2  Sparsity: 55.9167%\n",
      "layer   3  Sparsity: 33.1667%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-56  lr=['4.0000000'], tr/val_loss:979.910645/892.504456, val:  51.33%, val_best:  66.15%, tr:  95.19%, tr_best:  95.71%, epoch time: 174.42 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.4249%\n",
      "layer   3  Sparsity: 38.5541%\n",
      "total_backward_count 1378944 real_backward_count 266926  19.357%\n",
      "layer   1  Sparsity: 89.7135%\n",
      "layer   2  Sparsity: 69.3333%\n",
      "layer   3  Sparsity: 46.1667%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-57  lr=['4.0000000'], tr/val_loss:983.343628/929.542236, val:  51.11%, val_best:  66.15%, tr:  95.39%, tr_best:  95.71%, epoch time: 173.89 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.3980%\n",
      "layer   3  Sparsity: 38.2314%\n",
      "total_backward_count 1403136 real_backward_count 271738  19.366%\n",
      "layer   1  Sparsity: 92.0898%\n",
      "layer   2  Sparsity: 70.5833%\n",
      "layer   3  Sparsity: 56.0000%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 315 occurrences\n",
      "test - Value 1: 137 occurrences\n",
      "epoch-58  lr=['4.0000000'], tr/val_loss:986.268860/878.485229, val:  67.48%, val_best:  67.48%, tr:  94.92%, tr_best:  95.71%, epoch time: 174.58 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 63.4124%\n",
      "layer   3  Sparsity: 38.3167%\n",
      "total_backward_count 1427328 real_backward_count 276341  19.361%\n",
      "layer   1  Sparsity: 78.4831%\n",
      "layer   2  Sparsity: 60.1667%\n",
      "layer   3  Sparsity: 32.0000%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 363 occurrences\n",
      "test - Value 1: 89 occurrences\n",
      "epoch-59  lr=['4.0000000'], tr/val_loss:981.840027/879.956238, val:  63.94%, val_best:  67.48%, tr:  95.34%, tr_best:  95.71%, epoch time: 172.61 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 63.4006%\n",
      "layer   3  Sparsity: 38.3394%\n",
      "total_backward_count 1451520 real_backward_count 280946  19.355%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 60.9167%\n",
      "layer   3  Sparsity: 35.1667%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-60  lr=['4.0000000'], tr/val_loss:977.213074/895.673157, val:  55.53%, val_best:  67.48%, tr:  95.19%, tr_best:  95.71%, epoch time: 174.73 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 63.7306%\n",
      "layer   3  Sparsity: 38.2907%\n",
      "total_backward_count 1475712 real_backward_count 285379  19.338%\n",
      "layer   1  Sparsity: 75.0000%\n",
      "layer   2  Sparsity: 54.2500%\n",
      "layer   3  Sparsity: 33.8333%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['4.0000000'], tr/val_loss:983.750488/986.419434, val:  50.00%, val_best:  67.48%, tr:  94.39%, tr_best:  95.71%, epoch time: 174.62 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 63.4015%\n",
      "layer   3  Sparsity: 38.2269%\n",
      "total_backward_count 1499904 real_backward_count 289880  19.327%\n",
      "layer   1  Sparsity: 78.5807%\n",
      "layer   2  Sparsity: 68.7500%\n",
      "layer   3  Sparsity: 42.0000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 374 occurrences\n",
      "test - Value 1: 78 occurrences\n",
      "epoch-62  lr=['4.0000000'], tr/val_loss:974.253845/877.383423, val:  62.83%, val_best:  67.48%, tr:  95.41%, tr_best:  95.71%, epoch time: 174.29 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.3998%\n",
      "layer   3  Sparsity: 38.5023%\n",
      "total_backward_count 1524096 real_backward_count 294340  19.312%\n",
      "layer   1  Sparsity: 80.9896%\n",
      "layer   2  Sparsity: 58.8333%\n",
      "layer   3  Sparsity: 33.6667%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-63  lr=['4.0000000'], tr/val_loss:973.093567/925.954285, val:  51.11%, val_best:  67.48%, tr:  95.49%, tr_best:  95.71%, epoch time: 172.86 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.2927%\n",
      "layer   3  Sparsity: 39.1564%\n",
      "total_backward_count 1548288 real_backward_count 299060  19.316%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 60.0000%\n",
      "layer   3  Sparsity: 33.9167%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-64  lr=['4.0000000'], tr/val_loss:970.831970/916.888306, val:  50.44%, val_best:  67.48%, tr:  95.49%, tr_best:  95.71%, epoch time: 173.07 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.4062%\n",
      "layer   3  Sparsity: 38.4386%\n",
      "total_backward_count 1572480 real_backward_count 303754  19.317%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 67.8333%\n",
      "layer   3  Sparsity: 43.0833%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-65  lr=['4.0000000'], tr/val_loss:980.060730/898.339966, val:  53.54%, val_best:  67.48%, tr:  94.99%, tr_best:  95.71%, epoch time: 174.81 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 63.3992%\n",
      "layer   3  Sparsity: 38.4279%\n",
      "total_backward_count 1596672 real_backward_count 308538  19.324%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 69.6667%\n",
      "layer   3  Sparsity: 44.8333%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-66  lr=['4.0000000'], tr/val_loss:973.610291/937.048767, val:  50.44%, val_best:  67.48%, tr:  94.82%, tr_best:  95.71%, epoch time: 175.55 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.2959%\n",
      "layer   3  Sparsity: 39.2635%\n",
      "total_backward_count 1620864 real_backward_count 313370  19.334%\n",
      "layer   1  Sparsity: 79.1341%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 46.9167%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 391 occurrences\n",
      "test - Value 1: 61 occurrences\n",
      "epoch-67  lr=['4.0000000'], tr/val_loss:976.921692/885.520081, val:  61.28%, val_best:  67.48%, tr:  94.99%, tr_best:  95.71%, epoch time: 174.56 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.3654%\n",
      "layer   3  Sparsity: 38.9162%\n",
      "total_backward_count 1645056 real_backward_count 317988  19.330%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 60.4167%\n",
      "layer   3  Sparsity: 34.8333%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['4.0000000'], tr/val_loss:983.335022/935.482788, val:  50.00%, val_best:  67.48%, tr:  95.06%, tr_best:  95.71%, epoch time: 172.60 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.2870%\n",
      "layer   3  Sparsity: 38.5494%\n",
      "total_backward_count 1669248 real_backward_count 322574  19.325%\n",
      "layer   1  Sparsity: 89.8112%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 56.5833%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-69  lr=['4.0000000'], tr/val_loss:981.936646/902.206543, val:  57.74%, val_best:  67.48%, tr:  95.56%, tr_best:  95.71%, epoch time: 174.63 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.4044%\n",
      "layer   3  Sparsity: 38.5834%\n",
      "total_backward_count 1693440 real_backward_count 327155  19.319%\n",
      "layer   1  Sparsity: 73.4701%\n",
      "layer   2  Sparsity: 68.1667%\n",
      "layer   3  Sparsity: 30.6667%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-70  lr=['4.0000000'], tr/val_loss:975.358582/897.723877, val:  50.66%, val_best:  67.48%, tr:  95.26%, tr_best:  95.71%, epoch time: 174.88 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 63.3907%\n",
      "layer   3  Sparsity: 38.3574%\n",
      "total_backward_count 1717632 real_backward_count 331682  19.310%\n",
      "layer   1  Sparsity: 73.0143%\n",
      "layer   2  Sparsity: 60.3333%\n",
      "layer   3  Sparsity: 30.1667%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-71  lr=['4.0000000'], tr/val_loss:983.297974/942.067139, val:  50.00%, val_best:  67.48%, tr:  95.24%, tr_best:  95.71%, epoch time: 170.19 seconds, 2.84 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 63.3634%\n",
      "layer   3  Sparsity: 38.3919%\n",
      "total_backward_count 1741824 real_backward_count 336325  19.309%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 66.0833%\n",
      "layer   3  Sparsity: 44.3333%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['4.0000000'], tr/val_loss:980.447510/905.383484, val:  50.00%, val_best:  67.48%, tr:  95.16%, tr_best:  95.71%, epoch time: 173.40 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 63.1225%\n",
      "layer   3  Sparsity: 38.5864%\n",
      "total_backward_count 1766016 real_backward_count 340812  19.298%\n",
      "layer   1  Sparsity: 81.8685%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 43.4167%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-73  lr=['4.0000000'], tr/val_loss:968.015015/930.572388, val:  50.66%, val_best:  67.48%, tr:  95.01%, tr_best:  95.71%, epoch time: 173.48 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.4292%\n",
      "layer   3  Sparsity: 39.1093%\n",
      "total_backward_count 1790208 real_backward_count 345336  19.290%\n",
      "layer   1  Sparsity: 87.5000%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 45.0833%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-74  lr=['4.0000000'], tr/val_loss:968.062500/928.816650, val:  50.00%, val_best:  67.48%, tr:  95.26%, tr_best:  95.71%, epoch time: 175.09 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 63.3916%\n",
      "layer   3  Sparsity: 38.9159%\n",
      "total_backward_count 1814400 real_backward_count 349898  19.285%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 63.6667%\n",
      "layer   3  Sparsity: 42.9167%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 392 occurrences\n",
      "test - Value 1: 60 occurrences\n",
      "epoch-75  lr=['4.0000000'], tr/val_loss:981.287231/895.019958, val:  60.18%, val_best:  67.48%, tr:  95.09%, tr_best:  95.71%, epoch time: 174.23 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.3339%\n",
      "layer   3  Sparsity: 38.9956%\n",
      "total_backward_count 1838592 real_backward_count 354606  19.287%\n",
      "layer   1  Sparsity: 87.1419%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 45.2500%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 354 occurrences\n",
      "test - Value 1: 98 occurrences\n",
      "epoch-76  lr=['4.0000000'], tr/val_loss:976.385925/870.222229, val:  63.27%, val_best:  67.48%, tr:  94.69%, tr_best:  95.71%, epoch time: 173.75 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 63.3330%\n",
      "layer   3  Sparsity: 38.9845%\n",
      "total_backward_count 1862784 real_backward_count 359264  19.286%\n",
      "layer   1  Sparsity: 77.6367%\n",
      "layer   2  Sparsity: 66.4167%\n",
      "layer   3  Sparsity: 32.6667%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-77  lr=['4.0000000'], tr/val_loss:976.114258/917.789551, val:  51.55%, val_best:  67.48%, tr:  94.59%, tr_best:  95.71%, epoch time: 172.66 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 63.4212%\n",
      "layer   3  Sparsity: 38.8503%\n",
      "total_backward_count 1886976 real_backward_count 363948  19.287%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 67.4167%\n",
      "layer   3  Sparsity: 42.4167%\n",
      "fc layer 3 self.abs_max_out: 1305.0\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['4.0000000'], tr/val_loss:979.242676/988.801880, val:  50.00%, val_best:  67.48%, tr:  94.72%, tr_best:  95.71%, epoch time: 173.65 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 63.3790%\n",
      "layer   3  Sparsity: 38.9202%\n",
      "total_backward_count 1911168 real_backward_count 368697  19.292%\n",
      "layer   1  Sparsity: 86.5560%\n",
      "layer   2  Sparsity: 54.1667%\n",
      "layer   3  Sparsity: 30.5833%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-79  lr=['4.0000000'], tr/val_loss:972.389465/884.443848, val:  56.42%, val_best:  67.48%, tr:  94.57%, tr_best:  95.71%, epoch time: 175.32 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 63.2539%\n",
      "layer   3  Sparsity: 39.0157%\n",
      "total_backward_count 1935360 real_backward_count 373380  19.293%\n",
      "layer   1  Sparsity: 84.8307%\n",
      "layer   2  Sparsity: 55.6667%\n",
      "layer   3  Sparsity: 32.2500%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-80  lr=['4.0000000'], tr/val_loss:975.049194/935.774536, val:  50.88%, val_best:  67.48%, tr:  94.74%, tr_best:  95.71%, epoch time: 174.64 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.3898%\n",
      "layer   3  Sparsity: 39.2438%\n",
      "total_backward_count 1959552 real_backward_count 378125  19.297%\n",
      "layer   1  Sparsity: 89.2253%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 45.6667%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['4.0000000'], tr/val_loss:976.910400/959.670288, val:  50.00%, val_best:  67.48%, tr:  94.67%, tr_best:  95.71%, epoch time: 175.51 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 63.3297%\n",
      "layer   3  Sparsity: 38.9246%\n",
      "total_backward_count 1983744 real_backward_count 382838  19.299%\n",
      "layer   1  Sparsity: 80.7943%\n",
      "layer   2  Sparsity: 55.6667%\n",
      "layer   3  Sparsity: 36.6667%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-82  lr=['4.0000000'], tr/val_loss:982.251282/917.424500, val:  50.00%, val_best:  67.48%, tr:  94.89%, tr_best:  95.71%, epoch time: 175.05 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 63.3738%\n",
      "layer   3  Sparsity: 39.0336%\n",
      "total_backward_count 2007936 real_backward_count 387692  19.308%\n",
      "layer   1  Sparsity: 77.1159%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 31.9167%\n",
      "train - Value 0: 1975 occurrences\n",
      "train - Value 1: 2057 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['4.0000000'], tr/val_loss:978.782593/966.438293, val:  50.00%, val_best:  67.48%, tr:  94.62%, tr_best:  95.71%, epoch time: 174.58 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 63.2727%\n",
      "layer   3  Sparsity: 38.9883%\n",
      "total_backward_count 2032128 real_backward_count 392306  19.305%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 60.0833%\n",
      "layer   3  Sparsity: 33.0000%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 26 occurrences\n",
      "test - Value 1: 426 occurrences\n",
      "epoch-84  lr=['4.0000000'], tr/val_loss:969.426331/870.651367, val:  53.54%, val_best:  67.48%, tr:  94.92%, tr_best:  95.71%, epoch time: 174.86 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 62.9054%\n",
      "layer   3  Sparsity: 38.5830%\n",
      "total_backward_count 2056320 real_backward_count 396918  19.302%\n",
      "layer   1  Sparsity: 73.8281%\n",
      "layer   2  Sparsity: 66.4167%\n",
      "layer   3  Sparsity: 32.1667%\n",
      "train - Value 0: 1969 occurrences\n",
      "train - Value 1: 2063 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-85  lr=['4.0000000'], tr/val_loss:969.949158/909.317566, val:  50.00%, val_best:  67.48%, tr:  94.17%, tr_best:  95.71%, epoch time: 173.79 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 62.4850%\n",
      "layer   3  Sparsity: 38.8567%\n",
      "total_backward_count 2080512 real_backward_count 401635  19.305%\n",
      "layer   1  Sparsity: 73.6328%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 31.4167%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['4.0000000'], tr/val_loss:977.511536/936.972412, val:  50.00%, val_best:  67.48%, tr:  94.99%, tr_best:  95.71%, epoch time: 173.54 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 63.1359%\n",
      "layer   3  Sparsity: 39.1628%\n",
      "total_backward_count 2104704 real_backward_count 406374  19.308%\n",
      "layer   1  Sparsity: 81.3477%\n",
      "layer   2  Sparsity: 55.8333%\n",
      "layer   3  Sparsity: 35.4167%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-87  lr=['4.0000000'], tr/val_loss:977.006042/909.404053, val:  50.00%, val_best:  67.48%, tr:  95.19%, tr_best:  95.71%, epoch time: 173.23 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 63.3688%\n",
      "layer   3  Sparsity: 39.3644%\n",
      "total_backward_count 2128896 real_backward_count 411165  19.314%\n",
      "layer   1  Sparsity: 79.4596%\n",
      "layer   2  Sparsity: 58.9167%\n",
      "layer   3  Sparsity: 33.6667%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['4.0000000'], tr/val_loss:973.411865/905.936157, val:  50.00%, val_best:  67.48%, tr:  95.78%, tr_best:  95.78%, epoch time: 175.67 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.3900%\n",
      "layer   3  Sparsity: 39.3774%\n",
      "total_backward_count 2153088 real_backward_count 415580  19.302%\n",
      "layer   1  Sparsity: 91.8945%\n",
      "layer   2  Sparsity: 72.8333%\n",
      "layer   3  Sparsity: 54.0000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-89  lr=['4.0000000'], tr/val_loss:969.627686/873.612732, val:  59.29%, val_best:  67.48%, tr:  95.31%, tr_best:  95.78%, epoch time: 175.01 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 63.3976%\n",
      "layer   3  Sparsity: 39.3371%\n",
      "total_backward_count 2177280 real_backward_count 420190  19.299%\n",
      "layer   1  Sparsity: 84.6029%\n",
      "layer   2  Sparsity: 69.4167%\n",
      "layer   3  Sparsity: 46.2500%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-90  lr=['4.0000000'], tr/val_loss:962.998108/904.370117, val:  50.00%, val_best:  67.48%, tr:  95.04%, tr_best:  95.78%, epoch time: 173.53 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.3933%\n",
      "layer   3  Sparsity: 38.7045%\n",
      "total_backward_count 2201472 real_backward_count 424706  19.292%\n",
      "layer   1  Sparsity: 82.7474%\n",
      "layer   2  Sparsity: 70.4167%\n",
      "layer   3  Sparsity: 45.3333%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-91  lr=['4.0000000'], tr/val_loss:972.687073/891.150085, val:  50.66%, val_best:  67.48%, tr:  96.06%, tr_best:  96.06%, epoch time: 174.00 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.3900%\n",
      "layer   3  Sparsity: 38.8119%\n",
      "total_backward_count 2225664 real_backward_count 429161  19.282%\n",
      "layer   1  Sparsity: 81.3151%\n",
      "layer   2  Sparsity: 71.0833%\n",
      "layer   3  Sparsity: 44.3333%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['4.0000000'], tr/val_loss:973.842468/1029.781006, val:  50.00%, val_best:  67.48%, tr:  94.79%, tr_best:  96.06%, epoch time: 173.82 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 63.3913%\n",
      "layer   3  Sparsity: 39.2029%\n",
      "total_backward_count 2249856 real_backward_count 433791  19.281%\n",
      "layer   1  Sparsity: 80.9570%\n",
      "layer   2  Sparsity: 55.8333%\n",
      "layer   3  Sparsity: 30.5833%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['4.0000000'], tr/val_loss:977.621338/984.421387, val:  50.00%, val_best:  67.48%, tr:  94.87%, tr_best:  96.06%, epoch time: 174.28 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.4307%\n",
      "layer   3  Sparsity: 39.3457%\n",
      "total_backward_count 2274048 real_backward_count 438543  19.285%\n",
      "layer   1  Sparsity: 77.0182%\n",
      "layer   2  Sparsity: 60.4167%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-94  lr=['4.0000000'], tr/val_loss:969.606018/955.601135, val:  50.44%, val_best:  67.48%, tr:  95.04%, tr_best:  96.06%, epoch time: 175.39 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 63.3548%\n",
      "layer   3  Sparsity: 39.3327%\n",
      "total_backward_count 2298240 real_backward_count 443144  19.282%\n",
      "layer   1  Sparsity: 68.0013%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 31.0000%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['4.0000000'], tr/val_loss:980.200439/931.442566, val:  50.00%, val_best:  67.48%, tr:  94.87%, tr_best:  96.06%, epoch time: 171.65 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4686%\n",
      "layer   2  Sparsity: 63.4211%\n",
      "layer   3  Sparsity: 39.4857%\n",
      "total_backward_count 2322432 real_backward_count 447693  19.277%\n",
      "layer   1  Sparsity: 90.1693%\n",
      "layer   2  Sparsity: 68.9167%\n",
      "layer   3  Sparsity: 56.0000%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-96  lr=['4.0000000'], tr/val_loss:980.983765/882.247864, val:  52.43%, val_best:  67.48%, tr:  94.10%, tr_best:  96.06%, epoch time: 174.04 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.3477%\n",
      "layer   3  Sparsity: 39.0873%\n",
      "total_backward_count 2346624 real_backward_count 452440  19.280%\n",
      "layer   1  Sparsity: 72.0378%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 30.2500%\n",
      "train - Value 0: 1970 occurrences\n",
      "train - Value 1: 2062 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-97  lr=['4.0000000'], tr/val_loss:980.419983/934.649719, val:  50.88%, val_best:  67.48%, tr:  94.74%, tr_best:  96.06%, epoch time: 174.76 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 63.3923%\n",
      "layer   3  Sparsity: 39.5125%\n",
      "total_backward_count 2370816 real_backward_count 457338  19.290%\n",
      "layer   1  Sparsity: 78.7435%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 33.9167%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 250 occurrences\n",
      "test - Value 1: 202 occurrences\n",
      "epoch-98  lr=['4.0000000'], tr/val_loss:977.162964/879.646240, val:  69.47%, val_best:  69.47%, tr:  94.89%, tr_best:  96.06%, epoch time: 173.47 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.4641%\n",
      "layer   3  Sparsity: 39.2765%\n",
      "total_backward_count 2395008 real_backward_count 462148  19.296%\n",
      "layer   1  Sparsity: 79.8503%\n",
      "layer   2  Sparsity: 59.6667%\n",
      "layer   3  Sparsity: 33.4167%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['4.0000000'], tr/val_loss:981.776306/964.509766, val:  50.00%, val_best:  69.47%, tr:  94.74%, tr_best:  96.06%, epoch time: 174.06 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 63.4337%\n",
      "layer   3  Sparsity: 39.6914%\n",
      "total_backward_count 2419200 real_backward_count 466920  19.301%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 67.8333%\n",
      "layer   3  Sparsity: 44.5833%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-100 lr=['4.0000000'], tr/val_loss:981.631165/941.888367, val:  50.66%, val_best:  69.47%, tr:  95.46%, tr_best:  96.06%, epoch time: 172.90 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 63.3807%\n",
      "layer   3  Sparsity: 39.9955%\n",
      "total_backward_count 2443392 real_backward_count 471599  19.301%\n",
      "layer   1  Sparsity: 68.5221%\n",
      "layer   2  Sparsity: 59.8333%\n",
      "layer   3  Sparsity: 34.8333%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 429 occurrences\n",
      "test - Value 1: 23 occurrences\n",
      "epoch-101 lr=['4.0000000'], tr/val_loss:979.557068/900.641296, val:  55.09%, val_best:  69.47%, tr:  96.01%, tr_best:  96.06%, epoch time: 174.93 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4685%\n",
      "layer   2  Sparsity: 63.3813%\n",
      "layer   3  Sparsity: 40.0572%\n",
      "total_backward_count 2467584 real_backward_count 476425  19.307%\n",
      "layer   1  Sparsity: 85.3516%\n",
      "layer   2  Sparsity: 66.5833%\n",
      "layer   3  Sparsity: 44.5833%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-102 lr=['4.0000000'], tr/val_loss:977.874756/948.279602, val:  50.88%, val_best:  69.47%, tr:  95.41%, tr_best:  96.06%, epoch time: 174.06 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.3920%\n",
      "layer   3  Sparsity: 39.7465%\n",
      "total_backward_count 2491776 real_backward_count 481022  19.304%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 67.1667%\n",
      "layer   3  Sparsity: 33.5833%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-103 lr=['4.0000000'], tr/val_loss:974.832581/982.736816, val:  50.00%, val_best:  69.47%, tr:  95.68%, tr_best:  96.06%, epoch time: 172.68 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 63.3919%\n",
      "layer   3  Sparsity: 40.1209%\n",
      "total_backward_count 2515968 real_backward_count 485522  19.298%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 43.9167%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['4.0000000'], tr/val_loss:975.597473/924.214172, val:  50.00%, val_best:  69.47%, tr:  95.83%, tr_best:  96.06%, epoch time: 174.09 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.3364%\n",
      "layer   3  Sparsity: 40.3681%\n",
      "total_backward_count 2540160 real_backward_count 490157  19.296%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 32.5000%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-105 lr=['4.0000000'], tr/val_loss:981.028137/964.279541, val:  50.00%, val_best:  69.47%, tr:  95.06%, tr_best:  96.06%, epoch time: 174.47 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 63.3357%\n",
      "layer   3  Sparsity: 40.3854%\n",
      "total_backward_count 2564352 real_backward_count 495004  19.303%\n",
      "layer   1  Sparsity: 84.8958%\n",
      "layer   2  Sparsity: 64.6667%\n",
      "layer   3  Sparsity: 44.5833%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['4.0000000'], tr/val_loss:978.092590/937.406372, val:  50.00%, val_best:  69.47%, tr:  95.54%, tr_best:  96.06%, epoch time: 173.82 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 63.2955%\n",
      "layer   3  Sparsity: 40.3979%\n",
      "total_backward_count 2588544 real_backward_count 499749  19.306%\n",
      "layer   1  Sparsity: 90.8203%\n",
      "layer   2  Sparsity: 76.5833%\n",
      "layer   3  Sparsity: 56.7500%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 214 occurrences\n",
      "test - Value 1: 238 occurrences\n",
      "epoch-107 lr=['4.0000000'], tr/val_loss:978.320129/860.395813, val:  69.47%, val_best:  69.47%, tr:  95.19%, tr_best:  96.06%, epoch time: 174.39 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4635%\n",
      "layer   2  Sparsity: 63.4411%\n",
      "layer   3  Sparsity: 39.7493%\n",
      "total_backward_count 2612736 real_backward_count 504392  19.305%\n",
      "layer   1  Sparsity: 86.2305%\n",
      "layer   2  Sparsity: 65.4167%\n",
      "layer   3  Sparsity: 43.1667%\n",
      "fc layer 2 self.abs_max_out: 5742.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-108 lr=['4.0000000'], tr/val_loss:979.209534/939.839233, val:  50.66%, val_best:  69.47%, tr:  95.26%, tr_best:  96.06%, epoch time: 175.02 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 63.4681%\n",
      "layer   3  Sparsity: 39.6944%\n",
      "total_backward_count 2636928 real_backward_count 509165  19.309%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 61.3333%\n",
      "layer   3  Sparsity: 45.8333%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-109 lr=['4.0000000'], tr/val_loss:987.397949/940.545288, val:  50.00%, val_best:  69.47%, tr:  94.74%, tr_best:  96.06%, epoch time: 174.92 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.3973%\n",
      "layer   3  Sparsity: 39.5122%\n",
      "total_backward_count 2661120 real_backward_count 513936  19.313%\n",
      "layer   1  Sparsity: 88.2161%\n",
      "layer   2  Sparsity: 71.1667%\n",
      "layer   3  Sparsity: 46.0833%\n",
      "fc layer 2 self.abs_max_out: 5819.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-110 lr=['4.0000000'], tr/val_loss:987.333130/981.789368, val:  50.00%, val_best:  69.47%, tr:  94.69%, tr_best:  96.06%, epoch time: 173.47 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 63.4324%\n",
      "layer   3  Sparsity: 39.7160%\n",
      "total_backward_count 2685312 real_backward_count 518627  19.313%\n",
      "layer   1  Sparsity: 80.5013%\n",
      "layer   2  Sparsity: 59.9167%\n",
      "layer   3  Sparsity: 31.9167%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-111 lr=['4.0000000'], tr/val_loss:984.883728/955.415894, val:  50.88%, val_best:  69.47%, tr:  95.16%, tr_best:  96.06%, epoch time: 174.74 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 63.3610%\n",
      "layer   3  Sparsity: 39.5307%\n",
      "total_backward_count 2709504 real_backward_count 523288  19.313%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 33.4167%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 62 occurrences\n",
      "test - Value 1: 390 occurrences\n",
      "epoch-112 lr=['4.0000000'], tr/val_loss:982.916626/882.388123, val:  59.29%, val_best:  69.47%, tr:  95.71%, tr_best:  96.06%, epoch time: 173.98 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 63.3830%\n",
      "layer   3  Sparsity: 39.7519%\n",
      "total_backward_count 2733696 real_backward_count 528024  19.315%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 64.0833%\n",
      "layer   3  Sparsity: 45.6667%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-113 lr=['4.0000000'], tr/val_loss:980.364929/974.919434, val:  50.00%, val_best:  69.47%, tr:  95.31%, tr_best:  96.06%, epoch time: 172.85 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.3294%\n",
      "layer   3  Sparsity: 40.1779%\n",
      "total_backward_count 2757888 real_backward_count 532854  19.321%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 35.5000%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-114 lr=['4.0000000'], tr/val_loss:978.858337/935.453918, val:  50.44%, val_best:  69.47%, tr:  95.46%, tr_best:  96.06%, epoch time: 174.59 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 63.3785%\n",
      "layer   3  Sparsity: 40.3443%\n",
      "total_backward_count 2782080 real_backward_count 537573  19.323%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 69.3333%\n",
      "layer   3  Sparsity: 47.5833%\n",
      "fc layer 2 self.abs_max_out: 5825.0\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-115 lr=['4.0000000'], tr/val_loss:978.228027/930.947510, val:  50.66%, val_best:  69.47%, tr:  95.11%, tr_best:  96.06%, epoch time: 174.78 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4664%\n",
      "layer   2  Sparsity: 63.4357%\n",
      "layer   3  Sparsity: 40.3056%\n",
      "total_backward_count 2806272 real_backward_count 542466  19.330%\n",
      "layer   1  Sparsity: 86.7513%\n",
      "layer   2  Sparsity: 70.0833%\n",
      "layer   3  Sparsity: 54.9167%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 395 occurrences\n",
      "test - Value 1: 57 occurrences\n",
      "epoch-116 lr=['4.0000000'], tr/val_loss:983.322327/883.293457, val:  61.28%, val_best:  69.47%, tr:  95.01%, tr_best:  96.06%, epoch time: 173.13 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 63.4340%\n",
      "layer   3  Sparsity: 40.1314%\n",
      "total_backward_count 2830464 real_backward_count 547284  19.335%\n",
      "layer   1  Sparsity: 70.9635%\n",
      "layer   2  Sparsity: 59.0833%\n",
      "layer   3  Sparsity: 33.8333%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-117 lr=['4.0000000'], tr/val_loss:974.325195/925.484131, val:  50.00%, val_best:  69.47%, tr:  94.77%, tr_best:  96.06%, epoch time: 172.99 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 63.4440%\n",
      "layer   3  Sparsity: 40.1739%\n",
      "total_backward_count 2854656 real_backward_count 552002  19.337%\n",
      "layer   1  Sparsity: 87.2721%\n",
      "layer   2  Sparsity: 67.3333%\n",
      "layer   3  Sparsity: 44.6667%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['4.0000000'], tr/val_loss:977.159973/918.844177, val:  50.00%, val_best:  69.47%, tr:  95.34%, tr_best:  96.06%, epoch time: 173.63 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 63.3512%\n",
      "layer   3  Sparsity: 39.9116%\n",
      "total_backward_count 2878848 real_backward_count 556765  19.340%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 66.9167%\n",
      "layer   3  Sparsity: 45.9167%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 316 occurrences\n",
      "test - Value 1: 136 occurrences\n",
      "epoch-119 lr=['4.0000000'], tr/val_loss:975.653748/873.475342, val:  65.49%, val_best:  69.47%, tr:  95.06%, tr_best:  96.06%, epoch time: 173.12 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 63.3865%\n",
      "layer   3  Sparsity: 40.0203%\n",
      "total_backward_count 2903040 real_backward_count 561307  19.335%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 71.4167%\n",
      "layer   3  Sparsity: 45.6667%\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-120 lr=['4.0000000'], tr/val_loss:976.073975/898.122009, val:  50.00%, val_best:  69.47%, tr:  95.09%, tr_best:  96.06%, epoch time: 170.09 seconds, 2.83 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 63.3965%\n",
      "layer   3  Sparsity: 40.1966%\n",
      "total_backward_count 2927232 real_backward_count 566131  19.340%\n",
      "layer   1  Sparsity: 81.5104%\n",
      "layer   2  Sparsity: 59.2500%\n",
      "layer   3  Sparsity: 35.6667%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['4.0000000'], tr/val_loss:970.215576/952.097412, val:  50.00%, val_best:  69.47%, tr:  95.34%, tr_best:  96.06%, epoch time: 173.57 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 63.3661%\n",
      "layer   3  Sparsity: 40.5673%\n",
      "total_backward_count 2951424 real_backward_count 570958  19.345%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 67.5833%\n",
      "layer   3  Sparsity: 45.2500%\n",
      "fc layer 3 self.abs_max_out: 1347.0\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['4.0000000'], tr/val_loss:975.470581/973.821838, val:  50.00%, val_best:  69.47%, tr:  94.72%, tr_best:  96.06%, epoch time: 174.87 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 63.4150%\n",
      "layer   3  Sparsity: 39.8623%\n",
      "total_backward_count 2975616 real_backward_count 575831  19.352%\n",
      "layer   1  Sparsity: 88.1510%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 45.3333%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-123 lr=['4.0000000'], tr/val_loss:973.661316/884.685852, val:  51.99%, val_best:  69.47%, tr:  94.99%, tr_best:  96.06%, epoch time: 174.36 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 63.4558%\n",
      "layer   3  Sparsity: 39.8829%\n",
      "total_backward_count 2999808 real_backward_count 580551  19.353%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 60.3333%\n",
      "layer   3  Sparsity: 44.6667%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-124 lr=['4.0000000'], tr/val_loss:974.127136/918.921265, val:  51.55%, val_best:  69.47%, tr:  94.99%, tr_best:  96.06%, epoch time: 174.96 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 63.4297%\n",
      "layer   3  Sparsity: 40.0602%\n",
      "total_backward_count 3024000 real_backward_count 585273  19.354%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 46.0833%\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 335 occurrences\n",
      "test - Value 1: 117 occurrences\n",
      "epoch-125 lr=['4.0000000'], tr/val_loss:973.807434/868.374939, val:  66.15%, val_best:  69.47%, tr:  95.04%, tr_best:  96.06%, epoch time: 174.19 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.3868%\n",
      "layer   3  Sparsity: 40.2478%\n",
      "total_backward_count 3048192 real_backward_count 590035  19.357%\n",
      "layer   1  Sparsity: 72.4284%\n",
      "layer   2  Sparsity: 60.8333%\n",
      "layer   3  Sparsity: 32.6667%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-126 lr=['4.0000000'], tr/val_loss:978.043701/935.679016, val:  50.00%, val_best:  69.47%, tr:  95.24%, tr_best:  96.06%, epoch time: 173.76 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4676%\n",
      "layer   2  Sparsity: 63.3933%\n",
      "layer   3  Sparsity: 40.2634%\n",
      "total_backward_count 3072384 real_backward_count 594691  19.356%\n",
      "layer   1  Sparsity: 75.6185%\n",
      "layer   2  Sparsity: 56.5000%\n",
      "layer   3  Sparsity: 32.2500%\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['4.0000000'], tr/val_loss:971.836914/955.314941, val:  50.00%, val_best:  69.47%, tr:  94.44%, tr_best:  96.06%, epoch time: 172.79 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.2950%\n",
      "layer   3  Sparsity: 39.7862%\n",
      "total_backward_count 3096576 real_backward_count 599418  19.357%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 63.3333%\n",
      "layer   3  Sparsity: 45.2500%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['4.0000000'], tr/val_loss:933.030640/892.085815, val:  50.00%, val_best:  69.47%, tr:  95.06%, tr_best:  96.06%, epoch time: 175.65 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.3277%\n",
      "layer   3  Sparsity: 40.0161%\n",
      "total_backward_count 3120768 real_backward_count 604011  19.355%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 71.1667%\n",
      "layer   3  Sparsity: 46.1667%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['4.0000000'], tr/val_loss:922.524841/940.814758, val:  50.00%, val_best:  69.47%, tr:  94.74%, tr_best:  96.06%, epoch time: 175.61 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.4019%\n",
      "layer   3  Sparsity: 40.0196%\n",
      "total_backward_count 3144960 real_backward_count 608578  19.351%\n",
      "layer   1  Sparsity: 89.6159%\n",
      "layer   2  Sparsity: 67.9167%\n",
      "layer   3  Sparsity: 44.6667%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 437 occurrences\n",
      "test - Value 1: 15 occurrences\n",
      "epoch-130 lr=['4.0000000'], tr/val_loss:934.842834/836.434814, val:  52.88%, val_best:  69.47%, tr:  94.47%, tr_best:  96.06%, epoch time: 173.92 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.4512%\n",
      "layer   3  Sparsity: 40.0944%\n",
      "total_backward_count 3169152 real_backward_count 613261  19.351%\n",
      "layer   1  Sparsity: 88.8997%\n",
      "layer   2  Sparsity: 71.5833%\n",
      "layer   3  Sparsity: 56.3333%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-131 lr=['4.0000000'], tr/val_loss:920.436157/908.649536, val:  50.00%, val_best:  69.47%, tr:  94.79%, tr_best:  96.06%, epoch time: 174.59 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 63.4958%\n",
      "layer   3  Sparsity: 39.8338%\n",
      "total_backward_count 3193344 real_backward_count 617885  19.349%\n",
      "layer   1  Sparsity: 77.5065%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 34.9167%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-132 lr=['4.0000000'], tr/val_loss:950.523987/943.970337, val:  50.00%, val_best:  69.47%, tr:  94.89%, tr_best:  96.06%, epoch time: 174.79 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 63.4016%\n",
      "layer   3  Sparsity: 39.9096%\n",
      "total_backward_count 3217536 real_backward_count 622504  19.347%\n",
      "layer   1  Sparsity: 87.4349%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 46.5000%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-133 lr=['4.0000000'], tr/val_loss:941.334412/894.103516, val:  50.00%, val_best:  69.47%, tr:  94.59%, tr_best:  96.06%, epoch time: 174.46 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 63.5608%\n",
      "layer   3  Sparsity: 40.0414%\n",
      "total_backward_count 3241728 real_backward_count 627267  19.350%\n",
      "layer   1  Sparsity: 75.8464%\n",
      "layer   2  Sparsity: 57.8333%\n",
      "layer   3  Sparsity: 35.3333%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['4.0000000'], tr/val_loss:954.860168/936.853516, val:  50.00%, val_best:  69.47%, tr:  95.31%, tr_best:  96.06%, epoch time: 174.11 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.5201%\n",
      "layer   3  Sparsity: 40.3091%\n",
      "total_backward_count 3265920 real_backward_count 631928  19.349%\n",
      "layer   1  Sparsity: 81.8359%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 44.1667%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-135 lr=['4.0000000'], tr/val_loss:953.503662/855.231995, val:  56.19%, val_best:  69.47%, tr:  94.57%, tr_best:  96.06%, epoch time: 174.27 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.5390%\n",
      "layer   3  Sparsity: 40.0321%\n",
      "total_backward_count 3290112 real_backward_count 636532  19.347%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 46.0833%\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 173 occurrences\n",
      "test - Value 1: 279 occurrences\n",
      "epoch-136 lr=['4.0000000'], tr/val_loss:948.418091/846.294739, val:  69.25%, val_best:  69.47%, tr:  95.19%, tr_best:  96.06%, epoch time: 173.88 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.5044%\n",
      "layer   3  Sparsity: 39.7375%\n",
      "total_backward_count 3314304 real_backward_count 641225  19.347%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 57.2500%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 389 occurrences\n",
      "test - Value 1: 63 occurrences\n",
      "epoch-137 lr=['4.0000000'], tr/val_loss:949.544434/854.069458, val:  59.96%, val_best:  69.47%, tr:  95.24%, tr_best:  96.06%, epoch time: 174.53 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.5548%\n",
      "layer   3  Sparsity: 39.8631%\n",
      "total_backward_count 3338496 real_backward_count 645970  19.349%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 61.3333%\n",
      "layer   3  Sparsity: 36.9167%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-138 lr=['4.0000000'], tr/val_loss:955.071228/916.810791, val:  50.44%, val_best:  69.47%, tr:  95.66%, tr_best:  96.06%, epoch time: 173.33 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.5126%\n",
      "layer   3  Sparsity: 40.1711%\n",
      "total_backward_count 3362688 real_backward_count 650718  19.351%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 68.0833%\n",
      "layer   3  Sparsity: 45.6667%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 34 occurrences\n",
      "test - Value 1: 418 occurrences\n",
      "epoch-139 lr=['4.0000000'], tr/val_loss:959.196411/860.476868, val:  54.87%, val_best:  69.47%, tr:  94.72%, tr_best:  96.06%, epoch time: 172.76 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.4918%\n",
      "layer   3  Sparsity: 40.2790%\n",
      "total_backward_count 3386880 real_backward_count 655556  19.356%\n",
      "layer   1  Sparsity: 94.2057%\n",
      "layer   2  Sparsity: 74.0833%\n",
      "layer   3  Sparsity: 58.4167%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-140 lr=['4.0000000'], tr/val_loss:955.194519/869.091370, val:  57.30%, val_best:  69.47%, tr:  95.14%, tr_best:  96.06%, epoch time: 173.55 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 63.5594%\n",
      "layer   3  Sparsity: 40.3776%\n",
      "total_backward_count 3411072 real_backward_count 660319  19.358%\n",
      "layer   1  Sparsity: 79.6875%\n",
      "layer   2  Sparsity: 63.5833%\n",
      "layer   3  Sparsity: 36.2500%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-141 lr=['4.0000000'], tr/val_loss:943.406067/909.173706, val:  50.00%, val_best:  69.47%, tr:  94.54%, tr_best:  96.06%, epoch time: 174.24 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 63.3214%\n",
      "layer   3  Sparsity: 39.6520%\n",
      "total_backward_count 3435264 real_backward_count 665011  19.358%\n",
      "layer   1  Sparsity: 71.0938%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 33.3333%\n",
      "train - Value 0: 2054 occurrences\n",
      "train - Value 1: 1978 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-142 lr=['4.0000000'], tr/val_loss:957.101257/952.988770, val:  50.00%, val_best:  69.47%, tr:  95.19%, tr_best:  96.06%, epoch time: 174.90 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 63.4538%\n",
      "layer   3  Sparsity: 40.0225%\n",
      "total_backward_count 3459456 real_backward_count 669724  19.359%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 67.4167%\n",
      "layer   3  Sparsity: 46.3333%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 293 occurrences\n",
      "test - Value 1: 159 occurrences\n",
      "epoch-143 lr=['4.0000000'], tr/val_loss:956.465576/846.003662, val:  67.92%, val_best:  69.47%, tr:  94.94%, tr_best:  96.06%, epoch time: 174.76 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.6146%\n",
      "layer   3  Sparsity: 40.3034%\n",
      "total_backward_count 3483648 real_backward_count 674316  19.357%\n",
      "layer   1  Sparsity: 93.3594%\n",
      "layer   2  Sparsity: 82.4167%\n",
      "layer   3  Sparsity: 67.3333%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-144 lr=['4.0000000'], tr/val_loss:950.024414/922.011780, val:  50.00%, val_best:  69.47%, tr:  94.77%, tr_best:  96.06%, epoch time: 173.89 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4630%\n",
      "layer   2  Sparsity: 63.6243%\n",
      "layer   3  Sparsity: 40.0425%\n",
      "total_backward_count 3507840 real_backward_count 679110  19.360%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 61.6667%\n",
      "layer   3  Sparsity: 33.5833%\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-145 lr=['4.0000000'], tr/val_loss:950.617065/914.883057, val:  50.22%, val_best:  69.47%, tr:  95.21%, tr_best:  96.06%, epoch time: 169.84 seconds, 2.83 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 63.5174%\n",
      "layer   3  Sparsity: 39.7595%\n",
      "total_backward_count 3532032 real_backward_count 683899  19.363%\n",
      "layer   1  Sparsity: 75.9766%\n",
      "layer   2  Sparsity: 64.7500%\n",
      "layer   3  Sparsity: 42.1667%\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-146 lr=['4.0000000'], tr/val_loss:954.598633/917.449646, val:  50.22%, val_best:  69.47%, tr:  94.67%, tr_best:  96.06%, epoch time: 174.32 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 63.4509%\n",
      "layer   3  Sparsity: 39.9109%\n",
      "total_backward_count 3556224 real_backward_count 688814  19.369%\n",
      "layer   1  Sparsity: 81.7057%\n",
      "layer   2  Sparsity: 54.4167%\n",
      "layer   3  Sparsity: 32.5000%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['4.0000000'], tr/val_loss:946.279114/945.851990, val:  50.00%, val_best:  69.47%, tr:  94.89%, tr_best:  96.06%, epoch time: 173.51 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.5733%\n",
      "layer   3  Sparsity: 40.0853%\n",
      "total_backward_count 3580416 real_backward_count 693631  19.373%\n",
      "layer   1  Sparsity: 85.2539%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 46.4167%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "lif layer 1 self.abs_max_v: 50440.0\n",
      "lif layer 1 self.abs_max_v: 51584.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['4.0000000'], tr/val_loss:957.973206/961.195618, val:  50.00%, val_best:  69.47%, tr:  95.19%, tr_best:  96.06%, epoch time: 174.70 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 63.2034%\n",
      "layer   3  Sparsity: 39.9543%\n",
      "total_backward_count 3604608 real_backward_count 698456  19.377%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 69.2500%\n",
      "layer   3  Sparsity: 45.9167%\n",
      "fc layer 1 self.abs_max_out: 31616.0\n",
      "fc layer 1 self.abs_max_out: 31725.0\n",
      "train - Value 0: 1977 occurrences\n",
      "train - Value 1: 2055 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 370 occurrences\n",
      "test - Value 1: 82 occurrences\n",
      "epoch-149 lr=['4.0000000'], tr/val_loss:947.321899/849.573120, val:  63.27%, val_best:  69.47%, tr:  94.27%, tr_best:  96.06%, epoch time: 174.06 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.6766%\n",
      "layer   3  Sparsity: 39.4519%\n",
      "total_backward_count 3628800 real_backward_count 703257  19.380%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 55.4167%\n",
      "layer   3  Sparsity: 33.7500%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-150 lr=['4.0000000'], tr/val_loss:950.806519/943.307068, val:  50.00%, val_best:  69.47%, tr:  95.46%, tr_best:  96.06%, epoch time: 174.28 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 63.4646%\n",
      "layer   3  Sparsity: 40.5046%\n",
      "total_backward_count 3652992 real_backward_count 708078  19.384%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 65.8333%\n",
      "layer   3  Sparsity: 35.1667%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['4.0000000'], tr/val_loss:910.936401/768.160461, val:  50.00%, val_best:  69.47%, tr:  95.56%, tr_best:  96.06%, epoch time: 174.26 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 63.4535%\n",
      "layer   3  Sparsity: 39.9730%\n",
      "total_backward_count 3677184 real_backward_count 712666  19.381%\n",
      "layer   1  Sparsity: 84.7331%\n",
      "layer   2  Sparsity: 64.1667%\n",
      "layer   3  Sparsity: 43.0000%\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-152 lr=['4.0000000'], tr/val_loss:891.008057/820.970154, val:  50.66%, val_best:  69.47%, tr:  94.02%, tr_best:  96.06%, epoch time: 174.62 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.5802%\n",
      "layer   3  Sparsity: 39.9346%\n",
      "total_backward_count 3701376 real_backward_count 717569  19.387%\n",
      "layer   1  Sparsity: 81.2500%\n",
      "layer   2  Sparsity: 57.0833%\n",
      "layer   3  Sparsity: 33.7500%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-153 lr=['4.0000000'], tr/val_loss:898.504822/895.725159, val:  50.00%, val_best:  69.47%, tr:  93.87%, tr_best:  96.06%, epoch time: 174.53 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.2791%\n",
      "layer   3  Sparsity: 40.5469%\n",
      "total_backward_count 3725568 real_backward_count 722464  19.392%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 60.0833%\n",
      "layer   3  Sparsity: 34.9167%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-154 lr=['4.0000000'], tr/val_loss:919.288330/935.054199, val:  50.00%, val_best:  69.47%, tr:  94.32%, tr_best:  96.06%, epoch time: 172.93 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 62.4377%\n",
      "layer   3  Sparsity: 40.6808%\n",
      "total_backward_count 3749760 real_backward_count 727316  19.396%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 56.4167%\n",
      "layer   3  Sparsity: 36.0833%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 411 occurrences\n",
      "test - Value 1: 41 occurrences\n",
      "epoch-155 lr=['4.0000000'], tr/val_loss:927.378357/824.878540, val:  56.42%, val_best:  69.47%, tr:  94.52%, tr_best:  96.06%, epoch time: 175.30 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 63.0797%\n",
      "layer   3  Sparsity: 40.1351%\n",
      "total_backward_count 3773952 real_backward_count 732159  19.400%\n",
      "layer   1  Sparsity: 88.9974%\n",
      "layer   2  Sparsity: 70.7500%\n",
      "layer   3  Sparsity: 57.5833%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-156 lr=['4.0000000'], tr/val_loss:904.431641/839.370728, val:  50.44%, val_best:  69.47%, tr:  94.69%, tr_best:  96.06%, epoch time: 175.47 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 62.9649%\n",
      "layer   3  Sparsity: 39.7429%\n",
      "total_backward_count 3798144 real_backward_count 736838  19.400%\n",
      "layer   1  Sparsity: 78.7109%\n",
      "layer   2  Sparsity: 64.5000%\n",
      "layer   3  Sparsity: 31.6667%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-157 lr=['4.0000000'], tr/val_loss:933.349670/848.316162, val:  64.16%, val_best:  69.47%, tr:  95.24%, tr_best:  96.06%, epoch time: 173.39 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.3674%\n",
      "layer   3  Sparsity: 39.8230%\n",
      "total_backward_count 3822336 real_backward_count 741521  19.400%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 67.9167%\n",
      "layer   3  Sparsity: 45.9167%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['4.0000000'], tr/val_loss:945.326294/963.795837, val:  50.00%, val_best:  69.47%, tr:  95.26%, tr_best:  96.06%, epoch time: 174.15 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.5323%\n",
      "layer   3  Sparsity: 40.0739%\n",
      "total_backward_count 3846528 real_backward_count 746295  19.402%\n",
      "layer   1  Sparsity: 85.7422%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 44.4167%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-159 lr=['4.0000000'], tr/val_loss:939.861084/894.402344, val:  49.78%, val_best:  69.47%, tr:  95.04%, tr_best:  96.06%, epoch time: 175.51 seconds, 2.93 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 63.5541%\n",
      "layer   3  Sparsity: 39.8598%\n",
      "total_backward_count 3870720 real_backward_count 750846  19.398%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 47.5833%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-160 lr=['4.0000000'], tr/val_loss:945.930420/888.606934, val:  50.00%, val_best:  69.47%, tr:  95.06%, tr_best:  96.06%, epoch time: 174.78 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 63.3574%\n",
      "layer   3  Sparsity: 39.7456%\n",
      "total_backward_count 3894912 real_backward_count 755477  19.397%\n",
      "layer   1  Sparsity: 63.6068%\n",
      "layer   2  Sparsity: 59.7500%\n",
      "layer   3  Sparsity: 32.2500%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['4.0000000'], tr/val_loss:927.263184/910.320190, val:  50.00%, val_best:  69.47%, tr:  95.39%, tr_best:  96.06%, epoch time: 174.47 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4696%\n",
      "layer   2  Sparsity: 62.9359%\n",
      "layer   3  Sparsity: 39.3886%\n",
      "total_backward_count 3919104 real_backward_count 760089  19.394%\n",
      "layer   1  Sparsity: 93.6523%\n",
      "layer   2  Sparsity: 72.1667%\n",
      "layer   3  Sparsity: 55.4167%\n",
      "fc layer 2 self.abs_max_out: 5894.0\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "lif layer 1 self.abs_max_v: 52510.5\n",
      "lif layer 1 self.abs_max_v: 53806.5\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-162 lr=['4.0000000'], tr/val_loss:913.439636/850.562500, val:  50.44%, val_best:  69.47%, tr:  94.35%, tr_best:  96.06%, epoch time: 173.95 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 63.0979%\n",
      "layer   3  Sparsity: 39.9063%\n",
      "total_backward_count 3943296 real_backward_count 764787  19.395%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 65.6667%\n",
      "layer   3  Sparsity: 35.8333%\n",
      "fc layer 1 self.abs_max_out: 31788.0\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 184 occurrences\n",
      "test - Value 1: 268 occurrences\n",
      "epoch-163 lr=['4.0000000'], tr/val_loss:938.920227/839.028259, val:  64.60%, val_best:  69.47%, tr:  95.01%, tr_best:  96.06%, epoch time: 174.99 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 63.0939%\n",
      "layer   3  Sparsity: 39.5526%\n",
      "total_backward_count 3967488 real_backward_count 769373  19.392%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 33.9167%\n",
      "fc layer 1 self.abs_max_out: 32414.0\n",
      "fc layer 1 self.abs_max_out: 32736.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-164 lr=['4.0000000'], tr/val_loss:917.191284/903.634705, val:  50.00%, val_best:  69.47%, tr:  94.62%, tr_best:  96.06%, epoch time: 173.65 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 63.0189%\n",
      "layer   3  Sparsity: 39.7923%\n",
      "total_backward_count 3991680 real_backward_count 774022  19.391%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 73.9167%\n",
      "layer   3  Sparsity: 57.5000%\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 255 occurrences\n",
      "test - Value 1: 197 occurrences\n",
      "epoch-165 lr=['4.0000000'], tr/val_loss:943.454346/823.452393, val:  68.81%, val_best:  69.47%, tr:  94.94%, tr_best:  96.06%, epoch time: 174.03 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.3416%\n",
      "layer   3  Sparsity: 39.8540%\n",
      "total_backward_count 4015872 real_backward_count 778726  19.391%\n",
      "layer   1  Sparsity: 73.9909%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 35.2500%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['4.0000000'], tr/val_loss:914.875061/905.409607, val:  50.00%, val_best:  69.47%, tr:  94.52%, tr_best:  96.06%, epoch time: 173.83 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 63.9729%\n",
      "layer   3  Sparsity: 39.6721%\n",
      "total_backward_count 4040064 real_backward_count 783512  19.394%\n",
      "layer   1  Sparsity: 84.5378%\n",
      "layer   2  Sparsity: 63.6667%\n",
      "layer   3  Sparsity: 45.6667%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-167 lr=['4.0000000'], tr/val_loss:958.172180/888.273193, val:  50.00%, val_best:  69.47%, tr:  94.89%, tr_best:  96.06%, epoch time: 173.07 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 63.3945%\n",
      "layer   3  Sparsity: 39.6338%\n",
      "total_backward_count 4064256 real_backward_count 788170  19.393%\n",
      "layer   1  Sparsity: 82.7799%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 44.0833%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['4.0000000'], tr/val_loss:991.508301/940.958984, val:  50.00%, val_best:  69.47%, tr:  95.36%, tr_best:  96.06%, epoch time: 173.49 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.2560%\n",
      "layer   3  Sparsity: 39.5541%\n",
      "total_backward_count 4088448 real_backward_count 792775  19.391%\n",
      "layer   1  Sparsity: 91.1784%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 56.8333%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-169 lr=['4.0000000'], tr/val_loss:943.176453/884.213135, val:  69.03%, val_best:  69.47%, tr:  95.11%, tr_best:  96.06%, epoch time: 171.22 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4634%\n",
      "layer   2  Sparsity: 63.3831%\n",
      "layer   3  Sparsity: 39.7761%\n",
      "total_backward_count 4112640 real_backward_count 797530  19.392%\n",
      "layer   1  Sparsity: 79.0365%\n",
      "layer   2  Sparsity: 56.8333%\n",
      "layer   3  Sparsity: 32.4167%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['4.0000000'], tr/val_loss:939.955994/905.286316, val:  50.00%, val_best:  69.47%, tr:  95.11%, tr_best:  96.06%, epoch time: 175.26 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.0584%\n",
      "layer   3  Sparsity: 39.7435%\n",
      "total_backward_count 4136832 real_backward_count 802380  19.396%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 69.5833%\n",
      "layer   3  Sparsity: 45.8333%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-171 lr=['4.0000000'], tr/val_loss:942.263611/925.578979, val:  50.00%, val_best:  69.47%, tr:  94.82%, tr_best:  96.06%, epoch time: 170.39 seconds, 2.84 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.4272%\n",
      "layer   3  Sparsity: 39.8740%\n",
      "total_backward_count 4161024 real_backward_count 807111  19.397%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 48.3333%\n",
      "layer   3  Sparsity: 31.3333%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-172 lr=['4.0000000'], tr/val_loss:951.054810/952.081665, val:  50.00%, val_best:  69.47%, tr:  93.80%, tr_best:  96.06%, epoch time: 174.23 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 61.7986%\n",
      "layer   3  Sparsity: 39.4303%\n",
      "total_backward_count 4185216 real_backward_count 811596  19.392%\n",
      "layer   1  Sparsity: 86.4909%\n",
      "layer   2  Sparsity: 60.3333%\n",
      "layer   3  Sparsity: 44.1667%\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-173 lr=['4.0000000'], tr/val_loss:885.732178/846.810974, val:  50.88%, val_best:  69.47%, tr:  93.97%, tr_best:  96.06%, epoch time: 174.25 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 62.2775%\n",
      "layer   3  Sparsity: 39.5446%\n",
      "total_backward_count 4209408 real_backward_count 816509  19.397%\n",
      "layer   1  Sparsity: 94.4010%\n",
      "layer   2  Sparsity: 78.3333%\n",
      "layer   3  Sparsity: 67.0833%\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 240 occurrences\n",
      "test - Value 1: 212 occurrences\n",
      "epoch-174 lr=['4.0000000'], tr/val_loss:905.464600/779.530457, val:  63.72%, val_best:  69.47%, tr:  93.28%, tr_best:  96.06%, epoch time: 174.21 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4627%\n",
      "layer   2  Sparsity: 62.0816%\n",
      "layer   3  Sparsity: 39.9107%\n",
      "total_backward_count 4233600 real_backward_count 821459  19.403%\n",
      "layer   1  Sparsity: 92.1875%\n",
      "layer   2  Sparsity: 76.3333%\n",
      "layer   3  Sparsity: 56.1667%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-175 lr=['4.0000000'], tr/val_loss:909.493042/918.272888, val:  50.00%, val_best:  69.47%, tr:  94.25%, tr_best:  96.06%, epoch time: 173.13 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 62.6345%\n",
      "layer   3  Sparsity: 39.4142%\n",
      "total_backward_count 4257792 real_backward_count 826188  19.404%\n",
      "layer   1  Sparsity: 76.1068%\n",
      "layer   2  Sparsity: 59.6667%\n",
      "layer   3  Sparsity: 31.7500%\n",
      "fc layer 2 self.abs_max_out: 5908.0\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-176 lr=['4.0000000'], tr/val_loss:950.846130/886.690979, val:  50.88%, val_best:  69.47%, tr:  94.64%, tr_best:  96.06%, epoch time: 174.11 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 62.7830%\n",
      "layer   3  Sparsity: 39.4563%\n",
      "total_backward_count 4281984 real_backward_count 830967  19.406%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 65.0833%\n",
      "layer   3  Sparsity: 44.8333%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 407 occurrences\n",
      "test - Value 1: 45 occurrences\n",
      "epoch-177 lr=['4.0000000'], tr/val_loss:956.958313/875.556091, val:  59.07%, val_best:  69.47%, tr:  95.56%, tr_best:  96.06%, epoch time: 174.24 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 62.6141%\n",
      "layer   3  Sparsity: 39.2155%\n",
      "total_backward_count 4306176 real_backward_count 835678  19.406%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 69.3333%\n",
      "layer   3  Sparsity: 44.8333%\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-178 lr=['4.0000000'], tr/val_loss:924.980652/896.442505, val:  51.55%, val_best:  69.47%, tr:  95.51%, tr_best:  96.06%, epoch time: 173.36 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 63.1642%\n",
      "layer   3  Sparsity: 39.8015%\n",
      "total_backward_count 4330368 real_backward_count 840187  19.402%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 68.5833%\n",
      "layer   3  Sparsity: 43.6667%\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['4.0000000'], tr/val_loss:901.682190/887.570923, val:  50.00%, val_best:  69.47%, tr:  94.69%, tr_best:  96.06%, epoch time: 174.68 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.9514%\n",
      "layer   3  Sparsity: 39.2766%\n",
      "total_backward_count 4354560 real_backward_count 844998  19.405%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 55.3333%\n",
      "layer   3  Sparsity: 32.7500%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-180 lr=['4.0000000'], tr/val_loss:912.073303/875.586731, val:  50.66%, val_best:  69.47%, tr:  94.69%, tr_best:  96.06%, epoch time: 174.65 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 63.0789%\n",
      "layer   3  Sparsity: 39.1985%\n",
      "total_backward_count 4378752 real_backward_count 849639  19.404%\n",
      "layer   1  Sparsity: 88.6393%\n",
      "layer   2  Sparsity: 71.5000%\n",
      "layer   3  Sparsity: 45.7500%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 435 occurrences\n",
      "test - Value 1: 17 occurrences\n",
      "epoch-181 lr=['4.0000000'], tr/val_loss:911.980347/819.398621, val:  53.32%, val_best:  69.47%, tr:  95.14%, tr_best:  96.06%, epoch time: 173.17 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4640%\n",
      "layer   2  Sparsity: 62.9754%\n",
      "layer   3  Sparsity: 39.4675%\n",
      "total_backward_count 4402944 real_backward_count 854360  19.404%\n",
      "layer   1  Sparsity: 59.0495%\n",
      "layer   2  Sparsity: 64.8333%\n",
      "layer   3  Sparsity: 34.5000%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-182 lr=['4.0000000'], tr/val_loss:957.276184/906.202942, val:  50.22%, val_best:  69.47%, tr:  94.52%, tr_best:  96.06%, epoch time: 173.34 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4706%\n",
      "layer   2  Sparsity: 62.6315%\n",
      "layer   3  Sparsity: 39.4863%\n",
      "total_backward_count 4427136 real_backward_count 859067  19.405%\n",
      "layer   1  Sparsity: 79.7201%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 32.5000%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-183 lr=['4.0000000'], tr/val_loss:913.319275/905.298889, val:  50.00%, val_best:  69.47%, tr:  94.89%, tr_best:  96.06%, epoch time: 173.43 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 62.8316%\n",
      "layer   3  Sparsity: 39.4823%\n",
      "total_backward_count 4451328 real_backward_count 863699  19.403%\n",
      "layer   1  Sparsity: 76.4323%\n",
      "layer   2  Sparsity: 56.0833%\n",
      "layer   3  Sparsity: 29.6667%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['4.0000000'], tr/val_loss:930.937927/1043.440186, val:  50.00%, val_best:  69.47%, tr:  95.09%, tr_best:  96.06%, epoch time: 174.56 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 62.3220%\n",
      "layer   3  Sparsity: 39.6146%\n",
      "total_backward_count 4475520 real_backward_count 868359  19.402%\n",
      "layer   1  Sparsity: 88.1185%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 36.8333%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-185 lr=['4.0000000'], tr/val_loss:983.247864/948.538574, val:  50.00%, val_best:  69.47%, tr:  95.04%, tr_best:  96.06%, epoch time: 173.19 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 62.4156%\n",
      "layer   3  Sparsity: 39.6862%\n",
      "total_backward_count 4499712 real_backward_count 873083  19.403%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 69.3333%\n",
      "layer   3  Sparsity: 44.8333%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-186 lr=['4.0000000'], tr/val_loss:945.154846/919.725098, val:  50.00%, val_best:  69.47%, tr:  94.97%, tr_best:  96.06%, epoch time: 174.77 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 62.1360%\n",
      "layer   3  Sparsity: 39.5839%\n",
      "total_backward_count 4523904 real_backward_count 877764  19.403%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 59.1667%\n",
      "layer   3  Sparsity: 44.0000%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['4.0000000'], tr/val_loss:930.910950/962.284424, val:  50.00%, val_best:  69.47%, tr:  94.69%, tr_best:  96.06%, epoch time: 175.05 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.3799%\n",
      "layer   3  Sparsity: 39.6357%\n",
      "total_backward_count 4548096 real_backward_count 882476  19.403%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 58.8333%\n",
      "layer   3  Sparsity: 34.5833%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-188 lr=['4.0000000'], tr/val_loss:922.759766/826.170532, val:  69.47%, val_best:  69.47%, tr:  94.00%, tr_best:  96.06%, epoch time: 173.68 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 62.2910%\n",
      "layer   3  Sparsity: 39.5512%\n",
      "total_backward_count 4572288 real_backward_count 887339  19.407%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 65.8333%\n",
      "layer   3  Sparsity: 33.9167%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-189 lr=['4.0000000'], tr/val_loss:928.103760/905.051025, val:  50.00%, val_best:  69.47%, tr:  94.25%, tr_best:  96.06%, epoch time: 173.88 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 62.3311%\n",
      "layer   3  Sparsity: 39.4275%\n",
      "total_backward_count 4596480 real_backward_count 892064  19.408%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 66.2500%\n",
      "layer   3  Sparsity: 46.0833%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-190 lr=['4.0000000'], tr/val_loss:966.141602/983.105530, val:  50.00%, val_best:  69.47%, tr:  95.16%, tr_best:  96.06%, epoch time: 175.45 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.1618%\n",
      "layer   3  Sparsity: 39.0325%\n",
      "total_backward_count 4620672 real_backward_count 896659  19.405%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 33.4167%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-191 lr=['4.0000000'], tr/val_loss:948.271851/982.361694, val:  50.00%, val_best:  69.47%, tr:  95.01%, tr_best:  96.06%, epoch time: 174.95 seconds, 2.92 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 62.1893%\n",
      "layer   3  Sparsity: 39.3630%\n",
      "total_backward_count 4644864 real_backward_count 901306  19.404%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 65.9167%\n",
      "layer   3  Sparsity: 44.4167%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-192 lr=['4.0000000'], tr/val_loss:979.627319/775.246521, val:  51.33%, val_best:  69.47%, tr:  94.97%, tr_best:  96.06%, epoch time: 174.26 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 62.0992%\n",
      "layer   3  Sparsity: 39.3299%\n",
      "total_backward_count 4669056 real_backward_count 906024  19.405%\n",
      "layer   1  Sparsity: 64.3555%\n",
      "layer   2  Sparsity: 67.4167%\n",
      "layer   3  Sparsity: 32.8333%\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['4.0000000'], tr/val_loss:918.686035/907.326294, val:  50.00%, val_best:  69.47%, tr:  94.10%, tr_best:  96.06%, epoch time: 174.09 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4694%\n",
      "layer   2  Sparsity: 62.0696%\n",
      "layer   3  Sparsity: 39.8519%\n",
      "total_backward_count 4693248 real_backward_count 910802  19.407%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 63.8333%\n",
      "layer   3  Sparsity: 41.6667%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['4.0000000'], tr/val_loss:924.868530/936.108337, val:  50.00%, val_best:  69.47%, tr:  94.00%, tr_best:  96.06%, epoch time: 174.53 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 62.0812%\n",
      "layer   3  Sparsity: 39.5118%\n",
      "total_backward_count 4717440 real_backward_count 915601  19.409%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 46.6667%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-195 lr=['4.0000000'], tr/val_loss:946.161682/965.066406, val:  50.00%, val_best:  69.47%, tr:  94.62%, tr_best:  96.06%, epoch time: 171.62 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 61.8575%\n",
      "layer   3  Sparsity: 39.5527%\n",
      "total_backward_count 4741632 real_backward_count 920444  19.412%\n",
      "layer   1  Sparsity: 83.9193%\n",
      "layer   2  Sparsity: 69.6667%\n",
      "layer   3  Sparsity: 48.4167%\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-196 lr=['4.0000000'], tr/val_loss:923.701721/848.226318, val:  50.66%, val_best:  69.47%, tr:  93.97%, tr_best:  96.06%, epoch time: 172.73 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 61.9772%\n",
      "layer   3  Sparsity: 39.7350%\n",
      "total_backward_count 4765824 real_backward_count 925228  19.414%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 51.4167%\n",
      "layer   3  Sparsity: 35.8333%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-197 lr=['4.0000000'], tr/val_loss:945.289856/844.117981, val:  50.22%, val_best:  69.47%, tr:  94.62%, tr_best:  96.06%, epoch time: 174.75 seconds, 2.91 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 62.0564%\n",
      "layer   3  Sparsity: 40.1629%\n",
      "total_backward_count 4790016 real_backward_count 929906  19.413%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 33.0000%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['4.0000000'], tr/val_loss:953.766052/869.556702, val:  50.00%, val_best:  69.47%, tr:  94.82%, tr_best:  96.06%, epoch time: 173.83 seconds, 2.90 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 62.2854%\n",
      "layer   3  Sparsity: 40.0278%\n",
      "total_backward_count 4814208 real_backward_count 934557  19.412%\n",
      "layer   1  Sparsity: 71.8424%\n",
      "layer   2  Sparsity: 55.5000%\n",
      "layer   3  Sparsity: 35.0000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-199 lr=['4.0000000'], tr/val_loss:952.284851/970.858154, val:  50.00%, val_best:  69.47%, tr:  93.80%, tr_best:  96.06%, epoch time: 173.49 seconds, 2.89 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 62.2343%\n",
      "layer   3  Sparsity: 39.9360%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeec07cadeb44416a2814992a3557fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.938</td></tr><tr><td>tr_epoch_loss</td><td>952.28485</td></tr><tr><td>val_acc_best</td><td>0.69469</td></tr><tr><td>val_acc_now</td><td>0.5</td></tr><tr><td>val_loss</td><td>970.85815</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-40</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/pztfajjm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/pztfajjm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251213_103424-pztfajjm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kp5q4dmm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251213_201508-kp5q4dmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/kp5q4dmm' target=\"_blank\">electric-sweep-41</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/kp5q4dmm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/kp5q4dmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251213_201517_500', 'my_seed': 42, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 64, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 0.25, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 4, 'lif_layer_v_threshold2': 32, 'init_scaling': [1, 0.0625, 0.0625], 'learning_rate': 4, 'learning_rate2': 1, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 0.25, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 4, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.0625, 0.0625])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=0.25, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.0625, 0.0625])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.0625, 0.0625])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 4\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 824.0\n",
      "lif layer 1 self.abs_max_v: 824.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 132.0\n",
      "lif layer 2 self.abs_max_v: 132.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 45.0\n",
      "fc layer 1 self.abs_max_out: 2492.0\n",
      "lif layer 1 self.abs_max_v: 2548.5\n",
      "fc layer 2 self.abs_max_out: 173.0\n",
      "lif layer 2 self.abs_max_v: 173.0\n",
      "fc layer 3 self.abs_max_out: 52.0\n",
      "fc layer 1 self.abs_max_out: 3214.0\n",
      "lif layer 1 self.abs_max_v: 4059.0\n",
      "lif layer 2 self.abs_max_v: 192.5\n",
      "fc layer 3 self.abs_max_out: 54.0\n",
      "fc layer 1 self.abs_max_out: 3409.0\n",
      "lif layer 1 self.abs_max_v: 5021.5\n",
      "lif layer 2 self.abs_max_v: 260.5\n",
      "fc layer 3 self.abs_max_out: 73.0\n",
      "lif layer 1 self.abs_max_v: 5706.0\n",
      "lif layer 2 self.abs_max_v: 299.5\n",
      "fc layer 2 self.abs_max_out: 178.0\n",
      "layer   1  Sparsity: 74.8535%\n",
      "layer   2  Sparsity: 58.1250%\n",
      "layer   3  Sparsity: 75.7500%\n",
      "fc layer 1 self.abs_max_out: 3516.0\n",
      "fc layer 2 self.abs_max_out: 189.0\n",
      "lif layer 2 self.abs_max_v: 304.5\n",
      "fc layer 2 self.abs_max_out: 217.0\n",
      "fc layer 3 self.abs_max_out: 91.0\n",
      "fc layer 3 self.abs_max_out: 101.0\n",
      "fc layer 2 self.abs_max_out: 222.0\n",
      "fc layer 1 self.abs_max_out: 3722.0\n",
      "fc layer 3 self.abs_max_out: 109.0\n",
      "fc layer 2 self.abs_max_out: 226.0\n",
      "lif layer 2 self.abs_max_v: 306.0\n",
      "fc layer 1 self.abs_max_out: 4382.0\n",
      "lif layer 2 self.abs_max_v: 331.5\n",
      "lif layer 2 self.abs_max_v: 335.0\n",
      "lif layer 2 self.abs_max_v: 336.5\n",
      "fc layer 3 self.abs_max_out: 110.0\n",
      "fc layer 3 self.abs_max_out: 147.0\n",
      "fc layer 2 self.abs_max_out: 227.0\n",
      "fc layer 2 self.abs_max_out: 249.0\n",
      "fc layer 2 self.abs_max_out: 268.0\n",
      "lif layer 2 self.abs_max_v: 402.0\n",
      "lif layer 2 self.abs_max_v: 442.0\n",
      "fc layer 2 self.abs_max_out: 276.0\n",
      "lif layer 2 self.abs_max_v: 447.0\n",
      "lif layer 2 self.abs_max_v: 465.5\n",
      "fc layer 2 self.abs_max_out: 277.0\n",
      "fc layer 2 self.abs_max_out: 311.0\n",
      "fc layer 2 self.abs_max_out: 330.0\n",
      "lif layer 2 self.abs_max_v: 466.5\n",
      "lif layer 2 self.abs_max_v: 475.5\n",
      "fc layer 3 self.abs_max_out: 166.0\n",
      "fc layer 3 self.abs_max_out: 170.0\n",
      "fc layer 2 self.abs_max_out: 345.0\n",
      "lif layer 1 self.abs_max_v: 5903.5\n",
      "lif layer 2 self.abs_max_v: 477.5\n",
      "lif layer 2 self.abs_max_v: 485.0\n",
      "fc layer 1 self.abs_max_out: 4749.0\n",
      "fc layer 3 self.abs_max_out: 173.0\n",
      "lif layer 1 self.abs_max_v: 6131.0\n",
      "lif layer 2 self.abs_max_v: 503.0\n",
      "fc layer 3 self.abs_max_out: 189.0\n",
      "fc layer 1 self.abs_max_out: 4837.0\n",
      "fc layer 1 self.abs_max_out: 4921.0\n",
      "lif layer 1 self.abs_max_v: 6353.5\n",
      "fc layer 2 self.abs_max_out: 356.0\n",
      "fc layer 2 self.abs_max_out: 398.0\n",
      "fc layer 1 self.abs_max_out: 5696.0\n",
      "lif layer 1 self.abs_max_v: 6637.5\n",
      "fc layer 2 self.abs_max_out: 418.0\n",
      "lif layer 1 self.abs_max_v: 7232.0\n",
      "fc layer 2 self.abs_max_out: 423.0\n",
      "lif layer 2 self.abs_max_v: 519.5\n",
      "fc layer 3 self.abs_max_out: 209.0\n",
      "fc layer 1 self.abs_max_out: 5876.0\n",
      "fc layer 2 self.abs_max_out: 439.0\n",
      "fc layer 2 self.abs_max_out: 458.0\n",
      "lif layer 1 self.abs_max_v: 7234.5\n",
      "fc layer 1 self.abs_max_out: 6841.0\n",
      "fc layer 2 self.abs_max_out: 468.0\n",
      "fc layer 2 self.abs_max_out: 508.0\n",
      "lif layer 1 self.abs_max_v: 7349.5\n",
      "lif layer 1 self.abs_max_v: 7832.0\n",
      "lif layer 1 self.abs_max_v: 8040.5\n",
      "lif layer 1 self.abs_max_v: 9156.5\n",
      "fc layer 2 self.abs_max_out: 520.0\n",
      "lif layer 2 self.abs_max_v: 520.0\n",
      "fc layer 1 self.abs_max_out: 7052.0\n",
      "fc layer 1 self.abs_max_out: 7330.0\n",
      "lif layer 2 self.abs_max_v: 577.0\n",
      "lif layer 1 self.abs_max_v: 9667.0\n",
      "lif layer 2 self.abs_max_v: 598.0\n",
      "lif layer 2 self.abs_max_v: 622.0\n",
      "fc layer 3 self.abs_max_out: 231.0\n",
      "fc layer 2 self.abs_max_out: 540.0\n",
      "lif layer 2 self.abs_max_v: 627.0\n",
      "lif layer 2 self.abs_max_v: 630.5\n",
      "fc layer 2 self.abs_max_out: 557.0\n",
      "fc layer 2 self.abs_max_out: 566.0\n",
      "fc layer 2 self.abs_max_out: 567.0\n",
      "fc layer 2 self.abs_max_out: 586.0\n",
      "fc layer 2 self.abs_max_out: 594.0\n",
      "lif layer 2 self.abs_max_v: 643.0\n",
      "fc layer 2 self.abs_max_out: 627.0\n",
      "lif layer 2 self.abs_max_v: 665.5\n",
      "lif layer 2 self.abs_max_v: 667.5\n",
      "fc layer 2 self.abs_max_out: 671.0\n",
      "lif layer 2 self.abs_max_v: 671.0\n",
      "fc layer 2 self.abs_max_out: 683.0\n",
      "lif layer 2 self.abs_max_v: 683.0\n",
      "lif layer 2 self.abs_max_v: 683.5\n",
      "fc layer 3 self.abs_max_out: 236.0\n",
      "fc layer 2 self.abs_max_out: 693.0\n",
      "lif layer 2 self.abs_max_v: 693.0\n",
      "fc layer 2 self.abs_max_out: 705.0\n",
      "lif layer 2 self.abs_max_v: 705.0\n",
      "lif layer 2 self.abs_max_v: 708.5\n",
      "fc layer 1 self.abs_max_out: 7563.0\n",
      "fc layer 3 self.abs_max_out: 254.0\n",
      "lif layer 2 self.abs_max_v: 710.0\n",
      "lif layer 2 self.abs_max_v: 718.5\n",
      "fc layer 1 self.abs_max_out: 8323.0\n",
      "lif layer 1 self.abs_max_v: 10551.5\n",
      "lif layer 2 self.abs_max_v: 737.5\n",
      "lif layer 2 self.abs_max_v: 770.0\n",
      "lif layer 2 self.abs_max_v: 800.0\n",
      "lif layer 2 self.abs_max_v: 804.0\n",
      "fc layer 3 self.abs_max_out: 317.0\n",
      "lif layer 1 self.abs_max_v: 10753.5\n",
      "lif layer 1 self.abs_max_v: 11103.0\n",
      "lif layer 1 self.abs_max_v: 11151.0\n",
      "lif layer 1 self.abs_max_v: 11278.0\n",
      "lif layer 1 self.abs_max_v: 11602.0\n",
      "lif layer 1 self.abs_max_v: 11825.0\n",
      "lif layer 2 self.abs_max_v: 804.5\n",
      "lif layer 2 self.abs_max_v: 807.5\n",
      "lif layer 2 self.abs_max_v: 901.0\n",
      "fc layer 1 self.abs_max_out: 8605.0\n",
      "lif layer 1 self.abs_max_v: 11974.5\n",
      "fc layer 1 self.abs_max_out: 8738.0\n",
      "lif layer 1 self.abs_max_v: 12361.5\n",
      "lif layer 1 self.abs_max_v: 13834.5\n",
      "lif layer 2 self.abs_max_v: 921.0\n",
      "lif layer 1 self.abs_max_v: 14253.0\n",
      "fc layer 1 self.abs_max_out: 9173.0\n",
      "lif layer 2 self.abs_max_v: 921.5\n",
      "lif layer 2 self.abs_max_v: 988.0\n",
      "lif layer 2 self.abs_max_v: 992.5\n",
      "lif layer 2 self.abs_max_v: 1044.5\n",
      "lif layer 2 self.abs_max_v: 1053.5\n",
      "lif layer 2 self.abs_max_v: 1063.5\n",
      "lif layer 1 self.abs_max_v: 15015.0\n",
      "fc layer 1 self.abs_max_out: 9343.0\n",
      "fc layer 2 self.abs_max_out: 710.0\n",
      "fc layer 2 self.abs_max_out: 737.0\n",
      "fc layer 2 self.abs_max_out: 738.0\n",
      "fc layer 1 self.abs_max_out: 9543.0\n",
      "fc layer 1 self.abs_max_out: 9656.0\n",
      "lif layer 1 self.abs_max_v: 15829.5\n",
      "fc layer 1 self.abs_max_out: 9840.0\n",
      "fc layer 2 self.abs_max_out: 749.0\n",
      "lif layer 2 self.abs_max_v: 1092.0\n",
      "lif layer 2 self.abs_max_v: 1108.0\n",
      "lif layer 2 self.abs_max_v: 1148.5\n",
      "fc layer 1 self.abs_max_out: 10327.0\n",
      "lif layer 2 self.abs_max_v: 1190.5\n",
      "lif layer 2 self.abs_max_v: 1199.0\n",
      "lif layer 1 self.abs_max_v: 15952.5\n",
      "fc layer 3 self.abs_max_out: 326.0\n",
      "fc layer 3 self.abs_max_out: 373.0\n",
      "fc layer 2 self.abs_max_out: 758.0\n",
      "lif layer 2 self.abs_max_v: 1200.5\n",
      "lif layer 2 self.abs_max_v: 1271.5\n",
      "fc layer 2 self.abs_max_out: 759.0\n",
      "fc layer 2 self.abs_max_out: 777.0\n",
      "lif layer 2 self.abs_max_v: 1272.0\n",
      "fc layer 2 self.abs_max_out: 797.0\n",
      "lif layer 2 self.abs_max_v: 1303.5\n",
      "fc layer 2 self.abs_max_out: 835.0\n",
      "fc layer 2 self.abs_max_out: 866.0\n",
      "fc layer 2 self.abs_max_out: 875.0\n",
      "fc layer 2 self.abs_max_out: 899.0\n",
      "fc layer 2 self.abs_max_out: 906.0\n",
      "fc layer 2 self.abs_max_out: 917.0\n",
      "fc layer 2 self.abs_max_out: 942.0\n",
      "fc layer 3 self.abs_max_out: 391.0\n",
      "lif layer 2 self.abs_max_v: 1310.0\n",
      "fc layer 2 self.abs_max_out: 987.0\n",
      "lif layer 2 self.abs_max_v: 1349.0\n",
      "fc layer 3 self.abs_max_out: 447.0\n",
      "fc layer 2 self.abs_max_out: 988.0\n",
      "lif layer 2 self.abs_max_v: 1356.0\n",
      "lif layer 2 self.abs_max_v: 1358.5\n",
      "lif layer 2 self.abs_max_v: 1486.5\n",
      "lif layer 2 self.abs_max_v: 1488.0\n",
      "lif layer 2 self.abs_max_v: 1524.0\n",
      "lif layer 2 self.abs_max_v: 1544.0\n",
      "lif layer 1 self.abs_max_v: 16610.0\n",
      "fc layer 2 self.abs_max_out: 994.0\n",
      "fc layer 2 self.abs_max_out: 1014.0\n",
      "fc layer 2 self.abs_max_out: 1040.0\n",
      "fc layer 2 self.abs_max_out: 1050.0\n",
      "fc layer 2 self.abs_max_out: 1054.0\n",
      "fc layer 2 self.abs_max_out: 1067.0\n",
      "fc layer 2 self.abs_max_out: 1071.0\n",
      "lif layer 2 self.abs_max_v: 1547.5\n",
      "fc layer 2 self.abs_max_out: 1073.0\n",
      "lif layer 2 self.abs_max_v: 1554.0\n",
      "lif layer 2 self.abs_max_v: 1558.0\n",
      "lif layer 2 self.abs_max_v: 1666.0\n",
      "lif layer 2 self.abs_max_v: 1732.0\n",
      "fc layer 2 self.abs_max_out: 1092.0\n",
      "fc layer 2 self.abs_max_out: 1104.0\n",
      "fc layer 2 self.abs_max_out: 1110.0\n",
      "fc layer 2 self.abs_max_out: 1160.0\n",
      "fc layer 2 self.abs_max_out: 1193.0\n",
      "fc layer 2 self.abs_max_out: 1243.0\n",
      "fc layer 2 self.abs_max_out: 1278.0\n",
      "fc layer 2 self.abs_max_out: 1287.0\n",
      "fc layer 2 self.abs_max_out: 1290.0\n",
      "fc layer 2 self.abs_max_out: 1304.0\n",
      "fc layer 2 self.abs_max_out: 1312.0\n",
      "fc layer 2 self.abs_max_out: 1323.0\n",
      "fc layer 2 self.abs_max_out: 1339.0\n",
      "fc layer 2 self.abs_max_out: 1341.0\n",
      "lif layer 2 self.abs_max_v: 1765.0\n",
      "fc layer 2 self.abs_max_out: 1414.0\n",
      "fc layer 1 self.abs_max_out: 10429.0\n",
      "fc layer 1 self.abs_max_out: 10539.0\n",
      "fc layer 1 self.abs_max_out: 10616.0\n",
      "fc layer 1 self.abs_max_out: 10874.0\n",
      "fc layer 1 self.abs_max_out: 10916.0\n",
      "fc layer 1 self.abs_max_out: 12171.0\n",
      "fc layer 3 self.abs_max_out: 458.0\n",
      "fc layer 3 self.abs_max_out: 483.0\n",
      "lif layer 1 self.abs_max_v: 17474.5\n",
      "fc layer 3 self.abs_max_out: 524.0\n",
      "fc layer 1 self.abs_max_out: 12194.0\n",
      "fc layer 1 self.abs_max_out: 13355.0\n",
      "fc layer 1 self.abs_max_out: 13796.0\n",
      "fc layer 3 self.abs_max_out: 535.0\n",
      "fc layer 1 self.abs_max_out: 14292.0\n",
      "fc layer 3 self.abs_max_out: 558.0\n",
      "lif layer 2 self.abs_max_v: 1796.0\n",
      "lif layer 2 self.abs_max_v: 1870.0\n",
      "fc layer 2 self.abs_max_out: 1516.0\n",
      "lif layer 1 self.abs_max_v: 18560.0\n",
      "lif layer 1 self.abs_max_v: 19277.0\n",
      "lif layer 2 self.abs_max_v: 1883.0\n",
      "lif layer 2 self.abs_max_v: 1948.5\n",
      "lif layer 2 self.abs_max_v: 1976.5\n",
      "fc layer 2 self.abs_max_out: 1525.0\n",
      "lif layer 2 self.abs_max_v: 2010.5\n",
      "lif layer 2 self.abs_max_v: 2018.5\n",
      "lif layer 2 self.abs_max_v: 2020.5\n",
      "lif layer 2 self.abs_max_v: 2044.0\n",
      "fc layer 2 self.abs_max_out: 1549.0\n",
      "lif layer 2 self.abs_max_v: 2047.0\n",
      "fc layer 2 self.abs_max_out: 1555.0\n",
      "fc layer 3 self.abs_max_out: 592.0\n",
      "fc layer 2 self.abs_max_out: 1583.0\n",
      "fc layer 2 self.abs_max_out: 1628.0\n",
      "lif layer 2 self.abs_max_v: 2049.0\n",
      "fc layer 2 self.abs_max_out: 1666.0\n",
      "lif layer 2 self.abs_max_v: 2055.5\n",
      "lif layer 2 self.abs_max_v: 2083.0\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 1809.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2041.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2194.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2379.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2585.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2740.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3064.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3247.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3277.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['4.0000000'], tr/val_loss:195.150909/295.377167, val:  50.00%, val_best:  50.00%, tr:  90.75%, tr_best:  90.75%, epoch time: 230.64 seconds, 3.84 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 71.7177%\n",
      "layer   3  Sparsity: 66.2343%\n",
      "total_backward_count 32256 real_backward_count 7469  23.155%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 78.1006%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 51.0000%\n",
      "fc layer 3 self.abs_max_out: 601.0\n",
      "lif layer 2 self.abs_max_v: 2108.5\n",
      "fc layer 2 self.abs_max_out: 1673.0\n",
      "lif layer 2 self.abs_max_v: 2132.5\n",
      "fc layer 3 self.abs_max_out: 603.0\n",
      "fc layer 3 self.abs_max_out: 614.0\n",
      "fc layer 3 self.abs_max_out: 631.0\n",
      "fc layer 2 self.abs_max_out: 1742.0\n",
      "fc layer 3 self.abs_max_out: 655.0\n",
      "fc layer 2 self.abs_max_out: 1786.0\n",
      "fc layer 2 self.abs_max_out: 1835.0\n",
      "fc layer 2 self.abs_max_out: 1866.0\n",
      "lif layer 1 self.abs_max_v: 20212.5\n",
      "lif layer 1 self.abs_max_v: 20766.0\n",
      "fc layer 2 self.abs_max_out: 1920.0\n",
      "fc layer 2 self.abs_max_out: 1996.0\n",
      "fc layer 2 self.abs_max_out: 2034.0\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "lif layer 2 self.abs_max_v: 2157.5\n",
      "max_activation_accul updated: 3323.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 3347.00 at epoch 1, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['4.0000000'], tr/val_loss:279.035706/322.209778, val:  50.00%, val_best:  50.00%, tr:  93.08%, tr_best:  93.08%, epoch time: 228.20 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 76.6027%\n",
      "layer   3  Sparsity: 57.7021%\n",
      "total_backward_count 64512 real_backward_count 14850  23.019%\n",
      "layer   1  Sparsity: 86.3525%\n",
      "layer   2  Sparsity: 77.2500%\n",
      "layer   3  Sparsity: 63.3750%\n",
      "lif layer 2 self.abs_max_v: 2222.5\n",
      "lif layer 2 self.abs_max_v: 2290.0\n",
      "lif layer 2 self.abs_max_v: 2345.5\n",
      "lif layer 2 self.abs_max_v: 2362.0\n",
      "fc layer 2 self.abs_max_out: 2093.0\n",
      "fc layer 2 self.abs_max_out: 2135.0\n",
      "fc layer 1 self.abs_max_out: 14305.0\n",
      "fc layer 2 self.abs_max_out: 2180.0\n",
      "fc layer 2 self.abs_max_out: 2239.0\n",
      "fc layer 3 self.abs_max_out: 680.0\n",
      "fc layer 2 self.abs_max_out: 2275.0\n",
      "lif layer 2 self.abs_max_v: 2461.5\n",
      "lif layer 1 self.abs_max_v: 21887.5\n",
      "lif layer 1 self.abs_max_v: 22049.0\n",
      "fc layer 3 self.abs_max_out: 728.0\n",
      "lif layer 2 self.abs_max_v: 2473.0\n",
      "lif layer 2 self.abs_max_v: 2600.5\n",
      "fc layer 3 self.abs_max_out: 737.0\n",
      "lif layer 2 self.abs_max_v: 2644.5\n",
      "fc layer 3 self.abs_max_out: 757.0\n",
      "fc layer 1 self.abs_max_out: 14450.0\n",
      "fc layer 2 self.abs_max_out: 2300.0\n",
      "fc layer 2 self.abs_max_out: 2310.0\n",
      "fc layer 2 self.abs_max_out: 2325.0\n",
      "lif layer 1 self.abs_max_v: 22550.5\n",
      "lif layer 1 self.abs_max_v: 22552.5\n",
      "fc layer 2 self.abs_max_out: 2357.0\n",
      "fc layer 2 self.abs_max_out: 2370.0\n",
      "lif layer 2 self.abs_max_v: 2655.5\n",
      "lif layer 1 self.abs_max_v: 22676.5\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 2 self.abs_max_out: 2425.0\n",
      "lif layer 1 self.abs_max_v: 23215.5\n",
      "fc layer 2 self.abs_max_out: 2434.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['4.0000000'], tr/val_loss:302.759888/266.470337, val:  50.00%, val_best:  50.00%, tr:  93.73%, tr_best:  93.73%, epoch time: 228.04 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 76.4333%\n",
      "layer   3  Sparsity: 58.7805%\n",
      "total_backward_count 96768 real_backward_count 21902  22.634%\n",
      "layer   1  Sparsity: 75.9277%\n",
      "layer   2  Sparsity: 73.0000%\n",
      "layer   3  Sparsity: 61.0000%\n",
      "fc layer 2 self.abs_max_out: 2489.0\n",
      "lif layer 1 self.abs_max_v: 24710.0\n",
      "lif layer 1 self.abs_max_v: 24787.0\n",
      "fc layer 2 self.abs_max_out: 2555.0\n",
      "fc layer 1 self.abs_max_out: 14950.0\n",
      "fc layer 1 self.abs_max_out: 15305.0\n",
      "lif layer 2 self.abs_max_v: 2674.5\n",
      "lif layer 2 self.abs_max_v: 2704.0\n",
      "lif layer 2 self.abs_max_v: 2720.5\n",
      "lif layer 2 self.abs_max_v: 2750.5\n",
      "lif layer 2 self.abs_max_v: 2785.0\n",
      "lif layer 2 self.abs_max_v: 2847.0\n",
      "lif layer 2 self.abs_max_v: 2923.5\n",
      "lif layer 2 self.abs_max_v: 3074.0\n",
      "lif layer 2 self.abs_max_v: 3129.0\n",
      "fc layer 2 self.abs_max_out: 2565.0\n",
      "lif layer 2 self.abs_max_v: 3202.0\n",
      "fc layer 1 self.abs_max_out: 15414.0\n",
      "lif layer 2 self.abs_max_v: 3322.0\n",
      "fc layer 1 self.abs_max_out: 15463.0\n",
      "fc layer 2 self.abs_max_out: 2837.0\n",
      "lif layer 2 self.abs_max_v: 3423.5\n",
      "fc layer 1 self.abs_max_out: 15554.0\n",
      "lif layer 1 self.abs_max_v: 24934.0\n",
      "lif layer 1 self.abs_max_v: 26479.0\n",
      "lif layer 1 self.abs_max_v: 27049.5\n",
      "fc layer 1 self.abs_max_out: 15561.0\n",
      "fc layer 1 self.abs_max_out: 16019.0\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 2 self.abs_max_out: 2879.0\n",
      "fc layer 2 self.abs_max_out: 2911.0\n",
      "fc layer 2 self.abs_max_out: 2986.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['4.0000000'], tr/val_loss:281.313049/347.461029, val:  50.00%, val_best:  50.00%, tr:  92.86%, tr_best:  93.73%, epoch time: 227.80 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 73.6672%\n",
      "layer   3  Sparsity: 62.7966%\n",
      "total_backward_count 129024 real_backward_count 28720  22.259%\n",
      "layer   1  Sparsity: 78.0518%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 65.1250%\n",
      "fc layer 1 self.abs_max_out: 16236.0\n",
      "lif layer 2 self.abs_max_v: 3542.0\n",
      "fc layer 1 self.abs_max_out: 16591.0\n",
      "fc layer 3 self.abs_max_out: 780.0\n",
      "fc layer 1 self.abs_max_out: 16624.0\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-4   lr=['4.0000000'], tr/val_loss:342.382324/303.094543, val:  51.11%, val_best:  51.11%, tr:  92.63%, tr_best:  93.73%, epoch time: 228.71 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 72.3958%\n",
      "layer   3  Sparsity: 63.8636%\n",
      "total_backward_count 161280 real_backward_count 35615  22.083%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 76.6875%\n",
      "layer   3  Sparsity: 66.4375%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3556.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 3617.00 at epoch 5, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['4.0000000'], tr/val_loss:345.642120/366.803436, val:  50.00%, val_best:  51.11%, tr:  93.45%, tr_best:  93.73%, epoch time: 229.23 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 72.7522%\n",
      "layer   3  Sparsity: 63.1001%\n",
      "total_backward_count 193536 real_backward_count 42595  22.009%\n",
      "layer   1  Sparsity: 85.8154%\n",
      "layer   2  Sparsity: 71.2500%\n",
      "layer   3  Sparsity: 64.3125%\n",
      "fc layer 3 self.abs_max_out: 785.0\n",
      "lif layer 2 self.abs_max_v: 3572.0\n",
      "lif layer 2 self.abs_max_v: 3622.0\n",
      "lif layer 2 self.abs_max_v: 3700.5\n",
      "lif layer 2 self.abs_max_v: 3752.5\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3707.00 at epoch 6, iter 4031\n",
      "max_activation_accul updated: 3747.00 at epoch 6, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['4.0000000'], tr/val_loss:348.237427/381.547729, val:  50.00%, val_best:  51.11%, tr:  93.53%, tr_best:  93.73%, epoch time: 226.84 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 72.6762%\n",
      "layer   3  Sparsity: 64.1884%\n",
      "total_backward_count 225792 real_backward_count 49495  21.921%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 80.3125%\n",
      "layer   3  Sparsity: 73.9375%\n",
      "lif layer 2 self.abs_max_v: 3824.0\n",
      "lif layer 2 self.abs_max_v: 3959.5\n",
      "lif layer 2 self.abs_max_v: 4203.0\n",
      "lif layer 2 self.abs_max_v: 4254.0\n",
      "lif layer 2 self.abs_max_v: 4399.5\n",
      "fc layer 2 self.abs_max_out: 2988.0\n",
      "fc layer 2 self.abs_max_out: 3112.0\n",
      "lif layer 2 self.abs_max_v: 4587.5\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-7   lr=['4.0000000'], tr/val_loss:352.786285/341.240662, val:  50.22%, val_best:  51.11%, tr:  94.10%, tr_best:  94.10%, epoch time: 228.25 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 72.7345%\n",
      "layer   3  Sparsity: 63.6670%\n",
      "total_backward_count 258048 real_backward_count 56368  21.844%\n",
      "layer   1  Sparsity: 83.2520%\n",
      "layer   2  Sparsity: 76.7500%\n",
      "layer   3  Sparsity: 68.6250%\n",
      "fc layer 3 self.abs_max_out: 799.0\n",
      "fc layer 3 self.abs_max_out: 805.0\n",
      "fc layer 3 self.abs_max_out: 808.0\n",
      "fc layer 3 self.abs_max_out: 832.0\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-8   lr=['4.0000000'], tr/val_loss:353.364960/325.011444, val:  51.99%, val_best:  51.99%, tr:  93.92%, tr_best:  94.10%, epoch time: 228.36 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 72.7550%\n",
      "layer   3  Sparsity: 63.6697%\n",
      "total_backward_count 290304 real_backward_count 63194  21.768%\n",
      "layer   1  Sparsity: 83.5938%\n",
      "layer   2  Sparsity: 75.3125%\n",
      "layer   3  Sparsity: 66.0625%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['4.0000000'], tr/val_loss:343.584991/308.429657, val:  50.00%, val_best:  51.99%, tr:  93.80%, tr_best:  94.10%, epoch time: 228.18 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 72.3291%\n",
      "layer   3  Sparsity: 63.5564%\n",
      "total_backward_count 322560 real_backward_count 69966  21.691%\n",
      "layer   1  Sparsity: 80.6152%\n",
      "layer   2  Sparsity: 73.0000%\n",
      "layer   3  Sparsity: 58.5000%\n",
      "fc layer 2 self.abs_max_out: 3371.0\n",
      "train - Value 0: 2031 occurrences\n",
      "train - Value 1: 2001 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3769.00 at epoch 10, iter 4031\n",
      "max_activation_accul updated: 3817.00 at epoch 10, iter 4031\n",
      "max_activation_accul updated: 3863.00 at epoch 10, iter 4031\n",
      "fc layer 2 self.abs_max_out: 3396.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-10  lr=['4.0000000'], tr/val_loss:331.172028/342.921478, val:  50.00%, val_best:  51.99%, tr:  94.17%, tr_best:  94.17%, epoch time: 228.56 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 72.8003%\n",
      "layer   3  Sparsity: 61.8362%\n",
      "total_backward_count 354816 real_backward_count 76685  21.613%\n",
      "layer   1  Sparsity: 87.9150%\n",
      "layer   2  Sparsity: 70.2500%\n",
      "layer   3  Sparsity: 60.0625%\n",
      "lif layer 2 self.abs_max_v: 4601.0\n",
      "lif layer 2 self.abs_max_v: 4637.0\n",
      "lif layer 2 self.abs_max_v: 4640.5\n",
      "lif layer 2 self.abs_max_v: 4683.0\n",
      "lif layer 2 self.abs_max_v: 4784.0\n",
      "lif layer 2 self.abs_max_v: 4785.5\n",
      "lif layer 2 self.abs_max_v: 4828.0\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['4.0000000'], tr/val_loss:337.953461/342.479645, val:  50.00%, val_best:  51.99%, tr:  94.59%, tr_best:  94.59%, epoch time: 228.49 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 72.8791%\n",
      "layer   3  Sparsity: 61.9569%\n",
      "total_backward_count 387072 real_backward_count 83259  21.510%\n",
      "layer   1  Sparsity: 84.6924%\n",
      "layer   2  Sparsity: 76.3125%\n",
      "layer   3  Sparsity: 67.0000%\n",
      "fc layer 3 self.abs_max_out: 835.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-12  lr=['4.0000000'], tr/val_loss:325.087585/290.120575, val:  50.22%, val_best:  51.99%, tr:  95.34%, tr_best:  95.34%, epoch time: 228.45 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 72.8501%\n",
      "layer   3  Sparsity: 61.9885%\n",
      "total_backward_count 419328 real_backward_count 89886  21.436%\n",
      "layer   1  Sparsity: 88.7939%\n",
      "layer   2  Sparsity: 76.2500%\n",
      "layer   3  Sparsity: 66.3750%\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['4.0000000'], tr/val_loss:316.444641/257.794006, val:  50.00%, val_best:  51.99%, tr:  93.87%, tr_best:  95.34%, epoch time: 227.68 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 72.3490%\n",
      "layer   3  Sparsity: 60.4840%\n",
      "total_backward_count 451584 real_backward_count 96643  21.401%\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 81.1250%\n",
      "layer   3  Sparsity: 67.1875%\n",
      "fc layer 3 self.abs_max_out: 844.0\n",
      "fc layer 3 self.abs_max_out: 870.0\n",
      "fc layer 3 self.abs_max_out: 882.0\n",
      "lif layer 1 self.abs_max_v: 27184.5\n",
      "fc layer 3 self.abs_max_out: 887.0\n",
      "fc layer 2 self.abs_max_out: 3534.0\n",
      "fc layer 1 self.abs_max_out: 16790.0\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 3867.00 at epoch 14, iter 4031\n",
      "max_activation_accul updated: 4037.00 at epoch 14, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-14  lr=['4.0000000'], tr/val_loss:360.948822/349.615936, val:  50.22%, val_best:  51.99%, tr:  94.92%, tr_best:  95.34%, epoch time: 228.84 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 72.7912%\n",
      "layer   3  Sparsity: 58.3548%\n",
      "total_backward_count 483840 real_backward_count 103285  21.347%\n",
      "layer   1  Sparsity: 94.1406%\n",
      "layer   2  Sparsity: 85.6250%\n",
      "layer   3  Sparsity: 74.8125%\n",
      "fc layer 3 self.abs_max_out: 890.0\n",
      "fc layer 3 self.abs_max_out: 921.0\n",
      "lif layer 1 self.abs_max_v: 27460.5\n",
      "fc layer 1 self.abs_max_out: 16807.0\n",
      "fc layer 1 self.abs_max_out: 16882.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-15  lr=['4.0000000'], tr/val_loss:363.043488/277.209534, val:  61.95%, val_best:  61.95%, tr:  94.62%, tr_best:  95.34%, epoch time: 224.05 seconds, 3.73 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 73.5609%\n",
      "layer   3  Sparsity: 57.5051%\n",
      "total_backward_count 516096 real_backward_count 109892  21.293%\n",
      "layer   1  Sparsity: 86.2793%\n",
      "layer   2  Sparsity: 76.2500%\n",
      "layer   3  Sparsity: 63.0000%\n",
      "fc layer 3 self.abs_max_out: 964.0\n",
      "lif layer 1 self.abs_max_v: 27638.5\n",
      "fc layer 1 self.abs_max_out: 16922.0\n",
      "lif layer 2 self.abs_max_v: 4852.5\n",
      "lif layer 2 self.abs_max_v: 4949.5\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4073.00 at epoch 16, iter 4031\n",
      "max_activation_accul updated: 4202.00 at epoch 16, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-16  lr=['4.0000000'], tr/val_loss:394.982941/357.179047, val:  51.11%, val_best:  61.95%, tr:  93.92%, tr_best:  95.34%, epoch time: 227.99 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 73.0942%\n",
      "layer   3  Sparsity: 58.2064%\n",
      "total_backward_count 548352 real_backward_count 116750  21.291%\n",
      "layer   1  Sparsity: 79.7119%\n",
      "layer   2  Sparsity: 66.2500%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "lif layer 2 self.abs_max_v: 4950.5\n",
      "lif layer 2 self.abs_max_v: 4969.0\n",
      "lif layer 2 self.abs_max_v: 4975.5\n",
      "lif layer 2 self.abs_max_v: 4988.0\n",
      "lif layer 2 self.abs_max_v: 5004.5\n",
      "lif layer 2 self.abs_max_v: 5015.0\n",
      "lif layer 2 self.abs_max_v: 5146.5\n",
      "fc layer 3 self.abs_max_out: 983.0\n",
      "lif layer 2 self.abs_max_v: 5211.5\n",
      "lif layer 2 self.abs_max_v: 5305.0\n",
      "lif layer 2 self.abs_max_v: 5426.5\n",
      "lif layer 2 self.abs_max_v: 5441.0\n",
      "lif layer 2 self.abs_max_v: 5623.5\n",
      "lif layer 2 self.abs_max_v: 5690.5\n",
      "lif layer 2 self.abs_max_v: 5710.5\n",
      "lif layer 2 self.abs_max_v: 5780.5\n",
      "lif layer 2 self.abs_max_v: 5893.0\n",
      "lif layer 2 self.abs_max_v: 5919.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-17  lr=['4.0000000'], tr/val_loss:400.354645/385.779846, val:  50.00%, val_best:  61.95%, tr:  93.30%, tr_best:  95.34%, epoch time: 227.11 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 73.0470%\n",
      "layer   3  Sparsity: 58.7923%\n",
      "total_backward_count 580608 real_backward_count 123562  21.281%\n",
      "layer   1  Sparsity: 76.7822%\n",
      "layer   2  Sparsity: 71.6875%\n",
      "layer   3  Sparsity: 49.8125%\n",
      "fc layer 2 self.abs_max_out: 3548.0\n",
      "fc layer 3 self.abs_max_out: 1028.0\n",
      "fc layer 2 self.abs_max_out: 3605.0\n",
      "lif layer 2 self.abs_max_v: 5923.0\n",
      "lif layer 2 self.abs_max_v: 6014.0\n",
      "fc layer 2 self.abs_max_out: 3727.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['4.0000000'], tr/val_loss:399.163361/432.610168, val:  50.00%, val_best:  61.95%, tr:  93.75%, tr_best:  95.34%, epoch time: 228.27 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 72.8296%\n",
      "layer   3  Sparsity: 58.8864%\n",
      "total_backward_count 612864 real_backward_count 130380  21.274%\n",
      "layer   1  Sparsity: 88.8184%\n",
      "layer   2  Sparsity: 79.3750%\n",
      "layer   3  Sparsity: 70.3125%\n",
      "lif layer 2 self.abs_max_v: 6068.0\n",
      "lif layer 2 self.abs_max_v: 6080.5\n",
      "lif layer 2 self.abs_max_v: 6104.0\n",
      "lif layer 2 self.abs_max_v: 6133.0\n",
      "lif layer 2 self.abs_max_v: 6168.0\n",
      "lif layer 2 self.abs_max_v: 6173.0\n",
      "lif layer 2 self.abs_max_v: 6338.0\n",
      "fc layer 3 self.abs_max_out: 1037.0\n",
      "fc layer 2 self.abs_max_out: 3763.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4205.00 at epoch 19, iter 4031\n",
      "max_activation_accul updated: 4242.00 at epoch 19, iter 4031\n",
      "max_activation_accul updated: 4412.00 at epoch 19, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-19  lr=['4.0000000'], tr/val_loss:378.492493/386.903107, val:  50.00%, val_best:  61.95%, tr:  93.85%, tr_best:  95.34%, epoch time: 228.26 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 73.1636%\n",
      "layer   3  Sparsity: 59.0736%\n",
      "total_backward_count 645120 real_backward_count 137213  21.269%\n",
      "layer   1  Sparsity: 83.1787%\n",
      "layer   2  Sparsity: 68.0625%\n",
      "layer   3  Sparsity: 54.3125%\n",
      "fc layer 2 self.abs_max_out: 3783.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 346 occurrences\n",
      "test - Value 1: 106 occurrences\n",
      "epoch-20  lr=['4.0000000'], tr/val_loss:392.755341/325.101074, val:  66.37%, val_best:  66.37%, tr:  93.80%, tr_best:  95.34%, epoch time: 229.45 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 73.2304%\n",
      "layer   3  Sparsity: 59.9927%\n",
      "total_backward_count 677376 real_backward_count 144160  21.282%\n",
      "layer   1  Sparsity: 86.4746%\n",
      "layer   2  Sparsity: 77.5625%\n",
      "layer   3  Sparsity: 60.8750%\n",
      "fc layer 1 self.abs_max_out: 17004.0\n",
      "lif layer 1 self.abs_max_v: 27855.0\n",
      "fc layer 1 self.abs_max_out: 17138.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-21  lr=['4.0000000'], tr/val_loss:382.006927/361.439453, val:  55.97%, val_best:  66.37%, tr:  93.28%, tr_best:  95.34%, epoch time: 228.26 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 73.1723%\n",
      "layer   3  Sparsity: 60.3872%\n",
      "total_backward_count 709632 real_backward_count 151079  21.290%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 74.8750%\n",
      "layer   3  Sparsity: 64.1250%\n",
      "lif layer 1 self.abs_max_v: 28026.0\n",
      "fc layer 3 self.abs_max_out: 1070.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 10 occurrences\n",
      "test - Value 1: 442 occurrences\n",
      "epoch-22  lr=['4.0000000'], tr/val_loss:391.297333/361.800293, val:  51.77%, val_best:  66.37%, tr:  92.76%, tr_best:  95.34%, epoch time: 229.68 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 72.7414%\n",
      "layer   3  Sparsity: 61.2590%\n",
      "total_backward_count 741888 real_backward_count 158025  21.300%\n",
      "layer   1  Sparsity: 77.0264%\n",
      "layer   2  Sparsity: 68.5625%\n",
      "layer   3  Sparsity: 52.7500%\n",
      "fc layer 2 self.abs_max_out: 3873.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 4500.00 at epoch 23, iter 4031\n",
      "max_activation_accul updated: 5113.00 at epoch 23, iter 4031\n",
      "max_activation_accul updated: 5126.00 at epoch 23, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['4.0000000'], tr/val_loss:385.173828/433.205688, val:  50.00%, val_best:  66.37%, tr:  93.33%, tr_best:  95.34%, epoch time: 229.39 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 72.1400%\n",
      "layer   3  Sparsity: 60.8291%\n",
      "total_backward_count 774144 real_backward_count 164926  21.304%\n",
      "layer   1  Sparsity: 76.9287%\n",
      "layer   2  Sparsity: 68.0625%\n",
      "layer   3  Sparsity: 51.4375%\n",
      "fc layer 2 self.abs_max_out: 3885.0\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-24  lr=['4.0000000'], tr/val_loss:383.696350/353.511078, val:  50.66%, val_best:  66.37%, tr:  93.65%, tr_best:  95.34%, epoch time: 229.46 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 72.2213%\n",
      "layer   3  Sparsity: 60.0649%\n",
      "total_backward_count 806400 real_backward_count 171792  21.304%\n",
      "layer   1  Sparsity: 74.2432%\n",
      "layer   2  Sparsity: 71.8750%\n",
      "layer   3  Sparsity: 52.8125%\n",
      "fc layer 2 self.abs_max_out: 3951.0\n",
      "fc layer 2 self.abs_max_out: 4243.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-25  lr=['4.0000000'], tr/val_loss:367.294403/354.147125, val:  51.33%, val_best:  66.37%, tr:  94.10%, tr_best:  95.34%, epoch time: 230.05 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 72.8119%\n",
      "layer   3  Sparsity: 58.5314%\n",
      "total_backward_count 838656 real_backward_count 178470  21.280%\n",
      "layer   1  Sparsity: 77.8564%\n",
      "layer   2  Sparsity: 72.3750%\n",
      "layer   3  Sparsity: 54.0625%\n",
      "fc layer 3 self.abs_max_out: 1106.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['4.0000000'], tr/val_loss:395.753601/419.425537, val:  50.00%, val_best:  66.37%, tr:  94.02%, tr_best:  95.34%, epoch time: 229.63 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 72.6005%\n",
      "layer   3  Sparsity: 57.5730%\n",
      "total_backward_count 870912 real_backward_count 185301  21.277%\n",
      "layer   1  Sparsity: 73.9990%\n",
      "layer   2  Sparsity: 70.3125%\n",
      "layer   3  Sparsity: 51.5000%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-27  lr=['4.0000000'], tr/val_loss:412.418701/375.811768, val:  50.00%, val_best:  66.37%, tr:  94.12%, tr_best:  95.34%, epoch time: 228.32 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6669%\n",
      "layer   2  Sparsity: 72.9085%\n",
      "layer   3  Sparsity: 57.1954%\n",
      "total_backward_count 903168 real_backward_count 192202  21.281%\n",
      "layer   1  Sparsity: 81.9824%\n",
      "layer   2  Sparsity: 69.5000%\n",
      "layer   3  Sparsity: 59.8125%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['4.0000000'], tr/val_loss:393.544708/429.707001, val:  50.00%, val_best:  66.37%, tr:  94.39%, tr_best:  95.34%, epoch time: 228.84 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 72.6635%\n",
      "layer   3  Sparsity: 56.7034%\n",
      "total_backward_count 935424 real_backward_count 199094  21.284%\n",
      "layer   1  Sparsity: 82.2998%\n",
      "layer   2  Sparsity: 70.1250%\n",
      "layer   3  Sparsity: 53.0000%\n",
      "lif layer 1 self.abs_max_v: 28750.0\n",
      "fc layer 1 self.abs_max_out: 17679.0\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['4.0000000'], tr/val_loss:433.025726/449.072571, val:  50.00%, val_best:  66.37%, tr:  94.02%, tr_best:  95.34%, epoch time: 227.39 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 71.7206%\n",
      "layer   3  Sparsity: 54.8577%\n",
      "total_backward_count 967680 real_backward_count 205935  21.281%\n",
      "layer   1  Sparsity: 90.6250%\n",
      "layer   2  Sparsity: 73.6875%\n",
      "layer   3  Sparsity: 56.1875%\n",
      "lif layer 1 self.abs_max_v: 28782.5\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 5148.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5437.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5577.00 at epoch 30, iter 4031\n",
      "max_activation_accul updated: 5780.00 at epoch 30, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['4.0000000'], tr/val_loss:465.825104/543.263123, val:  50.00%, val_best:  66.37%, tr:  94.62%, tr_best:  95.34%, epoch time: 229.21 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 70.4603%\n",
      "layer   3  Sparsity: 56.0354%\n",
      "total_backward_count 999936 real_backward_count 212885  21.290%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 46.7500%\n",
      "lif layer 2 self.abs_max_v: 6520.0\n",
      "fc layer 3 self.abs_max_out: 1135.0\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-31  lr=['4.0000000'], tr/val_loss:484.387299/462.949982, val:  51.11%, val_best:  66.37%, tr:  94.20%, tr_best:  95.34%, epoch time: 230.08 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 71.4300%\n",
      "layer   3  Sparsity: 57.1238%\n",
      "total_backward_count 1032192 real_backward_count 219752  21.290%\n",
      "layer   1  Sparsity: 76.0986%\n",
      "layer   2  Sparsity: 66.0625%\n",
      "layer   3  Sparsity: 50.0625%\n",
      "fc layer 2 self.abs_max_out: 4363.0\n",
      "lif layer 2 self.abs_max_v: 6554.0\n",
      "lif layer 2 self.abs_max_v: 6578.5\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 402 occurrences\n",
      "test - Value 1: 50 occurrences\n",
      "epoch-32  lr=['4.0000000'], tr/val_loss:483.446045/437.129913, val:  59.29%, val_best:  66.37%, tr:  94.30%, tr_best:  95.34%, epoch time: 229.36 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6664%\n",
      "layer   2  Sparsity: 70.9959%\n",
      "layer   3  Sparsity: 57.4060%\n",
      "total_backward_count 1064448 real_backward_count 226534  21.282%\n",
      "layer   1  Sparsity: 91.4795%\n",
      "layer   2  Sparsity: 75.4375%\n",
      "layer   3  Sparsity: 69.4375%\n",
      "lif layer 2 self.abs_max_v: 6624.5\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-33  lr=['4.0000000'], tr/val_loss:482.861816/459.373657, val:  51.33%, val_best:  66.37%, tr:  94.57%, tr_best:  95.34%, epoch time: 229.39 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6630%\n",
      "layer   2  Sparsity: 71.3263%\n",
      "layer   3  Sparsity: 57.3895%\n",
      "total_backward_count 1096704 real_backward_count 233371  21.279%\n",
      "layer   1  Sparsity: 76.0742%\n",
      "layer   2  Sparsity: 72.3125%\n",
      "layer   3  Sparsity: 56.1250%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-34  lr=['4.0000000'], tr/val_loss:477.020844/420.673920, val:  69.91%, val_best:  69.91%, tr:  94.82%, tr_best:  95.34%, epoch time: 224.26 seconds, 3.74 minutes\n",
      "layer   1  Sparsity: 82.6664%\n",
      "layer   2  Sparsity: 72.4567%\n",
      "layer   3  Sparsity: 56.5571%\n",
      "total_backward_count 1128960 real_backward_count 240160  21.273%\n",
      "layer   1  Sparsity: 88.6230%\n",
      "layer   2  Sparsity: 78.8125%\n",
      "layer   3  Sparsity: 67.8125%\n",
      "fc layer 2 self.abs_max_out: 4380.0\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-35  lr=['4.0000000'], tr/val_loss:478.716187/427.899353, val:  53.54%, val_best:  69.91%, tr:  94.89%, tr_best:  95.34%, epoch time: 227.28 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 72.4210%\n",
      "layer   3  Sparsity: 56.7744%\n",
      "total_backward_count 1161216 real_backward_count 246970  21.268%\n",
      "layer   1  Sparsity: 95.0195%\n",
      "layer   2  Sparsity: 76.5000%\n",
      "layer   3  Sparsity: 61.2500%\n",
      "fc layer 2 self.abs_max_out: 4422.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 445 occurrences\n",
      "test - Value 1: 7 occurrences\n",
      "epoch-36  lr=['4.0000000'], tr/val_loss:420.607086/355.840057, val:  51.11%, val_best:  69.91%, tr:  95.11%, tr_best:  95.34%, epoch time: 230.05 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 72.0088%\n",
      "layer   3  Sparsity: 57.4819%\n",
      "total_backward_count 1193472 real_backward_count 253845  21.269%\n",
      "layer   1  Sparsity: 81.8848%\n",
      "layer   2  Sparsity: 70.1250%\n",
      "layer   3  Sparsity: 54.9375%\n",
      "lif layer 1 self.abs_max_v: 29124.0\n",
      "lif layer 1 self.abs_max_v: 29440.0\n",
      "lif layer 1 self.abs_max_v: 29763.0\n",
      "fc layer 1 self.abs_max_out: 17729.0\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-37  lr=['4.0000000'], tr/val_loss:413.704315/367.749207, val:  50.44%, val_best:  69.91%, tr:  94.49%, tr_best:  95.34%, epoch time: 227.13 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 71.9653%\n",
      "layer   3  Sparsity: 57.3391%\n",
      "total_backward_count 1225728 real_backward_count 260700  21.269%\n",
      "layer   1  Sparsity: 71.6797%\n",
      "layer   2  Sparsity: 72.0625%\n",
      "layer   3  Sparsity: 50.7500%\n",
      "fc layer 2 self.abs_max_out: 4650.0\n",
      "fc layer 2 self.abs_max_out: 4657.0\n",
      "fc layer 2 self.abs_max_out: 4751.0\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-38  lr=['4.0000000'], tr/val_loss:371.221832/329.620453, val:  50.88%, val_best:  69.91%, tr:  94.69%, tr_best:  95.34%, epoch time: 228.82 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 71.3275%\n",
      "layer   3  Sparsity: 58.0606%\n",
      "total_backward_count 1257984 real_backward_count 267573  21.270%\n",
      "layer   1  Sparsity: 84.0088%\n",
      "layer   2  Sparsity: 71.8125%\n",
      "layer   3  Sparsity: 49.6250%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['4.0000000'], tr/val_loss:401.782776/469.391479, val:  50.00%, val_best:  69.91%, tr:  94.82%, tr_best:  95.34%, epoch time: 229.09 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 71.2037%\n",
      "layer   3  Sparsity: 54.4962%\n",
      "total_backward_count 1290240 real_backward_count 274437  21.270%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 62.9375%\n",
      "layer   3  Sparsity: 39.4375%\n",
      "fc layer 2 self.abs_max_out: 4793.0\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-40  lr=['4.0000000'], tr/val_loss:412.760437/294.399689, val:  53.10%, val_best:  69.91%, tr:  95.49%, tr_best:  95.49%, epoch time: 228.55 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 70.7215%\n",
      "layer   3  Sparsity: 52.7384%\n",
      "total_backward_count 1322496 real_backward_count 281053  21.252%\n",
      "layer   1  Sparsity: 84.2773%\n",
      "layer   2  Sparsity: 75.2500%\n",
      "layer   3  Sparsity: 55.4375%\n",
      "fc layer 2 self.abs_max_out: 4808.0\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['4.0000000'], tr/val_loss:355.605011/291.087524, val:  50.00%, val_best:  69.91%, tr:  95.71%, tr_best:  95.71%, epoch time: 229.70 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 70.4382%\n",
      "layer   3  Sparsity: 53.2100%\n",
      "total_backward_count 1354752 real_backward_count 287805  21.244%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 63.5625%\n",
      "layer   3  Sparsity: 39.3125%\n",
      "fc layer 2 self.abs_max_out: 5266.0\n",
      "fc layer 1 self.abs_max_out: 17844.0\n",
      "lif layer 1 self.abs_max_v: 31742.0\n",
      "lif layer 1 self.abs_max_v: 32115.0\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['4.0000000'], tr/val_loss:337.185364/174.589081, val:  50.00%, val_best:  69.91%, tr:  94.59%, tr_best:  95.71%, epoch time: 229.28 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 69.4330%\n",
      "layer   3  Sparsity: 51.6371%\n",
      "total_backward_count 1387008 real_backward_count 294585  21.239%\n",
      "layer   1  Sparsity: 80.7861%\n",
      "layer   2  Sparsity: 68.2500%\n",
      "layer   3  Sparsity: 45.3750%\n",
      "fc layer 2 self.abs_max_out: 5272.0\n",
      "fc layer 2 self.abs_max_out: 5273.0\n",
      "fc layer 2 self.abs_max_out: 5405.0\n",
      "fc layer 2 self.abs_max_out: 5489.0\n",
      "fc layer 1 self.abs_max_out: 17892.0\n",
      "train - Value 0: 1959 occurrences\n",
      "train - Value 1: 2073 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "fc layer 1 self.abs_max_out: 18133.0\n",
      "fc layer 1 self.abs_max_out: 18143.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-43  lr=['4.0000000'], tr/val_loss:292.501923/315.864502, val:  50.66%, val_best:  69.91%, tr:  93.87%, tr_best:  95.71%, epoch time: 228.96 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 69.7873%\n",
      "layer   3  Sparsity: 50.3874%\n",
      "total_backward_count 1419264 real_backward_count 301564  21.248%\n",
      "layer   1  Sparsity: 89.6240%\n",
      "layer   2  Sparsity: 76.3125%\n",
      "layer   3  Sparsity: 62.5000%\n",
      "fc layer 1 self.abs_max_out: 18464.0\n",
      "fc layer 1 self.abs_max_out: 18532.0\n",
      "fc layer 2 self.abs_max_out: 5533.0\n",
      "fc layer 1 self.abs_max_out: 18709.0\n",
      "fc layer 1 self.abs_max_out: 18773.0\n",
      "fc layer 1 self.abs_max_out: 18850.0\n",
      "lif layer 1 self.abs_max_v: 32957.5\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['4.0000000'], tr/val_loss:298.388153/308.157135, val:  50.00%, val_best:  69.91%, tr:  93.06%, tr_best:  95.71%, epoch time: 229.22 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 69.6926%\n",
      "layer   3  Sparsity: 48.8160%\n",
      "total_backward_count 1451520 real_backward_count 308854  21.278%\n",
      "layer   1  Sparsity: 83.5449%\n",
      "layer   2  Sparsity: 71.0625%\n",
      "layer   3  Sparsity: 50.3125%\n",
      "fc layer 3 self.abs_max_out: 1188.0\n",
      "fc layer 2 self.abs_max_out: 5576.0\n",
      "fc layer 2 self.abs_max_out: 5733.0\n",
      "fc layer 3 self.abs_max_out: 1203.0\n",
      "lif layer 2 self.abs_max_v: 6649.0\n",
      "lif layer 2 self.abs_max_v: 6834.0\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 303 occurrences\n",
      "test - Value 1: 149 occurrences\n",
      "epoch-45  lr=['4.0000000'], tr/val_loss:296.225433/214.596115, val:  60.40%, val_best:  69.91%, tr:  92.78%, tr_best:  95.71%, epoch time: 230.47 seconds, 3.84 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 66.8387%\n",
      "layer   3  Sparsity: 46.0955%\n",
      "total_backward_count 1483776 real_backward_count 316115  21.305%\n",
      "layer   1  Sparsity: 94.3604%\n",
      "layer   2  Sparsity: 73.8750%\n",
      "layer   3  Sparsity: 57.8750%\n",
      "lif layer 2 self.abs_max_v: 6841.5\n",
      "lif layer 2 self.abs_max_v: 6896.0\n",
      "lif layer 2 self.abs_max_v: 6906.0\n",
      "lif layer 2 self.abs_max_v: 7007.0\n",
      "lif layer 2 self.abs_max_v: 7078.0\n",
      "fc layer 2 self.abs_max_out: 5763.0\n",
      "fc layer 2 self.abs_max_out: 5856.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-46  lr=['4.0000000'], tr/val_loss:267.988098/318.233978, val:  50.00%, val_best:  69.91%, tr:  93.58%, tr_best:  95.71%, epoch time: 230.31 seconds, 3.84 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 65.6085%\n",
      "layer   3  Sparsity: 45.2170%\n",
      "total_backward_count 1516032 real_backward_count 323482  21.337%\n",
      "layer   1  Sparsity: 76.4893%\n",
      "layer   2  Sparsity: 63.3125%\n",
      "layer   3  Sparsity: 30.3750%\n",
      "fc layer 2 self.abs_max_out: 5935.0\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 409 occurrences\n",
      "test - Value 1: 43 occurrences\n",
      "epoch-47  lr=['4.0000000'], tr/val_loss:382.397644/331.405914, val:  56.42%, val_best:  69.91%, tr:  95.86%, tr_best:  95.86%, epoch time: 229.12 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 66.4153%\n",
      "layer   3  Sparsity: 44.6371%\n",
      "total_backward_count 1548288 real_backward_count 330341  21.336%\n",
      "layer   1  Sparsity: 85.2783%\n",
      "layer   2  Sparsity: 69.4375%\n",
      "layer   3  Sparsity: 49.4375%\n",
      "fc layer 3 self.abs_max_out: 1250.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 6144.00 at epoch 48, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-48  lr=['4.0000000'], tr/val_loss:347.977936/574.594666, val:  50.66%, val_best:  69.91%, tr:  95.41%, tr_best:  95.86%, epoch time: 227.95 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 64.8292%\n",
      "layer   3  Sparsity: 44.1161%\n",
      "total_backward_count 1580544 real_backward_count 337195  21.334%\n",
      "layer   1  Sparsity: 90.0635%\n",
      "layer   2  Sparsity: 73.1250%\n",
      "layer   3  Sparsity: 49.4375%\n",
      "fc layer 3 self.abs_max_out: 1282.0\n",
      "fc layer 3 self.abs_max_out: 1326.0\n",
      "lif layer 2 self.abs_max_v: 7097.0\n",
      "fc layer 3 self.abs_max_out: 1386.0\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 6214.00 at epoch 49, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['4.0000000'], tr/val_loss:655.691772/624.446838, val:  50.00%, val_best:  69.91%, tr:  97.07%, tr_best:  97.07%, epoch time: 229.81 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 64.3788%\n",
      "layer   3  Sparsity: 43.8679%\n",
      "total_backward_count 1612800 real_backward_count 343546  21.301%\n",
      "layer   1  Sparsity: 82.8613%\n",
      "layer   2  Sparsity: 66.3750%\n",
      "layer   3  Sparsity: 48.9375%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-50  lr=['4.0000000'], tr/val_loss:676.884888/591.521057, val:  50.66%, val_best:  69.91%, tr:  97.40%, tr_best:  97.40%, epoch time: 227.86 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 65.3439%\n",
      "layer   3  Sparsity: 42.7701%\n",
      "total_backward_count 1645056 real_backward_count 349883  21.269%\n",
      "layer   1  Sparsity: 77.3926%\n",
      "layer   2  Sparsity: 68.3750%\n",
      "layer   3  Sparsity: 47.1875%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['4.0000000'], tr/val_loss:642.868164/554.555298, val:  50.00%, val_best:  69.91%, tr:  96.75%, tr_best:  97.40%, epoch time: 229.84 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6661%\n",
      "layer   2  Sparsity: 65.0651%\n",
      "layer   3  Sparsity: 42.7841%\n",
      "total_backward_count 1677312 real_backward_count 356283  21.241%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 70.0625%\n",
      "layer   3  Sparsity: 47.5625%\n",
      "lif layer 2 self.abs_max_v: 7249.5\n",
      "lif layer 2 self.abs_max_v: 7284.0\n",
      "lif layer 2 self.abs_max_v: 7320.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-52  lr=['4.0000000'], tr/val_loss:569.751099/556.472534, val:  50.00%, val_best:  69.91%, tr:  97.22%, tr_best:  97.40%, epoch time: 229.37 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6637%\n",
      "layer   2  Sparsity: 63.9820%\n",
      "layer   3  Sparsity: 43.4919%\n",
      "total_backward_count 1709568 real_backward_count 362497  21.204%\n",
      "layer   1  Sparsity: 92.7490%\n",
      "layer   2  Sparsity: 67.3125%\n",
      "layer   3  Sparsity: 51.8750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-53  lr=['4.0000000'], tr/val_loss:465.990173/536.146912, val:  50.00%, val_best:  69.91%, tr:  96.80%, tr_best:  97.40%, epoch time: 226.03 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 65.0647%\n",
      "layer   3  Sparsity: 43.1115%\n",
      "total_backward_count 1741824 real_backward_count 368833  21.175%\n",
      "layer   1  Sparsity: 87.5000%\n",
      "layer   2  Sparsity: 61.6875%\n",
      "layer   3  Sparsity: 41.1250%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-54  lr=['4.0000000'], tr/val_loss:573.709229/486.874573, val:  50.66%, val_best:  69.91%, tr:  97.25%, tr_best:  97.40%, epoch time: 229.25 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 65.4498%\n",
      "layer   3  Sparsity: 42.7646%\n",
      "total_backward_count 1774080 real_backward_count 375070  21.142%\n",
      "layer   1  Sparsity: 82.2510%\n",
      "layer   2  Sparsity: 62.0625%\n",
      "layer   3  Sparsity: 37.3125%\n",
      "lif layer 2 self.abs_max_v: 7423.5\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-55  lr=['4.0000000'], tr/val_loss:555.157288/494.153931, val:  58.41%, val_best:  69.91%, tr:  97.35%, tr_best:  97.40%, epoch time: 228.77 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 65.1714%\n",
      "layer   3  Sparsity: 42.9672%\n",
      "total_backward_count 1806336 real_backward_count 381336  21.111%\n",
      "layer   1  Sparsity: 82.3242%\n",
      "layer   2  Sparsity: 65.8750%\n",
      "layer   3  Sparsity: 38.7500%\n",
      "lif layer 2 self.abs_max_v: 7526.0\n",
      "lif layer 2 self.abs_max_v: 7529.5\n",
      "lif layer 2 self.abs_max_v: 7611.5\n",
      "lif layer 2 self.abs_max_v: 7645.5\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 6530.00 at epoch 56, iter 4031\n",
      "max_activation_accul updated: 7168.00 at epoch 56, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-56  lr=['4.0000000'], tr/val_loss:626.245300/656.433838, val:  50.00%, val_best:  69.91%, tr:  96.97%, tr_best:  97.40%, epoch time: 229.48 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 63.8769%\n",
      "layer   3  Sparsity: 41.2996%\n",
      "total_backward_count 1838592 real_backward_count 387515  21.077%\n",
      "layer   1  Sparsity: 90.3564%\n",
      "layer   2  Sparsity: 71.3125%\n",
      "layer   3  Sparsity: 55.5000%\n",
      "lif layer 2 self.abs_max_v: 7674.0\n",
      "lif layer 2 self.abs_max_v: 7717.5\n",
      "lif layer 2 self.abs_max_v: 7804.0\n",
      "lif layer 2 self.abs_max_v: 7901.0\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 7379.00 at epoch 57, iter 4031\n",
      "max_activation_accul updated: 7445.00 at epoch 57, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-57  lr=['4.0000000'], tr/val_loss:748.017151/727.933289, val:  50.22%, val_best:  69.91%, tr:  97.62%, tr_best:  97.62%, epoch time: 228.32 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 63.9966%\n",
      "layer   3  Sparsity: 38.9679%\n",
      "total_backward_count 1870848 real_backward_count 393892  21.054%\n",
      "layer   1  Sparsity: 92.8955%\n",
      "layer   2  Sparsity: 77.3125%\n",
      "layer   3  Sparsity: 62.5625%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 7460.00 at epoch 58, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-58  lr=['4.0000000'], tr/val_loss:793.998413/704.850586, val:  51.11%, val_best:  69.91%, tr:  97.37%, tr_best:  97.62%, epoch time: 227.52 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 64.1178%\n",
      "layer   3  Sparsity: 39.2257%\n",
      "total_backward_count 1903104 real_backward_count 400264  21.032%\n",
      "layer   1  Sparsity: 79.9316%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 25.3750%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 104 occurrences\n",
      "test - Value 1: 348 occurrences\n",
      "epoch-59  lr=['4.0000000'], tr/val_loss:781.371643/674.409790, val:  61.95%, val_best:  69.91%, tr:  97.32%, tr_best:  97.62%, epoch time: 231.85 seconds, 3.86 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 64.2398%\n",
      "layer   3  Sparsity: 39.3299%\n",
      "total_backward_count 1935360 real_backward_count 406600  21.009%\n",
      "layer   1  Sparsity: 84.2773%\n",
      "layer   2  Sparsity: 66.3125%\n",
      "layer   3  Sparsity: 43.8750%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 7461.00 at epoch 60, iter 4031\n",
      "max_activation_accul updated: 7531.00 at epoch 60, iter 4031\n",
      "max_activation_accul updated: 7586.00 at epoch 60, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-60  lr=['4.0000000'], tr/val_loss:753.720093/733.189209, val:  50.22%, val_best:  69.91%, tr:  97.07%, tr_best:  97.62%, epoch time: 248.63 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 63.7289%\n",
      "layer   3  Sparsity: 39.7782%\n",
      "total_backward_count 1967616 real_backward_count 412959  20.988%\n",
      "layer   1  Sparsity: 75.9766%\n",
      "layer   2  Sparsity: 54.6875%\n",
      "layer   3  Sparsity: 25.7500%\n",
      "lif layer 2 self.abs_max_v: 7947.5\n",
      "lif layer 2 self.abs_max_v: 8029.0\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['4.0000000'], tr/val_loss:589.206055/636.435547, val:  50.00%, val_best:  69.91%, tr:  96.50%, tr_best:  97.62%, epoch time: 246.87 seconds, 4.11 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 61.8216%\n",
      "layer   3  Sparsity: 39.2219%\n",
      "total_backward_count 1999872 real_backward_count 419414  20.972%\n",
      "layer   1  Sparsity: 79.2969%\n",
      "layer   2  Sparsity: 61.0625%\n",
      "layer   3  Sparsity: 34.2500%\n",
      "lif layer 2 self.abs_max_v: 8237.5\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-62  lr=['4.0000000'], tr/val_loss:729.430542/686.665649, val:  50.44%, val_best:  69.91%, tr:  96.95%, tr_best:  97.62%, epoch time: 248.29 seconds, 4.14 minutes\n",
      "layer   1  Sparsity: 82.6657%\n",
      "layer   2  Sparsity: 62.2799%\n",
      "layer   3  Sparsity: 38.2559%\n",
      "total_backward_count 2032128 real_backward_count 425798  20.953%\n",
      "layer   1  Sparsity: 81.5674%\n",
      "layer   2  Sparsity: 59.8125%\n",
      "layer   3  Sparsity: 37.6875%\n",
      "train - Value 0: 1973 occurrences\n",
      "train - Value 1: 2059 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-63  lr=['4.0000000'], tr/val_loss:722.370728/620.140381, val:  50.88%, val_best:  69.91%, tr:  96.95%, tr_best:  97.62%, epoch time: 244.44 seconds, 4.07 minutes\n",
      "layer   1  Sparsity: 82.6652%\n",
      "layer   2  Sparsity: 61.8967%\n",
      "layer   3  Sparsity: 38.6727%\n",
      "total_backward_count 2064384 real_backward_count 432284  20.940%\n",
      "layer   1  Sparsity: 80.0049%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 34.5625%\n",
      "lif layer 2 self.abs_max_v: 8334.5\n",
      "lif layer 2 self.abs_max_v: 8517.0\n",
      "lif layer 2 self.abs_max_v: 8620.0\n",
      "lif layer 2 self.abs_max_v: 8756.0\n",
      "lif layer 2 self.abs_max_v: 8764.0\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-64  lr=['4.0000000'], tr/val_loss:677.676941/582.664124, val:  50.00%, val_best:  69.91%, tr:  96.90%, tr_best:  97.62%, epoch time: 226.29 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 62.3488%\n",
      "layer   3  Sparsity: 35.2446%\n",
      "total_backward_count 2096640 real_backward_count 438737  20.926%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 62.4375%\n",
      "layer   3  Sparsity: 37.1875%\n",
      "lif layer 2 self.abs_max_v: 8892.0\n",
      "fc layer 2 self.abs_max_out: 6042.0\n",
      "fc layer 2 self.abs_max_out: 6080.0\n",
      "fc layer 2 self.abs_max_out: 6111.0\n",
      "fc layer 2 self.abs_max_out: 6115.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-65  lr=['4.0000000'], tr/val_loss:651.982178/647.141113, val:  50.00%, val_best:  69.91%, tr:  97.17%, tr_best:  97.62%, epoch time: 227.30 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 62.5799%\n",
      "layer   3  Sparsity: 32.5729%\n",
      "total_backward_count 2128896 real_backward_count 445041  20.905%\n",
      "layer   1  Sparsity: 90.0635%\n",
      "layer   2  Sparsity: 68.4375%\n",
      "layer   3  Sparsity: 41.0625%\n",
      "fc layer 2 self.abs_max_out: 6150.0\n",
      "fc layer 2 self.abs_max_out: 6163.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-66  lr=['4.0000000'], tr/val_loss:711.921265/667.866516, val:  50.00%, val_best:  69.91%, tr:  97.15%, tr_best:  97.62%, epoch time: 228.57 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 61.9550%\n",
      "layer   3  Sparsity: 33.4787%\n",
      "total_backward_count 2161152 real_backward_count 451415  20.888%\n",
      "layer   1  Sparsity: 79.6875%\n",
      "layer   2  Sparsity: 60.6875%\n",
      "layer   3  Sparsity: 30.1250%\n",
      "fc layer 2 self.abs_max_out: 6194.0\n",
      "train - Value 0: 2030 occurrences\n",
      "train - Value 1: 2002 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 362 occurrences\n",
      "test - Value 1: 90 occurrences\n",
      "epoch-67  lr=['4.0000000'], tr/val_loss:747.471802/636.812500, val:  65.93%, val_best:  69.91%, tr:  97.17%, tr_best:  97.62%, epoch time: 228.38 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 62.1494%\n",
      "layer   3  Sparsity: 33.3262%\n",
      "total_backward_count 2193408 real_backward_count 457780  20.871%\n",
      "layer   1  Sparsity: 84.0088%\n",
      "layer   2  Sparsity: 58.8750%\n",
      "layer   3  Sparsity: 28.0000%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['4.0000000'], tr/val_loss:743.300476/723.461487, val:  50.00%, val_best:  69.91%, tr:  97.32%, tr_best:  97.62%, epoch time: 228.19 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 62.3082%\n",
      "layer   3  Sparsity: 33.1904%\n",
      "total_backward_count 2225664 real_backward_count 464247  20.859%\n",
      "layer   1  Sparsity: 90.7715%\n",
      "layer   2  Sparsity: 72.0625%\n",
      "layer   3  Sparsity: 49.3125%\n",
      "fc layer 2 self.abs_max_out: 6245.0\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-69  lr=['4.0000000'], tr/val_loss:737.006287/676.090515, val:  50.44%, val_best:  69.91%, tr:  97.20%, tr_best:  97.62%, epoch time: 229.90 seconds, 3.83 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 62.7360%\n",
      "layer   3  Sparsity: 33.0838%\n",
      "total_backward_count 2257920 real_backward_count 470656  20.845%\n",
      "layer   1  Sparsity: 78.4668%\n",
      "layer   2  Sparsity: 49.5000%\n",
      "layer   3  Sparsity: 18.6875%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 7916.00 at epoch 70, iter 4031\n",
      "max_activation_accul updated: 8012.00 at epoch 70, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-70  lr=['4.0000000'], tr/val_loss:734.002075/748.362732, val:  50.00%, val_best:  69.91%, tr:  97.32%, tr_best:  97.62%, epoch time: 228.75 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 62.6303%\n",
      "layer   3  Sparsity: 33.3825%\n",
      "total_backward_count 2290176 real_backward_count 477000  20.828%\n",
      "layer   1  Sparsity: 74.6094%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 30.3750%\n",
      "fc layer 2 self.abs_max_out: 6252.0\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-71  lr=['4.0000000'], tr/val_loss:744.380859/673.174133, val:  50.00%, val_best:  69.91%, tr:  97.57%, tr_best:  97.62%, epoch time: 227.50 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 62.7281%\n",
      "layer   3  Sparsity: 33.5631%\n",
      "total_backward_count 2322432 real_backward_count 483493  20.818%\n",
      "layer   1  Sparsity: 80.7861%\n",
      "layer   2  Sparsity: 60.4375%\n",
      "layer   3  Sparsity: 27.9375%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-72  lr=['4.0000000'], tr/val_loss:745.141113/751.508362, val:  50.00%, val_best:  69.91%, tr:  97.62%, tr_best:  97.62%, epoch time: 226.74 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 62.6417%\n",
      "layer   3  Sparsity: 33.4560%\n",
      "total_backward_count 2354688 real_backward_count 489887  20.805%\n",
      "layer   1  Sparsity: 83.0078%\n",
      "layer   2  Sparsity: 58.9375%\n",
      "layer   3  Sparsity: 29.2500%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-73  lr=['4.0000000'], tr/val_loss:739.801270/676.718933, val:  50.00%, val_best:  69.91%, tr:  97.47%, tr_best:  97.62%, epoch time: 227.26 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 62.7752%\n",
      "layer   3  Sparsity: 33.7423%\n",
      "total_backward_count 2386944 real_backward_count 496230  20.789%\n",
      "layer   1  Sparsity: 88.0859%\n",
      "layer   2  Sparsity: 70.3125%\n",
      "layer   3  Sparsity: 50.1250%\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-74  lr=['4.0000000'], tr/val_loss:745.183594/738.171448, val:  50.00%, val_best:  69.91%, tr:  97.77%, tr_best:  97.77%, epoch time: 226.85 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 62.7608%\n",
      "layer   3  Sparsity: 33.3432%\n",
      "total_backward_count 2419200 real_backward_count 502514  20.772%\n",
      "layer   1  Sparsity: 86.9141%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 49.1875%\n",
      "train - Value 0: 1976 occurrences\n",
      "train - Value 1: 2056 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-75  lr=['4.0000000'], tr/val_loss:737.420715/711.288513, val:  50.00%, val_best:  69.91%, tr:  97.17%, tr_best:  97.77%, epoch time: 228.84 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 62.9107%\n",
      "layer   3  Sparsity: 33.4468%\n",
      "total_backward_count 2451456 real_backward_count 508930  20.760%\n",
      "layer   1  Sparsity: 88.3301%\n",
      "layer   2  Sparsity: 66.3750%\n",
      "layer   3  Sparsity: 39.5625%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-76  lr=['4.0000000'], tr/val_loss:742.351990/673.378601, val:  50.22%, val_best:  69.91%, tr:  97.69%, tr_best:  97.77%, epoch time: 231.73 seconds, 3.86 minutes\n",
      "layer   1  Sparsity: 82.6637%\n",
      "layer   2  Sparsity: 62.4379%\n",
      "layer   3  Sparsity: 33.5874%\n",
      "total_backward_count 2483712 real_backward_count 515289  20.747%\n",
      "layer   1  Sparsity: 78.9062%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 17.9375%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 424 occurrences\n",
      "test - Value 1: 28 occurrences\n",
      "epoch-77  lr=['4.0000000'], tr/val_loss:730.356018/640.475525, val:  56.19%, val_best:  69.91%, tr:  97.45%, tr_best:  97.77%, epoch time: 225.10 seconds, 3.75 minutes\n",
      "layer   1  Sparsity: 82.6658%\n",
      "layer   2  Sparsity: 62.6376%\n",
      "layer   3  Sparsity: 33.1489%\n",
      "total_backward_count 2515968 real_backward_count 521629  20.733%\n",
      "layer   1  Sparsity: 79.7363%\n",
      "layer   2  Sparsity: 61.3125%\n",
      "layer   3  Sparsity: 28.8750%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 8145.00 at epoch 78, iter 4031\n",
      "max_activation_accul updated: 8155.00 at epoch 78, iter 4031\n",
      "max_activation_accul updated: 8334.00 at epoch 78, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-78  lr=['4.0000000'], tr/val_loss:708.887939/797.230469, val:  50.00%, val_best:  69.91%, tr:  97.20%, tr_best:  97.77%, epoch time: 229.20 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 63.1430%\n",
      "layer   3  Sparsity: 33.1132%\n",
      "total_backward_count 2548224 real_backward_count 527919  20.717%\n",
      "layer   1  Sparsity: 87.4512%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 32.6250%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 185 occurrences\n",
      "test - Value 1: 267 occurrences\n",
      "epoch-79  lr=['4.0000000'], tr/val_loss:709.039124/566.182495, val:  72.79%, val_best:  72.79%, tr:  97.72%, tr_best:  97.77%, epoch time: 229.39 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 63.1050%\n",
      "layer   3  Sparsity: 33.6411%\n",
      "total_backward_count 2580480 real_backward_count 534142  20.699%\n",
      "layer   1  Sparsity: 86.2061%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 43.6875%\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['4.0000000'], tr/val_loss:686.418335/610.302429, val:  50.00%, val_best:  72.79%, tr:  97.15%, tr_best:  97.77%, epoch time: 228.99 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 62.5588%\n",
      "layer   3  Sparsity: 34.1174%\n",
      "total_backward_count 2612736 real_backward_count 540528  20.688%\n",
      "layer   1  Sparsity: 89.7949%\n",
      "layer   2  Sparsity: 70.6250%\n",
      "layer   3  Sparsity: 49.8750%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-81  lr=['4.0000000'], tr/val_loss:619.284241/584.864319, val:  50.00%, val_best:  72.79%, tr:  96.92%, tr_best:  97.77%, epoch time: 228.47 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 62.8729%\n",
      "layer   3  Sparsity: 33.7872%\n",
      "total_backward_count 2644992 real_backward_count 546817  20.674%\n",
      "layer   1  Sparsity: 82.0801%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 21.8750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-82  lr=['4.0000000'], tr/val_loss:583.549744/480.327240, val:  54.87%, val_best:  72.79%, tr:  97.50%, tr_best:  97.77%, epoch time: 228.74 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 62.3375%\n",
      "layer   3  Sparsity: 32.3712%\n",
      "total_backward_count 2677248 real_backward_count 553057  20.658%\n",
      "layer   1  Sparsity: 80.0049%\n",
      "layer   2  Sparsity: 48.6250%\n",
      "layer   3  Sparsity: 13.4375%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-83  lr=['4.0000000'], tr/val_loss:603.433838/578.435486, val:  50.00%, val_best:  72.79%, tr:  97.82%, tr_best:  97.82%, epoch time: 228.67 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 62.5737%\n",
      "layer   3  Sparsity: 32.2071%\n",
      "total_backward_count 2709504 real_backward_count 559209  20.639%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 54.1875%\n",
      "layer   3  Sparsity: 14.5625%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 32 occurrences\n",
      "test - Value 1: 420 occurrences\n",
      "epoch-84  lr=['4.0000000'], tr/val_loss:616.687256/501.053131, val:  55.75%, val_best:  72.79%, tr:  97.05%, tr_best:  97.82%, epoch time: 228.17 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6666%\n",
      "layer   2  Sparsity: 62.4157%\n",
      "layer   3  Sparsity: 32.2486%\n",
      "total_backward_count 2741760 real_backward_count 565402  20.622%\n",
      "layer   1  Sparsity: 74.8779%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 26.4375%\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 14 occurrences\n",
      "test - Value 1: 438 occurrences\n",
      "epoch-85  lr=['4.0000000'], tr/val_loss:605.647644/497.813324, val:  52.65%, val_best:  72.79%, tr:  97.10%, tr_best:  97.82%, epoch time: 228.06 seconds, 3.80 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 62.3399%\n",
      "layer   3  Sparsity: 32.2301%\n",
      "total_backward_count 2774016 real_backward_count 571694  20.609%\n",
      "layer   1  Sparsity: 74.8047%\n",
      "layer   2  Sparsity: 59.5625%\n",
      "layer   3  Sparsity: 26.4375%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-86  lr=['4.0000000'], tr/val_loss:647.433228/639.333618, val:  50.00%, val_best:  72.79%, tr:  97.52%, tr_best:  97.82%, epoch time: 227.37 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6667%\n",
      "layer   2  Sparsity: 61.4750%\n",
      "layer   3  Sparsity: 31.9902%\n",
      "total_backward_count 2806272 real_backward_count 577956  20.595%\n",
      "layer   1  Sparsity: 82.7393%\n",
      "layer   2  Sparsity: 59.6875%\n",
      "layer   3  Sparsity: 30.0625%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-87  lr=['4.0000000'], tr/val_loss:649.242615/550.543457, val:  50.88%, val_best:  72.79%, tr:  97.15%, tr_best:  97.82%, epoch time: 227.01 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 61.2962%\n",
      "layer   3  Sparsity: 31.9852%\n",
      "total_backward_count 2838528 real_backward_count 584141  20.579%\n",
      "layer   1  Sparsity: 80.7373%\n",
      "layer   2  Sparsity: 65.3125%\n",
      "layer   3  Sparsity: 37.2500%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-88  lr=['4.0000000'], tr/val_loss:643.510559/607.884216, val:  50.00%, val_best:  72.79%, tr:  97.47%, tr_best:  97.82%, epoch time: 226.21 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 61.5508%\n",
      "layer   3  Sparsity: 32.2103%\n",
      "total_backward_count 2870784 real_backward_count 590358  20.564%\n",
      "layer   1  Sparsity: 92.7246%\n",
      "layer   2  Sparsity: 69.4375%\n",
      "layer   3  Sparsity: 50.0625%\n",
      "fc layer 1 self.abs_max_out: 18923.0\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 416 occurrences\n",
      "test - Value 1: 36 occurrences\n",
      "epoch-89  lr=['4.0000000'], tr/val_loss:652.631042/568.731323, val:  57.96%, val_best:  72.79%, tr:  97.00%, tr_best:  97.82%, epoch time: 227.03 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6627%\n",
      "layer   2  Sparsity: 61.1936%\n",
      "layer   3  Sparsity: 32.1934%\n",
      "total_backward_count 2903040 real_backward_count 596756  20.556%\n",
      "layer   1  Sparsity: 85.4004%\n",
      "layer   2  Sparsity: 60.5000%\n",
      "layer   3  Sparsity: 29.7500%\n",
      "fc layer 1 self.abs_max_out: 19228.0\n",
      "fc layer 1 self.abs_max_out: 20101.0\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-90  lr=['4.0000000'], tr/val_loss:647.649414/561.480591, val:  50.88%, val_best:  72.79%, tr:  97.17%, tr_best:  97.82%, epoch time: 225.76 seconds, 3.76 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 61.1685%\n",
      "layer   3  Sparsity: 32.1417%\n",
      "total_backward_count 2935296 real_backward_count 603054  20.545%\n",
      "layer   1  Sparsity: 83.4229%\n",
      "layer   2  Sparsity: 58.8125%\n",
      "layer   3  Sparsity: 27.1875%\n",
      "fc layer 1 self.abs_max_out: 20676.0\n",
      "fc layer 1 self.abs_max_out: 20776.0\n",
      "fc layer 1 self.abs_max_out: 21447.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-91  lr=['4.0000000'], tr/val_loss:641.143738/578.330322, val:  50.00%, val_best:  72.79%, tr:  97.84%, tr_best:  97.84%, epoch time: 225.59 seconds, 3.76 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 61.2832%\n",
      "layer   3  Sparsity: 31.7475%\n",
      "total_backward_count 2967552 real_backward_count 609235  20.530%\n",
      "layer   1  Sparsity: 82.1777%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 26.6250%\n",
      "fc layer 1 self.abs_max_out: 21799.0\n",
      "fc layer 1 self.abs_max_out: 21857.0\n",
      "fc layer 1 self.abs_max_out: 22581.0\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-92  lr=['4.0000000'], tr/val_loss:644.517883/621.135925, val:  50.00%, val_best:  72.79%, tr:  96.88%, tr_best:  97.84%, epoch time: 225.10 seconds, 3.75 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 60.9983%\n",
      "layer   3  Sparsity: 31.8074%\n",
      "total_backward_count 2999808 real_backward_count 615429  20.516%\n",
      "layer   1  Sparsity: 82.2754%\n",
      "layer   2  Sparsity: 59.6875%\n",
      "layer   3  Sparsity: 28.6875%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 101 occurrences\n",
      "test - Value 1: 351 occurrences\n",
      "epoch-93  lr=['4.0000000'], tr/val_loss:644.710693/553.082153, val:  65.71%, val_best:  72.79%, tr:  97.69%, tr_best:  97.84%, epoch time: 225.90 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 60.9008%\n",
      "layer   3  Sparsity: 31.8643%\n",
      "total_backward_count 3032064 real_backward_count 621709  20.504%\n",
      "layer   1  Sparsity: 79.3701%\n",
      "layer   2  Sparsity: 50.5625%\n",
      "layer   3  Sparsity: 15.1250%\n",
      "fc layer 2 self.abs_max_out: 6276.0\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-94  lr=['4.0000000'], tr/val_loss:661.874817/628.315247, val:  50.00%, val_best:  72.79%, tr:  97.12%, tr_best:  97.84%, epoch time: 223.54 seconds, 3.73 minutes\n",
      "layer   1  Sparsity: 82.6657%\n",
      "layer   2  Sparsity: 61.0045%\n",
      "layer   3  Sparsity: 32.1509%\n",
      "total_backward_count 3064320 real_backward_count 628090  20.497%\n",
      "layer   1  Sparsity: 69.2383%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 17.7500%\n",
      "train - Value 0: 1968 occurrences\n",
      "train - Value 1: 2064 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-95  lr=['4.0000000'], tr/val_loss:661.932373/615.995911, val:  50.00%, val_best:  72.79%, tr:  97.52%, tr_best:  97.84%, epoch time: 226.43 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6680%\n",
      "layer   2  Sparsity: 61.4638%\n",
      "layer   3  Sparsity: 32.1063%\n",
      "total_backward_count 3096576 real_backward_count 634343  20.485%\n",
      "layer   1  Sparsity: 90.9180%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 51.6875%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-96  lr=['4.0000000'], tr/val_loss:645.834534/596.188782, val:  50.00%, val_best:  72.79%, tr:  97.30%, tr_best:  97.84%, epoch time: 226.67 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 61.4217%\n",
      "layer   3  Sparsity: 32.0860%\n",
      "total_backward_count 3128832 real_backward_count 640629  20.475%\n",
      "layer   1  Sparsity: 76.7090%\n",
      "layer   2  Sparsity: 49.3750%\n",
      "layer   3  Sparsity: 13.6875%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-97  lr=['4.0000000'], tr/val_loss:644.105408/613.027954, val:  50.00%, val_best:  72.79%, tr:  96.92%, tr_best:  97.84%, epoch time: 226.17 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 61.6182%\n",
      "layer   3  Sparsity: 32.0733%\n",
      "total_backward_count 3161088 real_backward_count 647019  20.468%\n",
      "layer   1  Sparsity: 82.8857%\n",
      "layer   2  Sparsity: 51.3125%\n",
      "layer   3  Sparsity: 20.1250%\n",
      "train - Value 0: 1981 occurrences\n",
      "train - Value 1: 2051 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 397 occurrences\n",
      "test - Value 1: 55 occurrences\n",
      "epoch-98  lr=['4.0000000'], tr/val_loss:647.280457/539.896606, val:  61.73%, val_best:  72.79%, tr:  97.30%, tr_best:  97.84%, epoch time: 226.80 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 61.2575%\n",
      "layer   3  Sparsity: 32.0335%\n",
      "total_backward_count 3193344 real_backward_count 653281  20.458%\n",
      "layer   1  Sparsity: 81.2256%\n",
      "layer   2  Sparsity: 59.0000%\n",
      "layer   3  Sparsity: 27.3125%\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-99  lr=['4.0000000'], tr/val_loss:643.981079/627.748962, val:  50.00%, val_best:  72.79%, tr:  97.27%, tr_best:  97.84%, epoch time: 226.24 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 61.4062%\n",
      "layer   3  Sparsity: 32.0295%\n",
      "total_backward_count 3225600 real_backward_count 659549  20.447%\n",
      "layer   1  Sparsity: 84.1064%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 36.6875%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-100 lr=['4.0000000'], tr/val_loss:646.185669/584.646851, val:  51.33%, val_best:  72.79%, tr:  97.17%, tr_best:  97.84%, epoch time: 226.29 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6646%\n",
      "layer   2  Sparsity: 61.1470%\n",
      "layer   3  Sparsity: 31.8474%\n",
      "total_backward_count 3257856 real_backward_count 665782  20.436%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 56.6875%\n",
      "layer   3  Sparsity: 26.0000%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-101 lr=['4.0000000'], tr/val_loss:644.473022/575.371338, val:  52.43%, val_best:  72.79%, tr:  97.42%, tr_best:  97.84%, epoch time: 197.48 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6679%\n",
      "layer   2  Sparsity: 61.0495%\n",
      "layer   3  Sparsity: 31.9275%\n",
      "total_backward_count 3290112 real_backward_count 672095  20.428%\n",
      "layer   1  Sparsity: 86.0840%\n",
      "layer   2  Sparsity: 69.9375%\n",
      "layer   3  Sparsity: 48.1250%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-102 lr=['4.0000000'], tr/val_loss:647.246216/604.304565, val:  50.22%, val_best:  72.79%, tr:  97.50%, tr_best:  97.84%, epoch time: 206.03 seconds, 3.43 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 61.0904%\n",
      "layer   3  Sparsity: 31.8013%\n",
      "total_backward_count 3322368 real_backward_count 678430  20.420%\n",
      "layer   1  Sparsity: 71.6309%\n",
      "layer   2  Sparsity: 47.9375%\n",
      "layer   3  Sparsity: 14.4375%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-103 lr=['4.0000000'], tr/val_loss:648.771301/605.260254, val:  50.44%, val_best:  72.79%, tr:  97.84%, tr_best:  97.84%, epoch time: 223.52 seconds, 3.73 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 60.9878%\n",
      "layer   3  Sparsity: 31.9297%\n",
      "total_backward_count 3354624 real_backward_count 684656  20.409%\n",
      "layer   1  Sparsity: 80.1270%\n",
      "layer   2  Sparsity: 66.0625%\n",
      "layer   3  Sparsity: 40.6875%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-104 lr=['4.0000000'], tr/val_loss:657.653442/597.150208, val:  50.00%, val_best:  72.79%, tr:  97.45%, tr_best:  97.84%, epoch time: 226.07 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 61.3155%\n",
      "layer   3  Sparsity: 32.2281%\n",
      "total_backward_count 3386880 real_backward_count 691008  20.402%\n",
      "layer   1  Sparsity: 77.0264%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 18.4375%\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-105 lr=['4.0000000'], tr/val_loss:646.270691/580.889587, val:  50.22%, val_best:  72.79%, tr:  97.22%, tr_best:  97.84%, epoch time: 226.16 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 61.3915%\n",
      "layer   3  Sparsity: 32.0602%\n",
      "total_backward_count 3419136 real_backward_count 697321  20.395%\n",
      "layer   1  Sparsity: 85.7666%\n",
      "layer   2  Sparsity: 70.9375%\n",
      "layer   3  Sparsity: 47.4375%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-106 lr=['4.0000000'], tr/val_loss:641.898193/636.222412, val:  50.00%, val_best:  72.79%, tr:  97.37%, tr_best:  97.84%, epoch time: 227.13 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 61.3386%\n",
      "layer   3  Sparsity: 32.1015%\n",
      "total_backward_count 3451392 real_backward_count 703632  20.387%\n",
      "layer   1  Sparsity: 91.3574%\n",
      "layer   2  Sparsity: 70.3750%\n",
      "layer   3  Sparsity: 49.1250%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 93 occurrences\n",
      "test - Value 1: 359 occurrences\n",
      "epoch-107 lr=['4.0000000'], tr/val_loss:638.602722/537.327759, val:  67.92%, val_best:  72.79%, tr:  97.84%, tr_best:  97.84%, epoch time: 227.25 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6630%\n",
      "layer   2  Sparsity: 61.5825%\n",
      "layer   3  Sparsity: 32.0004%\n",
      "total_backward_count 3483648 real_backward_count 709755  20.374%\n",
      "layer   1  Sparsity: 87.0850%\n",
      "layer   2  Sparsity: 68.0625%\n",
      "layer   3  Sparsity: 50.2500%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-108 lr=['4.0000000'], tr/val_loss:627.425537/539.593689, val:  50.00%, val_best:  72.79%, tr:  97.57%, tr_best:  97.84%, epoch time: 228.44 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 61.1213%\n",
      "layer   3  Sparsity: 31.8100%\n",
      "total_backward_count 3515904 real_backward_count 716035  20.366%\n",
      "layer   1  Sparsity: 86.3525%\n",
      "layer   2  Sparsity: 63.6875%\n",
      "layer   3  Sparsity: 39.5625%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-109 lr=['4.0000000'], tr/val_loss:582.821472/567.281799, val:  50.00%, val_best:  72.79%, tr:  97.27%, tr_best:  97.84%, epoch time: 227.64 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 62.2278%\n",
      "layer   3  Sparsity: 30.4864%\n",
      "total_backward_count 3548160 real_backward_count 722236  20.355%\n",
      "layer   1  Sparsity: 89.0869%\n",
      "layer   2  Sparsity: 63.6250%\n",
      "layer   3  Sparsity: 37.3750%\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-110 lr=['4.0000000'], tr/val_loss:655.910645/567.150208, val:  50.44%, val_best:  72.79%, tr:  97.22%, tr_best:  97.84%, epoch time: 227.43 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 61.8065%\n",
      "layer   3  Sparsity: 30.2228%\n",
      "total_backward_count 3580416 real_backward_count 728481  20.346%\n",
      "layer   1  Sparsity: 81.3232%\n",
      "layer   2  Sparsity: 62.8125%\n",
      "layer   3  Sparsity: 26.8750%\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-111 lr=['4.0000000'], tr/val_loss:645.602905/518.002808, val:  50.44%, val_best:  72.79%, tr:  97.30%, tr_best:  97.84%, epoch time: 228.36 seconds, 3.81 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 61.2593%\n",
      "layer   3  Sparsity: 30.2959%\n",
      "total_backward_count 3612672 real_backward_count 734448  20.330%\n",
      "layer   1  Sparsity: 80.8594%\n",
      "layer   2  Sparsity: 55.9375%\n",
      "layer   3  Sparsity: 18.2500%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-112 lr=['4.0000000'], tr/val_loss:613.501160/577.945007, val:  52.43%, val_best:  72.79%, tr:  96.08%, tr_best:  97.84%, epoch time: 229.23 seconds, 3.82 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 59.4233%\n",
      "layer   3  Sparsity: 30.1138%\n",
      "total_backward_count 3644928 real_backward_count 740701  20.321%\n",
      "layer   1  Sparsity: 85.9131%\n",
      "layer   2  Sparsity: 61.1250%\n",
      "layer   3  Sparsity: 36.3125%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-113 lr=['4.0000000'], tr/val_loss:653.688965/577.434326, val:  50.00%, val_best:  72.79%, tr:  97.57%, tr_best:  97.84%, epoch time: 224.28 seconds, 3.74 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 59.9754%\n",
      "layer   3  Sparsity: 30.4653%\n",
      "total_backward_count 3677184 real_backward_count 746850  20.310%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 56.0625%\n",
      "layer   3  Sparsity: 15.5000%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['4.0000000'], tr/val_loss:596.056641/570.039856, val:  50.00%, val_best:  72.79%, tr:  96.83%, tr_best:  97.84%, epoch time: 226.16 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 60.6814%\n",
      "layer   3  Sparsity: 30.7009%\n",
      "total_backward_count 3709440 real_backward_count 753222  20.306%\n",
      "layer   1  Sparsity: 80.0537%\n",
      "layer   2  Sparsity: 59.1875%\n",
      "layer   3  Sparsity: 38.7500%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-115 lr=['4.0000000'], tr/val_loss:631.380432/554.536926, val:  52.21%, val_best:  72.79%, tr:  96.95%, tr_best:  97.84%, epoch time: 227.22 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 59.5479%\n",
      "layer   3  Sparsity: 30.9478%\n",
      "total_backward_count 3741696 real_backward_count 759530  20.299%\n",
      "layer   1  Sparsity: 87.3779%\n",
      "layer   2  Sparsity: 67.8125%\n",
      "layer   3  Sparsity: 50.5000%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-116 lr=['4.0000000'], tr/val_loss:646.237549/631.207703, val:  50.00%, val_best:  72.79%, tr:  97.02%, tr_best:  97.84%, epoch time: 226.07 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 59.1498%\n",
      "layer   3  Sparsity: 31.0354%\n",
      "total_backward_count 3773952 real_backward_count 765952  20.296%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 56.0625%\n",
      "layer   3  Sparsity: 27.0000%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-117 lr=['4.0000000'], tr/val_loss:633.236572/589.876831, val:  50.00%, val_best:  72.79%, tr:  97.47%, tr_best:  97.84%, epoch time: 226.27 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 59.1004%\n",
      "layer   3  Sparsity: 30.8783%\n",
      "total_backward_count 3806208 real_backward_count 772213  20.288%\n",
      "layer   1  Sparsity: 87.9639%\n",
      "layer   2  Sparsity: 60.9375%\n",
      "layer   3  Sparsity: 39.5000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-118 lr=['4.0000000'], tr/val_loss:637.081055/595.173218, val:  50.00%, val_best:  72.79%, tr:  96.92%, tr_best:  97.84%, epoch time: 227.12 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 59.3858%\n",
      "layer   3  Sparsity: 31.2935%\n",
      "total_backward_count 3838464 real_backward_count 778627  20.285%\n",
      "layer   1  Sparsity: 88.8672%\n",
      "layer   2  Sparsity: 63.4375%\n",
      "layer   3  Sparsity: 36.7500%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-119 lr=['4.0000000'], tr/val_loss:636.837524/601.111084, val:  50.00%, val_best:  72.79%, tr:  97.57%, tr_best:  97.84%, epoch time: 226.03 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 59.6202%\n",
      "layer   3  Sparsity: 31.5704%\n",
      "total_backward_count 3870720 real_backward_count 784759  20.274%\n",
      "layer   1  Sparsity: 87.5977%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-120 lr=['4.0000000'], tr/val_loss:640.219238/595.701721, val:  50.00%, val_best:  72.79%, tr:  97.05%, tr_best:  97.84%, epoch time: 222.52 seconds, 3.71 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 59.4917%\n",
      "layer   3  Sparsity: 31.7598%\n",
      "total_backward_count 3902976 real_backward_count 791057  20.268%\n",
      "layer   1  Sparsity: 82.3730%\n",
      "layer   2  Sparsity: 62.6875%\n",
      "layer   3  Sparsity: 26.2500%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-121 lr=['4.0000000'], tr/val_loss:641.743408/604.525452, val:  50.00%, val_best:  72.79%, tr:  97.45%, tr_best:  97.84%, epoch time: 225.67 seconds, 3.76 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 59.4382%\n",
      "layer   3  Sparsity: 31.5697%\n",
      "total_backward_count 3935232 real_backward_count 797420  20.264%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 58.6250%\n",
      "layer   3  Sparsity: 37.3125%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['4.0000000'], tr/val_loss:643.831177/650.594055, val:  50.00%, val_best:  72.79%, tr:  97.47%, tr_best:  97.84%, epoch time: 227.38 seconds, 3.79 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 60.0683%\n",
      "layer   3  Sparsity: 31.7989%\n",
      "total_backward_count 3967488 real_backward_count 803600  20.255%\n",
      "layer   1  Sparsity: 88.7207%\n",
      "layer   2  Sparsity: 62.6250%\n",
      "layer   3  Sparsity: 40.1250%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "lif layer 2 self.abs_max_v: 8953.0\n",
      "lif layer 2 self.abs_max_v: 9211.5\n",
      "lif layer 2 self.abs_max_v: 9591.0\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 270 occurrences\n",
      "test - Value 1: 182 occurrences\n",
      "epoch-123 lr=['4.0000000'], tr/val_loss:641.924194/539.092285, val:  69.91%, val_best:  72.79%, tr:  97.30%, tr_best:  97.84%, epoch time: 226.02 seconds, 3.77 minutes\n",
      "layer   1  Sparsity: 82.6636%\n",
      "layer   2  Sparsity: 60.3789%\n",
      "layer   3  Sparsity: 32.1093%\n",
      "total_backward_count 3999744 real_backward_count 809797  20.246%\n",
      "layer   1  Sparsity: 83.9111%\n",
      "layer   2  Sparsity: 58.5000%\n",
      "layer   3  Sparsity: 27.5000%\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-124 lr=['4.0000000'], tr/val_loss:647.217590/601.735535, val:  50.00%, val_best:  72.79%, tr:  97.42%, tr_best:  97.84%, epoch time: 223.32 seconds, 3.72 minutes\n",
      "layer   1  Sparsity: 82.6647%\n",
      "layer   2  Sparsity: 60.0558%\n",
      "layer   3  Sparsity: 31.8709%\n",
      "total_backward_count 4032000 real_backward_count 816131  20.241%\n",
      "layer   1  Sparsity: 86.0840%\n",
      "layer   2  Sparsity: 70.1875%\n",
      "layer   3  Sparsity: 46.8125%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-125 lr=['4.0000000'], tr/val_loss:653.168396/622.751648, val:  50.00%, val_best:  72.79%, tr:  96.95%, tr_best:  97.84%, epoch time: 226.78 seconds, 3.78 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 60.2632%\n",
      "layer   3  Sparsity: 32.1284%\n",
      "total_backward_count 4064256 real_backward_count 822541  20.238%\n",
      "layer   1  Sparsity: 73.3154%\n",
      "layer   2  Sparsity: 58.0625%\n",
      "layer   3  Sparsity: 26.0000%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-126 lr=['4.0000000'], tr/val_loss:651.165710/597.298889, val:  50.00%, val_best:  72.79%, tr:  97.62%, tr_best:  97.84%, epoch time: 217.77 seconds, 3.63 minutes\n",
      "layer   1  Sparsity: 82.6671%\n",
      "layer   2  Sparsity: 60.4157%\n",
      "layer   3  Sparsity: 32.1137%\n",
      "total_backward_count 4096512 real_backward_count 828800  20.232%\n",
      "layer   1  Sparsity: 77.4170%\n",
      "layer   2  Sparsity: 58.0625%\n",
      "layer   3  Sparsity: 24.8125%\n",
      "train - Value 0: 2032 occurrences\n",
      "train - Value 1: 2000 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-127 lr=['4.0000000'], tr/val_loss:645.483948/616.188538, val:  50.00%, val_best:  72.79%, tr:  97.42%, tr_best:  97.84%, epoch time: 198.69 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6661%\n",
      "layer   2  Sparsity: 59.7908%\n",
      "layer   3  Sparsity: 31.8641%\n",
      "total_backward_count 4128768 real_backward_count 835153  20.228%\n",
      "layer   1  Sparsity: 91.1133%\n",
      "layer   2  Sparsity: 62.8750%\n",
      "layer   3  Sparsity: 42.0000%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-128 lr=['4.0000000'], tr/val_loss:687.239807/636.464478, val:  50.00%, val_best:  72.79%, tr:  98.16%, tr_best:  98.16%, epoch time: 197.79 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6631%\n",
      "layer   2  Sparsity: 59.7727%\n",
      "layer   3  Sparsity: 31.8286%\n",
      "total_backward_count 4161024 real_backward_count 841294  20.218%\n",
      "layer   1  Sparsity: 86.2061%\n",
      "layer   2  Sparsity: 70.5000%\n",
      "layer   3  Sparsity: 47.8750%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-129 lr=['4.0000000'], tr/val_loss:695.597229/637.296021, val:  50.00%, val_best:  72.79%, tr:  97.99%, tr_best:  98.16%, epoch time: 197.68 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 59.8164%\n",
      "layer   3  Sparsity: 31.8505%\n",
      "total_backward_count 4193280 real_backward_count 847637  20.214%\n",
      "layer   1  Sparsity: 90.5029%\n",
      "layer   2  Sparsity: 70.3750%\n",
      "layer   3  Sparsity: 49.1250%\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-130 lr=['4.0000000'], tr/val_loss:690.553101/653.502869, val:  50.00%, val_best:  72.79%, tr:  97.47%, tr_best:  98.16%, epoch time: 198.01 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6632%\n",
      "layer   2  Sparsity: 59.8227%\n",
      "layer   3  Sparsity: 31.8478%\n",
      "total_backward_count 4225536 real_backward_count 853923  20.209%\n",
      "layer   1  Sparsity: 90.0879%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 38.6250%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-131 lr=['4.0000000'], tr/val_loss:695.690918/632.630615, val:  50.00%, val_best:  72.79%, tr:  97.82%, tr_best:  98.16%, epoch time: 197.57 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 59.8026%\n",
      "layer   3  Sparsity: 31.8476%\n",
      "total_backward_count 4257792 real_backward_count 860187  20.203%\n",
      "layer   1  Sparsity: 79.1260%\n",
      "layer   2  Sparsity: 57.9375%\n",
      "layer   3  Sparsity: 27.5000%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-132 lr=['4.0000000'], tr/val_loss:690.542908/571.587585, val:  66.15%, val_best:  72.79%, tr:  97.12%, tr_best:  98.16%, epoch time: 197.83 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6658%\n",
      "layer   2  Sparsity: 59.5163%\n",
      "layer   3  Sparsity: 31.6770%\n",
      "total_backward_count 4290048 real_backward_count 866604  20.200%\n",
      "layer   1  Sparsity: 88.1104%\n",
      "layer   2  Sparsity: 55.5625%\n",
      "layer   3  Sparsity: 27.2500%\n",
      "train - Value 0: 2037 occurrences\n",
      "train - Value 1: 1995 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-133 lr=['4.0000000'], tr/val_loss:693.859741/643.588989, val:  50.00%, val_best:  72.79%, tr:  97.59%, tr_best:  98.16%, epoch time: 196.19 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6638%\n",
      "layer   2  Sparsity: 59.1487%\n",
      "layer   3  Sparsity: 31.7194%\n",
      "total_backward_count 4322304 real_backward_count 872787  20.193%\n",
      "layer   1  Sparsity: 77.1729%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 28.7500%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-134 lr=['4.0000000'], tr/val_loss:696.110779/669.256104, val:  50.00%, val_best:  72.79%, tr:  97.17%, tr_best:  98.16%, epoch time: 196.52 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 58.9964%\n",
      "layer   3  Sparsity: 31.7749%\n",
      "total_backward_count 4354560 real_backward_count 879063  20.187%\n",
      "layer   1  Sparsity: 82.8125%\n",
      "layer   2  Sparsity: 61.8750%\n",
      "layer   3  Sparsity: 29.7500%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-135 lr=['4.0000000'], tr/val_loss:695.375732/631.161011, val:  50.00%, val_best:  72.79%, tr:  97.62%, tr_best:  98.16%, epoch time: 195.98 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 59.1262%\n",
      "layer   3  Sparsity: 32.0430%\n",
      "total_backward_count 4386816 real_backward_count 885303  20.181%\n",
      "layer   1  Sparsity: 83.5938%\n",
      "layer   2  Sparsity: 64.1875%\n",
      "layer   3  Sparsity: 36.6250%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-136 lr=['4.0000000'], tr/val_loss:695.736755/604.036926, val:  50.66%, val_best:  72.79%, tr:  97.25%, tr_best:  98.16%, epoch time: 196.57 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 59.1524%\n",
      "layer   3  Sparsity: 32.0301%\n",
      "total_backward_count 4419072 real_backward_count 891497  20.174%\n",
      "layer   1  Sparsity: 78.1738%\n",
      "layer   2  Sparsity: 44.7500%\n",
      "layer   3  Sparsity: 18.8125%\n",
      "train - Value 0: 2010 occurrences\n",
      "train - Value 1: 2022 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-137 lr=['4.0000000'], tr/val_loss:697.072571/599.993347, val:  51.99%, val_best:  72.79%, tr:  97.07%, tr_best:  98.16%, epoch time: 197.04 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 59.1341%\n",
      "layer   3  Sparsity: 31.9982%\n",
      "total_backward_count 4451328 real_backward_count 897873  20.171%\n",
      "layer   1  Sparsity: 85.0098%\n",
      "layer   2  Sparsity: 62.3125%\n",
      "layer   3  Sparsity: 36.2500%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-138 lr=['4.0000000'], tr/val_loss:702.651062/681.792175, val:  50.00%, val_best:  72.79%, tr:  97.89%, tr_best:  98.16%, epoch time: 197.19 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 59.2049%\n",
      "layer   3  Sparsity: 31.7011%\n",
      "total_backward_count 4483584 real_backward_count 904191  20.167%\n",
      "layer   1  Sparsity: 84.5459%\n",
      "layer   2  Sparsity: 61.3750%\n",
      "layer   3  Sparsity: 40.3750%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-139 lr=['4.0000000'], tr/val_loss:697.645569/655.344238, val:  50.00%, val_best:  72.79%, tr:  97.32%, tr_best:  98.16%, epoch time: 197.25 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 59.1682%\n",
      "layer   3  Sparsity: 32.0348%\n",
      "total_backward_count 4515840 real_backward_count 910491  20.162%\n",
      "layer   1  Sparsity: 95.0195%\n",
      "layer   2  Sparsity: 73.2500%\n",
      "layer   3  Sparsity: 58.4375%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-140 lr=['4.0000000'], tr/val_loss:697.037476/590.744324, val:  63.50%, val_best:  72.79%, tr:  97.17%, tr_best:  98.16%, epoch time: 197.10 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 58.8770%\n",
      "layer   3  Sparsity: 31.8192%\n",
      "total_backward_count 4548096 real_backward_count 916808  20.158%\n",
      "layer   1  Sparsity: 80.5420%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 25.1875%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-141 lr=['4.0000000'], tr/val_loss:690.815186/599.956848, val:  55.53%, val_best:  72.79%, tr:  97.74%, tr_best:  98.16%, epoch time: 197.65 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 59.3015%\n",
      "layer   3  Sparsity: 31.9084%\n",
      "total_backward_count 4580352 real_backward_count 922969  20.151%\n",
      "layer   1  Sparsity: 72.3389%\n",
      "layer   2  Sparsity: 50.6250%\n",
      "layer   3  Sparsity: 20.0000%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-142 lr=['4.0000000'], tr/val_loss:696.384766/642.010437, val:  51.33%, val_best:  72.79%, tr:  98.34%, tr_best:  98.34%, epoch time: 196.83 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6673%\n",
      "layer   2  Sparsity: 59.3264%\n",
      "layer   3  Sparsity: 31.9936%\n",
      "total_backward_count 4612608 real_backward_count 929192  20.145%\n",
      "layer   1  Sparsity: 84.8877%\n",
      "layer   2  Sparsity: 61.5625%\n",
      "layer   3  Sparsity: 38.1875%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-143 lr=['4.0000000'], tr/val_loss:695.737610/644.621887, val:  50.00%, val_best:  72.79%, tr:  97.42%, tr_best:  98.34%, epoch time: 197.91 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 59.1886%\n",
      "layer   3  Sparsity: 32.2552%\n",
      "total_backward_count 4644864 real_backward_count 935427  20.139%\n",
      "layer   1  Sparsity: 94.0918%\n",
      "layer   2  Sparsity: 73.8750%\n",
      "layer   3  Sparsity: 61.0000%\n",
      "train - Value 0: 2012 occurrences\n",
      "train - Value 1: 2020 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-144 lr=['4.0000000'], tr/val_loss:694.326355/640.796387, val:  50.00%, val_best:  72.79%, tr:  97.82%, tr_best:  98.34%, epoch time: 196.68 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 59.4092%\n",
      "layer   3  Sparsity: 32.2085%\n",
      "total_backward_count 4677120 real_backward_count 941698  20.134%\n",
      "layer   1  Sparsity: 70.4346%\n",
      "layer   2  Sparsity: 50.2500%\n",
      "layer   3  Sparsity: 14.8125%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-145 lr=['4.0000000'], tr/val_loss:690.837219/637.135925, val:  51.11%, val_best:  72.79%, tr:  97.45%, tr_best:  98.34%, epoch time: 198.34 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6677%\n",
      "layer   2  Sparsity: 59.1773%\n",
      "layer   3  Sparsity: 31.9732%\n",
      "total_backward_count 4709376 real_backward_count 948088  20.132%\n",
      "layer   1  Sparsity: 76.6113%\n",
      "layer   2  Sparsity: 56.8750%\n",
      "layer   3  Sparsity: 27.5625%\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 314 occurrences\n",
      "test - Value 1: 138 occurrences\n",
      "epoch-146 lr=['4.0000000'], tr/val_loss:685.784973/593.284485, val:  67.70%, val_best:  72.79%, tr:  97.45%, tr_best:  98.34%, epoch time: 195.65 seconds, 3.26 minutes\n",
      "layer   1  Sparsity: 82.6663%\n",
      "layer   2  Sparsity: 59.4188%\n",
      "layer   3  Sparsity: 31.9790%\n",
      "total_backward_count 4741632 real_backward_count 954504  20.130%\n",
      "layer   1  Sparsity: 82.8857%\n",
      "layer   2  Sparsity: 47.6875%\n",
      "layer   3  Sparsity: 22.5000%\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-147 lr=['4.0000000'], tr/val_loss:696.505676/669.117065, val:  50.00%, val_best:  72.79%, tr:  97.97%, tr_best:  98.34%, epoch time: 195.75 seconds, 3.26 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 60.9955%\n",
      "layer   3  Sparsity: 32.3869%\n",
      "total_backward_count 4773888 real_backward_count 960875  20.128%\n",
      "layer   1  Sparsity: 86.1084%\n",
      "layer   2  Sparsity: 65.1875%\n",
      "layer   3  Sparsity: 38.1250%\n",
      "fc layer 2 self.abs_max_out: 6361.0\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['4.0000000'], tr/val_loss:696.377380/619.112915, val:  50.00%, val_best:  72.79%, tr:  97.89%, tr_best:  98.34%, epoch time: 196.00 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 61.1921%\n",
      "layer   3  Sparsity: 32.2934%\n",
      "total_backward_count 4806144 real_backward_count 967039  20.121%\n",
      "layer   1  Sparsity: 85.9863%\n",
      "layer   2  Sparsity: 64.3125%\n",
      "layer   3  Sparsity: 39.7500%\n",
      "lif layer 2 self.abs_max_v: 9785.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 426 occurrences\n",
      "test - Value 1: 26 occurrences\n",
      "epoch-149 lr=['4.0000000'], tr/val_loss:690.219849/625.345581, val:  55.31%, val_best:  72.79%, tr:  97.84%, tr_best:  98.34%, epoch time: 197.94 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6642%\n",
      "layer   2  Sparsity: 61.2005%\n",
      "layer   3  Sparsity: 32.5064%\n",
      "total_backward_count 4838400 real_backward_count 973358  20.117%\n",
      "layer   1  Sparsity: 74.2432%\n",
      "layer   2  Sparsity: 55.6875%\n",
      "layer   3  Sparsity: 17.5000%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 441 occurrences\n",
      "test - Value 1: 11 occurrences\n",
      "epoch-150 lr=['4.0000000'], tr/val_loss:697.934875/606.338501, val:  51.99%, val_best:  72.79%, tr:  98.19%, tr_best:  98.34%, epoch time: 196.20 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6668%\n",
      "layer   2  Sparsity: 61.0918%\n",
      "layer   3  Sparsity: 32.2847%\n",
      "total_backward_count 4870656 real_backward_count 979629  20.113%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 47.7500%\n",
      "layer   3  Sparsity: 17.3750%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['4.0000000'], tr/val_loss:699.025818/655.102905, val:  50.00%, val_best:  72.79%, tr:  98.09%, tr_best:  98.34%, epoch time: 197.88 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 61.1628%\n",
      "layer   3  Sparsity: 32.2892%\n",
      "total_backward_count 4902912 real_backward_count 985882  20.108%\n",
      "layer   1  Sparsity: 85.7910%\n",
      "layer   2  Sparsity: 64.3125%\n",
      "layer   3  Sparsity: 39.0625%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 438 occurrences\n",
      "test - Value 1: 14 occurrences\n",
      "epoch-152 lr=['4.0000000'], tr/val_loss:696.847412/616.077271, val:  53.10%, val_best:  72.79%, tr:  98.02%, tr_best:  98.34%, epoch time: 197.36 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 61.1751%\n",
      "layer   3  Sparsity: 32.3842%\n",
      "total_backward_count 4935168 real_backward_count 992253  20.106%\n",
      "layer   1  Sparsity: 82.1289%\n",
      "layer   2  Sparsity: 65.7500%\n",
      "layer   3  Sparsity: 29.8125%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-153 lr=['4.0000000'], tr/val_loss:701.189331/592.750061, val:  62.17%, val_best:  72.79%, tr:  98.16%, tr_best:  98.34%, epoch time: 198.21 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 61.3386%\n",
      "layer   3  Sparsity: 32.1171%\n",
      "total_backward_count 4967424 real_backward_count 998509  20.101%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 14.5625%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-154 lr=['4.0000000'], tr/val_loss:694.845032/705.924377, val:  50.00%, val_best:  72.79%, tr:  97.87%, tr_best:  98.34%, epoch time: 198.31 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6666%\n",
      "layer   2  Sparsity: 60.7763%\n",
      "layer   3  Sparsity: 32.0997%\n",
      "total_backward_count 4999680 real_backward_count 1004887  20.099%\n",
      "layer   1  Sparsity: 83.5693%\n",
      "layer   2  Sparsity: 48.6875%\n",
      "layer   3  Sparsity: 20.0000%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 425 occurrences\n",
      "test - Value 1: 27 occurrences\n",
      "epoch-155 lr=['4.0000000'], tr/val_loss:698.105835/595.348389, val:  55.53%, val_best:  72.79%, tr:  97.79%, tr_best:  98.34%, epoch time: 198.90 seconds, 3.32 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 60.9351%\n",
      "layer   3  Sparsity: 31.9503%\n",
      "total_backward_count 5031936 real_backward_count 1011215  20.096%\n",
      "layer   1  Sparsity: 89.7705%\n",
      "layer   2  Sparsity: 73.1875%\n",
      "layer   3  Sparsity: 58.6875%\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 259 occurrences\n",
      "test - Value 1: 193 occurrences\n",
      "epoch-156 lr=['4.0000000'], tr/val_loss:691.292053/576.307678, val:  72.35%, val_best:  72.79%, tr:  97.72%, tr_best:  98.34%, epoch time: 197.63 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6634%\n",
      "layer   2  Sparsity: 61.1515%\n",
      "layer   3  Sparsity: 32.1987%\n",
      "total_backward_count 5064192 real_backward_count 1017365  20.089%\n",
      "layer   1  Sparsity: 81.3965%\n",
      "layer   2  Sparsity: 51.9375%\n",
      "layer   3  Sparsity: 22.3750%\n",
      "fc layer 1 self.abs_max_out: 22609.0\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-157 lr=['4.0000000'], tr/val_loss:693.846130/664.258179, val:  50.00%, val_best:  72.79%, tr:  98.19%, tr_best:  98.34%, epoch time: 197.39 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6652%\n",
      "layer   2  Sparsity: 61.1808%\n",
      "layer   3  Sparsity: 32.0061%\n",
      "total_backward_count 5096448 real_backward_count 1023518  20.083%\n",
      "layer   1  Sparsity: 84.8389%\n",
      "layer   2  Sparsity: 64.0625%\n",
      "layer   3  Sparsity: 38.5625%\n",
      "lif layer 2 self.abs_max_v: 9911.0\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 397 occurrences\n",
      "test - Value 1: 55 occurrences\n",
      "epoch-158 lr=['4.0000000'], tr/val_loss:697.356079/610.243713, val:  60.40%, val_best:  72.79%, tr:  98.16%, tr_best:  98.34%, epoch time: 194.50 seconds, 3.24 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 61.3771%\n",
      "layer   3  Sparsity: 32.2311%\n",
      "total_backward_count 5128704 real_backward_count 1029693  20.077%\n",
      "layer   1  Sparsity: 86.3770%\n",
      "layer   2  Sparsity: 64.6875%\n",
      "layer   3  Sparsity: 40.0625%\n",
      "fc layer 3 self.abs_max_out: 1456.0\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-159 lr=['4.0000000'], tr/val_loss:702.508972/713.725769, val:  50.00%, val_best:  72.79%, tr:  97.47%, tr_best:  98.34%, epoch time: 194.49 seconds, 3.24 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 61.3203%\n",
      "layer   3  Sparsity: 32.1534%\n",
      "total_backward_count 5160960 real_backward_count 1035981  20.073%\n",
      "layer   1  Sparsity: 86.5967%\n",
      "layer   2  Sparsity: 64.4375%\n",
      "layer   3  Sparsity: 37.3750%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-160 lr=['4.0000000'], tr/val_loss:699.237366/628.194641, val:  50.88%, val_best:  72.79%, tr:  97.59%, tr_best:  98.34%, epoch time: 198.76 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6641%\n",
      "layer   2  Sparsity: 61.3097%\n",
      "layer   3  Sparsity: 32.2300%\n",
      "total_backward_count 5193216 real_backward_count 1042164  20.068%\n",
      "layer   1  Sparsity: 64.9170%\n",
      "layer   2  Sparsity: 48.2500%\n",
      "layer   3  Sparsity: 15.7500%\n",
      "train - Value 0: 1988 occurrences\n",
      "train - Value 1: 2044 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['4.0000000'], tr/val_loss:692.938660/717.802124, val:  50.00%, val_best:  72.79%, tr:  97.87%, tr_best:  98.34%, epoch time: 197.50 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6689%\n",
      "layer   2  Sparsity: 61.2792%\n",
      "layer   3  Sparsity: 32.2535%\n",
      "total_backward_count 5225472 real_backward_count 1048353  20.062%\n",
      "layer   1  Sparsity: 93.9453%\n",
      "layer   2  Sparsity: 68.3125%\n",
      "layer   3  Sparsity: 50.1250%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-162 lr=['4.0000000'], tr/val_loss:692.941406/655.674133, val:  50.00%, val_best:  72.79%, tr:  97.92%, tr_best:  98.34%, epoch time: 198.20 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6624%\n",
      "layer   2  Sparsity: 61.3522%\n",
      "layer   3  Sparsity: 32.2978%\n",
      "total_backward_count 5257728 real_backward_count 1054553  20.057%\n",
      "layer   1  Sparsity: 81.3721%\n",
      "layer   2  Sparsity: 53.2500%\n",
      "layer   3  Sparsity: 18.6250%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['4.0000000'], tr/val_loss:694.078979/700.755371, val:  50.00%, val_best:  72.79%, tr:  97.59%, tr_best:  98.34%, epoch time: 197.75 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 61.3991%\n",
      "layer   3  Sparsity: 32.2731%\n",
      "total_backward_count 5289984 real_backward_count 1060709  20.051%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 55.3750%\n",
      "layer   3  Sparsity: 16.5000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 291 occurrences\n",
      "test - Value 1: 161 occurrences\n",
      "epoch-164 lr=['4.0000000'], tr/val_loss:696.047852/594.900818, val:  70.58%, val_best:  72.79%, tr:  97.50%, tr_best:  98.34%, epoch time: 198.14 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 61.0440%\n",
      "layer   3  Sparsity: 32.0874%\n",
      "total_backward_count 5322240 real_backward_count 1066925  20.047%\n",
      "layer   1  Sparsity: 85.8154%\n",
      "layer   2  Sparsity: 64.6875%\n",
      "layer   3  Sparsity: 40.1875%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-165 lr=['4.0000000'], tr/val_loss:695.918030/650.995544, val:  50.00%, val_best:  72.79%, tr:  97.67%, tr_best:  98.34%, epoch time: 199.02 seconds, 3.32 minutes\n",
      "layer   1  Sparsity: 82.6643%\n",
      "layer   2  Sparsity: 61.1911%\n",
      "layer   3  Sparsity: 32.4851%\n",
      "total_backward_count 5354496 real_backward_count 1073230  20.044%\n",
      "layer   1  Sparsity: 75.9521%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 17.3750%\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-166 lr=['4.0000000'], tr/val_loss:694.747192/681.275940, val:  50.00%, val_best:  72.79%, tr:  97.62%, tr_best:  98.34%, epoch time: 198.20 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6665%\n",
      "layer   2  Sparsity: 61.1107%\n",
      "layer   3  Sparsity: 32.2252%\n",
      "total_backward_count 5386752 real_backward_count 1079440  20.039%\n",
      "layer   1  Sparsity: 85.2295%\n",
      "layer   2  Sparsity: 63.6875%\n",
      "layer   3  Sparsity: 38.8125%\n",
      "lif layer 2 self.abs_max_v: 9916.0\n",
      "lif layer 2 self.abs_max_v: 9991.5\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-167 lr=['4.0000000'], tr/val_loss:698.867981/612.675720, val:  50.22%, val_best:  72.79%, tr:  97.79%, tr_best:  98.34%, epoch time: 197.58 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 61.0605%\n",
      "layer   3  Sparsity: 32.3925%\n",
      "total_backward_count 5419008 real_backward_count 1085773  20.036%\n",
      "layer   1  Sparsity: 83.3008%\n",
      "layer   2  Sparsity: 56.1250%\n",
      "layer   3  Sparsity: 28.3125%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['4.0000000'], tr/val_loss:693.530029/701.648743, val:  50.00%, val_best:  72.79%, tr:  97.92%, tr_best:  98.34%, epoch time: 197.55 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 61.3002%\n",
      "layer   3  Sparsity: 32.2551%\n",
      "total_backward_count 5451264 real_backward_count 1091840  20.029%\n",
      "layer   1  Sparsity: 91.7480%\n",
      "layer   2  Sparsity: 67.8750%\n",
      "layer   3  Sparsity: 53.3125%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 297 occurrences\n",
      "test - Value 1: 155 occurrences\n",
      "epoch-169 lr=['4.0000000'], tr/val_loss:695.035767/583.900024, val:  71.46%, val_best:  72.79%, tr:  97.77%, tr_best:  98.34%, epoch time: 195.70 seconds, 3.26 minutes\n",
      "layer   1  Sparsity: 82.6629%\n",
      "layer   2  Sparsity: 61.1739%\n",
      "layer   3  Sparsity: 32.3633%\n",
      "total_backward_count 5483520 real_backward_count 1098215  20.028%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 62.1875%\n",
      "layer   3  Sparsity: 29.1875%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['4.0000000'], tr/val_loss:694.502075/698.993652, val:  50.00%, val_best:  72.79%, tr:  97.79%, tr_best:  98.34%, epoch time: 194.20 seconds, 3.24 minutes\n",
      "layer   1  Sparsity: 82.6653%\n",
      "layer   2  Sparsity: 61.4788%\n",
      "layer   3  Sparsity: 32.2228%\n",
      "total_backward_count 5515776 real_backward_count 1104514  20.025%\n",
      "layer   1  Sparsity: 82.9590%\n",
      "layer   2  Sparsity: 62.8125%\n",
      "layer   3  Sparsity: 29.4375%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-171 lr=['4.0000000'], tr/val_loss:708.438660/652.955872, val:  50.22%, val_best:  72.79%, tr:  98.19%, tr_best:  98.34%, epoch time: 196.12 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6649%\n",
      "layer   2  Sparsity: 61.3592%\n",
      "layer   3  Sparsity: 32.0514%\n",
      "total_backward_count 5548032 real_backward_count 1110760  20.021%\n",
      "layer   1  Sparsity: 82.1045%\n",
      "layer   2  Sparsity: 64.2500%\n",
      "layer   3  Sparsity: 37.3125%\n",
      "train - Value 0: 2000 occurrences\n",
      "train - Value 1: 2032 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-172 lr=['4.0000000'], tr/val_loss:704.573975/647.805237, val:  50.00%, val_best:  72.79%, tr:  97.97%, tr_best:  98.34%, epoch time: 197.29 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6651%\n",
      "layer   2  Sparsity: 61.4883%\n",
      "layer   3  Sparsity: 32.1008%\n",
      "total_backward_count 5580288 real_backward_count 1116921  20.015%\n",
      "layer   1  Sparsity: 87.0117%\n",
      "layer   2  Sparsity: 67.8750%\n",
      "layer   3  Sparsity: 49.0000%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-173 lr=['4.0000000'], tr/val_loss:706.236816/650.296631, val:  50.88%, val_best:  72.79%, tr:  97.82%, tr_best:  98.34%, epoch time: 197.69 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6640%\n",
      "layer   2  Sparsity: 61.3602%\n",
      "layer   3  Sparsity: 32.0806%\n",
      "total_backward_count 5612544 real_backward_count 1123239  20.013%\n",
      "layer   1  Sparsity: 95.0684%\n",
      "layer   2  Sparsity: 74.8750%\n",
      "layer   3  Sparsity: 58.2500%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-174 lr=['4.0000000'], tr/val_loss:706.623108/747.946533, val:  50.00%, val_best:  72.79%, tr:  97.50%, tr_best:  98.34%, epoch time: 196.20 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6622%\n",
      "layer   2  Sparsity: 61.1998%\n",
      "layer   3  Sparsity: 31.8903%\n",
      "total_backward_count 5644800 real_backward_count 1129584  20.011%\n",
      "layer   1  Sparsity: 93.3350%\n",
      "layer   2  Sparsity: 72.6250%\n",
      "layer   3  Sparsity: 49.9375%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 273 occurrences\n",
      "test - Value 1: 179 occurrences\n",
      "epoch-175 lr=['4.0000000'], tr/val_loss:710.556213/600.871033, val:  74.12%, val_best:  74.12%, tr:  98.19%, tr_best:  98.34%, epoch time: 196.46 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6626%\n",
      "layer   2  Sparsity: 61.1066%\n",
      "layer   3  Sparsity: 31.9452%\n",
      "total_backward_count 5677056 real_backward_count 1135675  20.005%\n",
      "layer   1  Sparsity: 77.2217%\n",
      "layer   2  Sparsity: 61.6250%\n",
      "layer   3  Sparsity: 27.3750%\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 439 occurrences\n",
      "test - Value 1: 13 occurrences\n",
      "epoch-176 lr=['4.0000000'], tr/val_loss:706.680176/607.164307, val:  52.88%, val_best:  74.12%, tr:  98.14%, tr_best:  98.34%, epoch time: 197.25 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 61.2319%\n",
      "layer   3  Sparsity: 32.0518%\n",
      "total_backward_count 5709312 real_backward_count 1141926  20.001%\n",
      "layer   1  Sparsity: 85.3027%\n",
      "layer   2  Sparsity: 59.6875%\n",
      "layer   3  Sparsity: 28.2500%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 215 occurrences\n",
      "test - Value 1: 237 occurrences\n",
      "epoch-177 lr=['4.0000000'], tr/val_loss:703.273071/589.595947, val:  75.88%, val_best:  75.88%, tr:  98.14%, tr_best:  98.34%, epoch time: 196.83 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6644%\n",
      "layer   2  Sparsity: 61.3156%\n",
      "layer   3  Sparsity: 32.0266%\n",
      "total_backward_count 5741568 real_backward_count 1148179  19.998%\n",
      "layer   1  Sparsity: 87.4756%\n",
      "layer   2  Sparsity: 58.4375%\n",
      "layer   3  Sparsity: 31.0625%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 377 occurrences\n",
      "test - Value 1: 75 occurrences\n",
      "epoch-178 lr=['4.0000000'], tr/val_loss:707.522522/606.259094, val:  63.05%, val_best:  75.88%, tr:  97.59%, tr_best:  98.34%, epoch time: 196.67 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 61.1934%\n",
      "layer   3  Sparsity: 31.9188%\n",
      "total_backward_count 5773824 real_backward_count 1154439  19.994%\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 63.6875%\n",
      "layer   3  Sparsity: 39.8750%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-179 lr=['4.0000000'], tr/val_loss:709.973328/656.085754, val:  50.00%, val_best:  75.88%, tr:  97.79%, tr_best:  98.34%, epoch time: 198.20 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 61.0742%\n",
      "layer   3  Sparsity: 32.0090%\n",
      "total_backward_count 5806080 real_backward_count 1160798  19.993%\n",
      "layer   1  Sparsity: 80.6396%\n",
      "layer   2  Sparsity: 48.9375%\n",
      "layer   3  Sparsity: 17.9375%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 329 occurrences\n",
      "test - Value 1: 123 occurrences\n",
      "epoch-180 lr=['4.0000000'], tr/val_loss:707.431763/590.345642, val:  67.92%, val_best:  75.88%, tr:  97.89%, tr_best:  98.34%, epoch time: 198.19 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6654%\n",
      "layer   2  Sparsity: 61.1339%\n",
      "layer   3  Sparsity: 31.8662%\n",
      "total_backward_count 5838336 real_backward_count 1166828  19.986%\n",
      "layer   1  Sparsity: 89.4043%\n",
      "layer   2  Sparsity: 65.8750%\n",
      "layer   3  Sparsity: 37.3125%\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 444 occurrences\n",
      "test - Value 1: 8 occurrences\n",
      "epoch-181 lr=['4.0000000'], tr/val_loss:709.759888/643.594421, val:  51.77%, val_best:  75.88%, tr:  98.04%, tr_best:  98.34%, epoch time: 196.06 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 61.1633%\n",
      "layer   3  Sparsity: 31.9614%\n",
      "total_backward_count 5870592 real_backward_count 1173064  19.982%\n",
      "layer   1  Sparsity: 61.9385%\n",
      "layer   2  Sparsity: 52.8750%\n",
      "layer   3  Sparsity: 15.3125%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-182 lr=['4.0000000'], tr/val_loss:711.324951/644.962158, val:  51.11%, val_best:  75.88%, tr:  97.99%, tr_best:  98.34%, epoch time: 194.32 seconds, 3.24 minutes\n",
      "layer   1  Sparsity: 82.6696%\n",
      "layer   2  Sparsity: 61.2207%\n",
      "layer   3  Sparsity: 31.7145%\n",
      "total_backward_count 5902848 real_backward_count 1179207  19.977%\n",
      "layer   1  Sparsity: 80.3955%\n",
      "layer   2  Sparsity: 62.0000%\n",
      "layer   3  Sparsity: 26.3750%\n",
      "train - Value 0: 1997 occurrences\n",
      "train - Value 1: 2035 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-183 lr=['4.0000000'], tr/val_loss:706.888000/645.510864, val:  50.00%, val_best:  75.88%, tr:  98.09%, tr_best:  98.34%, epoch time: 195.15 seconds, 3.25 minutes\n",
      "layer   1  Sparsity: 82.6655%\n",
      "layer   2  Sparsity: 61.3686%\n",
      "layer   3  Sparsity: 31.8174%\n",
      "total_backward_count 5935104 real_backward_count 1185424  19.973%\n",
      "layer   1  Sparsity: 79.7852%\n",
      "layer   2  Sparsity: 52.8750%\n",
      "layer   3  Sparsity: 20.7500%\n",
      "train - Value 0: 2003 occurrences\n",
      "train - Value 1: 2029 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "max_activation_accul updated: 8363.00 at epoch 184, iter 4031\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['4.0000000'], tr/val_loss:707.941711/787.248718, val:  50.00%, val_best:  75.88%, tr:  98.19%, tr_best:  98.34%, epoch time: 196.70 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6656%\n",
      "layer   2  Sparsity: 61.3972%\n",
      "layer   3  Sparsity: 31.8373%\n",
      "total_backward_count 5967360 real_backward_count 1191739  19.971%\n",
      "layer   1  Sparsity: 89.0381%\n",
      "layer   2  Sparsity: 63.6875%\n",
      "layer   3  Sparsity: 41.3125%\n",
      "train - Value 0: 1979 occurrences\n",
      "train - Value 1: 2053 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-185 lr=['4.0000000'], tr/val_loss:710.080444/607.869568, val:  57.52%, val_best:  75.88%, tr:  97.64%, tr_best:  98.34%, epoch time: 197.71 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6635%\n",
      "layer   2  Sparsity: 61.1660%\n",
      "layer   3  Sparsity: 31.7865%\n",
      "total_backward_count 5999616 real_backward_count 1198113  19.970%\n",
      "layer   1  Sparsity: 87.4756%\n",
      "layer   2  Sparsity: 58.4375%\n",
      "layer   3  Sparsity: 29.3125%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-186 lr=['4.0000000'], tr/val_loss:711.556824/632.958618, val:  51.33%, val_best:  75.88%, tr:  97.87%, tr_best:  98.34%, epoch time: 198.07 seconds, 3.30 minutes\n",
      "layer   1  Sparsity: 82.6639%\n",
      "layer   2  Sparsity: 61.0481%\n",
      "layer   3  Sparsity: 31.7330%\n",
      "total_backward_count 6031872 real_backward_count 1204497  19.969%\n",
      "layer   1  Sparsity: 83.4961%\n",
      "layer   2  Sparsity: 59.8125%\n",
      "layer   3  Sparsity: 29.9375%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-187 lr=['4.0000000'], tr/val_loss:709.461548/663.718811, val:  50.00%, val_best:  75.88%, tr:  98.51%, tr_best:  98.51%, epoch time: 197.64 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 61.3020%\n",
      "layer   3  Sparsity: 31.7606%\n",
      "total_backward_count 6064128 real_backward_count 1210552  19.963%\n",
      "layer   1  Sparsity: 71.8018%\n",
      "layer   2  Sparsity: 54.8125%\n",
      "layer   3  Sparsity: 15.7500%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 11 occurrences\n",
      "test - Value 1: 441 occurrences\n",
      "epoch-188 lr=['4.0000000'], tr/val_loss:711.990051/609.525757, val:  51.99%, val_best:  75.88%, tr:  98.12%, tr_best:  98.51%, epoch time: 196.44 seconds, 3.27 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 61.3708%\n",
      "layer   3  Sparsity: 31.8651%\n",
      "total_backward_count 6096384 real_backward_count 1216728  19.958%\n",
      "layer   1  Sparsity: 71.8262%\n",
      "layer   2  Sparsity: 50.5000%\n",
      "layer   3  Sparsity: 16.5625%\n",
      "train - Value 0: 1991 occurrences\n",
      "train - Value 1: 2041 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-189 lr=['4.0000000'], tr/val_loss:712.846008/723.036865, val:  50.00%, val_best:  75.88%, tr:  98.14%, tr_best:  98.51%, epoch time: 197.23 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 61.1976%\n",
      "layer   3  Sparsity: 31.9396%\n",
      "total_backward_count 6128640 real_backward_count 1222917  19.954%\n",
      "layer   1  Sparsity: 82.5439%\n",
      "layer   2  Sparsity: 64.3750%\n",
      "layer   3  Sparsity: 38.2500%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 39 occurrences\n",
      "test - Value 1: 413 occurrences\n",
      "epoch-190 lr=['4.0000000'], tr/val_loss:714.337769/607.120056, val:  56.42%, val_best:  75.88%, tr:  98.09%, tr_best:  98.51%, epoch time: 197.15 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6650%\n",
      "layer   2  Sparsity: 61.2618%\n",
      "layer   3  Sparsity: 32.0319%\n",
      "total_backward_count 6160896 real_backward_count 1229136  19.951%\n",
      "layer   1  Sparsity: 71.6309%\n",
      "layer   2  Sparsity: 47.1875%\n",
      "layer   3  Sparsity: 14.1250%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 448 occurrences\n",
      "test - Value 1: 4 occurrences\n",
      "epoch-191 lr=['4.0000000'], tr/val_loss:713.970764/630.619690, val:  50.88%, val_best:  75.88%, tr:  97.77%, tr_best:  98.51%, epoch time: 197.04 seconds, 3.28 minutes\n",
      "layer   1  Sparsity: 82.6674%\n",
      "layer   2  Sparsity: 61.0652%\n",
      "layer   3  Sparsity: 32.0420%\n",
      "total_backward_count 6193152 real_backward_count 1235307  19.946%\n",
      "layer   1  Sparsity: 78.6865%\n",
      "layer   2  Sparsity: 60.2500%\n",
      "layer   3  Sparsity: 37.4375%\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 193 occurrences\n",
      "test - Value 1: 259 occurrences\n",
      "epoch-192 lr=['4.0000000'], tr/val_loss:710.725952/589.688110, val:  73.23%, val_best:  75.88%, tr:  98.36%, tr_best:  98.51%, epoch time: 197.30 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6659%\n",
      "layer   2  Sparsity: 60.9247%\n",
      "layer   3  Sparsity: 31.8364%\n",
      "total_backward_count 6225408 real_backward_count 1241531  19.943%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 53.6250%\n",
      "layer   3  Sparsity: 16.5625%\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['4.0000000'], tr/val_loss:701.430664/713.523438, val:  50.00%, val_best:  75.88%, tr:  98.39%, tr_best:  98.51%, epoch time: 194.07 seconds, 3.23 minutes\n",
      "layer   1  Sparsity: 82.6679%\n",
      "layer   2  Sparsity: 61.1430%\n",
      "layer   3  Sparsity: 32.0162%\n",
      "total_backward_count 6257664 real_backward_count 1247667  19.938%\n",
      "layer   1  Sparsity: 78.2227%\n",
      "layer   2  Sparsity: 63.0000%\n",
      "layer   3  Sparsity: 38.1875%\n",
      "train - Value 0: 1974 occurrences\n",
      "train - Value 1: 2058 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-194 lr=['4.0000000'], tr/val_loss:704.504944/698.336792, val:  50.00%, val_best:  75.88%, tr:  97.97%, tr_best:  98.51%, epoch time: 195.14 seconds, 3.25 minutes\n",
      "layer   1  Sparsity: 82.6660%\n",
      "layer   2  Sparsity: 61.1581%\n",
      "layer   3  Sparsity: 31.8418%\n",
      "total_backward_count 6289920 real_backward_count 1253961  19.936%\n",
      "layer   1  Sparsity: 90.0391%\n",
      "layer   2  Sparsity: 61.9375%\n",
      "layer   3  Sparsity: 41.4375%\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-195 lr=['4.0000000'], tr/val_loss:705.815796/587.985901, val:  72.35%, val_best:  75.88%, tr:  98.02%, tr_best:  98.51%, epoch time: 197.48 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6633%\n",
      "layer   2  Sparsity: 61.2161%\n",
      "layer   3  Sparsity: 31.9283%\n",
      "total_backward_count 6322176 real_backward_count 1260236  19.934%\n",
      "layer   1  Sparsity: 84.6924%\n",
      "layer   2  Sparsity: 59.3125%\n",
      "layer   3  Sparsity: 28.1875%\n",
      "train - Value 0: 2006 occurrences\n",
      "train - Value 1: 2026 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-196 lr=['4.0000000'], tr/val_loss:706.767029/661.115906, val:  50.00%, val_best:  75.88%, tr:  98.02%, tr_best:  98.51%, epoch time: 198.57 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6645%\n",
      "layer   2  Sparsity: 61.2099%\n",
      "layer   3  Sparsity: 31.9675%\n",
      "total_backward_count 6354432 real_backward_count 1266483  19.931%\n",
      "layer   1  Sparsity: 83.5449%\n",
      "layer   2  Sparsity: 67.3125%\n",
      "layer   3  Sparsity: 37.5000%\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 115 occurrences\n",
      "test - Value 1: 337 occurrences\n",
      "epoch-197 lr=['4.0000000'], tr/val_loss:710.315186/589.164551, val:  68.36%, val_best:  75.88%, tr:  97.94%, tr_best:  98.51%, epoch time: 198.30 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6648%\n",
      "layer   2  Sparsity: 61.2846%\n",
      "layer   3  Sparsity: 31.9025%\n",
      "total_backward_count 6386688 real_backward_count 1272764  19.928%\n",
      "layer   1  Sparsity: 77.0020%\n",
      "layer   2  Sparsity: 57.8125%\n",
      "layer   3  Sparsity: 26.7500%\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-198 lr=['4.0000000'], tr/val_loss:710.469971/636.239624, val:  50.00%, val_best:  75.88%, tr:  97.50%, tr_best:  98.51%, epoch time: 198.48 seconds, 3.31 minutes\n",
      "layer   1  Sparsity: 82.6662%\n",
      "layer   2  Sparsity: 60.9951%\n",
      "layer   3  Sparsity: 31.8192%\n",
      "total_backward_count 6418944 real_backward_count 1278965  19.925%\n",
      "layer   1  Sparsity: 73.3887%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 25.5625%\n",
      "train - Value 0: 2004 occurrences\n",
      "train - Value 1: 2028 occurrences\n",
      "train_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test_spike_distribution.mean 8.000000, min 8, max 8\n",
      "test - Value 0: 213 occurrences\n",
      "test - Value 1: 239 occurrences\n",
      "epoch-199 lr=['4.0000000'], tr/val_loss:709.655640/592.971985, val:  72.35%, val_best:  75.88%, tr:  98.12%, tr_best:  98.51%, epoch time: 197.21 seconds, 3.29 minutes\n",
      "layer   1  Sparsity: 82.6670%\n",
      "layer   2  Sparsity: 61.1631%\n",
      "layer   3  Sparsity: 31.9006%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758df5426d3d403391ae71e6baea6287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá</td></tr><tr><td>val_loss</td><td>‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñÜ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98115</td></tr><tr><td>tr_epoch_loss</td><td>709.65564</td></tr><tr><td>val_acc_best</td><td>0.75885</td></tr><tr><td>val_acc_now</td><td>0.72345</td></tr><tr><td>val_loss</td><td>592.97198</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-41</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/kp5q4dmm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/kp5q4dmm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251213_201508-kp5q4dmm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l93duo4y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251214_081812-l93duo4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l93duo4y' target=\"_blank\">generous-sweep-42</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l93duo4y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l93duo4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251214_081820_980', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 64, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 16, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 64, 'lif_layer_v_threshold2': 32, 'init_scaling': [1, 0.03125, 0.03125], 'learning_rate': 2, 'learning_rate2': 1, 'loser_encourage_mode': True} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 16, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 64, self.v_threshold 32\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.03125, 0.03125])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=16, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.03125, 0.03125])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=32, v_reset=10000, sg_width=64, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[1, 0.03125, 0.03125])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 2\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 1357.0\n",
      "lif layer 1 self.abs_max_v: 1357.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 64.0\n",
      "lif layer 2 self.abs_max_v: 64.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 18.0\n",
      "fc layer 1 self.abs_max_out: 3281.0\n",
      "lif layer 1 self.abs_max_v: 3384.5\n",
      "fc layer 2 self.abs_max_out: 65.0\n",
      "lif layer 2 self.abs_max_v: 88.5\n",
      "fc layer 3 self.abs_max_out: 22.0\n",
      "fc layer 1 self.abs_max_out: 3429.0\n",
      "lif layer 1 self.abs_max_v: 4987.5\n",
      "fc layer 2 self.abs_max_out: 69.0\n",
      "lif layer 2 self.abs_max_v: 104.5\n",
      "fc layer 3 self.abs_max_out: 29.0\n",
      "lif layer 1 self.abs_max_v: 5010.0\n",
      "fc layer 2 self.abs_max_out: 87.0\n",
      "lif layer 2 self.abs_max_v: 139.5\n",
      "fc layer 2 self.abs_max_out: 94.0\n",
      "layer   1  Sparsity: 74.1211%\n",
      "layer   2  Sparsity: 54.6667%\n",
      "layer   3  Sparsity: 87.5833%\n",
      "fc layer 2 self.abs_max_out: 96.0\n",
      "fc layer 2 self.abs_max_out: 124.0\n",
      "fc layer 2 self.abs_max_out: 135.0\n",
      "fc layer 3 self.abs_max_out: 35.0\n",
      "fc layer 1 self.abs_max_out: 4810.0\n",
      "lif layer 1 self.abs_max_v: 5316.5\n",
      "lif layer 2 self.abs_max_v: 141.0\n",
      "fc layer 3 self.abs_max_out: 38.0\n",
      "fc layer 3 self.abs_max_out: 41.0\n",
      "lif layer 2 self.abs_max_v: 148.5\n",
      "fc layer 2 self.abs_max_out: 136.0\n",
      "lif layer 2 self.abs_max_v: 168.5\n",
      "fc layer 2 self.abs_max_out: 141.0\n",
      "fc layer 2 self.abs_max_out: 158.0\n",
      "lif layer 2 self.abs_max_v: 173.5\n",
      "fc layer 2 self.abs_max_out: 176.0\n",
      "lif layer 2 self.abs_max_v: 176.0\n",
      "fc layer 2 self.abs_max_out: 190.0\n",
      "lif layer 2 self.abs_max_v: 190.0\n",
      "lif layer 1 self.abs_max_v: 5366.0\n",
      "fc layer 2 self.abs_max_out: 192.0\n",
      "lif layer 2 self.abs_max_v: 192.0\n",
      "fc layer 2 self.abs_max_out: 197.0\n",
      "lif layer 2 self.abs_max_v: 197.0\n",
      "fc layer 2 self.abs_max_out: 198.0\n",
      "lif layer 2 self.abs_max_v: 198.0\n",
      "fc layer 2 self.abs_max_out: 207.0\n",
      "lif layer 2 self.abs_max_v: 207.0\n",
      "fc layer 3 self.abs_max_out: 43.0\n",
      "fc layer 3 self.abs_max_out: 44.0\n",
      "fc layer 3 self.abs_max_out: 46.0\n",
      "fc layer 3 self.abs_max_out: 51.0\n",
      "lif layer 1 self.abs_max_v: 5969.5\n",
      "fc layer 2 self.abs_max_out: 220.0\n",
      "lif layer 2 self.abs_max_v: 220.0\n",
      "lif layer 2 self.abs_max_v: 240.0\n",
      "fc layer 3 self.abs_max_out: 53.0\n",
      "lif layer 2 self.abs_max_v: 256.0\n",
      "lif layer 2 self.abs_max_v: 285.0\n",
      "lif layer 2 self.abs_max_v: 298.5\n",
      "lif layer 2 self.abs_max_v: 304.0\n",
      "lif layer 2 self.abs_max_v: 315.0\n",
      "lif layer 2 self.abs_max_v: 325.5\n",
      "lif layer 2 self.abs_max_v: 329.5\n",
      "lif layer 2 self.abs_max_v: 341.0\n",
      "lif layer 1 self.abs_max_v: 6217.5\n",
      "lif layer 2 self.abs_max_v: 355.5\n",
      "fc layer 2 self.abs_max_out: 225.0\n",
      "fc layer 3 self.abs_max_out: 55.0\n",
      "fc layer 2 self.abs_max_out: 241.0\n",
      "fc layer 3 self.abs_max_out: 58.0\n",
      "fc layer 3 self.abs_max_out: 88.0\n",
      "fc layer 2 self.abs_max_out: 249.0\n",
      "fc layer 2 self.abs_max_out: 259.0\n",
      "lif layer 2 self.abs_max_v: 368.5\n",
      "lif layer 2 self.abs_max_v: 388.0\n",
      "lif layer 2 self.abs_max_v: 397.0\n",
      "lif layer 2 self.abs_max_v: 407.0\n",
      "lif layer 1 self.abs_max_v: 6509.0\n",
      "fc layer 2 self.abs_max_out: 261.0\n",
      "fc layer 2 self.abs_max_out: 264.0\n",
      "fc layer 2 self.abs_max_out: 273.0\n",
      "fc layer 2 self.abs_max_out: 277.0\n",
      "fc layer 2 self.abs_max_out: 289.0\n",
      "fc layer 2 self.abs_max_out: 295.0\n",
      "lif layer 2 self.abs_max_v: 409.5\n",
      "lif layer 1 self.abs_max_v: 6588.0\n",
      "lif layer 1 self.abs_max_v: 7244.0\n",
      "lif layer 2 self.abs_max_v: 412.0\n",
      "lif layer 2 self.abs_max_v: 417.0\n",
      "lif layer 2 self.abs_max_v: 442.5\n",
      "lif layer 2 self.abs_max_v: 455.5\n",
      "fc layer 2 self.abs_max_out: 299.0\n",
      "lif layer 2 self.abs_max_v: 483.5\n",
      "lif layer 2 self.abs_max_v: 494.0\n",
      "lif layer 2 self.abs_max_v: 499.0\n",
      "lif layer 2 self.abs_max_v: 520.5\n",
      "fc layer 2 self.abs_max_out: 301.0\n",
      "fc layer 2 self.abs_max_out: 306.0\n",
      "fc layer 2 self.abs_max_out: 313.0\n",
      "fc layer 2 self.abs_max_out: 324.0\n",
      "fc layer 2 self.abs_max_out: 327.0\n",
      "fc layer 2 self.abs_max_out: 341.0\n",
      "lif layer 2 self.abs_max_v: 548.5\n",
      "lif layer 2 self.abs_max_v: 552.5\n",
      "fc layer 2 self.abs_max_out: 343.0\n",
      "fc layer 2 self.abs_max_out: 344.0\n",
      "fc layer 2 self.abs_max_out: 348.0\n",
      "fc layer 2 self.abs_max_out: 350.0\n",
      "lif layer 2 self.abs_max_v: 558.0\n",
      "fc layer 2 self.abs_max_out: 363.0\n",
      "fc layer 2 self.abs_max_out: 382.0\n",
      "lif layer 2 self.abs_max_v: 560.5\n",
      "lif layer 2 self.abs_max_v: 562.5\n",
      "lif layer 2 self.abs_max_v: 602.0\n",
      "fc layer 2 self.abs_max_out: 395.0\n",
      "lif layer 2 self.abs_max_v: 629.0\n",
      "lif layer 2 self.abs_max_v: 679.5\n",
      "lif layer 2 self.abs_max_v: 689.5\n",
      "fc layer 2 self.abs_max_out: 414.0\n",
      "fc layer 2 self.abs_max_out: 418.0\n",
      "fc layer 2 self.abs_max_out: 425.0\n",
      "lif layer 1 self.abs_max_v: 7591.0\n",
      "train - Value 0: 1954 occurrences\n",
      "train - Value 1: 2078 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 177.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 198.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 219.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 225.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 243.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 254.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 258.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 284.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 308.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-0   lr=['2.0000000'], tr/val_loss: 30.983194/ 29.967855, val:  50.00%, val_best:  50.00%, tr:  88.14%, tr_best:  88.14%, epoch time: 152.05 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4672%\n",
      "layer   2  Sparsity: 62.6822%\n",
      "layer   3  Sparsity: 75.8054%\n",
      "total_backward_count 24192 real_backward_count 4477  18.506%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 75.7161%\n",
      "layer   2  Sparsity: 58.2500%\n",
      "layer   3  Sparsity: 71.0833%\n",
      "fc layer 2 self.abs_max_out: 434.0\n",
      "fc layer 2 self.abs_max_out: 442.0\n",
      "fc layer 2 self.abs_max_out: 444.0\n",
      "fc layer 2 self.abs_max_out: 470.0\n",
      "fc layer 2 self.abs_max_out: 480.0\n",
      "fc layer 2 self.abs_max_out: 484.0\n",
      "fc layer 2 self.abs_max_out: 501.0\n",
      "lif layer 2 self.abs_max_v: 700.5\n",
      "lif layer 2 self.abs_max_v: 708.0\n",
      "fc layer 1 self.abs_max_out: 4861.0\n",
      "lif layer 2 self.abs_max_v: 713.0\n",
      "lif layer 2 self.abs_max_v: 734.5\n",
      "fc layer 2 self.abs_max_out: 512.0\n",
      "lif layer 2 self.abs_max_v: 736.0\n",
      "lif layer 2 self.abs_max_v: 736.5\n",
      "fc layer 2 self.abs_max_out: 513.0\n",
      "fc layer 2 self.abs_max_out: 516.0\n",
      "fc layer 2 self.abs_max_out: 517.0\n",
      "fc layer 2 self.abs_max_out: 522.0\n",
      "fc layer 2 self.abs_max_out: 533.0\n",
      "fc layer 2 self.abs_max_out: 534.0\n",
      "fc layer 2 self.abs_max_out: 542.0\n",
      "lif layer 2 self.abs_max_v: 778.5\n",
      "train - Value 0: 2097 occurrences\n",
      "train - Value 1: 1935 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 1 self.abs_max_out: 4974.0\n",
      "fc layer 1 self.abs_max_out: 4991.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-1   lr=['2.0000000'], tr/val_loss: 30.786745/  8.877489, val:  50.00%, val_best:  50.00%, tr:  86.68%, tr_best:  88.14%, epoch time: 152.09 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 64.2884%\n",
      "layer   3  Sparsity: 74.5780%\n",
      "total_backward_count 48384 real_backward_count 9350  19.325%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 66.0833%\n",
      "layer   3  Sparsity: 76.9167%\n",
      "lif layer 2 self.abs_max_v: 779.0\n",
      "lif layer 2 self.abs_max_v: 800.5\n",
      "lif layer 2 self.abs_max_v: 814.5\n",
      "fc layer 2 self.abs_max_out: 551.0\n",
      "fc layer 3 self.abs_max_out: 89.0\n",
      "lif layer 2 self.abs_max_v: 824.0\n",
      "lif layer 2 self.abs_max_v: 826.0\n",
      "lif layer 2 self.abs_max_v: 830.5\n",
      "lif layer 2 self.abs_max_v: 840.0\n",
      "lif layer 2 self.abs_max_v: 842.5\n",
      "lif layer 2 self.abs_max_v: 858.5\n",
      "fc layer 1 self.abs_max_out: 5090.0\n",
      "lif layer 2 self.abs_max_v: 870.5\n",
      "lif layer 2 self.abs_max_v: 892.0\n",
      "fc layer 3 self.abs_max_out: 90.0\n",
      "fc layer 3 self.abs_max_out: 94.0\n",
      "fc layer 3 self.abs_max_out: 95.0\n",
      "fc layer 2 self.abs_max_out: 628.0\n",
      "fc layer 1 self.abs_max_out: 5524.0\n",
      "fc layer 2 self.abs_max_out: 649.0\n",
      "fc layer 1 self.abs_max_out: 5555.0\n",
      "train - Value 0: 1873 occurrences\n",
      "train - Value 1: 2159 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['2.0000000'], tr/val_loss: 40.942482/ 49.704861, val:  50.00%, val_best:  50.00%, tr:  86.38%, tr_best:  88.14%, epoch time: 151.95 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 64.3659%\n",
      "layer   3  Sparsity: 74.6538%\n",
      "total_backward_count 72576 real_backward_count 14205  19.573%\n",
      "layer   1  Sparsity: 74.7721%\n",
      "layer   2  Sparsity: 64.3333%\n",
      "layer   3  Sparsity: 77.1667%\n",
      "fc layer 1 self.abs_max_out: 5584.0\n",
      "lif layer 1 self.abs_max_v: 7666.5\n",
      "fc layer 2 self.abs_max_out: 653.0\n",
      "train - Value 0: 1763 occurrences\n",
      "train - Value 1: 2269 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-3   lr=['2.0000000'], tr/val_loss: 35.215374/ 27.879354, val:  50.44%, val_best:  50.44%, tr:  75.82%, tr_best:  88.14%, epoch time: 153.03 seconds, 2.55 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 63.9598%\n",
      "layer   3  Sparsity: 74.6420%\n",
      "total_backward_count 96768 real_backward_count 19183  19.824%\n",
      "layer   1  Sparsity: 76.6602%\n",
      "layer   2  Sparsity: 65.5000%\n",
      "layer   3  Sparsity: 76.3333%\n",
      "fc layer 2 self.abs_max_out: 659.0\n",
      "fc layer 2 self.abs_max_out: 662.0\n",
      "fc layer 2 self.abs_max_out: 665.0\n",
      "fc layer 2 self.abs_max_out: 680.0\n",
      "fc layer 1 self.abs_max_out: 5805.0\n",
      "fc layer 2 self.abs_max_out: 681.0\n",
      "fc layer 2 self.abs_max_out: 688.0\n",
      "fc layer 2 self.abs_max_out: 703.0\n",
      "train - Value 0: 2278 occurrences\n",
      "train - Value 1: 1754 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-4   lr=['2.0000000'], tr/val_loss: 18.159550/ 10.839653, val:  50.00%, val_best:  50.44%, tr:  80.11%, tr_best:  88.14%, epoch time: 151.28 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 63.0840%\n",
      "layer   3  Sparsity: 74.0913%\n",
      "total_backward_count 120960 real_backward_count 24025  19.862%\n",
      "layer   1  Sparsity: 83.4310%\n",
      "layer   2  Sparsity: 66.6667%\n",
      "layer   3  Sparsity: 75.9167%\n",
      "lif layer 2 self.abs_max_v: 904.0\n",
      "fc layer 1 self.abs_max_out: 6135.0\n",
      "fc layer 2 self.abs_max_out: 712.0\n",
      "lif layer 2 self.abs_max_v: 908.0\n",
      "lif layer 2 self.abs_max_v: 922.5\n",
      "fc layer 2 self.abs_max_out: 718.0\n",
      "lif layer 2 self.abs_max_v: 942.0\n",
      "lif layer 2 self.abs_max_v: 957.0\n",
      "fc layer 2 self.abs_max_out: 722.0\n",
      "fc layer 2 self.abs_max_out: 746.0\n",
      "fc layer 3 self.abs_max_out: 99.0\n",
      "fc layer 2 self.abs_max_out: 758.0\n",
      "fc layer 3 self.abs_max_out: 105.0\n",
      "fc layer 3 self.abs_max_out: 113.0\n",
      "fc layer 3 self.abs_max_out: 115.0\n",
      "lif layer 1 self.abs_max_v: 7695.5\n",
      "fc layer 1 self.abs_max_out: 6206.0\n",
      "train - Value 0: 1930 occurrences\n",
      "train - Value 1: 2102 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 311.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 316.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 323.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 376.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 398.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 404.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 406.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 429.00 at epoch 5, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['2.0000000'], tr/val_loss: 25.232159/ 56.422211, val:  50.00%, val_best:  50.44%, tr:  83.68%, tr_best:  88.14%, epoch time: 150.37 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 63.5681%\n",
      "layer   3  Sparsity: 73.4565%\n",
      "total_backward_count 145152 real_backward_count 28943  19.940%\n",
      "layer   1  Sparsity: 84.4401%\n",
      "layer   2  Sparsity: 60.0833%\n",
      "layer   3  Sparsity: 70.7500%\n",
      "fc layer 2 self.abs_max_out: 762.0\n",
      "fc layer 2 self.abs_max_out: 773.0\n",
      "fc layer 1 self.abs_max_out: 6224.0\n",
      "lif layer 2 self.abs_max_v: 1003.5\n",
      "lif layer 2 self.abs_max_v: 1007.0\n",
      "lif layer 2 self.abs_max_v: 1038.0\n",
      "lif layer 2 self.abs_max_v: 1048.0\n",
      "lif layer 2 self.abs_max_v: 1066.0\n",
      "lif layer 2 self.abs_max_v: 1072.5\n",
      "lif layer 2 self.abs_max_v: 1076.0\n",
      "fc layer 1 self.abs_max_out: 6259.0\n",
      "lif layer 2 self.abs_max_v: 1167.0\n",
      "lif layer 2 self.abs_max_v: 1176.0\n",
      "lif layer 2 self.abs_max_v: 1203.5\n",
      "lif layer 2 self.abs_max_v: 1224.0\n",
      "fc layer 1 self.abs_max_out: 6479.0\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['2.0000000'], tr/val_loss: 31.983368/ 41.901642, val:  50.00%, val_best:  50.44%, tr:  89.26%, tr_best:  89.26%, epoch time: 148.88 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 62.7841%\n",
      "layer   3  Sparsity: 72.3737%\n",
      "total_backward_count 169344 real_backward_count 33819  19.971%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 74.6667%\n",
      "lif layer 2 self.abs_max_v: 1235.0\n",
      "lif layer 2 self.abs_max_v: 1245.5\n",
      "lif layer 2 self.abs_max_v: 1278.5\n",
      "lif layer 2 self.abs_max_v: 1284.5\n",
      "lif layer 2 self.abs_max_v: 1286.0\n",
      "lif layer 2 self.abs_max_v: 1292.0\n",
      "fc layer 1 self.abs_max_out: 6480.0\n",
      "fc layer 2 self.abs_max_out: 775.0\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 777.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['2.0000000'], tr/val_loss: 25.063824/  8.679223, val:  50.00%, val_best:  50.44%, tr:  86.78%, tr_best:  89.26%, epoch time: 148.59 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.7338%\n",
      "layer   3  Sparsity: 71.8670%\n",
      "total_backward_count 193536 real_backward_count 38466  19.875%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 60.7500%\n",
      "layer   3  Sparsity: 68.8333%\n",
      "fc layer 2 self.abs_max_out: 786.0\n",
      "fc layer 2 self.abs_max_out: 790.0\n",
      "fc layer 2 self.abs_max_out: 794.0\n",
      "fc layer 2 self.abs_max_out: 799.0\n",
      "fc layer 3 self.abs_max_out: 122.0\n",
      "fc layer 3 self.abs_max_out: 123.0\n",
      "fc layer 3 self.abs_max_out: 125.0\n",
      "fc layer 3 self.abs_max_out: 126.0\n",
      "fc layer 3 self.abs_max_out: 139.0\n",
      "fc layer 2 self.abs_max_out: 804.0\n",
      "train - Value 0: 2052 occurrences\n",
      "train - Value 1: 1980 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-8   lr=['2.0000000'], tr/val_loss: 35.031898/ 19.946003, val:  50.44%, val_best:  50.44%, tr:  92.06%, tr_best:  92.06%, epoch time: 148.75 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.1618%\n",
      "layer   3  Sparsity: 71.5215%\n",
      "total_backward_count 217728 real_backward_count 43111  19.800%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 68.0833%\n",
      "layer   3  Sparsity: 74.0833%\n",
      "fc layer 1 self.abs_max_out: 6580.0\n",
      "fc layer 2 self.abs_max_out: 808.0\n",
      "train - Value 0: 2082 occurrences\n",
      "train - Value 1: 1950 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 450.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 464.00 at epoch 9, iter 4031\n",
      "max_activation_accul updated: 476.00 at epoch 9, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-9   lr=['2.0000000'], tr/val_loss: 31.553980/ 59.550934, val:  50.00%, val_best:  50.44%, tr:  91.02%, tr_best:  92.06%, epoch time: 151.93 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 61.8761%\n",
      "layer   3  Sparsity: 71.1863%\n",
      "total_backward_count 241920 real_backward_count 47753  19.739%\n",
      "layer   1  Sparsity: 79.0690%\n",
      "layer   2  Sparsity: 57.0000%\n",
      "layer   3  Sparsity: 68.7500%\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-10  lr=['2.0000000'], tr/val_loss: 41.075703/ 29.503094, val:  50.22%, val_best:  50.44%, tr:  94.39%, tr_best:  94.39%, epoch time: 150.39 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 60.6097%\n",
      "layer   3  Sparsity: 71.3903%\n",
      "total_backward_count 266112 real_backward_count 52061  19.564%\n",
      "layer   1  Sparsity: 86.7188%\n",
      "layer   2  Sparsity: 61.2500%\n",
      "layer   3  Sparsity: 68.7500%\n",
      "fc layer 2 self.abs_max_out: 814.0\n",
      "fc layer 2 self.abs_max_out: 827.0\n",
      "fc layer 2 self.abs_max_out: 857.0\n",
      "fc layer 2 self.abs_max_out: 870.0\n",
      "fc layer 2 self.abs_max_out: 886.0\n",
      "train - Value 0: 2134 occurrences\n",
      "train - Value 1: 1898 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['2.0000000'], tr/val_loss: 33.476669/ 43.879013, val:  50.00%, val_best:  50.44%, tr:  88.39%, tr_best:  94.39%, epoch time: 151.15 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 60.9503%\n",
      "layer   3  Sparsity: 72.2953%\n",
      "total_backward_count 290304 real_backward_count 56763  19.553%\n",
      "layer   1  Sparsity: 83.8542%\n",
      "layer   2  Sparsity: 59.5000%\n",
      "layer   3  Sparsity: 70.0833%\n",
      "lif layer 2 self.abs_max_v: 1317.0\n",
      "lif layer 2 self.abs_max_v: 1333.5\n",
      "lif layer 2 self.abs_max_v: 1334.5\n",
      "fc layer 1 self.abs_max_out: 6741.0\n",
      "lif layer 1 self.abs_max_v: 8051.0\n",
      "lif layer 1 self.abs_max_v: 8857.5\n",
      "lif layer 2 self.abs_max_v: 1347.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-12  lr=['2.0000000'], tr/val_loss: 27.568378/ 12.289001, val:  59.51%, val_best:  59.51%, tr:  90.50%, tr_best:  94.39%, epoch time: 150.97 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 62.1503%\n",
      "layer   3  Sparsity: 72.3647%\n",
      "total_backward_count 314496 real_backward_count 61213  19.464%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 70.1667%\n",
      "layer   3  Sparsity: 74.6667%\n",
      "fc layer 1 self.abs_max_out: 6745.0\n",
      "lif layer 1 self.abs_max_v: 9214.5\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 892.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-13  lr=['2.0000000'], tr/val_loss: 35.641747/ 20.482748, val:  50.66%, val_best:  59.51%, tr:  89.24%, tr_best:  94.39%, epoch time: 150.41 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 62.0429%\n",
      "layer   3  Sparsity: 73.0105%\n",
      "total_backward_count 338688 real_backward_count 65962  19.476%\n",
      "layer   1  Sparsity: 90.3971%\n",
      "layer   2  Sparsity: 69.5000%\n",
      "layer   3  Sparsity: 75.7500%\n",
      "fc layer 2 self.abs_max_out: 904.0\n",
      "lif layer 1 self.abs_max_v: 9915.5\n",
      "fc layer 2 self.abs_max_out: 919.0\n",
      "fc layer 2 self.abs_max_out: 941.0\n",
      "fc layer 1 self.abs_max_out: 6821.0\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['2.0000000'], tr/val_loss: 35.021122/ 38.336540, val:  50.00%, val_best:  59.51%, tr:  92.81%, tr_best:  94.39%, epoch time: 150.80 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 60.8774%\n",
      "layer   3  Sparsity: 73.3564%\n",
      "total_backward_count 362880 real_backward_count 70571  19.447%\n",
      "layer   1  Sparsity: 93.8151%\n",
      "layer   2  Sparsity: 74.2500%\n",
      "layer   3  Sparsity: 81.1667%\n",
      "lif layer 1 self.abs_max_v: 10193.5\n",
      "fc layer 1 self.abs_max_out: 6968.0\n",
      "fc layer 2 self.abs_max_out: 950.0\n",
      "fc layer 3 self.abs_max_out: 140.0\n",
      "fc layer 3 self.abs_max_out: 150.0\n",
      "train - Value 0: 2123 occurrences\n",
      "train - Value 1: 1909 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 418 occurrences\n",
      "test - Value 1: 34 occurrences\n",
      "epoch-15  lr=['2.0000000'], tr/val_loss: 29.061846/ 31.716909, val:  56.64%, val_best:  59.51%, tr:  90.80%, tr_best:  94.39%, epoch time: 151.64 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 61.1337%\n",
      "layer   3  Sparsity: 73.0497%\n",
      "total_backward_count 387072 real_backward_count 74917  19.355%\n",
      "layer   1  Sparsity: 84.9935%\n",
      "layer   2  Sparsity: 63.5000%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "lif layer 1 self.abs_max_v: 10540.0\n",
      "lif layer 2 self.abs_max_v: 1358.5\n",
      "fc layer 1 self.abs_max_out: 7139.0\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 394 occurrences\n",
      "test - Value 1: 58 occurrences\n",
      "epoch-16  lr=['2.0000000'], tr/val_loss: 31.478823/ 18.205988, val:  61.06%, val_best:  61.06%, tr:  90.08%, tr_best:  94.39%, epoch time: 152.37 seconds, 2.54 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 61.2434%\n",
      "layer   3  Sparsity: 72.6734%\n",
      "total_backward_count 411264 real_backward_count 79242  19.268%\n",
      "layer   1  Sparsity: 75.6510%\n",
      "layer   2  Sparsity: 48.9167%\n",
      "layer   3  Sparsity: 69.8333%\n",
      "fc layer 1 self.abs_max_out: 7211.0\n",
      "lif layer 2 self.abs_max_v: 1382.0\n",
      "lif layer 2 self.abs_max_v: 1419.5\n",
      "fc layer 2 self.abs_max_out: 952.0\n",
      "fc layer 1 self.abs_max_out: 7332.0\n",
      "fc layer 2 self.abs_max_out: 973.0\n",
      "lif layer 1 self.abs_max_v: 10818.5\n",
      "train - Value 0: 1902 occurrences\n",
      "train - Value 1: 2130 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-17  lr=['2.0000000'], tr/val_loss: 43.938568/ 52.284676, val:  50.00%, val_best:  61.06%, tr:  94.30%, tr_best:  94.39%, epoch time: 150.87 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 61.0183%\n",
      "layer   3  Sparsity: 73.1062%\n",
      "total_backward_count 435456 real_backward_count 83545  19.186%\n",
      "layer   1  Sparsity: 75.2930%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 69.9167%\n",
      "fc layer 2 self.abs_max_out: 990.0\n",
      "fc layer 2 self.abs_max_out: 997.0\n",
      "lif layer 1 self.abs_max_v: 10934.5\n",
      "lif layer 2 self.abs_max_v: 1434.5\n",
      "fc layer 1 self.abs_max_out: 7466.0\n",
      "train - Value 0: 1950 occurrences\n",
      "train - Value 1: 2082 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['2.0000000'], tr/val_loss: 40.345181/ 60.918640, val:  50.00%, val_best:  61.06%, tr:  90.97%, tr_best:  94.39%, epoch time: 150.73 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 61.2600%\n",
      "layer   3  Sparsity: 73.0265%\n",
      "total_backward_count 459648 real_backward_count 88275  19.205%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 73.5833%\n",
      "layer   3  Sparsity: 80.2500%\n",
      "lif layer 1 self.abs_max_v: 11047.0\n",
      "fc layer 1 self.abs_max_out: 7485.0\n",
      "train - Value 0: 1789 occurrences\n",
      "train - Value 1: 2243 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 446 occurrences\n",
      "test - Value 1: 6 occurrences\n",
      "epoch-19  lr=['2.0000000'], tr/val_loss: 40.717094/  8.851181, val:  51.33%, val_best:  61.06%, tr:  91.44%, tr_best:  94.39%, epoch time: 150.90 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 61.4635%\n",
      "layer   3  Sparsity: 73.4847%\n",
      "total_backward_count 483840 real_backward_count 92929  19.207%\n",
      "layer   1  Sparsity: 81.2826%\n",
      "layer   2  Sparsity: 61.7500%\n",
      "layer   3  Sparsity: 76.0833%\n",
      "fc layer 1 self.abs_max_out: 7488.0\n",
      "train - Value 0: 1857 occurrences\n",
      "train - Value 1: 2175 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-20  lr=['2.0000000'], tr/val_loss: 40.366318/ 37.861099, val:  52.21%, val_best:  61.06%, tr:  90.80%, tr_best:  94.39%, epoch time: 150.85 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 61.1980%\n",
      "layer   3  Sparsity: 73.7557%\n",
      "total_backward_count 508032 real_backward_count 97629  19.217%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 66.4167%\n",
      "layer   3  Sparsity: 75.9167%\n",
      "fc layer 1 self.abs_max_out: 7604.0\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 253 occurrences\n",
      "test - Value 1: 199 occurrences\n",
      "epoch-21  lr=['2.0000000'], tr/val_loss: 30.065910/ 15.973337, val:  73.23%, val_best:  73.23%, tr:  92.49%, tr_best:  94.39%, epoch time: 149.19 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 60.9376%\n",
      "layer   3  Sparsity: 73.8435%\n",
      "total_backward_count 532224 real_backward_count 102268  19.215%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 61.5833%\n",
      "layer   3  Sparsity: 75.8333%\n",
      "lif layer 2 self.abs_max_v: 1445.0\n",
      "fc layer 1 self.abs_max_out: 7713.0\n",
      "train - Value 0: 2178 occurrences\n",
      "train - Value 1: 1854 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-22  lr=['2.0000000'], tr/val_loss: 37.924084/ 40.588402, val:  52.65%, val_best:  73.23%, tr:  93.25%, tr_best:  94.39%, epoch time: 149.51 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 60.6139%\n",
      "layer   3  Sparsity: 74.3760%\n",
      "total_backward_count 556416 real_backward_count 106788  19.192%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 57.5000%\n",
      "layer   3  Sparsity: 71.9167%\n",
      "fc layer 2 self.abs_max_out: 998.0\n",
      "fc layer 1 self.abs_max_out: 7809.0\n",
      "fc layer 2 self.abs_max_out: 1015.0\n",
      "train - Value 0: 2129 occurrences\n",
      "train - Value 1: 1903 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 261 occurrences\n",
      "test - Value 1: 191 occurrences\n",
      "epoch-23  lr=['2.0000000'], tr/val_loss: 31.322289/ 15.024408, val:  72.79%, val_best:  73.23%, tr:  91.49%, tr_best:  94.39%, epoch time: 149.24 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 61.0434%\n",
      "layer   3  Sparsity: 74.0719%\n",
      "total_backward_count 580608 real_backward_count 111482  19.201%\n",
      "layer   1  Sparsity: 75.5208%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "lif layer 2 self.abs_max_v: 1446.5\n",
      "lif layer 2 self.abs_max_v: 1473.5\n",
      "fc layer 2 self.abs_max_out: 1019.0\n",
      "train - Value 0: 2170 occurrences\n",
      "train - Value 1: 1862 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-24  lr=['2.0000000'], tr/val_loss: 30.442945/ 42.717571, val:  50.00%, val_best:  73.23%, tr:  87.60%, tr_best:  94.39%, epoch time: 149.61 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 61.2833%\n",
      "layer   3  Sparsity: 74.1600%\n",
      "total_backward_count 604800 real_backward_count 116356  19.239%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 54.8333%\n",
      "layer   3  Sparsity: 71.0000%\n",
      "fc layer 2 self.abs_max_out: 1023.0\n",
      "train - Value 0: 2259 occurrences\n",
      "train - Value 1: 1773 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-25  lr=['2.0000000'], tr/val_loss: 27.878023/ 38.589252, val:  52.65%, val_best:  73.23%, tr:  88.72%, tr_best:  94.39%, epoch time: 150.61 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 61.3811%\n",
      "layer   3  Sparsity: 74.1693%\n",
      "total_backward_count 628992 real_backward_count 121105  19.254%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 58.6667%\n",
      "layer   3  Sparsity: 72.5833%\n",
      "fc layer 1 self.abs_max_out: 7929.0\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['2.0000000'], tr/val_loss: 37.787476/ 47.905643, val:  50.00%, val_best:  73.23%, tr:  91.72%, tr_best:  94.39%, epoch time: 151.00 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 62.0849%\n",
      "layer   3  Sparsity: 74.8019%\n",
      "total_backward_count 653184 real_backward_count 125817  19.262%\n",
      "layer   1  Sparsity: 72.9818%\n",
      "layer   2  Sparsity: 55.0833%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 102 occurrences\n",
      "test - Value 1: 350 occurrences\n",
      "epoch-27  lr=['2.0000000'], tr/val_loss: 43.092720/ 16.387512, val:  67.70%, val_best:  73.23%, tr:  93.15%, tr_best:  94.39%, epoch time: 151.29 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 62.8096%\n",
      "layer   3  Sparsity: 75.2368%\n",
      "total_backward_count 677376 real_backward_count 130425  19.254%\n",
      "layer   1  Sparsity: 80.7617%\n",
      "layer   2  Sparsity: 64.5833%\n",
      "layer   3  Sparsity: 77.6667%\n",
      "train - Value 0: 1821 occurrences\n",
      "train - Value 1: 2211 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 260 occurrences\n",
      "test - Value 1: 192 occurrences\n",
      "epoch-28  lr=['2.0000000'], tr/val_loss: 37.916508/ 18.678738, val:  75.66%, val_best:  75.66%, tr:  91.74%, tr_best:  94.39%, epoch time: 151.35 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 62.8400%\n",
      "layer   3  Sparsity: 75.7969%\n",
      "total_backward_count 701568 real_backward_count 134995  19.242%\n",
      "layer   1  Sparsity: 80.3385%\n",
      "layer   2  Sparsity: 58.1667%\n",
      "layer   3  Sparsity: 73.3333%\n",
      "lif layer 2 self.abs_max_v: 1480.0\n",
      "lif layer 2 self.abs_max_v: 1531.5\n",
      "train - Value 0: 1962 occurrences\n",
      "train - Value 1: 2070 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-29  lr=['2.0000000'], tr/val_loss: 30.461666/ 18.055130, val:  62.17%, val_best:  75.66%, tr:  92.36%, tr_best:  94.39%, epoch time: 151.99 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 63.2771%\n",
      "layer   3  Sparsity: 75.3825%\n",
      "total_backward_count 725760 real_backward_count 139660  19.243%\n",
      "layer   1  Sparsity: 89.8763%\n",
      "layer   2  Sparsity: 70.3333%\n",
      "layer   3  Sparsity: 77.0000%\n",
      "fc layer 1 self.abs_max_out: 7949.0\n",
      "train - Value 0: 1903 occurrences\n",
      "train - Value 1: 2129 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 403 occurrences\n",
      "test - Value 1: 49 occurrences\n",
      "epoch-30  lr=['2.0000000'], tr/val_loss: 38.344784/ 37.970535, val:  59.51%, val_best:  75.66%, tr:  91.94%, tr_best:  94.39%, epoch time: 150.57 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.1290%\n",
      "layer   3  Sparsity: 74.9465%\n",
      "total_backward_count 749952 real_backward_count 144208  19.229%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 52.5000%\n",
      "layer   3  Sparsity: 71.8333%\n",
      "lif layer 2 self.abs_max_v: 1562.5\n",
      "lif layer 2 self.abs_max_v: 1563.5\n",
      "lif layer 2 self.abs_max_v: 1620.0\n",
      "lif layer 1 self.abs_max_v: 11095.0\n",
      "fc layer 1 self.abs_max_out: 8035.0\n",
      "train - Value 0: 1958 occurrences\n",
      "train - Value 1: 2074 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 357 occurrences\n",
      "test - Value 1: 95 occurrences\n",
      "epoch-31  lr=['2.0000000'], tr/val_loss: 37.077965/ 16.485497, val:  67.48%, val_best:  75.66%, tr:  93.80%, tr_best:  94.39%, epoch time: 151.16 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 62.3374%\n",
      "layer   3  Sparsity: 75.4983%\n",
      "total_backward_count 774144 real_backward_count 148805  19.222%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 56.1667%\n",
      "layer   3  Sparsity: 73.1667%\n",
      "lif layer 1 self.abs_max_v: 11167.0\n",
      "fc layer 2 self.abs_max_out: 1031.0\n",
      "fc layer 1 self.abs_max_out: 8134.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 51 occurrences\n",
      "test - Value 1: 401 occurrences\n",
      "epoch-32  lr=['2.0000000'], tr/val_loss: 36.061714/ 17.394112, val:  60.40%, val_best:  75.66%, tr:  95.56%, tr_best:  95.56%, epoch time: 150.03 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 62.2747%\n",
      "layer   3  Sparsity: 75.2280%\n",
      "total_backward_count 798336 real_backward_count 153300  19.202%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 66.6667%\n",
      "layer   3  Sparsity: 77.3333%\n",
      "fc layer 2 self.abs_max_out: 1033.0\n",
      "lif layer 1 self.abs_max_v: 11300.5\n",
      "fc layer 1 self.abs_max_out: 8159.0\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 415 occurrences\n",
      "test - Value 1: 37 occurrences\n",
      "epoch-33  lr=['2.0000000'], tr/val_loss: 32.946362/ 24.763098, val:  58.19%, val_best:  75.66%, tr:  95.41%, tr_best:  95.56%, epoch time: 150.82 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 62.2690%\n",
      "layer   3  Sparsity: 75.2507%\n",
      "total_backward_count 822528 real_backward_count 157976  19.206%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 56.7500%\n",
      "layer   3  Sparsity: 73.2500%\n",
      "lif layer 1 self.abs_max_v: 11775.0\n",
      "train - Value 0: 1932 occurrences\n",
      "train - Value 1: 2100 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-34  lr=['2.0000000'], tr/val_loss: 37.130497/ 35.157932, val:  73.89%, val_best:  75.66%, tr:  95.34%, tr_best:  95.56%, epoch time: 150.62 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 62.4826%\n",
      "layer   3  Sparsity: 75.8482%\n",
      "total_backward_count 846720 real_backward_count 162531  19.195%\n",
      "layer   1  Sparsity: 87.9232%\n",
      "layer   2  Sparsity: 69.6667%\n",
      "layer   3  Sparsity: 77.5000%\n",
      "train - Value 0: 2105 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-35  lr=['2.0000000'], tr/val_loss: 36.217766/ 52.956451, val:  49.78%, val_best:  75.66%, tr:  93.97%, tr_best:  95.56%, epoch time: 151.25 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 62.2444%\n",
      "layer   3  Sparsity: 75.8582%\n",
      "total_backward_count 870912 real_backward_count 167079  19.184%\n",
      "layer   1  Sparsity: 93.9779%\n",
      "layer   2  Sparsity: 77.9167%\n",
      "layer   3  Sparsity: 82.2500%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['2.0000000'], tr/val_loss: 30.011578/  1.639468, val:  50.00%, val_best:  75.66%, tr:  88.96%, tr_best:  95.56%, epoch time: 149.01 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 62.7600%\n",
      "layer   3  Sparsity: 75.6490%\n",
      "total_backward_count 895104 real_backward_count 171853  19.199%\n",
      "layer   1  Sparsity: 80.7292%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 73.4167%\n",
      "lif layer 2 self.abs_max_v: 1623.5\n",
      "lif layer 2 self.abs_max_v: 1627.5\n",
      "lif layer 2 self.abs_max_v: 1635.0\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-37  lr=['2.0000000'], tr/val_loss: 29.652506/ 29.821495, val:  54.42%, val_best:  75.66%, tr:  92.44%, tr_best:  95.56%, epoch time: 149.08 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 62.7657%\n",
      "layer   3  Sparsity: 75.8545%\n",
      "total_backward_count 919296 real_backward_count 176385  19.187%\n",
      "layer   1  Sparsity: 70.4753%\n",
      "layer   2  Sparsity: 56.4167%\n",
      "layer   3  Sparsity: 74.5833%\n",
      "lif layer 1 self.abs_max_v: 11882.0\n",
      "fc layer 2 self.abs_max_out: 1043.0\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 363 occurrences\n",
      "test - Value 1: 89 occurrences\n",
      "epoch-38  lr=['2.0000000'], tr/val_loss: 34.747864/ 13.354770, val:  64.82%, val_best:  75.66%, tr:  94.15%, tr_best:  95.56%, epoch time: 149.51 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4681%\n",
      "layer   2  Sparsity: 62.1171%\n",
      "layer   3  Sparsity: 76.4463%\n",
      "total_backward_count 943488 real_backward_count 180699  19.152%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 62.4167%\n",
      "layer   3  Sparsity: 73.8333%\n",
      "lif layer 2 self.abs_max_v: 1636.5\n",
      "lif layer 1 self.abs_max_v: 12009.5\n",
      "train - Value 0: 1996 occurrences\n",
      "train - Value 1: 2036 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-39  lr=['2.0000000'], tr/val_loss: 36.069195/ 34.181416, val:  50.44%, val_best:  75.66%, tr:  95.73%, tr_best:  95.73%, epoch time: 149.34 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.2266%\n",
      "layer   3  Sparsity: 75.7865%\n",
      "total_backward_count 967680 real_backward_count 185078  19.126%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 77.6667%\n",
      "fc layer 2 self.abs_max_out: 1046.0\n",
      "lif layer 2 self.abs_max_v: 1646.0\n",
      "fc layer 2 self.abs_max_out: 1063.0\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 172 occurrences\n",
      "test - Value 1: 280 occurrences\n",
      "epoch-40  lr=['2.0000000'], tr/val_loss: 32.403904/ 33.391235, val:  77.43%, val_best:  77.43%, tr:  91.64%, tr_best:  95.73%, epoch time: 152.07 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 62.7129%\n",
      "layer   3  Sparsity: 75.8703%\n",
      "total_backward_count 991872 real_backward_count 189459  19.101%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 63.5000%\n",
      "layer   3  Sparsity: 73.1667%\n",
      "lif layer 1 self.abs_max_v: 12110.0\n",
      "train - Value 0: 2106 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 653.00 at epoch 41, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-41  lr=['2.0000000'], tr/val_loss: 30.639650/ 86.664314, val:  50.00%, val_best:  77.43%, tr:  91.37%, tr_best:  95.73%, epoch time: 151.17 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 62.8287%\n",
      "layer   3  Sparsity: 75.2269%\n",
      "total_backward_count 1016064 real_backward_count 194020  19.095%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 72.6667%\n",
      "lif layer 1 self.abs_max_v: 12139.0\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['2.0000000'], tr/val_loss: 35.922062/  4.890276, val:  50.00%, val_best:  77.43%, tr:  94.52%, tr_best:  95.73%, epoch time: 150.51 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4683%\n",
      "layer   2  Sparsity: 62.8724%\n",
      "layer   3  Sparsity: 75.0551%\n",
      "total_backward_count 1040256 real_backward_count 198333  19.066%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 67.6667%\n",
      "layer   3  Sparsity: 77.1667%\n",
      "fc layer 3 self.abs_max_out: 156.0\n",
      "lif layer 1 self.abs_max_v: 12232.5\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 337 occurrences\n",
      "test - Value 1: 115 occurrences\n",
      "epoch-43  lr=['2.0000000'], tr/val_loss: 29.299358/ 17.988134, val:  69.25%, val_best:  77.43%, tr:  94.64%, tr_best:  95.73%, epoch time: 150.86 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 62.8963%\n",
      "layer   3  Sparsity: 75.1762%\n",
      "total_backward_count 1064448 real_backward_count 202708  19.043%\n",
      "layer   1  Sparsity: 89.1276%\n",
      "layer   2  Sparsity: 70.0833%\n",
      "layer   3  Sparsity: 77.1667%\n",
      "fc layer 2 self.abs_max_out: 1067.0\n",
      "lif layer 2 self.abs_max_v: 1659.0\n",
      "train - Value 0: 1904 occurrences\n",
      "train - Value 1: 2128 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['2.0000000'], tr/val_loss: 36.303444/ 49.899666, val:  50.00%, val_best:  77.43%, tr:  92.81%, tr_best:  95.73%, epoch time: 150.86 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 62.5161%\n",
      "layer   3  Sparsity: 75.1812%\n",
      "total_backward_count 1088640 real_backward_count 207189  19.032%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 58.6667%\n",
      "layer   3  Sparsity: 72.7500%\n",
      "lif layer 2 self.abs_max_v: 1666.5\n",
      "lif layer 2 self.abs_max_v: 1721.0\n",
      "fc layer 1 self.abs_max_out: 8167.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['2.0000000'], tr/val_loss: 32.378445/ 40.350422, val:  50.00%, val_best:  77.43%, tr:  94.62%, tr_best:  95.73%, epoch time: 151.13 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 62.4668%\n",
      "layer   3  Sparsity: 74.6573%\n",
      "total_backward_count 1112832 real_backward_count 211611  19.016%\n",
      "layer   1  Sparsity: 93.5872%\n",
      "layer   2  Sparsity: 77.0833%\n",
      "layer   3  Sparsity: 81.5000%\n",
      "fc layer 3 self.abs_max_out: 162.0\n",
      "fc layer 3 self.abs_max_out: 174.0\n",
      "fc layer 3 self.abs_max_out: 176.0\n",
      "lif layer 2 self.abs_max_v: 1722.0\n",
      "lif layer 2 self.abs_max_v: 1746.0\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 396 occurrences\n",
      "test - Value 1: 56 occurrences\n",
      "epoch-46  lr=['2.0000000'], tr/val_loss: 39.496628/ 39.909763, val:  60.62%, val_best:  77.43%, tr:  94.25%, tr_best:  95.73%, epoch time: 151.08 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 62.8711%\n",
      "layer   3  Sparsity: 74.9240%\n",
      "total_backward_count 1137024 real_backward_count 216005  18.997%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 73.0833%\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-47  lr=['2.0000000'], tr/val_loss: 27.312372/ 16.762842, val:  51.11%, val_best:  77.43%, tr:  92.04%, tr_best:  95.73%, epoch time: 152.56 seconds, 2.54 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 63.5504%\n",
      "layer   3  Sparsity: 74.9003%\n",
      "total_backward_count 1161216 real_backward_count 220420  18.982%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 69.3333%\n",
      "layer   3  Sparsity: 77.2500%\n",
      "fc layer 1 self.abs_max_out: 8700.0\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 708.00 at epoch 48, iter 4031\n",
      "max_activation_accul updated: 713.00 at epoch 48, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['2.0000000'], tr/val_loss: 34.225845/ 57.139015, val:  50.00%, val_best:  77.43%, tr:  96.88%, tr_best:  96.88%, epoch time: 152.17 seconds, 2.54 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 63.6249%\n",
      "layer   3  Sparsity: 74.7233%\n",
      "total_backward_count 1185408 real_backward_count 224560  18.944%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 72.5000%\n",
      "layer   3  Sparsity: 76.5000%\n",
      "fc layer 1 self.abs_max_out: 8757.0\n",
      "train - Value 0: 1998 occurrences\n",
      "train - Value 1: 2034 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-49  lr=['2.0000000'], tr/val_loss: 36.570354/ 62.441151, val:  50.88%, val_best:  77.43%, tr:  94.20%, tr_best:  96.88%, epoch time: 152.68 seconds, 2.54 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.1251%\n",
      "layer   3  Sparsity: 74.6947%\n",
      "total_backward_count 1209600 real_backward_count 229009  18.933%\n",
      "layer   1  Sparsity: 81.9336%\n",
      "layer   2  Sparsity: 67.2500%\n",
      "layer   3  Sparsity: 76.5833%\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['2.0000000'], tr/val_loss: 41.819916/ 70.762924, val:  50.00%, val_best:  77.43%, tr:  94.64%, tr_best:  96.88%, epoch time: 151.01 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.0615%\n",
      "layer   3  Sparsity: 74.3085%\n",
      "total_backward_count 1233792 real_backward_count 233460  18.922%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 63.0833%\n",
      "layer   3  Sparsity: 76.3333%\n",
      "lif layer 1 self.abs_max_v: 12267.0\n",
      "fc layer 1 self.abs_max_out: 9113.0\n",
      "train - Value 0: 2134 occurrences\n",
      "train - Value 1: 1898 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-51  lr=['2.0000000'], tr/val_loss: 31.576546/  8.947998, val:  65.93%, val_best:  77.43%, tr:  93.06%, tr_best:  96.88%, epoch time: 149.95 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 63.2255%\n",
      "layer   3  Sparsity: 74.3524%\n",
      "total_backward_count 1257984 real_backward_count 238017  18.921%\n",
      "layer   1  Sparsity: 87.6953%\n",
      "layer   2  Sparsity: 70.4167%\n",
      "layer   3  Sparsity: 76.8333%\n",
      "fc layer 1 self.abs_max_out: 9155.0\n",
      "train - Value 0: 2150 occurrences\n",
      "train - Value 1: 1882 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 190 occurrences\n",
      "test - Value 1: 262 occurrences\n",
      "epoch-52  lr=['2.0000000'], tr/val_loss: 25.375635/  7.077850, val:  75.22%, val_best:  77.43%, tr:  89.58%, tr_best:  96.88%, epoch time: 148.50 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 63.6319%\n",
      "layer   3  Sparsity: 74.2054%\n",
      "total_backward_count 1282176 real_backward_count 242503  18.913%\n",
      "layer   1  Sparsity: 91.9922%\n",
      "layer   2  Sparsity: 70.1667%\n",
      "layer   3  Sparsity: 76.3333%\n",
      "fc layer 1 self.abs_max_out: 9171.0\n",
      "fc layer 2 self.abs_max_out: 1074.0\n",
      "fc layer 2 self.abs_max_out: 1076.0\n",
      "train - Value 0: 2105 occurrences\n",
      "train - Value 1: 1927 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-53  lr=['2.0000000'], tr/val_loss: 31.462881/ 11.519079, val:  71.68%, val_best:  77.43%, tr:  93.97%, tr_best:  96.88%, epoch time: 148.60 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 63.1940%\n",
      "layer   3  Sparsity: 73.5589%\n",
      "total_backward_count 1306368 real_backward_count 246972  18.905%\n",
      "layer   1  Sparsity: 86.3281%\n",
      "layer   2  Sparsity: 67.5833%\n",
      "layer   3  Sparsity: 76.3333%\n",
      "fc layer 2 self.abs_max_out: 1077.0\n",
      "fc layer 2 self.abs_max_out: 1078.0\n",
      "train - Value 0: 1987 occurrences\n",
      "train - Value 1: 2045 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-54  lr=['2.0000000'], tr/val_loss: 35.910847/ 59.306099, val:  50.00%, val_best:  77.43%, tr:  94.87%, tr_best:  96.88%, epoch time: 148.99 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 63.2106%\n",
      "layer   3  Sparsity: 74.1498%\n",
      "total_backward_count 1330560 real_backward_count 251044  18.868%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 58.5000%\n",
      "layer   3  Sparsity: 72.3333%\n",
      "fc layer 2 self.abs_max_out: 1081.0\n",
      "train - Value 0: 1956 occurrences\n",
      "train - Value 1: 2076 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 309 occurrences\n",
      "test - Value 1: 143 occurrences\n",
      "epoch-55  lr=['2.0000000'], tr/val_loss: 42.693836/ 15.841328, val:  76.33%, val_best:  77.43%, tr:  92.56%, tr_best:  96.88%, epoch time: 149.64 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.1306%\n",
      "layer   3  Sparsity: 74.0560%\n",
      "total_backward_count 1354752 real_backward_count 255538  18.862%\n",
      "layer   1  Sparsity: 81.0872%\n",
      "layer   2  Sparsity: 57.9167%\n",
      "layer   3  Sparsity: 71.5000%\n",
      "fc layer 2 self.abs_max_out: 1086.0\n",
      "train - Value 0: 2047 occurrences\n",
      "train - Value 1: 1985 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 87 occurrences\n",
      "test - Value 1: 365 occurrences\n",
      "epoch-56  lr=['2.0000000'], tr/val_loss: 28.729130/ 30.963161, val:  66.59%, val_best:  77.43%, tr:  94.47%, tr_best:  96.88%, epoch time: 151.00 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.1389%\n",
      "layer   3  Sparsity: 74.1110%\n",
      "total_backward_count 1378944 real_backward_count 259927  18.850%\n",
      "layer   1  Sparsity: 89.7135%\n",
      "layer   2  Sparsity: 70.3333%\n",
      "layer   3  Sparsity: 76.4167%\n",
      "train - Value 0: 2080 occurrences\n",
      "train - Value 1: 1952 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 415 occurrences\n",
      "test - Value 1: 37 occurrences\n",
      "epoch-57  lr=['2.0000000'], tr/val_loss: 30.034842/ 25.217960, val:  56.86%, val_best:  77.43%, tr:  94.89%, tr_best:  96.88%, epoch time: 150.25 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.6234%\n",
      "layer   3  Sparsity: 74.5379%\n",
      "total_backward_count 1403136 real_backward_count 264262  18.834%\n",
      "layer   1  Sparsity: 92.0898%\n",
      "layer   2  Sparsity: 76.1667%\n",
      "layer   3  Sparsity: 81.8333%\n",
      "lif layer 1 self.abs_max_v: 12602.5\n",
      "fc layer 2 self.abs_max_out: 1087.0\n",
      "fc layer 2 self.abs_max_out: 1110.0\n",
      "fc layer 2 self.abs_max_out: 1150.0\n",
      "train - Value 0: 2130 occurrences\n",
      "train - Value 1: 1902 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-58  lr=['2.0000000'], tr/val_loss: 32.013054/ 52.352001, val:  50.66%, val_best:  77.43%, tr:  95.24%, tr_best:  96.88%, epoch time: 149.29 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 63.5318%\n",
      "layer   3  Sparsity: 75.1092%\n",
      "total_backward_count 1427328 real_backward_count 268393  18.804%\n",
      "layer   1  Sparsity: 78.4831%\n",
      "layer   2  Sparsity: 57.7500%\n",
      "layer   3  Sparsity: 72.6667%\n",
      "fc layer 2 self.abs_max_out: 1158.0\n",
      "fc layer 2 self.abs_max_out: 1180.0\n",
      "fc layer 2 self.abs_max_out: 1268.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 203 occurrences\n",
      "test - Value 1: 249 occurrences\n",
      "epoch-59  lr=['2.0000000'], tr/val_loss: 41.744572/ 22.667240, val:  78.10%, val_best:  78.10%, tr:  98.46%, tr_best:  98.46%, epoch time: 150.06 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 63.2081%\n",
      "layer   3  Sparsity: 74.8517%\n",
      "total_backward_count 1451520 real_backward_count 272341  18.762%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 63.3333%\n",
      "layer   3  Sparsity: 72.1667%\n",
      "lif layer 1 self.abs_max_v: 12719.5\n",
      "lif layer 2 self.abs_max_v: 1795.0\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-60  lr=['2.0000000'], tr/val_loss: 42.508881/ 20.189322, val:  69.91%, val_best:  78.10%, tr:  94.02%, tr_best:  98.46%, epoch time: 150.84 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 63.0406%\n",
      "layer   3  Sparsity: 74.7105%\n",
      "total_backward_count 1475712 real_backward_count 276741  18.753%\n",
      "layer   1  Sparsity: 75.0000%\n",
      "layer   2  Sparsity: 56.4167%\n",
      "layer   3  Sparsity: 72.5000%\n",
      "lif layer 2 self.abs_max_v: 1933.5\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['2.0000000'], tr/val_loss: 38.717686/ 34.310749, val:  50.00%, val_best:  78.10%, tr:  88.22%, tr_best:  98.46%, epoch time: 150.17 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 63.0802%\n",
      "layer   3  Sparsity: 74.2461%\n",
      "total_backward_count 1499904 real_backward_count 281302  18.755%\n",
      "layer   1  Sparsity: 78.5807%\n",
      "layer   2  Sparsity: 67.1667%\n",
      "layer   3  Sparsity: 76.0833%\n",
      "train - Value 0: 1943 occurrences\n",
      "train - Value 1: 2089 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-62  lr=['2.0000000'], tr/val_loss: 31.430496/ 19.991917, val:  69.03%, val_best:  78.10%, tr:  87.03%, tr_best:  98.46%, epoch time: 150.55 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.6429%\n",
      "layer   3  Sparsity: 74.3122%\n",
      "total_backward_count 1524096 real_backward_count 285925  18.760%\n",
      "layer   1  Sparsity: 80.9896%\n",
      "layer   2  Sparsity: 58.7500%\n",
      "layer   3  Sparsity: 71.5833%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-63  lr=['2.0000000'], tr/val_loss: 31.331921/ 27.748878, val:  52.88%, val_best:  78.10%, tr:  90.77%, tr_best:  98.46%, epoch time: 150.67 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 63.5078%\n",
      "layer   3  Sparsity: 74.4095%\n",
      "total_backward_count 1548288 real_backward_count 290345  18.753%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 59.0833%\n",
      "layer   3  Sparsity: 71.5833%\n",
      "fc layer 3 self.abs_max_out: 183.0\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 322 occurrences\n",
      "test - Value 1: 130 occurrences\n",
      "epoch-64  lr=['2.0000000'], tr/val_loss: 47.753662/ 21.984159, val:  73.45%, val_best:  78.10%, tr:  95.44%, tr_best:  98.46%, epoch time: 151.10 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.8637%\n",
      "layer   3  Sparsity: 73.4943%\n",
      "total_backward_count 1572480 real_backward_count 294782  18.746%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 67.1667%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 68 occurrences\n",
      "test - Value 1: 384 occurrences\n",
      "epoch-65  lr=['2.0000000'], tr/val_loss: 44.168015/ 31.862331, val:  62.83%, val_best:  78.10%, tr:  96.18%, tr_best:  98.46%, epoch time: 150.60 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 63.7071%\n",
      "layer   3  Sparsity: 73.2864%\n",
      "total_backward_count 1596672 real_backward_count 299154  18.736%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 72.1667%\n",
      "layer   3  Sparsity: 75.5833%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 61 occurrences\n",
      "test - Value 1: 391 occurrences\n",
      "epoch-66  lr=['2.0000000'], tr/val_loss: 36.693886/ 48.815010, val:  63.05%, val_best:  78.10%, tr:  95.63%, tr_best:  98.46%, epoch time: 149.58 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 63.7520%\n",
      "layer   3  Sparsity: 73.4017%\n",
      "total_backward_count 1620864 real_backward_count 303527  18.726%\n",
      "layer   1  Sparsity: 79.1341%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 76.0000%\n",
      "train - Value 0: 1963 occurrences\n",
      "train - Value 1: 2069 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 88 occurrences\n",
      "test - Value 1: 364 occurrences\n",
      "epoch-67  lr=['2.0000000'], tr/val_loss: 41.858784/ 31.870890, val:  66.81%, val_best:  78.10%, tr:  95.61%, tr_best:  98.46%, epoch time: 148.90 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.3331%\n",
      "layer   3  Sparsity: 73.4390%\n",
      "total_backward_count 1645056 real_backward_count 307675  18.703%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 63.5833%\n",
      "layer   3  Sparsity: 70.1667%\n",
      "train - Value 0: 1916 occurrences\n",
      "train - Value 1: 2116 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-68  lr=['2.0000000'], tr/val_loss: 41.537914/ 64.307121, val:  50.00%, val_best:  78.10%, tr:  94.25%, tr_best:  98.46%, epoch time: 149.39 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 63.8034%\n",
      "layer   3  Sparsity: 73.8134%\n",
      "total_backward_count 1669248 real_backward_count 312021  18.692%\n",
      "layer   1  Sparsity: 89.8112%\n",
      "layer   2  Sparsity: 75.7500%\n",
      "layer   3  Sparsity: 81.1667%\n",
      "train - Value 0: 1886 occurrences\n",
      "train - Value 1: 2146 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 353 occurrences\n",
      "test - Value 1: 99 occurrences\n",
      "epoch-69  lr=['2.0000000'], tr/val_loss: 38.116100/ 27.076075, val:  70.13%, val_best:  78.10%, tr:  93.45%, tr_best:  98.46%, epoch time: 148.86 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 63.5045%\n",
      "layer   3  Sparsity: 74.2710%\n",
      "total_backward_count 1693440 real_backward_count 316347  18.681%\n",
      "layer   1  Sparsity: 73.4701%\n",
      "layer   2  Sparsity: 53.9167%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-70  lr=['2.0000000'], tr/val_loss: 34.842384/ 54.156487, val:  50.00%, val_best:  78.10%, tr:  95.46%, tr_best:  98.46%, epoch time: 150.03 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 63.5355%\n",
      "layer   3  Sparsity: 74.4520%\n",
      "total_backward_count 1717632 real_backward_count 320601  18.665%\n",
      "layer   1  Sparsity: 73.0143%\n",
      "layer   2  Sparsity: 57.4167%\n",
      "layer   3  Sparsity: 72.0000%\n",
      "train - Value 0: 1935 occurrences\n",
      "train - Value 1: 2097 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 371 occurrences\n",
      "test - Value 1: 81 occurrences\n",
      "epoch-71  lr=['2.0000000'], tr/val_loss: 44.021759/ 25.000252, val:  66.15%, val_best:  78.10%, tr:  95.96%, tr_best:  98.46%, epoch time: 151.64 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 62.9875%\n",
      "layer   3  Sparsity: 74.2510%\n",
      "total_backward_count 1741824 real_backward_count 324710  18.642%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 67.6667%\n",
      "layer   3  Sparsity: 76.2500%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 6 occurrences\n",
      "test - Value 1: 446 occurrences\n",
      "epoch-72  lr=['2.0000000'], tr/val_loss: 36.270386/ 49.063587, val:  51.33%, val_best:  78.10%, tr:  96.50%, tr_best:  98.46%, epoch time: 150.87 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 63.0646%\n",
      "layer   3  Sparsity: 74.0400%\n",
      "total_backward_count 1766016 real_backward_count 328773  18.617%\n",
      "layer   1  Sparsity: 81.8685%\n",
      "layer   2  Sparsity: 64.5833%\n",
      "layer   3  Sparsity: 76.5833%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-73  lr=['2.0000000'], tr/val_loss: 36.840034/ 59.327099, val:  50.00%, val_best:  78.10%, tr:  94.82%, tr_best:  98.46%, epoch time: 151.10 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.7791%\n",
      "layer   3  Sparsity: 73.6712%\n",
      "total_backward_count 1790208 real_backward_count 332981  18.600%\n",
      "layer   1  Sparsity: 87.5000%\n",
      "layer   2  Sparsity: 69.9167%\n",
      "layer   3  Sparsity: 75.5833%\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 72 occurrences\n",
      "test - Value 1: 380 occurrences\n",
      "epoch-74  lr=['2.0000000'], tr/val_loss: 42.721745/ 28.178497, val:  64.60%, val_best:  78.10%, tr:  96.92%, tr_best:  98.46%, epoch time: 151.42 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 62.6882%\n",
      "layer   3  Sparsity: 73.4218%\n",
      "total_backward_count 1814400 real_backward_count 337117  18.580%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 69.7500%\n",
      "layer   3  Sparsity: 75.4167%\n",
      "train - Value 0: 2029 occurrences\n",
      "train - Value 1: 2003 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 208 occurrences\n",
      "test - Value 1: 244 occurrences\n",
      "epoch-75  lr=['2.0000000'], tr/val_loss: 35.188110/ 20.639322, val:  76.11%, val_best:  78.10%, tr:  96.50%, tr_best:  98.46%, epoch time: 152.02 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.6621%\n",
      "layer   3  Sparsity: 73.3678%\n",
      "total_backward_count 1838592 real_backward_count 341397  18.568%\n",
      "layer   1  Sparsity: 87.1419%\n",
      "layer   2  Sparsity: 67.6667%\n",
      "layer   3  Sparsity: 75.6667%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 95 occurrences\n",
      "test - Value 1: 357 occurrences\n",
      "epoch-76  lr=['2.0000000'], tr/val_loss: 32.249004/ 25.681128, val:  68.81%, val_best:  78.10%, tr:  96.21%, tr_best:  98.46%, epoch time: 150.96 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 62.6208%\n",
      "layer   3  Sparsity: 73.4467%\n",
      "total_backward_count 1862784 real_backward_count 345631  18.555%\n",
      "layer   1  Sparsity: 77.6367%\n",
      "layer   2  Sparsity: 54.5000%\n",
      "layer   3  Sparsity: 70.5833%\n",
      "train - Value 0: 2162 occurrences\n",
      "train - Value 1: 1870 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 401 occurrences\n",
      "test - Value 1: 51 occurrences\n",
      "epoch-77  lr=['2.0000000'], tr/val_loss: 27.823061/  6.430408, val:  60.84%, val_best:  78.10%, tr:  94.39%, tr_best:  98.46%, epoch time: 151.15 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 62.6225%\n",
      "layer   3  Sparsity: 73.7532%\n",
      "total_backward_count 1886976 real_backward_count 349978  18.547%\n",
      "layer   1  Sparsity: 78.4180%\n",
      "layer   2  Sparsity: 62.9167%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-78  lr=['2.0000000'], tr/val_loss: 27.472994/ 37.501534, val:  51.11%, val_best:  78.10%, tr:  97.10%, tr_best:  98.46%, epoch time: 151.51 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 62.5324%\n",
      "layer   3  Sparsity: 73.7379%\n",
      "total_backward_count 1911168 real_backward_count 354110  18.528%\n",
      "layer   1  Sparsity: 86.5560%\n",
      "layer   2  Sparsity: 56.0000%\n",
      "layer   3  Sparsity: 72.1667%\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 396 occurrences\n",
      "test - Value 1: 56 occurrences\n",
      "epoch-79  lr=['2.0000000'], tr/val_loss: 29.329372/ 31.273415, val:  61.50%, val_best:  78.10%, tr:  93.40%, tr_best:  98.46%, epoch time: 151.63 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 62.2002%\n",
      "layer   3  Sparsity: 74.6368%\n",
      "total_backward_count 1935360 real_backward_count 358391  18.518%\n",
      "layer   1  Sparsity: 84.8307%\n",
      "layer   2  Sparsity: 58.0833%\n",
      "layer   3  Sparsity: 72.4167%\n",
      "train - Value 0: 2169 occurrences\n",
      "train - Value 1: 1863 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-80  lr=['2.0000000'], tr/val_loss: 30.761311/ 24.973154, val:  50.00%, val_best:  78.10%, tr:  94.77%, tr_best:  98.46%, epoch time: 150.82 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 62.3921%\n",
      "layer   3  Sparsity: 74.7351%\n",
      "total_backward_count 1959552 real_backward_count 362448  18.496%\n",
      "layer   1  Sparsity: 89.2253%\n",
      "layer   2  Sparsity: 72.3333%\n",
      "layer   3  Sparsity: 77.2500%\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 24 occurrences\n",
      "test - Value 1: 428 occurrences\n",
      "epoch-81  lr=['2.0000000'], tr/val_loss: 27.123781/ 28.168352, val:  54.87%, val_best:  78.10%, tr:  95.31%, tr_best:  98.46%, epoch time: 151.37 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 62.1611%\n",
      "layer   3  Sparsity: 74.8258%\n",
      "total_backward_count 1983744 real_backward_count 366663  18.483%\n",
      "layer   1  Sparsity: 80.7943%\n",
      "layer   2  Sparsity: 55.4167%\n",
      "layer   3  Sparsity: 72.5833%\n",
      "lif layer 1 self.abs_max_v: 12759.5\n",
      "train - Value 0: 2111 occurrences\n",
      "train - Value 1: 1921 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-82  lr=['2.0000000'], tr/val_loss: 29.330297/ 45.774040, val:  54.42%, val_best:  78.10%, tr:  93.77%, tr_best:  98.46%, epoch time: 148.73 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 61.8684%\n",
      "layer   3  Sparsity: 74.8831%\n",
      "total_backward_count 2007936 real_backward_count 370828  18.468%\n",
      "layer   1  Sparsity: 77.1159%\n",
      "layer   2  Sparsity: 51.8333%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "lif layer 1 self.abs_max_v: 12900.0\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-83  lr=['2.0000000'], tr/val_loss: 33.473080/ 35.044933, val:  55.09%, val_best:  78.10%, tr:  94.69%, tr_best:  98.46%, epoch time: 149.03 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 62.1936%\n",
      "layer   3  Sparsity: 74.4789%\n",
      "total_backward_count 2032128 real_backward_count 375060  18.457%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 52.6667%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "lif layer 1 self.abs_max_v: 12905.0\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 5 occurrences\n",
      "test - Value 1: 447 occurrences\n",
      "epoch-84  lr=['2.0000000'], tr/val_loss: 42.321457/ 37.759373, val:  51.11%, val_best:  78.10%, tr:  96.58%, tr_best:  98.46%, epoch time: 150.26 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 62.3460%\n",
      "layer   3  Sparsity: 74.0457%\n",
      "total_backward_count 2056320 real_backward_count 379209  18.441%\n",
      "layer   1  Sparsity: 73.8281%\n",
      "layer   2  Sparsity: 55.7500%\n",
      "layer   3  Sparsity: 70.4167%\n",
      "lif layer 1 self.abs_max_v: 12908.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 12 occurrences\n",
      "test - Value 1: 440 occurrences\n",
      "epoch-85  lr=['2.0000000'], tr/val_loss: 35.091755/ 50.929440, val:  52.65%, val_best:  78.10%, tr:  97.10%, tr_best:  98.46%, epoch time: 149.47 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 61.9962%\n",
      "layer   3  Sparsity: 73.8178%\n",
      "total_backward_count 2080512 real_backward_count 383507  18.433%\n",
      "layer   1  Sparsity: 73.6328%\n",
      "layer   2  Sparsity: 56.9167%\n",
      "layer   3  Sparsity: 71.0000%\n",
      "train - Value 0: 1972 occurrences\n",
      "train - Value 1: 2060 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-86  lr=['2.0000000'], tr/val_loss: 31.040369/ 53.993633, val:  50.22%, val_best:  78.10%, tr:  96.38%, tr_best:  98.46%, epoch time: 150.60 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4674%\n",
      "layer   2  Sparsity: 62.1622%\n",
      "layer   3  Sparsity: 74.1124%\n",
      "total_backward_count 2104704 real_backward_count 387808  18.426%\n",
      "layer   1  Sparsity: 81.3477%\n",
      "layer   2  Sparsity: 56.9167%\n",
      "layer   3  Sparsity: 71.4167%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-87  lr=['2.0000000'], tr/val_loss: 35.392761/ 26.838095, val:  53.54%, val_best:  78.10%, tr:  94.35%, tr_best:  98.46%, epoch time: 151.58 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 62.4089%\n",
      "layer   3  Sparsity: 73.7265%\n",
      "total_backward_count 2128896 real_backward_count 392099  18.418%\n",
      "layer   1  Sparsity: 79.4596%\n",
      "layer   2  Sparsity: 58.9167%\n",
      "layer   3  Sparsity: 70.3333%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 45 occurrences\n",
      "test - Value 1: 407 occurrences\n",
      "epoch-88  lr=['2.0000000'], tr/val_loss: 30.130882/ 34.859287, val:  58.63%, val_best:  78.10%, tr:  96.75%, tr_best:  98.46%, epoch time: 150.82 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 62.6209%\n",
      "layer   3  Sparsity: 73.3850%\n",
      "total_backward_count 2153088 real_backward_count 396291  18.406%\n",
      "layer   1  Sparsity: 91.8945%\n",
      "layer   2  Sparsity: 76.5000%\n",
      "layer   3  Sparsity: 80.8333%\n",
      "train - Value 0: 2106 occurrences\n",
      "train - Value 1: 1926 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-89  lr=['2.0000000'], tr/val_loss: 32.738903/ 33.872288, val:  51.99%, val_best:  78.10%, tr:  95.68%, tr_best:  98.46%, epoch time: 150.87 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 62.5951%\n",
      "layer   3  Sparsity: 73.2892%\n",
      "total_backward_count 2177280 real_backward_count 400476  18.393%\n",
      "layer   1  Sparsity: 84.6029%\n",
      "layer   2  Sparsity: 66.6667%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "lif layer 1 self.abs_max_v: 13043.0\n",
      "train - Value 0: 2112 occurrences\n",
      "train - Value 1: 1920 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 59 occurrences\n",
      "test - Value 1: 393 occurrences\n",
      "epoch-90  lr=['2.0000000'], tr/val_loss: 38.368263/ 16.033253, val:  60.84%, val_best:  78.10%, tr:  96.58%, tr_best:  98.46%, epoch time: 150.44 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 62.5116%\n",
      "layer   3  Sparsity: 73.0663%\n",
      "total_backward_count 2201472 real_backward_count 404802  18.388%\n",
      "layer   1  Sparsity: 82.7474%\n",
      "layer   2  Sparsity: 66.1667%\n",
      "layer   3  Sparsity: 75.5833%\n",
      "train - Value 0: 2076 occurrences\n",
      "train - Value 1: 1956 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-91  lr=['2.0000000'], tr/val_loss: 36.841492/ 29.528440, val:  55.53%, val_best:  78.10%, tr:  96.63%, tr_best:  98.46%, epoch time: 150.20 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.2246%\n",
      "layer   3  Sparsity: 73.4917%\n",
      "total_backward_count 2225664 real_backward_count 408929  18.373%\n",
      "layer   1  Sparsity: 81.3151%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "lif layer 1 self.abs_max_v: 13077.5\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-92  lr=['2.0000000'], tr/val_loss: 36.246586/ 25.813444, val:  51.55%, val_best:  78.10%, tr:  96.92%, tr_best:  98.46%, epoch time: 151.43 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 62.0090%\n",
      "layer   3  Sparsity: 73.6857%\n",
      "total_backward_count 2249856 real_backward_count 413004  18.357%\n",
      "layer   1  Sparsity: 80.9570%\n",
      "layer   2  Sparsity: 62.5000%\n",
      "layer   3  Sparsity: 71.0000%\n",
      "lif layer 1 self.abs_max_v: 13135.5\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-93  lr=['2.0000000'], tr/val_loss: 35.301224/ 33.493008, val:  50.00%, val_best:  78.10%, tr:  91.12%, tr_best:  98.46%, epoch time: 150.42 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 62.0307%\n",
      "layer   3  Sparsity: 73.9268%\n",
      "total_backward_count 2274048 real_backward_count 417531  18.361%\n",
      "layer   1  Sparsity: 77.0182%\n",
      "layer   2  Sparsity: 54.3333%\n",
      "layer   3  Sparsity: 71.2500%\n",
      "lif layer 1 self.abs_max_v: 13223.0\n",
      "train - Value 0: 1942 occurrences\n",
      "train - Value 1: 2090 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-94  lr=['2.0000000'], tr/val_loss: 30.125290/ 26.239166, val:  50.00%, val_best:  78.10%, tr:  92.31%, tr_best:  98.46%, epoch time: 151.93 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 62.3005%\n",
      "layer   3  Sparsity: 74.3007%\n",
      "total_backward_count 2298240 real_backward_count 422138  18.368%\n",
      "layer   1  Sparsity: 68.0013%\n",
      "layer   2  Sparsity: 55.1667%\n",
      "layer   3  Sparsity: 71.9167%\n",
      "lif layer 1 self.abs_max_v: 13231.0\n",
      "train - Value 0: 1992 occurrences\n",
      "train - Value 1: 2040 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 163 occurrences\n",
      "test - Value 1: 289 occurrences\n",
      "epoch-95  lr=['2.0000000'], tr/val_loss: 40.191849/ 49.417347, val:  77.21%, val_best:  78.10%, tr:  96.97%, tr_best:  98.46%, epoch time: 150.62 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4686%\n",
      "layer   2  Sparsity: 62.8982%\n",
      "layer   3  Sparsity: 74.1379%\n",
      "total_backward_count 2322432 real_backward_count 426387  18.360%\n",
      "layer   1  Sparsity: 90.1693%\n",
      "layer   2  Sparsity: 73.8333%\n",
      "layer   3  Sparsity: 81.1667%\n",
      "lif layer 1 self.abs_max_v: 13258.0\n",
      "train - Value 0: 2087 occurrences\n",
      "train - Value 1: 1945 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-96  lr=['2.0000000'], tr/val_loss: 43.329712/ 51.219200, val:  50.22%, val_best:  78.10%, tr:  96.60%, tr_best:  98.46%, epoch time: 150.94 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 62.9331%\n",
      "layer   3  Sparsity: 73.7287%\n",
      "total_backward_count 2346624 real_backward_count 430684  18.353%\n",
      "layer   1  Sparsity: 72.0378%\n",
      "layer   2  Sparsity: 53.9167%\n",
      "layer   3  Sparsity: 70.6667%\n",
      "train - Value 0: 2070 occurrences\n",
      "train - Value 1: 1962 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 419 occurrences\n",
      "test - Value 1: 33 occurrences\n",
      "epoch-97  lr=['2.0000000'], tr/val_loss: 47.324890/ 44.933601, val:  57.30%, val_best:  78.10%, tr:  96.58%, tr_best:  98.46%, epoch time: 149.41 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 62.6593%\n",
      "layer   3  Sparsity: 73.4434%\n",
      "total_backward_count 2370816 real_backward_count 434893  18.344%\n",
      "layer   1  Sparsity: 78.7435%\n",
      "layer   2  Sparsity: 56.3333%\n",
      "layer   3  Sparsity: 70.5833%\n",
      "lif layer 1 self.abs_max_v: 13282.5\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-98  lr=['2.0000000'], tr/val_loss: 37.426445/ 48.675537, val:  51.55%, val_best:  78.10%, tr:  97.15%, tr_best:  98.46%, epoch time: 149.17 seconds, 2.49 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 63.2877%\n",
      "layer   3  Sparsity: 73.8962%\n",
      "total_backward_count 2395008 real_backward_count 438963  18.328%\n",
      "layer   1  Sparsity: 79.8503%\n",
      "layer   2  Sparsity: 59.0833%\n",
      "layer   3  Sparsity: 71.5833%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 100 occurrences\n",
      "test - Value 1: 352 occurrences\n",
      "epoch-99  lr=['2.0000000'], tr/val_loss: 41.328388/ 35.516327, val:  69.03%, val_best:  78.10%, tr:  97.10%, tr_best:  98.46%, epoch time: 150.04 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 63.6005%\n",
      "layer   3  Sparsity: 74.4018%\n",
      "total_backward_count 2419200 real_backward_count 443063  18.314%\n",
      "layer   1  Sparsity: 83.6589%\n",
      "layer   2  Sparsity: 66.0000%\n",
      "layer   3  Sparsity: 76.5833%\n",
      "train - Value 0: 1982 occurrences\n",
      "train - Value 1: 2050 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-100 lr=['2.0000000'], tr/val_loss: 37.662968/ 26.510750, val:  52.21%, val_best:  78.10%, tr:  95.93%, tr_best:  98.46%, epoch time: 148.92 seconds, 2.48 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 63.7335%\n",
      "layer   3  Sparsity: 74.4076%\n",
      "total_backward_count 2443392 real_backward_count 447219  18.303%\n",
      "layer   1  Sparsity: 68.5221%\n",
      "layer   2  Sparsity: 54.5833%\n",
      "layer   3  Sparsity: 71.7500%\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-101 lr=['2.0000000'], tr/val_loss: 37.065895/ 48.917694, val:  50.00%, val_best:  78.10%, tr:  96.90%, tr_best:  98.46%, epoch time: 149.71 seconds, 2.50 minutes\n",
      "layer   1  Sparsity: 81.4685%\n",
      "layer   2  Sparsity: 63.3703%\n",
      "layer   3  Sparsity: 74.3621%\n",
      "total_backward_count 2467584 real_backward_count 451367  18.292%\n",
      "layer   1  Sparsity: 85.3516%\n",
      "layer   2  Sparsity: 70.1667%\n",
      "layer   3  Sparsity: 76.0833%\n",
      "train - Value 0: 1934 occurrences\n",
      "train - Value 1: 2098 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 364 occurrences\n",
      "test - Value 1: 88 occurrences\n",
      "epoch-102 lr=['2.0000000'], tr/val_loss: 37.468971/ 16.833063, val:  68.14%, val_best:  78.10%, tr:  94.30%, tr_best:  98.46%, epoch time: 151.25 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 63.1680%\n",
      "layer   3  Sparsity: 73.9662%\n",
      "total_backward_count 2491776 real_backward_count 455617  18.285%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 70.7500%\n",
      "train - Value 0: 2002 occurrences\n",
      "train - Value 1: 2030 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 58 occurrences\n",
      "test - Value 1: 394 occurrences\n",
      "epoch-103 lr=['2.0000000'], tr/val_loss: 28.311811/ 27.038351, val:  61.50%, val_best:  78.10%, tr:  95.14%, tr_best:  98.46%, epoch time: 151.32 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 63.2999%\n",
      "layer   3  Sparsity: 73.8352%\n",
      "total_backward_count 2515968 real_backward_count 459862  18.278%\n",
      "layer   1  Sparsity: 79.3294%\n",
      "layer   2  Sparsity: 66.0833%\n",
      "layer   3  Sparsity: 77.0000%\n",
      "train - Value 0: 2021 occurrences\n",
      "train - Value 1: 2011 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-104 lr=['2.0000000'], tr/val_loss: 36.516026/ 44.988758, val:  50.22%, val_best:  78.10%, tr:  96.35%, tr_best:  98.46%, epoch time: 150.76 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 63.4205%\n",
      "layer   3  Sparsity: 73.9207%\n",
      "total_backward_count 2540160 real_backward_count 464081  18.270%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 62.3333%\n",
      "layer   3  Sparsity: 71.8333%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 8 occurrences\n",
      "test - Value 1: 444 occurrences\n",
      "epoch-105 lr=['2.0000000'], tr/val_loss: 37.339401/ 40.864506, val:  51.77%, val_best:  78.10%, tr:  95.78%, tr_best:  98.46%, epoch time: 151.00 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 63.0243%\n",
      "layer   3  Sparsity: 73.4800%\n",
      "total_backward_count 2564352 real_backward_count 468076  18.253%\n",
      "layer   1  Sparsity: 84.8958%\n",
      "layer   2  Sparsity: 69.8333%\n",
      "layer   3  Sparsity: 75.4167%\n",
      "lif layer 1 self.abs_max_v: 13343.0\n",
      "fc layer 1 self.abs_max_out: 9175.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 20 occurrences\n",
      "test - Value 1: 432 occurrences\n",
      "epoch-106 lr=['2.0000000'], tr/val_loss: 34.000374/ 42.829479, val:  54.42%, val_best:  78.10%, tr:  96.58%, tr_best:  98.46%, epoch time: 150.72 seconds, 2.51 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 63.2415%\n",
      "layer   3  Sparsity: 73.3834%\n",
      "total_backward_count 2588544 real_backward_count 472286  18.245%\n",
      "layer   1  Sparsity: 90.8203%\n",
      "layer   2  Sparsity: 74.7500%\n",
      "layer   3  Sparsity: 80.8333%\n",
      "lif layer 1 self.abs_max_v: 13359.5\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 105 occurrences\n",
      "test - Value 1: 347 occurrences\n",
      "epoch-107 lr=['2.0000000'], tr/val_loss: 36.948967/ 31.153883, val:  71.90%, val_best:  78.10%, tr:  97.40%, tr_best:  98.46%, epoch time: 151.37 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4635%\n",
      "layer   2  Sparsity: 63.3092%\n",
      "layer   3  Sparsity: 73.6696%\n",
      "total_backward_count 2612736 real_backward_count 476176  18.225%\n",
      "layer   1  Sparsity: 86.2305%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 76.2500%\n",
      "fc layer 2 self.abs_max_out: 1319.0\n",
      "lif layer 1 self.abs_max_v: 13378.5\n",
      "fc layer 1 self.abs_max_out: 9182.0\n",
      "train - Value 0: 2126 occurrences\n",
      "train - Value 1: 1906 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 263 occurrences\n",
      "test - Value 1: 189 occurrences\n",
      "epoch-108 lr=['2.0000000'], tr/val_loss: 39.248192/ 37.759113, val:  69.69%, val_best:  78.10%, tr:  94.69%, tr_best:  98.46%, epoch time: 150.99 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 63.4883%\n",
      "layer   3  Sparsity: 73.7788%\n",
      "total_backward_count 2636928 real_backward_count 480202  18.211%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 68.5833%\n",
      "layer   3  Sparsity: 76.0833%\n",
      "fc layer 2 self.abs_max_out: 1376.0\n",
      "fc layer 1 self.abs_max_out: 9200.0\n",
      "lif layer 1 self.abs_max_v: 13440.0\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 79 occurrences\n",
      "test - Value 1: 373 occurrences\n",
      "epoch-109 lr=['2.0000000'], tr/val_loss: 34.613453/ 13.242795, val:  65.27%, val_best:  78.10%, tr:  92.88%, tr_best:  98.46%, epoch time: 150.98 seconds, 2.52 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.9688%\n",
      "layer   3  Sparsity: 73.7488%\n",
      "total_backward_count 2661120 real_backward_count 484310  18.199%\n",
      "layer   1  Sparsity: 88.2161%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 76.0000%\n",
      "fc layer 1 self.abs_max_out: 9255.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-110 lr=['2.0000000'], tr/val_loss: 30.208555/ 58.126999, val:  50.00%, val_best:  78.10%, tr:  94.17%, tr_best:  98.46%, epoch time: 151.59 seconds, 2.53 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 63.0583%\n",
      "layer   3  Sparsity: 73.8762%\n",
      "total_backward_count 2685312 real_backward_count 488340  18.186%\n",
      "layer   1  Sparsity: 80.5013%\n",
      "layer   2  Sparsity: 60.8333%\n",
      "layer   3  Sparsity: 71.1667%\n",
      "lif layer 1 self.abs_max_v: 13444.0\n",
      "train - Value 0: 1967 occurrences\n",
      "train - Value 1: 2065 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 433 occurrences\n",
      "test - Value 1: 19 occurrences\n",
      "epoch-111 lr=['2.0000000'], tr/val_loss: 37.238625/ 17.553322, val:  54.20%, val_best:  78.10%, tr:  94.92%, tr_best:  98.46%, epoch time: 162.38 seconds, 2.71 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 63.3991%\n",
      "layer   3  Sparsity: 73.7849%\n",
      "total_backward_count 2709504 real_backward_count 492354  18.171%\n",
      "layer   1  Sparsity: 79.5898%\n",
      "layer   2  Sparsity: 57.5833%\n",
      "layer   3  Sparsity: 71.3333%\n",
      "lif layer 1 self.abs_max_v: 13462.5\n",
      "lif layer 2 self.abs_max_v: 1958.5\n",
      "lif layer 2 self.abs_max_v: 1976.5\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-112 lr=['2.0000000'], tr/val_loss: 40.737854/ 38.722874, val:  80.97%, val_best:  80.97%, tr:  96.83%, tr_best:  98.46%, epoch time: 171.34 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 63.1646%\n",
      "layer   3  Sparsity: 73.6168%\n",
      "total_backward_count 2733696 real_backward_count 496557  18.164%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 65.0833%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "lif layer 1 self.abs_max_v: 13484.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 420 occurrences\n",
      "test - Value 1: 32 occurrences\n",
      "epoch-113 lr=['2.0000000'], tr/val_loss: 43.428783/ 21.419060, val:  57.08%, val_best:  80.97%, tr:  97.74%, tr_best:  98.46%, epoch time: 169.63 seconds, 2.83 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.9101%\n",
      "layer   3  Sparsity: 73.6360%\n",
      "total_backward_count 2757888 real_backward_count 500714  18.156%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 56.3333%\n",
      "layer   3  Sparsity: 70.7500%\n",
      "fc layer 1 self.abs_max_out: 9256.0\n",
      "fc layer 1 self.abs_max_out: 9328.0\n",
      "fc layer 2 self.abs_max_out: 1395.0\n",
      "lif layer 2 self.abs_max_v: 2035.5\n",
      "lif layer 2 self.abs_max_v: 2055.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-114 lr=['2.0000000'], tr/val_loss: 49.198002/ 39.222065, val:  50.00%, val_best:  80.97%, tr:  97.05%, tr_best:  98.46%, epoch time: 170.64 seconds, 2.84 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 63.1724%\n",
      "layer   3  Sparsity: 73.7887%\n",
      "total_backward_count 2782080 real_backward_count 504802  18.145%\n",
      "layer   1  Sparsity: 78.0273%\n",
      "layer   2  Sparsity: 65.1667%\n",
      "layer   3  Sparsity: 76.0833%\n",
      "lif layer 2 self.abs_max_v: 2088.0\n",
      "lif layer 2 self.abs_max_v: 2093.0\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 195 occurrences\n",
      "test - Value 1: 257 occurrences\n",
      "epoch-115 lr=['2.0000000'], tr/val_loss: 45.398514/ 17.833229, val:  80.31%, val_best:  80.97%, tr:  95.34%, tr_best:  98.46%, epoch time: 170.08 seconds, 2.83 minutes\n",
      "layer   1  Sparsity: 81.4664%\n",
      "layer   2  Sparsity: 63.0666%\n",
      "layer   3  Sparsity: 73.8471%\n",
      "total_backward_count 2806272 real_backward_count 509115  18.142%\n",
      "layer   1  Sparsity: 86.7513%\n",
      "layer   2  Sparsity: 74.0000%\n",
      "layer   3  Sparsity: 81.1667%\n",
      "lif layer 2 self.abs_max_v: 2149.0\n",
      "fc layer 1 self.abs_max_out: 9347.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 436 occurrences\n",
      "test - Value 1: 16 occurrences\n",
      "epoch-116 lr=['2.0000000'], tr/val_loss: 44.846821/ 41.904644, val:  53.54%, val_best:  80.97%, tr:  96.80%, tr_best:  98.46%, epoch time: 172.42 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 62.9355%\n",
      "layer   3  Sparsity: 73.5417%\n",
      "total_backward_count 2830464 real_backward_count 513154  18.130%\n",
      "layer   1  Sparsity: 70.9635%\n",
      "layer   2  Sparsity: 57.3333%\n",
      "layer   3  Sparsity: 70.9167%\n",
      "fc layer 2 self.abs_max_out: 1421.0\n",
      "lif layer 2 self.abs_max_v: 2149.5\n",
      "lif layer 2 self.abs_max_v: 2216.5\n",
      "train - Value 0: 2046 occurrences\n",
      "train - Value 1: 1986 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 81 occurrences\n",
      "test - Value 1: 371 occurrences\n",
      "epoch-117 lr=['2.0000000'], tr/val_loss: 36.619156/ 18.193146, val:  67.04%, val_best:  80.97%, tr:  97.07%, tr_best:  98.46%, epoch time: 172.27 seconds, 2.87 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 62.8406%\n",
      "layer   3  Sparsity: 73.5774%\n",
      "total_backward_count 2854656 real_backward_count 517359  18.123%\n",
      "layer   1  Sparsity: 87.2721%\n",
      "layer   2  Sparsity: 68.1667%\n",
      "layer   3  Sparsity: 75.8333%\n",
      "lif layer 1 self.abs_max_v: 13492.5\n",
      "lif layer 2 self.abs_max_v: 2250.5\n",
      "train - Value 0: 1947 occurrences\n",
      "train - Value 1: 2085 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 27 occurrences\n",
      "test - Value 1: 425 occurrences\n",
      "epoch-118 lr=['2.0000000'], tr/val_loss: 43.912552/ 48.391937, val:  55.53%, val_best:  80.97%, tr:  96.50%, tr_best:  98.46%, epoch time: 171.53 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 62.8223%\n",
      "layer   3  Sparsity: 73.6810%\n",
      "total_backward_count 2878848 real_backward_count 521565  18.117%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 72.2500%\n",
      "layer   3  Sparsity: 76.1667%\n",
      "lif layer 1 self.abs_max_v: 13524.5\n",
      "train - Value 0: 1986 occurrences\n",
      "train - Value 1: 2046 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-119 lr=['2.0000000'], tr/val_loss: 51.506310/ 33.433014, val:  70.13%, val_best:  80.97%, tr:  95.83%, tr_best:  98.46%, epoch time: 171.02 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 62.5340%\n",
      "layer   3  Sparsity: 73.9323%\n",
      "total_backward_count 2903040 real_backward_count 525894  18.115%\n",
      "layer   1  Sparsity: 87.2070%\n",
      "layer   2  Sparsity: 67.7500%\n",
      "layer   3  Sparsity: 76.5000%\n",
      "lif layer 1 self.abs_max_v: 13529.0\n",
      "train - Value 0: 1989 occurrences\n",
      "train - Value 1: 2043 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 222 occurrences\n",
      "test - Value 1: 230 occurrences\n",
      "epoch-120 lr=['2.0000000'], tr/val_loss: 39.847881/ 23.110178, val:  82.74%, val_best:  82.74%, tr:  97.00%, tr_best:  98.46%, epoch time: 171.18 seconds, 2.85 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 62.2466%\n",
      "layer   3  Sparsity: 73.8749%\n",
      "total_backward_count 2927232 real_backward_count 530174  18.112%\n",
      "layer   1  Sparsity: 81.5104%\n",
      "layer   2  Sparsity: 58.3333%\n",
      "layer   3  Sparsity: 71.3333%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 108 occurrences\n",
      "test - Value 1: 344 occurrences\n",
      "epoch-121 lr=['2.0000000'], tr/val_loss: 37.489014/ 57.366905, val:  71.24%, val_best:  82.74%, tr:  96.63%, tr_best:  98.46%, epoch time: 171.77 seconds, 2.86 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 62.0627%\n",
      "layer   3  Sparsity: 73.5639%\n",
      "total_backward_count 2951424 real_backward_count 534391  18.106%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 63.5000%\n",
      "layer   3  Sparsity: 75.5000%\n",
      "train - Value 0: 2085 occurrences\n",
      "train - Value 1: 1947 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-122 lr=['2.0000000'], tr/val_loss: 45.848606/ 69.602158, val:  50.00%, val_best:  82.74%, tr:  96.70%, tr_best:  98.46%, epoch time: 172.92 seconds, 2.88 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 61.9881%\n",
      "layer   3  Sparsity: 73.4727%\n",
      "total_backward_count 2975616 real_backward_count 538509  18.097%\n",
      "layer   1  Sparsity: 88.1510%\n",
      "layer   2  Sparsity: 65.0833%\n",
      "layer   3  Sparsity: 75.9167%\n",
      "train - Value 0: 2009 occurrences\n",
      "train - Value 1: 2023 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-123 lr=['2.0000000'], tr/val_loss: 39.107834/ 31.254246, val:  53.54%, val_best:  82.74%, tr:  96.40%, tr_best:  98.46%, epoch time: 180.85 seconds, 3.01 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 62.3391%\n",
      "layer   3  Sparsity: 73.3819%\n",
      "total_backward_count 2999808 real_backward_count 542671  18.090%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 75.8333%\n",
      "train - Value 0: 2018 occurrences\n",
      "train - Value 1: 2014 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 252 occurrences\n",
      "test - Value 1: 200 occurrences\n",
      "epoch-124 lr=['2.0000000'], tr/val_loss: 46.574398/ 25.358364, val:  79.20%, val_best:  82.74%, tr:  96.83%, tr_best:  98.46%, epoch time: 189.11 seconds, 3.15 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 62.5372%\n",
      "layer   3  Sparsity: 73.1225%\n",
      "total_backward_count 3024000 real_backward_count 546767  18.081%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 67.0000%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "fc layer 1 self.abs_max_out: 9355.0\n",
      "lif layer 1 self.abs_max_v: 13542.5\n",
      "train - Value 0: 1983 occurrences\n",
      "train - Value 1: 2049 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 63 occurrences\n",
      "test - Value 1: 389 occurrences\n",
      "epoch-125 lr=['2.0000000'], tr/val_loss: 42.218559/ 34.844704, val:  62.17%, val_best:  82.74%, tr:  96.11%, tr_best:  98.46%, epoch time: 189.58 seconds, 3.16 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.6040%\n",
      "layer   3  Sparsity: 72.8385%\n",
      "total_backward_count 3048192 real_backward_count 550999  18.076%\n",
      "layer   1  Sparsity: 72.4284%\n",
      "layer   2  Sparsity: 56.9167%\n",
      "layer   3  Sparsity: 69.6667%\n",
      "lif layer 1 self.abs_max_v: 13557.5\n",
      "fc layer 1 self.abs_max_out: 9364.0\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-126 lr=['2.0000000'], tr/val_loss: 36.884129/ 67.990898, val:  50.00%, val_best:  82.74%, tr:  96.33%, tr_best:  98.46%, epoch time: 187.44 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4676%\n",
      "layer   2  Sparsity: 62.6780%\n",
      "layer   3  Sparsity: 73.0821%\n",
      "total_backward_count 3072384 real_backward_count 555182  18.070%\n",
      "layer   1  Sparsity: 75.6185%\n",
      "layer   2  Sparsity: 55.8333%\n",
      "layer   3  Sparsity: 69.9167%\n",
      "lif layer 1 self.abs_max_v: 13673.0\n",
      "train - Value 0: 1891 occurrences\n",
      "train - Value 1: 2141 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-127 lr=['2.0000000'], tr/val_loss: 47.687401/ 45.785809, val:  50.44%, val_best:  82.74%, tr:  94.87%, tr_best:  98.46%, epoch time: 187.98 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 62.4387%\n",
      "layer   3  Sparsity: 72.9240%\n",
      "total_backward_count 3096576 real_backward_count 559229  18.060%\n",
      "layer   1  Sparsity: 89.9414%\n",
      "layer   2  Sparsity: 71.5833%\n",
      "layer   3  Sparsity: 75.7500%\n",
      "fc layer 1 self.abs_max_out: 9410.0\n",
      "lif layer 1 self.abs_max_v: 13698.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 304 occurrences\n",
      "test - Value 1: 148 occurrences\n",
      "epoch-128 lr=['2.0000000'], tr/val_loss: 45.632732/ 66.488251, val:  76.99%, val_best:  82.74%, tr:  95.66%, tr_best:  98.46%, epoch time: 187.55 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 62.0920%\n",
      "layer   3  Sparsity: 73.1989%\n",
      "total_backward_count 3120768 real_backward_count 563330  18.051%\n",
      "layer   1  Sparsity: 85.7096%\n",
      "layer   2  Sparsity: 68.7500%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "fc layer 2 self.abs_max_out: 1532.0\n",
      "fc layer 1 self.abs_max_out: 9472.0\n",
      "train - Value 0: 1966 occurrences\n",
      "train - Value 1: 2066 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 201 occurrences\n",
      "test - Value 1: 251 occurrences\n",
      "epoch-129 lr=['2.0000000'], tr/val_loss: 37.564140/ 18.475521, val:  76.33%, val_best:  82.74%, tr:  95.68%, tr_best:  98.46%, epoch time: 187.75 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.1962%\n",
      "layer   3  Sparsity: 72.7985%\n",
      "total_backward_count 3144960 real_backward_count 567573  18.047%\n",
      "layer   1  Sparsity: 89.6159%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "lif layer 1 self.abs_max_v: 13710.0\n",
      "fc layer 1 self.abs_max_out: 9508.0\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 330 occurrences\n",
      "test - Value 1: 122 occurrences\n",
      "epoch-130 lr=['2.0000000'], tr/val_loss: 44.233940/ 29.269840, val:  72.12%, val_best:  82.74%, tr:  97.10%, tr_best:  98.46%, epoch time: 187.75 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 61.8821%\n",
      "layer   3  Sparsity: 72.7959%\n",
      "total_backward_count 3169152 real_backward_count 571821  18.043%\n",
      "layer   1  Sparsity: 88.8997%\n",
      "layer   2  Sparsity: 74.0833%\n",
      "layer   3  Sparsity: 80.2500%\n",
      "lif layer 1 self.abs_max_v: 13717.5\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 285 occurrences\n",
      "test - Value 1: 167 occurrences\n",
      "epoch-131 lr=['2.0000000'], tr/val_loss: 44.118954/ 38.611393, val:  78.98%, val_best:  82.74%, tr:  96.33%, tr_best:  98.46%, epoch time: 187.67 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 61.9995%\n",
      "layer   3  Sparsity: 73.0641%\n",
      "total_backward_count 3193344 real_backward_count 575690  18.028%\n",
      "layer   1  Sparsity: 77.5065%\n",
      "layer   2  Sparsity: 56.5833%\n",
      "layer   3  Sparsity: 70.4167%\n",
      "lif layer 1 self.abs_max_v: 13720.5\n",
      "fc layer 1 self.abs_max_out: 9563.0\n",
      "train - Value 0: 2063 occurrences\n",
      "train - Value 1: 1969 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 414 occurrences\n",
      "test - Value 1: 38 occurrences\n",
      "epoch-132 lr=['2.0000000'], tr/val_loss: 41.534767/ 30.694004, val:  58.41%, val_best:  82.74%, tr:  96.60%, tr_best:  98.46%, epoch time: 187.30 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 62.0287%\n",
      "layer   3  Sparsity: 73.1880%\n",
      "total_backward_count 3217536 real_backward_count 579736  18.018%\n",
      "layer   1  Sparsity: 87.4349%\n",
      "layer   2  Sparsity: 69.9167%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "fc layer 1 self.abs_max_out: 9575.0\n",
      "train - Value 0: 2059 occurrences\n",
      "train - Value 1: 1973 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 40 occurrences\n",
      "test - Value 1: 412 occurrences\n",
      "epoch-133 lr=['2.0000000'], tr/val_loss: 40.873505/ 52.816349, val:  58.85%, val_best:  82.74%, tr:  96.85%, tr_best:  98.46%, epoch time: 187.51 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4643%\n",
      "layer   2  Sparsity: 62.3407%\n",
      "layer   3  Sparsity: 73.2512%\n",
      "total_backward_count 3241728 real_backward_count 583658  18.005%\n",
      "layer   1  Sparsity: 75.8464%\n",
      "layer   2  Sparsity: 56.0833%\n",
      "layer   3  Sparsity: 70.6667%\n",
      "train - Value 0: 2084 occurrences\n",
      "train - Value 1: 1948 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 4 occurrences\n",
      "test - Value 1: 448 occurrences\n",
      "epoch-134 lr=['2.0000000'], tr/val_loss: 42.173412/ 39.875832, val:  50.88%, val_best:  82.74%, tr:  96.13%, tr_best:  98.46%, epoch time: 187.90 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 62.0991%\n",
      "layer   3  Sparsity: 73.2618%\n",
      "total_backward_count 3265920 real_backward_count 587499  17.989%\n",
      "layer   1  Sparsity: 81.8359%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 75.5833%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-135 lr=['2.0000000'], tr/val_loss: 44.814621/ 44.383499, val:  54.42%, val_best:  82.74%, tr:  96.30%, tr_best:  98.46%, epoch time: 187.79 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.1008%\n",
      "layer   3  Sparsity: 73.2770%\n",
      "total_backward_count 3290112 real_backward_count 591324  17.973%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 68.5000%\n",
      "layer   3  Sparsity: 75.4167%\n",
      "fc layer 2 self.abs_max_out: 1569.0\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 412 occurrences\n",
      "test - Value 1: 40 occurrences\n",
      "epoch-136 lr=['2.0000000'], tr/val_loss: 36.153446/ 46.347965, val:  58.85%, val_best:  82.74%, tr:  96.68%, tr_best:  98.46%, epoch time: 188.16 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.0682%\n",
      "layer   3  Sparsity: 73.4271%\n",
      "total_backward_count 3314304 real_backward_count 595183  17.958%\n",
      "layer   1  Sparsity: 75.4883%\n",
      "layer   2  Sparsity: 55.5833%\n",
      "layer   3  Sparsity: 70.9167%\n",
      "fc layer 2 self.abs_max_out: 1597.0\n",
      "fc layer 2 self.abs_max_out: 1626.0\n",
      "fc layer 2 self.abs_max_out: 1719.0\n",
      "fc layer 2 self.abs_max_out: 1764.0\n",
      "train - Value 0: 2005 occurrences\n",
      "train - Value 1: 2027 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 333 occurrences\n",
      "test - Value 1: 119 occurrences\n",
      "epoch-137 lr=['2.0000000'], tr/val_loss: 43.070686/ 35.709583, val:  71.90%, val_best:  82.74%, tr:  95.66%, tr_best:  98.46%, epoch time: 189.27 seconds, 3.15 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 61.7824%\n",
      "layer   3  Sparsity: 73.0613%\n",
      "total_backward_count 3338496 real_backward_count 599240  17.949%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 70.5000%\n",
      "fc layer 1 self.abs_max_out: 9703.0\n",
      "fc layer 2 self.abs_max_out: 1768.0\n",
      "train - Value 0: 1933 occurrences\n",
      "train - Value 1: 2099 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 278 occurrences\n",
      "test - Value 1: 174 occurrences\n",
      "epoch-138 lr=['2.0000000'], tr/val_loss: 40.834240/ 17.535652, val:  71.68%, val_best:  82.74%, tr:  93.18%, tr_best:  98.46%, epoch time: 187.44 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 61.9645%\n",
      "layer   3  Sparsity: 72.9576%\n",
      "total_backward_count 3362688 real_backward_count 603422  17.945%\n",
      "layer   1  Sparsity: 84.1797%\n",
      "layer   2  Sparsity: 66.4167%\n",
      "layer   3  Sparsity: 75.2500%\n",
      "train - Value 0: 1965 occurrences\n",
      "train - Value 1: 2067 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 21 occurrences\n",
      "test - Value 1: 431 occurrences\n",
      "epoch-139 lr=['2.0000000'], tr/val_loss: 31.115023/ 20.506527, val:  54.20%, val_best:  82.74%, tr:  93.82%, tr_best:  98.46%, epoch time: 185.98 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 62.0799%\n",
      "layer   3  Sparsity: 73.0622%\n",
      "total_backward_count 3386880 real_backward_count 607580  17.939%\n",
      "layer   1  Sparsity: 94.2057%\n",
      "layer   2  Sparsity: 77.0000%\n",
      "layer   3  Sparsity: 80.5000%\n",
      "train - Value 0: 2100 occurrences\n",
      "train - Value 1: 1932 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 160 occurrences\n",
      "test - Value 1: 292 occurrences\n",
      "epoch-140 lr=['2.0000000'], tr/val_loss: 36.588791/ 28.000235, val:  78.32%, val_best:  82.74%, tr:  96.33%, tr_best:  98.46%, epoch time: 186.33 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 62.2973%\n",
      "layer   3  Sparsity: 73.2667%\n",
      "total_backward_count 3411072 real_backward_count 611419  17.925%\n",
      "layer   1  Sparsity: 79.6875%\n",
      "layer   2  Sparsity: 60.4167%\n",
      "layer   3  Sparsity: 70.2500%\n",
      "lif layer 1 self.abs_max_v: 13735.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 423 occurrences\n",
      "test - Value 1: 29 occurrences\n",
      "epoch-141 lr=['2.0000000'], tr/val_loss: 39.621891/ 46.074608, val:  56.42%, val_best:  82.74%, tr:  96.53%, tr_best:  98.46%, epoch time: 186.19 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 62.5146%\n",
      "layer   3  Sparsity: 73.2390%\n",
      "total_backward_count 3435264 real_backward_count 615574  17.919%\n",
      "layer   1  Sparsity: 71.0938%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 70.0833%\n",
      "lif layer 1 self.abs_max_v: 13739.0\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 268 occurrences\n",
      "test - Value 1: 184 occurrences\n",
      "epoch-142 lr=['2.0000000'], tr/val_loss: 39.565903/ 36.729221, val:  79.65%, val_best:  82.74%, tr:  97.87%, tr_best:  98.46%, epoch time: 187.10 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4679%\n",
      "layer   2  Sparsity: 62.1953%\n",
      "layer   3  Sparsity: 73.1837%\n",
      "total_backward_count 3459456 real_backward_count 619559  17.909%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 66.3333%\n",
      "layer   3  Sparsity: 75.4167%\n",
      "lif layer 1 self.abs_max_v: 13744.5\n",
      "train - Value 0: 2040 occurrences\n",
      "train - Value 1: 1992 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 176 occurrences\n",
      "test - Value 1: 276 occurrences\n",
      "epoch-143 lr=['2.0000000'], tr/val_loss: 42.182728/ 16.850002, val:  77.88%, val_best:  82.74%, tr:  96.97%, tr_best:  98.46%, epoch time: 187.22 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 62.4137%\n",
      "layer   3  Sparsity: 73.0664%\n",
      "total_backward_count 3483648 real_backward_count 623744  17.905%\n",
      "layer   1  Sparsity: 93.3594%\n",
      "layer   2  Sparsity: 82.6667%\n",
      "layer   3  Sparsity: 85.1667%\n",
      "lif layer 1 self.abs_max_v: 13750.5\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-144 lr=['2.0000000'], tr/val_loss: 37.790245/ 22.858868, val:  50.66%, val_best:  82.74%, tr:  97.10%, tr_best:  98.46%, epoch time: 187.87 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4630%\n",
      "layer   2  Sparsity: 62.6247%\n",
      "layer   3  Sparsity: 72.9932%\n",
      "total_backward_count 3507840 real_backward_count 628005  17.903%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 55.5833%\n",
      "layer   3  Sparsity: 70.2500%\n",
      "fc layer 2 self.abs_max_out: 1787.0\n",
      "lif layer 1 self.abs_max_v: 13752.0\n",
      "train - Value 0: 1949 occurrences\n",
      "train - Value 1: 2083 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 225 occurrences\n",
      "test - Value 1: 227 occurrences\n",
      "epoch-145 lr=['2.0000000'], tr/val_loss: 38.101036/ 15.347235, val:  79.87%, val_best:  82.74%, tr:  96.85%, tr_best:  98.46%, epoch time: 187.19 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 62.7972%\n",
      "layer   3  Sparsity: 73.1430%\n",
      "total_backward_count 3532032 real_backward_count 632161  17.898%\n",
      "layer   1  Sparsity: 75.9766%\n",
      "layer   2  Sparsity: 62.5833%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 1960 occurrences\n",
      "train - Value 1: 2072 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-146 lr=['2.0000000'], tr/val_loss: 40.985882/ 43.015598, val:  67.04%, val_best:  82.74%, tr:  96.58%, tr_best:  98.46%, epoch time: 186.62 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 62.9493%\n",
      "layer   3  Sparsity: 73.0926%\n",
      "total_backward_count 3556224 real_backward_count 636438  17.896%\n",
      "layer   1  Sparsity: 81.7057%\n",
      "layer   2  Sparsity: 58.5000%\n",
      "layer   3  Sparsity: 70.9167%\n",
      "fc layer 2 self.abs_max_out: 1821.0\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 272 occurrences\n",
      "test - Value 1: 180 occurrences\n",
      "epoch-147 lr=['2.0000000'], tr/val_loss: 47.330112/ 20.664282, val:  79.65%, val_best:  82.74%, tr:  96.90%, tr_best:  98.46%, epoch time: 187.33 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.9922%\n",
      "layer   3  Sparsity: 73.1013%\n",
      "total_backward_count 3580416 real_backward_count 640443  17.887%\n",
      "layer   1  Sparsity: 85.2539%\n",
      "layer   2  Sparsity: 68.1667%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "fc layer 2 self.abs_max_out: 1834.0\n",
      "train - Value 0: 1957 occurrences\n",
      "train - Value 1: 2075 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-148 lr=['2.0000000'], tr/val_loss: 42.384373/ 87.818390, val:  50.00%, val_best:  82.74%, tr:  96.80%, tr_best:  98.46%, epoch time: 187.65 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 62.7609%\n",
      "layer   3  Sparsity: 73.1656%\n",
      "total_backward_count 3604608 real_backward_count 644491  17.880%\n",
      "layer   1  Sparsity: 85.4818%\n",
      "layer   2  Sparsity: 68.0000%\n",
      "layer   3  Sparsity: 75.8333%\n",
      "fc layer 2 self.abs_max_out: 1863.0\n",
      "lif layer 1 self.abs_max_v: 13764.0\n",
      "train - Value 0: 1971 occurrences\n",
      "train - Value 1: 2061 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 377 occurrences\n",
      "test - Value 1: 75 occurrences\n",
      "epoch-149 lr=['2.0000000'], tr/val_loss: 33.491959/ 13.447850, val:  66.59%, val_best:  82.74%, tr:  96.35%, tr_best:  98.46%, epoch time: 186.12 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 62.3794%\n",
      "layer   3  Sparsity: 73.0650%\n",
      "total_backward_count 3628800 real_backward_count 648597  17.874%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 56.0833%\n",
      "layer   3  Sparsity: 69.9167%\n",
      "fc layer 1 self.abs_max_out: 9774.0\n",
      "train - Value 0: 1990 occurrences\n",
      "train - Value 1: 2042 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 311 occurrences\n",
      "test - Value 1: 141 occurrences\n",
      "epoch-150 lr=['2.0000000'], tr/val_loss: 36.849434/  9.569347, val:  73.67%, val_best:  82.74%, tr:  97.17%, tr_best:  98.46%, epoch time: 186.60 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 62.5187%\n",
      "layer   3  Sparsity: 72.6902%\n",
      "total_backward_count 3652992 real_backward_count 652630  17.866%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 53.7500%\n",
      "layer   3  Sparsity: 69.5833%\n",
      "lif layer 1 self.abs_max_v: 13766.0\n",
      "fc layer 2 self.abs_max_out: 1869.0\n",
      "fc layer 2 self.abs_max_out: 1887.0\n",
      "fc layer 1 self.abs_max_out: 9836.0\n",
      "train - Value 0: 1995 occurrences\n",
      "train - Value 1: 2037 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-151 lr=['2.0000000'], tr/val_loss: 38.144558/ 63.028954, val:  50.00%, val_best:  82.74%, tr:  97.50%, tr_best:  98.46%, epoch time: 185.70 seconds, 3.09 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 62.2705%\n",
      "layer   3  Sparsity: 72.7163%\n",
      "total_backward_count 3677184 real_backward_count 656386  17.850%\n",
      "layer   1  Sparsity: 84.7331%\n",
      "layer   2  Sparsity: 64.9167%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "fc layer 1 self.abs_max_out: 9844.0\n",
      "fc layer 2 self.abs_max_out: 1949.0\n",
      "lif layer 1 self.abs_max_v: 13769.5\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 384 occurrences\n",
      "test - Value 1: 68 occurrences\n",
      "epoch-152 lr=['2.0000000'], tr/val_loss: 41.961430/ 14.275768, val:  64.16%, val_best:  82.74%, tr:  97.37%, tr_best:  98.46%, epoch time: 186.37 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 61.8264%\n",
      "layer   3  Sparsity: 72.5462%\n",
      "total_backward_count 3701376 real_backward_count 660244  17.838%\n",
      "layer   1  Sparsity: 81.2500%\n",
      "layer   2  Sparsity: 60.8333%\n",
      "layer   3  Sparsity: 69.4167%\n",
      "lif layer 1 self.abs_max_v: 13770.0\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 71 occurrences\n",
      "test - Value 1: 381 occurrences\n",
      "epoch-153 lr=['2.0000000'], tr/val_loss: 45.227093/ 36.012669, val:  64.38%, val_best:  82.74%, tr:  97.45%, tr_best:  98.46%, epoch time: 186.42 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 61.3791%\n",
      "layer   3  Sparsity: 72.3574%\n",
      "total_backward_count 3725568 real_backward_count 664099  17.825%\n",
      "layer   1  Sparsity: 71.6471%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 69.4167%\n",
      "train - Value 0: 1921 occurrences\n",
      "train - Value 1: 2111 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-154 lr=['2.0000000'], tr/val_loss: 51.619164/ 61.225857, val:  50.22%, val_best:  82.74%, tr:  95.41%, tr_best:  98.46%, epoch time: 187.73 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4678%\n",
      "layer   2  Sparsity: 61.2076%\n",
      "layer   3  Sparsity: 72.2879%\n",
      "total_backward_count 3749760 real_backward_count 668150  17.818%\n",
      "layer   1  Sparsity: 82.1615%\n",
      "layer   2  Sparsity: 58.5833%\n",
      "layer   3  Sparsity: 69.5833%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-155 lr=['2.0000000'], tr/val_loss: 45.963623/ 16.303463, val:  62.39%, val_best:  82.74%, tr:  96.11%, tr_best:  98.46%, epoch time: 188.83 seconds, 3.15 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 61.3606%\n",
      "layer   3  Sparsity: 71.9423%\n",
      "total_backward_count 3773952 real_backward_count 672297  17.814%\n",
      "layer   1  Sparsity: 88.9974%\n",
      "layer   2  Sparsity: 71.9167%\n",
      "layer   3  Sparsity: 79.4167%\n",
      "train - Value 0: 2139 occurrences\n",
      "train - Value 1: 1893 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 146 occurrences\n",
      "test - Value 1: 306 occurrences\n",
      "epoch-156 lr=['2.0000000'], tr/val_loss: 35.127697/ 12.261155, val:  67.70%, val_best:  82.74%, tr:  95.11%, tr_best:  98.46%, epoch time: 186.92 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 61.1138%\n",
      "layer   3  Sparsity: 72.2671%\n",
      "total_backward_count 3798144 real_backward_count 676457  17.810%\n",
      "layer   1  Sparsity: 78.7109%\n",
      "layer   2  Sparsity: 54.2500%\n",
      "layer   3  Sparsity: 69.1667%\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 132 occurrences\n",
      "test - Value 1: 320 occurrences\n",
      "epoch-157 lr=['2.0000000'], tr/val_loss: 44.305599/ 30.749273, val:  75.66%, val_best:  82.74%, tr:  96.58%, tr_best:  98.46%, epoch time: 187.93 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 61.3623%\n",
      "layer   3  Sparsity: 72.2120%\n",
      "total_backward_count 3822336 real_backward_count 680588  17.806%\n",
      "layer   1  Sparsity: 84.2122%\n",
      "layer   2  Sparsity: 65.6667%\n",
      "layer   3  Sparsity: 74.7500%\n",
      "train - Value 0: 1955 occurrences\n",
      "train - Value 1: 2077 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-158 lr=['2.0000000'], tr/val_loss: 38.319851/ 25.844296, val:  50.00%, val_best:  82.74%, tr:  96.16%, tr_best:  98.46%, epoch time: 187.67 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 61.4393%\n",
      "layer   3  Sparsity: 72.7002%\n",
      "total_backward_count 3846528 real_backward_count 684615  17.798%\n",
      "layer   1  Sparsity: 85.7422%\n",
      "layer   2  Sparsity: 65.6667%\n",
      "layer   3  Sparsity: 75.5000%\n",
      "fc layer 1 self.abs_max_out: 9906.0\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 29 occurrences\n",
      "test - Value 1: 423 occurrences\n",
      "epoch-159 lr=['2.0000000'], tr/val_loss: 38.543831/ 24.609495, val:  56.42%, val_best:  82.74%, tr:  95.76%, tr_best:  98.46%, epoch time: 188.10 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 61.3978%\n",
      "layer   3  Sparsity: 72.5966%\n",
      "total_backward_count 3870720 real_backward_count 688674  17.792%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 67.5000%\n",
      "layer   3  Sparsity: 75.1667%\n",
      "fc layer 1 self.abs_max_out: 9965.0\n",
      "train - Value 0: 2115 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 52 occurrences\n",
      "test - Value 1: 400 occurrences\n",
      "epoch-160 lr=['2.0000000'], tr/val_loss: 39.693024/ 21.502119, val:  60.18%, val_best:  82.74%, tr:  96.70%, tr_best:  98.46%, epoch time: 187.71 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 61.4457%\n",
      "layer   3  Sparsity: 72.7400%\n",
      "total_backward_count 3894912 real_backward_count 692655  17.784%\n",
      "layer   1  Sparsity: 63.6068%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 69.6667%\n",
      "fc layer 1 self.abs_max_out: 9999.0\n",
      "fc layer 1 self.abs_max_out: 10054.0\n",
      "train - Value 0: 2094 occurrences\n",
      "train - Value 1: 1938 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-161 lr=['2.0000000'], tr/val_loss: 33.921688/ 56.251904, val:  50.00%, val_best:  82.74%, tr:  96.08%, tr_best:  98.46%, epoch time: 188.20 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4696%\n",
      "layer   2  Sparsity: 61.5874%\n",
      "layer   3  Sparsity: 72.3902%\n",
      "total_backward_count 3919104 real_backward_count 696813  17.780%\n",
      "layer   1  Sparsity: 93.6523%\n",
      "layer   2  Sparsity: 74.1667%\n",
      "layer   3  Sparsity: 79.8333%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 376 occurrences\n",
      "test - Value 1: 76 occurrences\n",
      "epoch-162 lr=['2.0000000'], tr/val_loss: 33.494156/ 61.162659, val:  65.93%, val_best:  82.74%, tr:  96.16%, tr_best:  98.46%, epoch time: 188.56 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 61.7925%\n",
      "layer   3  Sparsity: 72.0356%\n",
      "total_backward_count 3943296 real_backward_count 700986  17.777%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 53.2500%\n",
      "layer   3  Sparsity: 69.6667%\n",
      "train - Value 0: 2050 occurrences\n",
      "train - Value 1: 1982 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-163 lr=['2.0000000'], tr/val_loss: 39.732105/ 47.209099, val:  50.00%, val_best:  82.74%, tr:  97.62%, tr_best:  98.46%, epoch time: 186.15 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 62.1733%\n",
      "layer   3  Sparsity: 72.2574%\n",
      "total_backward_count 3967488 real_backward_count 705238  17.775%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 54.4167%\n",
      "layer   3  Sparsity: 69.1667%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 416 occurrences\n",
      "test - Value 1: 36 occurrences\n",
      "epoch-164 lr=['2.0000000'], tr/val_loss: 34.279285/ 25.018923, val:  57.96%, val_best:  82.74%, tr:  95.96%, tr_best:  98.46%, epoch time: 186.86 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 62.2265%\n",
      "layer   3  Sparsity: 72.2024%\n",
      "total_backward_count 3991680 real_backward_count 709394  17.772%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 74.6667%\n",
      "layer   3  Sparsity: 79.8333%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 223 occurrences\n",
      "test - Value 1: 229 occurrences\n",
      "epoch-165 lr=['2.0000000'], tr/val_loss: 38.094841/ 41.414593, val:  83.41%, val_best:  83.41%, tr:  97.89%, tr_best:  98.46%, epoch time: 187.44 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 61.9342%\n",
      "layer   3  Sparsity: 72.2808%\n",
      "total_backward_count 4015872 real_backward_count 713257  17.761%\n",
      "layer   1  Sparsity: 73.9909%\n",
      "layer   2  Sparsity: 54.3333%\n",
      "layer   3  Sparsity: 70.1667%\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 64 occurrences\n",
      "test - Value 1: 388 occurrences\n",
      "epoch-166 lr=['2.0000000'], tr/val_loss: 36.261017/ 40.548302, val:  62.83%, val_best:  83.41%, tr:  97.27%, tr_best:  98.46%, epoch time: 185.59 seconds, 3.09 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 61.9005%\n",
      "layer   3  Sparsity: 72.2677%\n",
      "total_backward_count 4040064 real_backward_count 717204  17.752%\n",
      "layer   1  Sparsity: 84.5378%\n",
      "layer   2  Sparsity: 67.0833%\n",
      "layer   3  Sparsity: 74.7500%\n",
      "fc layer 3 self.abs_max_out: 217.0\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 18 occurrences\n",
      "test - Value 1: 434 occurrences\n",
      "epoch-167 lr=['2.0000000'], tr/val_loss: 33.743114/ 58.530491, val:  53.98%, val_best:  83.41%, tr:  97.10%, tr_best:  98.46%, epoch time: 188.07 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 61.7765%\n",
      "layer   3  Sparsity: 72.2431%\n",
      "total_backward_count 4064256 real_backward_count 721273  17.747%\n",
      "layer   1  Sparsity: 82.7799%\n",
      "layer   2  Sparsity: 62.2500%\n",
      "layer   3  Sparsity: 74.5000%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 716.00 at epoch 168, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-168 lr=['2.0000000'], tr/val_loss: 34.621883/ 83.422028, val:  50.00%, val_best:  83.41%, tr:  98.07%, tr_best:  98.46%, epoch time: 188.04 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.0823%\n",
      "layer   3  Sparsity: 71.9902%\n",
      "total_backward_count 4088448 real_backward_count 725241  17.739%\n",
      "layer   1  Sparsity: 91.1784%\n",
      "layer   2  Sparsity: 75.6667%\n",
      "layer   3  Sparsity: 79.6667%\n",
      "train - Value 0: 2090 occurrences\n",
      "train - Value 1: 1942 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 112 occurrences\n",
      "test - Value 1: 340 occurrences\n",
      "epoch-169 lr=['2.0000000'], tr/val_loss: 32.215809/ 36.628586, val:  71.68%, val_best:  83.41%, tr:  97.52%, tr_best:  98.46%, epoch time: 187.90 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4634%\n",
      "layer   2  Sparsity: 62.0521%\n",
      "layer   3  Sparsity: 72.0993%\n",
      "total_backward_count 4112640 real_backward_count 729285  17.733%\n",
      "layer   1  Sparsity: 79.0365%\n",
      "layer   2  Sparsity: 58.9167%\n",
      "layer   3  Sparsity: 68.6667%\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 748.00 at epoch 170, iter 4031\n",
      "max_activation_accul updated: 752.00 at epoch 170, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-170 lr=['2.0000000'], tr/val_loss: 33.022175/ 86.970688, val:  50.00%, val_best:  83.41%, tr:  97.82%, tr_best:  98.46%, epoch time: 186.98 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 62.0292%\n",
      "layer   3  Sparsity: 72.2667%\n",
      "total_backward_count 4136832 real_backward_count 733239  17.725%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 61.1667%\n",
      "layer   3  Sparsity: 74.6667%\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-171 lr=['2.0000000'], tr/val_loss: 38.320732/ 38.875816, val:  50.22%, val_best:  83.41%, tr:  98.19%, tr_best:  98.46%, epoch time: 188.88 seconds, 3.15 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 61.7723%\n",
      "layer   3  Sparsity: 72.4963%\n",
      "total_backward_count 4161024 real_backward_count 737238  17.718%\n",
      "layer   1  Sparsity: 80.6641%\n",
      "layer   2  Sparsity: 59.3333%\n",
      "layer   3  Sparsity: 70.3333%\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 279 occurrences\n",
      "test - Value 1: 173 occurrences\n",
      "epoch-172 lr=['2.0000000'], tr/val_loss: 49.998905/ 16.888048, val:  79.87%, val_best:  83.41%, tr:  98.04%, tr_best:  98.46%, epoch time: 187.57 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 61.9377%\n",
      "layer   3  Sparsity: 72.8144%\n",
      "total_backward_count 4185216 real_backward_count 741276  17.712%\n",
      "layer   1  Sparsity: 86.4909%\n",
      "layer   2  Sparsity: 67.5833%\n",
      "layer   3  Sparsity: 75.3333%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 310 occurrences\n",
      "test - Value 1: 142 occurrences\n",
      "epoch-173 lr=['2.0000000'], tr/val_loss: 42.015965/ 27.765396, val:  75.66%, val_best:  83.41%, tr:  97.89%, tr_best:  98.46%, epoch time: 187.77 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 61.8153%\n",
      "layer   3  Sparsity: 72.7200%\n",
      "total_backward_count 4209408 real_backward_count 745404  17.708%\n",
      "layer   1  Sparsity: 94.4010%\n",
      "layer   2  Sparsity: 82.4167%\n",
      "layer   3  Sparsity: 85.2500%\n",
      "train - Value 0: 2051 occurrences\n",
      "train - Value 1: 1981 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-174 lr=['2.0000000'], tr/val_loss: 30.746546/ 98.591347, val:  50.00%, val_best:  83.41%, tr:  97.00%, tr_best:  98.46%, epoch time: 188.24 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4627%\n",
      "layer   2  Sparsity: 61.3762%\n",
      "layer   3  Sparsity: 72.7108%\n",
      "total_backward_count 4233600 real_backward_count 749559  17.705%\n",
      "layer   1  Sparsity: 92.1875%\n",
      "layer   2  Sparsity: 69.0833%\n",
      "layer   3  Sparsity: 80.3333%\n",
      "fc layer 1 self.abs_max_out: 10059.0\n",
      "fc layer 1 self.abs_max_out: 10064.0\n",
      "fc layer 1 self.abs_max_out: 10105.0\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 66 occurrences\n",
      "test - Value 1: 386 occurrences\n",
      "epoch-175 lr=['2.0000000'], tr/val_loss: 35.007488/ 30.653696, val:  64.16%, val_best:  83.41%, tr:  97.17%, tr_best:  98.46%, epoch time: 186.72 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 61.3221%\n",
      "layer   3  Sparsity: 72.6998%\n",
      "total_backward_count 4257792 real_backward_count 753497  17.697%\n",
      "layer   1  Sparsity: 76.1068%\n",
      "layer   2  Sparsity: 54.3333%\n",
      "layer   3  Sparsity: 69.8333%\n",
      "fc layer 1 self.abs_max_out: 10135.0\n",
      "fc layer 1 self.abs_max_out: 10148.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 292 occurrences\n",
      "test - Value 1: 160 occurrences\n",
      "epoch-176 lr=['2.0000000'], tr/val_loss: 35.348595/ 28.806414, val:  77.88%, val_best:  83.41%, tr:  97.35%, tr_best:  98.46%, epoch time: 186.91 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 61.8189%\n",
      "layer   3  Sparsity: 72.8463%\n",
      "total_backward_count 4281984 real_backward_count 757636  17.694%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 67.8333%\n",
      "layer   3  Sparsity: 75.3333%\n",
      "fc layer 1 self.abs_max_out: 10170.0\n",
      "fc layer 1 self.abs_max_out: 10185.0\n",
      "train - Value 0: 2044 occurrences\n",
      "train - Value 1: 1988 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 325 occurrences\n",
      "test - Value 1: 127 occurrences\n",
      "epoch-177 lr=['2.0000000'], tr/val_loss: 35.467297/ 25.400578, val:  73.23%, val_best:  83.41%, tr:  98.31%, tr_best:  98.46%, epoch time: 186.88 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 61.9860%\n",
      "layer   3  Sparsity: 72.5966%\n",
      "total_backward_count 4306176 real_backward_count 761569  17.686%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 74.5833%\n",
      "fc layer 1 self.abs_max_out: 10192.0\n",
      "train - Value 0: 2043 occurrences\n",
      "train - Value 1: 1989 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-178 lr=['2.0000000'], tr/val_loss: 34.111034/ 34.143169, val:  50.00%, val_best:  83.41%, tr:  97.64%, tr_best:  98.46%, epoch time: 186.83 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 61.8704%\n",
      "layer   3  Sparsity: 72.4944%\n",
      "total_backward_count 4330368 real_backward_count 765582  17.679%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 63.2500%\n",
      "layer   3  Sparsity: 75.0833%\n",
      "fc layer 1 self.abs_max_out: 10218.0\n",
      "train - Value 0: 2034 occurrences\n",
      "train - Value 1: 1998 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-179 lr=['2.0000000'], tr/val_loss: 42.859669/ 73.041512, val:  50.44%, val_best:  83.41%, tr:  98.51%, tr_best:  98.51%, epoch time: 185.53 seconds, 3.09 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 62.0114%\n",
      "layer   3  Sparsity: 72.8415%\n",
      "total_backward_count 4354560 real_backward_count 769419  17.669%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 52.0833%\n",
      "layer   3  Sparsity: 70.4167%\n",
      "fc layer 1 self.abs_max_out: 10242.0\n",
      "fc layer 1 self.abs_max_out: 10268.0\n",
      "fc layer 1 self.abs_max_out: 10272.0\n",
      "lif layer 1 self.abs_max_v: 13861.0\n",
      "train - Value 0: 1993 occurrences\n",
      "train - Value 1: 2039 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 135 occurrences\n",
      "test - Value 1: 317 occurrences\n",
      "epoch-180 lr=['2.0000000'], tr/val_loss: 49.280426/ 13.705688, val:  73.67%, val_best:  83.41%, tr:  96.65%, tr_best:  98.51%, epoch time: 188.00 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 61.9275%\n",
      "layer   3  Sparsity: 72.7570%\n",
      "total_backward_count 4378752 real_backward_count 773381  17.662%\n",
      "layer   1  Sparsity: 88.6393%\n",
      "layer   2  Sparsity: 68.3333%\n",
      "layer   3  Sparsity: 75.0833%\n",
      "fc layer 1 self.abs_max_out: 10291.0\n",
      "fc layer 1 self.abs_max_out: 10314.0\n",
      "lif layer 1 self.abs_max_v: 13939.5\n",
      "fc layer 1 self.abs_max_out: 10350.0\n",
      "train - Value 0: 2019 occurrences\n",
      "train - Value 1: 2013 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 149 occurrences\n",
      "test - Value 1: 303 occurrences\n",
      "epoch-181 lr=['2.0000000'], tr/val_loss: 45.156151/ 20.141010, val:  75.00%, val_best:  83.41%, tr:  97.99%, tr_best:  98.51%, epoch time: 187.26 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4640%\n",
      "layer   2  Sparsity: 61.9641%\n",
      "layer   3  Sparsity: 72.7523%\n",
      "total_backward_count 4402944 real_backward_count 777382  17.656%\n",
      "layer   1  Sparsity: 59.0495%\n",
      "layer   2  Sparsity: 51.8333%\n",
      "layer   3  Sparsity: 69.5000%\n",
      "lif layer 1 self.abs_max_v: 13951.0\n",
      "train - Value 0: 1984 occurrences\n",
      "train - Value 1: 2048 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-182 lr=['2.0000000'], tr/val_loss: 41.466793/ 36.043186, val:  52.65%, val_best:  83.41%, tr:  97.82%, tr_best:  98.51%, epoch time: 189.38 seconds, 3.16 minutes\n",
      "layer   1  Sparsity: 81.4706%\n",
      "layer   2  Sparsity: 61.8400%\n",
      "layer   3  Sparsity: 72.3677%\n",
      "total_backward_count 4427136 real_backward_count 781399  17.650%\n",
      "layer   1  Sparsity: 79.7201%\n",
      "layer   2  Sparsity: 56.8333%\n",
      "layer   3  Sparsity: 69.2500%\n",
      "lif layer 1 self.abs_max_v: 13960.5\n",
      "fc layer 3 self.abs_max_out: 221.0\n",
      "train - Value 0: 2001 occurrences\n",
      "train - Value 1: 2031 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 356 occurrences\n",
      "test - Value 1: 96 occurrences\n",
      "epoch-183 lr=['2.0000000'], tr/val_loss: 33.429707/ 19.614124, val:  68.14%, val_best:  83.41%, tr:  97.89%, tr_best:  98.51%, epoch time: 187.40 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4660%\n",
      "layer   2  Sparsity: 61.2789%\n",
      "layer   3  Sparsity: 71.9862%\n",
      "total_backward_count 4451328 real_backward_count 785450  17.645%\n",
      "layer   1  Sparsity: 76.4323%\n",
      "layer   2  Sparsity: 53.5833%\n",
      "layer   3  Sparsity: 69.2500%\n",
      "train - Value 0: 2017 occurrences\n",
      "train - Value 1: 2015 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-184 lr=['2.0000000'], tr/val_loss: 35.823505/ 76.293610, val:  50.00%, val_best:  83.41%, tr:  97.89%, tr_best:  98.51%, epoch time: 186.39 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 61.6100%\n",
      "layer   3  Sparsity: 72.1420%\n",
      "total_backward_count 4475520 real_backward_count 789496  17.640%\n",
      "layer   1  Sparsity: 88.1185%\n",
      "layer   2  Sparsity: 58.0833%\n",
      "layer   3  Sparsity: 69.7500%\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 338 occurrences\n",
      "test - Value 1: 114 occurrences\n",
      "epoch-185 lr=['2.0000000'], tr/val_loss: 47.197159/ 38.416546, val:  73.89%, val_best:  83.41%, tr:  98.78%, tr_best:  98.78%, epoch time: 187.92 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 61.6138%\n",
      "layer   3  Sparsity: 72.0757%\n",
      "total_backward_count 4499712 real_backward_count 793483  17.634%\n",
      "layer   1  Sparsity: 86.6862%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 74.0000%\n",
      "lif layer 1 self.abs_max_v: 13983.5\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 136 occurrences\n",
      "test - Value 1: 316 occurrences\n",
      "epoch-186 lr=['2.0000000'], tr/val_loss: 48.219597/ 26.476080, val:  75.66%, val_best:  83.41%, tr:  98.49%, tr_best:  98.78%, epoch time: 187.26 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 61.7741%\n",
      "layer   3  Sparsity: 72.0040%\n",
      "total_backward_count 4523904 real_backward_count 797273  17.624%\n",
      "layer   1  Sparsity: 82.6172%\n",
      "layer   2  Sparsity: 64.1667%\n",
      "layer   3  Sparsity: 74.4167%\n",
      "train - Value 0: 2028 occurrences\n",
      "train - Value 1: 2004 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 138 occurrences\n",
      "test - Value 1: 314 occurrences\n",
      "epoch-187 lr=['2.0000000'], tr/val_loss: 40.448078/ 50.727467, val:  76.55%, val_best:  83.41%, tr:  98.66%, tr_best:  98.78%, epoch time: 187.98 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 62.0842%\n",
      "layer   3  Sparsity: 71.9587%\n",
      "total_backward_count 4548096 real_backward_count 801118  17.614%\n",
      "layer   1  Sparsity: 70.6380%\n",
      "layer   2  Sparsity: 54.7500%\n",
      "layer   3  Sparsity: 68.7500%\n",
      "lif layer 1 self.abs_max_v: 13994.5\n",
      "fc layer 1 self.abs_max_out: 10355.0\n",
      "train - Value 0: 2014 occurrences\n",
      "train - Value 1: 2018 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 48 occurrences\n",
      "test - Value 1: 404 occurrences\n",
      "epoch-188 lr=['2.0000000'], tr/val_loss: 35.867344/ 56.294281, val:  60.18%, val_best:  83.41%, tr:  98.66%, tr_best:  98.78%, epoch time: 186.84 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4680%\n",
      "layer   2  Sparsity: 61.9195%\n",
      "layer   3  Sparsity: 71.8366%\n",
      "total_backward_count 4572288 real_backward_count 804990  17.606%\n",
      "layer   1  Sparsity: 67.1224%\n",
      "layer   2  Sparsity: 51.5000%\n",
      "layer   3  Sparsity: 68.7500%\n",
      "fc layer 1 self.abs_max_out: 10424.0\n",
      "fc layer 1 self.abs_max_out: 10440.0\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 7 occurrences\n",
      "test - Value 1: 445 occurrences\n",
      "epoch-189 lr=['2.0000000'], tr/val_loss: 39.431618/ 46.339176, val:  51.55%, val_best:  83.41%, tr:  98.09%, tr_best:  98.78%, epoch time: 186.34 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4688%\n",
      "layer   2  Sparsity: 61.7869%\n",
      "layer   3  Sparsity: 72.1058%\n",
      "total_backward_count 4596480 real_backward_count 808863  17.597%\n",
      "layer   1  Sparsity: 81.9010%\n",
      "layer   2  Sparsity: 67.3333%\n",
      "layer   3  Sparsity: 75.0000%\n",
      "train - Value 0: 2026 occurrences\n",
      "train - Value 1: 2006 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-190 lr=['2.0000000'], tr/val_loss: 40.597710/ 64.516396, val:  50.00%, val_best:  83.41%, tr:  97.87%, tr_best:  98.78%, epoch time: 187.32 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 61.7344%\n",
      "layer   3  Sparsity: 72.2090%\n",
      "total_backward_count 4620672 real_backward_count 812932  17.593%\n",
      "layer   1  Sparsity: 69.0430%\n",
      "layer   2  Sparsity: 51.3333%\n",
      "layer   3  Sparsity: 69.0833%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 373 occurrences\n",
      "test - Value 1: 79 occurrences\n",
      "epoch-191 lr=['2.0000000'], tr/val_loss: 36.489735/ 19.077253, val:  65.71%, val_best:  83.41%, tr:  98.29%, tr_best:  98.78%, epoch time: 185.92 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 61.6244%\n",
      "layer   3  Sparsity: 71.9857%\n",
      "total_backward_count 4644864 real_backward_count 816910  17.587%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 61.4167%\n",
      "layer   3  Sparsity: 74.0833%\n",
      "fc layer 1 self.abs_max_out: 10470.0\n",
      "fc layer 1 self.abs_max_out: 10475.0\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-192 lr=['2.0000000'], tr/val_loss: 32.690086/ 67.563225, val:  50.00%, val_best:  83.41%, tr:  98.59%, tr_best:  98.78%, epoch time: 187.56 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 61.1764%\n",
      "layer   3  Sparsity: 72.0317%\n",
      "total_backward_count 4669056 real_backward_count 820816  17.580%\n",
      "layer   1  Sparsity: 64.3555%\n",
      "layer   2  Sparsity: 50.6667%\n",
      "layer   3  Sparsity: 68.6667%\n",
      "fc layer 1 self.abs_max_out: 10489.0\n",
      "fc layer 1 self.abs_max_out: 10521.0\n",
      "train - Value 0: 2022 occurrences\n",
      "train - Value 1: 2010 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-193 lr=['2.0000000'], tr/val_loss: 35.408131/ 84.667702, val:  50.00%, val_best:  83.41%, tr:  97.42%, tr_best:  98.78%, epoch time: 186.05 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4694%\n",
      "layer   2  Sparsity: 61.0300%\n",
      "layer   3  Sparsity: 72.0396%\n",
      "total_backward_count 4693248 real_backward_count 824658  17.571%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 61.8333%\n",
      "layer   3  Sparsity: 74.5000%\n",
      "fc layer 1 self.abs_max_out: 10539.0\n",
      "train - Value 0: 2013 occurrences\n",
      "train - Value 1: 2019 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 1 occurrences\n",
      "test - Value 1: 451 occurrences\n",
      "epoch-194 lr=['2.0000000'], tr/val_loss: 38.829102/ 79.272705, val:  50.22%, val_best:  83.41%, tr:  98.54%, tr_best:  98.78%, epoch time: 186.25 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 61.0177%\n",
      "layer   3  Sparsity: 71.9515%\n",
      "total_backward_count 4717440 real_backward_count 828526  17.563%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 66.9167%\n",
      "layer   3  Sparsity: 74.4167%\n",
      "fc layer 1 self.abs_max_out: 10569.0\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 9 occurrences\n",
      "test - Value 1: 443 occurrences\n",
      "epoch-195 lr=['2.0000000'], tr/val_loss: 39.027847/ 66.526787, val:  51.99%, val_best:  83.41%, tr:  98.19%, tr_best:  98.78%, epoch time: 186.80 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 61.3257%\n",
      "layer   3  Sparsity: 71.9236%\n",
      "total_backward_count 4741632 real_backward_count 832373  17.555%\n",
      "layer   1  Sparsity: 83.9193%\n",
      "layer   2  Sparsity: 62.6667%\n",
      "layer   3  Sparsity: 74.0000%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 196 occurrences\n",
      "test - Value 1: 256 occurrences\n",
      "epoch-196 lr=['2.0000000'], tr/val_loss: 37.940861/ 24.757313, val:  83.63%, val_best:  83.63%, tr:  98.02%, tr_best:  98.78%, epoch time: 187.98 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 61.3916%\n",
      "layer   3  Sparsity: 72.0551%\n",
      "total_backward_count 4765824 real_backward_count 836220  17.546%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 56.3333%\n",
      "layer   3  Sparsity: 69.0000%\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 2 occurrences\n",
      "test - Value 1: 450 occurrences\n",
      "epoch-197 lr=['2.0000000'], tr/val_loss: 34.231792/ 80.292900, val:  50.44%, val_best:  83.63%, tr:  97.82%, tr_best:  98.78%, epoch time: 186.73 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 61.5411%\n",
      "layer   3  Sparsity: 71.8588%\n",
      "total_backward_count 4790016 real_backward_count 840171  17.540%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 56.0833%\n",
      "layer   3  Sparsity: 68.9167%\n",
      "train - Value 0: 2042 occurrences\n",
      "train - Value 1: 1990 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 15 occurrences\n",
      "test - Value 1: 437 occurrences\n",
      "epoch-198 lr=['2.0000000'], tr/val_loss: 47.217194/ 58.676140, val:  53.32%, val_best:  83.63%, tr:  98.46%, tr_best:  98.78%, epoch time: 188.33 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 61.4963%\n",
      "layer   3  Sparsity: 72.2153%\n",
      "total_backward_count 4814208 real_backward_count 844022  17.532%\n",
      "layer   1  Sparsity: 71.8424%\n",
      "layer   2  Sparsity: 53.4167%\n",
      "layer   3  Sparsity: 69.5000%\n",
      "train - Value 0: 2016 occurrences\n",
      "train - Value 1: 2016 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 17 occurrences\n",
      "test - Value 1: 435 occurrences\n",
      "epoch-199 lr=['2.0000000'], tr/val_loss: 35.304775/ 40.680912, val:  53.32%, val_best:  83.63%, tr:  96.92%, tr_best:  98.78%, epoch time: 187.25 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4677%\n",
      "layer   2  Sparsity: 61.3897%\n",
      "layer   3  Sparsity: 72.2583%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebcadb9ff6c4bc0bc82180d07616e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÅ‚ñÇ</td></tr><tr><td>tr_acc</td><td>‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá</td></tr><tr><td>tr_epoch_loss</td><td>‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÅ‚ñÇ</td></tr><tr><td>val_loss</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96925</td></tr><tr><td>tr_epoch_loss</td><td>35.30478</td></tr><tr><td>val_acc_best</td><td>0.83628</td></tr><tr><td>val_acc_now</td><td>0.53319</td></tr><tr><td>val_loss</td><td>40.68091</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-42</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l93duo4y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/l93duo4y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251214_081812-l93duo4y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uwumpqdo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251214_173205-uwumpqdo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uwumpqdo' target=\"_blank\">avid-sweep-43</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/9m2jgqar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uwumpqdo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/uwumpqdo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': '20251214_173213_913', 'my_seed': 42, 'TIME': 6, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 64, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 0.25, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 0, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 0.03125, 'lif_layer_v_threshold2': 64, 'init_scaling': [0.125, 0.25, 0.5], 'learning_rate': 8, 'learning_rate2': 1, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 0\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4032, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4032 BATCH: 1 train_data_count: 4032\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 0.25, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 0.03125, self.v_threshold 64\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.5])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=0.25, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.5])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=64, v_reset=10000, sg_width=0.03125, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=6, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=6, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.125, 0.25, 0.5])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "ÏûëÏùÄÍ±∏ÌÅ¨Í≤å\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 8\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 171.0\n",
      "lif layer 1 self.abs_max_v: 171.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 2 self.abs_max_out: 285.0\n",
      "lif layer 2 self.abs_max_v: 285.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 3 self.abs_max_out: 313.0\n",
      "fc layer 1 self.abs_max_out: 408.0\n",
      "lif layer 1 self.abs_max_v: 420.5\n",
      "fc layer 2 self.abs_max_out: 457.0\n",
      "lif layer 2 self.abs_max_v: 504.5\n",
      "fc layer 3 self.abs_max_out: 735.0\n",
      "fc layer 1 self.abs_max_out: 425.0\n",
      "lif layer 1 self.abs_max_v: 625.5\n",
      "lif layer 2 self.abs_max_v: 648.5\n",
      "lif layer 1 self.abs_max_v: 633.0\n",
      "fc layer 2 self.abs_max_out: 503.0\n",
      "lif layer 2 self.abs_max_v: 827.5\n",
      "fc layer 1 self.abs_max_out: 526.0\n",
      "lif layer 1 self.abs_max_v: 808.5\n",
      "layer   1  Sparsity: 74.1211%\n",
      "layer   2  Sparsity: 70.8333%\n",
      "layer   3  Sparsity: 70.7500%\n",
      "fc layer 1 self.abs_max_out: 761.0\n",
      "fc layer 2 self.abs_max_out: 514.0\n",
      "fc layer 1 self.abs_max_out: 3047.0\n",
      "lif layer 1 self.abs_max_v: 3390.0\n",
      "lif layer 1 self.abs_max_v: 3624.0\n",
      "fc layer 2 self.abs_max_out: 515.0\n",
      "fc layer 2 self.abs_max_out: 550.0\n",
      "fc layer 2 self.abs_max_out: 605.0\n",
      "fc layer 2 self.abs_max_out: 648.0\n",
      "fc layer 2 self.abs_max_out: 770.0\n",
      "lif layer 2 self.abs_max_v: 850.0\n",
      "lif layer 2 self.abs_max_v: 858.0\n",
      "lif layer 1 self.abs_max_v: 3813.5\n",
      "lif layer 2 self.abs_max_v: 944.5\n",
      "fc layer 3 self.abs_max_out: 752.0\n",
      "lif layer 2 self.abs_max_v: 1036.5\n",
      "fc layer 3 self.abs_max_out: 882.0\n",
      "lif layer 1 self.abs_max_v: 4276.0\n",
      "fc layer 2 self.abs_max_out: 806.0\n",
      "lif layer 2 self.abs_max_v: 1315.5\n",
      "lif layer 1 self.abs_max_v: 4638.0\n",
      "lif layer 2 self.abs_max_v: 1379.0\n",
      "lif layer 2 self.abs_max_v: 1436.5\n",
      "fc layer 1 self.abs_max_out: 3448.0\n",
      "fc layer 1 self.abs_max_out: 4186.0\n",
      "fc layer 2 self.abs_max_out: 858.0\n",
      "lif layer 1 self.abs_max_v: 5516.5\n",
      "fc layer 1 self.abs_max_out: 4220.0\n",
      "lif layer 1 self.abs_max_v: 5751.0\n",
      "fc layer 1 self.abs_max_out: 4399.0\n",
      "lif layer 1 self.abs_max_v: 6802.0\n",
      "lif layer 2 self.abs_max_v: 1483.5\n",
      "fc layer 2 self.abs_max_out: 912.0\n",
      "fc layer 1 self.abs_max_out: 4780.0\n",
      "lif layer 1 self.abs_max_v: 7132.0\n",
      "lif layer 2 self.abs_max_v: 1506.5\n",
      "lif layer 2 self.abs_max_v: 1528.5\n",
      "fc layer 1 self.abs_max_out: 5196.0\n",
      "lif layer 1 self.abs_max_v: 7210.5\n",
      "fc layer 2 self.abs_max_out: 1042.0\n",
      "fc layer 1 self.abs_max_out: 6083.0\n",
      "lif layer 1 self.abs_max_v: 7678.5\n",
      "lif layer 1 self.abs_max_v: 8421.5\n",
      "lif layer 2 self.abs_max_v: 1775.0\n",
      "lif layer 2 self.abs_max_v: 1823.5\n",
      "fc layer 1 self.abs_max_out: 6147.0\n",
      "fc layer 1 self.abs_max_out: 6439.0\n",
      "lif layer 1 self.abs_max_v: 9712.0\n",
      "fc layer 1 self.abs_max_out: 6505.0\n",
      "fc layer 2 self.abs_max_out: 1140.0\n",
      "fc layer 1 self.abs_max_out: 7275.0\n",
      "lif layer 1 self.abs_max_v: 11816.5\n",
      "lif layer 2 self.abs_max_v: 1898.5\n",
      "fc layer 2 self.abs_max_out: 1220.0\n",
      "fc layer 1 self.abs_max_out: 7903.0\n",
      "lif layer 1 self.abs_max_v: 11900.5\n",
      "lif layer 2 self.abs_max_v: 1956.5\n",
      "lif layer 1 self.abs_max_v: 13598.5\n",
      "lif layer 2 self.abs_max_v: 2097.5\n",
      "fc layer 1 self.abs_max_out: 8987.0\n",
      "fc layer 1 self.abs_max_out: 10207.0\n",
      "fc layer 2 self.abs_max_out: 1262.0\n",
      "lif layer 1 self.abs_max_v: 14129.5\n",
      "lif layer 2 self.abs_max_v: 2106.5\n",
      "lif layer 2 self.abs_max_v: 2121.0\n",
      "fc layer 2 self.abs_max_out: 1284.0\n",
      "fc layer 2 self.abs_max_out: 1331.0\n",
      "lif layer 2 self.abs_max_v: 2329.5\n",
      "fc layer 1 self.abs_max_out: 10503.0\n",
      "lif layer 1 self.abs_max_v: 16657.0\n",
      "lif layer 2 self.abs_max_v: 2415.0\n",
      "fc layer 2 self.abs_max_out: 1403.0\n",
      "lif layer 2 self.abs_max_v: 2448.0\n",
      "lif layer 2 self.abs_max_v: 2457.0\n",
      "fc layer 1 self.abs_max_out: 10791.0\n",
      "lif layer 1 self.abs_max_v: 17895.5\n",
      "lif layer 2 self.abs_max_v: 2575.5\n",
      "fc layer 2 self.abs_max_out: 1425.0\n",
      "fc layer 2 self.abs_max_out: 1439.0\n",
      "lif layer 2 self.abs_max_v: 2616.5\n",
      "fc layer 2 self.abs_max_out: 1531.0\n",
      "lif layer 2 self.abs_max_v: 2839.5\n",
      "fc layer 3 self.abs_max_out: 998.0\n",
      "fc layer 2 self.abs_max_out: 1620.0\n",
      "fc layer 1 self.abs_max_out: 11070.0\n",
      "lif layer 2 self.abs_max_v: 2874.0\n",
      "fc layer 2 self.abs_max_out: 1622.0\n",
      "fc layer 2 self.abs_max_out: 1646.0\n",
      "fc layer 2 self.abs_max_out: 1698.0\n",
      "lif layer 2 self.abs_max_v: 2908.5\n",
      "fc layer 1 self.abs_max_out: 11667.0\n",
      "fc layer 2 self.abs_max_out: 1708.0\n",
      "lif layer 2 self.abs_max_v: 3088.0\n",
      "lif layer 2 self.abs_max_v: 3232.0\n",
      "lif layer 1 self.abs_max_v: 17988.0\n",
      "fc layer 2 self.abs_max_out: 1722.0\n",
      "fc layer 2 self.abs_max_out: 1749.0\n",
      "fc layer 2 self.abs_max_out: 1760.0\n",
      "fc layer 3 self.abs_max_out: 1063.0\n",
      "fc layer 1 self.abs_max_out: 11802.0\n",
      "fc layer 1 self.abs_max_out: 12663.0\n",
      "fc layer 1 self.abs_max_out: 12780.0\n",
      "fc layer 1 self.abs_max_out: 12918.0\n",
      "fc layer 1 self.abs_max_out: 14517.0\n",
      "fc layer 1 self.abs_max_out: 14752.0\n",
      "fc layer 1 self.abs_max_out: 14800.0\n",
      "lif layer 1 self.abs_max_v: 18613.0\n",
      "fc layer 1 self.abs_max_out: 14910.0\n",
      "lif layer 1 self.abs_max_v: 18711.5\n",
      "fc layer 2 self.abs_max_out: 1781.0\n",
      "fc layer 2 self.abs_max_out: 1783.0\n",
      "fc layer 2 self.abs_max_out: 1787.0\n",
      "lif layer 2 self.abs_max_v: 3248.5\n",
      "fc layer 1 self.abs_max_out: 15985.0\n",
      "fc layer 2 self.abs_max_out: 1832.0\n",
      "lif layer 2 self.abs_max_v: 3403.5\n",
      "lif layer 2 self.abs_max_v: 3413.0\n",
      "fc layer 1 self.abs_max_out: 16165.0\n",
      "fc layer 1 self.abs_max_out: 16932.0\n",
      "lif layer 1 self.abs_max_v: 19038.0\n",
      "lif layer 1 self.abs_max_v: 20259.0\n",
      "fc layer 1 self.abs_max_out: 18477.0\n",
      "fc layer 1 self.abs_max_out: 18705.0\n",
      "fc layer 2 self.abs_max_out: 1833.0\n",
      "fc layer 2 self.abs_max_out: 1961.0\n",
      "fc layer 2 self.abs_max_out: 2046.0\n",
      "fc layer 2 self.abs_max_out: 2129.0\n",
      "fc layer 2 self.abs_max_out: 2159.0\n",
      "lif layer 2 self.abs_max_v: 3793.5\n",
      "fc layer 2 self.abs_max_out: 2204.0\n",
      "fc layer 2 self.abs_max_out: 2221.0\n",
      "fc layer 2 self.abs_max_out: 2253.0\n",
      "fc layer 2 self.abs_max_out: 2262.0\n",
      "lif layer 2 self.abs_max_v: 4088.5\n",
      "lif layer 2 self.abs_max_v: 4249.5\n",
      "lif layer 2 self.abs_max_v: 4260.0\n",
      "fc layer 2 self.abs_max_out: 2266.0\n",
      "fc layer 2 self.abs_max_out: 2281.0\n",
      "fc layer 2 self.abs_max_out: 2287.0\n",
      "fc layer 2 self.abs_max_out: 2288.0\n",
      "fc layer 2 self.abs_max_out: 2368.0\n",
      "fc layer 2 self.abs_max_out: 2374.0\n",
      "fc layer 2 self.abs_max_out: 2531.0\n",
      "fc layer 2 self.abs_max_out: 2547.0\n",
      "lif layer 2 self.abs_max_v: 4275.5\n",
      "fc layer 2 self.abs_max_out: 2596.0\n",
      "lif layer 2 self.abs_max_v: 4407.0\n",
      "lif layer 2 self.abs_max_v: 4686.5\n",
      "fc layer 2 self.abs_max_out: 2647.0\n",
      "lif layer 2 self.abs_max_v: 4855.5\n",
      "lif layer 2 self.abs_max_v: 5028.0\n",
      "fc layer 2 self.abs_max_out: 2657.0\n",
      "fc layer 2 self.abs_max_out: 2706.0\n",
      "fc layer 2 self.abs_max_out: 2804.0\n",
      "fc layer 2 self.abs_max_out: 2866.0\n",
      "fc layer 2 self.abs_max_out: 2934.0\n",
      "lif layer 2 self.abs_max_v: 5229.0\n",
      "lif layer 2 self.abs_max_v: 5357.5\n",
      "fc layer 2 self.abs_max_out: 3054.0\n",
      "fc layer 2 self.abs_max_out: 3165.0\n",
      "lif layer 2 self.abs_max_v: 5416.0\n",
      "fc layer 2 self.abs_max_out: 3173.0\n",
      "fc layer 2 self.abs_max_out: 3192.0\n",
      "fc layer 2 self.abs_max_out: 3280.0\n",
      "lif layer 2 self.abs_max_v: 5446.0\n",
      "fc layer 2 self.abs_max_out: 3295.0\n",
      "lif layer 2 self.abs_max_v: 5459.5\n",
      "lif layer 2 self.abs_max_v: 5586.0\n",
      "fc layer 2 self.abs_max_out: 3394.0\n",
      "lif layer 2 self.abs_max_v: 5690.0\n",
      "lif layer 2 self.abs_max_v: 5717.5\n",
      "lif layer 2 self.abs_max_v: 5850.0\n",
      "lif layer 2 self.abs_max_v: 6196.0\n",
      "fc layer 2 self.abs_max_out: 3555.0\n",
      "lif layer 2 self.abs_max_v: 6308.0\n",
      "lif layer 2 self.abs_max_v: 6419.5\n",
      "lif layer 2 self.abs_max_v: 6491.0\n",
      "fc layer 2 self.abs_max_out: 3577.0\n",
      "fc layer 2 self.abs_max_out: 3666.0\n",
      "lif layer 2 self.abs_max_v: 6532.5\n",
      "fc layer 2 self.abs_max_out: 3681.0\n",
      "lif layer 2 self.abs_max_v: 6786.0\n",
      "lif layer 2 self.abs_max_v: 6856.0\n",
      "fc layer 2 self.abs_max_out: 3743.0\n",
      "fc layer 2 self.abs_max_out: 3892.0\n",
      "lif layer 2 self.abs_max_v: 7020.0\n",
      "lif layer 2 self.abs_max_v: 7138.0\n",
      "fc layer 2 self.abs_max_out: 3970.0\n",
      "lif layer 2 self.abs_max_v: 7280.0\n",
      "fc layer 2 self.abs_max_out: 3981.0\n",
      "fc layer 2 self.abs_max_out: 4073.0\n",
      "fc layer 2 self.abs_max_out: 4115.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 2668.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 2873.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3216.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3267.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3303.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3347.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3511.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3620.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3683.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3723.00 at epoch 0, iter 4031\n",
      "max_activation_accul updated: 3806.00 at epoch 0, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-0   lr=['8.0000000'], tr/val_loss:451.315582/425.642181, val:  50.22%, val_best:  50.22%, tr:  80.03%, tr_best:  80.03%, epoch time: 186.47 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4672%\n",
      "layer   2  Sparsity: 57.0647%\n",
      "layer   3  Sparsity: 61.1543%\n",
      "total_backward_count 24192 real_backward_count 7403  30.601%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "layer   1  Sparsity: 75.7161%\n",
      "layer   2  Sparsity: 47.8333%\n",
      "layer   3  Sparsity: 57.3333%\n",
      "lif layer 2 self.abs_max_v: 7308.5\n",
      "fc layer 2 self.abs_max_out: 4118.0\n",
      "fc layer 2 self.abs_max_out: 4217.0\n",
      "lif layer 2 self.abs_max_v: 7358.0\n",
      "lif layer 2 self.abs_max_v: 7568.0\n",
      "lif layer 2 self.abs_max_v: 7612.0\n",
      "lif layer 2 self.abs_max_v: 7857.0\n",
      "fc layer 2 self.abs_max_out: 4219.0\n",
      "fc layer 2 self.abs_max_out: 4232.0\n",
      "fc layer 2 self.abs_max_out: 4309.0\n",
      "fc layer 2 self.abs_max_out: 4407.0\n",
      "fc layer 2 self.abs_max_out: 4513.0\n",
      "fc layer 2 self.abs_max_out: 4561.0\n",
      "lif layer 2 self.abs_max_v: 8073.5\n",
      "fc layer 3 self.abs_max_out: 1074.0\n",
      "fc layer 3 self.abs_max_out: 1175.0\n",
      "fc layer 3 self.abs_max_out: 1308.0\n",
      "fc layer 2 self.abs_max_out: 4606.0\n",
      "fc layer 2 self.abs_max_out: 4735.0\n",
      "fc layer 2 self.abs_max_out: 4808.0\n",
      "lif layer 2 self.abs_max_v: 8685.5\n",
      "lif layer 2 self.abs_max_v: 8899.0\n",
      "fc layer 2 self.abs_max_out: 4861.0\n",
      "lif layer 2 self.abs_max_v: 9310.5\n",
      "fc layer 2 self.abs_max_out: 4871.0\n",
      "fc layer 2 self.abs_max_out: 4892.0\n",
      "fc layer 2 self.abs_max_out: 4959.0\n",
      "fc layer 2 self.abs_max_out: 5164.0\n",
      "fc layer 2 self.abs_max_out: 5247.0\n",
      "fc layer 2 self.abs_max_out: 5269.0\n",
      "fc layer 2 self.abs_max_out: 5272.0\n",
      "lif layer 2 self.abs_max_v: 9744.5\n",
      "fc layer 2 self.abs_max_out: 5281.0\n",
      "fc layer 2 self.abs_max_out: 5318.0\n",
      "fc layer 2 self.abs_max_out: 5347.0\n",
      "fc layer 2 self.abs_max_out: 5348.0\n",
      "lif layer 2 self.abs_max_v: 9772.5\n",
      "lif layer 2 self.abs_max_v: 10024.5\n",
      "lif layer 2 self.abs_max_v: 10286.5\n",
      "fc layer 2 self.abs_max_out: 5356.0\n",
      "fc layer 2 self.abs_max_out: 5433.0\n",
      "fc layer 2 self.abs_max_out: 5450.0\n",
      "fc layer 2 self.abs_max_out: 5476.0\n",
      "fc layer 2 self.abs_max_out: 5630.0\n",
      "train - Value 0: 2061 occurrences\n",
      "train - Value 1: 1971 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 3885.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 3969.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 4045.00 at epoch 1, iter 4031\n",
      "max_activation_accul updated: 4401.00 at epoch 1, iter 4031\n",
      "lif layer 1 self.abs_max_v: 21581.5\n",
      "lif layer 1 self.abs_max_v: 21911.0\n",
      "lif layer 1 self.abs_max_v: 23357.0\n",
      "lif layer 1 self.abs_max_v: 24276.5\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-1   lr=['8.0000000'], tr/val_loss:501.319153/402.034393, val:  50.66%, val_best:  50.66%, tr:  85.09%, tr_best:  85.09%, epoch time: 186.45 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 55.5671%\n",
      "layer   3  Sparsity: 61.2754%\n",
      "total_backward_count 48384 real_backward_count 13675  28.263%\n",
      "layer   1  Sparsity: 84.7982%\n",
      "layer   2  Sparsity: 60.9167%\n",
      "layer   3  Sparsity: 66.9167%\n",
      "fc layer 2 self.abs_max_out: 5726.0\n",
      "fc layer 2 self.abs_max_out: 5890.0\n",
      "fc layer 2 self.abs_max_out: 5956.0\n",
      "lif layer 2 self.abs_max_v: 10347.0\n",
      "lif layer 2 self.abs_max_v: 10586.5\n",
      "lif layer 2 self.abs_max_v: 10956.5\n",
      "fc layer 2 self.abs_max_out: 6001.0\n",
      "fc layer 2 self.abs_max_out: 6139.0\n",
      "fc layer 2 self.abs_max_out: 6276.0\n",
      "lif layer 2 self.abs_max_v: 11088.5\n",
      "lif layer 2 self.abs_max_v: 11189.5\n",
      "fc layer 2 self.abs_max_out: 6309.0\n",
      "train - Value 0: 2310 occurrences\n",
      "train - Value 1: 1722 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 4602.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5035.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5479.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5854.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5881.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5887.00 at epoch 2, iter 4031\n",
      "max_activation_accul updated: 5932.00 at epoch 2, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-2   lr=['8.0000000'], tr/val_loss:479.501831/422.248047, val:  50.00%, val_best:  50.66%, tr:  83.53%, tr_best:  85.09%, epoch time: 187.84 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 55.2105%\n",
      "layer   3  Sparsity: 57.5276%\n",
      "total_backward_count 72576 real_backward_count 19978  27.527%\n",
      "layer   1  Sparsity: 74.7721%\n",
      "layer   2  Sparsity: 52.0833%\n",
      "layer   3  Sparsity: 57.4167%\n",
      "fc layer 2 self.abs_max_out: 6357.0\n",
      "lif layer 2 self.abs_max_v: 11271.5\n",
      "lif layer 2 self.abs_max_v: 11810.0\n",
      "fc layer 2 self.abs_max_out: 6382.0\n",
      "fc layer 2 self.abs_max_out: 6481.0\n",
      "fc layer 2 self.abs_max_out: 6516.0\n",
      "fc layer 2 self.abs_max_out: 6570.0\n",
      "lif layer 2 self.abs_max_v: 12004.0\n",
      "lif layer 2 self.abs_max_v: 12221.0\n",
      "fc layer 1 self.abs_max_out: 19117.0\n",
      "fc layer 1 self.abs_max_out: 19327.0\n",
      "fc layer 1 self.abs_max_out: 20318.0\n",
      "fc layer 1 self.abs_max_out: 20736.0\n",
      "fc layer 1 self.abs_max_out: 20786.0\n",
      "fc layer 1 self.abs_max_out: 20843.0\n",
      "fc layer 1 self.abs_max_out: 21844.0\n",
      "fc layer 1 self.abs_max_out: 21955.0\n",
      "fc layer 2 self.abs_max_out: 6573.0\n",
      "fc layer 2 self.abs_max_out: 6606.0\n",
      "fc layer 2 self.abs_max_out: 6607.0\n",
      "fc layer 2 self.abs_max_out: 6665.0\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 6667.0\n",
      "fc layer 2 self.abs_max_out: 6685.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-3   lr=['8.0000000'], tr/val_loss:533.903564/586.669250, val:  50.00%, val_best:  50.66%, tr:  85.89%, tr_best:  85.89%, epoch time: 186.32 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 54.4601%\n",
      "layer   3  Sparsity: 59.0510%\n",
      "total_backward_count 96768 real_backward_count 25997  26.865%\n",
      "layer   1  Sparsity: 76.6602%\n",
      "layer   2  Sparsity: 56.2500%\n",
      "layer   3  Sparsity: 63.5833%\n",
      "fc layer 2 self.abs_max_out: 6792.0\n",
      "lif layer 2 self.abs_max_v: 12307.5\n",
      "lif layer 2 self.abs_max_v: 12407.0\n",
      "fc layer 2 self.abs_max_out: 6802.0\n",
      "fc layer 2 self.abs_max_out: 7027.0\n",
      "fc layer 2 self.abs_max_out: 7048.0\n",
      "fc layer 2 self.abs_max_out: 7147.0\n",
      "train - Value 0: 2129 occurrences\n",
      "train - Value 1: 1903 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 7219.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 404 occurrences\n",
      "test - Value 1: 48 occurrences\n",
      "epoch-4   lr=['8.0000000'], tr/val_loss:711.008301/672.511963, val:  53.98%, val_best:  53.98%, tr:  86.93%, tr_best:  86.93%, epoch time: 187.37 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4667%\n",
      "layer   2  Sparsity: 58.3291%\n",
      "layer   3  Sparsity: 61.5337%\n",
      "total_backward_count 120960 real_backward_count 31650  26.166%\n",
      "layer   1  Sparsity: 83.4310%\n",
      "layer   2  Sparsity: 61.5000%\n",
      "layer   3  Sparsity: 63.1667%\n",
      "fc layer 2 self.abs_max_out: 7273.0\n",
      "fc layer 2 self.abs_max_out: 7283.0\n",
      "lif layer 2 self.abs_max_v: 12627.0\n",
      "lif layer 2 self.abs_max_v: 13308.5\n",
      "fc layer 2 self.abs_max_out: 7390.0\n",
      "fc layer 2 self.abs_max_out: 7400.0\n",
      "fc layer 2 self.abs_max_out: 7768.0\n",
      "train - Value 0: 2191 occurrences\n",
      "train - Value 1: 1841 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 5939.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 6006.00 at epoch 5, iter 4031\n",
      "max_activation_accul updated: 6199.00 at epoch 5, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-5   lr=['8.0000000'], tr/val_loss:732.361206/734.420715, val:  50.00%, val_best:  53.98%, tr:  88.07%, tr_best:  88.07%, epoch time: 186.36 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 62.4661%\n",
      "layer   3  Sparsity: 62.4470%\n",
      "total_backward_count 145152 real_backward_count 37352  25.733%\n",
      "layer   1  Sparsity: 84.4401%\n",
      "layer   2  Sparsity: 59.6667%\n",
      "layer   3  Sparsity: 63.1667%\n",
      "lif layer 2 self.abs_max_v: 13557.5\n",
      "lif layer 2 self.abs_max_v: 14324.0\n",
      "fc layer 2 self.abs_max_out: 7836.0\n",
      "fc layer 2 self.abs_max_out: 8205.0\n",
      "train - Value 0: 2146 occurrences\n",
      "train - Value 1: 1886 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-6   lr=['8.0000000'], tr/val_loss:713.891968/745.478882, val:  50.00%, val_best:  53.98%, tr:  87.05%, tr_best:  88.07%, epoch time: 187.68 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4649%\n",
      "layer   2  Sparsity: 62.7837%\n",
      "layer   3  Sparsity: 62.2027%\n",
      "total_backward_count 169344 real_backward_count 43120  25.463%\n",
      "layer   1  Sparsity: 85.6120%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 61.5833%\n",
      "fc layer 2 self.abs_max_out: 8366.0\n",
      "fc layer 2 self.abs_max_out: 8422.0\n",
      "lif layer 2 self.abs_max_v: 14361.0\n",
      "train - Value 0: 2064 occurrences\n",
      "train - Value 1: 1968 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-7   lr=['8.0000000'], tr/val_loss:774.812805/757.554321, val:  50.00%, val_best:  53.98%, tr:  88.54%, tr_best:  88.54%, epoch time: 188.34 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4647%\n",
      "layer   2  Sparsity: 60.0274%\n",
      "layer   3  Sparsity: 62.2761%\n",
      "total_backward_count 193536 real_backward_count 48683  25.154%\n",
      "layer   1  Sparsity: 81.7383%\n",
      "layer   2  Sparsity: 57.3333%\n",
      "layer   3  Sparsity: 59.7500%\n",
      "fc layer 2 self.abs_max_out: 8537.0\n",
      "train - Value 0: 2039 occurrences\n",
      "train - Value 1: 1993 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "max_activation_accul updated: 6376.00 at epoch 8, iter 4031\n",
      "max_activation_accul updated: 6415.00 at epoch 8, iter 4031\n",
      "max_activation_accul updated: 6596.00 at epoch 8, iter 4031\n",
      "max_activation_accul updated: 6641.00 at epoch 8, iter 4031\n",
      "max_activation_accul updated: 6741.00 at epoch 8, iter 4031\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-8   lr=['8.0000000'], tr/val_loss:768.806458/799.871399, val:  50.00%, val_best:  53.98%, tr:  89.31%, tr_best:  89.31%, epoch time: 187.37 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 63.1444%\n",
      "layer   3  Sparsity: 62.5699%\n",
      "total_backward_count 217728 real_backward_count 54175  24.882%\n",
      "layer   1  Sparsity: 82.6823%\n",
      "layer   2  Sparsity: 68.4167%\n",
      "layer   3  Sparsity: 66.8333%\n",
      "fc layer 3 self.abs_max_out: 1318.0\n",
      "fc layer 3 self.abs_max_out: 1325.0\n",
      "train - Value 0: 2023 occurrences\n",
      "train - Value 1: 2009 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 16 occurrences\n",
      "test - Value 1: 436 occurrences\n",
      "epoch-9   lr=['8.0000000'], tr/val_loss:835.484924/802.067749, val:  52.65%, val_best:  53.98%, tr:  90.65%, tr_best:  90.65%, epoch time: 187.90 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 64.1152%\n",
      "layer   3  Sparsity: 62.6249%\n",
      "total_backward_count 241920 real_backward_count 59402  24.554%\n",
      "layer   1  Sparsity: 79.0690%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 62.7500%\n",
      "lif layer 2 self.abs_max_v: 14627.5\n",
      "fc layer 3 self.abs_max_out: 1328.0\n",
      "fc layer 2 self.abs_max_out: 8908.0\n",
      "fc layer 3 self.abs_max_out: 1350.0\n",
      "fc layer 2 self.abs_max_out: 9263.0\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 447 occurrences\n",
      "test - Value 1: 5 occurrences\n",
      "epoch-10  lr=['8.0000000'], tr/val_loss:830.257935/792.683838, val:  51.11%, val_best:  53.98%, tr:  90.60%, tr_best:  90.65%, epoch time: 187.52 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4661%\n",
      "layer   2  Sparsity: 64.3666%\n",
      "layer   3  Sparsity: 62.6088%\n",
      "total_backward_count 266112 real_backward_count 64880  24.381%\n",
      "layer   1  Sparsity: 86.7188%\n",
      "layer   2  Sparsity: 60.5833%\n",
      "layer   3  Sparsity: 61.3333%\n",
      "lif layer 2 self.abs_max_v: 14801.5\n",
      "lif layer 2 self.abs_max_v: 15752.0\n",
      "fc layer 2 self.abs_max_out: 9655.0\n",
      "lif layer 2 self.abs_max_v: 15868.0\n",
      "lif layer 2 self.abs_max_v: 16325.5\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-11  lr=['8.0000000'], tr/val_loss:842.363892/822.908020, val:  50.00%, val_best:  53.98%, tr:  91.25%, tr_best:  91.25%, epoch time: 187.03 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4644%\n",
      "layer   2  Sparsity: 64.5632%\n",
      "layer   3  Sparsity: 61.1411%\n",
      "total_backward_count 290304 real_backward_count 70103  24.148%\n",
      "layer   1  Sparsity: 83.8542%\n",
      "layer   2  Sparsity: 66.4167%\n",
      "layer   3  Sparsity: 54.1667%\n",
      "fc layer 2 self.abs_max_out: 9916.0\n",
      "lif layer 2 self.abs_max_v: 16424.5\n",
      "lif layer 2 self.abs_max_v: 16938.5\n",
      "lif layer 2 self.abs_max_v: 17120.5\n",
      "lif layer 2 self.abs_max_v: 18050.5\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 110 occurrences\n",
      "test - Value 1: 342 occurrences\n",
      "epoch-12  lr=['8.0000000'], tr/val_loss:827.311646/737.629395, val:  57.96%, val_best:  57.96%, tr:  91.69%, tr_best:  91.69%, epoch time: 187.50 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4651%\n",
      "layer   2  Sparsity: 64.5210%\n",
      "layer   3  Sparsity: 60.8952%\n",
      "total_backward_count 314496 real_backward_count 75299  23.943%\n",
      "layer   1  Sparsity: 88.2487%\n",
      "layer   2  Sparsity: 76.0000%\n",
      "layer   3  Sparsity: 64.0833%\n",
      "fc layer 2 self.abs_max_out: 9987.0\n",
      "fc layer 2 self.abs_max_out: 9995.0\n",
      "fc layer 2 self.abs_max_out: 10131.0\n",
      "fc layer 2 self.abs_max_out: 10226.0\n",
      "fc layer 2 self.abs_max_out: 10313.0\n",
      "fc layer 2 self.abs_max_out: 10377.0\n",
      "lif layer 2 self.abs_max_v: 18875.0\n",
      "lif layer 2 self.abs_max_v: 19482.5\n",
      "train - Value 0: 2071 occurrences\n",
      "train - Value 1: 1961 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-13  lr=['8.0000000'], tr/val_loss:813.084961/793.574158, val:  50.00%, val_best:  57.96%, tr:  91.25%, tr_best:  91.69%, epoch time: 186.84 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 64.8956%\n",
      "layer   3  Sparsity: 60.7765%\n",
      "total_backward_count 338688 real_backward_count 80582  23.792%\n",
      "layer   1  Sparsity: 90.3971%\n",
      "layer   2  Sparsity: 75.5000%\n",
      "layer   3  Sparsity: 62.8333%\n",
      "fc layer 2 self.abs_max_out: 10592.0\n",
      "fc layer 2 self.abs_max_out: 10617.0\n",
      "fc layer 2 self.abs_max_out: 10629.0\n",
      "fc layer 2 self.abs_max_out: 10799.0\n",
      "lif layer 2 self.abs_max_v: 19902.5\n",
      "fc layer 2 self.abs_max_out: 10819.0\n",
      "fc layer 2 self.abs_max_out: 10904.0\n",
      "train - Value 0: 2033 occurrences\n",
      "train - Value 1: 1999 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-14  lr=['8.0000000'], tr/val_loss:830.939514/834.478699, val:  50.00%, val_best:  57.96%, tr:  92.93%, tr_best:  92.93%, epoch time: 186.70 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 62.8528%\n",
      "layer   3  Sparsity: 60.3512%\n",
      "total_backward_count 362880 real_backward_count 85734  23.626%\n",
      "layer   1  Sparsity: 93.8151%\n",
      "layer   2  Sparsity: 74.4167%\n",
      "layer   3  Sparsity: 71.4167%\n",
      "fc layer 2 self.abs_max_out: 10936.0\n",
      "lif layer 2 self.abs_max_v: 20583.5\n",
      "lif layer 2 self.abs_max_v: 20627.0\n",
      "fc layer 2 self.abs_max_out: 10959.0\n",
      "fc layer 2 self.abs_max_out: 11004.0\n",
      "fc layer 2 self.abs_max_out: 11116.0\n",
      "fc layer 2 self.abs_max_out: 11161.0\n",
      "fc layer 2 self.abs_max_out: 11174.0\n",
      "train - Value 0: 2065 occurrences\n",
      "train - Value 1: 1967 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-15  lr=['8.0000000'], tr/val_loss:826.114807/785.045166, val:  50.00%, val_best:  57.96%, tr:  92.78%, tr_best:  92.93%, epoch time: 187.64 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 62.3102%\n",
      "layer   3  Sparsity: 60.3784%\n",
      "total_backward_count 387072 real_backward_count 90845  23.470%\n",
      "layer   1  Sparsity: 84.9935%\n",
      "layer   2  Sparsity: 70.0833%\n",
      "layer   3  Sparsity: 64.5833%\n",
      "fc layer 2 self.abs_max_out: 11189.0\n",
      "fc layer 2 self.abs_max_out: 11355.0\n",
      "lif layer 2 self.abs_max_v: 21140.0\n",
      "lif layer 2 self.abs_max_v: 21502.0\n",
      "train - Value 0: 2062 occurrences\n",
      "train - Value 1: 1970 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-16  lr=['8.0000000'], tr/val_loss:837.208435/767.388306, val:  50.00%, val_best:  57.96%, tr:  93.45%, tr_best:  93.45%, epoch time: 186.71 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4648%\n",
      "layer   2  Sparsity: 61.9615%\n",
      "layer   3  Sparsity: 60.3598%\n",
      "total_backward_count 411264 real_backward_count 95956  23.332%\n",
      "layer   1  Sparsity: 75.6510%\n",
      "layer   2  Sparsity: 51.1667%\n",
      "layer   3  Sparsity: 53.0000%\n",
      "fc layer 2 self.abs_max_out: 11379.0\n",
      "fc layer 2 self.abs_max_out: 11429.0\n",
      "fc layer 2 self.abs_max_out: 11753.0\n",
      "train - Value 0: 2058 occurrences\n",
      "train - Value 1: 1974 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-17  lr=['8.0000000'], tr/val_loss:806.343140/792.991943, val:  50.00%, val_best:  57.96%, tr:  92.76%, tr_best:  93.45%, epoch time: 187.83 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 61.0258%\n",
      "layer   3  Sparsity: 59.9314%\n",
      "total_backward_count 435456 real_backward_count 101091  23.215%\n",
      "layer   1  Sparsity: 75.2930%\n",
      "layer   2  Sparsity: 60.0833%\n",
      "layer   3  Sparsity: 55.0000%\n",
      "lif layer 2 self.abs_max_v: 21983.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-18  lr=['8.0000000'], tr/val_loss:819.041199/837.980652, val:  50.00%, val_best:  57.96%, tr:  92.16%, tr_best:  93.45%, epoch time: 187.17 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 63.3218%\n",
      "layer   3  Sparsity: 60.5563%\n",
      "total_backward_count 459648 real_backward_count 106350  23.137%\n",
      "layer   1  Sparsity: 88.3789%\n",
      "layer   2  Sparsity: 78.8333%\n",
      "layer   3  Sparsity: 69.0000%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 440 occurrences\n",
      "test - Value 1: 12 occurrences\n",
      "epoch-19  lr=['8.0000000'], tr/val_loss:824.822876/700.687012, val:  52.65%, val_best:  57.96%, tr:  93.33%, tr_best:  93.45%, epoch time: 186.48 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4641%\n",
      "layer   2  Sparsity: 64.6679%\n",
      "layer   3  Sparsity: 61.0764%\n",
      "total_backward_count 483840 real_backward_count 111544  23.054%\n",
      "layer   1  Sparsity: 81.2826%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 61.2500%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-20  lr=['8.0000000'], tr/val_loss:790.218994/770.316956, val:  54.42%, val_best:  57.96%, tr:  91.34%, tr_best:  93.45%, epoch time: 187.36 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4656%\n",
      "layer   2  Sparsity: 62.7420%\n",
      "layer   3  Sparsity: 60.8482%\n",
      "total_backward_count 508032 real_backward_count 116997  23.029%\n",
      "layer   1  Sparsity: 85.8724%\n",
      "layer   2  Sparsity: 71.4167%\n",
      "layer   3  Sparsity: 63.5833%\n",
      "train - Value 0: 2060 occurrences\n",
      "train - Value 1: 1972 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 312 occurrences\n",
      "test - Value 1: 140 occurrences\n",
      "epoch-21  lr=['8.0000000'], tr/val_loss:813.647644/733.330811, val:  64.16%, val_best:  64.16%, tr:  91.87%, tr_best:  93.45%, epoch time: 187.45 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4646%\n",
      "layer   2  Sparsity: 63.0501%\n",
      "layer   3  Sparsity: 60.4356%\n",
      "total_backward_count 532224 real_backward_count 122259  22.971%\n",
      "layer   1  Sparsity: 77.2461%\n",
      "layer   2  Sparsity: 66.5000%\n",
      "layer   3  Sparsity: 58.3333%\n",
      "train - Value 0: 2095 occurrences\n",
      "train - Value 1: 1937 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-22  lr=['8.0000000'], tr/val_loss:803.479919/781.284485, val:  50.00%, val_best:  64.16%, tr:  90.75%, tr_best:  93.45%, epoch time: 187.66 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4665%\n",
      "layer   2  Sparsity: 61.6245%\n",
      "layer   3  Sparsity: 59.8223%\n",
      "total_backward_count 556416 real_backward_count 127797  22.968%\n",
      "layer   1  Sparsity: 76.0091%\n",
      "layer   2  Sparsity: 57.8333%\n",
      "layer   3  Sparsity: 53.2500%\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-23  lr=['8.0000000'], tr/val_loss:644.596191/646.053650, val:  50.00%, val_best:  64.16%, tr:  91.42%, tr_best:  93.45%, epoch time: 187.93 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4668%\n",
      "layer   2  Sparsity: 57.8909%\n",
      "layer   3  Sparsity: 59.8810%\n",
      "total_backward_count 580608 real_backward_count 133021  22.911%\n",
      "layer   1  Sparsity: 75.5208%\n",
      "layer   2  Sparsity: 45.5000%\n",
      "layer   3  Sparsity: 59.3333%\n",
      "train - Value 0: 2035 occurrences\n",
      "train - Value 1: 1997 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 451 occurrences\n",
      "test - Value 1: 1 occurrences\n",
      "epoch-24  lr=['8.0000000'], tr/val_loss:702.910278/670.260498, val:  50.22%, val_best:  64.16%, tr:  92.83%, tr_best:  93.45%, epoch time: 187.76 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 52.5442%\n",
      "layer   3  Sparsity: 61.0463%\n",
      "total_backward_count 604800 real_backward_count 137988  22.815%\n",
      "layer   1  Sparsity: 72.7865%\n",
      "layer   2  Sparsity: 44.6667%\n",
      "layer   3  Sparsity: 59.0833%\n",
      "train - Value 0: 2066 occurrences\n",
      "train - Value 1: 1966 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-25  lr=['8.0000000'], tr/val_loss:646.160583/537.948792, val:  50.00%, val_best:  64.16%, tr:  90.38%, tr_best:  93.45%, epoch time: 186.52 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 55.8279%\n",
      "layer   3  Sparsity: 62.2036%\n",
      "total_backward_count 628992 real_backward_count 143237  22.772%\n",
      "layer   1  Sparsity: 77.2135%\n",
      "layer   2  Sparsity: 52.6667%\n",
      "layer   3  Sparsity: 59.8333%\n",
      "train - Value 0: 2038 occurrences\n",
      "train - Value 1: 1994 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-26  lr=['8.0000000'], tr/val_loss:584.543274/596.369202, val:  50.00%, val_best:  64.16%, tr:  89.24%, tr_best:  93.45%, epoch time: 186.31 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4666%\n",
      "layer   2  Sparsity: 55.8103%\n",
      "layer   3  Sparsity: 63.2567%\n",
      "total_backward_count 653184 real_backward_count 148874  22.792%\n",
      "layer   1  Sparsity: 72.9818%\n",
      "layer   2  Sparsity: 52.7500%\n",
      "layer   3  Sparsity: 62.7500%\n",
      "train - Value 0: 1961 occurrences\n",
      "train - Value 1: 2071 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 3 occurrences\n",
      "test - Value 1: 449 occurrences\n",
      "epoch-27  lr=['8.0000000'], tr/val_loss:565.893311/554.849915, val:  50.22%, val_best:  64.16%, tr:  87.72%, tr_best:  93.45%, epoch time: 187.11 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4675%\n",
      "layer   2  Sparsity: 58.1023%\n",
      "layer   3  Sparsity: 63.6216%\n",
      "total_backward_count 677376 real_backward_count 154629  22.828%\n",
      "layer   1  Sparsity: 80.7617%\n",
      "layer   2  Sparsity: 61.0833%\n",
      "layer   3  Sparsity: 67.7500%\n",
      "train - Value 0: 2025 occurrences\n",
      "train - Value 1: 2007 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-28  lr=['8.0000000'], tr/val_loss:765.295532/778.264160, val:  50.00%, val_best:  64.16%, tr:  90.85%, tr_best:  93.45%, epoch time: 186.66 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 59.7414%\n",
      "layer   3  Sparsity: 62.4658%\n",
      "total_backward_count 701568 real_backward_count 159899  22.792%\n",
      "layer   1  Sparsity: 80.3385%\n",
      "layer   2  Sparsity: 49.5000%\n",
      "layer   3  Sparsity: 62.9167%\n",
      "fc layer 3 self.abs_max_out: 1376.0\n",
      "train - Value 0: 1994 occurrences\n",
      "train - Value 1: 2038 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-29  lr=['8.0000000'], tr/val_loss:804.343384/748.883179, val:  50.00%, val_best:  64.16%, tr:  91.62%, tr_best:  93.45%, epoch time: 187.02 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 59.1586%\n",
      "layer   3  Sparsity: 61.9315%\n",
      "total_backward_count 725760 real_backward_count 165080  22.746%\n",
      "layer   1  Sparsity: 89.8763%\n",
      "layer   2  Sparsity: 64.6667%\n",
      "layer   3  Sparsity: 66.7500%\n",
      "fc layer 1 self.abs_max_out: 21972.0\n",
      "train - Value 0: 2048 occurrences\n",
      "train - Value 1: 1984 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-30  lr=['8.0000000'], tr/val_loss:805.941772/816.255432, val:  50.00%, val_best:  64.16%, tr:  91.02%, tr_best:  93.45%, epoch time: 187.87 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4637%\n",
      "layer   2  Sparsity: 59.4039%\n",
      "layer   3  Sparsity: 62.0718%\n",
      "total_backward_count 749952 real_backward_count 170316  22.710%\n",
      "layer   1  Sparsity: 69.0104%\n",
      "layer   2  Sparsity: 48.1667%\n",
      "layer   3  Sparsity: 57.9167%\n",
      "train - Value 0: 2020 occurrences\n",
      "train - Value 1: 2012 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-31  lr=['8.0000000'], tr/val_loss:803.208801/752.987549, val:  50.66%, val_best:  64.16%, tr:  90.92%, tr_best:  93.45%, epoch time: 187.70 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4684%\n",
      "layer   2  Sparsity: 59.7248%\n",
      "layer   3  Sparsity: 61.9913%\n",
      "total_backward_count 774144 real_backward_count 175574  22.680%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 55.0000%\n",
      "layer   3  Sparsity: 60.5000%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 249 occurrences\n",
      "test - Value 1: 203 occurrences\n",
      "epoch-32  lr=['8.0000000'], tr/val_loss:803.375122/721.191711, val:  69.69%, val_best:  69.69%, tr:  91.84%, tr_best:  93.45%, epoch time: 187.79 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 59.7764%\n",
      "layer   3  Sparsity: 62.1453%\n",
      "total_backward_count 798336 real_backward_count 180836  22.652%\n",
      "layer   1  Sparsity: 90.4297%\n",
      "layer   2  Sparsity: 65.1667%\n",
      "layer   3  Sparsity: 66.0000%\n",
      "train - Value 0: 2011 occurrences\n",
      "train - Value 1: 2021 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 339 occurrences\n",
      "test - Value 1: 113 occurrences\n",
      "epoch-33  lr=['8.0000000'], tr/val_loss:801.516113/737.392273, val:  61.28%, val_best:  69.69%, tr:  91.49%, tr_best:  93.45%, epoch time: 188.18 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4636%\n",
      "layer   2  Sparsity: 59.3477%\n",
      "layer   3  Sparsity: 61.9140%\n",
      "total_backward_count 822528 real_backward_count 186048  22.619%\n",
      "layer   1  Sparsity: 74.7070%\n",
      "layer   2  Sparsity: 56.8333%\n",
      "layer   3  Sparsity: 56.5833%\n",
      "fc layer 1 self.abs_max_out: 22805.0\n",
      "train - Value 0: 2007 occurrences\n",
      "train - Value 1: 2025 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 432 occurrences\n",
      "test - Value 1: 20 occurrences\n",
      "epoch-34  lr=['8.0000000'], tr/val_loss:804.549255/732.855103, val:  53.54%, val_best:  69.69%, tr:  90.65%, tr_best:  93.45%, epoch time: 187.46 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4671%\n",
      "layer   2  Sparsity: 59.7602%\n",
      "layer   3  Sparsity: 61.8426%\n",
      "total_backward_count 846720 real_backward_count 191308  22.594%\n",
      "layer   1  Sparsity: 87.9232%\n",
      "layer   2  Sparsity: 69.4167%\n",
      "layer   3  Sparsity: 64.6667%\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-35  lr=['8.0000000'], tr/val_loss:777.209839/728.931946, val:  50.00%, val_best:  69.69%, tr:  91.64%, tr_best:  93.45%, epoch time: 187.20 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 59.3297%\n",
      "layer   3  Sparsity: 61.7773%\n",
      "total_backward_count 870912 real_backward_count 196462  22.558%\n",
      "layer   1  Sparsity: 93.9779%\n",
      "layer   2  Sparsity: 79.7500%\n",
      "layer   3  Sparsity: 78.4167%\n",
      "train - Value 0: 1941 occurrences\n",
      "train - Value 1: 2091 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-36  lr=['8.0000000'], tr/val_loss:683.847473/519.696838, val:  50.00%, val_best:  69.69%, tr:  90.30%, tr_best:  93.45%, epoch time: 187.81 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4628%\n",
      "layer   2  Sparsity: 59.0156%\n",
      "layer   3  Sparsity: 62.5301%\n",
      "total_backward_count 895104 real_backward_count 201860  22.552%\n",
      "layer   1  Sparsity: 80.7292%\n",
      "layer   2  Sparsity: 53.0833%\n",
      "layer   3  Sparsity: 59.9167%\n",
      "train - Value 0: 2027 occurrences\n",
      "train - Value 1: 2005 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-37  lr=['8.0000000'], tr/val_loss:683.091980/714.915100, val:  50.00%, val_best:  69.69%, tr:  92.44%, tr_best:  93.45%, epoch time: 185.60 seconds, 3.09 minutes\n",
      "layer   1  Sparsity: 81.4658%\n",
      "layer   2  Sparsity: 57.5204%\n",
      "layer   3  Sparsity: 62.5798%\n",
      "total_backward_count 919296 real_backward_count 206875  22.504%\n",
      "layer   1  Sparsity: 70.4753%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 56.9167%\n",
      "train - Value 0: 2015 occurrences\n",
      "train - Value 1: 2017 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-38  lr=['8.0000000'], tr/val_loss:746.092346/720.402100, val:  50.66%, val_best:  69.69%, tr:  93.82%, tr_best:  93.82%, epoch time: 185.99 seconds, 3.10 minutes\n",
      "layer   1  Sparsity: 81.4681%\n",
      "layer   2  Sparsity: 55.6786%\n",
      "layer   3  Sparsity: 62.5448%\n",
      "total_backward_count 943488 real_backward_count 211633  22.431%\n",
      "layer   1  Sparsity: 82.8451%\n",
      "layer   2  Sparsity: 54.8333%\n",
      "layer   3  Sparsity: 61.0833%\n",
      "train - Value 0: 2049 occurrences\n",
      "train - Value 1: 1983 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-39  lr=['8.0000000'], tr/val_loss:752.458435/697.482178, val:  50.00%, val_best:  69.69%, tr:  93.53%, tr_best:  93.82%, epoch time: 187.27 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4653%\n",
      "layer   2  Sparsity: 55.4394%\n",
      "layer   3  Sparsity: 62.6049%\n",
      "total_backward_count 967680 real_backward_count 216570  22.380%\n",
      "layer   1  Sparsity: 78.8086%\n",
      "layer   2  Sparsity: 54.0000%\n",
      "layer   3  Sparsity: 67.5833%\n",
      "fc layer 2 self.abs_max_out: 11761.0\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-40  lr=['8.0000000'], tr/val_loss:785.011536/797.682617, val:  50.00%, val_best:  69.69%, tr:  94.05%, tr_best:  94.05%, epoch time: 187.46 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 55.7884%\n",
      "layer   3  Sparsity: 62.5263%\n",
      "total_backward_count 991872 real_backward_count 221306  22.312%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 55.2500%\n",
      "layer   3  Sparsity: 58.9167%\n",
      "train - Value 0: 2045 occurrences\n",
      "train - Value 1: 1987 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 49 occurrences\n",
      "test - Value 1: 403 occurrences\n",
      "epoch-41  lr=['8.0000000'], tr/val_loss:816.020996/713.723328, val:  55.53%, val_best:  69.69%, tr:  93.68%, tr_best:  94.05%, epoch time: 186.93 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 55.7568%\n",
      "layer   3  Sparsity: 62.4610%\n",
      "total_backward_count 1016064 real_backward_count 226125  22.255%\n",
      "layer   1  Sparsity: 69.5312%\n",
      "layer   2  Sparsity: 48.5000%\n",
      "layer   3  Sparsity: 58.3333%\n",
      "train - Value 0: 2036 occurrences\n",
      "train - Value 1: 1996 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-42  lr=['8.0000000'], tr/val_loss:792.514160/726.950867, val:  50.00%, val_best:  69.69%, tr:  94.35%, tr_best:  94.35%, epoch time: 188.56 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4683%\n",
      "layer   2  Sparsity: 55.2045%\n",
      "layer   3  Sparsity: 62.1132%\n",
      "total_backward_count 1040256 real_backward_count 230906  22.197%\n",
      "layer   1  Sparsity: 79.9805%\n",
      "layer   2  Sparsity: 60.0833%\n",
      "layer   3  Sparsity: 65.1667%\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 443 occurrences\n",
      "test - Value 1: 9 occurrences\n",
      "epoch-43  lr=['8.0000000'], tr/val_loss:787.434387/694.935059, val:  51.55%, val_best:  69.69%, tr:  92.53%, tr_best:  94.35%, epoch time: 187.68 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4659%\n",
      "layer   2  Sparsity: 56.2611%\n",
      "layer   3  Sparsity: 62.2457%\n",
      "total_backward_count 1064448 real_backward_count 235884  22.160%\n",
      "layer   1  Sparsity: 89.1276%\n",
      "layer   2  Sparsity: 62.8333%\n",
      "layer   3  Sparsity: 66.5833%\n",
      "fc layer 2 self.abs_max_out: 11910.0\n",
      "train - Value 0: 2053 occurrences\n",
      "train - Value 1: 1979 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "fc layer 2 self.abs_max_out: 11911.0\n",
      "fc layer 2 self.abs_max_out: 12026.0\n",
      "fc layer 2 self.abs_max_out: 12221.0\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-44  lr=['8.0000000'], tr/val_loss:794.911377/778.415161, val:  50.00%, val_best:  69.69%, tr:  93.43%, tr_best:  94.35%, epoch time: 187.57 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4639%\n",
      "layer   2  Sparsity: 55.7402%\n",
      "layer   3  Sparsity: 61.7391%\n",
      "total_backward_count 1088640 real_backward_count 240774  22.117%\n",
      "layer   1  Sparsity: 82.4544%\n",
      "layer   2  Sparsity: 50.0000%\n",
      "layer   3  Sparsity: 59.2500%\n",
      "train - Value 0: 2096 occurrences\n",
      "train - Value 1: 1936 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-45  lr=['8.0000000'], tr/val_loss:789.518250/762.058899, val:  50.00%, val_best:  69.69%, tr:  93.70%, tr_best:  94.35%, epoch time: 187.96 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4654%\n",
      "layer   2  Sparsity: 55.1930%\n",
      "layer   3  Sparsity: 61.7014%\n",
      "total_backward_count 1112832 real_backward_count 245607  22.070%\n",
      "layer   1  Sparsity: 93.5872%\n",
      "layer   2  Sparsity: 65.0000%\n",
      "layer   3  Sparsity: 72.2500%\n",
      "train - Value 0: 2092 occurrences\n",
      "train - Value 1: 1940 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 449 occurrences\n",
      "test - Value 1: 3 occurrences\n",
      "epoch-46  lr=['8.0000000'], tr/val_loss:753.824219/703.860229, val:  50.22%, val_best:  69.69%, tr:  92.36%, tr_best:  94.35%, epoch time: 187.61 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4629%\n",
      "layer   2  Sparsity: 55.4138%\n",
      "layer   3  Sparsity: 61.8552%\n",
      "total_backward_count 1137024 real_backward_count 250533  22.034%\n",
      "layer   1  Sparsity: 74.0234%\n",
      "layer   2  Sparsity: 52.9167%\n",
      "layer   3  Sparsity: 54.6667%\n",
      "train - Value 0: 2083 occurrences\n",
      "train - Value 1: 1949 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-47  lr=['8.0000000'], tr/val_loss:782.976318/825.434265, val:  50.00%, val_best:  69.69%, tr:  93.53%, tr_best:  94.35%, epoch time: 187.77 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4673%\n",
      "layer   2  Sparsity: 54.6367%\n",
      "layer   3  Sparsity: 61.6376%\n",
      "total_backward_count 1161216 real_backward_count 255300  21.986%\n",
      "layer   1  Sparsity: 84.3099%\n",
      "layer   2  Sparsity: 57.6667%\n",
      "layer   3  Sparsity: 64.5833%\n",
      "train - Value 0: 2041 occurrences\n",
      "train - Value 1: 1991 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-48  lr=['8.0000000'], tr/val_loss:797.998596/791.414673, val:  50.00%, val_best:  69.69%, tr:  94.07%, tr_best:  94.35%, epoch time: 188.07 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4650%\n",
      "layer   2  Sparsity: 55.5100%\n",
      "layer   3  Sparsity: 61.8364%\n",
      "total_backward_count 1185408 real_backward_count 260049  21.938%\n",
      "layer   1  Sparsity: 89.3555%\n",
      "layer   2  Sparsity: 64.3333%\n",
      "layer   3  Sparsity: 67.0833%\n",
      "train - Value 0: 2115 occurrences\n",
      "train - Value 1: 1917 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-49  lr=['8.0000000'], tr/val_loss:779.231384/705.920776, val:  50.00%, val_best:  69.69%, tr:  92.04%, tr_best:  94.35%, epoch time: 187.48 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 55.2204%\n",
      "layer   3  Sparsity: 62.1093%\n",
      "total_backward_count 1209600 real_backward_count 264972  21.906%\n",
      "layer   1  Sparsity: 81.9336%\n",
      "layer   2  Sparsity: 64.0000%\n",
      "layer   3  Sparsity: 64.5000%\n",
      "fc layer 1 self.abs_max_out: 23071.0\n",
      "fc layer 1 self.abs_max_out: 24028.0\n",
      "train - Value 0: 2067 occurrences\n",
      "train - Value 1: 1965 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-50  lr=['8.0000000'], tr/val_loss:619.669800/605.403992, val:  50.00%, val_best:  69.69%, tr:  91.59%, tr_best:  94.35%, epoch time: 187.10 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4655%\n",
      "layer   2  Sparsity: 56.0490%\n",
      "layer   3  Sparsity: 61.8520%\n",
      "total_backward_count 1233792 real_backward_count 270140  21.895%\n",
      "layer   1  Sparsity: 75.7812%\n",
      "layer   2  Sparsity: 58.0833%\n",
      "layer   3  Sparsity: 60.3333%\n",
      "train - Value 0: 2081 occurrences\n",
      "train - Value 1: 1951 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-51  lr=['8.0000000'], tr/val_loss:636.018555/552.917786, val:  50.00%, val_best:  69.69%, tr:  89.81%, tr_best:  94.35%, epoch time: 186.51 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4669%\n",
      "layer   2  Sparsity: 57.9340%\n",
      "layer   3  Sparsity: 61.2814%\n",
      "total_backward_count 1257984 real_backward_count 275504  21.900%\n",
      "layer   1  Sparsity: 87.6953%\n",
      "layer   2  Sparsity: 64.5833%\n",
      "layer   3  Sparsity: 67.8333%\n",
      "train - Value 0: 2024 occurrences\n",
      "train - Value 1: 2008 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-52  lr=['8.0000000'], tr/val_loss:574.050171/521.088196, val:  50.00%, val_best:  69.69%, tr:  87.90%, tr_best:  94.35%, epoch time: 187.67 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4642%\n",
      "layer   2  Sparsity: 56.2196%\n",
      "layer   3  Sparsity: 62.5853%\n",
      "total_backward_count 1282176 real_backward_count 281179  21.930%\n",
      "layer   1  Sparsity: 91.9922%\n",
      "layer   2  Sparsity: 62.1667%\n",
      "layer   3  Sparsity: 66.7500%\n",
      "fc layer 2 self.abs_max_out: 12259.0\n",
      "fc layer 2 self.abs_max_out: 12450.0\n",
      "train - Value 0: 2120 occurrences\n",
      "train - Value 1: 1912 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-53  lr=['8.0000000'], tr/val_loss:592.236694/664.052429, val:  52.21%, val_best:  69.69%, tr:  88.39%, tr_best:  94.35%, epoch time: 187.43 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4633%\n",
      "layer   2  Sparsity: 54.8256%\n",
      "layer   3  Sparsity: 62.4759%\n",
      "total_backward_count 1306368 real_backward_count 286811  21.955%\n",
      "layer   1  Sparsity: 86.3281%\n",
      "layer   2  Sparsity: 63.0000%\n",
      "layer   3  Sparsity: 67.5000%\n",
      "fc layer 1 self.abs_max_out: 24851.0\n",
      "lif layer 1 self.abs_max_v: 24851.0\n",
      "train - Value 0: 2114 occurrences\n",
      "train - Value 1: 1918 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 413 occurrences\n",
      "test - Value 1: 39 occurrences\n",
      "epoch-54  lr=['8.0000000'], tr/val_loss:549.246399/454.228455, val:  51.99%, val_best:  69.69%, tr:  88.00%, tr_best:  94.35%, epoch time: 187.02 seconds, 3.12 minutes\n",
      "layer   1  Sparsity: 81.4645%\n",
      "layer   2  Sparsity: 54.3217%\n",
      "layer   3  Sparsity: 62.3243%\n",
      "total_backward_count 1330560 real_backward_count 292650  21.994%\n",
      "layer   1  Sparsity: 81.0547%\n",
      "layer   2  Sparsity: 53.4167%\n",
      "layer   3  Sparsity: 58.6667%\n",
      "train - Value 0: 2008 occurrences\n",
      "train - Value 1: 2024 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 417 occurrences\n",
      "test - Value 1: 35 occurrences\n",
      "epoch-55  lr=['8.0000000'], tr/val_loss:562.556763/590.724182, val:  54.20%, val_best:  69.69%, tr:  88.39%, tr_best:  94.35%, epoch time: 186.81 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 56.5591%\n",
      "layer   3  Sparsity: 60.6448%\n",
      "total_backward_count 1354752 real_backward_count 298416  22.027%\n",
      "layer   1  Sparsity: 81.0872%\n",
      "layer   2  Sparsity: 50.7500%\n",
      "layer   3  Sparsity: 56.2500%\n",
      "train - Value 0: 1999 occurrences\n",
      "train - Value 1: 2033 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 25 occurrences\n",
      "test - Value 1: 427 occurrences\n",
      "epoch-56  lr=['8.0000000'], tr/val_loss:572.559204/487.271729, val:  53.76%, val_best:  69.69%, tr:  88.91%, tr_best:  94.35%, epoch time: 187.82 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4657%\n",
      "layer   2  Sparsity: 56.3239%\n",
      "layer   3  Sparsity: 62.6401%\n",
      "total_backward_count 1378944 real_backward_count 304178  22.059%\n",
      "layer   1  Sparsity: 89.7135%\n",
      "layer   2  Sparsity: 63.5833%\n",
      "layer   3  Sparsity: 65.8333%\n",
      "train - Value 0: 1980 occurrences\n",
      "train - Value 1: 2052 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 282 occurrences\n",
      "test - Value 1: 170 occurrences\n",
      "epoch-57  lr=['8.0000000'], tr/val_loss:552.916992/527.230408, val:  69.03%, val_best:  69.69%, tr:  88.19%, tr_best:  94.35%, epoch time: 187.50 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4638%\n",
      "layer   2  Sparsity: 54.5257%\n",
      "layer   3  Sparsity: 63.1220%\n",
      "total_backward_count 1403136 real_backward_count 309941  22.089%\n",
      "layer   1  Sparsity: 92.0898%\n",
      "layer   2  Sparsity: 71.5833%\n",
      "layer   3  Sparsity: 68.5000%\n",
      "train - Value 0: 1936 occurrences\n",
      "train - Value 1: 2096 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 442 occurrences\n",
      "test - Value 1: 10 occurrences\n",
      "epoch-58  lr=['8.0000000'], tr/val_loss:588.284668/471.859406, val:  51.77%, val_best:  69.69%, tr:  85.27%, tr_best:  94.35%, epoch time: 188.13 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4632%\n",
      "layer   2  Sparsity: 56.3731%\n",
      "layer   3  Sparsity: 62.7002%\n",
      "total_backward_count 1427328 real_backward_count 315976  22.138%\n",
      "layer   1  Sparsity: 78.4831%\n",
      "layer   2  Sparsity: 48.8333%\n",
      "layer   3  Sparsity: 61.2500%\n",
      "train - Value 0: 2078 occurrences\n",
      "train - Value 1: 1954 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 434 occurrences\n",
      "test - Value 1: 18 occurrences\n",
      "epoch-59  lr=['8.0000000'], tr/val_loss:620.131775/682.203857, val:  53.98%, val_best:  69.69%, tr:  87.20%, tr_best:  94.35%, epoch time: 187.61 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4663%\n",
      "layer   2  Sparsity: 57.9286%\n",
      "layer   3  Sparsity: 63.5145%\n",
      "total_backward_count 1451520 real_backward_count 321713  22.164%\n",
      "layer   1  Sparsity: 83.3333%\n",
      "layer   2  Sparsity: 59.6667%\n",
      "layer   3  Sparsity: 59.8333%\n",
      "train - Value 0: 2091 occurrences\n",
      "train - Value 1: 1941 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 450 occurrences\n",
      "test - Value 1: 2 occurrences\n",
      "epoch-60  lr=['8.0000000'], tr/val_loss:703.299927/646.870789, val:  50.44%, val_best:  69.69%, tr:  87.08%, tr_best:  94.35%, epoch time: 188.03 seconds, 3.13 minutes\n",
      "layer   1  Sparsity: 81.4652%\n",
      "layer   2  Sparsity: 57.8660%\n",
      "layer   3  Sparsity: 62.7395%\n",
      "total_backward_count 1475712 real_backward_count 327522  22.194%\n",
      "layer   1  Sparsity: 75.0000%\n",
      "layer   2  Sparsity: 48.6667%\n",
      "layer   3  Sparsity: 57.0000%\n",
      "train - Value 0: 1985 occurrences\n",
      "train - Value 1: 2047 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 1: 452 occurrences\n",
      "epoch-61  lr=['8.0000000'], tr/val_loss:647.725708/715.000977, val:  50.00%, val_best:  69.69%, tr:  86.38%, tr_best:  94.35%, epoch time: 188.15 seconds, 3.14 minutes\n",
      "layer   1  Sparsity: 81.4670%\n",
      "layer   2  Sparsity: 59.9814%\n",
      "layer   3  Sparsity: 60.7631%\n",
      "total_backward_count 1499904 real_backward_count 333429  22.230%\n",
      "layer   1  Sparsity: 78.5807%\n",
      "layer   2  Sparsity: 61.8333%\n",
      "layer   3  Sparsity: 68.1667%\n",
      "train - Value 0: 1978 occurrences\n",
      "train - Value 1: 2054 occurrences\n",
      "train_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test_spike_distribution.mean 6.000000, min 6, max 6\n",
      "test - Value 0: 452 occurrences\n",
      "epoch-62  lr=['8.0000000'], tr/val_loss:646.918823/610.518860, val:  50.00%, val_best:  69.69%, tr:  88.00%, tr_best:  94.35%, epoch time: 186.38 seconds, 3.11 minutes\n",
      "layer   1  Sparsity: 81.4662%\n",
      "layer   2  Sparsity: 60.3150%\n",
      "layer   3  Sparsity: 61.4026%\n",
      "total_backward_count 1524096 real_backward_count 339171  22.254%\n",
      "layer   1  Sparsity: 80.9896%\n",
      "layer   2  Sparsity: 52.5833%\n",
      "layer   3  Sparsity: 56.5000%\n"
     ]
    }
   ],
   "source": [
    "# sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "target_word=0\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_targetword{target_word}_new251129',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [4,6,8]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [8]},\n",
    "        \"which_data\": {\"values\": ['n_tidigits_tonic']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [4096.0,2048.0,1024.0,512.0,256.0,128.0,64.0,32.0]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]},\n",
    "        # \"lif_layer_sg_width\": {\"values\": [4.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1.0, 2.0, 4.0, 8.0]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [1]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [target_word]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [False]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [8]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"scale_exp_2w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "\n",
    "        \"scale_exp_3w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"timestep_sums_threshold\": {\"values\": [0]},\n",
    "\n",
    "        \"loser_encourage_mode\": {\"values\": [True, False]},\n",
    "        \n",
    "        \"lif_layer_sg_width2\": {\"values\": [1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]},\n",
    "        \"lif_layer_v_threshold2\": {\"values\": [4096.0,2048.0,1024.0,512.0,256.0,128.0,64.0,32.0]},\n",
    "        \"learning_rate2\": {\"values\": [1.0, 2.0, 4.0, 8.0]},\n",
    "        \"init_scaling_0\": {\"values\": [1.0, 1/2, 1/4, 1/8, 1/16, 1/32]},\n",
    "        \"init_scaling_1\": {\"values\": [1.0, 1/2, 1/4, 1/8, 1/16, 1/32]},\n",
    "        \"init_scaling_2\": {\"values\": [1.0, 1/2, 1/4, 1/8, 1/16, 1/32]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"4\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "        timestep_sums_threshold  =  wandb.config.timestep_sums_threshold,\n",
    "        loser_encourage_mode  =  wandb.config.loser_encourage_mode,\n",
    "        lif_layer_sg_width2  =  wandb.config.lif_layer_sg_width2,\n",
    "        lif_layer_v_threshold2  =  wandb.config.lif_layer_v_threshold2,\n",
    "        learning_rate2  =  wandb.config.learning_rate2,\n",
    "        init_scaling = [wandb.config.init_scaling_0,wandb.config.init_scaling_1,wandb.config.init_scaling_2],\n",
    "                        ) \n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling\n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = '9m2jgqar'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn NTIDIGITS SWEEP LOSER ONOFF new251129')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn NTIDIGITS SWEEP LOSER ONOFF new251129')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
