{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device) # batch, time\n",
    "            if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                spike = (spike > levels).to(torch.float) \n",
    "                # spike: batch, time, level_num\n",
    "                # levels: time, level_num\n",
    "                assert spike.shape[0] == batch_size and spike.shape[1] == TIME and spike.shape[2] == spike_length\n",
    "            elif 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            \n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "            iter += 1\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if coarse_com_mode == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 2\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.5 # -cor\n",
    "# v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# coarse_com_mode = True\n",
    "# coarse_com_config = (3.0, -3.0) # (max, min) (2.0, -2.0) (3.0 -3.0)\n",
    "\n",
    "# sae_l2_norm_bridge = False # True False\n",
    "# sae_lif_bridge = True # False True\n",
    "\n",
    "# accuracy_check_epoch_term = 50\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "#     current_time = current_time,\n",
    "\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#     coarse_com_mode = coarse_com_mode,\n",
    "#     coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "#     sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#     sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#     accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 83jy6q80\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: unkang4b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taccuracy_check_epoch_term: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_config: [2, -2]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_l2_norm_bridge: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_lif_bridge: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250106_145132-unkang4b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/unkang4b' target=\"_blank\">fresh-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/unkang4b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/unkang4b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_mode' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_l2_norm_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_lif_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'accuracy_check_epoch_term' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_config' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 5, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 20, 'v_decay': 0.125, 'v_threshold': 0.75, 'v_reset': 10000, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250106_145138_739', 'optimizer': 'SGD', 'coarse_com_mode': True, 'sae_l2_norm_bridge': False, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 5, 'coarse_com_config': [2, -2]}\n",
      "conv length [1, 4, 9, 20]\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=96, out_features=4, bias=False)\n",
      "      (17): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (18): LIF_layer()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=96, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250106_145138_739\n",
      "\n",
      "epoch-0 loss : nan\n",
      "ae train 실행 시간: 207.543초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.77%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 22.534초\n",
      "\n",
      "epoch-1 loss : nan\n",
      "ae train 실행 시간: 205.440초\n",
      "\n",
      "epoch-1 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.77%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 22.448초\n",
      "\n",
      "epoch-2 loss : nan\n",
      "ae train 실행 시간: 208.914초\n",
      "\n",
      "epoch-3 loss : nan\n",
      "ae train 실행 시간: 213.254초\n",
      "\n",
      "epoch-4 loss : nan\n",
      "ae train 실행 시간: 214.923초\n",
      "\n",
      "epoch-5 loss : nan\n",
      "ae train 실행 시간: 214.929초\n",
      "\n",
      "epoch-5 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.77%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 23.592초\n",
      "\n",
      "epoch-6 loss : nan\n",
      "ae train 실행 시간: 219.668초\n",
      "\n",
      "epoch-7 loss : nan\n",
      "ae train 실행 시간: 216.938초\n",
      "\n",
      "epoch-8 loss : nan\n",
      "ae train 실행 시간: 209.867초\n",
      "\n",
      "epoch-9 loss : nan\n",
      "ae train 실행 시간: 212.336초\n",
      "\n",
      "epoch-9 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.77%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 21.925초\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb4e2af585545fcaf2c0df99a825e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset2</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>nan</td></tr><tr><td>best_mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.33514</td></tr><tr><td>mean_cluster_accuracy_post_training_cycle_all_dataset</td><td>0.33514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/unkang4b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/unkang4b</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250106_145132-unkang4b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mzpza8n1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taccuracy_check_epoch_term: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_config: [2, -2]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_l2_norm_bridge: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_lif_bridge: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 2400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.75\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250106_152847-mzpza8n1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/mzpza8n1' target=\"_blank\">stellar-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/83jy6q80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/mzpza8n1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/mzpza8n1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_mode' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_l2_norm_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_lif_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'accuracy_check_epoch_term' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_config' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 5, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 8, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 40, 'v_decay': 0.125, 'v_threshold': 0.75, 'v_reset': 0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250106_152853_556', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': False, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 5, 'coarse_com_config': [2, -2]}\n",
      "conv length [4, 9, 19, 40]\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=384, out_features=4, bias=False)\n",
      "      (17): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (18): LIF_layer()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=384, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250106_152853_556\n",
      "\n",
      "epoch-0 loss : 0.12979\n",
      "ae train 실행 시간: 723.351초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.82675045 0.87076649 0.80872795 0.75977654 0.78613861 0.70357143\n",
      " 0.64985163 0.44316163 0.43438454 0.4389313  0.40671642 0.48323471\n",
      " 0.6120332  0.51506591 0.47115385 0.42086002]\n",
      "mean_cluster_accuracy_during_training_cycle : 59.95%, post_traincycle_acc : 60.19%, total_acc : 60.01%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 60.19%\n",
      "accuracy_check 실행 시간: 21.795초\n",
      "\n",
      "epoch-1 loss : 0.02378\n",
      "ae train 실행 시간: 730.464초\n",
      "\n",
      "epoch-1 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.9171123  0.75394615 0.79981378 0.81089109 0.61696429\n",
      " 0.58654797 0.51065719 0.45879959 0.48187023 0.49906716 0.35502959\n",
      " 0.66493776 0.39453861 0.44326923 0.40347667]\n",
      "mean_cluster_accuracy_during_training_cycle : 59.53%, post_traincycle_acc : 60.43%, total_acc : 59.79%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 60.43%\n",
      "accuracy_check 실행 시간: 22.403초\n",
      "\n",
      "epoch-2 loss : 0.02095\n",
      "ae train 실행 시간: 730.336초\n",
      "\n",
      "epoch-3 loss : 0.01899\n",
      "ae train 실행 시간: 736.142초\n",
      "\n",
      "epoch-4 loss : 0.01166\n",
      "ae train 실행 시간: 734.537초\n",
      "\n",
      "epoch-5 loss : 0.01475\n",
      "ae train 실행 시간: 736.969초\n",
      "\n",
      "epoch-5 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.9714795  0.9275766  0.86312849 0.91980198 0.81696429\n",
      " 0.64787339 0.57548845 0.93082401 0.66412214 0.52145522 0.48717949\n",
      " 0.78112033 0.54990584 0.40480769 0.37328454]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.76%, post_traincycle_acc : 71.29%, total_acc : 71.61%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 71.29%\n",
      "accuracy_check 실행 시간: 24.613초\n",
      "\n",
      "epoch-6 loss : 0.01724\n",
      "ae train 실행 시간: 737.898초\n",
      "\n",
      "epoch-7 loss : 0.01385\n",
      "ae train 실행 시간: 731.849초\n",
      "\n",
      "epoch-8 loss : 0.01491\n",
      "ae train 실행 시간: 730.433초\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [8,16,32,64]}, \n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [50,40,30,20]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.125, 0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"coarse_com_mode\": {\"values\": [True]}, # ['Adam', 'SGD']\n",
    "        \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"sae_l2_norm_bridge\": {\"values\": [False]}, # [True, False]\n",
    "        \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "        \"accuracy_check_epoch_term\": {\"values\": [5]}, # [False, True]\n",
    "        \n",
    "        \n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  5\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "    coarse_com_mode = wandb.config.coarse_com_mode\n",
    "    coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "    sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "    accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "        coarse_com_mode = coarse_com_mode,\n",
    "        coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "        sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "        sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "        accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "        )\n",
    "    \n",
    "# sweep_id = 'ygoj9jt4'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# current_time = '20250102_225243_972'\n",
    "\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# JSON으로 저장\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "    loaded_hyperparameters = json.load(f)\n",
    "\n",
    "loss_history = data['loss_history']\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "print(data)\n",
    "max_acc = 0\n",
    "for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "    if i[1] > max_acc:\n",
    "        max_acc = i[1]\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "    f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "    f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "    f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
