{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35189/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64ae18213954dfc867c02c4b468bf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113528710686498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250507_225538-8qn4eet9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qn4eet9' target=\"_blank\">wild-rain-8290</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qn4eet9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qn4eet9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 128, 'IMAGE_SIZE': 17, 'which_data': 'NMNIST_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.01, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 5000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'temporal_filter': 1, 'initial_pooling': 1, 'temporal_filter_accumulation': False} \n",
      "\n",
      "dataset_hash = 7b0583c2e220caca87b64bcaac63adf4\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 469 BATCH: 128 train_data_count: 60000\n",
      "len(test_loader): 79 BATCH: 128\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=578, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (2): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (3): Feedback_Receiver()\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (5): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 158,010\n",
      "========================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  0.633496/  0.343911, val:  95.16%, val_best:  95.16%, tr:  87.13%, tr_best:  87.13%\n",
      "[module.layers.3] weight_fb parameter count: 2,000\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  0.329309/  0.303887, val:  95.41%, val_best:  95.41%, tr:  95.06%, tr_best:  95.06%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  0.282046/  0.297063, val:  95.70%, val_best:  95.70%, tr:  95.88%, tr_best:  95.88%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.248014/  0.229869, val:  96.96%, val_best:  96.96%, tr:  96.57%, tr_best:  96.57%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.230926/  0.224592, val:  96.88%, val_best:  96.96%, tr:  96.93%, tr_best:  96.93%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.214312/  0.245426, val:  96.29%, val_best:  96.96%, tr:  97.29%, tr_best:  97.29%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.207151/  0.233697, val:  96.84%, val_best:  96.96%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.198052/  0.221952, val:  97.13%, val_best:  97.13%, tr:  97.54%, tr_best:  97.54%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.190543/  0.216317, val:  97.12%, val_best:  97.13%, tr:  97.73%, tr_best:  97.73%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.179904/  0.210142, val:  97.33%, val_best:  97.33%, tr:  97.97%, tr_best:  97.97%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.180130/  0.204720, val:  97.44%, val_best:  97.44%, tr:  97.96%, tr_best:  97.97%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.171359/  0.208276, val:  97.36%, val_best:  97.44%, tr:  98.21%, tr_best:  98.21%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.167729/  0.217000, val:  97.15%, val_best:  97.44%, tr:  98.24%, tr_best:  98.24%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.163136/  0.228746, val:  97.05%, val_best:  97.44%, tr:  98.33%, tr_best:  98.33%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.162158/  0.208174, val:  97.57%, val_best:  97.57%, tr:  98.27%, tr_best:  98.33%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.155350/  0.225064, val:  97.41%, val_best:  97.57%, tr:  98.49%, tr_best:  98.49%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.154520/  0.206647, val:  97.77%, val_best:  97.77%, tr:  98.45%, tr_best:  98.49%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.150775/  0.198868, val:  97.63%, val_best:  97.77%, tr:  98.51%, tr_best:  98.51%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.148758/  0.222239, val:  97.36%, val_best:  97.77%, tr:  98.53%, tr_best:  98.53%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.141637/  0.243008, val:  96.78%, val_best:  97.77%, tr:  98.74%, tr_best:  98.74%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.142387/  0.217860, val:  97.40%, val_best:  97.77%, tr:  98.69%, tr_best:  98.74%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.136320/  0.198475, val:  97.81%, val_best:  97.81%, tr:  98.83%, tr_best:  98.83%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.137193/  0.218214, val:  97.45%, val_best:  97.81%, tr:  98.74%, tr_best:  98.83%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.137304/  0.195805, val:  97.84%, val_best:  97.84%, tr:  98.78%, tr_best:  98.83%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.132219/  0.211912, val:  97.75%, val_best:  97.84%, tr:  98.90%, tr_best:  98.90%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.129655/  0.216681, val:  97.60%, val_best:  97.84%, tr:  98.89%, tr_best:  98.90%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.127382/  0.200207, val:  98.00%, val_best:  98.00%, tr:  98.97%, tr_best:  98.97%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.125941/  0.199929, val:  97.86%, val_best:  98.00%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.125426/  0.206078, val:  97.81%, val_best:  98.00%, tr:  98.97%, tr_best:  98.98%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.122614/  0.203397, val:  97.87%, val_best:  98.00%, tr:  99.07%, tr_best:  99.07%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.123574/  0.203341, val:  98.19%, val_best:  98.19%, tr:  99.02%, tr_best:  99.07%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.123460/  0.217568, val:  97.75%, val_best:  98.19%, tr:  99.03%, tr_best:  99.07%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.117966/  0.204029, val:  98.00%, val_best:  98.19%, tr:  99.09%, tr_best:  99.09%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.119149/  0.212242, val:  97.84%, val_best:  98.19%, tr:  99.09%, tr_best:  99.09%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.115488/  0.222493, val:  97.48%, val_best:  98.19%, tr:  99.15%, tr_best:  99.15%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.113857/  0.216377, val:  97.77%, val_best:  98.19%, tr:  99.22%, tr_best:  99.22%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.114927/  0.219551, val:  97.63%, val_best:  98.19%, tr:  99.17%, tr_best:  99.22%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.112240/  0.220315, val:  97.79%, val_best:  98.19%, tr:  99.18%, tr_best:  99.22%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.113411/  0.215849, val:  97.59%, val_best:  98.19%, tr:  99.20%, tr_best:  99.22%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.111554/  0.223737, val:  97.48%, val_best:  98.19%, tr:  99.25%, tr_best:  99.25%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.109841/  0.218403, val:  97.84%, val_best:  98.19%, tr:  99.23%, tr_best:  99.25%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.107088/  0.222300, val:  97.94%, val_best:  98.19%, tr:  99.32%, tr_best:  99.32%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.107366/  0.219477, val:  97.83%, val_best:  98.19%, tr:  99.29%, tr_best:  99.32%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.103534/  0.216043, val:  97.93%, val_best:  98.19%, tr:  99.35%, tr_best:  99.35%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.106427/  0.216952, val:  97.79%, val_best:  98.19%, tr:  99.32%, tr_best:  99.35%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.101668/  0.212762, val:  98.06%, val_best:  98.19%, tr:  99.37%, tr_best:  99.37%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.101761/  0.225412, val:  97.65%, val_best:  98.19%, tr:  99.38%, tr_best:  99.38%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.100621/  0.220726, val:  97.83%, val_best:  98.19%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.099394/  0.214360, val:  98.10%, val_best:  98.19%, tr:  99.41%, tr_best:  99.41%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.099710/  0.227194, val:  97.69%, val_best:  98.19%, tr:  99.38%, tr_best:  99.41%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.098214/  0.215353, val:  98.04%, val_best:  98.19%, tr:  99.43%, tr_best:  99.43%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.096683/  0.222905, val:  97.84%, val_best:  98.19%, tr:  99.47%, tr_best:  99.47%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.096853/  0.217824, val:  97.99%, val_best:  98.19%, tr:  99.46%, tr_best:  99.47%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.098140/  0.215100, val:  98.05%, val_best:  98.19%, tr:  99.43%, tr_best:  99.47%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.094584/  0.231061, val:  97.76%, val_best:  98.19%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.094834/  0.227861, val:  98.00%, val_best:  98.19%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.093530/  0.233793, val:  97.65%, val_best:  98.19%, tr:  99.50%, tr_best:  99.50%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.091875/  0.228045, val:  97.88%, val_best:  98.19%, tr:  99.54%, tr_best:  99.54%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.093526/  0.215732, val:  98.19%, val_best:  98.19%, tr:  99.53%, tr_best:  99.54%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.089935/  0.220441, val:  98.18%, val_best:  98.19%, tr:  99.54%, tr_best:  99.54%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.090830/  0.221643, val:  98.08%, val_best:  98.19%, tr:  99.55%, tr_best:  99.55%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.090470/  0.239394, val:  97.77%, val_best:  98.19%, tr:  99.51%, tr_best:  99.55%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.090355/  0.216213, val:  98.19%, val_best:  98.19%, tr:  99.57%, tr_best:  99.57%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.089697/  0.219922, val:  98.21%, val_best:  98.21%, tr:  99.56%, tr_best:  99.57%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.089824/  0.237728, val:  97.85%, val_best:  98.21%, tr:  99.53%, tr_best:  99.57%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.088545/  0.222227, val:  98.13%, val_best:  98.21%, tr:  99.57%, tr_best:  99.57%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.086685/  0.224853, val:  98.08%, val_best:  98.21%, tr:  99.61%, tr_best:  99.61%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.085982/  0.223959, val:  98.10%, val_best:  98.21%, tr:  99.58%, tr_best:  99.61%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.085793/  0.231095, val:  97.87%, val_best:  98.21%, tr:  99.63%, tr_best:  99.63%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.086450/  0.245609, val:  97.87%, val_best:  98.21%, tr:  99.62%, tr_best:  99.63%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.084422/  0.229119, val:  98.12%, val_best:  98.21%, tr:  99.64%, tr_best:  99.64%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.084193/  0.227597, val:  98.15%, val_best:  98.21%, tr:  99.64%, tr_best:  99.64%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.083938/  0.245110, val:  97.62%, val_best:  98.21%, tr:  99.66%, tr_best:  99.66%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.082543/  0.240184, val:  98.06%, val_best:  98.21%, tr:  99.64%, tr_best:  99.66%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.082831/  0.242689, val:  97.99%, val_best:  98.21%, tr:  99.62%, tr_best:  99.66%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.081743/  0.231736, val:  98.23%, val_best:  98.23%, tr:  99.66%, tr_best:  99.66%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.081902/  0.243761, val:  97.96%, val_best:  98.23%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.081649/  0.249471, val:  97.64%, val_best:  98.23%, tr:  99.65%, tr_best:  99.67%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.082683/  0.232296, val:  98.24%, val_best:  98.24%, tr:  99.64%, tr_best:  99.67%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.078966/  0.236032, val:  98.08%, val_best:  98.24%, tr:  99.71%, tr_best:  99.71%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.077786/  0.234894, val:  98.14%, val_best:  98.24%, tr:  99.69%, tr_best:  99.71%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.078704/  0.251858, val:  97.74%, val_best:  98.24%, tr:  99.70%, tr_best:  99.71%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.078112/  0.248103, val:  97.98%, val_best:  98.24%, tr:  99.70%, tr_best:  99.71%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.078957/  0.234853, val:  98.17%, val_best:  98.24%, tr:  99.69%, tr_best:  99.71%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.078258/  0.241286, val:  97.84%, val_best:  98.24%, tr:  99.72%, tr_best:  99.72%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.076623/  0.245589, val:  97.93%, val_best:  98.24%, tr:  99.72%, tr_best:  99.72%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.076942/  0.241337, val:  97.99%, val_best:  98.24%, tr:  99.73%, tr_best:  99.73%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.076892/  0.239591, val:  98.07%, val_best:  98.24%, tr:  99.71%, tr_best:  99.73%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.077748/  0.257055, val:  97.78%, val_best:  98.24%, tr:  99.71%, tr_best:  99.73%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.076070/  0.240089, val:  98.11%, val_best:  98.24%, tr:  99.74%, tr_best:  99.74%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.077239/  0.242296, val:  98.12%, val_best:  98.24%, tr:  99.73%, tr_best:  99.74%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.075619/  0.248400, val:  97.98%, val_best:  98.24%, tr:  99.73%, tr_best:  99.74%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.072824/  0.244031, val:  98.05%, val_best:  98.24%, tr:  99.74%, tr_best:  99.74%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.074377/  0.244640, val:  98.05%, val_best:  98.24%, tr:  99.72%, tr_best:  99.74%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.073973/  0.245978, val:  97.96%, val_best:  98.24%, tr:  99.76%, tr_best:  99.76%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.073967/  0.246397, val:  97.99%, val_best:  98.24%, tr:  99.74%, tr_best:  99.76%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.072887/  0.245197, val:  98.08%, val_best:  98.24%, tr:  99.76%, tr_best:  99.76%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.073699/  0.245539, val:  98.05%, val_best:  98.24%, tr:  99.76%, tr_best:  99.76%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.071121/  0.242919, val:  98.14%, val_best:  98.24%, tr:  99.77%, tr_best:  99.77%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.072082/  0.253250, val:  97.94%, val_best:  98.24%, tr:  99.79%, tr_best:  99.79%\n",
      "epoch-100 lr=['0.0100000'], tr/val_loss:  0.070843/  0.246610, val:  98.11%, val_best:  98.24%, tr:  99.79%, tr_best:  99.79%\n",
      "epoch-101 lr=['0.0100000'], tr/val_loss:  0.073454/  0.252841, val:  97.86%, val_best:  98.24%, tr:  99.76%, tr_best:  99.79%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"4\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 17, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'NMNIST_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.01, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 5_000, # 10_000 # 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 1, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "#         \"epoch_num\": {\"values\": [100]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [True]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [1]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"0\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  unique_name_hyper,\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '6pj3lh8j'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
