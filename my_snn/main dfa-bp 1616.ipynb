{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20612/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    \n",
    "    print('\\nyour OTTT_sWS_on', OTTT_sWS_on,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"))\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                no_val_best_growth_count = 0\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                no_tr_best_growth_count = 0\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter:{100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            val_loss=0\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += val_loss_temp.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                iterator.set_description(f\"{iter_acc_string}, iter/val_loss:{loss:.3f}/{val_loss:.3f}, tr:{100 * tr_acc:.2f}%, val:{100 * val_acc_now:.2f}%, val_best:{100 * val_acc_best:.2f}%\")  \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240819_001650-p6kb7e2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p6kb7e2c' target=\"_blank\">copper-waterfall-3114</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p6kb7e2c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p6kb7e2c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your OTTT_sWS_on False \n",
      "\n",
      "processing - exclude 'other' class\n",
      "processing done - exclude 'other' class\n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): DimChanger_for_FC_sstep()\n",
      "      (4): SYNAPSE_FC_trace_sstep()\n",
      "      (5): LIF_layer_trace_sstep()\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "      (8): LIF_layer_trace_sstep()\n",
      "      (9): Feedback_Receiver()\n",
      "      (10): SYNAPSE_FC_trace_sstep()\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 144,810, system's param_num : 144,810\n",
      "Memory: 0.55MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-61/62 iter:66.67%, lr=['0.001'], iter/val_loss:22.679/344.046, tr:8.78%, val:12.50%, val_best:12.50%: 100%|██████████| 62/62 [00:38<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.80291175842285 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1-61/62 iter:66.67%, lr=['0.000999972584682756'], iter/val_loss:17.860/271.439, tr:28.09%, val:37.50%, val_best:37.50%: 100%|██████████| 62/62 [00:38<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.855475664138794 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2-61/62 iter:33.33%, lr=['0.0009998903417374227'], iter/val_loss:16.469/232.799, tr:46.37%, val:48.33%, val_best:48.33%: 100%|██████████| 62/62 [00:39<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.67630624771118 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3-61/62 iter:0.00%, lr=['0.0009997532801828658'], iter/val_loss:14.414/223.100, tr:57.61%, val:57.50%, val_best:57.50%: 100%|██████████| 62/62 [00:39<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.223270416259766 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4-61/62 iter:100.00%, lr=['0.0009995614150494292'], iter/val_loss:11.140/220.337, tr:59.55%, val:51.67%, val_best:57.50%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.427579402923584 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5-61/62 iter:33.33%, lr=['0.000999314767377287'], iter/val_loss:17.200/207.907, tr:61.39%, val:57.92%, val_best:57.92%: 100%|██████████| 62/62 [00:39<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.26453518867493 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6-61/62 iter:33.33%, lr=['0.0009990133642141358'], iter/val_loss:8.345/204.124, tr:65.17%, val:62.08%, val_best:62.08%: 100%|██████████| 62/62 [00:40<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 40.83174443244934 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7-61/62 iter:100.00%, lr=['0.000998657238612229'], iter/val_loss:4.854/202.099, tr:66.19%, val:58.75%, val_best:62.08%: 100%|██████████| 62/62 [00:38<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.12896776199341 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8-61/62 iter:100.00%, lr=['0.0009982464296247522'], iter/val_loss:11.572/194.694, tr:67.62%, val:62.08%, val_best:62.08%: 100%|██████████| 62/62 [00:38<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.04719591140747 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9-61/62 iter:33.33%, lr=['0.00099778098230154'], iter/val_loss:7.530/193.536, tr:68.03%, val:61.25%, val_best:62.08%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.463475704193115 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10-61/62 iter:100.00%, lr=['0.0009972609476841367'], iter/val_loss:11.620/195.343, tr:69.25%, val:60.83%, val_best:62.08%: 100%|██████████| 62/62 [00:39<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.91741132736206 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11-61/62 iter:66.67%, lr=['0.0009966863828001983'], iter/val_loss:11.377/198.493, tr:68.54%, val:62.08%, val_best:62.08%: 100%|██████████| 62/62 [00:39<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.622413873672485 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12-61/62 iter:100.00%, lr=['0.0009960573506572392'], iter/val_loss:4.835/195.505, tr:68.34%, val:65.83%, val_best:65.83%: 100%|██████████| 62/62 [00:38<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.97162127494812 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13-61/62 iter:100.00%, lr=['0.000995373920235722'], iter/val_loss:17.517/191.082, tr:71.81%, val:69.58%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.34043622016907 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14-61/62 iter:100.00%, lr=['0.0009946361664814943'], iter/val_loss:2.506/191.959, tr:74.57%, val:66.67%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.424357652664185 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15-61/62 iter:66.67%, lr=['0.000993844170297569'], iter/val_loss:8.577/190.083, tr:74.46%, val:67.92%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.264907121658325 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "16-61/62 iter:66.67%, lr=['0.0009929980185352527'], iter/val_loss:9.056/193.498, tr:75.79%, val:67.08%, val_best:69.58%: 100%|██████████| 62/62 [00:40<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 40.43997669219971 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17-61/62 iter:66.67%, lr=['0.000992097803984621'], iter/val_loss:9.048/192.331, tr:74.26%, val:65.42%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.3702437877655 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "18-61/62 iter:33.33%, lr=['0.0009911436253643446'], iter/val_loss:13.231/190.958, tr:75.49%, val:67.50%, val_best:69.58%: 100%|██████████| 62/62 [00:38<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.13889193534851 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "19-61/62 iter:100.00%, lr=['0.0009901355873108612'], iter/val_loss:3.257/198.253, tr:77.32%, val:61.67%, val_best:69.58%: 100%|██████████| 62/62 [00:38<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.76631212234497 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20-61/62 iter:100.00%, lr=['0.000989073800366903'], iter/val_loss:8.210/194.215, tr:77.32%, val:67.92%, val_best:69.58%: 100%|██████████| 62/62 [00:38<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.79395890235901 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21-61/62 iter:100.00%, lr=['0.0009879583809693738'], iter/val_loss:6.992/195.043, tr:78.24%, val:62.08%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.396268129348755 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "22-61/62 iter:100.00%, lr=['0.0009867894514365802'], iter/val_loss:11.844/192.165, tr:78.96%, val:65.42%, val_best:69.58%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.42324471473694 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "23-61/62 iter:100.00%, lr=['0.0009855671399548183'], iter/val_loss:6.425/196.316, tr:79.06%, val:66.25%, val_best:69.58%: 100%|██████████| 62/62 [00:38<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.987653970718384 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "24-61/62 iter:100.00%, lr=['0.0009842915805643158'], iter/val_loss:6.034/197.630, tr:78.14%, val:70.42%, val_best:70.42%: 100%|██████████| 62/62 [00:38<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.52278757095337 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25-61/62 iter:100.00%, lr=['0.0009829629131445344'], iter/val_loss:6.438/189.847, tr:81.72%, val:70.00%, val_best:70.42%: 100%|██████████| 62/62 [00:39<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.34494113922119 seconds\n",
      "\n",
      "EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "26-61/62 iter:100.00%, lr=['0.0009815812833988294'], iter/val_loss:5.837/195.588, tr:84.68%, val:65.83%, val_best:70.42%: 100%|██████████| 62/62 [00:39<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.91221284866333 seconds\n",
      "\n",
      "EPOCH 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "27-61/62 iter:66.67%, lr=['0.0009801468428384719'], iter/val_loss:6.994/198.537, tr:83.55%, val:67.50%, val_best:70.42%: 100%|██████████| 62/62 [00:39<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.25452470779419 seconds\n",
      "\n",
      "EPOCH 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "28-61/62 iter:100.00%, lr=['0.000978659748766034'], iter/val_loss:6.310/204.384, tr:82.12%, val:62.92%, val_best:70.42%: 100%|██████████| 62/62 [00:38<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.96983361244202 seconds\n",
      "\n",
      "EPOCH 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "29-61/62 iter:66.67%, lr=['0.0009771201642581387'], iter/val_loss:6.469/199.422, tr:82.12%, val:68.33%, val_best:70.42%: 100%|██████████| 62/62 [00:40<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 40.20307970046997 seconds\n",
      "\n",
      "EPOCH 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "30-61/62 iter:66.67%, lr=['0.0009755282581475771'], iter/val_loss:11.896/197.500, tr:84.27%, val:68.75%, val_best:70.42%: 100%|██████████| 62/62 [00:38<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 38.73758625984192 seconds\n",
      "\n",
      "EPOCH 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31-61/62 iter:66.67%, lr=['0.0009738842050047931'], iter/val_loss:15.506/206.184, tr:84.78%, val:62.08%, val_best:70.42%: 100%|██████████| 62/62 [00:39<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 39.992905139923096 seconds\n",
      "\n",
      "EPOCH 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32-61/62 iter:66.67%, lr=['0.0009721881851187409'], iter/val_loss:10.931/202.318, tr:86.11%, val:68.75%, val_best:70.42%: 100%|██████████| 62/62 [00:41<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 41.36786389350891 seconds\n",
      "\n",
      "EPOCH 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "33-61/62 iter:100.00%, lr=['0.0009704403844771131'], iter/val_loss:9.655/195.187, tr:85.29%, val:71.25%, val_best:71.25%: 100%|██████████| 62/62 [01:42<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.45968556404114 seconds\n",
      "\n",
      "EPOCH 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "34-61/62 iter:100.00%, lr=['0.0009686409947459461'], iter/val_loss:5.941/202.287, tr:85.39%, val:70.00%, val_best:71.25%: 100%|██████████| 62/62 [02:08<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 129.36749291419983 seconds\n",
      "\n",
      "EPOCH 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "35-61/62 iter:100.00%, lr=['0.0009667902132486011'], iter/val_loss:4.884/200.538, tr:85.90%, val:70.83%, val_best:71.25%: 100%|██████████| 62/62 [02:11<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 131.99978065490723 seconds\n",
      "\n",
      "EPOCH 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "36-61/62 iter:100.00%, lr=['0.000964888242944126'], iter/val_loss:10.855/207.041, tr:86.21%, val:67.92%, val_best:71.25%: 100%|██████████| 62/62 [01:57<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 117.90320062637329 seconds\n",
      "\n",
      "EPOCH 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "37-61/62 iter:100.00%, lr=['0.0009629352924049977'], iter/val_loss:2.551/198.733, tr:87.33%, val:70.83%, val_best:71.25%: 100%|██████████| 62/62 [01:58<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 119.29737424850464 seconds\n",
      "\n",
      "EPOCH 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "38-61/62 iter:100.00%, lr=['0.0009609315757942507'], iter/val_loss:2.785/199.423, tr:88.87%, val:70.83%, val_best:71.25%: 100%|██████████| 62/62 [02:02<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 122.6417350769043 seconds\n",
      "\n",
      "EPOCH 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "39-61/62 iter:100.00%, lr=['0.0009588773128419909'], iter/val_loss:2.119/201.360, tr:88.15%, val:71.25%, val_best:71.25%: 100%|██████████| 62/62 [02:00<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 121.08721327781677 seconds\n",
      "\n",
      "EPOCH 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40-61/62 iter:100.00%, lr=['0.0009567727288213008'], iter/val_loss:2.488/209.986, tr:89.79%, val:68.33%, val_best:71.25%: 100%|██████████| 62/62 [01:54<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 115.0371720790863 seconds\n",
      "\n",
      "EPOCH 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41-61/62 iter:66.67%, lr=['0.0009546180545235346'], iter/val_loss:11.860/204.560, tr:88.87%, val:72.92%, val_best:72.92%: 100%|██████████| 62/62 [02:45<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 165.5664188861847 seconds\n",
      "\n",
      "EPOCH 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "42-61/62 iter:66.67%, lr=['0.0009524135262330101'], iter/val_loss:7.287/207.475, tr:87.95%, val:70.83%, val_best:72.92%: 100%|██████████| 62/62 [02:12<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 132.73724913597107 seconds\n",
      "\n",
      "EPOCH 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "43-61/62 iter:100.00%, lr=['0.0009501593857010972'], iter/val_loss:6.854/208.113, tr:89.17%, val:67.92%, val_best:72.92%: 100%|██████████| 62/62 [02:31<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 151.45949149131775 seconds\n",
      "\n",
      "EPOCH 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "44-61/62 iter:100.00%, lr=['0.0009478558801197068'], iter/val_loss:6.992/208.911, tr:87.64%, val:72.08%, val_best:72.92%: 100%|██████████| 62/62 [02:55<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.52370262145996 seconds\n",
      "\n",
      "EPOCH 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "45-61/62 iter:100.00%, lr=['0.0009455032620941841'], iter/val_loss:7.819/211.842, tr:90.40%, val:68.33%, val_best:72.92%: 100%|██████████| 62/62 [02:28<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 148.79045486450195 seconds\n",
      "\n",
      "EPOCH 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "46-61/62 iter:100.00%, lr=['0.0009431017896156075'], iter/val_loss:9.134/202.915, tr:89.38%, val:73.75%, val_best:73.75%: 100%|██████████| 62/62 [02:22<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 143.45349884033203 seconds\n",
      "\n",
      "EPOCH 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "47-61/62 iter:100.00%, lr=['0.0009406517260324962'], iter/val_loss:4.300/212.268, tr:91.73%, val:71.25%, val_best:73.75%: 100%|██████████| 62/62 [02:26<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 147.21179008483887 seconds\n",
      "\n",
      "EPOCH 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48-61/62 iter:100.00%, lr=['0.000938153340021932'], iter/val_loss:8.160/211.118, tr:91.32%, val:71.25%, val_best:73.75%: 100%|██████████| 62/62 [02:29<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 149.6427607536316 seconds\n",
      "\n",
      "EPOCH 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "49-61/62 iter:66.67%, lr=['0.0009356069055600951'], iter/val_loss:10.827/212.830, tr:90.60%, val:70.83%, val_best:73.75%: 100%|██████████| 62/62 [02:36<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 156.5257339477539 seconds\n",
      "\n",
      "EPOCH 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "50-61/62 iter:66.67%, lr=['0.0009330127018922197'], iter/val_loss:9.370/215.997, tr:92.75%, val:70.00%, val_best:73.75%: 100%|██████████| 62/62 [02:29<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 149.7131576538086 seconds\n",
      "\n",
      "EPOCH 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51-61/62 iter:100.00%, lr=['0.0009303710135019722'], iter/val_loss:2.283/213.836, tr:91.62%, val:67.08%, val_best:73.75%: 100%|██████████| 62/62 [02:28<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 149.0511441230774 seconds\n",
      "\n",
      "EPOCH 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "52-61/62 iter:100.00%, lr=['0.0009276821300802536'], iter/val_loss:9.024/213.031, tr:94.08%, val:72.08%, val_best:73.75%: 100%|██████████| 62/62 [02:28<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 148.50630521774292 seconds\n",
      "\n",
      "EPOCH 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "53-61/62 iter:100.00%, lr=['0.0009249463464934323'], iter/val_loss:3.618/217.862, tr:92.65%, val:69.58%, val_best:73.75%: 100%|██████████| 62/62 [02:28<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 148.58420944213867 seconds\n",
      "\n",
      "EPOCH 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "54-61/62 iter:100.00%, lr=['0.0009221639627510079'], iter/val_loss:2.876/215.396, tr:92.75%, val:70.83%, val_best:73.75%: 100%|██████████| 62/62 [02:36<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 157.10867881774902 seconds\n",
      "\n",
      "EPOCH 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "55-61/62 iter:100.00%, lr=['0.0009193352839727124'], iter/val_loss:7.164/215.566, tr:94.69%, val:72.92%, val_best:73.75%: 100%|██████████| 62/62 [02:28<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 149.16967225074768 seconds\n",
      "\n",
      "EPOCH 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "56-61/62 iter:100.00%, lr=['0.0009164606203550501'], iter/val_loss:4.226/224.172, tr:94.48%, val:69.17%, val_best:73.75%: 100%|██████████| 62/62 [02:38<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 158.97592306137085 seconds\n",
      "\n",
      "EPOCH 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "57-61/62 iter:100.00%, lr=['0.0009135402871372812'], iter/val_loss:4.873/224.578, tr:93.26%, val:68.75%, val_best:73.75%: 100%|██████████| 62/62 [02:30<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 151.13889527320862 seconds\n",
      "\n",
      "EPOCH 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "58-61/62 iter:100.00%, lr=['0.0009105746045668523'], iter/val_loss:7.262/222.560, tr:93.67%, val:70.83%, val_best:73.75%: 100%|██████████| 62/62 [02:32<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 153.37598872184753 seconds\n",
      "\n",
      "EPOCH 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "59-61/62 iter:66.67%, lr=['0.0009075638978642773'], iter/val_loss:11.963/220.493, tr:94.59%, val:71.67%, val_best:73.75%: 100%|██████████| 62/62 [02:26<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 147.0614755153656 seconds\n",
      "\n",
      "EPOCH 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "60-61/62 iter:100.00%, lr=['0.000904508497187474'], iter/val_loss:2.263/222.002, tr:94.28%, val:70.83%, val_best:73.75%: 100%|██████████| 62/62 [02:14<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 135.0686478614807 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61-61/62 iter:66.67%, lr=['0.0009014087375955575'], iter/val_loss:5.933/223.272, tr:95.10%, val:67.50%, val_best:73.75%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.21678805351257 seconds\n",
      "\n",
      "EPOCH 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "62-61/62 iter:100.00%, lr=['0.0008982649590120983'], iter/val_loss:6.362/223.579, tr:95.71%, val:72.50%, val_best:73.75%: 100%|██████████| 62/62 [01:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.90422296524048 seconds\n",
      "\n",
      "EPOCH 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "63-61/62 iter:100.00%, lr=['0.0008950775061878453'], iter/val_loss:2.943/222.850, tr:93.77%, val:73.75%, val_best:73.75%: 100%|██████████| 62/62 [01:37<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.45268702507019 seconds\n",
      "\n",
      "EPOCH 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "64-61/62 iter:100.00%, lr=['0.0008918467286629201'], iter/val_loss:2.890/223.090, tr:95.71%, val:72.08%, val_best:73.75%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.66477489471436 seconds\n",
      "\n",
      "EPOCH 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "65-61/62 iter:100.00%, lr=['0.0008885729807284856'], iter/val_loss:3.019/224.641, tr:95.51%, val:72.50%, val_best:73.75%: 100%|██████████| 62/62 [01:42<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.68677616119385 seconds\n",
      "\n",
      "EPOCH 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "66-61/62 iter:100.00%, lr=['0.0008852566213878948'], iter/val_loss:5.235/226.998, tr:96.22%, val:72.92%, val_best:73.75%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.6990954875946 seconds\n",
      "\n",
      "EPOCH 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "67-61/62 iter:100.00%, lr=['0.0008818980143173213'], iter/val_loss:5.138/229.908, tr:96.02%, val:72.92%, val_best:73.75%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.61836743354797 seconds\n",
      "\n",
      "EPOCH 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "68-61/62 iter:100.00%, lr=['0.0008784975278258783'], iter/val_loss:5.348/226.353, tr:95.51%, val:72.50%, val_best:73.75%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.72132420539856 seconds\n",
      "\n",
      "EPOCH 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "69-61/62 iter:100.00%, lr=['0.0008750555348152299'], iter/val_loss:0.407/227.101, tr:96.42%, val:72.08%, val_best:73.75%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.80082893371582 seconds\n",
      "\n",
      "EPOCH 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "70-61/62 iter:100.00%, lr=['0.0008715724127386973'], iter/val_loss:1.135/232.141, tr:96.42%, val:69.58%, val_best:73.75%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.01386618614197 seconds\n",
      "\n",
      "EPOCH 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71-61/62 iter:100.00%, lr=['0.0008680485435598673'], iter/val_loss:1.994/226.579, tr:96.32%, val:72.92%, val_best:73.75%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.2380313873291 seconds\n",
      "\n",
      "EPOCH 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "72-61/62 iter:100.00%, lr=['0.000864484313710706'], iter/val_loss:4.186/230.852, tr:96.12%, val:72.92%, val_best:73.75%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.02819800376892 seconds\n",
      "\n",
      "EPOCH 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "73-61/62 iter:100.00%, lr=['0.0008608801140491813'], iter/val_loss:7.540/225.566, tr:95.71%, val:73.33%, val_best:73.75%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.80717062950134 seconds\n",
      "\n",
      "EPOCH 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "74-61/62 iter:100.00%, lr=['0.000857236339816402'], iter/val_loss:5.884/228.395, tr:96.83%, val:74.17%, val_best:74.17%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.52867937088013 seconds\n",
      "\n",
      "EPOCH 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "75-61/62 iter:100.00%, lr=['0.000853553390593274'], iter/val_loss:8.440/231.865, tr:96.63%, val:72.92%, val_best:74.17%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.76457977294922 seconds\n",
      "\n",
      "EPOCH 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "76-61/62 iter:66.67%, lr=['0.0008498316702566832'], iter/val_loss:9.539/231.748, tr:96.22%, val:72.08%, val_best:74.17%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.87069082260132 seconds\n",
      "\n",
      "EPOCH 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "77-61/62 iter:100.00%, lr=['0.0008460715869352037'], iter/val_loss:4.564/232.844, tr:97.45%, val:76.25%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.83254790306091 seconds\n",
      "\n",
      "EPOCH 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "78-61/62 iter:100.00%, lr=['0.0008422735529643446'], iter/val_loss:2.199/232.890, tr:97.85%, val:72.92%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.68328738212585 seconds\n",
      "\n",
      "EPOCH 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "79-61/62 iter:100.00%, lr=['0.0008384379848413306'], iter/val_loss:5.163/237.304, tr:97.45%, val:71.67%, val_best:76.25%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.24937319755554 seconds\n",
      "\n",
      "EPOCH 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "80-61/62 iter:100.00%, lr=['0.0008345653031794294'], iter/val_loss:3.343/238.766, tr:98.16%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.633047580719 seconds\n",
      "\n",
      "EPOCH 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81-61/62 iter:100.00%, lr=['0.0008306559326618262'], iter/val_loss:2.790/238.091, tr:97.55%, val:69.58%, val_best:76.25%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.21478080749512 seconds\n",
      "\n",
      "EPOCH 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "82-61/62 iter:100.00%, lr=['0.000826710301995053'], iter/val_loss:4.495/232.340, tr:97.24%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.64496326446533 seconds\n",
      "\n",
      "EPOCH 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "83-61/62 iter:100.00%, lr=['0.0008227288438619755'], iter/val_loss:5.343/237.201, tr:97.55%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.6286346912384 seconds\n",
      "\n",
      "EPOCH 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "84-61/62 iter:100.00%, lr=['0.0008187119948743451'], iter/val_loss:2.930/240.435, tr:97.55%, val:74.17%, val_best:76.25%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.13749098777771 seconds\n",
      "\n",
      "EPOCH 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "85-61/62 iter:100.00%, lr=['0.0008146601955249189'], iter/val_loss:1.350/242.120, tr:97.45%, val:72.08%, val_best:76.25%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.82389807701111 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "86-61/62 iter:100.00%, lr=['0.0008105738901391554'], iter/val_loss:4.721/241.489, tr:97.75%, val:73.33%, val_best:76.25%: 100%|██████████| 62/62 [01:41<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.28260135650635 seconds\n",
      "\n",
      "EPOCH 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "87-61/62 iter:100.00%, lr=['0.0008064535268264884'], iter/val_loss:1.516/241.349, tr:98.26%, val:72.92%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.94783020019531 seconds\n",
      "\n",
      "EPOCH 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "88-61/62 iter:100.00%, lr=['0.0008022995574311876'], iter/val_loss:4.778/241.168, tr:97.75%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.98133277893066 seconds\n",
      "\n",
      "EPOCH 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "89-61/62 iter:100.00%, lr=['0.000798112437482808'], iter/val_loss:6.489/240.773, tr:98.06%, val:72.50%, val_best:76.25%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.15741920471191 seconds\n",
      "\n",
      "EPOCH 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90-61/62 iter:100.00%, lr=['0.0007938926261462367'], iter/val_loss:4.305/245.154, tr:98.06%, val:73.33%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.31973266601562 seconds\n",
      "\n",
      "EPOCH 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91-61/62 iter:100.00%, lr=['0.0007896405861713395'], iter/val_loss:4.157/240.169, tr:98.16%, val:74.17%, val_best:76.25%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.75793170928955 seconds\n",
      "\n",
      "EPOCH 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92-61/62 iter:100.00%, lr=['0.0007853567838422161'], iter/val_loss:2.329/241.193, tr:98.37%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.70913052558899 seconds\n",
      "\n",
      "EPOCH 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "93-61/62 iter:100.00%, lr=['0.0007810416889260656'], iter/val_loss:2.958/245.500, tr:98.16%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.06160306930542 seconds\n",
      "\n",
      "EPOCH 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "94-61/62 iter:100.00%, lr=['0.0007766957746216722'], iter/val_loss:4.878/240.886, tr:98.16%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.71501851081848 seconds\n",
      "\n",
      "EPOCH 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "95-61/62 iter:100.00%, lr=['0.0007723195175075137'], iter/val_loss:2.540/245.120, tr:97.65%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.69379782676697 seconds\n",
      "\n",
      "EPOCH 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "96-61/62 iter:66.67%, lr=['0.0007679133974894984'], iter/val_loss:6.669/245.001, tr:98.37%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.99399733543396 seconds\n",
      "\n",
      "EPOCH 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "97-61/62 iter:100.00%, lr=['0.000763477897748339'], iter/val_loss:5.345/247.203, tr:98.37%, val:72.50%, val_best:76.25%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.33172655105591 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "98-61/62 iter:100.00%, lr=['0.0007590135046865653'], iter/val_loss:3.832/242.697, tr:97.65%, val:73.75%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.65296149253845 seconds\n",
      "\n",
      "EPOCH 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "99-61/62 iter:100.00%, lr=['0.0007545207078751859'], iter/val_loss:1.039/243.484, tr:98.26%, val:73.33%, val_best:76.25%: 100%|██████████| 62/62 [01:40<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.4133927822113 seconds\n",
      "\n",
      "EPOCH 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100-61/62 iter:100.00%, lr=['0.0007500000000000002'], iter/val_loss:4.152/247.466, tr:97.96%, val:72.50%, val_best:76.25%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.81428909301758 seconds\n",
      "\n",
      "EPOCH 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "101-61/62 iter:100.00%, lr=['0.0007454518768075707'], iter/val_loss:8.571/240.444, tr:97.85%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:47<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.90026450157166 seconds\n",
      "\n",
      "EPOCH 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "102-61/62 iter:100.00%, lr=['0.0007408768370508579'], iter/val_loss:4.435/246.648, tr:98.47%, val:74.17%, val_best:76.25%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.22790908813477 seconds\n",
      "\n",
      "EPOCH 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "103-61/62 iter:66.67%, lr=['0.0007362753824345274'], iter/val_loss:6.258/247.514, tr:97.75%, val:75.42%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.6612503528595 seconds\n",
      "\n",
      "EPOCH 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "104-61/62 iter:100.00%, lr=['0.0007316480175599313'], iter/val_loss:4.884/247.420, tr:98.16%, val:72.92%, val_best:76.25%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.01130795478821 seconds\n",
      "\n",
      "EPOCH 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "105-61/62 iter:100.00%, lr=['0.0007269952498697737'], iter/val_loss:2.739/253.160, tr:98.16%, val:71.67%, val_best:76.25%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.63324999809265 seconds\n",
      "\n",
      "EPOCH 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106-61/62 iter:100.00%, lr=['0.0007223175895924639'], iter/val_loss:1.583/241.725, tr:98.26%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.23606181144714 seconds\n",
      "\n",
      "EPOCH 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "107-61/62 iter:100.00%, lr=['0.000717615549686164'], iter/val_loss:4.929/249.612, tr:97.96%, val:74.58%, val_best:76.25%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.12208127975464 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "108-61/62 iter:100.00%, lr=['0.0007128896457825365'], iter/val_loss:4.898/247.007, tr:98.37%, val:74.17%, val_best:76.25%: 100%|██████████| 62/62 [01:41<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.70377993583679 seconds\n",
      "\n",
      "EPOCH 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "109-61/62 iter:66.67%, lr=['0.0007081403961302008'], iter/val_loss:6.385/248.877, tr:98.67%, val:75.00%, val_best:76.25%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.75793194770813 seconds\n",
      "\n",
      "EPOCH 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "110-61/62 iter:100.00%, lr=['0.0007033683215379003'], iter/val_loss:1.484/248.623, tr:98.47%, val:75.00%, val_best:76.25%: 100%|██████████| 62/62 [01:47<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.24187111854553 seconds\n",
      "\n",
      "EPOCH 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "111-61/62 iter:100.00%, lr=['0.0006985739453173905'], iter/val_loss:4.861/249.458, tr:98.88%, val:76.25%, val_best:76.25%: 100%|██████████| 62/62 [01:47<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.94893002510071 seconds\n",
      "\n",
      "EPOCH 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "112-61/62 iter:100.00%, lr=['0.0006937577932260517'], iter/val_loss:3.331/252.770, tr:98.67%, val:72.50%, val_best:76.25%: 100%|██████████| 62/62 [01:49<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.38708972930908 seconds\n",
      "\n",
      "EPOCH 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "113-61/62 iter:100.00%, lr=['0.0006889203934092339'], iter/val_loss:5.186/249.949, tr:99.18%, val:77.92%, val_best:77.92%: 100%|██████████| 62/62 [01:52<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 113.13742232322693 seconds\n",
      "\n",
      "EPOCH 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "114-61/62 iter:100.00%, lr=['0.0006840622763423393'], iter/val_loss:6.709/249.842, tr:98.57%, val:75.83%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.19840717315674 seconds\n",
      "\n",
      "EPOCH 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "115-61/62 iter:100.00%, lr=['0.0006791839747726503'], iter/val_loss:2.839/253.987, tr:98.67%, val:72.50%, val_best:77.92%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.84759855270386 seconds\n",
      "\n",
      "EPOCH 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "116-61/62 iter:100.00%, lr=['0.0006742860236609078'], iter/val_loss:6.933/248.767, tr:98.88%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.69239783287048 seconds\n",
      "\n",
      "EPOCH 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "117-61/62 iter:100.00%, lr=['0.000669368960122646'], iter/val_loss:1.701/251.774, tr:98.57%, val:72.92%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.21499347686768 seconds\n",
      "\n",
      "EPOCH 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "118-61/62 iter:66.67%, lr=['0.0006644333233692918'], iter/val_loss:6.536/249.476, tr:98.37%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.93100929260254 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "119-61/62 iter:100.00%, lr=['0.0006594796546490352'], iter/val_loss:4.953/252.508, tr:98.37%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.3933699131012 seconds\n",
      "\n",
      "EPOCH 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "120-61/62 iter:100.00%, lr=['0.000654508497187474'], iter/val_loss:3.627/252.340, tr:98.77%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.3899872303009 seconds\n",
      "\n",
      "EPOCH 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "121-61/62 iter:100.00%, lr=['0.0006495203961280436'], iter/val_loss:1.194/260.039, tr:98.98%, val:72.50%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.40201616287231 seconds\n",
      "\n",
      "EPOCH 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "122-61/62 iter:100.00%, lr=['0.000644515898472236'], iter/val_loss:3.121/254.950, tr:98.16%, val:75.00%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.40380930900574 seconds\n",
      "\n",
      "EPOCH 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123-61/62 iter:100.00%, lr=['0.0006394955530196149'], iter/val_loss:7.118/255.569, tr:98.77%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.93987488746643 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "124-61/62 iter:100.00%, lr=['0.0006344599103076331'], iter/val_loss:2.253/252.471, tr:98.98%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.20588898658752 seconds\n",
      "\n",
      "EPOCH 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "125-61/62 iter:100.00%, lr=['0.0006294095225512608'], iter/val_loss:5.124/253.226, tr:99.28%, val:75.00%, val_best:77.92%: 100%|██████████| 62/62 [01:46<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.7523934841156 seconds\n",
      "\n",
      "EPOCH 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "126-61/62 iter:100.00%, lr=['0.0006243449435824276'], iter/val_loss:2.910/255.292, tr:99.08%, val:72.08%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.50769877433777 seconds\n",
      "\n",
      "EPOCH 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "127-61/62 iter:100.00%, lr=['0.0006192667287892907'], iter/val_loss:1.758/255.406, tr:98.77%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.1242105960846 seconds\n",
      "\n",
      "EPOCH 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "128-61/62 iter:66.67%, lr=['0.0006141754350553281'], iter/val_loss:6.891/258.077, tr:99.28%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.02598404884338 seconds\n",
      "\n",
      "EPOCH 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "129-61/62 iter:100.00%, lr=['0.0006090716206982716'], iter/val_loss:4.604/257.166, tr:98.98%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.65804290771484 seconds\n",
      "\n",
      "EPOCH 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "130-61/62 iter:100.00%, lr=['0.0006039558454088799'], iter/val_loss:2.426/259.584, tr:99.39%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.93404912948608 seconds\n",
      "\n",
      "EPOCH 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "131-61/62 iter:100.00%, lr=['0.0005988286701895632'], iter/val_loss:1.892/258.467, tr:98.88%, val:75.83%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.47097373008728 seconds\n",
      "\n",
      "EPOCH 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "132-61/62 iter:100.00%, lr=['0.0005936906572928626'], iter/val_loss:6.381/258.616, tr:99.18%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.24552631378174 seconds\n",
      "\n",
      "EPOCH 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "133-61/62 iter:100.00%, lr=['0.000588542370159792'], iter/val_loss:2.226/258.028, tr:98.88%, val:75.00%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.1650664806366 seconds\n",
      "\n",
      "EPOCH 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "134-61/62 iter:100.00%, lr=['0.0005833843733580514'], iter/val_loss:3.183/259.305, tr:99.28%, val:72.08%, val_best:77.92%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.81684494018555 seconds\n",
      "\n",
      "EPOCH 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "135-61/62 iter:100.00%, lr=['0.0005782172325201158'], iter/val_loss:4.768/258.617, tr:99.08%, val:75.00%, val_best:77.92%: 100%|██████████| 62/62 [01:38<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.21887183189392 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "136-61/62 iter:100.00%, lr=['0.0005730415142812062'], iter/val_loss:2.629/262.763, tr:99.49%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:48<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.68796730041504 seconds\n",
      "\n",
      "EPOCH 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "137-61/62 iter:100.00%, lr=['0.0005678577862171525'], iter/val_loss:6.799/261.198, tr:99.18%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.83754348754883 seconds\n",
      "\n",
      "EPOCH 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "138-61/62 iter:100.00%, lr=['0.0005626666167821524'], iter/val_loss:4.336/261.620, tr:98.67%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.98182153701782 seconds\n",
      "\n",
      "EPOCH 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "139-61/62 iter:100.00%, lr=['0.0005574685752464337'], iter/val_loss:4.668/263.970, tr:99.28%, val:75.42%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.54317164421082 seconds\n",
      "\n",
      "EPOCH 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "140-61/62 iter:100.00%, lr=['0.0005522642316338271'], iter/val_loss:8.505/259.645, tr:99.49%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:47<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.09435486793518 seconds\n",
      "\n",
      "EPOCH 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "141-61/62 iter:100.00%, lr=['0.0005470541566592576'], iter/val_loss:3.869/263.878, tr:98.77%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.98836469650269 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "142-61/62 iter:100.00%, lr=['0.0005418389216661581'], iter/val_loss:4.478/263.831, tr:98.88%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.90996861457825 seconds\n",
      "\n",
      "EPOCH 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "143-61/62 iter:100.00%, lr=['0.0005366190985638162'], iter/val_loss:3.939/262.820, tr:99.18%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:52<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 113.2552695274353 seconds\n",
      "\n",
      "EPOCH 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "144-61/62 iter:100.00%, lr=['0.0005313952597646571'], iter/val_loss:3.910/261.448, tr:98.98%, val:76.25%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.08522343635559 seconds\n",
      "\n",
      "EPOCH 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "145-61/62 iter:100.00%, lr=['0.0005261679781214723'], iter/val_loss:7.970/261.788, tr:98.98%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.14326691627502 seconds\n",
      "\n",
      "EPOCH 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "146-61/62 iter:100.00%, lr=['0.0005209378268646002'], iter/val_loss:4.310/263.099, tr:99.18%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.10733556747437 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "147-61/62 iter:100.00%, lr=['0.0005157053795390643'], iter/val_loss:2.398/262.126, tr:99.18%, val:76.25%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.43571877479553 seconds\n",
      "\n",
      "EPOCH 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "148-61/62 iter:100.00%, lr=['0.0005104712099416788'], iter/val_loss:3.194/267.069, tr:99.28%, val:75.83%, val_best:77.92%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.29423213005066 seconds\n",
      "\n",
      "EPOCH 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "149-61/62 iter:100.00%, lr=['0.0005052358920581233'], iter/val_loss:2.719/265.530, tr:98.98%, val:73.33%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.040846824646 seconds\n",
      "\n",
      "EPOCH 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "150-61/62 iter:100.00%, lr=['0.0005000000000000003'], iter/val_loss:4.307/264.758, tr:99.39%, val:77.08%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.94937920570374 seconds\n",
      "\n",
      "EPOCH 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151-61/62 iter:100.00%, lr=['0.0004947641079418775'], iter/val_loss:4.070/265.477, tr:99.08%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.08908152580261 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "152-61/62 iter:100.00%, lr=['0.0004895287900583221'], iter/val_loss:2.399/269.264, tr:99.28%, val:74.17%, val_best:77.92%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.95311522483826 seconds\n",
      "\n",
      "EPOCH 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "153-61/62 iter:100.00%, lr=['0.0004842946204609363'], iter/val_loss:3.165/269.709, tr:98.77%, val:72.92%, val_best:77.92%: 100%|██████████| 62/62 [01:47<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.82039856910706 seconds\n",
      "\n",
      "EPOCH 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "154-61/62 iter:100.00%, lr=['0.0004790621731354006'], iter/val_loss:4.838/269.522, tr:99.39%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:57<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 117.52975296974182 seconds\n",
      "\n",
      "EPOCH 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "155-61/62 iter:100.00%, lr=['0.0004738320218785285'], iter/val_loss:2.867/269.494, tr:99.49%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.55726909637451 seconds\n",
      "\n",
      "EPOCH 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "156-61/62 iter:100.00%, lr=['0.00046860474023534385'], iter/val_loss:6.633/269.588, tr:99.69%, val:75.00%, val_best:77.92%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.72715163230896 seconds\n",
      "\n",
      "EPOCH 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "157-61/62 iter:100.00%, lr=['0.00046338090143618465'], iter/val_loss:8.098/269.865, tr:99.28%, val:75.42%, val_best:77.92%: 100%|██████████| 62/62 [01:41<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.83332657814026 seconds\n",
      "\n",
      "EPOCH 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "158-61/62 iter:100.00%, lr=['0.0004581610783338426'], iter/val_loss:1.873/274.101, tr:99.39%, val:73.75%, val_best:77.92%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.89135932922363 seconds\n",
      "\n",
      "EPOCH 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "159-61/62 iter:100.00%, lr=['0.0004529458433407432'], iter/val_loss:7.098/269.630, tr:99.39%, val:75.83%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.25560545921326 seconds\n",
      "\n",
      "EPOCH 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "160-61/62 iter:100.00%, lr=['0.00044773576836617374'], iter/val_loss:2.055/269.588, tr:99.69%, val:77.08%, val_best:77.92%: 100%|██████████| 62/62 [01:49<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.39766502380371 seconds\n",
      "\n",
      "EPOCH 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "161-61/62 iter:100.00%, lr=['0.00044253142475356714'], iter/val_loss:4.765/271.043, tr:99.39%, val:74.58%, val_best:77.92%: 100%|██████████| 62/62 [01:42<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.65524792671204 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "162-61/62 iter:100.00%, lr=['0.0004373333832178483'], iter/val_loss:2.775/268.094, tr:99.59%, val:78.33%, val_best:78.33%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.32244229316711 seconds\n",
      "\n",
      "EPOCH 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "163-61/62 iter:100.00%, lr=['0.0004321422137828482'], iter/val_loss:4.980/270.872, tr:98.98%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.94769930839539 seconds\n",
      "\n",
      "EPOCH 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "164-61/62 iter:100.00%, lr=['0.0004269584857187947'], iter/val_loss:4.076/271.547, tr:99.49%, val:74.17%, val_best:78.33%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.91910791397095 seconds\n",
      "\n",
      "EPOCH 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "165-61/62 iter:100.00%, lr=['0.00042178276747988503'], iter/val_loss:8.429/270.045, tr:99.69%, val:74.58%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.9798333644867 seconds\n",
      "\n",
      "EPOCH 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "166-61/62 iter:100.00%, lr=['0.0004166156266419491'], iter/val_loss:1.752/269.295, tr:99.49%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:41<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.53896069526672 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "167-61/62 iter:100.00%, lr=['0.00041145762984020874'], iter/val_loss:1.520/272.346, tr:99.49%, val:74.58%, val_best:78.33%: 100%|██████████| 62/62 [01:50<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 111.48044109344482 seconds\n",
      "\n",
      "EPOCH 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "168-61/62 iter:100.00%, lr=['0.00040630934270713805'], iter/val_loss:3.182/272.583, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:46<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.66076135635376 seconds\n",
      "\n",
      "EPOCH 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "169-61/62 iter:100.00%, lr=['0.00040117132981043723'], iter/val_loss:1.127/271.772, tr:99.59%, val:74.17%, val_best:78.33%: 100%|██████████| 62/62 [01:48<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.31241989135742 seconds\n",
      "\n",
      "EPOCH 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "170-61/62 iter:100.00%, lr=['0.00039604415459112063'], iter/val_loss:2.220/272.274, tr:99.59%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:50<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.6757161617279 seconds\n",
      "\n",
      "EPOCH 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "171-61/62 iter:100.00%, lr=['0.00039092837930172904'], iter/val_loss:3.698/274.752, tr:99.49%, val:74.17%, val_best:78.33%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.37940335273743 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "172-61/62 iter:100.00%, lr=['0.00038582456494467253'], iter/val_loss:5.157/273.400, tr:99.69%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.01480484008789 seconds\n",
      "\n",
      "EPOCH 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "173-61/62 iter:100.00%, lr=['0.00038073327121071'], iter/val_loss:1.516/271.180, tr:99.18%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.68321061134338 seconds\n",
      "\n",
      "EPOCH 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "174-61/62 iter:100.00%, lr=['0.00037565505641757305'], iter/val_loss:5.640/272.401, tr:99.28%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.08816409111023 seconds\n",
      "\n",
      "EPOCH 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "175-61/62 iter:100.00%, lr=['0.00037059047744874006'], iter/val_loss:5.648/268.115, tr:99.18%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:43<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.26281428337097 seconds\n",
      "\n",
      "EPOCH 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "176-61/62 iter:100.00%, lr=['0.00036554008969236766'], iter/val_loss:2.627/274.057, tr:99.49%, val:74.17%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.94372057914734 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "177-61/62 iter:100.00%, lr=['0.0003605044469803857'], iter/val_loss:3.209/273.096, tr:99.49%, val:73.75%, val_best:78.33%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.86199688911438 seconds\n",
      "\n",
      "EPOCH 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "178-61/62 iter:100.00%, lr=['0.0003554841015277645'], iter/val_loss:0.881/272.128, tr:99.49%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.22861933708191 seconds\n",
      "\n",
      "EPOCH 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "179-61/62 iter:100.00%, lr=['0.00035047960387195705'], iter/val_loss:4.430/273.085, tr:99.39%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:11<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 72.12667393684387 seconds\n",
      "\n",
      "EPOCH 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180-61/62 iter:100.00%, lr=['0.00034549150281252666'], iter/val_loss:4.813/273.814, tr:99.49%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:43<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.34237003326416 seconds\n",
      "\n",
      "EPOCH 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "181-61/62 iter:100.00%, lr=['0.00034052034535096535'], iter/val_loss:6.473/273.808, tr:99.80%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:44<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 105.33737587928772 seconds\n",
      "\n",
      "EPOCH 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "182-61/62 iter:100.00%, lr=['0.0003355666766307087'], iter/val_loss:2.164/275.007, tr:99.49%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.260409116745 seconds\n",
      "\n",
      "EPOCH 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "183-61/62 iter:100.00%, lr=['0.00033063103987735463'], iter/val_loss:0.660/276.314, tr:99.28%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.82520747184753 seconds\n",
      "\n",
      "EPOCH 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "184-61/62 iter:100.00%, lr=['0.0003257139763390928'], iter/val_loss:1.929/275.635, tr:99.49%, val:74.58%, val_best:78.33%: 100%|██████████| 62/62 [01:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 106.27435183525085 seconds\n",
      "\n",
      "EPOCH 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "185-61/62 iter:100.00%, lr=['0.0003208160252273503'], iter/val_loss:4.776/275.522, tr:99.49%, val:73.33%, val_best:78.33%: 100%|██████████| 62/62 [01:48<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 109.37654495239258 seconds\n",
      "\n",
      "EPOCH 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "186-61/62 iter:100.00%, lr=['0.0003159377236576615'], iter/val_loss:6.227/277.926, tr:99.39%, val:73.75%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.13148641586304 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "187-61/62 iter:100.00%, lr=['0.00031107960659076673'], iter/val_loss:1.630/273.836, tr:99.59%, val:73.75%, val_best:78.33%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.37042117118835 seconds\n",
      "\n",
      "EPOCH 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188-61/62 iter:100.00%, lr=['0.0003062422067739489'], iter/val_loss:4.615/274.540, tr:99.49%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:27<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 88.28694939613342 seconds\n",
      "\n",
      "EPOCH 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "189-61/62 iter:100.00%, lr=['0.00030142605468261'], iter/val_loss:2.470/274.194, tr:99.28%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.72228932380676 seconds\n",
      "\n",
      "EPOCH 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "190-61/62 iter:100.00%, lr=['0.00029663167846210025'], iter/val_loss:0.572/273.691, tr:99.39%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.54312205314636 seconds\n",
      "\n",
      "EPOCH 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "191-61/62 iter:100.00%, lr=['0.00029185960386979987'], iter/val_loss:2.145/277.025, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:47<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.82374262809753 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "192-61/62 iter:100.00%, lr=['0.00028711035421746404'], iter/val_loss:2.290/272.839, tr:99.49%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.35148310661316 seconds\n",
      "\n",
      "EPOCH 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "193-61/62 iter:100.00%, lr=['0.0002823844503138367'], iter/val_loss:2.581/273.524, tr:99.80%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:42<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.1864423751831 seconds\n",
      "\n",
      "EPOCH 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "194-61/62 iter:100.00%, lr=['0.00027768241040753675'], iter/val_loss:1.892/274.377, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.19858622550964 seconds\n",
      "\n",
      "EPOCH 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "195-61/62 iter:100.00%, lr=['0.000273004750130227'], iter/val_loss:4.807/272.415, tr:99.49%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:47<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 107.77649712562561 seconds\n",
      "\n",
      "EPOCH 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "196-61/62 iter:100.00%, lr=['0.0002683519824400696'], iter/val_loss:0.611/274.162, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:48<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.64182806015015 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "197-61/62 iter:100.00%, lr=['0.00026372461756547343'], iter/val_loss:3.016/274.176, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:49<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 110.345139503479 seconds\n",
      "\n",
      "EPOCH 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "198-61/62 iter:100.00%, lr=['0.00025912316294914267'], iter/val_loss:1.992/276.709, tr:99.49%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.65721726417542 seconds\n",
      "\n",
      "EPOCH 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "199-61/62 iter:100.00%, lr=['0.00025454812319242995'], iter/val_loss:2.200/275.243, tr:99.49%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:42<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.67193412780762 seconds\n",
      "\n",
      "EPOCH 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "200-61/62 iter:100.00%, lr=['0.0002500000000000002'], iter/val_loss:3.987/278.963, tr:99.69%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.71870303153992 seconds\n",
      "\n",
      "EPOCH 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "201-61/62 iter:100.00%, lr=['0.0002454792921248147'], iter/val_loss:3.721/277.084, tr:99.39%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:41<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 102.20714974403381 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "202-61/62 iter:100.00%, lr=['0.0002409864953134353'], iter/val_loss:5.603/275.508, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:43<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 103.81598401069641 seconds\n",
      "\n",
      "EPOCH 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "203-61/62 iter:100.00%, lr=['0.00023652210225166156'], iter/val_loss:2.575/276.208, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:43<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.24892091751099 seconds\n",
      "\n",
      "EPOCH 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "204-61/62 iter:100.00%, lr=['0.00023208660251050213'], iter/val_loss:1.073/276.886, tr:99.59%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:48<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 108.80171012878418 seconds\n",
      "\n",
      "EPOCH 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "205-61/62 iter:100.00%, lr=['0.00022768048249248695'], iter/val_loss:2.052/278.823, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:44<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 104.7175714969635 seconds\n",
      "\n",
      "EPOCH 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "206-61/62 iter:100.00%, lr=['0.00022330422537832832'], iter/val_loss:2.859/277.205, tr:99.49%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.2401475906372 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "207-61/62 iter:100.00%, lr=['0.00021895831107393514'], iter/val_loss:4.401/278.886, tr:99.59%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.91353726387024 seconds\n",
      "\n",
      "EPOCH 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "208-61/62 iter:100.00%, lr=['0.00021464321615778453'], iter/val_loss:1.471/275.526, tr:99.49%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.33191013336182 seconds\n",
      "\n",
      "EPOCH 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "209-61/62 iter:100.00%, lr=['0.00021035941382866084'], iter/val_loss:0.935/277.824, tr:99.69%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.01463270187378 seconds\n",
      "\n",
      "EPOCH 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "210-61/62 iter:100.00%, lr=['0.0002061073738537638'], iter/val_loss:7.457/278.365, tr:99.49%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.70664525032043 seconds\n",
      "\n",
      "EPOCH 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "211-61/62 iter:100.00%, lr=['0.00020188756251719235'], iter/val_loss:2.995/279.454, tr:99.49%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.38750195503235 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "212-61/62 iter:100.00%, lr=['0.0001977004425688129'], iter/val_loss:1.783/278.982, tr:99.59%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.58754277229309 seconds\n",
      "\n",
      "EPOCH 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "213-61/62 iter:100.00%, lr=['0.00019354647317351218'], iter/val_loss:3.424/277.333, tr:99.69%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.30970406532288 seconds\n",
      "\n",
      "EPOCH 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "214-61/62 iter:100.00%, lr=['0.00018942610986084514'], iter/val_loss:2.136/278.514, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:37<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.11128640174866 seconds\n",
      "\n",
      "EPOCH 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "215-61/62 iter:100.00%, lr=['0.00018533980447508163'], iter/val_loss:3.857/278.066, tr:99.69%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.38909339904785 seconds\n",
      "\n",
      "EPOCH 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "216-61/62 iter:100.00%, lr=['0.00018128800512565537'], iter/val_loss:2.793/277.762, tr:99.90%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:32<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.1464569568634 seconds\n",
      "\n",
      "EPOCH 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "217-61/62 iter:100.00%, lr=['0.00017727115613802504'], iter/val_loss:4.486/275.877, tr:99.59%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.94690227508545 seconds\n",
      "\n",
      "EPOCH 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "218-61/62 iter:100.00%, lr=['0.00017328969800494765'], iter/val_loss:2.435/276.129, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.33385872840881 seconds\n",
      "\n",
      "EPOCH 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "219-61/62 iter:100.00%, lr=['0.0001693440673381742'], iter/val_loss:1.410/276.613, tr:99.69%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.2823977470398 seconds\n",
      "\n",
      "EPOCH 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "220-61/62 iter:100.00%, lr=['0.00016543469682057108'], iter/val_loss:5.156/277.588, tr:99.59%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.52238321304321 seconds\n",
      "\n",
      "EPOCH 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "221-61/62 iter:100.00%, lr=['0.0001615620151586699'], iter/val_loss:5.204/277.997, tr:99.80%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.72682452201843 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "222-61/62 iter:100.00%, lr=['0.00015772644703565585'], iter/val_loss:2.887/278.644, tr:99.59%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.83693647384644 seconds\n",
      "\n",
      "EPOCH 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223-61/62 iter:100.00%, lr=['0.00015392841306479687'], iter/val_loss:5.562/277.113, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.70606589317322 seconds\n",
      "\n",
      "EPOCH 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "224-61/62 iter:100.00%, lr=['0.00015016832974331742'], iter/val_loss:1.664/278.467, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.76204705238342 seconds\n",
      "\n",
      "EPOCH 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "225-61/62 iter:100.00%, lr=['0.00014644660940672644'], iter/val_loss:1.574/279.561, tr:99.90%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 101.0670747756958 seconds\n",
      "\n",
      "EPOCH 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "226-61/62 iter:100.00%, lr=['0.0001427636601835986'], iter/val_loss:1.625/279.485, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.78819704055786 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "227-61/62 iter:100.00%, lr=['0.0001391198859508191'], iter/val_loss:1.649/277.747, tr:99.69%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.19196963310242 seconds\n",
      "\n",
      "EPOCH 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "228-61/62 iter:100.00%, lr=['0.00013551568628929452'], iter/val_loss:3.391/279.725, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:27<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 88.26644086837769 seconds\n",
      "\n",
      "EPOCH 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "229-61/62 iter:100.00%, lr=['0.0001319514564401332'], iter/val_loss:2.561/278.614, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:23<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 83.74602961540222 seconds\n",
      "\n",
      "EPOCH 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "230-61/62 iter:100.00%, lr=['0.000128427587261303'], iter/val_loss:1.299/279.365, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.99722242355347 seconds\n",
      "\n",
      "EPOCH 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "231-61/62 iter:100.00%, lr=['0.00012494446518477039'], iter/val_loss:2.245/279.756, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.40014314651489 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "232-61/62 iter:100.00%, lr=['0.00012150247217412203'], iter/val_loss:0.598/279.846, tr:99.90%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.76775813102722 seconds\n",
      "\n",
      "EPOCH 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "233-61/62 iter:100.00%, lr=['0.00011810198568267905'], iter/val_loss:2.472/280.386, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.98838067054749 seconds\n",
      "\n",
      "EPOCH 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "234-61/62 iter:100.00%, lr=['0.00011474337861210558'], iter/val_loss:0.542/280.187, tr:99.90%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.69668292999268 seconds\n",
      "\n",
      "EPOCH 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "235-61/62 iter:100.00%, lr=['0.0001114270192715147'], iter/val_loss:2.692/279.198, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.0148434638977 seconds\n",
      "\n",
      "EPOCH 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "236-61/62 iter:100.00%, lr=['0.00010815327133708028'], iter/val_loss:8.293/279.168, tr:99.69%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.6772575378418 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "237-61/62 iter:100.00%, lr=['0.00010492249381215504'], iter/val_loss:2.753/280.805, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:17<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 78.31499123573303 seconds\n",
      "\n",
      "EPOCH 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "238-61/62 iter:100.00%, lr=['0.000101735040987902'], iter/val_loss:3.928/281.608, tr:99.80%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:28<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 89.06604146957397 seconds\n",
      "\n",
      "EPOCH 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "239-61/62 iter:100.00%, lr=['9.859126240444295e-05'], iter/val_loss:3.155/280.976, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:37<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.66279006004333 seconds\n",
      "\n",
      "EPOCH 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "240-61/62 iter:100.00%, lr=['9.549150281252645e-05'], iter/val_loss:3.213/281.046, tr:99.80%, val:74.58%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.41546726226807 seconds\n",
      "\n",
      "EPOCH 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "241-61/62 iter:100.00%, lr=['9.243610213572296e-05'], iter/val_loss:1.623/281.089, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:32<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.3293285369873 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "242-61/62 iter:100.00%, lr=['8.942539543314809e-05'], iter/val_loss:1.998/280.693, tr:99.90%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.95355892181396 seconds\n",
      "\n",
      "EPOCH 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "243-61/62 iter:100.00%, lr=['8.645971286271914e-05'], iter/val_loss:2.286/281.804, tr:99.59%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.95856142044067 seconds\n",
      "\n",
      "EPOCH 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "244-61/62 iter:100.00%, lr=['8.353937964495038e-05'], iter/val_loss:3.929/280.033, tr:99.80%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:27<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 88.05357909202576 seconds\n",
      "\n",
      "EPOCH 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "245-61/62 iter:100.00%, lr=['8.066471602728812e-05'], iter/val_loss:4.208/280.882, tr:99.69%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.97618222236633 seconds\n",
      "\n",
      "EPOCH 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "246-61/62 iter:100.00%, lr=['7.783603724899255e-05'], iter/val_loss:4.275/280.000, tr:99.80%, val:75.00%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.2393445968628 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "247-61/62 iter:100.00%, lr=['7.50536535065682e-05'], iter/val_loss:3.284/280.518, tr:99.90%, val:75.42%, val_best:78.33%: 100%|██████████| 62/62 [01:26<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 87.15935754776001 seconds\n",
      "\n",
      "EPOCH 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "248-61/62 iter:100.00%, lr=['7.231786991974678e-05'], iter/val_loss:2.459/281.643, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:28<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 88.9959864616394 seconds\n",
      "\n",
      "EPOCH 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "249-61/62 iter:100.00%, lr=['6.962898649802832e-05'], iter/val_loss:5.673/281.081, tr:99.69%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.44631505012512 seconds\n",
      "\n",
      "EPOCH 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250-61/62 iter:100.00%, lr=['6.698729810778084e-05'], iter/val_loss:2.997/282.255, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.56157636642456 seconds\n",
      "\n",
      "EPOCH 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251-61/62 iter:100.00%, lr=['6.439309443990528e-05'], iter/val_loss:3.525/282.019, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.13333630561829 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "252-61/62 iter:100.00%, lr=['6.184665997806828e-05'], iter/val_loss:3.353/282.005, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.99276614189148 seconds\n",
      "\n",
      "EPOCH 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "253-61/62 iter:100.00%, lr=['5.9348273967503985e-05'], iter/val_loss:4.405/280.798, tr:99.90%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:37<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.99345111846924 seconds\n",
      "\n",
      "EPOCH 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "254-61/62 iter:100.00%, lr=['5.68982103843927e-05'], iter/val_loss:2.250/281.513, tr:99.80%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:32<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 92.89329528808594 seconds\n",
      "\n",
      "EPOCH 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "255-61/62 iter:100.00%, lr=['5.449673790581617e-05'], iter/val_loss:1.422/281.918, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.99299621582031 seconds\n",
      "\n",
      "EPOCH 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "256-61/62 iter:100.00%, lr=['5.214411988029372e-05'], iter/val_loss:1.228/281.877, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.03448414802551 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "257-61/62 iter:100.00%, lr=['4.98406142989033e-05'], iter/val_loss:1.503/281.002, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.7220253944397 seconds\n",
      "\n",
      "EPOCH 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "258-61/62 iter:100.00%, lr=['4.758647376699038e-05'], iter/val_loss:0.971/281.690, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.857253074646 seconds\n",
      "\n",
      "EPOCH 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "259-61/62 iter:100.00%, lr=['4.5381945476465794e-05'], iter/val_loss:1.643/281.330, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.06176829338074 seconds\n",
      "\n",
      "EPOCH 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "260-61/62 iter:100.00%, lr=['4.322727117869968e-05'], iter/val_loss:2.993/281.730, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.41291880607605 seconds\n",
      "\n",
      "EPOCH 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "261-61/62 iter:100.00%, lr=['4.1122687158009595e-05'], iter/val_loss:4.805/281.479, tr:99.80%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.29628372192383 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "262-61/62 iter:100.00%, lr=['3.906842420574974e-05'], iter/val_loss:1.977/281.635, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 93.9524986743927 seconds\n",
      "\n",
      "EPOCH 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "263-61/62 iter:100.00%, lr=['3.706470759500268e-05'], iter/val_loss:5.276/282.091, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.5627806186676 seconds\n",
      "\n",
      "EPOCH 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "264-61/62 iter:100.00%, lr=['3.511175705587437e-05'], iter/val_loss:8.060/282.354, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.83168172836304 seconds\n",
      "\n",
      "EPOCH 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "265-61/62 iter:100.00%, lr=['3.320978675139917e-05'], iter/val_loss:4.822/282.787, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:31<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 92.42600607872009 seconds\n",
      "\n",
      "EPOCH 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "266-61/62 iter:100.00%, lr=['3.1359005254054315e-05'], iter/val_loss:1.459/282.895, tr:99.90%, val:75.83%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.61581993103027 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "267-61/62 iter:100.00%, lr=['2.9559615522887314e-05'], iter/val_loss:2.202/283.158, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:31<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 92.24939155578613 seconds\n",
      "\n",
      "EPOCH 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "268-61/62 iter:100.00%, lr=['2.781181488125954e-05'], iter/val_loss:4.102/282.618, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.26709771156311 seconds\n",
      "\n",
      "EPOCH 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "269-61/62 iter:100.00%, lr=['2.611579499520726e-05'], iter/val_loss:4.762/282.715, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.3190815448761 seconds\n",
      "\n",
      "EPOCH 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "270-61/62 iter:100.00%, lr=['2.447174185242327e-05'], iter/val_loss:5.863/283.643, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.26267147064209 seconds\n",
      "\n",
      "EPOCH 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "271-61/62 iter:100.00%, lr=['2.287983574186162e-05'], iter/val_loss:3.719/282.741, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.67332482337952 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "272-61/62 iter:100.00%, lr=['2.134025123396641e-05'], iter/val_loss:3.691/282.927, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.4955062866211 seconds\n",
      "\n",
      "EPOCH 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "273-61/62 iter:100.00%, lr=['1.9853157161528496e-05'], iter/val_loss:5.688/282.368, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.28780341148376 seconds\n",
      "\n",
      "EPOCH 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "274-61/62 iter:66.67%, lr=['1.8418716601170976e-05'], iter/val_loss:4.307/283.491, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:33<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.13726735115051 seconds\n",
      "\n",
      "EPOCH 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "275-61/62 iter:100.00%, lr=['1.703708685546587e-05'], iter/val_loss:2.231/282.624, tr:99.90%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.52390456199646 seconds\n",
      "\n",
      "EPOCH 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "276-61/62 iter:100.00%, lr=['1.5708419435684487e-05'], iter/val_loss:4.782/282.659, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:25<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 86.09032154083252 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "277-61/62 iter:100.00%, lr=['1.443286004518204e-05'], iter/val_loss:2.605/283.024, tr:99.90%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:25<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 85.77318048477173 seconds\n",
      "\n",
      "EPOCH 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "278-61/62 iter:100.00%, lr=['1.3210548563419875e-05'], iter/val_loss:7.349/283.451, tr:99.90%, val:77.50%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 94.91532611846924 seconds\n",
      "\n",
      "EPOCH 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "279-61/62 iter:100.00%, lr=['1.2041619030626357e-05'], iter/val_loss:6.344/283.000, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.07726716995239 seconds\n",
      "\n",
      "EPOCH 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "280-61/62 iter:100.00%, lr=['1.0926199633097227e-05'], iter/val_loss:3.202/283.142, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.66714024543762 seconds\n",
      "\n",
      "EPOCH 281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "281-61/62 iter:100.00%, lr=['9.864412689139138e-06'], iter/val_loss:5.205/283.412, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.68903517723083 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "282-61/62 iter:100.00%, lr=['8.856374635655707e-06'], iter/val_loss:0.734/283.679, tr:99.90%, val:76.25%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 96.00857424736023 seconds\n",
      "\n",
      "EPOCH 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "283-61/62 iter:100.00%, lr=['7.90219601537907e-06'], iter/val_loss:5.132/283.691, tr:99.90%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.86097931861877 seconds\n",
      "\n",
      "EPOCH 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "284-61/62 iter:100.00%, lr=['7.001981464747518e-06'], iter/val_loss:2.497/283.279, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:30<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 91.15313625335693 seconds\n",
      "\n",
      "EPOCH 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "285-61/62 iter:100.00%, lr=['6.155829702431179e-06'], iter/val_loss:4.472/283.269, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:25<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 85.36584281921387 seconds\n",
      "\n",
      "EPOCH 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "286-61/62 iter:100.00%, lr=['5.363833518505841e-06'], iter/val_loss:3.381/283.159, tr:99.90%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:31<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 91.40845894813538 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "287-61/62 iter:100.00%, lr=['4.6260797642782075e-06'], iter/val_loss:3.048/283.114, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.40711975097656 seconds\n",
      "\n",
      "EPOCH 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "288-61/62 iter:100.00%, lr=['3.9426493427611224e-06'], iter/val_loss:5.795/283.096, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.13298678398132 seconds\n",
      "\n",
      "EPOCH 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "289-61/62 iter:100.00%, lr=['3.3136171998017812e-06'], iter/val_loss:6.903/282.991, tr:99.80%, val:77.08%, val_best:78.33%: 100%|██████████| 62/62 [01:32<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 92.94055557250977 seconds\n",
      "\n",
      "EPOCH 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "290-61/62 iter:100.00%, lr=['2.7390523158633588e-06'], iter/val_loss:0.118/282.995, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.35981750488281 seconds\n",
      "\n",
      "EPOCH 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "291-61/62 iter:100.00%, lr=['2.219017698460005e-06'], iter/val_loss:1.897/283.119, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.58568334579468 seconds\n",
      "\n",
      "\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "==================== e-transport DFA --> BP ===============================================\n",
      "\n",
      "\n",
      "EPOCH 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "292-61/62 iter:100.00%, lr=['1.753570375247817e-06'], iter/val_loss:5.433/283.071, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.33578133583069 seconds\n",
      "\n",
      "EPOCH 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "293-61/62 iter:100.00%, lr=['1.3427613877709538e-06'], iter/val_loss:2.983/283.307, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:36<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 97.32495093345642 seconds\n",
      "\n",
      "EPOCH 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "294-61/62 iter:100.00%, lr=['9.86635785864222e-07'], iter/val_loss:3.550/283.319, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.54961323738098 seconds\n",
      "\n",
      "EPOCH 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "295-61/62 iter:100.00%, lr=['6.852326227130843e-07'], iter/val_loss:2.868/283.285, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:34<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.14524292945862 seconds\n",
      "\n",
      "EPOCH 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "296-61/62 iter:100.00%, lr=['4.38584950570809e-07'], iter/val_loss:2.843/283.240, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:38<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 98.89737010002136 seconds\n",
      "\n",
      "\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "==================== e-transport BP --> DFA ===============================================\n",
      "\n",
      "\n",
      "EPOCH 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "297-61/62 iter:100.00%, lr=['2.467198171342003e-07'], iter/val_loss:1.503/283.200, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:40<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 100.81619310379028 seconds\n",
      "\n",
      "EPOCH 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "298-61/62 iter:100.00%, lr=['1.0965826257725033e-07'], iter/val_loss:0.954/283.281, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:35<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 95.42099738121033 seconds\n",
      "\n",
      "EPOCH 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "299-61/62 iter:100.00%, lr=['2.7415317243928465e-08'], iter/val_loss:3.583/283.281, tr:99.80%, val:76.67%, val_best:78.33%: 100%|██████████| 62/62 [01:39<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 99.8337652683258 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nddp_on 키고, gpu 개수 만큼 batch size 나눠줘\\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\\nCUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\\nCUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "if const2 == True:\n",
    "    const2 = decay\n",
    "else:\n",
    "    const2 = 0.0\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "my_snn_system(  devices = \"4\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'DVS_GESTURE_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                cfg = ['M','M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = 5, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = 5, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                \n",
    "                drop_rate = 0.0,\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# DDP 실행 코드\n",
    "'''\n",
    "ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# run_name = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.009]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"decay\": {\"values\": [0.25, 0.5, 0.75]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"epoch_num\": {\"values\": [40]},\n",
    "#         \"dvs_duration\": {\"values\": [100_000]},\n",
    "#         \"dvs_clipping\": {\"values\": [2]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "#         \"const2\": {\"values\": [False]},\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "#         \"DFA_on\": {\"values\": [False]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "#         \"e_transport_swap\": {\"values\": [5]},\n",
    "#         \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "#         \"drop_rate\": {\"min\": 0.25, \"max\": 0.75}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]},\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init(save_code = True)\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     BATCH  =  wandb.config.BATCH\n",
    "#     decay  =  wandb.config.decay\n",
    "#     IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     epoch_num  =  wandb.config.epoch_num \n",
    "#     dvs_duration  =  wandb.config.dvs_duration\n",
    "#     dvs_clipping  =  wandb.config.dvs_clipping\n",
    "#     which_data  =  wandb.config.which_data\n",
    "#     OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "#     const2  =  wandb.config.const2\n",
    "#     surrogate  =  wandb.config.surrogate\n",
    "#     DFA_on  =  wandb.config.DFA_on\n",
    "#     OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "#     cfg  =  wandb.config.cfg\n",
    "#     e_transport_swap  =  wandb.config.e_transport_swap\n",
    "#     e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "#     drop_rate  =  wandb.config.drop_rate\n",
    "#     exclude_class  =  wandb.config.exclude_class\n",
    "#     if const2 == True:\n",
    "#         const2 = decay\n",
    "#     else:\n",
    "#         const2 = 0.0\n",
    "\n",
    "#     my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = which_data,\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 cfg = cfg,\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [], \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = epoch_num,\n",
    "#                 verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    \n",
    "#                 drop_rate = drop_rate,\n",
    "\n",
    "#                 exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcd32ed88f846668e33b43759f9d24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='23.849 MB of 23.849 MB uploaded (22.195 MB deduped)\\r'), FloatProgress(value=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 87.9%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▃▁▅▇▆▇█▆██▇█████████████████████████▇█</td></tr><tr><td>summary_val_acc</td><td>▁▁▅▄▅▅▆▆▆▆█▆▆▇▇█▇▇▇▇▇█▇▇█▇██████▇███████</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▆▆▆▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▅▄▅▅▆▆▆▆█▆▆▇▇█▇▇▇▇▇█▇▇█▇██████▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>299</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-waterfall-3114</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p6kb7e2c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p6kb7e2c</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 37 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240819_001650-p6kb7e2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
